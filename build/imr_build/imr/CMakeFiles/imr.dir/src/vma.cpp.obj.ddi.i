# 0 "C:/Users/darkg/HAG/imr_mesh/imr/src/vma.cpp"
# 0 "<built-in>"
# 0 "<command-line>"
# 1 "C:/Users/darkg/HAG/imr_mesh/imr/src/vma.cpp"


# 1 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 1
# 128 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
extern "C" {



# 1 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan.h" 1 3 4
# 10 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan.h" 3 4
# 1 "C:/VulkanSDK/1.4.304.1/include/vulkan/vk_platform.h" 1 3 4
# 15 "C:/VulkanSDK/1.4.304.1/include/vulkan/vk_platform.h" 3 4

# 15 "C:/VulkanSDK/1.4.304.1/include/vulkan/vk_platform.h" 3 4
extern "C"
{
# 62 "C:/VulkanSDK/1.4.304.1/include/vulkan/vk_platform.h" 3 4
# 1 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/stddef.h" 1 3 4
# 1 "C:/msys64/mingw64/include/stddef.h" 1 3 4






# 1 "C:/msys64/mingw64/include/crtdefs.h" 1 3 4
# 10 "C:/msys64/mingw64/include/crtdefs.h" 3 4
# 1 "C:/msys64/mingw64/include/corecrt.h" 1 3 4
# 10 "C:/msys64/mingw64/include/corecrt.h" 3 4
# 1 "C:/msys64/mingw64/include/_mingw.h" 1 3 4
# 10 "C:/msys64/mingw64/include/_mingw.h" 3 4
# 1 "C:/msys64/mingw64/include/_mingw_mac.h" 1 3 4
# 108 "C:/msys64/mingw64/include/_mingw_mac.h" 3 4
             
# 117 "C:/msys64/mingw64/include/_mingw_mac.h" 3 4
             
# 326 "C:/msys64/mingw64/include/_mingw_mac.h" 3 4
       
# 405 "C:/msys64/mingw64/include/_mingw_mac.h" 3 4
       
# 11 "C:/msys64/mingw64/include/_mingw.h" 2 3 4
# 1 "C:/msys64/mingw64/include/_mingw_secapi.h" 1 3 4
# 44 "C:/msys64/mingw64/include/_mingw_secapi.h" 3 4
extern "C++" {
template <bool __test, typename __dsttype>
  struct __if_array;
template <typename __dsttype>
  struct __if_array <true, __dsttype> {
    typedef __dsttype __type;
};
}
# 12 "C:/msys64/mingw64/include/_mingw.h" 2 3 4
# 306 "C:/msys64/mingw64/include/_mingw.h" 3 4
# 1 "C:/msys64/mingw64/include/vadefs.h" 1 3 4
# 9 "C:/msys64/mingw64/include/vadefs.h" 3 4
# 1 "C:/msys64/mingw64/include/_mingw.h" 1 3 4
# 685 "C:/msys64/mingw64/include/_mingw.h" 3 4
# 1 "C:/msys64/mingw64/include/sdks/_mingw_ddk.h" 1 3 4
# 686 "C:/msys64/mingw64/include/_mingw.h" 2 3 4
# 10 "C:/msys64/mingw64/include/vadefs.h" 2 3 4




#pragma pack(push,_CRT_PACKING)



extern "C" {





  typedef __builtin_va_list __gnuc_va_list;






  typedef __gnuc_va_list va_list;
# 99 "C:/msys64/mingw64/include/vadefs.h" 3 4
}



#pragma pack(pop)
# 307 "C:/msys64/mingw64/include/_mingw.h" 2 3 4
# 592 "C:/msys64/mingw64/include/_mingw.h" 3 4
extern "C" {
# 604 "C:/msys64/mingw64/include/_mingw.h" 3 4
void __attribute__((__cdecl__)) __debugbreak(void);
extern __inline__ __attribute__((__always_inline__,__gnu_inline__)) void __attribute__((__cdecl__)) __debugbreak(void)
{



  __asm__ __volatile__("int {$}3":);





}
# 625 "C:/msys64/mingw64/include/_mingw.h" 3 4
void __attribute__((__cdecl__)) __attribute__ ((__noreturn__)) __fastfail(unsigned int code);
extern __inline__ __attribute__((__always_inline__,__gnu_inline__)) void __attribute__((__cdecl__)) __attribute__ ((__noreturn__)) __fastfail(unsigned int code)
{




  __asm__ __volatile__("int {$}0x29"::"c"(code));






  __builtin_unreachable();
}
# 665 "C:/msys64/mingw64/include/_mingw.h" 3 4
const char *__mingw_get_crt_info (void);


}
# 11 "C:/msys64/mingw64/include/corecrt.h" 2 3 4




#pragma pack(push,_CRT_PACKING)
# 35 "C:/msys64/mingw64/include/corecrt.h" 3 4
__extension__ typedef unsigned long long size_t;
# 45 "C:/msys64/mingw64/include/corecrt.h" 3 4
__extension__ typedef long long ssize_t;






typedef size_t rsize_t;
# 62 "C:/msys64/mingw64/include/corecrt.h" 3 4
__extension__ typedef long long intptr_t;
# 75 "C:/msys64/mingw64/include/corecrt.h" 3 4
__extension__ typedef unsigned long long uintptr_t;
# 88 "C:/msys64/mingw64/include/corecrt.h" 3 4
__extension__ typedef long long ptrdiff_t;
# 106 "C:/msys64/mingw64/include/corecrt.h" 3 4
typedef unsigned short wint_t;
typedef unsigned short wctype_t;





typedef int errno_t;




typedef long __time32_t;




__extension__ typedef long long __time64_t;
# 138 "C:/msys64/mingw64/include/corecrt.h" 3 4
typedef __time64_t time_t;
# 430 "C:/msys64/mingw64/include/corecrt.h" 3 4
struct threadlocaleinfostruct;
struct threadmbcinfostruct;
typedef struct threadlocaleinfostruct *pthreadlocinfo;
typedef struct threadmbcinfostruct *pthreadmbcinfo;
struct __lc_time_data;

typedef struct localeinfo_struct {
  pthreadlocinfo locinfo;
  pthreadmbcinfo mbcinfo;
} _locale_tstruct,*_locale_t;



typedef struct tagLC_ID {
  unsigned short wLanguage;
  unsigned short wCountry;
  unsigned short wCodePage;
} LC_ID,*LPLC_ID;




typedef struct threadlocaleinfostruct {





  int refcount;
  unsigned int lc_codepage;
  unsigned int lc_collate_cp;
  unsigned long lc_handle[6];
  LC_ID lc_id[6];
  struct {
    char *locale;
    wchar_t *wlocale;
    int *refcount;
    int *wrefcount;
  } lc_category[6];
  int lc_clike;
  int mb_cur_max;
  int *lconv_intl_refcount;
  int *lconv_num_refcount;
  int *lconv_mon_refcount;
  struct lconv *lconv;
  int *ctype1_refcount;
  unsigned short *ctype1;
  const unsigned short *pctype;
  const unsigned char *pclmap;
  const unsigned char *pcumap;
  struct __lc_time_data *lc_time_curr;

} threadlocinfo;
# 501 "C:/msys64/mingw64/include/corecrt.h" 3 4
#pragma pack(pop)
# 11 "C:/msys64/mingw64/include/crtdefs.h" 2 3 4
# 8 "C:/msys64/mingw64/include/stddef.h" 2 3 4





extern "C" {




  __attribute__ ((__dllimport__)) extern int *__attribute__((__cdecl__)) _errno(void);

  errno_t __attribute__((__cdecl__)) _set_errno(int _Value);
  errno_t __attribute__((__cdecl__)) _get_errno(int *_Value);


  __attribute__ ((__dllimport__)) extern unsigned long __attribute__((__cdecl__)) __threadid(void);

  __attribute__ ((__dllimport__)) extern uintptr_t __attribute__((__cdecl__)) __threadhandle(void);


}
# 424 "C:/msys64/mingw64/include/stddef.h" 3 4
typedef struct {
  long long __max_align_ll __attribute__((__aligned__(__alignof__(long long))));
  long double __max_align_ld __attribute__((__aligned__(__alignof__(long double))));
} max_align_t;
# 2 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/stddef.h" 2 3 4
# 63 "C:/VulkanSDK/1.4.304.1/include/vulkan/vk_platform.h" 2 3 4
# 76 "C:/VulkanSDK/1.4.304.1/include/vulkan/vk_platform.h" 3 4
# 1 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/stdint.h" 1 3 4
# 9 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/stdint.h" 3 4
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wpedantic"
# 1 "C:/msys64/mingw64/include/stdint.h" 1 3 4
# 32 "C:/msys64/mingw64/include/stdint.h" 3 4
# 1 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/stddef.h" 1 3 4
# 1 "C:/msys64/mingw64/include/stddef.h" 1 3 4
# 2 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/stddef.h" 2 3 4
# 33 "C:/msys64/mingw64/include/stdint.h" 2 3 4


typedef signed char int8_t;
typedef unsigned char uint8_t;
typedef short int16_t;
typedef unsigned short uint16_t;
typedef int int32_t;
typedef unsigned uint32_t;
__extension__ typedef long long int64_t;
__extension__ typedef unsigned long long uint64_t;


typedef signed char int_least8_t;
typedef unsigned char uint_least8_t;
typedef short int_least16_t;
typedef unsigned short uint_least16_t;
typedef int int_least32_t;
typedef unsigned uint_least32_t;
__extension__ typedef long long int_least64_t;
__extension__ typedef unsigned long long uint_least64_t;





typedef signed char int_fast8_t;
typedef unsigned char uint_fast8_t;
typedef short int_fast16_t;
typedef unsigned short uint_fast16_t;
typedef int int_fast32_t;
typedef unsigned int uint_fast32_t;
__extension__ typedef long long int_fast64_t;
__extension__ typedef unsigned long long uint_fast64_t;


__extension__ typedef long long intmax_t;
__extension__ typedef unsigned long long uintmax_t;
# 12 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/stdint.h" 2 3 4
#pragma GCC diagnostic pop
# 77 "C:/VulkanSDK/1.4.304.1/include/vulkan/vk_platform.h" 2 3 4




}
# 11 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan.h" 2 3 4
# 1 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 1 3 4
# 17 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
extern "C" {
# 98 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef uint32_t VkBool32;
typedef uint64_t VkDeviceAddress;
typedef uint64_t VkDeviceSize;
typedef uint32_t VkFlags;
typedef uint32_t VkSampleMask;
typedef struct VkBuffer_T *VkBuffer;
typedef struct VkImage_T *VkImage;
typedef struct VkInstance_T* VkInstance;
typedef struct VkPhysicalDevice_T* VkPhysicalDevice;
typedef struct VkDevice_T* VkDevice;
typedef struct VkQueue_T* VkQueue;
typedef struct VkSemaphore_T *VkSemaphore;
typedef struct VkCommandBuffer_T* VkCommandBuffer;
typedef struct VkFence_T *VkFence;
typedef struct VkDeviceMemory_T *VkDeviceMemory;
typedef struct VkEvent_T *VkEvent;
typedef struct VkQueryPool_T *VkQueryPool;
typedef struct VkBufferView_T *VkBufferView;
typedef struct VkImageView_T *VkImageView;
typedef struct VkShaderModule_T *VkShaderModule;
typedef struct VkPipelineCache_T *VkPipelineCache;
typedef struct VkPipelineLayout_T *VkPipelineLayout;
typedef struct VkPipeline_T *VkPipeline;
typedef struct VkRenderPass_T *VkRenderPass;
typedef struct VkDescriptorSetLayout_T *VkDescriptorSetLayout;
typedef struct VkSampler_T *VkSampler;
typedef struct VkDescriptorSet_T *VkDescriptorSet;
typedef struct VkDescriptorPool_T *VkDescriptorPool;
typedef struct VkFramebuffer_T *VkFramebuffer;
typedef struct VkCommandPool_T *VkCommandPool;
# 144 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkResult {
    VK_SUCCESS = 0,
    VK_NOT_READY = 1,
    VK_TIMEOUT = 2,
    VK_EVENT_SET = 3,
    VK_EVENT_RESET = 4,
    VK_INCOMPLETE = 5,
    VK_ERROR_OUT_OF_HOST_MEMORY = -1,
    VK_ERROR_OUT_OF_DEVICE_MEMORY = -2,
    VK_ERROR_INITIALIZATION_FAILED = -3,
    VK_ERROR_DEVICE_LOST = -4,
    VK_ERROR_MEMORY_MAP_FAILED = -5,
    VK_ERROR_LAYER_NOT_PRESENT = -6,
    VK_ERROR_EXTENSION_NOT_PRESENT = -7,
    VK_ERROR_FEATURE_NOT_PRESENT = -8,
    VK_ERROR_INCOMPATIBLE_DRIVER = -9,
    VK_ERROR_TOO_MANY_OBJECTS = -10,
    VK_ERROR_FORMAT_NOT_SUPPORTED = -11,
    VK_ERROR_FRAGMENTED_POOL = -12,
    VK_ERROR_UNKNOWN = -13,
    VK_ERROR_OUT_OF_POOL_MEMORY = -1000069000,
    VK_ERROR_INVALID_EXTERNAL_HANDLE = -1000072003,
    VK_ERROR_FRAGMENTATION = -1000161000,
    VK_ERROR_INVALID_OPAQUE_CAPTURE_ADDRESS = -1000257000,
    VK_PIPELINE_COMPILE_REQUIRED = 1000297000,
    VK_ERROR_NOT_PERMITTED = -1000174001,
    VK_ERROR_SURFACE_LOST_KHR = -1000000000,
    VK_ERROR_NATIVE_WINDOW_IN_USE_KHR = -1000000001,
    VK_SUBOPTIMAL_KHR = 1000001003,
    VK_ERROR_OUT_OF_DATE_KHR = -1000001004,
    VK_ERROR_INCOMPATIBLE_DISPLAY_KHR = -1000003001,
    VK_ERROR_VALIDATION_FAILED_EXT = -1000011001,
    VK_ERROR_INVALID_SHADER_NV = -1000012000,
    VK_ERROR_IMAGE_USAGE_NOT_SUPPORTED_KHR = -1000023000,
    VK_ERROR_VIDEO_PICTURE_LAYOUT_NOT_SUPPORTED_KHR = -1000023001,
    VK_ERROR_VIDEO_PROFILE_OPERATION_NOT_SUPPORTED_KHR = -1000023002,
    VK_ERROR_VIDEO_PROFILE_FORMAT_NOT_SUPPORTED_KHR = -1000023003,
    VK_ERROR_VIDEO_PROFILE_CODEC_NOT_SUPPORTED_KHR = -1000023004,
    VK_ERROR_VIDEO_STD_VERSION_NOT_SUPPORTED_KHR = -1000023005,
    VK_ERROR_INVALID_DRM_FORMAT_MODIFIER_PLANE_LAYOUT_EXT = -1000158000,
    VK_ERROR_FULL_SCREEN_EXCLUSIVE_MODE_LOST_EXT = -1000255000,
    VK_THREAD_IDLE_KHR = 1000268000,
    VK_THREAD_DONE_KHR = 1000268001,
    VK_OPERATION_DEFERRED_KHR = 1000268002,
    VK_OPERATION_NOT_DEFERRED_KHR = 1000268003,
    VK_ERROR_INVALID_VIDEO_STD_PARAMETERS_KHR = -1000299000,
    VK_ERROR_COMPRESSION_EXHAUSTED_EXT = -1000338000,
    VK_INCOMPATIBLE_SHADER_BINARY_EXT = 1000482000,
    VK_PIPELINE_BINARY_MISSING_KHR = 1000483000,
    VK_ERROR_NOT_ENOUGH_SPACE_KHR = -1000483000,
    VK_ERROR_OUT_OF_POOL_MEMORY_KHR = VK_ERROR_OUT_OF_POOL_MEMORY,
    VK_ERROR_INVALID_EXTERNAL_HANDLE_KHR = VK_ERROR_INVALID_EXTERNAL_HANDLE,
    VK_ERROR_FRAGMENTATION_EXT = VK_ERROR_FRAGMENTATION,
    VK_ERROR_NOT_PERMITTED_EXT = VK_ERROR_NOT_PERMITTED,
    VK_ERROR_NOT_PERMITTED_KHR = VK_ERROR_NOT_PERMITTED,
    VK_ERROR_INVALID_DEVICE_ADDRESS_EXT = VK_ERROR_INVALID_OPAQUE_CAPTURE_ADDRESS,
    VK_ERROR_INVALID_OPAQUE_CAPTURE_ADDRESS_KHR = VK_ERROR_INVALID_OPAQUE_CAPTURE_ADDRESS,
    VK_PIPELINE_COMPILE_REQUIRED_EXT = VK_PIPELINE_COMPILE_REQUIRED,
    VK_ERROR_PIPELINE_COMPILE_REQUIRED_EXT = VK_PIPELINE_COMPILE_REQUIRED,

    VK_ERROR_INCOMPATIBLE_SHADER_BINARY_EXT = VK_INCOMPATIBLE_SHADER_BINARY_EXT,
    VK_RESULT_MAX_ENUM = 0x7FFFFFFF
} VkResult;

typedef enum VkStructureType {
    VK_STRUCTURE_TYPE_APPLICATION_INFO = 0,
    VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO = 1,
    VK_STRUCTURE_TYPE_DEVICE_QUEUE_CREATE_INFO = 2,
    VK_STRUCTURE_TYPE_DEVICE_CREATE_INFO = 3,
    VK_STRUCTURE_TYPE_SUBMIT_INFO = 4,
    VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO = 5,
    VK_STRUCTURE_TYPE_MAPPED_MEMORY_RANGE = 6,
    VK_STRUCTURE_TYPE_BIND_SPARSE_INFO = 7,
    VK_STRUCTURE_TYPE_FENCE_CREATE_INFO = 8,
    VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO = 9,
    VK_STRUCTURE_TYPE_EVENT_CREATE_INFO = 10,
    VK_STRUCTURE_TYPE_QUERY_POOL_CREATE_INFO = 11,
    VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO = 12,
    VK_STRUCTURE_TYPE_BUFFER_VIEW_CREATE_INFO = 13,
    VK_STRUCTURE_TYPE_IMAGE_CREATE_INFO = 14,
    VK_STRUCTURE_TYPE_IMAGE_VIEW_CREATE_INFO = 15,
    VK_STRUCTURE_TYPE_SHADER_MODULE_CREATE_INFO = 16,
    VK_STRUCTURE_TYPE_PIPELINE_CACHE_CREATE_INFO = 17,
    VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO = 18,
    VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_STATE_CREATE_INFO = 19,
    VK_STRUCTURE_TYPE_PIPELINE_INPUT_ASSEMBLY_STATE_CREATE_INFO = 20,
    VK_STRUCTURE_TYPE_PIPELINE_TESSELLATION_STATE_CREATE_INFO = 21,
    VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_STATE_CREATE_INFO = 22,
    VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_STATE_CREATE_INFO = 23,
    VK_STRUCTURE_TYPE_PIPELINE_MULTISAMPLE_STATE_CREATE_INFO = 24,
    VK_STRUCTURE_TYPE_PIPELINE_DEPTH_STENCIL_STATE_CREATE_INFO = 25,
    VK_STRUCTURE_TYPE_PIPELINE_COLOR_BLEND_STATE_CREATE_INFO = 26,
    VK_STRUCTURE_TYPE_PIPELINE_DYNAMIC_STATE_CREATE_INFO = 27,
    VK_STRUCTURE_TYPE_GRAPHICS_PIPELINE_CREATE_INFO = 28,
    VK_STRUCTURE_TYPE_COMPUTE_PIPELINE_CREATE_INFO = 29,
    VK_STRUCTURE_TYPE_PIPELINE_LAYOUT_CREATE_INFO = 30,
    VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO = 31,
    VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO = 32,
    VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO = 33,
    VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO = 34,
    VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET = 35,
    VK_STRUCTURE_TYPE_COPY_DESCRIPTOR_SET = 36,
    VK_STRUCTURE_TYPE_FRAMEBUFFER_CREATE_INFO = 37,
    VK_STRUCTURE_TYPE_RENDER_PASS_CREATE_INFO = 38,
    VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO = 39,
    VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO = 40,
    VK_STRUCTURE_TYPE_COMMAND_BUFFER_INHERITANCE_INFO = 41,
    VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO = 42,
    VK_STRUCTURE_TYPE_RENDER_PASS_BEGIN_INFO = 43,
    VK_STRUCTURE_TYPE_BUFFER_MEMORY_BARRIER = 44,
    VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER = 45,
    VK_STRUCTURE_TYPE_MEMORY_BARRIER = 46,
    VK_STRUCTURE_TYPE_LOADER_INSTANCE_CREATE_INFO = 47,
    VK_STRUCTURE_TYPE_LOADER_DEVICE_CREATE_INFO = 48,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SUBGROUP_PROPERTIES = 1000094000,
    VK_STRUCTURE_TYPE_BIND_BUFFER_MEMORY_INFO = 1000157000,
    VK_STRUCTURE_TYPE_BIND_IMAGE_MEMORY_INFO = 1000157001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_16BIT_STORAGE_FEATURES = 1000083000,
    VK_STRUCTURE_TYPE_MEMORY_DEDICATED_REQUIREMENTS = 1000127000,
    VK_STRUCTURE_TYPE_MEMORY_DEDICATED_ALLOCATE_INFO = 1000127001,
    VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_FLAGS_INFO = 1000060000,
    VK_STRUCTURE_TYPE_DEVICE_GROUP_RENDER_PASS_BEGIN_INFO = 1000060003,
    VK_STRUCTURE_TYPE_DEVICE_GROUP_COMMAND_BUFFER_BEGIN_INFO = 1000060004,
    VK_STRUCTURE_TYPE_DEVICE_GROUP_SUBMIT_INFO = 1000060005,
    VK_STRUCTURE_TYPE_DEVICE_GROUP_BIND_SPARSE_INFO = 1000060006,
    VK_STRUCTURE_TYPE_BIND_BUFFER_MEMORY_DEVICE_GROUP_INFO = 1000060013,
    VK_STRUCTURE_TYPE_BIND_IMAGE_MEMORY_DEVICE_GROUP_INFO = 1000060014,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_GROUP_PROPERTIES = 1000070000,
    VK_STRUCTURE_TYPE_DEVICE_GROUP_DEVICE_CREATE_INFO = 1000070001,
    VK_STRUCTURE_TYPE_BUFFER_MEMORY_REQUIREMENTS_INFO_2 = 1000146000,
    VK_STRUCTURE_TYPE_IMAGE_MEMORY_REQUIREMENTS_INFO_2 = 1000146001,
    VK_STRUCTURE_TYPE_IMAGE_SPARSE_MEMORY_REQUIREMENTS_INFO_2 = 1000146002,
    VK_STRUCTURE_TYPE_MEMORY_REQUIREMENTS_2 = 1000146003,
    VK_STRUCTURE_TYPE_SPARSE_IMAGE_MEMORY_REQUIREMENTS_2 = 1000146004,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FEATURES_2 = 1000059000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PROPERTIES_2 = 1000059001,
    VK_STRUCTURE_TYPE_FORMAT_PROPERTIES_2 = 1000059002,
    VK_STRUCTURE_TYPE_IMAGE_FORMAT_PROPERTIES_2 = 1000059003,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_FORMAT_INFO_2 = 1000059004,
    VK_STRUCTURE_TYPE_QUEUE_FAMILY_PROPERTIES_2 = 1000059005,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MEMORY_PROPERTIES_2 = 1000059006,
    VK_STRUCTURE_TYPE_SPARSE_IMAGE_FORMAT_PROPERTIES_2 = 1000059007,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SPARSE_IMAGE_FORMAT_INFO_2 = 1000059008,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_POINT_CLIPPING_PROPERTIES = 1000117000,
    VK_STRUCTURE_TYPE_RENDER_PASS_INPUT_ATTACHMENT_ASPECT_CREATE_INFO = 1000117001,
    VK_STRUCTURE_TYPE_IMAGE_VIEW_USAGE_CREATE_INFO = 1000117002,
    VK_STRUCTURE_TYPE_PIPELINE_TESSELLATION_DOMAIN_ORIGIN_STATE_CREATE_INFO = 1000117003,
    VK_STRUCTURE_TYPE_RENDER_PASS_MULTIVIEW_CREATE_INFO = 1000053000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTIVIEW_FEATURES = 1000053001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTIVIEW_PROPERTIES = 1000053002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VARIABLE_POINTERS_FEATURES = 1000120000,
    VK_STRUCTURE_TYPE_PROTECTED_SUBMIT_INFO = 1000145000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PROTECTED_MEMORY_FEATURES = 1000145001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PROTECTED_MEMORY_PROPERTIES = 1000145002,
    VK_STRUCTURE_TYPE_DEVICE_QUEUE_INFO_2 = 1000145003,
    VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_CREATE_INFO = 1000156000,
    VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_INFO = 1000156001,
    VK_STRUCTURE_TYPE_BIND_IMAGE_PLANE_MEMORY_INFO = 1000156002,
    VK_STRUCTURE_TYPE_IMAGE_PLANE_MEMORY_REQUIREMENTS_INFO = 1000156003,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SAMPLER_YCBCR_CONVERSION_FEATURES = 1000156004,
    VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_IMAGE_FORMAT_PROPERTIES = 1000156005,
    VK_STRUCTURE_TYPE_DESCRIPTOR_UPDATE_TEMPLATE_CREATE_INFO = 1000085000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_IMAGE_FORMAT_INFO = 1000071000,
    VK_STRUCTURE_TYPE_EXTERNAL_IMAGE_FORMAT_PROPERTIES = 1000071001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_BUFFER_INFO = 1000071002,
    VK_STRUCTURE_TYPE_EXTERNAL_BUFFER_PROPERTIES = 1000071003,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ID_PROPERTIES = 1000071004,
    VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_BUFFER_CREATE_INFO = 1000072000,
    VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_IMAGE_CREATE_INFO = 1000072001,
    VK_STRUCTURE_TYPE_EXPORT_MEMORY_ALLOCATE_INFO = 1000072002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_FENCE_INFO = 1000112000,
    VK_STRUCTURE_TYPE_EXTERNAL_FENCE_PROPERTIES = 1000112001,
    VK_STRUCTURE_TYPE_EXPORT_FENCE_CREATE_INFO = 1000113000,
    VK_STRUCTURE_TYPE_EXPORT_SEMAPHORE_CREATE_INFO = 1000077000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_SEMAPHORE_INFO = 1000076000,
    VK_STRUCTURE_TYPE_EXTERNAL_SEMAPHORE_PROPERTIES = 1000076001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_3_PROPERTIES = 1000168000,
    VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_SUPPORT = 1000168001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_DRAW_PARAMETERS_FEATURES = 1000063000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_1_1_FEATURES = 49,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_1_1_PROPERTIES = 50,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_1_2_FEATURES = 51,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_1_2_PROPERTIES = 52,
    VK_STRUCTURE_TYPE_IMAGE_FORMAT_LIST_CREATE_INFO = 1000147000,
    VK_STRUCTURE_TYPE_ATTACHMENT_DESCRIPTION_2 = 1000109000,
    VK_STRUCTURE_TYPE_ATTACHMENT_REFERENCE_2 = 1000109001,
    VK_STRUCTURE_TYPE_SUBPASS_DESCRIPTION_2 = 1000109002,
    VK_STRUCTURE_TYPE_SUBPASS_DEPENDENCY_2 = 1000109003,
    VK_STRUCTURE_TYPE_RENDER_PASS_CREATE_INFO_2 = 1000109004,
    VK_STRUCTURE_TYPE_SUBPASS_BEGIN_INFO = 1000109005,
    VK_STRUCTURE_TYPE_SUBPASS_END_INFO = 1000109006,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_8BIT_STORAGE_FEATURES = 1000177000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DRIVER_PROPERTIES = 1000196000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_ATOMIC_INT64_FEATURES = 1000180000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_FLOAT16_INT8_FEATURES = 1000082000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FLOAT_CONTROLS_PROPERTIES = 1000197000,
    VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_BINDING_FLAGS_CREATE_INFO = 1000161000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DESCRIPTOR_INDEXING_FEATURES = 1000161001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DESCRIPTOR_INDEXING_PROPERTIES = 1000161002,
    VK_STRUCTURE_TYPE_DESCRIPTOR_SET_VARIABLE_DESCRIPTOR_COUNT_ALLOCATE_INFO = 1000161003,
    VK_STRUCTURE_TYPE_DESCRIPTOR_SET_VARIABLE_DESCRIPTOR_COUNT_LAYOUT_SUPPORT = 1000161004,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DEPTH_STENCIL_RESOLVE_PROPERTIES = 1000199000,
    VK_STRUCTURE_TYPE_SUBPASS_DESCRIPTION_DEPTH_STENCIL_RESOLVE = 1000199001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SCALAR_BLOCK_LAYOUT_FEATURES = 1000221000,
    VK_STRUCTURE_TYPE_IMAGE_STENCIL_USAGE_CREATE_INFO = 1000246000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SAMPLER_FILTER_MINMAX_PROPERTIES = 1000130000,
    VK_STRUCTURE_TYPE_SAMPLER_REDUCTION_MODE_CREATE_INFO = 1000130001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_MEMORY_MODEL_FEATURES = 1000211000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGELESS_FRAMEBUFFER_FEATURES = 1000108000,
    VK_STRUCTURE_TYPE_FRAMEBUFFER_ATTACHMENTS_CREATE_INFO = 1000108001,
    VK_STRUCTURE_TYPE_FRAMEBUFFER_ATTACHMENT_IMAGE_INFO = 1000108002,
    VK_STRUCTURE_TYPE_RENDER_PASS_ATTACHMENT_BEGIN_INFO = 1000108003,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_UNIFORM_BUFFER_STANDARD_LAYOUT_FEATURES = 1000253000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_SUBGROUP_EXTENDED_TYPES_FEATURES = 1000175000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SEPARATE_DEPTH_STENCIL_LAYOUTS_FEATURES = 1000241000,
    VK_STRUCTURE_TYPE_ATTACHMENT_REFERENCE_STENCIL_LAYOUT = 1000241001,
    VK_STRUCTURE_TYPE_ATTACHMENT_DESCRIPTION_STENCIL_LAYOUT = 1000241002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_HOST_QUERY_RESET_FEATURES = 1000261000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TIMELINE_SEMAPHORE_FEATURES = 1000207000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TIMELINE_SEMAPHORE_PROPERTIES = 1000207001,
    VK_STRUCTURE_TYPE_SEMAPHORE_TYPE_CREATE_INFO = 1000207002,
    VK_STRUCTURE_TYPE_TIMELINE_SEMAPHORE_SUBMIT_INFO = 1000207003,
    VK_STRUCTURE_TYPE_SEMAPHORE_WAIT_INFO = 1000207004,
    VK_STRUCTURE_TYPE_SEMAPHORE_SIGNAL_INFO = 1000207005,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_BUFFER_DEVICE_ADDRESS_FEATURES = 1000257000,
    VK_STRUCTURE_TYPE_BUFFER_DEVICE_ADDRESS_INFO = 1000244001,
    VK_STRUCTURE_TYPE_BUFFER_OPAQUE_CAPTURE_ADDRESS_CREATE_INFO = 1000257002,
    VK_STRUCTURE_TYPE_MEMORY_OPAQUE_CAPTURE_ADDRESS_ALLOCATE_INFO = 1000257003,
    VK_STRUCTURE_TYPE_DEVICE_MEMORY_OPAQUE_CAPTURE_ADDRESS_INFO = 1000257004,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_1_3_FEATURES = 53,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_1_3_PROPERTIES = 54,
    VK_STRUCTURE_TYPE_PIPELINE_CREATION_FEEDBACK_CREATE_INFO = 1000192000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_TERMINATE_INVOCATION_FEATURES = 1000215000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TOOL_PROPERTIES = 1000245000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_DEMOTE_TO_HELPER_INVOCATION_FEATURES = 1000276000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PRIVATE_DATA_FEATURES = 1000295000,
    VK_STRUCTURE_TYPE_DEVICE_PRIVATE_DATA_CREATE_INFO = 1000295001,
    VK_STRUCTURE_TYPE_PRIVATE_DATA_SLOT_CREATE_INFO = 1000295002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_CREATION_CACHE_CONTROL_FEATURES = 1000297000,
    VK_STRUCTURE_TYPE_MEMORY_BARRIER_2 = 1000314000,
    VK_STRUCTURE_TYPE_BUFFER_MEMORY_BARRIER_2 = 1000314001,
    VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER_2 = 1000314002,
    VK_STRUCTURE_TYPE_DEPENDENCY_INFO = 1000314003,
    VK_STRUCTURE_TYPE_SUBMIT_INFO_2 = 1000314004,
    VK_STRUCTURE_TYPE_SEMAPHORE_SUBMIT_INFO = 1000314005,
    VK_STRUCTURE_TYPE_COMMAND_BUFFER_SUBMIT_INFO = 1000314006,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SYNCHRONIZATION_2_FEATURES = 1000314007,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ZERO_INITIALIZE_WORKGROUP_MEMORY_FEATURES = 1000325000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_ROBUSTNESS_FEATURES = 1000335000,
    VK_STRUCTURE_TYPE_COPY_BUFFER_INFO_2 = 1000337000,
    VK_STRUCTURE_TYPE_COPY_IMAGE_INFO_2 = 1000337001,
    VK_STRUCTURE_TYPE_COPY_BUFFER_TO_IMAGE_INFO_2 = 1000337002,
    VK_STRUCTURE_TYPE_COPY_IMAGE_TO_BUFFER_INFO_2 = 1000337003,
    VK_STRUCTURE_TYPE_BLIT_IMAGE_INFO_2 = 1000337004,
    VK_STRUCTURE_TYPE_RESOLVE_IMAGE_INFO_2 = 1000337005,
    VK_STRUCTURE_TYPE_BUFFER_COPY_2 = 1000337006,
    VK_STRUCTURE_TYPE_IMAGE_COPY_2 = 1000337007,
    VK_STRUCTURE_TYPE_IMAGE_BLIT_2 = 1000337008,
    VK_STRUCTURE_TYPE_BUFFER_IMAGE_COPY_2 = 1000337009,
    VK_STRUCTURE_TYPE_IMAGE_RESOLVE_2 = 1000337010,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SUBGROUP_SIZE_CONTROL_PROPERTIES = 1000225000,
    VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_REQUIRED_SUBGROUP_SIZE_CREATE_INFO = 1000225001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SUBGROUP_SIZE_CONTROL_FEATURES = 1000225002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_INLINE_UNIFORM_BLOCK_FEATURES = 1000138000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_INLINE_UNIFORM_BLOCK_PROPERTIES = 1000138001,
    VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET_INLINE_UNIFORM_BLOCK = 1000138002,
    VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_INLINE_UNIFORM_BLOCK_CREATE_INFO = 1000138003,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TEXTURE_COMPRESSION_ASTC_HDR_FEATURES = 1000066000,
    VK_STRUCTURE_TYPE_RENDERING_INFO = 1000044000,
    VK_STRUCTURE_TYPE_RENDERING_ATTACHMENT_INFO = 1000044001,
    VK_STRUCTURE_TYPE_PIPELINE_RENDERING_CREATE_INFO = 1000044002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DYNAMIC_RENDERING_FEATURES = 1000044003,
    VK_STRUCTURE_TYPE_COMMAND_BUFFER_INHERITANCE_RENDERING_INFO = 1000044004,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_INTEGER_DOT_PRODUCT_FEATURES = 1000280000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_INTEGER_DOT_PRODUCT_PROPERTIES = 1000280001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TEXEL_BUFFER_ALIGNMENT_PROPERTIES = 1000281001,
    VK_STRUCTURE_TYPE_FORMAT_PROPERTIES_3 = 1000360000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_4_FEATURES = 1000413000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_4_PROPERTIES = 1000413001,
    VK_STRUCTURE_TYPE_DEVICE_BUFFER_MEMORY_REQUIREMENTS = 1000413002,
    VK_STRUCTURE_TYPE_DEVICE_IMAGE_MEMORY_REQUIREMENTS = 1000413003,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_1_4_FEATURES = 55,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_1_4_PROPERTIES = 56,
    VK_STRUCTURE_TYPE_DEVICE_QUEUE_GLOBAL_PRIORITY_CREATE_INFO = 1000174000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_GLOBAL_PRIORITY_QUERY_FEATURES = 1000388000,
    VK_STRUCTURE_TYPE_QUEUE_FAMILY_GLOBAL_PRIORITY_PROPERTIES = 1000388001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_SUBGROUP_ROTATE_FEATURES = 1000416000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_FLOAT_CONTROLS_2_FEATURES = 1000528000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_EXPECT_ASSUME_FEATURES = 1000544000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LINE_RASTERIZATION_FEATURES = 1000259000,
    VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_LINE_STATE_CREATE_INFO = 1000259001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LINE_RASTERIZATION_PROPERTIES = 1000259002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VERTEX_ATTRIBUTE_DIVISOR_PROPERTIES = 1000525000,
    VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_DIVISOR_STATE_CREATE_INFO = 1000190001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VERTEX_ATTRIBUTE_DIVISOR_FEATURES = 1000190002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_INDEX_TYPE_UINT8_FEATURES = 1000265000,
    VK_STRUCTURE_TYPE_MEMORY_MAP_INFO = 1000271000,
    VK_STRUCTURE_TYPE_MEMORY_UNMAP_INFO = 1000271001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_5_FEATURES = 1000470000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_5_PROPERTIES = 1000470001,
    VK_STRUCTURE_TYPE_RENDERING_AREA_INFO = 1000470003,
    VK_STRUCTURE_TYPE_DEVICE_IMAGE_SUBRESOURCE_INFO = 1000470004,
    VK_STRUCTURE_TYPE_SUBRESOURCE_LAYOUT_2 = 1000338002,
    VK_STRUCTURE_TYPE_IMAGE_SUBRESOURCE_2 = 1000338003,
    VK_STRUCTURE_TYPE_PIPELINE_CREATE_FLAGS_2_CREATE_INFO = 1000470005,
    VK_STRUCTURE_TYPE_BUFFER_USAGE_FLAGS_2_CREATE_INFO = 1000470006,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PUSH_DESCRIPTOR_PROPERTIES = 1000080000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DYNAMIC_RENDERING_LOCAL_READ_FEATURES = 1000232000,
    VK_STRUCTURE_TYPE_RENDERING_ATTACHMENT_LOCATION_INFO = 1000232001,
    VK_STRUCTURE_TYPE_RENDERING_INPUT_ATTACHMENT_INDEX_INFO = 1000232002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_6_FEATURES = 1000545000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_6_PROPERTIES = 1000545001,
    VK_STRUCTURE_TYPE_BIND_MEMORY_STATUS = 1000545002,
    VK_STRUCTURE_TYPE_BIND_DESCRIPTOR_SETS_INFO = 1000545003,
    VK_STRUCTURE_TYPE_PUSH_CONSTANTS_INFO = 1000545004,
    VK_STRUCTURE_TYPE_PUSH_DESCRIPTOR_SET_INFO = 1000545005,
    VK_STRUCTURE_TYPE_PUSH_DESCRIPTOR_SET_WITH_TEMPLATE_INFO = 1000545006,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_PROTECTED_ACCESS_FEATURES = 1000466000,
    VK_STRUCTURE_TYPE_PIPELINE_ROBUSTNESS_CREATE_INFO = 1000068000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_ROBUSTNESS_FEATURES = 1000068001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_ROBUSTNESS_PROPERTIES = 1000068002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_HOST_IMAGE_COPY_FEATURES = 1000270000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_HOST_IMAGE_COPY_PROPERTIES = 1000270001,
    VK_STRUCTURE_TYPE_MEMORY_TO_IMAGE_COPY = 1000270002,
    VK_STRUCTURE_TYPE_IMAGE_TO_MEMORY_COPY = 1000270003,
    VK_STRUCTURE_TYPE_COPY_IMAGE_TO_MEMORY_INFO = 1000270004,
    VK_STRUCTURE_TYPE_COPY_MEMORY_TO_IMAGE_INFO = 1000270005,
    VK_STRUCTURE_TYPE_HOST_IMAGE_LAYOUT_TRANSITION_INFO = 1000270006,
    VK_STRUCTURE_TYPE_COPY_IMAGE_TO_IMAGE_INFO = 1000270007,
    VK_STRUCTURE_TYPE_SUBRESOURCE_HOST_MEMCPY_SIZE = 1000270008,
    VK_STRUCTURE_TYPE_HOST_IMAGE_COPY_DEVICE_PERFORMANCE_QUERY = 1000270009,
    VK_STRUCTURE_TYPE_SWAPCHAIN_CREATE_INFO_KHR = 1000001000,
    VK_STRUCTURE_TYPE_PRESENT_INFO_KHR = 1000001001,
    VK_STRUCTURE_TYPE_DEVICE_GROUP_PRESENT_CAPABILITIES_KHR = 1000060007,
    VK_STRUCTURE_TYPE_IMAGE_SWAPCHAIN_CREATE_INFO_KHR = 1000060008,
    VK_STRUCTURE_TYPE_BIND_IMAGE_MEMORY_SWAPCHAIN_INFO_KHR = 1000060009,
    VK_STRUCTURE_TYPE_ACQUIRE_NEXT_IMAGE_INFO_KHR = 1000060010,
    VK_STRUCTURE_TYPE_DEVICE_GROUP_PRESENT_INFO_KHR = 1000060011,
    VK_STRUCTURE_TYPE_DEVICE_GROUP_SWAPCHAIN_CREATE_INFO_KHR = 1000060012,
    VK_STRUCTURE_TYPE_DISPLAY_MODE_CREATE_INFO_KHR = 1000002000,
    VK_STRUCTURE_TYPE_DISPLAY_SURFACE_CREATE_INFO_KHR = 1000002001,
    VK_STRUCTURE_TYPE_DISPLAY_PRESENT_INFO_KHR = 1000003000,
    VK_STRUCTURE_TYPE_XLIB_SURFACE_CREATE_INFO_KHR = 1000004000,
    VK_STRUCTURE_TYPE_XCB_SURFACE_CREATE_INFO_KHR = 1000005000,
    VK_STRUCTURE_TYPE_WAYLAND_SURFACE_CREATE_INFO_KHR = 1000006000,
    VK_STRUCTURE_TYPE_ANDROID_SURFACE_CREATE_INFO_KHR = 1000008000,
    VK_STRUCTURE_TYPE_WIN32_SURFACE_CREATE_INFO_KHR = 1000009000,
    VK_STRUCTURE_TYPE_DEBUG_REPORT_CALLBACK_CREATE_INFO_EXT = 1000011000,
    VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_STATE_RASTERIZATION_ORDER_AMD = 1000018000,
    VK_STRUCTURE_TYPE_DEBUG_MARKER_OBJECT_NAME_INFO_EXT = 1000022000,
    VK_STRUCTURE_TYPE_DEBUG_MARKER_OBJECT_TAG_INFO_EXT = 1000022001,
    VK_STRUCTURE_TYPE_DEBUG_MARKER_MARKER_INFO_EXT = 1000022002,
    VK_STRUCTURE_TYPE_VIDEO_PROFILE_INFO_KHR = 1000023000,
    VK_STRUCTURE_TYPE_VIDEO_CAPABILITIES_KHR = 1000023001,
    VK_STRUCTURE_TYPE_VIDEO_PICTURE_RESOURCE_INFO_KHR = 1000023002,
    VK_STRUCTURE_TYPE_VIDEO_SESSION_MEMORY_REQUIREMENTS_KHR = 1000023003,
    VK_STRUCTURE_TYPE_BIND_VIDEO_SESSION_MEMORY_INFO_KHR = 1000023004,
    VK_STRUCTURE_TYPE_VIDEO_SESSION_CREATE_INFO_KHR = 1000023005,
    VK_STRUCTURE_TYPE_VIDEO_SESSION_PARAMETERS_CREATE_INFO_KHR = 1000023006,
    VK_STRUCTURE_TYPE_VIDEO_SESSION_PARAMETERS_UPDATE_INFO_KHR = 1000023007,
    VK_STRUCTURE_TYPE_VIDEO_BEGIN_CODING_INFO_KHR = 1000023008,
    VK_STRUCTURE_TYPE_VIDEO_END_CODING_INFO_KHR = 1000023009,
    VK_STRUCTURE_TYPE_VIDEO_CODING_CONTROL_INFO_KHR = 1000023010,
    VK_STRUCTURE_TYPE_VIDEO_REFERENCE_SLOT_INFO_KHR = 1000023011,
    VK_STRUCTURE_TYPE_QUEUE_FAMILY_VIDEO_PROPERTIES_KHR = 1000023012,
    VK_STRUCTURE_TYPE_VIDEO_PROFILE_LIST_INFO_KHR = 1000023013,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VIDEO_FORMAT_INFO_KHR = 1000023014,
    VK_STRUCTURE_TYPE_VIDEO_FORMAT_PROPERTIES_KHR = 1000023015,
    VK_STRUCTURE_TYPE_QUEUE_FAMILY_QUERY_RESULT_STATUS_PROPERTIES_KHR = 1000023016,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_INFO_KHR = 1000024000,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_CAPABILITIES_KHR = 1000024001,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_USAGE_INFO_KHR = 1000024002,
    VK_STRUCTURE_TYPE_DEDICATED_ALLOCATION_IMAGE_CREATE_INFO_NV = 1000026000,
    VK_STRUCTURE_TYPE_DEDICATED_ALLOCATION_BUFFER_CREATE_INFO_NV = 1000026001,
    VK_STRUCTURE_TYPE_DEDICATED_ALLOCATION_MEMORY_ALLOCATE_INFO_NV = 1000026002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TRANSFORM_FEEDBACK_FEATURES_EXT = 1000028000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TRANSFORM_FEEDBACK_PROPERTIES_EXT = 1000028001,
    VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_STATE_STREAM_CREATE_INFO_EXT = 1000028002,
    VK_STRUCTURE_TYPE_CU_MODULE_CREATE_INFO_NVX = 1000029000,
    VK_STRUCTURE_TYPE_CU_FUNCTION_CREATE_INFO_NVX = 1000029001,
    VK_STRUCTURE_TYPE_CU_LAUNCH_INFO_NVX = 1000029002,
    VK_STRUCTURE_TYPE_CU_MODULE_TEXTURING_MODE_CREATE_INFO_NVX = 1000029004,
    VK_STRUCTURE_TYPE_IMAGE_VIEW_HANDLE_INFO_NVX = 1000030000,
    VK_STRUCTURE_TYPE_IMAGE_VIEW_ADDRESS_PROPERTIES_NVX = 1000030001,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H264_CAPABILITIES_KHR = 1000038000,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H264_SESSION_PARAMETERS_CREATE_INFO_KHR = 1000038001,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H264_SESSION_PARAMETERS_ADD_INFO_KHR = 1000038002,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H264_PICTURE_INFO_KHR = 1000038003,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H264_DPB_SLOT_INFO_KHR = 1000038004,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H264_NALU_SLICE_INFO_KHR = 1000038005,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H264_GOP_REMAINING_FRAME_INFO_KHR = 1000038006,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H264_PROFILE_INFO_KHR = 1000038007,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H264_RATE_CONTROL_INFO_KHR = 1000038008,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H264_RATE_CONTROL_LAYER_INFO_KHR = 1000038009,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H264_SESSION_CREATE_INFO_KHR = 1000038010,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H264_QUALITY_LEVEL_PROPERTIES_KHR = 1000038011,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H264_SESSION_PARAMETERS_GET_INFO_KHR = 1000038012,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H264_SESSION_PARAMETERS_FEEDBACK_INFO_KHR = 1000038013,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H265_CAPABILITIES_KHR = 1000039000,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H265_SESSION_PARAMETERS_CREATE_INFO_KHR = 1000039001,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H265_SESSION_PARAMETERS_ADD_INFO_KHR = 1000039002,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H265_PICTURE_INFO_KHR = 1000039003,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H265_DPB_SLOT_INFO_KHR = 1000039004,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H265_NALU_SLICE_SEGMENT_INFO_KHR = 1000039005,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H265_GOP_REMAINING_FRAME_INFO_KHR = 1000039006,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H265_PROFILE_INFO_KHR = 1000039007,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H265_RATE_CONTROL_INFO_KHR = 1000039009,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H265_RATE_CONTROL_LAYER_INFO_KHR = 1000039010,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H265_SESSION_CREATE_INFO_KHR = 1000039011,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H265_QUALITY_LEVEL_PROPERTIES_KHR = 1000039012,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H265_SESSION_PARAMETERS_GET_INFO_KHR = 1000039013,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H265_SESSION_PARAMETERS_FEEDBACK_INFO_KHR = 1000039014,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_H264_CAPABILITIES_KHR = 1000040000,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_H264_PICTURE_INFO_KHR = 1000040001,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_H264_PROFILE_INFO_KHR = 1000040003,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_H264_SESSION_PARAMETERS_CREATE_INFO_KHR = 1000040004,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_H264_SESSION_PARAMETERS_ADD_INFO_KHR = 1000040005,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_H264_DPB_SLOT_INFO_KHR = 1000040006,
    VK_STRUCTURE_TYPE_TEXTURE_LOD_GATHER_FORMAT_PROPERTIES_AMD = 1000041000,
    VK_STRUCTURE_TYPE_STREAM_DESCRIPTOR_SURFACE_CREATE_INFO_GGP = 1000049000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_CORNER_SAMPLED_IMAGE_FEATURES_NV = 1000050000,
    VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_IMAGE_CREATE_INFO_NV = 1000056000,
    VK_STRUCTURE_TYPE_EXPORT_MEMORY_ALLOCATE_INFO_NV = 1000056001,
    VK_STRUCTURE_TYPE_IMPORT_MEMORY_WIN32_HANDLE_INFO_NV = 1000057000,
    VK_STRUCTURE_TYPE_EXPORT_MEMORY_WIN32_HANDLE_INFO_NV = 1000057001,
    VK_STRUCTURE_TYPE_WIN32_KEYED_MUTEX_ACQUIRE_RELEASE_INFO_NV = 1000058000,
    VK_STRUCTURE_TYPE_VALIDATION_FLAGS_EXT = 1000061000,
    VK_STRUCTURE_TYPE_VI_SURFACE_CREATE_INFO_NN = 1000062000,
    VK_STRUCTURE_TYPE_IMAGE_VIEW_ASTC_DECODE_MODE_EXT = 1000067000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ASTC_DECODE_FEATURES_EXT = 1000067001,
    VK_STRUCTURE_TYPE_IMPORT_MEMORY_WIN32_HANDLE_INFO_KHR = 1000073000,
    VK_STRUCTURE_TYPE_EXPORT_MEMORY_WIN32_HANDLE_INFO_KHR = 1000073001,
    VK_STRUCTURE_TYPE_MEMORY_WIN32_HANDLE_PROPERTIES_KHR = 1000073002,
    VK_STRUCTURE_TYPE_MEMORY_GET_WIN32_HANDLE_INFO_KHR = 1000073003,
    VK_STRUCTURE_TYPE_IMPORT_MEMORY_FD_INFO_KHR = 1000074000,
    VK_STRUCTURE_TYPE_MEMORY_FD_PROPERTIES_KHR = 1000074001,
    VK_STRUCTURE_TYPE_MEMORY_GET_FD_INFO_KHR = 1000074002,
    VK_STRUCTURE_TYPE_WIN32_KEYED_MUTEX_ACQUIRE_RELEASE_INFO_KHR = 1000075000,
    VK_STRUCTURE_TYPE_IMPORT_SEMAPHORE_WIN32_HANDLE_INFO_KHR = 1000078000,
    VK_STRUCTURE_TYPE_EXPORT_SEMAPHORE_WIN32_HANDLE_INFO_KHR = 1000078001,
    VK_STRUCTURE_TYPE_D3D12_FENCE_SUBMIT_INFO_KHR = 1000078002,
    VK_STRUCTURE_TYPE_SEMAPHORE_GET_WIN32_HANDLE_INFO_KHR = 1000078003,
    VK_STRUCTURE_TYPE_IMPORT_SEMAPHORE_FD_INFO_KHR = 1000079000,
    VK_STRUCTURE_TYPE_SEMAPHORE_GET_FD_INFO_KHR = 1000079001,
    VK_STRUCTURE_TYPE_COMMAND_BUFFER_INHERITANCE_CONDITIONAL_RENDERING_INFO_EXT = 1000081000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_CONDITIONAL_RENDERING_FEATURES_EXT = 1000081001,
    VK_STRUCTURE_TYPE_CONDITIONAL_RENDERING_BEGIN_INFO_EXT = 1000081002,
    VK_STRUCTURE_TYPE_PRESENT_REGIONS_KHR = 1000084000,
    VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_W_SCALING_STATE_CREATE_INFO_NV = 1000087000,
    VK_STRUCTURE_TYPE_SURFACE_CAPABILITIES_2_EXT = 1000090000,
    VK_STRUCTURE_TYPE_DISPLAY_POWER_INFO_EXT = 1000091000,
    VK_STRUCTURE_TYPE_DEVICE_EVENT_INFO_EXT = 1000091001,
    VK_STRUCTURE_TYPE_DISPLAY_EVENT_INFO_EXT = 1000091002,
    VK_STRUCTURE_TYPE_SWAPCHAIN_COUNTER_CREATE_INFO_EXT = 1000091003,
    VK_STRUCTURE_TYPE_PRESENT_TIMES_INFO_GOOGLE = 1000092000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTIVIEW_PER_VIEW_ATTRIBUTES_PROPERTIES_NVX = 1000097000,
    VK_STRUCTURE_TYPE_MULTIVIEW_PER_VIEW_ATTRIBUTES_INFO_NVX = 1000044009,
    VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_SWIZZLE_STATE_CREATE_INFO_NV = 1000098000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DISCARD_RECTANGLE_PROPERTIES_EXT = 1000099000,
    VK_STRUCTURE_TYPE_PIPELINE_DISCARD_RECTANGLE_STATE_CREATE_INFO_EXT = 1000099001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_CONSERVATIVE_RASTERIZATION_PROPERTIES_EXT = 1000101000,
    VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_CONSERVATIVE_STATE_CREATE_INFO_EXT = 1000101001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DEPTH_CLIP_ENABLE_FEATURES_EXT = 1000102000,
    VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_DEPTH_CLIP_STATE_CREATE_INFO_EXT = 1000102001,
    VK_STRUCTURE_TYPE_HDR_METADATA_EXT = 1000105000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RELAXED_LINE_RASTERIZATION_FEATURES_IMG = 1000110000,
    VK_STRUCTURE_TYPE_SHARED_PRESENT_SURFACE_CAPABILITIES_KHR = 1000111000,
    VK_STRUCTURE_TYPE_IMPORT_FENCE_WIN32_HANDLE_INFO_KHR = 1000114000,
    VK_STRUCTURE_TYPE_EXPORT_FENCE_WIN32_HANDLE_INFO_KHR = 1000114001,
    VK_STRUCTURE_TYPE_FENCE_GET_WIN32_HANDLE_INFO_KHR = 1000114002,
    VK_STRUCTURE_TYPE_IMPORT_FENCE_FD_INFO_KHR = 1000115000,
    VK_STRUCTURE_TYPE_FENCE_GET_FD_INFO_KHR = 1000115001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PERFORMANCE_QUERY_FEATURES_KHR = 1000116000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PERFORMANCE_QUERY_PROPERTIES_KHR = 1000116001,
    VK_STRUCTURE_TYPE_QUERY_POOL_PERFORMANCE_CREATE_INFO_KHR = 1000116002,
    VK_STRUCTURE_TYPE_PERFORMANCE_QUERY_SUBMIT_INFO_KHR = 1000116003,
    VK_STRUCTURE_TYPE_ACQUIRE_PROFILING_LOCK_INFO_KHR = 1000116004,
    VK_STRUCTURE_TYPE_PERFORMANCE_COUNTER_KHR = 1000116005,
    VK_STRUCTURE_TYPE_PERFORMANCE_COUNTER_DESCRIPTION_KHR = 1000116006,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SURFACE_INFO_2_KHR = 1000119000,
    VK_STRUCTURE_TYPE_SURFACE_CAPABILITIES_2_KHR = 1000119001,
    VK_STRUCTURE_TYPE_SURFACE_FORMAT_2_KHR = 1000119002,
    VK_STRUCTURE_TYPE_DISPLAY_PROPERTIES_2_KHR = 1000121000,
    VK_STRUCTURE_TYPE_DISPLAY_PLANE_PROPERTIES_2_KHR = 1000121001,
    VK_STRUCTURE_TYPE_DISPLAY_MODE_PROPERTIES_2_KHR = 1000121002,
    VK_STRUCTURE_TYPE_DISPLAY_PLANE_INFO_2_KHR = 1000121003,
    VK_STRUCTURE_TYPE_DISPLAY_PLANE_CAPABILITIES_2_KHR = 1000121004,
    VK_STRUCTURE_TYPE_IOS_SURFACE_CREATE_INFO_MVK = 1000122000,
    VK_STRUCTURE_TYPE_MACOS_SURFACE_CREATE_INFO_MVK = 1000123000,
    VK_STRUCTURE_TYPE_DEBUG_UTILS_OBJECT_NAME_INFO_EXT = 1000128000,
    VK_STRUCTURE_TYPE_DEBUG_UTILS_OBJECT_TAG_INFO_EXT = 1000128001,
    VK_STRUCTURE_TYPE_DEBUG_UTILS_LABEL_EXT = 1000128002,
    VK_STRUCTURE_TYPE_DEBUG_UTILS_MESSENGER_CALLBACK_DATA_EXT = 1000128003,
    VK_STRUCTURE_TYPE_DEBUG_UTILS_MESSENGER_CREATE_INFO_EXT = 1000128004,
    VK_STRUCTURE_TYPE_ANDROID_HARDWARE_BUFFER_USAGE_ANDROID = 1000129000,
    VK_STRUCTURE_TYPE_ANDROID_HARDWARE_BUFFER_PROPERTIES_ANDROID = 1000129001,
    VK_STRUCTURE_TYPE_ANDROID_HARDWARE_BUFFER_FORMAT_PROPERTIES_ANDROID = 1000129002,
    VK_STRUCTURE_TYPE_IMPORT_ANDROID_HARDWARE_BUFFER_INFO_ANDROID = 1000129003,
    VK_STRUCTURE_TYPE_MEMORY_GET_ANDROID_HARDWARE_BUFFER_INFO_ANDROID = 1000129004,
    VK_STRUCTURE_TYPE_EXTERNAL_FORMAT_ANDROID = 1000129005,
    VK_STRUCTURE_TYPE_ANDROID_HARDWARE_BUFFER_FORMAT_PROPERTIES_2_ANDROID = 1000129006,
# 660 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
    VK_STRUCTURE_TYPE_ATTACHMENT_SAMPLE_COUNT_INFO_AMD = 1000044008,
    VK_STRUCTURE_TYPE_SAMPLE_LOCATIONS_INFO_EXT = 1000143000,
    VK_STRUCTURE_TYPE_RENDER_PASS_SAMPLE_LOCATIONS_BEGIN_INFO_EXT = 1000143001,
    VK_STRUCTURE_TYPE_PIPELINE_SAMPLE_LOCATIONS_STATE_CREATE_INFO_EXT = 1000143002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SAMPLE_LOCATIONS_PROPERTIES_EXT = 1000143003,
    VK_STRUCTURE_TYPE_MULTISAMPLE_PROPERTIES_EXT = 1000143004,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_BLEND_OPERATION_ADVANCED_FEATURES_EXT = 1000148000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_BLEND_OPERATION_ADVANCED_PROPERTIES_EXT = 1000148001,
    VK_STRUCTURE_TYPE_PIPELINE_COLOR_BLEND_ADVANCED_STATE_CREATE_INFO_EXT = 1000148002,
    VK_STRUCTURE_TYPE_PIPELINE_COVERAGE_TO_COLOR_STATE_CREATE_INFO_NV = 1000149000,
    VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET_ACCELERATION_STRUCTURE_KHR = 1000150007,
    VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_BUILD_GEOMETRY_INFO_KHR = 1000150000,
    VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_DEVICE_ADDRESS_INFO_KHR = 1000150002,
    VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_GEOMETRY_AABBS_DATA_KHR = 1000150003,
    VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_GEOMETRY_INSTANCES_DATA_KHR = 1000150004,
    VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_GEOMETRY_TRIANGLES_DATA_KHR = 1000150005,
    VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_GEOMETRY_KHR = 1000150006,
    VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_VERSION_INFO_KHR = 1000150009,
    VK_STRUCTURE_TYPE_COPY_ACCELERATION_STRUCTURE_INFO_KHR = 1000150010,
    VK_STRUCTURE_TYPE_COPY_ACCELERATION_STRUCTURE_TO_MEMORY_INFO_KHR = 1000150011,
    VK_STRUCTURE_TYPE_COPY_MEMORY_TO_ACCELERATION_STRUCTURE_INFO_KHR = 1000150012,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ACCELERATION_STRUCTURE_FEATURES_KHR = 1000150013,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ACCELERATION_STRUCTURE_PROPERTIES_KHR = 1000150014,
    VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_CREATE_INFO_KHR = 1000150017,
    VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_BUILD_SIZES_INFO_KHR = 1000150020,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RAY_TRACING_PIPELINE_FEATURES_KHR = 1000347000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RAY_TRACING_PIPELINE_PROPERTIES_KHR = 1000347001,
    VK_STRUCTURE_TYPE_RAY_TRACING_PIPELINE_CREATE_INFO_KHR = 1000150015,
    VK_STRUCTURE_TYPE_RAY_TRACING_SHADER_GROUP_CREATE_INFO_KHR = 1000150016,
    VK_STRUCTURE_TYPE_RAY_TRACING_PIPELINE_INTERFACE_CREATE_INFO_KHR = 1000150018,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RAY_QUERY_FEATURES_KHR = 1000348013,
    VK_STRUCTURE_TYPE_PIPELINE_COVERAGE_MODULATION_STATE_CREATE_INFO_NV = 1000152000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_SM_BUILTINS_FEATURES_NV = 1000154000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_SM_BUILTINS_PROPERTIES_NV = 1000154001,
    VK_STRUCTURE_TYPE_DRM_FORMAT_MODIFIER_PROPERTIES_LIST_EXT = 1000158000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_DRM_FORMAT_MODIFIER_INFO_EXT = 1000158002,
    VK_STRUCTURE_TYPE_IMAGE_DRM_FORMAT_MODIFIER_LIST_CREATE_INFO_EXT = 1000158003,
    VK_STRUCTURE_TYPE_IMAGE_DRM_FORMAT_MODIFIER_EXPLICIT_CREATE_INFO_EXT = 1000158004,
    VK_STRUCTURE_TYPE_IMAGE_DRM_FORMAT_MODIFIER_PROPERTIES_EXT = 1000158005,
    VK_STRUCTURE_TYPE_DRM_FORMAT_MODIFIER_PROPERTIES_LIST_2_EXT = 1000158006,
    VK_STRUCTURE_TYPE_VALIDATION_CACHE_CREATE_INFO_EXT = 1000160000,
    VK_STRUCTURE_TYPE_SHADER_MODULE_VALIDATION_CACHE_CREATE_INFO_EXT = 1000160001,






    VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_SHADING_RATE_IMAGE_STATE_CREATE_INFO_NV = 1000164000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADING_RATE_IMAGE_FEATURES_NV = 1000164001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADING_RATE_IMAGE_PROPERTIES_NV = 1000164002,
    VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_COARSE_SAMPLE_ORDER_STATE_CREATE_INFO_NV = 1000164005,
    VK_STRUCTURE_TYPE_RAY_TRACING_PIPELINE_CREATE_INFO_NV = 1000165000,
    VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_CREATE_INFO_NV = 1000165001,
    VK_STRUCTURE_TYPE_GEOMETRY_NV = 1000165003,
    VK_STRUCTURE_TYPE_GEOMETRY_TRIANGLES_NV = 1000165004,
    VK_STRUCTURE_TYPE_GEOMETRY_AABB_NV = 1000165005,
    VK_STRUCTURE_TYPE_BIND_ACCELERATION_STRUCTURE_MEMORY_INFO_NV = 1000165006,
    VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET_ACCELERATION_STRUCTURE_NV = 1000165007,
    VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_MEMORY_REQUIREMENTS_INFO_NV = 1000165008,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RAY_TRACING_PROPERTIES_NV = 1000165009,
    VK_STRUCTURE_TYPE_RAY_TRACING_SHADER_GROUP_CREATE_INFO_NV = 1000165011,
    VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_INFO_NV = 1000165012,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_REPRESENTATIVE_FRAGMENT_TEST_FEATURES_NV = 1000166000,
    VK_STRUCTURE_TYPE_PIPELINE_REPRESENTATIVE_FRAGMENT_TEST_STATE_CREATE_INFO_NV = 1000166001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_VIEW_IMAGE_FORMAT_INFO_EXT = 1000170000,
    VK_STRUCTURE_TYPE_FILTER_CUBIC_IMAGE_VIEW_IMAGE_FORMAT_PROPERTIES_EXT = 1000170001,
    VK_STRUCTURE_TYPE_IMPORT_MEMORY_HOST_POINTER_INFO_EXT = 1000178000,
    VK_STRUCTURE_TYPE_MEMORY_HOST_POINTER_PROPERTIES_EXT = 1000178001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_MEMORY_HOST_PROPERTIES_EXT = 1000178002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_CLOCK_FEATURES_KHR = 1000181000,
    VK_STRUCTURE_TYPE_PIPELINE_COMPILER_CONTROL_CREATE_INFO_AMD = 1000183000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_CORE_PROPERTIES_AMD = 1000185000,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_H265_CAPABILITIES_KHR = 1000187000,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_H265_SESSION_PARAMETERS_CREATE_INFO_KHR = 1000187001,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_H265_SESSION_PARAMETERS_ADD_INFO_KHR = 1000187002,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_H265_PROFILE_INFO_KHR = 1000187003,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_H265_PICTURE_INFO_KHR = 1000187004,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_H265_DPB_SLOT_INFO_KHR = 1000187005,
    VK_STRUCTURE_TYPE_DEVICE_MEMORY_OVERALLOCATION_CREATE_INFO_AMD = 1000189000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VERTEX_ATTRIBUTE_DIVISOR_PROPERTIES_EXT = 1000190000,
    VK_STRUCTURE_TYPE_PRESENT_FRAME_TOKEN_GGP = 1000191000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MESH_SHADER_FEATURES_NV = 1000202000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MESH_SHADER_PROPERTIES_NV = 1000202001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_IMAGE_FOOTPRINT_FEATURES_NV = 1000204000,
    VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_EXCLUSIVE_SCISSOR_STATE_CREATE_INFO_NV = 1000205000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXCLUSIVE_SCISSOR_FEATURES_NV = 1000205002,
    VK_STRUCTURE_TYPE_CHECKPOINT_DATA_NV = 1000206000,
    VK_STRUCTURE_TYPE_QUEUE_FAMILY_CHECKPOINT_PROPERTIES_NV = 1000206001,
    VK_STRUCTURE_TYPE_QUEUE_FAMILY_CHECKPOINT_PROPERTIES_2_NV = 1000314008,
    VK_STRUCTURE_TYPE_CHECKPOINT_DATA_2_NV = 1000314009,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_INTEGER_FUNCTIONS_2_FEATURES_INTEL = 1000209000,
    VK_STRUCTURE_TYPE_QUERY_POOL_PERFORMANCE_QUERY_CREATE_INFO_INTEL = 1000210000,
    VK_STRUCTURE_TYPE_INITIALIZE_PERFORMANCE_API_INFO_INTEL = 1000210001,
    VK_STRUCTURE_TYPE_PERFORMANCE_MARKER_INFO_INTEL = 1000210002,
    VK_STRUCTURE_TYPE_PERFORMANCE_STREAM_MARKER_INFO_INTEL = 1000210003,
    VK_STRUCTURE_TYPE_PERFORMANCE_OVERRIDE_INFO_INTEL = 1000210004,
    VK_STRUCTURE_TYPE_PERFORMANCE_CONFIGURATION_ACQUIRE_INFO_INTEL = 1000210005,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PCI_BUS_INFO_PROPERTIES_EXT = 1000212000,
    VK_STRUCTURE_TYPE_DISPLAY_NATIVE_HDR_SURFACE_CAPABILITIES_AMD = 1000213000,
    VK_STRUCTURE_TYPE_SWAPCHAIN_DISPLAY_NATIVE_HDR_CREATE_INFO_AMD = 1000213001,
    VK_STRUCTURE_TYPE_IMAGEPIPE_SURFACE_CREATE_INFO_FUCHSIA = 1000214000,
    VK_STRUCTURE_TYPE_METAL_SURFACE_CREATE_INFO_EXT = 1000217000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_DENSITY_MAP_FEATURES_EXT = 1000218000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_DENSITY_MAP_PROPERTIES_EXT = 1000218001,
    VK_STRUCTURE_TYPE_RENDER_PASS_FRAGMENT_DENSITY_MAP_CREATE_INFO_EXT = 1000218002,
    VK_STRUCTURE_TYPE_RENDERING_FRAGMENT_DENSITY_MAP_ATTACHMENT_INFO_EXT = 1000044007,
    VK_STRUCTURE_TYPE_FRAGMENT_SHADING_RATE_ATTACHMENT_INFO_KHR = 1000226000,
    VK_STRUCTURE_TYPE_PIPELINE_FRAGMENT_SHADING_RATE_STATE_CREATE_INFO_KHR = 1000226001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_SHADING_RATE_PROPERTIES_KHR = 1000226002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_SHADING_RATE_FEATURES_KHR = 1000226003,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_SHADING_RATE_KHR = 1000226004,
    VK_STRUCTURE_TYPE_RENDERING_FRAGMENT_SHADING_RATE_ATTACHMENT_INFO_KHR = 1000044006,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_CORE_PROPERTIES_2_AMD = 1000227000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COHERENT_MEMORY_FEATURES_AMD = 1000229000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_IMAGE_ATOMIC_INT64_FEATURES_EXT = 1000234000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_QUAD_CONTROL_FEATURES_KHR = 1000235000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MEMORY_BUDGET_PROPERTIES_EXT = 1000237000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MEMORY_PRIORITY_FEATURES_EXT = 1000238000,
    VK_STRUCTURE_TYPE_MEMORY_PRIORITY_ALLOCATE_INFO_EXT = 1000238001,
    VK_STRUCTURE_TYPE_SURFACE_PROTECTED_CAPABILITIES_KHR = 1000239000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DEDICATED_ALLOCATION_IMAGE_ALIASING_FEATURES_NV = 1000240000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_BUFFER_DEVICE_ADDRESS_FEATURES_EXT = 1000244000,
    VK_STRUCTURE_TYPE_BUFFER_DEVICE_ADDRESS_CREATE_INFO_EXT = 1000244002,
    VK_STRUCTURE_TYPE_VALIDATION_FEATURES_EXT = 1000247000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PRESENT_WAIT_FEATURES_KHR = 1000248000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COOPERATIVE_MATRIX_FEATURES_NV = 1000249000,
    VK_STRUCTURE_TYPE_COOPERATIVE_MATRIX_PROPERTIES_NV = 1000249001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COOPERATIVE_MATRIX_PROPERTIES_NV = 1000249002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COVERAGE_REDUCTION_MODE_FEATURES_NV = 1000250000,
    VK_STRUCTURE_TYPE_PIPELINE_COVERAGE_REDUCTION_STATE_CREATE_INFO_NV = 1000250001,
    VK_STRUCTURE_TYPE_FRAMEBUFFER_MIXED_SAMPLES_COMBINATION_NV = 1000250002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_SHADER_INTERLOCK_FEATURES_EXT = 1000251000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_YCBCR_IMAGE_ARRAYS_FEATURES_EXT = 1000252000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PROVOKING_VERTEX_FEATURES_EXT = 1000254000,
    VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_PROVOKING_VERTEX_STATE_CREATE_INFO_EXT = 1000254001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PROVOKING_VERTEX_PROPERTIES_EXT = 1000254002,
    VK_STRUCTURE_TYPE_SURFACE_FULL_SCREEN_EXCLUSIVE_INFO_EXT = 1000255000,
    VK_STRUCTURE_TYPE_SURFACE_CAPABILITIES_FULL_SCREEN_EXCLUSIVE_EXT = 1000255002,
    VK_STRUCTURE_TYPE_SURFACE_FULL_SCREEN_EXCLUSIVE_WIN32_INFO_EXT = 1000255001,
    VK_STRUCTURE_TYPE_HEADLESS_SURFACE_CREATE_INFO_EXT = 1000256000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_ATOMIC_FLOAT_FEATURES_EXT = 1000260000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTENDED_DYNAMIC_STATE_FEATURES_EXT = 1000267000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_EXECUTABLE_PROPERTIES_FEATURES_KHR = 1000269000,
    VK_STRUCTURE_TYPE_PIPELINE_INFO_KHR = 1000269001,
    VK_STRUCTURE_TYPE_PIPELINE_EXECUTABLE_PROPERTIES_KHR = 1000269002,
    VK_STRUCTURE_TYPE_PIPELINE_EXECUTABLE_INFO_KHR = 1000269003,
    VK_STRUCTURE_TYPE_PIPELINE_EXECUTABLE_STATISTIC_KHR = 1000269004,
    VK_STRUCTURE_TYPE_PIPELINE_EXECUTABLE_INTERNAL_REPRESENTATION_KHR = 1000269005,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAP_MEMORY_PLACED_FEATURES_EXT = 1000272000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAP_MEMORY_PLACED_PROPERTIES_EXT = 1000272001,
    VK_STRUCTURE_TYPE_MEMORY_MAP_PLACED_INFO_EXT = 1000272002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_ATOMIC_FLOAT_2_FEATURES_EXT = 1000273000,
    VK_STRUCTURE_TYPE_SURFACE_PRESENT_MODE_EXT = 1000274000,
    VK_STRUCTURE_TYPE_SURFACE_PRESENT_SCALING_CAPABILITIES_EXT = 1000274001,
    VK_STRUCTURE_TYPE_SURFACE_PRESENT_MODE_COMPATIBILITY_EXT = 1000274002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SWAPCHAIN_MAINTENANCE_1_FEATURES_EXT = 1000275000,
    VK_STRUCTURE_TYPE_SWAPCHAIN_PRESENT_FENCE_INFO_EXT = 1000275001,
    VK_STRUCTURE_TYPE_SWAPCHAIN_PRESENT_MODES_CREATE_INFO_EXT = 1000275002,
    VK_STRUCTURE_TYPE_SWAPCHAIN_PRESENT_MODE_INFO_EXT = 1000275003,
    VK_STRUCTURE_TYPE_SWAPCHAIN_PRESENT_SCALING_CREATE_INFO_EXT = 1000275004,
    VK_STRUCTURE_TYPE_RELEASE_SWAPCHAIN_IMAGES_INFO_EXT = 1000275005,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DEVICE_GENERATED_COMMANDS_PROPERTIES_NV = 1000277000,
    VK_STRUCTURE_TYPE_GRAPHICS_SHADER_GROUP_CREATE_INFO_NV = 1000277001,
    VK_STRUCTURE_TYPE_GRAPHICS_PIPELINE_SHADER_GROUPS_CREATE_INFO_NV = 1000277002,
    VK_STRUCTURE_TYPE_INDIRECT_COMMANDS_LAYOUT_TOKEN_NV = 1000277003,
    VK_STRUCTURE_TYPE_INDIRECT_COMMANDS_LAYOUT_CREATE_INFO_NV = 1000277004,
    VK_STRUCTURE_TYPE_GENERATED_COMMANDS_INFO_NV = 1000277005,
    VK_STRUCTURE_TYPE_GENERATED_COMMANDS_MEMORY_REQUIREMENTS_INFO_NV = 1000277006,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DEVICE_GENERATED_COMMANDS_FEATURES_NV = 1000277007,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_INHERITED_VIEWPORT_SCISSOR_FEATURES_NV = 1000278000,
    VK_STRUCTURE_TYPE_COMMAND_BUFFER_INHERITANCE_VIEWPORT_SCISSOR_INFO_NV = 1000278001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TEXEL_BUFFER_ALIGNMENT_FEATURES_EXT = 1000281000,
    VK_STRUCTURE_TYPE_COMMAND_BUFFER_INHERITANCE_RENDER_PASS_TRANSFORM_INFO_QCOM = 1000282000,
    VK_STRUCTURE_TYPE_RENDER_PASS_TRANSFORM_BEGIN_INFO_QCOM = 1000282001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DEPTH_BIAS_CONTROL_FEATURES_EXT = 1000283000,
    VK_STRUCTURE_TYPE_DEPTH_BIAS_INFO_EXT = 1000283001,
    VK_STRUCTURE_TYPE_DEPTH_BIAS_REPRESENTATION_INFO_EXT = 1000283002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DEVICE_MEMORY_REPORT_FEATURES_EXT = 1000284000,
    VK_STRUCTURE_TYPE_DEVICE_DEVICE_MEMORY_REPORT_CREATE_INFO_EXT = 1000284001,
    VK_STRUCTURE_TYPE_DEVICE_MEMORY_REPORT_CALLBACK_DATA_EXT = 1000284002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ROBUSTNESS_2_FEATURES_EXT = 1000286000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ROBUSTNESS_2_PROPERTIES_EXT = 1000286001,
    VK_STRUCTURE_TYPE_SAMPLER_CUSTOM_BORDER_COLOR_CREATE_INFO_EXT = 1000287000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_CUSTOM_BORDER_COLOR_PROPERTIES_EXT = 1000287001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_CUSTOM_BORDER_COLOR_FEATURES_EXT = 1000287002,
    VK_STRUCTURE_TYPE_PIPELINE_LIBRARY_CREATE_INFO_KHR = 1000290000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PRESENT_BARRIER_FEATURES_NV = 1000292000,
    VK_STRUCTURE_TYPE_SURFACE_CAPABILITIES_PRESENT_BARRIER_NV = 1000292001,
    VK_STRUCTURE_TYPE_SWAPCHAIN_PRESENT_BARRIER_CREATE_INFO_NV = 1000292002,
    VK_STRUCTURE_TYPE_PRESENT_ID_KHR = 1000294000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PRESENT_ID_FEATURES_KHR = 1000294001,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_INFO_KHR = 1000299000,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_RATE_CONTROL_INFO_KHR = 1000299001,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_RATE_CONTROL_LAYER_INFO_KHR = 1000299002,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_CAPABILITIES_KHR = 1000299003,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_USAGE_INFO_KHR = 1000299004,
    VK_STRUCTURE_TYPE_QUERY_POOL_VIDEO_ENCODE_FEEDBACK_CREATE_INFO_KHR = 1000299005,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VIDEO_ENCODE_QUALITY_LEVEL_INFO_KHR = 1000299006,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_QUALITY_LEVEL_PROPERTIES_KHR = 1000299007,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_QUALITY_LEVEL_INFO_KHR = 1000299008,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_SESSION_PARAMETERS_GET_INFO_KHR = 1000299009,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_SESSION_PARAMETERS_FEEDBACK_INFO_KHR = 1000299010,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DIAGNOSTICS_CONFIG_FEATURES_NV = 1000300000,
    VK_STRUCTURE_TYPE_DEVICE_DIAGNOSTICS_CONFIG_CREATE_INFO_NV = 1000300001,
    VK_STRUCTURE_TYPE_CUDA_MODULE_CREATE_INFO_NV = 1000307000,
    VK_STRUCTURE_TYPE_CUDA_FUNCTION_CREATE_INFO_NV = 1000307001,
    VK_STRUCTURE_TYPE_CUDA_LAUNCH_INFO_NV = 1000307002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_CUDA_KERNEL_LAUNCH_FEATURES_NV = 1000307003,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_CUDA_KERNEL_LAUNCH_PROPERTIES_NV = 1000307004,
    VK_STRUCTURE_TYPE_QUERY_LOW_LATENCY_SUPPORT_NV = 1000310000,
    VK_STRUCTURE_TYPE_EXPORT_METAL_OBJECT_CREATE_INFO_EXT = 1000311000,
    VK_STRUCTURE_TYPE_EXPORT_METAL_OBJECTS_INFO_EXT = 1000311001,
    VK_STRUCTURE_TYPE_EXPORT_METAL_DEVICE_INFO_EXT = 1000311002,
    VK_STRUCTURE_TYPE_EXPORT_METAL_COMMAND_QUEUE_INFO_EXT = 1000311003,
    VK_STRUCTURE_TYPE_EXPORT_METAL_BUFFER_INFO_EXT = 1000311004,
    VK_STRUCTURE_TYPE_IMPORT_METAL_BUFFER_INFO_EXT = 1000311005,
    VK_STRUCTURE_TYPE_EXPORT_METAL_TEXTURE_INFO_EXT = 1000311006,
    VK_STRUCTURE_TYPE_IMPORT_METAL_TEXTURE_INFO_EXT = 1000311007,
    VK_STRUCTURE_TYPE_EXPORT_METAL_IO_SURFACE_INFO_EXT = 1000311008,
    VK_STRUCTURE_TYPE_IMPORT_METAL_IO_SURFACE_INFO_EXT = 1000311009,
    VK_STRUCTURE_TYPE_EXPORT_METAL_SHARED_EVENT_INFO_EXT = 1000311010,
    VK_STRUCTURE_TYPE_IMPORT_METAL_SHARED_EVENT_INFO_EXT = 1000311011,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DESCRIPTOR_BUFFER_PROPERTIES_EXT = 1000316000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DESCRIPTOR_BUFFER_DENSITY_MAP_PROPERTIES_EXT = 1000316001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DESCRIPTOR_BUFFER_FEATURES_EXT = 1000316002,
    VK_STRUCTURE_TYPE_DESCRIPTOR_ADDRESS_INFO_EXT = 1000316003,
    VK_STRUCTURE_TYPE_DESCRIPTOR_GET_INFO_EXT = 1000316004,
    VK_STRUCTURE_TYPE_BUFFER_CAPTURE_DESCRIPTOR_DATA_INFO_EXT = 1000316005,
    VK_STRUCTURE_TYPE_IMAGE_CAPTURE_DESCRIPTOR_DATA_INFO_EXT = 1000316006,
    VK_STRUCTURE_TYPE_IMAGE_VIEW_CAPTURE_DESCRIPTOR_DATA_INFO_EXT = 1000316007,
    VK_STRUCTURE_TYPE_SAMPLER_CAPTURE_DESCRIPTOR_DATA_INFO_EXT = 1000316008,
    VK_STRUCTURE_TYPE_OPAQUE_CAPTURE_DESCRIPTOR_DATA_CREATE_INFO_EXT = 1000316010,
    VK_STRUCTURE_TYPE_DESCRIPTOR_BUFFER_BINDING_INFO_EXT = 1000316011,
    VK_STRUCTURE_TYPE_DESCRIPTOR_BUFFER_BINDING_PUSH_DESCRIPTOR_BUFFER_HANDLE_EXT = 1000316012,
    VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_CAPTURE_DESCRIPTOR_DATA_INFO_EXT = 1000316009,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_GRAPHICS_PIPELINE_LIBRARY_FEATURES_EXT = 1000320000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_GRAPHICS_PIPELINE_LIBRARY_PROPERTIES_EXT = 1000320001,
    VK_STRUCTURE_TYPE_GRAPHICS_PIPELINE_LIBRARY_CREATE_INFO_EXT = 1000320002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_EARLY_AND_LATE_FRAGMENT_TESTS_FEATURES_AMD = 1000321000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_SHADER_BARYCENTRIC_FEATURES_KHR = 1000203000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_SHADER_BARYCENTRIC_PROPERTIES_KHR = 1000322000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_SUBGROUP_UNIFORM_CONTROL_FLOW_FEATURES_KHR = 1000323000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_SHADING_RATE_ENUMS_PROPERTIES_NV = 1000326000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_SHADING_RATE_ENUMS_FEATURES_NV = 1000326001,
    VK_STRUCTURE_TYPE_PIPELINE_FRAGMENT_SHADING_RATE_ENUM_STATE_CREATE_INFO_NV = 1000326002,
    VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_GEOMETRY_MOTION_TRIANGLES_DATA_NV = 1000327000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RAY_TRACING_MOTION_BLUR_FEATURES_NV = 1000327001,
    VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_MOTION_INFO_NV = 1000327002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MESH_SHADER_FEATURES_EXT = 1000328000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MESH_SHADER_PROPERTIES_EXT = 1000328001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_YCBCR_2_PLANE_444_FORMATS_FEATURES_EXT = 1000330000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_DENSITY_MAP_2_FEATURES_EXT = 1000332000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_DENSITY_MAP_2_PROPERTIES_EXT = 1000332001,
    VK_STRUCTURE_TYPE_COPY_COMMAND_TRANSFORM_INFO_QCOM = 1000333000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_WORKGROUP_MEMORY_EXPLICIT_LAYOUT_FEATURES_KHR = 1000336000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_COMPRESSION_CONTROL_FEATURES_EXT = 1000338000,
    VK_STRUCTURE_TYPE_IMAGE_COMPRESSION_CONTROL_EXT = 1000338001,
    VK_STRUCTURE_TYPE_IMAGE_COMPRESSION_PROPERTIES_EXT = 1000338004,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ATTACHMENT_FEEDBACK_LOOP_LAYOUT_FEATURES_EXT = 1000339000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_4444_FORMATS_FEATURES_EXT = 1000340000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FAULT_FEATURES_EXT = 1000341000,
    VK_STRUCTURE_TYPE_DEVICE_FAULT_COUNTS_EXT = 1000341001,
    VK_STRUCTURE_TYPE_DEVICE_FAULT_INFO_EXT = 1000341002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RGBA10X6_FORMATS_FEATURES_EXT = 1000344000,
    VK_STRUCTURE_TYPE_DIRECTFB_SURFACE_CREATE_INFO_EXT = 1000346000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VERTEX_INPUT_DYNAMIC_STATE_FEATURES_EXT = 1000352000,
    VK_STRUCTURE_TYPE_VERTEX_INPUT_BINDING_DESCRIPTION_2_EXT = 1000352001,
    VK_STRUCTURE_TYPE_VERTEX_INPUT_ATTRIBUTE_DESCRIPTION_2_EXT = 1000352002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DRM_PROPERTIES_EXT = 1000353000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ADDRESS_BINDING_REPORT_FEATURES_EXT = 1000354000,
    VK_STRUCTURE_TYPE_DEVICE_ADDRESS_BINDING_CALLBACK_DATA_EXT = 1000354001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DEPTH_CLIP_CONTROL_FEATURES_EXT = 1000355000,
    VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_DEPTH_CLIP_CONTROL_CREATE_INFO_EXT = 1000355001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PRIMITIVE_TOPOLOGY_LIST_RESTART_FEATURES_EXT = 1000356000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PRESENT_MODE_FIFO_LATEST_READY_FEATURES_EXT = 1000361000,
    VK_STRUCTURE_TYPE_IMPORT_MEMORY_ZIRCON_HANDLE_INFO_FUCHSIA = 1000364000,
    VK_STRUCTURE_TYPE_MEMORY_ZIRCON_HANDLE_PROPERTIES_FUCHSIA = 1000364001,
    VK_STRUCTURE_TYPE_MEMORY_GET_ZIRCON_HANDLE_INFO_FUCHSIA = 1000364002,
    VK_STRUCTURE_TYPE_IMPORT_SEMAPHORE_ZIRCON_HANDLE_INFO_FUCHSIA = 1000365000,
    VK_STRUCTURE_TYPE_SEMAPHORE_GET_ZIRCON_HANDLE_INFO_FUCHSIA = 1000365001,
    VK_STRUCTURE_TYPE_BUFFER_COLLECTION_CREATE_INFO_FUCHSIA = 1000366000,
    VK_STRUCTURE_TYPE_IMPORT_MEMORY_BUFFER_COLLECTION_FUCHSIA = 1000366001,
    VK_STRUCTURE_TYPE_BUFFER_COLLECTION_IMAGE_CREATE_INFO_FUCHSIA = 1000366002,
    VK_STRUCTURE_TYPE_BUFFER_COLLECTION_PROPERTIES_FUCHSIA = 1000366003,
    VK_STRUCTURE_TYPE_BUFFER_CONSTRAINTS_INFO_FUCHSIA = 1000366004,
    VK_STRUCTURE_TYPE_BUFFER_COLLECTION_BUFFER_CREATE_INFO_FUCHSIA = 1000366005,
    VK_STRUCTURE_TYPE_IMAGE_CONSTRAINTS_INFO_FUCHSIA = 1000366006,
    VK_STRUCTURE_TYPE_IMAGE_FORMAT_CONSTRAINTS_INFO_FUCHSIA = 1000366007,
    VK_STRUCTURE_TYPE_SYSMEM_COLOR_SPACE_FUCHSIA = 1000366008,
    VK_STRUCTURE_TYPE_BUFFER_COLLECTION_CONSTRAINTS_INFO_FUCHSIA = 1000366009,
    VK_STRUCTURE_TYPE_SUBPASS_SHADING_PIPELINE_CREATE_INFO_HUAWEI = 1000369000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SUBPASS_SHADING_FEATURES_HUAWEI = 1000369001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SUBPASS_SHADING_PROPERTIES_HUAWEI = 1000369002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_INVOCATION_MASK_FEATURES_HUAWEI = 1000370000,
    VK_STRUCTURE_TYPE_MEMORY_GET_REMOTE_ADDRESS_INFO_NV = 1000371000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_MEMORY_RDMA_FEATURES_NV = 1000371001,
    VK_STRUCTURE_TYPE_PIPELINE_PROPERTIES_IDENTIFIER_EXT = 1000372000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_PROPERTIES_FEATURES_EXT = 1000372001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAME_BOUNDARY_FEATURES_EXT = 1000375000,
    VK_STRUCTURE_TYPE_FRAME_BOUNDARY_EXT = 1000375001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTISAMPLED_RENDER_TO_SINGLE_SAMPLED_FEATURES_EXT = 1000376000,
    VK_STRUCTURE_TYPE_SUBPASS_RESOLVE_PERFORMANCE_QUERY_EXT = 1000376001,
    VK_STRUCTURE_TYPE_MULTISAMPLED_RENDER_TO_SINGLE_SAMPLED_INFO_EXT = 1000376002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTENDED_DYNAMIC_STATE_2_FEATURES_EXT = 1000377000,
    VK_STRUCTURE_TYPE_SCREEN_SURFACE_CREATE_INFO_QNX = 1000378000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COLOR_WRITE_ENABLE_FEATURES_EXT = 1000381000,
    VK_STRUCTURE_TYPE_PIPELINE_COLOR_WRITE_CREATE_INFO_EXT = 1000381001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PRIMITIVES_GENERATED_QUERY_FEATURES_EXT = 1000382000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RAY_TRACING_MAINTENANCE_1_FEATURES_KHR = 1000386000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_VIEW_MIN_LOD_FEATURES_EXT = 1000391000,
    VK_STRUCTURE_TYPE_IMAGE_VIEW_MIN_LOD_CREATE_INFO_EXT = 1000391001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTI_DRAW_FEATURES_EXT = 1000392000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTI_DRAW_PROPERTIES_EXT = 1000392001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_2D_VIEW_OF_3D_FEATURES_EXT = 1000393000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_TILE_IMAGE_FEATURES_EXT = 1000395000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_TILE_IMAGE_PROPERTIES_EXT = 1000395001,
    VK_STRUCTURE_TYPE_MICROMAP_BUILD_INFO_EXT = 1000396000,
    VK_STRUCTURE_TYPE_MICROMAP_VERSION_INFO_EXT = 1000396001,
    VK_STRUCTURE_TYPE_COPY_MICROMAP_INFO_EXT = 1000396002,
    VK_STRUCTURE_TYPE_COPY_MICROMAP_TO_MEMORY_INFO_EXT = 1000396003,
    VK_STRUCTURE_TYPE_COPY_MEMORY_TO_MICROMAP_INFO_EXT = 1000396004,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_OPACITY_MICROMAP_FEATURES_EXT = 1000396005,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_OPACITY_MICROMAP_PROPERTIES_EXT = 1000396006,
    VK_STRUCTURE_TYPE_MICROMAP_CREATE_INFO_EXT = 1000396007,
    VK_STRUCTURE_TYPE_MICROMAP_BUILD_SIZES_INFO_EXT = 1000396008,
    VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_TRIANGLES_OPACITY_MICROMAP_EXT = 1000396009,
# 996 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_CLUSTER_CULLING_SHADER_FEATURES_HUAWEI = 1000404000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_CLUSTER_CULLING_SHADER_PROPERTIES_HUAWEI = 1000404001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_CLUSTER_CULLING_SHADER_VRS_FEATURES_HUAWEI = 1000404002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_BORDER_COLOR_SWIZZLE_FEATURES_EXT = 1000411000,
    VK_STRUCTURE_TYPE_SAMPLER_BORDER_COLOR_COMPONENT_MAPPING_CREATE_INFO_EXT = 1000411001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PAGEABLE_DEVICE_LOCAL_MEMORY_FEATURES_EXT = 1000412000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_CORE_PROPERTIES_ARM = 1000415000,
    VK_STRUCTURE_TYPE_DEVICE_QUEUE_SHADER_CORE_CONTROL_CREATE_INFO_ARM = 1000417000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SCHEDULING_CONTROLS_FEATURES_ARM = 1000417001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SCHEDULING_CONTROLS_PROPERTIES_ARM = 1000417002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_SLICED_VIEW_OF_3D_FEATURES_EXT = 1000418000,
    VK_STRUCTURE_TYPE_IMAGE_VIEW_SLICED_CREATE_INFO_EXT = 1000418001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DESCRIPTOR_SET_HOST_MAPPING_FEATURES_VALVE = 1000420000,
    VK_STRUCTURE_TYPE_DESCRIPTOR_SET_BINDING_REFERENCE_VALVE = 1000420001,
    VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_HOST_MAPPING_INFO_VALVE = 1000420002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DEPTH_CLAMP_ZERO_ONE_FEATURES_EXT = 1000421000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_NON_SEAMLESS_CUBE_MAP_FEATURES_EXT = 1000422000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RENDER_PASS_STRIPED_FEATURES_ARM = 1000424000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RENDER_PASS_STRIPED_PROPERTIES_ARM = 1000424001,
    VK_STRUCTURE_TYPE_RENDER_PASS_STRIPE_BEGIN_INFO_ARM = 1000424002,
    VK_STRUCTURE_TYPE_RENDER_PASS_STRIPE_INFO_ARM = 1000424003,
    VK_STRUCTURE_TYPE_RENDER_PASS_STRIPE_SUBMIT_INFO_ARM = 1000424004,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_DENSITY_MAP_OFFSET_FEATURES_QCOM = 1000425000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_DENSITY_MAP_OFFSET_PROPERTIES_QCOM = 1000425001,
    VK_STRUCTURE_TYPE_SUBPASS_FRAGMENT_DENSITY_MAP_OFFSET_END_INFO_QCOM = 1000425002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COPY_MEMORY_INDIRECT_FEATURES_NV = 1000426000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COPY_MEMORY_INDIRECT_PROPERTIES_NV = 1000426001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MEMORY_DECOMPRESSION_FEATURES_NV = 1000427000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MEMORY_DECOMPRESSION_PROPERTIES_NV = 1000427001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DEVICE_GENERATED_COMMANDS_COMPUTE_FEATURES_NV = 1000428000,
    VK_STRUCTURE_TYPE_COMPUTE_PIPELINE_INDIRECT_BUFFER_INFO_NV = 1000428001,
    VK_STRUCTURE_TYPE_PIPELINE_INDIRECT_DEVICE_ADDRESS_INFO_NV = 1000428002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LINEAR_COLOR_ATTACHMENT_FEATURES_NV = 1000430000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_MAXIMAL_RECONVERGENCE_FEATURES_KHR = 1000434000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_COMPRESSION_CONTROL_SWAPCHAIN_FEATURES_EXT = 1000437000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_PROCESSING_FEATURES_QCOM = 1000440000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_PROCESSING_PROPERTIES_QCOM = 1000440001,
    VK_STRUCTURE_TYPE_IMAGE_VIEW_SAMPLE_WEIGHT_CREATE_INFO_QCOM = 1000440002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_NESTED_COMMAND_BUFFER_FEATURES_EXT = 1000451000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_NESTED_COMMAND_BUFFER_PROPERTIES_EXT = 1000451001,
    VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_ACQUIRE_UNMODIFIED_EXT = 1000453000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTENDED_DYNAMIC_STATE_3_FEATURES_EXT = 1000455000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTENDED_DYNAMIC_STATE_3_PROPERTIES_EXT = 1000455001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SUBPASS_MERGE_FEEDBACK_FEATURES_EXT = 1000458000,
    VK_STRUCTURE_TYPE_RENDER_PASS_CREATION_CONTROL_EXT = 1000458001,
    VK_STRUCTURE_TYPE_RENDER_PASS_CREATION_FEEDBACK_CREATE_INFO_EXT = 1000458002,
    VK_STRUCTURE_TYPE_RENDER_PASS_SUBPASS_FEEDBACK_CREATE_INFO_EXT = 1000458003,
    VK_STRUCTURE_TYPE_DIRECT_DRIVER_LOADING_INFO_LUNARG = 1000459000,
    VK_STRUCTURE_TYPE_DIRECT_DRIVER_LOADING_LIST_LUNARG = 1000459001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_MODULE_IDENTIFIER_FEATURES_EXT = 1000462000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_MODULE_IDENTIFIER_PROPERTIES_EXT = 1000462001,
    VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_MODULE_IDENTIFIER_CREATE_INFO_EXT = 1000462002,
    VK_STRUCTURE_TYPE_SHADER_MODULE_IDENTIFIER_EXT = 1000462003,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RASTERIZATION_ORDER_ATTACHMENT_ACCESS_FEATURES_EXT = 1000342000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_OPTICAL_FLOW_FEATURES_NV = 1000464000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_OPTICAL_FLOW_PROPERTIES_NV = 1000464001,
    VK_STRUCTURE_TYPE_OPTICAL_FLOW_IMAGE_FORMAT_INFO_NV = 1000464002,
    VK_STRUCTURE_TYPE_OPTICAL_FLOW_IMAGE_FORMAT_PROPERTIES_NV = 1000464003,
    VK_STRUCTURE_TYPE_OPTICAL_FLOW_SESSION_CREATE_INFO_NV = 1000464004,
    VK_STRUCTURE_TYPE_OPTICAL_FLOW_EXECUTE_INFO_NV = 1000464005,
    VK_STRUCTURE_TYPE_OPTICAL_FLOW_SESSION_CREATE_PRIVATE_DATA_INFO_NV = 1000464010,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LEGACY_DITHERING_FEATURES_EXT = 1000465000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_FORMAT_RESOLVE_FEATURES_ANDROID = 1000468000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_FORMAT_RESOLVE_PROPERTIES_ANDROID = 1000468001,
    VK_STRUCTURE_TYPE_ANDROID_HARDWARE_BUFFER_FORMAT_RESOLVE_PROPERTIES_ANDROID = 1000468002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ANTI_LAG_FEATURES_AMD = 1000476000,
    VK_STRUCTURE_TYPE_ANTI_LAG_DATA_AMD = 1000476001,
    VK_STRUCTURE_TYPE_ANTI_LAG_PRESENTATION_INFO_AMD = 1000476002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RAY_TRACING_POSITION_FETCH_FEATURES_KHR = 1000481000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_OBJECT_FEATURES_EXT = 1000482000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_OBJECT_PROPERTIES_EXT = 1000482001,
    VK_STRUCTURE_TYPE_SHADER_CREATE_INFO_EXT = 1000482002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_BINARY_FEATURES_KHR = 1000483000,
    VK_STRUCTURE_TYPE_PIPELINE_BINARY_CREATE_INFO_KHR = 1000483001,
    VK_STRUCTURE_TYPE_PIPELINE_BINARY_INFO_KHR = 1000483002,
    VK_STRUCTURE_TYPE_PIPELINE_BINARY_KEY_KHR = 1000483003,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_BINARY_PROPERTIES_KHR = 1000483004,
    VK_STRUCTURE_TYPE_RELEASE_CAPTURED_PIPELINE_DATA_INFO_KHR = 1000483005,
    VK_STRUCTURE_TYPE_PIPELINE_BINARY_DATA_INFO_KHR = 1000483006,
    VK_STRUCTURE_TYPE_PIPELINE_CREATE_INFO_KHR = 1000483007,
    VK_STRUCTURE_TYPE_DEVICE_PIPELINE_BINARY_INTERNAL_CACHE_CONTROL_KHR = 1000483008,
    VK_STRUCTURE_TYPE_PIPELINE_BINARY_HANDLES_INFO_KHR = 1000483009,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TILE_PROPERTIES_FEATURES_QCOM = 1000484000,
    VK_STRUCTURE_TYPE_TILE_PROPERTIES_QCOM = 1000484001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_AMIGO_PROFILING_FEATURES_SEC = 1000485000,
    VK_STRUCTURE_TYPE_AMIGO_PROFILING_SUBMIT_INFO_SEC = 1000485001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTIVIEW_PER_VIEW_VIEWPORTS_FEATURES_QCOM = 1000488000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RAY_TRACING_INVOCATION_REORDER_FEATURES_NV = 1000490000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RAY_TRACING_INVOCATION_REORDER_PROPERTIES_NV = 1000490001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTENDED_SPARSE_ADDRESS_SPACE_FEATURES_NV = 1000492000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTENDED_SPARSE_ADDRESS_SPACE_PROPERTIES_NV = 1000492001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MUTABLE_DESCRIPTOR_TYPE_FEATURES_EXT = 1000351000,
    VK_STRUCTURE_TYPE_MUTABLE_DESCRIPTOR_TYPE_CREATE_INFO_EXT = 1000351002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LEGACY_VERTEX_ATTRIBUTES_FEATURES_EXT = 1000495000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LEGACY_VERTEX_ATTRIBUTES_PROPERTIES_EXT = 1000495001,
    VK_STRUCTURE_TYPE_LAYER_SETTINGS_CREATE_INFO_EXT = 1000496000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_CORE_BUILTINS_FEATURES_ARM = 1000497000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_CORE_BUILTINS_PROPERTIES_ARM = 1000497001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_LIBRARY_GROUP_HANDLES_FEATURES_EXT = 1000498000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DYNAMIC_RENDERING_UNUSED_ATTACHMENTS_FEATURES_EXT = 1000499000,
    VK_STRUCTURE_TYPE_LATENCY_SLEEP_MODE_INFO_NV = 1000505000,
    VK_STRUCTURE_TYPE_LATENCY_SLEEP_INFO_NV = 1000505001,
    VK_STRUCTURE_TYPE_SET_LATENCY_MARKER_INFO_NV = 1000505002,
    VK_STRUCTURE_TYPE_GET_LATENCY_MARKER_INFO_NV = 1000505003,
    VK_STRUCTURE_TYPE_LATENCY_TIMINGS_FRAME_REPORT_NV = 1000505004,
    VK_STRUCTURE_TYPE_LATENCY_SUBMISSION_PRESENT_ID_NV = 1000505005,
    VK_STRUCTURE_TYPE_OUT_OF_BAND_QUEUE_TYPE_INFO_NV = 1000505006,
    VK_STRUCTURE_TYPE_SWAPCHAIN_LATENCY_CREATE_INFO_NV = 1000505007,
    VK_STRUCTURE_TYPE_LATENCY_SURFACE_CAPABILITIES_NV = 1000505008,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COOPERATIVE_MATRIX_FEATURES_KHR = 1000506000,
    VK_STRUCTURE_TYPE_COOPERATIVE_MATRIX_PROPERTIES_KHR = 1000506001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COOPERATIVE_MATRIX_PROPERTIES_KHR = 1000506002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTIVIEW_PER_VIEW_RENDER_AREAS_FEATURES_QCOM = 1000510000,
    VK_STRUCTURE_TYPE_MULTIVIEW_PER_VIEW_RENDER_AREAS_RENDER_PASS_BEGIN_INFO_QCOM = 1000510001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COMPUTE_SHADER_DERIVATIVES_FEATURES_KHR = 1000201000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COMPUTE_SHADER_DERIVATIVES_PROPERTIES_KHR = 1000511000,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_AV1_CAPABILITIES_KHR = 1000512000,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_AV1_PICTURE_INFO_KHR = 1000512001,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_AV1_PROFILE_INFO_KHR = 1000512003,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_AV1_SESSION_PARAMETERS_CREATE_INFO_KHR = 1000512004,
    VK_STRUCTURE_TYPE_VIDEO_DECODE_AV1_DPB_SLOT_INFO_KHR = 1000512005,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_AV1_CAPABILITIES_KHR = 1000513000,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_AV1_SESSION_PARAMETERS_CREATE_INFO_KHR = 1000513001,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_AV1_PICTURE_INFO_KHR = 1000513002,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_AV1_DPB_SLOT_INFO_KHR = 1000513003,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VIDEO_ENCODE_AV1_FEATURES_KHR = 1000513004,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_AV1_PROFILE_INFO_KHR = 1000513005,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_AV1_RATE_CONTROL_INFO_KHR = 1000513006,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_AV1_RATE_CONTROL_LAYER_INFO_KHR = 1000513007,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_AV1_QUALITY_LEVEL_PROPERTIES_KHR = 1000513008,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_AV1_SESSION_CREATE_INFO_KHR = 1000513009,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_AV1_GOP_REMAINING_FRAME_INFO_KHR = 1000513010,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VIDEO_MAINTENANCE_1_FEATURES_KHR = 1000515000,
    VK_STRUCTURE_TYPE_VIDEO_INLINE_QUERY_INFO_KHR = 1000515001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PER_STAGE_DESCRIPTOR_SET_FEATURES_NV = 1000516000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_PROCESSING_2_FEATURES_QCOM = 1000518000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_PROCESSING_2_PROPERTIES_QCOM = 1000518001,
    VK_STRUCTURE_TYPE_SAMPLER_BLOCK_MATCH_WINDOW_CREATE_INFO_QCOM = 1000518002,
    VK_STRUCTURE_TYPE_SAMPLER_CUBIC_WEIGHTS_CREATE_INFO_QCOM = 1000519000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_CUBIC_WEIGHTS_FEATURES_QCOM = 1000519001,
    VK_STRUCTURE_TYPE_BLIT_IMAGE_CUBIC_WEIGHTS_INFO_QCOM = 1000519002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_YCBCR_DEGAMMA_FEATURES_QCOM = 1000520000,
    VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_YCBCR_DEGAMMA_CREATE_INFO_QCOM = 1000520001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_CUBIC_CLAMP_FEATURES_QCOM = 1000521000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ATTACHMENT_FEEDBACK_LOOP_DYNAMIC_STATE_FEATURES_EXT = 1000524000,
    VK_STRUCTURE_TYPE_SCREEN_BUFFER_PROPERTIES_QNX = 1000529000,
    VK_STRUCTURE_TYPE_SCREEN_BUFFER_FORMAT_PROPERTIES_QNX = 1000529001,
    VK_STRUCTURE_TYPE_IMPORT_SCREEN_BUFFER_INFO_QNX = 1000529002,
    VK_STRUCTURE_TYPE_EXTERNAL_FORMAT_QNX = 1000529003,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_MEMORY_SCREEN_BUFFER_FEATURES_QNX = 1000529004,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LAYERED_DRIVER_PROPERTIES_MSFT = 1000530000,
    VK_STRUCTURE_TYPE_CALIBRATED_TIMESTAMP_INFO_KHR = 1000184000,
    VK_STRUCTURE_TYPE_SET_DESCRIPTOR_BUFFER_OFFSETS_INFO_EXT = 1000545007,
    VK_STRUCTURE_TYPE_BIND_DESCRIPTOR_BUFFER_EMBEDDED_SAMPLERS_INFO_EXT = 1000545008,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DESCRIPTOR_POOL_OVERALLOCATION_FEATURES_NV = 1000546000,
    VK_STRUCTURE_TYPE_DISPLAY_SURFACE_STEREO_CREATE_INFO_NV = 1000551000,
    VK_STRUCTURE_TYPE_DISPLAY_MODE_STEREO_PROPERTIES_NV = 1000551001,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_QUANTIZATION_MAP_CAPABILITIES_KHR = 1000553000,
    VK_STRUCTURE_TYPE_VIDEO_FORMAT_QUANTIZATION_MAP_PROPERTIES_KHR = 1000553001,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_QUANTIZATION_MAP_INFO_KHR = 1000553002,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_QUANTIZATION_MAP_SESSION_PARAMETERS_CREATE_INFO_KHR = 1000553005,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VIDEO_ENCODE_QUANTIZATION_MAP_FEATURES_KHR = 1000553009,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H264_QUANTIZATION_MAP_CAPABILITIES_KHR = 1000553003,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_H265_QUANTIZATION_MAP_CAPABILITIES_KHR = 1000553004,
    VK_STRUCTURE_TYPE_VIDEO_FORMAT_H265_QUANTIZATION_MAP_PROPERTIES_KHR = 1000553006,
    VK_STRUCTURE_TYPE_VIDEO_ENCODE_AV1_QUANTIZATION_MAP_CAPABILITIES_KHR = 1000553007,
    VK_STRUCTURE_TYPE_VIDEO_FORMAT_AV1_QUANTIZATION_MAP_PROPERTIES_KHR = 1000553008,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RAW_ACCESS_CHAINS_FEATURES_NV = 1000555000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_RELAXED_EXTENDED_INSTRUCTION_FEATURES_KHR = 1000558000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COMMAND_BUFFER_INHERITANCE_FEATURES_NV = 1000559000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_7_FEATURES_KHR = 1000562000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_7_PROPERTIES_KHR = 1000562001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LAYERED_API_PROPERTIES_LIST_KHR = 1000562002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LAYERED_API_PROPERTIES_KHR = 1000562003,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LAYERED_API_VULKAN_PROPERTIES_KHR = 1000562004,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_ATOMIC_FLOAT16_VECTOR_FEATURES_NV = 1000563000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_REPLICATED_COMPOSITES_FEATURES_EXT = 1000564000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RAY_TRACING_VALIDATION_FEATURES_NV = 1000568000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DEVICE_GENERATED_COMMANDS_FEATURES_EXT = 1000572000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DEVICE_GENERATED_COMMANDS_PROPERTIES_EXT = 1000572001,
    VK_STRUCTURE_TYPE_GENERATED_COMMANDS_MEMORY_REQUIREMENTS_INFO_EXT = 1000572002,
    VK_STRUCTURE_TYPE_INDIRECT_EXECUTION_SET_CREATE_INFO_EXT = 1000572003,
    VK_STRUCTURE_TYPE_GENERATED_COMMANDS_INFO_EXT = 1000572004,
    VK_STRUCTURE_TYPE_INDIRECT_COMMANDS_LAYOUT_CREATE_INFO_EXT = 1000572006,
    VK_STRUCTURE_TYPE_INDIRECT_COMMANDS_LAYOUT_TOKEN_EXT = 1000572007,
    VK_STRUCTURE_TYPE_WRITE_INDIRECT_EXECUTION_SET_PIPELINE_EXT = 1000572008,
    VK_STRUCTURE_TYPE_WRITE_INDIRECT_EXECUTION_SET_SHADER_EXT = 1000572009,
    VK_STRUCTURE_TYPE_INDIRECT_EXECUTION_SET_PIPELINE_INFO_EXT = 1000572010,
    VK_STRUCTURE_TYPE_INDIRECT_EXECUTION_SET_SHADER_INFO_EXT = 1000572011,
    VK_STRUCTURE_TYPE_INDIRECT_EXECUTION_SET_SHADER_LAYOUT_INFO_EXT = 1000572012,
    VK_STRUCTURE_TYPE_GENERATED_COMMANDS_PIPELINE_INFO_EXT = 1000572013,
    VK_STRUCTURE_TYPE_GENERATED_COMMANDS_SHADER_INFO_EXT = 1000572014,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_ALIGNMENT_CONTROL_FEATURES_MESA = 1000575000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_ALIGNMENT_CONTROL_PROPERTIES_MESA = 1000575001,
    VK_STRUCTURE_TYPE_IMAGE_ALIGNMENT_CONTROL_CREATE_INFO_MESA = 1000575002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DEPTH_CLAMP_CONTROL_FEATURES_EXT = 1000582000,
    VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_DEPTH_CLAMP_CONTROL_CREATE_INFO_EXT = 1000582001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_HDR_VIVID_FEATURES_HUAWEI = 1000590000,
    VK_STRUCTURE_TYPE_HDR_VIVID_DYNAMIC_METADATA_HUAWEI = 1000590001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COOPERATIVE_MATRIX_2_FEATURES_NV = 1000593000,
    VK_STRUCTURE_TYPE_COOPERATIVE_MATRIX_FLEXIBLE_DIMENSIONS_PROPERTIES_NV = 1000593001,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COOPERATIVE_MATRIX_2_PROPERTIES_NV = 1000593002,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VERTEX_ATTRIBUTE_ROBUSTNESS_FEATURES_EXT = 1000608000,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VARIABLE_POINTER_FEATURES = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VARIABLE_POINTERS_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_DRAW_PARAMETER_FEATURES = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_DRAW_PARAMETERS_FEATURES,

    VK_STRUCTURE_TYPE_DEBUG_REPORT_CREATE_INFO_EXT = VK_STRUCTURE_TYPE_DEBUG_REPORT_CALLBACK_CREATE_INFO_EXT,
    VK_STRUCTURE_TYPE_RENDERING_INFO_KHR = VK_STRUCTURE_TYPE_RENDERING_INFO,
    VK_STRUCTURE_TYPE_RENDERING_ATTACHMENT_INFO_KHR = VK_STRUCTURE_TYPE_RENDERING_ATTACHMENT_INFO,
    VK_STRUCTURE_TYPE_PIPELINE_RENDERING_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_PIPELINE_RENDERING_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DYNAMIC_RENDERING_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DYNAMIC_RENDERING_FEATURES,
    VK_STRUCTURE_TYPE_COMMAND_BUFFER_INHERITANCE_RENDERING_INFO_KHR = VK_STRUCTURE_TYPE_COMMAND_BUFFER_INHERITANCE_RENDERING_INFO,
    VK_STRUCTURE_TYPE_RENDER_PASS_MULTIVIEW_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_RENDER_PASS_MULTIVIEW_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTIVIEW_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTIVIEW_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTIVIEW_PROPERTIES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTIVIEW_PROPERTIES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FEATURES_2_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FEATURES_2,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PROPERTIES_2_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PROPERTIES_2,
    VK_STRUCTURE_TYPE_FORMAT_PROPERTIES_2_KHR = VK_STRUCTURE_TYPE_FORMAT_PROPERTIES_2,
    VK_STRUCTURE_TYPE_IMAGE_FORMAT_PROPERTIES_2_KHR = VK_STRUCTURE_TYPE_IMAGE_FORMAT_PROPERTIES_2,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_FORMAT_INFO_2_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_FORMAT_INFO_2,
    VK_STRUCTURE_TYPE_QUEUE_FAMILY_PROPERTIES_2_KHR = VK_STRUCTURE_TYPE_QUEUE_FAMILY_PROPERTIES_2,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MEMORY_PROPERTIES_2_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MEMORY_PROPERTIES_2,
    VK_STRUCTURE_TYPE_SPARSE_IMAGE_FORMAT_PROPERTIES_2_KHR = VK_STRUCTURE_TYPE_SPARSE_IMAGE_FORMAT_PROPERTIES_2,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SPARSE_IMAGE_FORMAT_INFO_2_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SPARSE_IMAGE_FORMAT_INFO_2,
    VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_FLAGS_INFO_KHR = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_FLAGS_INFO,
    VK_STRUCTURE_TYPE_DEVICE_GROUP_RENDER_PASS_BEGIN_INFO_KHR = VK_STRUCTURE_TYPE_DEVICE_GROUP_RENDER_PASS_BEGIN_INFO,
    VK_STRUCTURE_TYPE_DEVICE_GROUP_COMMAND_BUFFER_BEGIN_INFO_KHR = VK_STRUCTURE_TYPE_DEVICE_GROUP_COMMAND_BUFFER_BEGIN_INFO,
    VK_STRUCTURE_TYPE_DEVICE_GROUP_SUBMIT_INFO_KHR = VK_STRUCTURE_TYPE_DEVICE_GROUP_SUBMIT_INFO,
    VK_STRUCTURE_TYPE_DEVICE_GROUP_BIND_SPARSE_INFO_KHR = VK_STRUCTURE_TYPE_DEVICE_GROUP_BIND_SPARSE_INFO,
    VK_STRUCTURE_TYPE_BIND_BUFFER_MEMORY_DEVICE_GROUP_INFO_KHR = VK_STRUCTURE_TYPE_BIND_BUFFER_MEMORY_DEVICE_GROUP_INFO,
    VK_STRUCTURE_TYPE_BIND_IMAGE_MEMORY_DEVICE_GROUP_INFO_KHR = VK_STRUCTURE_TYPE_BIND_IMAGE_MEMORY_DEVICE_GROUP_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TEXTURE_COMPRESSION_ASTC_HDR_FEATURES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TEXTURE_COMPRESSION_ASTC_HDR_FEATURES,
    VK_STRUCTURE_TYPE_PIPELINE_ROBUSTNESS_CREATE_INFO_EXT = VK_STRUCTURE_TYPE_PIPELINE_ROBUSTNESS_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_ROBUSTNESS_FEATURES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_ROBUSTNESS_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_ROBUSTNESS_PROPERTIES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_ROBUSTNESS_PROPERTIES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_GROUP_PROPERTIES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_GROUP_PROPERTIES,
    VK_STRUCTURE_TYPE_DEVICE_GROUP_DEVICE_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_DEVICE_GROUP_DEVICE_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_IMAGE_FORMAT_INFO_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_IMAGE_FORMAT_INFO,
    VK_STRUCTURE_TYPE_EXTERNAL_IMAGE_FORMAT_PROPERTIES_KHR = VK_STRUCTURE_TYPE_EXTERNAL_IMAGE_FORMAT_PROPERTIES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_BUFFER_INFO_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_BUFFER_INFO,
    VK_STRUCTURE_TYPE_EXTERNAL_BUFFER_PROPERTIES_KHR = VK_STRUCTURE_TYPE_EXTERNAL_BUFFER_PROPERTIES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ID_PROPERTIES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ID_PROPERTIES,
    VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_BUFFER_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_BUFFER_CREATE_INFO,
    VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_IMAGE_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_IMAGE_CREATE_INFO,
    VK_STRUCTURE_TYPE_EXPORT_MEMORY_ALLOCATE_INFO_KHR = VK_STRUCTURE_TYPE_EXPORT_MEMORY_ALLOCATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_SEMAPHORE_INFO_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_SEMAPHORE_INFO,
    VK_STRUCTURE_TYPE_EXTERNAL_SEMAPHORE_PROPERTIES_KHR = VK_STRUCTURE_TYPE_EXTERNAL_SEMAPHORE_PROPERTIES,
    VK_STRUCTURE_TYPE_EXPORT_SEMAPHORE_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_EXPORT_SEMAPHORE_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PUSH_DESCRIPTOR_PROPERTIES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PUSH_DESCRIPTOR_PROPERTIES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_FLOAT16_INT8_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_FLOAT16_INT8_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FLOAT16_INT8_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_FLOAT16_INT8_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_16BIT_STORAGE_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_16BIT_STORAGE_FEATURES,
    VK_STRUCTURE_TYPE_DESCRIPTOR_UPDATE_TEMPLATE_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_DESCRIPTOR_UPDATE_TEMPLATE_CREATE_INFO,

    VK_STRUCTURE_TYPE_SURFACE_CAPABILITIES2_EXT = VK_STRUCTURE_TYPE_SURFACE_CAPABILITIES_2_EXT,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGELESS_FRAMEBUFFER_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGELESS_FRAMEBUFFER_FEATURES,
    VK_STRUCTURE_TYPE_FRAMEBUFFER_ATTACHMENTS_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_FRAMEBUFFER_ATTACHMENTS_CREATE_INFO,
    VK_STRUCTURE_TYPE_FRAMEBUFFER_ATTACHMENT_IMAGE_INFO_KHR = VK_STRUCTURE_TYPE_FRAMEBUFFER_ATTACHMENT_IMAGE_INFO,
    VK_STRUCTURE_TYPE_RENDER_PASS_ATTACHMENT_BEGIN_INFO_KHR = VK_STRUCTURE_TYPE_RENDER_PASS_ATTACHMENT_BEGIN_INFO,
    VK_STRUCTURE_TYPE_ATTACHMENT_DESCRIPTION_2_KHR = VK_STRUCTURE_TYPE_ATTACHMENT_DESCRIPTION_2,
    VK_STRUCTURE_TYPE_ATTACHMENT_REFERENCE_2_KHR = VK_STRUCTURE_TYPE_ATTACHMENT_REFERENCE_2,
    VK_STRUCTURE_TYPE_SUBPASS_DESCRIPTION_2_KHR = VK_STRUCTURE_TYPE_SUBPASS_DESCRIPTION_2,
    VK_STRUCTURE_TYPE_SUBPASS_DEPENDENCY_2_KHR = VK_STRUCTURE_TYPE_SUBPASS_DEPENDENCY_2,
    VK_STRUCTURE_TYPE_RENDER_PASS_CREATE_INFO_2_KHR = VK_STRUCTURE_TYPE_RENDER_PASS_CREATE_INFO_2,
    VK_STRUCTURE_TYPE_SUBPASS_BEGIN_INFO_KHR = VK_STRUCTURE_TYPE_SUBPASS_BEGIN_INFO,
    VK_STRUCTURE_TYPE_SUBPASS_END_INFO_KHR = VK_STRUCTURE_TYPE_SUBPASS_END_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_FENCE_INFO_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_FENCE_INFO,
    VK_STRUCTURE_TYPE_EXTERNAL_FENCE_PROPERTIES_KHR = VK_STRUCTURE_TYPE_EXTERNAL_FENCE_PROPERTIES,
    VK_STRUCTURE_TYPE_EXPORT_FENCE_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_EXPORT_FENCE_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_POINT_CLIPPING_PROPERTIES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_POINT_CLIPPING_PROPERTIES,
    VK_STRUCTURE_TYPE_RENDER_PASS_INPUT_ATTACHMENT_ASPECT_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_RENDER_PASS_INPUT_ATTACHMENT_ASPECT_CREATE_INFO,
    VK_STRUCTURE_TYPE_IMAGE_VIEW_USAGE_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_IMAGE_VIEW_USAGE_CREATE_INFO,
    VK_STRUCTURE_TYPE_PIPELINE_TESSELLATION_DOMAIN_ORIGIN_STATE_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_PIPELINE_TESSELLATION_DOMAIN_ORIGIN_STATE_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VARIABLE_POINTERS_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VARIABLE_POINTERS_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VARIABLE_POINTER_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VARIABLE_POINTERS_FEATURES_KHR,
    VK_STRUCTURE_TYPE_MEMORY_DEDICATED_REQUIREMENTS_KHR = VK_STRUCTURE_TYPE_MEMORY_DEDICATED_REQUIREMENTS,
    VK_STRUCTURE_TYPE_MEMORY_DEDICATED_ALLOCATE_INFO_KHR = VK_STRUCTURE_TYPE_MEMORY_DEDICATED_ALLOCATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SAMPLER_FILTER_MINMAX_PROPERTIES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SAMPLER_FILTER_MINMAX_PROPERTIES,
    VK_STRUCTURE_TYPE_SAMPLER_REDUCTION_MODE_CREATE_INFO_EXT = VK_STRUCTURE_TYPE_SAMPLER_REDUCTION_MODE_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_INLINE_UNIFORM_BLOCK_FEATURES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_INLINE_UNIFORM_BLOCK_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_INLINE_UNIFORM_BLOCK_PROPERTIES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_INLINE_UNIFORM_BLOCK_PROPERTIES,
    VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET_INLINE_UNIFORM_BLOCK_EXT = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET_INLINE_UNIFORM_BLOCK,
    VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_INLINE_UNIFORM_BLOCK_CREATE_INFO_EXT = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_INLINE_UNIFORM_BLOCK_CREATE_INFO,
    VK_STRUCTURE_TYPE_BUFFER_MEMORY_REQUIREMENTS_INFO_2_KHR = VK_STRUCTURE_TYPE_BUFFER_MEMORY_REQUIREMENTS_INFO_2,
    VK_STRUCTURE_TYPE_IMAGE_MEMORY_REQUIREMENTS_INFO_2_KHR = VK_STRUCTURE_TYPE_IMAGE_MEMORY_REQUIREMENTS_INFO_2,
    VK_STRUCTURE_TYPE_IMAGE_SPARSE_MEMORY_REQUIREMENTS_INFO_2_KHR = VK_STRUCTURE_TYPE_IMAGE_SPARSE_MEMORY_REQUIREMENTS_INFO_2,
    VK_STRUCTURE_TYPE_MEMORY_REQUIREMENTS_2_KHR = VK_STRUCTURE_TYPE_MEMORY_REQUIREMENTS_2,
    VK_STRUCTURE_TYPE_SPARSE_IMAGE_MEMORY_REQUIREMENTS_2_KHR = VK_STRUCTURE_TYPE_SPARSE_IMAGE_MEMORY_REQUIREMENTS_2,
    VK_STRUCTURE_TYPE_IMAGE_FORMAT_LIST_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_IMAGE_FORMAT_LIST_CREATE_INFO,
    VK_STRUCTURE_TYPE_ATTACHMENT_SAMPLE_COUNT_INFO_NV = VK_STRUCTURE_TYPE_ATTACHMENT_SAMPLE_COUNT_INFO_AMD,
    VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_CREATE_INFO,
    VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_INFO_KHR = VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_INFO,
    VK_STRUCTURE_TYPE_BIND_IMAGE_PLANE_MEMORY_INFO_KHR = VK_STRUCTURE_TYPE_BIND_IMAGE_PLANE_MEMORY_INFO,
    VK_STRUCTURE_TYPE_IMAGE_PLANE_MEMORY_REQUIREMENTS_INFO_KHR = VK_STRUCTURE_TYPE_IMAGE_PLANE_MEMORY_REQUIREMENTS_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SAMPLER_YCBCR_CONVERSION_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SAMPLER_YCBCR_CONVERSION_FEATURES,
    VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_IMAGE_FORMAT_PROPERTIES_KHR = VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_IMAGE_FORMAT_PROPERTIES,
    VK_STRUCTURE_TYPE_BIND_BUFFER_MEMORY_INFO_KHR = VK_STRUCTURE_TYPE_BIND_BUFFER_MEMORY_INFO,
    VK_STRUCTURE_TYPE_BIND_IMAGE_MEMORY_INFO_KHR = VK_STRUCTURE_TYPE_BIND_IMAGE_MEMORY_INFO,
    VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_BINDING_FLAGS_CREATE_INFO_EXT = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_BINDING_FLAGS_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DESCRIPTOR_INDEXING_FEATURES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DESCRIPTOR_INDEXING_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DESCRIPTOR_INDEXING_PROPERTIES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DESCRIPTOR_INDEXING_PROPERTIES,
    VK_STRUCTURE_TYPE_DESCRIPTOR_SET_VARIABLE_DESCRIPTOR_COUNT_ALLOCATE_INFO_EXT = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_VARIABLE_DESCRIPTOR_COUNT_ALLOCATE_INFO,
    VK_STRUCTURE_TYPE_DESCRIPTOR_SET_VARIABLE_DESCRIPTOR_COUNT_LAYOUT_SUPPORT_EXT = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_VARIABLE_DESCRIPTOR_COUNT_LAYOUT_SUPPORT,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_3_PROPERTIES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_3_PROPERTIES,
    VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_SUPPORT_KHR = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_SUPPORT,
    VK_STRUCTURE_TYPE_DEVICE_QUEUE_GLOBAL_PRIORITY_CREATE_INFO_EXT = VK_STRUCTURE_TYPE_DEVICE_QUEUE_GLOBAL_PRIORITY_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_SUBGROUP_EXTENDED_TYPES_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_SUBGROUP_EXTENDED_TYPES_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_8BIT_STORAGE_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_8BIT_STORAGE_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_ATOMIC_INT64_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_ATOMIC_INT64_FEATURES,
    VK_STRUCTURE_TYPE_CALIBRATED_TIMESTAMP_INFO_EXT = VK_STRUCTURE_TYPE_CALIBRATED_TIMESTAMP_INFO_KHR,
    VK_STRUCTURE_TYPE_DEVICE_QUEUE_GLOBAL_PRIORITY_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_DEVICE_QUEUE_GLOBAL_PRIORITY_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_GLOBAL_PRIORITY_QUERY_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_GLOBAL_PRIORITY_QUERY_FEATURES,
    VK_STRUCTURE_TYPE_QUEUE_FAMILY_GLOBAL_PRIORITY_PROPERTIES_KHR = VK_STRUCTURE_TYPE_QUEUE_FAMILY_GLOBAL_PRIORITY_PROPERTIES,
    VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_DIVISOR_STATE_CREATE_INFO_EXT = VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_DIVISOR_STATE_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VERTEX_ATTRIBUTE_DIVISOR_FEATURES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VERTEX_ATTRIBUTE_DIVISOR_FEATURES,
    VK_STRUCTURE_TYPE_PIPELINE_CREATION_FEEDBACK_CREATE_INFO_EXT = VK_STRUCTURE_TYPE_PIPELINE_CREATION_FEEDBACK_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DRIVER_PROPERTIES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DRIVER_PROPERTIES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FLOAT_CONTROLS_PROPERTIES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FLOAT_CONTROLS_PROPERTIES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DEPTH_STENCIL_RESOLVE_PROPERTIES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DEPTH_STENCIL_RESOLVE_PROPERTIES,
    VK_STRUCTURE_TYPE_SUBPASS_DESCRIPTION_DEPTH_STENCIL_RESOLVE_KHR = VK_STRUCTURE_TYPE_SUBPASS_DESCRIPTION_DEPTH_STENCIL_RESOLVE,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COMPUTE_SHADER_DERIVATIVES_FEATURES_NV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COMPUTE_SHADER_DERIVATIVES_FEATURES_KHR,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_SHADER_BARYCENTRIC_FEATURES_NV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_SHADER_BARYCENTRIC_FEATURES_KHR,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TIMELINE_SEMAPHORE_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TIMELINE_SEMAPHORE_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TIMELINE_SEMAPHORE_PROPERTIES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TIMELINE_SEMAPHORE_PROPERTIES,
    VK_STRUCTURE_TYPE_SEMAPHORE_TYPE_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_SEMAPHORE_TYPE_CREATE_INFO,
    VK_STRUCTURE_TYPE_TIMELINE_SEMAPHORE_SUBMIT_INFO_KHR = VK_STRUCTURE_TYPE_TIMELINE_SEMAPHORE_SUBMIT_INFO,
    VK_STRUCTURE_TYPE_SEMAPHORE_WAIT_INFO_KHR = VK_STRUCTURE_TYPE_SEMAPHORE_WAIT_INFO,
    VK_STRUCTURE_TYPE_SEMAPHORE_SIGNAL_INFO_KHR = VK_STRUCTURE_TYPE_SEMAPHORE_SIGNAL_INFO,

    VK_STRUCTURE_TYPE_QUERY_POOL_CREATE_INFO_INTEL = VK_STRUCTURE_TYPE_QUERY_POOL_PERFORMANCE_QUERY_CREATE_INFO_INTEL,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_MEMORY_MODEL_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_MEMORY_MODEL_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_TERMINATE_INVOCATION_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_TERMINATE_INVOCATION_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SCALAR_BLOCK_LAYOUT_FEATURES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SCALAR_BLOCK_LAYOUT_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SUBGROUP_SIZE_CONTROL_PROPERTIES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SUBGROUP_SIZE_CONTROL_PROPERTIES,
    VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_REQUIRED_SUBGROUP_SIZE_CREATE_INFO_EXT = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_REQUIRED_SUBGROUP_SIZE_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SUBGROUP_SIZE_CONTROL_FEATURES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SUBGROUP_SIZE_CONTROL_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DYNAMIC_RENDERING_LOCAL_READ_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DYNAMIC_RENDERING_LOCAL_READ_FEATURES,
    VK_STRUCTURE_TYPE_RENDERING_ATTACHMENT_LOCATION_INFO_KHR = VK_STRUCTURE_TYPE_RENDERING_ATTACHMENT_LOCATION_INFO,
    VK_STRUCTURE_TYPE_RENDERING_INPUT_ATTACHMENT_INDEX_INFO_KHR = VK_STRUCTURE_TYPE_RENDERING_INPUT_ATTACHMENT_INDEX_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SEPARATE_DEPTH_STENCIL_LAYOUTS_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SEPARATE_DEPTH_STENCIL_LAYOUTS_FEATURES,
    VK_STRUCTURE_TYPE_ATTACHMENT_REFERENCE_STENCIL_LAYOUT_KHR = VK_STRUCTURE_TYPE_ATTACHMENT_REFERENCE_STENCIL_LAYOUT,
    VK_STRUCTURE_TYPE_ATTACHMENT_DESCRIPTION_STENCIL_LAYOUT_KHR = VK_STRUCTURE_TYPE_ATTACHMENT_DESCRIPTION_STENCIL_LAYOUT,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_BUFFER_ADDRESS_FEATURES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_BUFFER_DEVICE_ADDRESS_FEATURES_EXT,
    VK_STRUCTURE_TYPE_BUFFER_DEVICE_ADDRESS_INFO_EXT = VK_STRUCTURE_TYPE_BUFFER_DEVICE_ADDRESS_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TOOL_PROPERTIES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TOOL_PROPERTIES,
    VK_STRUCTURE_TYPE_IMAGE_STENCIL_USAGE_CREATE_INFO_EXT = VK_STRUCTURE_TYPE_IMAGE_STENCIL_USAGE_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_UNIFORM_BUFFER_STANDARD_LAYOUT_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_UNIFORM_BUFFER_STANDARD_LAYOUT_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_BUFFER_DEVICE_ADDRESS_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_BUFFER_DEVICE_ADDRESS_FEATURES,
    VK_STRUCTURE_TYPE_BUFFER_DEVICE_ADDRESS_INFO_KHR = VK_STRUCTURE_TYPE_BUFFER_DEVICE_ADDRESS_INFO,
    VK_STRUCTURE_TYPE_BUFFER_OPAQUE_CAPTURE_ADDRESS_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_BUFFER_OPAQUE_CAPTURE_ADDRESS_CREATE_INFO,
    VK_STRUCTURE_TYPE_MEMORY_OPAQUE_CAPTURE_ADDRESS_ALLOCATE_INFO_KHR = VK_STRUCTURE_TYPE_MEMORY_OPAQUE_CAPTURE_ADDRESS_ALLOCATE_INFO,
    VK_STRUCTURE_TYPE_DEVICE_MEMORY_OPAQUE_CAPTURE_ADDRESS_INFO_KHR = VK_STRUCTURE_TYPE_DEVICE_MEMORY_OPAQUE_CAPTURE_ADDRESS_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LINE_RASTERIZATION_FEATURES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LINE_RASTERIZATION_FEATURES,
    VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_LINE_STATE_CREATE_INFO_EXT = VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_LINE_STATE_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LINE_RASTERIZATION_PROPERTIES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LINE_RASTERIZATION_PROPERTIES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_HOST_QUERY_RESET_FEATURES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_HOST_QUERY_RESET_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_INDEX_TYPE_UINT8_FEATURES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_INDEX_TYPE_UINT8_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_HOST_IMAGE_COPY_FEATURES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_HOST_IMAGE_COPY_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_HOST_IMAGE_COPY_PROPERTIES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_HOST_IMAGE_COPY_PROPERTIES,
    VK_STRUCTURE_TYPE_MEMORY_TO_IMAGE_COPY_EXT = VK_STRUCTURE_TYPE_MEMORY_TO_IMAGE_COPY,
    VK_STRUCTURE_TYPE_IMAGE_TO_MEMORY_COPY_EXT = VK_STRUCTURE_TYPE_IMAGE_TO_MEMORY_COPY,
    VK_STRUCTURE_TYPE_COPY_IMAGE_TO_MEMORY_INFO_EXT = VK_STRUCTURE_TYPE_COPY_IMAGE_TO_MEMORY_INFO,
    VK_STRUCTURE_TYPE_COPY_MEMORY_TO_IMAGE_INFO_EXT = VK_STRUCTURE_TYPE_COPY_MEMORY_TO_IMAGE_INFO,
    VK_STRUCTURE_TYPE_HOST_IMAGE_LAYOUT_TRANSITION_INFO_EXT = VK_STRUCTURE_TYPE_HOST_IMAGE_LAYOUT_TRANSITION_INFO,
    VK_STRUCTURE_TYPE_COPY_IMAGE_TO_IMAGE_INFO_EXT = VK_STRUCTURE_TYPE_COPY_IMAGE_TO_IMAGE_INFO,
    VK_STRUCTURE_TYPE_SUBRESOURCE_HOST_MEMCPY_SIZE_EXT = VK_STRUCTURE_TYPE_SUBRESOURCE_HOST_MEMCPY_SIZE,
    VK_STRUCTURE_TYPE_HOST_IMAGE_COPY_DEVICE_PERFORMANCE_QUERY_EXT = VK_STRUCTURE_TYPE_HOST_IMAGE_COPY_DEVICE_PERFORMANCE_QUERY,
    VK_STRUCTURE_TYPE_MEMORY_MAP_INFO_KHR = VK_STRUCTURE_TYPE_MEMORY_MAP_INFO,
    VK_STRUCTURE_TYPE_MEMORY_UNMAP_INFO_KHR = VK_STRUCTURE_TYPE_MEMORY_UNMAP_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_DEMOTE_TO_HELPER_INVOCATION_FEATURES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_DEMOTE_TO_HELPER_INVOCATION_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_INTEGER_DOT_PRODUCT_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_INTEGER_DOT_PRODUCT_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_INTEGER_DOT_PRODUCT_PROPERTIES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_INTEGER_DOT_PRODUCT_PROPERTIES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TEXEL_BUFFER_ALIGNMENT_PROPERTIES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TEXEL_BUFFER_ALIGNMENT_PROPERTIES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PRIVATE_DATA_FEATURES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PRIVATE_DATA_FEATURES,
    VK_STRUCTURE_TYPE_DEVICE_PRIVATE_DATA_CREATE_INFO_EXT = VK_STRUCTURE_TYPE_DEVICE_PRIVATE_DATA_CREATE_INFO,
    VK_STRUCTURE_TYPE_PRIVATE_DATA_SLOT_CREATE_INFO_EXT = VK_STRUCTURE_TYPE_PRIVATE_DATA_SLOT_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_CREATION_CACHE_CONTROL_FEATURES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_CREATION_CACHE_CONTROL_FEATURES,
    VK_STRUCTURE_TYPE_MEMORY_BARRIER_2_KHR = VK_STRUCTURE_TYPE_MEMORY_BARRIER_2,
    VK_STRUCTURE_TYPE_BUFFER_MEMORY_BARRIER_2_KHR = VK_STRUCTURE_TYPE_BUFFER_MEMORY_BARRIER_2,
    VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER_2_KHR = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER_2,
    VK_STRUCTURE_TYPE_DEPENDENCY_INFO_KHR = VK_STRUCTURE_TYPE_DEPENDENCY_INFO,
    VK_STRUCTURE_TYPE_SUBMIT_INFO_2_KHR = VK_STRUCTURE_TYPE_SUBMIT_INFO_2,
    VK_STRUCTURE_TYPE_SEMAPHORE_SUBMIT_INFO_KHR = VK_STRUCTURE_TYPE_SEMAPHORE_SUBMIT_INFO,
    VK_STRUCTURE_TYPE_COMMAND_BUFFER_SUBMIT_INFO_KHR = VK_STRUCTURE_TYPE_COMMAND_BUFFER_SUBMIT_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SYNCHRONIZATION_2_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SYNCHRONIZATION_2_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ZERO_INITIALIZE_WORKGROUP_MEMORY_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ZERO_INITIALIZE_WORKGROUP_MEMORY_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_ROBUSTNESS_FEATURES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_ROBUSTNESS_FEATURES,
    VK_STRUCTURE_TYPE_COPY_BUFFER_INFO_2_KHR = VK_STRUCTURE_TYPE_COPY_BUFFER_INFO_2,
    VK_STRUCTURE_TYPE_COPY_IMAGE_INFO_2_KHR = VK_STRUCTURE_TYPE_COPY_IMAGE_INFO_2,
    VK_STRUCTURE_TYPE_COPY_BUFFER_TO_IMAGE_INFO_2_KHR = VK_STRUCTURE_TYPE_COPY_BUFFER_TO_IMAGE_INFO_2,
    VK_STRUCTURE_TYPE_COPY_IMAGE_TO_BUFFER_INFO_2_KHR = VK_STRUCTURE_TYPE_COPY_IMAGE_TO_BUFFER_INFO_2,
    VK_STRUCTURE_TYPE_BLIT_IMAGE_INFO_2_KHR = VK_STRUCTURE_TYPE_BLIT_IMAGE_INFO_2,
    VK_STRUCTURE_TYPE_RESOLVE_IMAGE_INFO_2_KHR = VK_STRUCTURE_TYPE_RESOLVE_IMAGE_INFO_2,
    VK_STRUCTURE_TYPE_BUFFER_COPY_2_KHR = VK_STRUCTURE_TYPE_BUFFER_COPY_2,
    VK_STRUCTURE_TYPE_IMAGE_COPY_2_KHR = VK_STRUCTURE_TYPE_IMAGE_COPY_2,
    VK_STRUCTURE_TYPE_IMAGE_BLIT_2_KHR = VK_STRUCTURE_TYPE_IMAGE_BLIT_2,
    VK_STRUCTURE_TYPE_BUFFER_IMAGE_COPY_2_KHR = VK_STRUCTURE_TYPE_BUFFER_IMAGE_COPY_2,
    VK_STRUCTURE_TYPE_IMAGE_RESOLVE_2_KHR = VK_STRUCTURE_TYPE_IMAGE_RESOLVE_2,
    VK_STRUCTURE_TYPE_SUBRESOURCE_LAYOUT_2_EXT = VK_STRUCTURE_TYPE_SUBRESOURCE_LAYOUT_2,
    VK_STRUCTURE_TYPE_IMAGE_SUBRESOURCE_2_EXT = VK_STRUCTURE_TYPE_IMAGE_SUBRESOURCE_2,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RASTERIZATION_ORDER_ATTACHMENT_ACCESS_FEATURES_ARM = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RASTERIZATION_ORDER_ATTACHMENT_ACCESS_FEATURES_EXT,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MUTABLE_DESCRIPTOR_TYPE_FEATURES_VALVE = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MUTABLE_DESCRIPTOR_TYPE_FEATURES_EXT,
    VK_STRUCTURE_TYPE_MUTABLE_DESCRIPTOR_TYPE_CREATE_INFO_VALVE = VK_STRUCTURE_TYPE_MUTABLE_DESCRIPTOR_TYPE_CREATE_INFO_EXT,
    VK_STRUCTURE_TYPE_FORMAT_PROPERTIES_3_KHR = VK_STRUCTURE_TYPE_FORMAT_PROPERTIES_3,
    VK_STRUCTURE_TYPE_PIPELINE_INFO_EXT = VK_STRUCTURE_TYPE_PIPELINE_INFO_KHR,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_GLOBAL_PRIORITY_QUERY_FEATURES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_GLOBAL_PRIORITY_QUERY_FEATURES,
    VK_STRUCTURE_TYPE_QUEUE_FAMILY_GLOBAL_PRIORITY_PROPERTIES_EXT = VK_STRUCTURE_TYPE_QUEUE_FAMILY_GLOBAL_PRIORITY_PROPERTIES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_4_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_4_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_4_PROPERTIES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_4_PROPERTIES,
    VK_STRUCTURE_TYPE_DEVICE_BUFFER_MEMORY_REQUIREMENTS_KHR = VK_STRUCTURE_TYPE_DEVICE_BUFFER_MEMORY_REQUIREMENTS,
    VK_STRUCTURE_TYPE_DEVICE_IMAGE_MEMORY_REQUIREMENTS_KHR = VK_STRUCTURE_TYPE_DEVICE_IMAGE_MEMORY_REQUIREMENTS,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_SUBGROUP_ROTATE_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_SUBGROUP_ROTATE_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_PROTECTED_ACCESS_FEATURES_EXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_PROTECTED_ACCESS_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_5_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_5_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_5_PROPERTIES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_5_PROPERTIES,
    VK_STRUCTURE_TYPE_RENDERING_AREA_INFO_KHR = VK_STRUCTURE_TYPE_RENDERING_AREA_INFO,
    VK_STRUCTURE_TYPE_DEVICE_IMAGE_SUBRESOURCE_INFO_KHR = VK_STRUCTURE_TYPE_DEVICE_IMAGE_SUBRESOURCE_INFO,
    VK_STRUCTURE_TYPE_SUBRESOURCE_LAYOUT_2_KHR = VK_STRUCTURE_TYPE_SUBRESOURCE_LAYOUT_2,
    VK_STRUCTURE_TYPE_IMAGE_SUBRESOURCE_2_KHR = VK_STRUCTURE_TYPE_IMAGE_SUBRESOURCE_2,
    VK_STRUCTURE_TYPE_PIPELINE_CREATE_FLAGS_2_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_PIPELINE_CREATE_FLAGS_2_CREATE_INFO,
    VK_STRUCTURE_TYPE_BUFFER_USAGE_FLAGS_2_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_BUFFER_USAGE_FLAGS_2_CREATE_INFO,
    VK_STRUCTURE_TYPE_SHADER_REQUIRED_SUBGROUP_SIZE_CREATE_INFO_EXT = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_REQUIRED_SUBGROUP_SIZE_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VERTEX_ATTRIBUTE_DIVISOR_PROPERTIES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VERTEX_ATTRIBUTE_DIVISOR_PROPERTIES,
    VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_DIVISOR_STATE_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_DIVISOR_STATE_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VERTEX_ATTRIBUTE_DIVISOR_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VERTEX_ATTRIBUTE_DIVISOR_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_FLOAT_CONTROLS_2_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_FLOAT_CONTROLS_2_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_INDEX_TYPE_UINT8_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_INDEX_TYPE_UINT8_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LINE_RASTERIZATION_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LINE_RASTERIZATION_FEATURES,
    VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_LINE_STATE_CREATE_INFO_KHR = VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_LINE_STATE_CREATE_INFO,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LINE_RASTERIZATION_PROPERTIES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LINE_RASTERIZATION_PROPERTIES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_EXPECT_ASSUME_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_EXPECT_ASSUME_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_6_FEATURES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_6_FEATURES,
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_6_PROPERTIES_KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_6_PROPERTIES,
    VK_STRUCTURE_TYPE_BIND_MEMORY_STATUS_KHR = VK_STRUCTURE_TYPE_BIND_MEMORY_STATUS,
    VK_STRUCTURE_TYPE_BIND_DESCRIPTOR_SETS_INFO_KHR = VK_STRUCTURE_TYPE_BIND_DESCRIPTOR_SETS_INFO,
    VK_STRUCTURE_TYPE_PUSH_CONSTANTS_INFO_KHR = VK_STRUCTURE_TYPE_PUSH_CONSTANTS_INFO,
    VK_STRUCTURE_TYPE_PUSH_DESCRIPTOR_SET_INFO_KHR = VK_STRUCTURE_TYPE_PUSH_DESCRIPTOR_SET_INFO,
    VK_STRUCTURE_TYPE_PUSH_DESCRIPTOR_SET_WITH_TEMPLATE_INFO_KHR = VK_STRUCTURE_TYPE_PUSH_DESCRIPTOR_SET_WITH_TEMPLATE_INFO,
    VK_STRUCTURE_TYPE_MAX_ENUM = 0x7FFFFFFF
} VkStructureType;

typedef enum VkPipelineCacheHeaderVersion {
    VK_PIPELINE_CACHE_HEADER_VERSION_ONE = 1,
    VK_PIPELINE_CACHE_HEADER_VERSION_MAX_ENUM = 0x7FFFFFFF
} VkPipelineCacheHeaderVersion;

typedef enum VkImageLayout {
    VK_IMAGE_LAYOUT_UNDEFINED = 0,
    VK_IMAGE_LAYOUT_GENERAL = 1,
    VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL = 2,
    VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL = 3,
    VK_IMAGE_LAYOUT_DEPTH_STENCIL_READ_ONLY_OPTIMAL = 4,
    VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL = 5,
    VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL = 6,
    VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL = 7,
    VK_IMAGE_LAYOUT_PREINITIALIZED = 8,
    VK_IMAGE_LAYOUT_DEPTH_READ_ONLY_STENCIL_ATTACHMENT_OPTIMAL = 1000117000,
    VK_IMAGE_LAYOUT_DEPTH_ATTACHMENT_STENCIL_READ_ONLY_OPTIMAL = 1000117001,
    VK_IMAGE_LAYOUT_DEPTH_ATTACHMENT_OPTIMAL = 1000241000,
    VK_IMAGE_LAYOUT_DEPTH_READ_ONLY_OPTIMAL = 1000241001,
    VK_IMAGE_LAYOUT_STENCIL_ATTACHMENT_OPTIMAL = 1000241002,
    VK_IMAGE_LAYOUT_STENCIL_READ_ONLY_OPTIMAL = 1000241003,
    VK_IMAGE_LAYOUT_READ_ONLY_OPTIMAL = 1000314000,
    VK_IMAGE_LAYOUT_ATTACHMENT_OPTIMAL = 1000314001,
    VK_IMAGE_LAYOUT_RENDERING_LOCAL_READ = 1000232000,
    VK_IMAGE_LAYOUT_PRESENT_SRC_KHR = 1000001002,
    VK_IMAGE_LAYOUT_VIDEO_DECODE_DST_KHR = 1000024000,
    VK_IMAGE_LAYOUT_VIDEO_DECODE_SRC_KHR = 1000024001,
    VK_IMAGE_LAYOUT_VIDEO_DECODE_DPB_KHR = 1000024002,
    VK_IMAGE_LAYOUT_SHARED_PRESENT_KHR = 1000111000,
    VK_IMAGE_LAYOUT_FRAGMENT_DENSITY_MAP_OPTIMAL_EXT = 1000218000,
    VK_IMAGE_LAYOUT_FRAGMENT_SHADING_RATE_ATTACHMENT_OPTIMAL_KHR = 1000164003,
    VK_IMAGE_LAYOUT_VIDEO_ENCODE_DST_KHR = 1000299000,
    VK_IMAGE_LAYOUT_VIDEO_ENCODE_SRC_KHR = 1000299001,
    VK_IMAGE_LAYOUT_VIDEO_ENCODE_DPB_KHR = 1000299002,
    VK_IMAGE_LAYOUT_ATTACHMENT_FEEDBACK_LOOP_OPTIMAL_EXT = 1000339000,
    VK_IMAGE_LAYOUT_VIDEO_ENCODE_QUANTIZATION_MAP_KHR = 1000553000,
    VK_IMAGE_LAYOUT_DEPTH_READ_ONLY_STENCIL_ATTACHMENT_OPTIMAL_KHR = VK_IMAGE_LAYOUT_DEPTH_READ_ONLY_STENCIL_ATTACHMENT_OPTIMAL,
    VK_IMAGE_LAYOUT_DEPTH_ATTACHMENT_STENCIL_READ_ONLY_OPTIMAL_KHR = VK_IMAGE_LAYOUT_DEPTH_ATTACHMENT_STENCIL_READ_ONLY_OPTIMAL,
    VK_IMAGE_LAYOUT_SHADING_RATE_OPTIMAL_NV = VK_IMAGE_LAYOUT_FRAGMENT_SHADING_RATE_ATTACHMENT_OPTIMAL_KHR,
    VK_IMAGE_LAYOUT_RENDERING_LOCAL_READ_KHR = VK_IMAGE_LAYOUT_RENDERING_LOCAL_READ,
    VK_IMAGE_LAYOUT_DEPTH_ATTACHMENT_OPTIMAL_KHR = VK_IMAGE_LAYOUT_DEPTH_ATTACHMENT_OPTIMAL,
    VK_IMAGE_LAYOUT_DEPTH_READ_ONLY_OPTIMAL_KHR = VK_IMAGE_LAYOUT_DEPTH_READ_ONLY_OPTIMAL,
    VK_IMAGE_LAYOUT_STENCIL_ATTACHMENT_OPTIMAL_KHR = VK_IMAGE_LAYOUT_STENCIL_ATTACHMENT_OPTIMAL,
    VK_IMAGE_LAYOUT_STENCIL_READ_ONLY_OPTIMAL_KHR = VK_IMAGE_LAYOUT_STENCIL_READ_ONLY_OPTIMAL,
    VK_IMAGE_LAYOUT_READ_ONLY_OPTIMAL_KHR = VK_IMAGE_LAYOUT_READ_ONLY_OPTIMAL,
    VK_IMAGE_LAYOUT_ATTACHMENT_OPTIMAL_KHR = VK_IMAGE_LAYOUT_ATTACHMENT_OPTIMAL,
    VK_IMAGE_LAYOUT_MAX_ENUM = 0x7FFFFFFF
} VkImageLayout;

typedef enum VkObjectType {
    VK_OBJECT_TYPE_UNKNOWN = 0,
    VK_OBJECT_TYPE_INSTANCE = 1,
    VK_OBJECT_TYPE_PHYSICAL_DEVICE = 2,
    VK_OBJECT_TYPE_DEVICE = 3,
    VK_OBJECT_TYPE_QUEUE = 4,
    VK_OBJECT_TYPE_SEMAPHORE = 5,
    VK_OBJECT_TYPE_COMMAND_BUFFER = 6,
    VK_OBJECT_TYPE_FENCE = 7,
    VK_OBJECT_TYPE_DEVICE_MEMORY = 8,
    VK_OBJECT_TYPE_BUFFER = 9,
    VK_OBJECT_TYPE_IMAGE = 10,
    VK_OBJECT_TYPE_EVENT = 11,
    VK_OBJECT_TYPE_QUERY_POOL = 12,
    VK_OBJECT_TYPE_BUFFER_VIEW = 13,
    VK_OBJECT_TYPE_IMAGE_VIEW = 14,
    VK_OBJECT_TYPE_SHADER_MODULE = 15,
    VK_OBJECT_TYPE_PIPELINE_CACHE = 16,
    VK_OBJECT_TYPE_PIPELINE_LAYOUT = 17,
    VK_OBJECT_TYPE_RENDER_PASS = 18,
    VK_OBJECT_TYPE_PIPELINE = 19,
    VK_OBJECT_TYPE_DESCRIPTOR_SET_LAYOUT = 20,
    VK_OBJECT_TYPE_SAMPLER = 21,
    VK_OBJECT_TYPE_DESCRIPTOR_POOL = 22,
    VK_OBJECT_TYPE_DESCRIPTOR_SET = 23,
    VK_OBJECT_TYPE_FRAMEBUFFER = 24,
    VK_OBJECT_TYPE_COMMAND_POOL = 25,
    VK_OBJECT_TYPE_SAMPLER_YCBCR_CONVERSION = 1000156000,
    VK_OBJECT_TYPE_DESCRIPTOR_UPDATE_TEMPLATE = 1000085000,
    VK_OBJECT_TYPE_PRIVATE_DATA_SLOT = 1000295000,
    VK_OBJECT_TYPE_SURFACE_KHR = 1000000000,
    VK_OBJECT_TYPE_SWAPCHAIN_KHR = 1000001000,
    VK_OBJECT_TYPE_DISPLAY_KHR = 1000002000,
    VK_OBJECT_TYPE_DISPLAY_MODE_KHR = 1000002001,
    VK_OBJECT_TYPE_DEBUG_REPORT_CALLBACK_EXT = 1000011000,
    VK_OBJECT_TYPE_VIDEO_SESSION_KHR = 1000023000,
    VK_OBJECT_TYPE_VIDEO_SESSION_PARAMETERS_KHR = 1000023001,
    VK_OBJECT_TYPE_CU_MODULE_NVX = 1000029000,
    VK_OBJECT_TYPE_CU_FUNCTION_NVX = 1000029001,
    VK_OBJECT_TYPE_DEBUG_UTILS_MESSENGER_EXT = 1000128000,
    VK_OBJECT_TYPE_ACCELERATION_STRUCTURE_KHR = 1000150000,
    VK_OBJECT_TYPE_VALIDATION_CACHE_EXT = 1000160000,
    VK_OBJECT_TYPE_ACCELERATION_STRUCTURE_NV = 1000165000,
    VK_OBJECT_TYPE_PERFORMANCE_CONFIGURATION_INTEL = 1000210000,
    VK_OBJECT_TYPE_DEFERRED_OPERATION_KHR = 1000268000,
    VK_OBJECT_TYPE_INDIRECT_COMMANDS_LAYOUT_NV = 1000277000,
    VK_OBJECT_TYPE_CUDA_MODULE_NV = 1000307000,
    VK_OBJECT_TYPE_CUDA_FUNCTION_NV = 1000307001,
    VK_OBJECT_TYPE_BUFFER_COLLECTION_FUCHSIA = 1000366000,
    VK_OBJECT_TYPE_MICROMAP_EXT = 1000396000,
    VK_OBJECT_TYPE_OPTICAL_FLOW_SESSION_NV = 1000464000,
    VK_OBJECT_TYPE_SHADER_EXT = 1000482000,
    VK_OBJECT_TYPE_PIPELINE_BINARY_KHR = 1000483000,
    VK_OBJECT_TYPE_INDIRECT_COMMANDS_LAYOUT_EXT = 1000572000,
    VK_OBJECT_TYPE_INDIRECT_EXECUTION_SET_EXT = 1000572001,
    VK_OBJECT_TYPE_DESCRIPTOR_UPDATE_TEMPLATE_KHR = VK_OBJECT_TYPE_DESCRIPTOR_UPDATE_TEMPLATE,
    VK_OBJECT_TYPE_SAMPLER_YCBCR_CONVERSION_KHR = VK_OBJECT_TYPE_SAMPLER_YCBCR_CONVERSION,
    VK_OBJECT_TYPE_PRIVATE_DATA_SLOT_EXT = VK_OBJECT_TYPE_PRIVATE_DATA_SLOT,
    VK_OBJECT_TYPE_MAX_ENUM = 0x7FFFFFFF
} VkObjectType;

typedef enum VkVendorId {
    VK_VENDOR_ID_KHRONOS = 0x10000,
    VK_VENDOR_ID_VIV = 0x10001,
    VK_VENDOR_ID_VSI = 0x10002,
    VK_VENDOR_ID_KAZAN = 0x10003,
    VK_VENDOR_ID_CODEPLAY = 0x10004,
    VK_VENDOR_ID_MESA = 0x10005,
    VK_VENDOR_ID_POCL = 0x10006,
    VK_VENDOR_ID_MOBILEYE = 0x10007,
    VK_VENDOR_ID_MAX_ENUM = 0x7FFFFFFF
} VkVendorId;

typedef enum VkSystemAllocationScope {
    VK_SYSTEM_ALLOCATION_SCOPE_COMMAND = 0,
    VK_SYSTEM_ALLOCATION_SCOPE_OBJECT = 1,
    VK_SYSTEM_ALLOCATION_SCOPE_CACHE = 2,
    VK_SYSTEM_ALLOCATION_SCOPE_DEVICE = 3,
    VK_SYSTEM_ALLOCATION_SCOPE_INSTANCE = 4,
    VK_SYSTEM_ALLOCATION_SCOPE_MAX_ENUM = 0x7FFFFFFF
} VkSystemAllocationScope;

typedef enum VkInternalAllocationType {
    VK_INTERNAL_ALLOCATION_TYPE_EXECUTABLE = 0,
    VK_INTERNAL_ALLOCATION_TYPE_MAX_ENUM = 0x7FFFFFFF
} VkInternalAllocationType;

typedef enum VkFormat {
    VK_FORMAT_UNDEFINED = 0,
    VK_FORMAT_R4G4_UNORM_PACK8 = 1,
    VK_FORMAT_R4G4B4A4_UNORM_PACK16 = 2,
    VK_FORMAT_B4G4R4A4_UNORM_PACK16 = 3,
    VK_FORMAT_R5G6B5_UNORM_PACK16 = 4,
    VK_FORMAT_B5G6R5_UNORM_PACK16 = 5,
    VK_FORMAT_R5G5B5A1_UNORM_PACK16 = 6,
    VK_FORMAT_B5G5R5A1_UNORM_PACK16 = 7,
    VK_FORMAT_A1R5G5B5_UNORM_PACK16 = 8,
    VK_FORMAT_R8_UNORM = 9,
    VK_FORMAT_R8_SNORM = 10,
    VK_FORMAT_R8_USCALED = 11,
    VK_FORMAT_R8_SSCALED = 12,
    VK_FORMAT_R8_UINT = 13,
    VK_FORMAT_R8_SINT = 14,
    VK_FORMAT_R8_SRGB = 15,
    VK_FORMAT_R8G8_UNORM = 16,
    VK_FORMAT_R8G8_SNORM = 17,
    VK_FORMAT_R8G8_USCALED = 18,
    VK_FORMAT_R8G8_SSCALED = 19,
    VK_FORMAT_R8G8_UINT = 20,
    VK_FORMAT_R8G8_SINT = 21,
    VK_FORMAT_R8G8_SRGB = 22,
    VK_FORMAT_R8G8B8_UNORM = 23,
    VK_FORMAT_R8G8B8_SNORM = 24,
    VK_FORMAT_R8G8B8_USCALED = 25,
    VK_FORMAT_R8G8B8_SSCALED = 26,
    VK_FORMAT_R8G8B8_UINT = 27,
    VK_FORMAT_R8G8B8_SINT = 28,
    VK_FORMAT_R8G8B8_SRGB = 29,
    VK_FORMAT_B8G8R8_UNORM = 30,
    VK_FORMAT_B8G8R8_SNORM = 31,
    VK_FORMAT_B8G8R8_USCALED = 32,
    VK_FORMAT_B8G8R8_SSCALED = 33,
    VK_FORMAT_B8G8R8_UINT = 34,
    VK_FORMAT_B8G8R8_SINT = 35,
    VK_FORMAT_B8G8R8_SRGB = 36,
    VK_FORMAT_R8G8B8A8_UNORM = 37,
    VK_FORMAT_R8G8B8A8_SNORM = 38,
    VK_FORMAT_R8G8B8A8_USCALED = 39,
    VK_FORMAT_R8G8B8A8_SSCALED = 40,
    VK_FORMAT_R8G8B8A8_UINT = 41,
    VK_FORMAT_R8G8B8A8_SINT = 42,
    VK_FORMAT_R8G8B8A8_SRGB = 43,
    VK_FORMAT_B8G8R8A8_UNORM = 44,
    VK_FORMAT_B8G8R8A8_SNORM = 45,
    VK_FORMAT_B8G8R8A8_USCALED = 46,
    VK_FORMAT_B8G8R8A8_SSCALED = 47,
    VK_FORMAT_B8G8R8A8_UINT = 48,
    VK_FORMAT_B8G8R8A8_SINT = 49,
    VK_FORMAT_B8G8R8A8_SRGB = 50,
    VK_FORMAT_A8B8G8R8_UNORM_PACK32 = 51,
    VK_FORMAT_A8B8G8R8_SNORM_PACK32 = 52,
    VK_FORMAT_A8B8G8R8_USCALED_PACK32 = 53,
    VK_FORMAT_A8B8G8R8_SSCALED_PACK32 = 54,
    VK_FORMAT_A8B8G8R8_UINT_PACK32 = 55,
    VK_FORMAT_A8B8G8R8_SINT_PACK32 = 56,
    VK_FORMAT_A8B8G8R8_SRGB_PACK32 = 57,
    VK_FORMAT_A2R10G10B10_UNORM_PACK32 = 58,
    VK_FORMAT_A2R10G10B10_SNORM_PACK32 = 59,
    VK_FORMAT_A2R10G10B10_USCALED_PACK32 = 60,
    VK_FORMAT_A2R10G10B10_SSCALED_PACK32 = 61,
    VK_FORMAT_A2R10G10B10_UINT_PACK32 = 62,
    VK_FORMAT_A2R10G10B10_SINT_PACK32 = 63,
    VK_FORMAT_A2B10G10R10_UNORM_PACK32 = 64,
    VK_FORMAT_A2B10G10R10_SNORM_PACK32 = 65,
    VK_FORMAT_A2B10G10R10_USCALED_PACK32 = 66,
    VK_FORMAT_A2B10G10R10_SSCALED_PACK32 = 67,
    VK_FORMAT_A2B10G10R10_UINT_PACK32 = 68,
    VK_FORMAT_A2B10G10R10_SINT_PACK32 = 69,
    VK_FORMAT_R16_UNORM = 70,
    VK_FORMAT_R16_SNORM = 71,
    VK_FORMAT_R16_USCALED = 72,
    VK_FORMAT_R16_SSCALED = 73,
    VK_FORMAT_R16_UINT = 74,
    VK_FORMAT_R16_SINT = 75,
    VK_FORMAT_R16_SFLOAT = 76,
    VK_FORMAT_R16G16_UNORM = 77,
    VK_FORMAT_R16G16_SNORM = 78,
    VK_FORMAT_R16G16_USCALED = 79,
    VK_FORMAT_R16G16_SSCALED = 80,
    VK_FORMAT_R16G16_UINT = 81,
    VK_FORMAT_R16G16_SINT = 82,
    VK_FORMAT_R16G16_SFLOAT = 83,
    VK_FORMAT_R16G16B16_UNORM = 84,
    VK_FORMAT_R16G16B16_SNORM = 85,
    VK_FORMAT_R16G16B16_USCALED = 86,
    VK_FORMAT_R16G16B16_SSCALED = 87,
    VK_FORMAT_R16G16B16_UINT = 88,
    VK_FORMAT_R16G16B16_SINT = 89,
    VK_FORMAT_R16G16B16_SFLOAT = 90,
    VK_FORMAT_R16G16B16A16_UNORM = 91,
    VK_FORMAT_R16G16B16A16_SNORM = 92,
    VK_FORMAT_R16G16B16A16_USCALED = 93,
    VK_FORMAT_R16G16B16A16_SSCALED = 94,
    VK_FORMAT_R16G16B16A16_UINT = 95,
    VK_FORMAT_R16G16B16A16_SINT = 96,
    VK_FORMAT_R16G16B16A16_SFLOAT = 97,
    VK_FORMAT_R32_UINT = 98,
    VK_FORMAT_R32_SINT = 99,
    VK_FORMAT_R32_SFLOAT = 100,
    VK_FORMAT_R32G32_UINT = 101,
    VK_FORMAT_R32G32_SINT = 102,
    VK_FORMAT_R32G32_SFLOAT = 103,
    VK_FORMAT_R32G32B32_UINT = 104,
    VK_FORMAT_R32G32B32_SINT = 105,
    VK_FORMAT_R32G32B32_SFLOAT = 106,
    VK_FORMAT_R32G32B32A32_UINT = 107,
    VK_FORMAT_R32G32B32A32_SINT = 108,
    VK_FORMAT_R32G32B32A32_SFLOAT = 109,
    VK_FORMAT_R64_UINT = 110,
    VK_FORMAT_R64_SINT = 111,
    VK_FORMAT_R64_SFLOAT = 112,
    VK_FORMAT_R64G64_UINT = 113,
    VK_FORMAT_R64G64_SINT = 114,
    VK_FORMAT_R64G64_SFLOAT = 115,
    VK_FORMAT_R64G64B64_UINT = 116,
    VK_FORMAT_R64G64B64_SINT = 117,
    VK_FORMAT_R64G64B64_SFLOAT = 118,
    VK_FORMAT_R64G64B64A64_UINT = 119,
    VK_FORMAT_R64G64B64A64_SINT = 120,
    VK_FORMAT_R64G64B64A64_SFLOAT = 121,
    VK_FORMAT_B10G11R11_UFLOAT_PACK32 = 122,
    VK_FORMAT_E5B9G9R9_UFLOAT_PACK32 = 123,
    VK_FORMAT_D16_UNORM = 124,
    VK_FORMAT_X8_D24_UNORM_PACK32 = 125,
    VK_FORMAT_D32_SFLOAT = 126,
    VK_FORMAT_S8_UINT = 127,
    VK_FORMAT_D16_UNORM_S8_UINT = 128,
    VK_FORMAT_D24_UNORM_S8_UINT = 129,
    VK_FORMAT_D32_SFLOAT_S8_UINT = 130,
    VK_FORMAT_BC1_RGB_UNORM_BLOCK = 131,
    VK_FORMAT_BC1_RGB_SRGB_BLOCK = 132,
    VK_FORMAT_BC1_RGBA_UNORM_BLOCK = 133,
    VK_FORMAT_BC1_RGBA_SRGB_BLOCK = 134,
    VK_FORMAT_BC2_UNORM_BLOCK = 135,
    VK_FORMAT_BC2_SRGB_BLOCK = 136,
    VK_FORMAT_BC3_UNORM_BLOCK = 137,
    VK_FORMAT_BC3_SRGB_BLOCK = 138,
    VK_FORMAT_BC4_UNORM_BLOCK = 139,
    VK_FORMAT_BC4_SNORM_BLOCK = 140,
    VK_FORMAT_BC5_UNORM_BLOCK = 141,
    VK_FORMAT_BC5_SNORM_BLOCK = 142,
    VK_FORMAT_BC6H_UFLOAT_BLOCK = 143,
    VK_FORMAT_BC6H_SFLOAT_BLOCK = 144,
    VK_FORMAT_BC7_UNORM_BLOCK = 145,
    VK_FORMAT_BC7_SRGB_BLOCK = 146,
    VK_FORMAT_ETC2_R8G8B8_UNORM_BLOCK = 147,
    VK_FORMAT_ETC2_R8G8B8_SRGB_BLOCK = 148,
    VK_FORMAT_ETC2_R8G8B8A1_UNORM_BLOCK = 149,
    VK_FORMAT_ETC2_R8G8B8A1_SRGB_BLOCK = 150,
    VK_FORMAT_ETC2_R8G8B8A8_UNORM_BLOCK = 151,
    VK_FORMAT_ETC2_R8G8B8A8_SRGB_BLOCK = 152,
    VK_FORMAT_EAC_R11_UNORM_BLOCK = 153,
    VK_FORMAT_EAC_R11_SNORM_BLOCK = 154,
    VK_FORMAT_EAC_R11G11_UNORM_BLOCK = 155,
    VK_FORMAT_EAC_R11G11_SNORM_BLOCK = 156,
    VK_FORMAT_ASTC_4x4_UNORM_BLOCK = 157,
    VK_FORMAT_ASTC_4x4_SRGB_BLOCK = 158,
    VK_FORMAT_ASTC_5x4_UNORM_BLOCK = 159,
    VK_FORMAT_ASTC_5x4_SRGB_BLOCK = 160,
    VK_FORMAT_ASTC_5x5_UNORM_BLOCK = 161,
    VK_FORMAT_ASTC_5x5_SRGB_BLOCK = 162,
    VK_FORMAT_ASTC_6x5_UNORM_BLOCK = 163,
    VK_FORMAT_ASTC_6x5_SRGB_BLOCK = 164,
    VK_FORMAT_ASTC_6x6_UNORM_BLOCK = 165,
    VK_FORMAT_ASTC_6x6_SRGB_BLOCK = 166,
    VK_FORMAT_ASTC_8x5_UNORM_BLOCK = 167,
    VK_FORMAT_ASTC_8x5_SRGB_BLOCK = 168,
    VK_FORMAT_ASTC_8x6_UNORM_BLOCK = 169,
    VK_FORMAT_ASTC_8x6_SRGB_BLOCK = 170,
    VK_FORMAT_ASTC_8x8_UNORM_BLOCK = 171,
    VK_FORMAT_ASTC_8x8_SRGB_BLOCK = 172,
    VK_FORMAT_ASTC_10x5_UNORM_BLOCK = 173,
    VK_FORMAT_ASTC_10x5_SRGB_BLOCK = 174,
    VK_FORMAT_ASTC_10x6_UNORM_BLOCK = 175,
    VK_FORMAT_ASTC_10x6_SRGB_BLOCK = 176,
    VK_FORMAT_ASTC_10x8_UNORM_BLOCK = 177,
    VK_FORMAT_ASTC_10x8_SRGB_BLOCK = 178,
    VK_FORMAT_ASTC_10x10_UNORM_BLOCK = 179,
    VK_FORMAT_ASTC_10x10_SRGB_BLOCK = 180,
    VK_FORMAT_ASTC_12x10_UNORM_BLOCK = 181,
    VK_FORMAT_ASTC_12x10_SRGB_BLOCK = 182,
    VK_FORMAT_ASTC_12x12_UNORM_BLOCK = 183,
    VK_FORMAT_ASTC_12x12_SRGB_BLOCK = 184,
    VK_FORMAT_G8B8G8R8_422_UNORM = 1000156000,
    VK_FORMAT_B8G8R8G8_422_UNORM = 1000156001,
    VK_FORMAT_G8_B8_R8_3PLANE_420_UNORM = 1000156002,
    VK_FORMAT_G8_B8R8_2PLANE_420_UNORM = 1000156003,
    VK_FORMAT_G8_B8_R8_3PLANE_422_UNORM = 1000156004,
    VK_FORMAT_G8_B8R8_2PLANE_422_UNORM = 1000156005,
    VK_FORMAT_G8_B8_R8_3PLANE_444_UNORM = 1000156006,
    VK_FORMAT_R10X6_UNORM_PACK16 = 1000156007,
    VK_FORMAT_R10X6G10X6_UNORM_2PACK16 = 1000156008,
    VK_FORMAT_R10X6G10X6B10X6A10X6_UNORM_4PACK16 = 1000156009,
    VK_FORMAT_G10X6B10X6G10X6R10X6_422_UNORM_4PACK16 = 1000156010,
    VK_FORMAT_B10X6G10X6R10X6G10X6_422_UNORM_4PACK16 = 1000156011,
    VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_420_UNORM_3PACK16 = 1000156012,
    VK_FORMAT_G10X6_B10X6R10X6_2PLANE_420_UNORM_3PACK16 = 1000156013,
    VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_422_UNORM_3PACK16 = 1000156014,
    VK_FORMAT_G10X6_B10X6R10X6_2PLANE_422_UNORM_3PACK16 = 1000156015,
    VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_444_UNORM_3PACK16 = 1000156016,
    VK_FORMAT_R12X4_UNORM_PACK16 = 1000156017,
    VK_FORMAT_R12X4G12X4_UNORM_2PACK16 = 1000156018,
    VK_FORMAT_R12X4G12X4B12X4A12X4_UNORM_4PACK16 = 1000156019,
    VK_FORMAT_G12X4B12X4G12X4R12X4_422_UNORM_4PACK16 = 1000156020,
    VK_FORMAT_B12X4G12X4R12X4G12X4_422_UNORM_4PACK16 = 1000156021,
    VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_420_UNORM_3PACK16 = 1000156022,
    VK_FORMAT_G12X4_B12X4R12X4_2PLANE_420_UNORM_3PACK16 = 1000156023,
    VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_422_UNORM_3PACK16 = 1000156024,
    VK_FORMAT_G12X4_B12X4R12X4_2PLANE_422_UNORM_3PACK16 = 1000156025,
    VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_444_UNORM_3PACK16 = 1000156026,
    VK_FORMAT_G16B16G16R16_422_UNORM = 1000156027,
    VK_FORMAT_B16G16R16G16_422_UNORM = 1000156028,
    VK_FORMAT_G16_B16_R16_3PLANE_420_UNORM = 1000156029,
    VK_FORMAT_G16_B16R16_2PLANE_420_UNORM = 1000156030,
    VK_FORMAT_G16_B16_R16_3PLANE_422_UNORM = 1000156031,
    VK_FORMAT_G16_B16R16_2PLANE_422_UNORM = 1000156032,
    VK_FORMAT_G16_B16_R16_3PLANE_444_UNORM = 1000156033,
    VK_FORMAT_G8_B8R8_2PLANE_444_UNORM = 1000330000,
    VK_FORMAT_G10X6_B10X6R10X6_2PLANE_444_UNORM_3PACK16 = 1000330001,
    VK_FORMAT_G12X4_B12X4R12X4_2PLANE_444_UNORM_3PACK16 = 1000330002,
    VK_FORMAT_G16_B16R16_2PLANE_444_UNORM = 1000330003,
    VK_FORMAT_A4R4G4B4_UNORM_PACK16 = 1000340000,
    VK_FORMAT_A4B4G4R4_UNORM_PACK16 = 1000340001,
    VK_FORMAT_ASTC_4x4_SFLOAT_BLOCK = 1000066000,
    VK_FORMAT_ASTC_5x4_SFLOAT_BLOCK = 1000066001,
    VK_FORMAT_ASTC_5x5_SFLOAT_BLOCK = 1000066002,
    VK_FORMAT_ASTC_6x5_SFLOAT_BLOCK = 1000066003,
    VK_FORMAT_ASTC_6x6_SFLOAT_BLOCK = 1000066004,
    VK_FORMAT_ASTC_8x5_SFLOAT_BLOCK = 1000066005,
    VK_FORMAT_ASTC_8x6_SFLOAT_BLOCK = 1000066006,
    VK_FORMAT_ASTC_8x8_SFLOAT_BLOCK = 1000066007,
    VK_FORMAT_ASTC_10x5_SFLOAT_BLOCK = 1000066008,
    VK_FORMAT_ASTC_10x6_SFLOAT_BLOCK = 1000066009,
    VK_FORMAT_ASTC_10x8_SFLOAT_BLOCK = 1000066010,
    VK_FORMAT_ASTC_10x10_SFLOAT_BLOCK = 1000066011,
    VK_FORMAT_ASTC_12x10_SFLOAT_BLOCK = 1000066012,
    VK_FORMAT_ASTC_12x12_SFLOAT_BLOCK = 1000066013,
    VK_FORMAT_A1B5G5R5_UNORM_PACK16 = 1000470000,
    VK_FORMAT_A8_UNORM = 1000470001,
    VK_FORMAT_PVRTC1_2BPP_UNORM_BLOCK_IMG = 1000054000,
    VK_FORMAT_PVRTC1_4BPP_UNORM_BLOCK_IMG = 1000054001,
    VK_FORMAT_PVRTC2_2BPP_UNORM_BLOCK_IMG = 1000054002,
    VK_FORMAT_PVRTC2_4BPP_UNORM_BLOCK_IMG = 1000054003,
    VK_FORMAT_PVRTC1_2BPP_SRGB_BLOCK_IMG = 1000054004,
    VK_FORMAT_PVRTC1_4BPP_SRGB_BLOCK_IMG = 1000054005,
    VK_FORMAT_PVRTC2_2BPP_SRGB_BLOCK_IMG = 1000054006,
    VK_FORMAT_PVRTC2_4BPP_SRGB_BLOCK_IMG = 1000054007,
    VK_FORMAT_R16G16_SFIXED5_NV = 1000464000,
    VK_FORMAT_ASTC_4x4_SFLOAT_BLOCK_EXT = VK_FORMAT_ASTC_4x4_SFLOAT_BLOCK,
    VK_FORMAT_ASTC_5x4_SFLOAT_BLOCK_EXT = VK_FORMAT_ASTC_5x4_SFLOAT_BLOCK,
    VK_FORMAT_ASTC_5x5_SFLOAT_BLOCK_EXT = VK_FORMAT_ASTC_5x5_SFLOAT_BLOCK,
    VK_FORMAT_ASTC_6x5_SFLOAT_BLOCK_EXT = VK_FORMAT_ASTC_6x5_SFLOAT_BLOCK,
    VK_FORMAT_ASTC_6x6_SFLOAT_BLOCK_EXT = VK_FORMAT_ASTC_6x6_SFLOAT_BLOCK,
    VK_FORMAT_ASTC_8x5_SFLOAT_BLOCK_EXT = VK_FORMAT_ASTC_8x5_SFLOAT_BLOCK,
    VK_FORMAT_ASTC_8x6_SFLOAT_BLOCK_EXT = VK_FORMAT_ASTC_8x6_SFLOAT_BLOCK,
    VK_FORMAT_ASTC_8x8_SFLOAT_BLOCK_EXT = VK_FORMAT_ASTC_8x8_SFLOAT_BLOCK,
    VK_FORMAT_ASTC_10x5_SFLOAT_BLOCK_EXT = VK_FORMAT_ASTC_10x5_SFLOAT_BLOCK,
    VK_FORMAT_ASTC_10x6_SFLOAT_BLOCK_EXT = VK_FORMAT_ASTC_10x6_SFLOAT_BLOCK,
    VK_FORMAT_ASTC_10x8_SFLOAT_BLOCK_EXT = VK_FORMAT_ASTC_10x8_SFLOAT_BLOCK,
    VK_FORMAT_ASTC_10x10_SFLOAT_BLOCK_EXT = VK_FORMAT_ASTC_10x10_SFLOAT_BLOCK,
    VK_FORMAT_ASTC_12x10_SFLOAT_BLOCK_EXT = VK_FORMAT_ASTC_12x10_SFLOAT_BLOCK,
    VK_FORMAT_ASTC_12x12_SFLOAT_BLOCK_EXT = VK_FORMAT_ASTC_12x12_SFLOAT_BLOCK,
    VK_FORMAT_G8B8G8R8_422_UNORM_KHR = VK_FORMAT_G8B8G8R8_422_UNORM,
    VK_FORMAT_B8G8R8G8_422_UNORM_KHR = VK_FORMAT_B8G8R8G8_422_UNORM,
    VK_FORMAT_G8_B8_R8_3PLANE_420_UNORM_KHR = VK_FORMAT_G8_B8_R8_3PLANE_420_UNORM,
    VK_FORMAT_G8_B8R8_2PLANE_420_UNORM_KHR = VK_FORMAT_G8_B8R8_2PLANE_420_UNORM,
    VK_FORMAT_G8_B8_R8_3PLANE_422_UNORM_KHR = VK_FORMAT_G8_B8_R8_3PLANE_422_UNORM,
    VK_FORMAT_G8_B8R8_2PLANE_422_UNORM_KHR = VK_FORMAT_G8_B8R8_2PLANE_422_UNORM,
    VK_FORMAT_G8_B8_R8_3PLANE_444_UNORM_KHR = VK_FORMAT_G8_B8_R8_3PLANE_444_UNORM,
    VK_FORMAT_R10X6_UNORM_PACK16_KHR = VK_FORMAT_R10X6_UNORM_PACK16,
    VK_FORMAT_R10X6G10X6_UNORM_2PACK16_KHR = VK_FORMAT_R10X6G10X6_UNORM_2PACK16,
    VK_FORMAT_R10X6G10X6B10X6A10X6_UNORM_4PACK16_KHR = VK_FORMAT_R10X6G10X6B10X6A10X6_UNORM_4PACK16,
    VK_FORMAT_G10X6B10X6G10X6R10X6_422_UNORM_4PACK16_KHR = VK_FORMAT_G10X6B10X6G10X6R10X6_422_UNORM_4PACK16,
    VK_FORMAT_B10X6G10X6R10X6G10X6_422_UNORM_4PACK16_KHR = VK_FORMAT_B10X6G10X6R10X6G10X6_422_UNORM_4PACK16,
    VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_420_UNORM_3PACK16_KHR = VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_420_UNORM_3PACK16,
    VK_FORMAT_G10X6_B10X6R10X6_2PLANE_420_UNORM_3PACK16_KHR = VK_FORMAT_G10X6_B10X6R10X6_2PLANE_420_UNORM_3PACK16,
    VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_422_UNORM_3PACK16_KHR = VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_422_UNORM_3PACK16,
    VK_FORMAT_G10X6_B10X6R10X6_2PLANE_422_UNORM_3PACK16_KHR = VK_FORMAT_G10X6_B10X6R10X6_2PLANE_422_UNORM_3PACK16,
    VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_444_UNORM_3PACK16_KHR = VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_444_UNORM_3PACK16,
    VK_FORMAT_R12X4_UNORM_PACK16_KHR = VK_FORMAT_R12X4_UNORM_PACK16,
    VK_FORMAT_R12X4G12X4_UNORM_2PACK16_KHR = VK_FORMAT_R12X4G12X4_UNORM_2PACK16,
    VK_FORMAT_R12X4G12X4B12X4A12X4_UNORM_4PACK16_KHR = VK_FORMAT_R12X4G12X4B12X4A12X4_UNORM_4PACK16,
    VK_FORMAT_G12X4B12X4G12X4R12X4_422_UNORM_4PACK16_KHR = VK_FORMAT_G12X4B12X4G12X4R12X4_422_UNORM_4PACK16,
    VK_FORMAT_B12X4G12X4R12X4G12X4_422_UNORM_4PACK16_KHR = VK_FORMAT_B12X4G12X4R12X4G12X4_422_UNORM_4PACK16,
    VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_420_UNORM_3PACK16_KHR = VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_420_UNORM_3PACK16,
    VK_FORMAT_G12X4_B12X4R12X4_2PLANE_420_UNORM_3PACK16_KHR = VK_FORMAT_G12X4_B12X4R12X4_2PLANE_420_UNORM_3PACK16,
    VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_422_UNORM_3PACK16_KHR = VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_422_UNORM_3PACK16,
    VK_FORMAT_G12X4_B12X4R12X4_2PLANE_422_UNORM_3PACK16_KHR = VK_FORMAT_G12X4_B12X4R12X4_2PLANE_422_UNORM_3PACK16,
    VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_444_UNORM_3PACK16_KHR = VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_444_UNORM_3PACK16,
    VK_FORMAT_G16B16G16R16_422_UNORM_KHR = VK_FORMAT_G16B16G16R16_422_UNORM,
    VK_FORMAT_B16G16R16G16_422_UNORM_KHR = VK_FORMAT_B16G16R16G16_422_UNORM,
    VK_FORMAT_G16_B16_R16_3PLANE_420_UNORM_KHR = VK_FORMAT_G16_B16_R16_3PLANE_420_UNORM,
    VK_FORMAT_G16_B16R16_2PLANE_420_UNORM_KHR = VK_FORMAT_G16_B16R16_2PLANE_420_UNORM,
    VK_FORMAT_G16_B16_R16_3PLANE_422_UNORM_KHR = VK_FORMAT_G16_B16_R16_3PLANE_422_UNORM,
    VK_FORMAT_G16_B16R16_2PLANE_422_UNORM_KHR = VK_FORMAT_G16_B16R16_2PLANE_422_UNORM,
    VK_FORMAT_G16_B16_R16_3PLANE_444_UNORM_KHR = VK_FORMAT_G16_B16_R16_3PLANE_444_UNORM,
    VK_FORMAT_G8_B8R8_2PLANE_444_UNORM_EXT = VK_FORMAT_G8_B8R8_2PLANE_444_UNORM,
    VK_FORMAT_G10X6_B10X6R10X6_2PLANE_444_UNORM_3PACK16_EXT = VK_FORMAT_G10X6_B10X6R10X6_2PLANE_444_UNORM_3PACK16,
    VK_FORMAT_G12X4_B12X4R12X4_2PLANE_444_UNORM_3PACK16_EXT = VK_FORMAT_G12X4_B12X4R12X4_2PLANE_444_UNORM_3PACK16,
    VK_FORMAT_G16_B16R16_2PLANE_444_UNORM_EXT = VK_FORMAT_G16_B16R16_2PLANE_444_UNORM,
    VK_FORMAT_A4R4G4B4_UNORM_PACK16_EXT = VK_FORMAT_A4R4G4B4_UNORM_PACK16,
    VK_FORMAT_A4B4G4R4_UNORM_PACK16_EXT = VK_FORMAT_A4B4G4R4_UNORM_PACK16,

    VK_FORMAT_R16G16_S10_5_NV = VK_FORMAT_R16G16_SFIXED5_NV,
    VK_FORMAT_A1B5G5R5_UNORM_PACK16_KHR = VK_FORMAT_A1B5G5R5_UNORM_PACK16,
    VK_FORMAT_A8_UNORM_KHR = VK_FORMAT_A8_UNORM,
    VK_FORMAT_MAX_ENUM = 0x7FFFFFFF
} VkFormat;

typedef enum VkImageTiling {
    VK_IMAGE_TILING_OPTIMAL = 0,
    VK_IMAGE_TILING_LINEAR = 1,
    VK_IMAGE_TILING_DRM_FORMAT_MODIFIER_EXT = 1000158000,
    VK_IMAGE_TILING_MAX_ENUM = 0x7FFFFFFF
} VkImageTiling;

typedef enum VkImageType {
    VK_IMAGE_TYPE_1D = 0,
    VK_IMAGE_TYPE_2D = 1,
    VK_IMAGE_TYPE_3D = 2,
    VK_IMAGE_TYPE_MAX_ENUM = 0x7FFFFFFF
} VkImageType;

typedef enum VkPhysicalDeviceType {
    VK_PHYSICAL_DEVICE_TYPE_OTHER = 0,
    VK_PHYSICAL_DEVICE_TYPE_INTEGRATED_GPU = 1,
    VK_PHYSICAL_DEVICE_TYPE_DISCRETE_GPU = 2,
    VK_PHYSICAL_DEVICE_TYPE_VIRTUAL_GPU = 3,
    VK_PHYSICAL_DEVICE_TYPE_CPU = 4,
    VK_PHYSICAL_DEVICE_TYPE_MAX_ENUM = 0x7FFFFFFF
} VkPhysicalDeviceType;

typedef enum VkQueryType {
    VK_QUERY_TYPE_OCCLUSION = 0,
    VK_QUERY_TYPE_PIPELINE_STATISTICS = 1,
    VK_QUERY_TYPE_TIMESTAMP = 2,
    VK_QUERY_TYPE_RESULT_STATUS_ONLY_KHR = 1000023000,
    VK_QUERY_TYPE_TRANSFORM_FEEDBACK_STREAM_EXT = 1000028004,
    VK_QUERY_TYPE_PERFORMANCE_QUERY_KHR = 1000116000,
    VK_QUERY_TYPE_ACCELERATION_STRUCTURE_COMPACTED_SIZE_KHR = 1000150000,
    VK_QUERY_TYPE_ACCELERATION_STRUCTURE_SERIALIZATION_SIZE_KHR = 1000150001,
    VK_QUERY_TYPE_ACCELERATION_STRUCTURE_COMPACTED_SIZE_NV = 1000165000,
    VK_QUERY_TYPE_PERFORMANCE_QUERY_INTEL = 1000210000,
    VK_QUERY_TYPE_VIDEO_ENCODE_FEEDBACK_KHR = 1000299000,
    VK_QUERY_TYPE_MESH_PRIMITIVES_GENERATED_EXT = 1000328000,
    VK_QUERY_TYPE_PRIMITIVES_GENERATED_EXT = 1000382000,
    VK_QUERY_TYPE_ACCELERATION_STRUCTURE_SERIALIZATION_BOTTOM_LEVEL_POINTERS_KHR = 1000386000,
    VK_QUERY_TYPE_ACCELERATION_STRUCTURE_SIZE_KHR = 1000386001,
    VK_QUERY_TYPE_MICROMAP_SERIALIZATION_SIZE_EXT = 1000396000,
    VK_QUERY_TYPE_MICROMAP_COMPACTED_SIZE_EXT = 1000396001,
    VK_QUERY_TYPE_MAX_ENUM = 0x7FFFFFFF
} VkQueryType;

typedef enum VkSharingMode {
    VK_SHARING_MODE_EXCLUSIVE = 0,
    VK_SHARING_MODE_CONCURRENT = 1,
    VK_SHARING_MODE_MAX_ENUM = 0x7FFFFFFF
} VkSharingMode;

typedef enum VkComponentSwizzle {
    VK_COMPONENT_SWIZZLE_IDENTITY = 0,
    VK_COMPONENT_SWIZZLE_ZERO = 1,
    VK_COMPONENT_SWIZZLE_ONE = 2,
    VK_COMPONENT_SWIZZLE_R = 3,
    VK_COMPONENT_SWIZZLE_G = 4,
    VK_COMPONENT_SWIZZLE_B = 5,
    VK_COMPONENT_SWIZZLE_A = 6,
    VK_COMPONENT_SWIZZLE_MAX_ENUM = 0x7FFFFFFF
} VkComponentSwizzle;

typedef enum VkImageViewType {
    VK_IMAGE_VIEW_TYPE_1D = 0,
    VK_IMAGE_VIEW_TYPE_2D = 1,
    VK_IMAGE_VIEW_TYPE_3D = 2,
    VK_IMAGE_VIEW_TYPE_CUBE = 3,
    VK_IMAGE_VIEW_TYPE_1D_ARRAY = 4,
    VK_IMAGE_VIEW_TYPE_2D_ARRAY = 5,
    VK_IMAGE_VIEW_TYPE_CUBE_ARRAY = 6,
    VK_IMAGE_VIEW_TYPE_MAX_ENUM = 0x7FFFFFFF
} VkImageViewType;

typedef enum VkBlendFactor {
    VK_BLEND_FACTOR_ZERO = 0,
    VK_BLEND_FACTOR_ONE = 1,
    VK_BLEND_FACTOR_SRC_COLOR = 2,
    VK_BLEND_FACTOR_ONE_MINUS_SRC_COLOR = 3,
    VK_BLEND_FACTOR_DST_COLOR = 4,
    VK_BLEND_FACTOR_ONE_MINUS_DST_COLOR = 5,
    VK_BLEND_FACTOR_SRC_ALPHA = 6,
    VK_BLEND_FACTOR_ONE_MINUS_SRC_ALPHA = 7,
    VK_BLEND_FACTOR_DST_ALPHA = 8,
    VK_BLEND_FACTOR_ONE_MINUS_DST_ALPHA = 9,
    VK_BLEND_FACTOR_CONSTANT_COLOR = 10,
    VK_BLEND_FACTOR_ONE_MINUS_CONSTANT_COLOR = 11,
    VK_BLEND_FACTOR_CONSTANT_ALPHA = 12,
    VK_BLEND_FACTOR_ONE_MINUS_CONSTANT_ALPHA = 13,
    VK_BLEND_FACTOR_SRC_ALPHA_SATURATE = 14,
    VK_BLEND_FACTOR_SRC1_COLOR = 15,
    VK_BLEND_FACTOR_ONE_MINUS_SRC1_COLOR = 16,
    VK_BLEND_FACTOR_SRC1_ALPHA = 17,
    VK_BLEND_FACTOR_ONE_MINUS_SRC1_ALPHA = 18,
    VK_BLEND_FACTOR_MAX_ENUM = 0x7FFFFFFF
} VkBlendFactor;

typedef enum VkBlendOp {
    VK_BLEND_OP_ADD = 0,
    VK_BLEND_OP_SUBTRACT = 1,
    VK_BLEND_OP_REVERSE_SUBTRACT = 2,
    VK_BLEND_OP_MIN = 3,
    VK_BLEND_OP_MAX = 4,
    VK_BLEND_OP_ZERO_EXT = 1000148000,
    VK_BLEND_OP_SRC_EXT = 1000148001,
    VK_BLEND_OP_DST_EXT = 1000148002,
    VK_BLEND_OP_SRC_OVER_EXT = 1000148003,
    VK_BLEND_OP_DST_OVER_EXT = 1000148004,
    VK_BLEND_OP_SRC_IN_EXT = 1000148005,
    VK_BLEND_OP_DST_IN_EXT = 1000148006,
    VK_BLEND_OP_SRC_OUT_EXT = 1000148007,
    VK_BLEND_OP_DST_OUT_EXT = 1000148008,
    VK_BLEND_OP_SRC_ATOP_EXT = 1000148009,
    VK_BLEND_OP_DST_ATOP_EXT = 1000148010,
    VK_BLEND_OP_XOR_EXT = 1000148011,
    VK_BLEND_OP_MULTIPLY_EXT = 1000148012,
    VK_BLEND_OP_SCREEN_EXT = 1000148013,
    VK_BLEND_OP_OVERLAY_EXT = 1000148014,
    VK_BLEND_OP_DARKEN_EXT = 1000148015,
    VK_BLEND_OP_LIGHTEN_EXT = 1000148016,
    VK_BLEND_OP_COLORDODGE_EXT = 1000148017,
    VK_BLEND_OP_COLORBURN_EXT = 1000148018,
    VK_BLEND_OP_HARDLIGHT_EXT = 1000148019,
    VK_BLEND_OP_SOFTLIGHT_EXT = 1000148020,
    VK_BLEND_OP_DIFFERENCE_EXT = 1000148021,
    VK_BLEND_OP_EXCLUSION_EXT = 1000148022,
    VK_BLEND_OP_INVERT_EXT = 1000148023,
    VK_BLEND_OP_INVERT_RGB_EXT = 1000148024,
    VK_BLEND_OP_LINEARDODGE_EXT = 1000148025,
    VK_BLEND_OP_LINEARBURN_EXT = 1000148026,
    VK_BLEND_OP_VIVIDLIGHT_EXT = 1000148027,
    VK_BLEND_OP_LINEARLIGHT_EXT = 1000148028,
    VK_BLEND_OP_PINLIGHT_EXT = 1000148029,
    VK_BLEND_OP_HARDMIX_EXT = 1000148030,
    VK_BLEND_OP_HSL_HUE_EXT = 1000148031,
    VK_BLEND_OP_HSL_SATURATION_EXT = 1000148032,
    VK_BLEND_OP_HSL_COLOR_EXT = 1000148033,
    VK_BLEND_OP_HSL_LUMINOSITY_EXT = 1000148034,
    VK_BLEND_OP_PLUS_EXT = 1000148035,
    VK_BLEND_OP_PLUS_CLAMPED_EXT = 1000148036,
    VK_BLEND_OP_PLUS_CLAMPED_ALPHA_EXT = 1000148037,
    VK_BLEND_OP_PLUS_DARKER_EXT = 1000148038,
    VK_BLEND_OP_MINUS_EXT = 1000148039,
    VK_BLEND_OP_MINUS_CLAMPED_EXT = 1000148040,
    VK_BLEND_OP_CONTRAST_EXT = 1000148041,
    VK_BLEND_OP_INVERT_OVG_EXT = 1000148042,
    VK_BLEND_OP_RED_EXT = 1000148043,
    VK_BLEND_OP_GREEN_EXT = 1000148044,
    VK_BLEND_OP_BLUE_EXT = 1000148045,
    VK_BLEND_OP_MAX_ENUM = 0x7FFFFFFF
} VkBlendOp;

typedef enum VkCompareOp {
    VK_COMPARE_OP_NEVER = 0,
    VK_COMPARE_OP_LESS = 1,
    VK_COMPARE_OP_EQUAL = 2,
    VK_COMPARE_OP_LESS_OR_EQUAL = 3,
    VK_COMPARE_OP_GREATER = 4,
    VK_COMPARE_OP_NOT_EQUAL = 5,
    VK_COMPARE_OP_GREATER_OR_EQUAL = 6,
    VK_COMPARE_OP_ALWAYS = 7,
    VK_COMPARE_OP_MAX_ENUM = 0x7FFFFFFF
} VkCompareOp;

typedef enum VkDynamicState {
    VK_DYNAMIC_STATE_VIEWPORT = 0,
    VK_DYNAMIC_STATE_SCISSOR = 1,
    VK_DYNAMIC_STATE_LINE_WIDTH = 2,
    VK_DYNAMIC_STATE_DEPTH_BIAS = 3,
    VK_DYNAMIC_STATE_BLEND_CONSTANTS = 4,
    VK_DYNAMIC_STATE_DEPTH_BOUNDS = 5,
    VK_DYNAMIC_STATE_STENCIL_COMPARE_MASK = 6,
    VK_DYNAMIC_STATE_STENCIL_WRITE_MASK = 7,
    VK_DYNAMIC_STATE_STENCIL_REFERENCE = 8,
    VK_DYNAMIC_STATE_CULL_MODE = 1000267000,
    VK_DYNAMIC_STATE_FRONT_FACE = 1000267001,
    VK_DYNAMIC_STATE_PRIMITIVE_TOPOLOGY = 1000267002,
    VK_DYNAMIC_STATE_VIEWPORT_WITH_COUNT = 1000267003,
    VK_DYNAMIC_STATE_SCISSOR_WITH_COUNT = 1000267004,
    VK_DYNAMIC_STATE_VERTEX_INPUT_BINDING_STRIDE = 1000267005,
    VK_DYNAMIC_STATE_DEPTH_TEST_ENABLE = 1000267006,
    VK_DYNAMIC_STATE_DEPTH_WRITE_ENABLE = 1000267007,
    VK_DYNAMIC_STATE_DEPTH_COMPARE_OP = 1000267008,
    VK_DYNAMIC_STATE_DEPTH_BOUNDS_TEST_ENABLE = 1000267009,
    VK_DYNAMIC_STATE_STENCIL_TEST_ENABLE = 1000267010,
    VK_DYNAMIC_STATE_STENCIL_OP = 1000267011,
    VK_DYNAMIC_STATE_RASTERIZER_DISCARD_ENABLE = 1000377001,
    VK_DYNAMIC_STATE_DEPTH_BIAS_ENABLE = 1000377002,
    VK_DYNAMIC_STATE_PRIMITIVE_RESTART_ENABLE = 1000377004,
    VK_DYNAMIC_STATE_LINE_STIPPLE = 1000259000,
    VK_DYNAMIC_STATE_VIEWPORT_W_SCALING_NV = 1000087000,
    VK_DYNAMIC_STATE_DISCARD_RECTANGLE_EXT = 1000099000,
    VK_DYNAMIC_STATE_DISCARD_RECTANGLE_ENABLE_EXT = 1000099001,
    VK_DYNAMIC_STATE_DISCARD_RECTANGLE_MODE_EXT = 1000099002,
    VK_DYNAMIC_STATE_SAMPLE_LOCATIONS_EXT = 1000143000,
    VK_DYNAMIC_STATE_RAY_TRACING_PIPELINE_STACK_SIZE_KHR = 1000347000,
    VK_DYNAMIC_STATE_VIEWPORT_SHADING_RATE_PALETTE_NV = 1000164004,
    VK_DYNAMIC_STATE_VIEWPORT_COARSE_SAMPLE_ORDER_NV = 1000164006,
    VK_DYNAMIC_STATE_EXCLUSIVE_SCISSOR_ENABLE_NV = 1000205000,
    VK_DYNAMIC_STATE_EXCLUSIVE_SCISSOR_NV = 1000205001,
    VK_DYNAMIC_STATE_FRAGMENT_SHADING_RATE_KHR = 1000226000,
    VK_DYNAMIC_STATE_VERTEX_INPUT_EXT = 1000352000,
    VK_DYNAMIC_STATE_PATCH_CONTROL_POINTS_EXT = 1000377000,
    VK_DYNAMIC_STATE_LOGIC_OP_EXT = 1000377003,
    VK_DYNAMIC_STATE_COLOR_WRITE_ENABLE_EXT = 1000381000,
    VK_DYNAMIC_STATE_DEPTH_CLAMP_ENABLE_EXT = 1000455003,
    VK_DYNAMIC_STATE_POLYGON_MODE_EXT = 1000455004,
    VK_DYNAMIC_STATE_RASTERIZATION_SAMPLES_EXT = 1000455005,
    VK_DYNAMIC_STATE_SAMPLE_MASK_EXT = 1000455006,
    VK_DYNAMIC_STATE_ALPHA_TO_COVERAGE_ENABLE_EXT = 1000455007,
    VK_DYNAMIC_STATE_ALPHA_TO_ONE_ENABLE_EXT = 1000455008,
    VK_DYNAMIC_STATE_LOGIC_OP_ENABLE_EXT = 1000455009,
    VK_DYNAMIC_STATE_COLOR_BLEND_ENABLE_EXT = 1000455010,
    VK_DYNAMIC_STATE_COLOR_BLEND_EQUATION_EXT = 1000455011,
    VK_DYNAMIC_STATE_COLOR_WRITE_MASK_EXT = 1000455012,
    VK_DYNAMIC_STATE_TESSELLATION_DOMAIN_ORIGIN_EXT = 1000455002,
    VK_DYNAMIC_STATE_RASTERIZATION_STREAM_EXT = 1000455013,
    VK_DYNAMIC_STATE_CONSERVATIVE_RASTERIZATION_MODE_EXT = 1000455014,
    VK_DYNAMIC_STATE_EXTRA_PRIMITIVE_OVERESTIMATION_SIZE_EXT = 1000455015,
    VK_DYNAMIC_STATE_DEPTH_CLIP_ENABLE_EXT = 1000455016,
    VK_DYNAMIC_STATE_SAMPLE_LOCATIONS_ENABLE_EXT = 1000455017,
    VK_DYNAMIC_STATE_COLOR_BLEND_ADVANCED_EXT = 1000455018,
    VK_DYNAMIC_STATE_PROVOKING_VERTEX_MODE_EXT = 1000455019,
    VK_DYNAMIC_STATE_LINE_RASTERIZATION_MODE_EXT = 1000455020,
    VK_DYNAMIC_STATE_LINE_STIPPLE_ENABLE_EXT = 1000455021,
    VK_DYNAMIC_STATE_DEPTH_CLIP_NEGATIVE_ONE_TO_ONE_EXT = 1000455022,
    VK_DYNAMIC_STATE_VIEWPORT_W_SCALING_ENABLE_NV = 1000455023,
    VK_DYNAMIC_STATE_VIEWPORT_SWIZZLE_NV = 1000455024,
    VK_DYNAMIC_STATE_COVERAGE_TO_COLOR_ENABLE_NV = 1000455025,
    VK_DYNAMIC_STATE_COVERAGE_TO_COLOR_LOCATION_NV = 1000455026,
    VK_DYNAMIC_STATE_COVERAGE_MODULATION_MODE_NV = 1000455027,
    VK_DYNAMIC_STATE_COVERAGE_MODULATION_TABLE_ENABLE_NV = 1000455028,
    VK_DYNAMIC_STATE_COVERAGE_MODULATION_TABLE_NV = 1000455029,
    VK_DYNAMIC_STATE_SHADING_RATE_IMAGE_ENABLE_NV = 1000455030,
    VK_DYNAMIC_STATE_REPRESENTATIVE_FRAGMENT_TEST_ENABLE_NV = 1000455031,
    VK_DYNAMIC_STATE_COVERAGE_REDUCTION_MODE_NV = 1000455032,
    VK_DYNAMIC_STATE_ATTACHMENT_FEEDBACK_LOOP_ENABLE_EXT = 1000524000,
    VK_DYNAMIC_STATE_DEPTH_CLAMP_RANGE_EXT = 1000582000,
    VK_DYNAMIC_STATE_LINE_STIPPLE_EXT = VK_DYNAMIC_STATE_LINE_STIPPLE,
    VK_DYNAMIC_STATE_CULL_MODE_EXT = VK_DYNAMIC_STATE_CULL_MODE,
    VK_DYNAMIC_STATE_FRONT_FACE_EXT = VK_DYNAMIC_STATE_FRONT_FACE,
    VK_DYNAMIC_STATE_PRIMITIVE_TOPOLOGY_EXT = VK_DYNAMIC_STATE_PRIMITIVE_TOPOLOGY,
    VK_DYNAMIC_STATE_VIEWPORT_WITH_COUNT_EXT = VK_DYNAMIC_STATE_VIEWPORT_WITH_COUNT,
    VK_DYNAMIC_STATE_SCISSOR_WITH_COUNT_EXT = VK_DYNAMIC_STATE_SCISSOR_WITH_COUNT,
    VK_DYNAMIC_STATE_VERTEX_INPUT_BINDING_STRIDE_EXT = VK_DYNAMIC_STATE_VERTEX_INPUT_BINDING_STRIDE,
    VK_DYNAMIC_STATE_DEPTH_TEST_ENABLE_EXT = VK_DYNAMIC_STATE_DEPTH_TEST_ENABLE,
    VK_DYNAMIC_STATE_DEPTH_WRITE_ENABLE_EXT = VK_DYNAMIC_STATE_DEPTH_WRITE_ENABLE,
    VK_DYNAMIC_STATE_DEPTH_COMPARE_OP_EXT = VK_DYNAMIC_STATE_DEPTH_COMPARE_OP,
    VK_DYNAMIC_STATE_DEPTH_BOUNDS_TEST_ENABLE_EXT = VK_DYNAMIC_STATE_DEPTH_BOUNDS_TEST_ENABLE,
    VK_DYNAMIC_STATE_STENCIL_TEST_ENABLE_EXT = VK_DYNAMIC_STATE_STENCIL_TEST_ENABLE,
    VK_DYNAMIC_STATE_STENCIL_OP_EXT = VK_DYNAMIC_STATE_STENCIL_OP,
    VK_DYNAMIC_STATE_RASTERIZER_DISCARD_ENABLE_EXT = VK_DYNAMIC_STATE_RASTERIZER_DISCARD_ENABLE,
    VK_DYNAMIC_STATE_DEPTH_BIAS_ENABLE_EXT = VK_DYNAMIC_STATE_DEPTH_BIAS_ENABLE,
    VK_DYNAMIC_STATE_PRIMITIVE_RESTART_ENABLE_EXT = VK_DYNAMIC_STATE_PRIMITIVE_RESTART_ENABLE,
    VK_DYNAMIC_STATE_LINE_STIPPLE_KHR = VK_DYNAMIC_STATE_LINE_STIPPLE,
    VK_DYNAMIC_STATE_MAX_ENUM = 0x7FFFFFFF
} VkDynamicState;

typedef enum VkFrontFace {
    VK_FRONT_FACE_COUNTER_CLOCKWISE = 0,
    VK_FRONT_FACE_CLOCKWISE = 1,
    VK_FRONT_FACE_MAX_ENUM = 0x7FFFFFFF
} VkFrontFace;

typedef enum VkVertexInputRate {
    VK_VERTEX_INPUT_RATE_VERTEX = 0,
    VK_VERTEX_INPUT_RATE_INSTANCE = 1,
    VK_VERTEX_INPUT_RATE_MAX_ENUM = 0x7FFFFFFF
} VkVertexInputRate;

typedef enum VkPrimitiveTopology {
    VK_PRIMITIVE_TOPOLOGY_POINT_LIST = 0,
    VK_PRIMITIVE_TOPOLOGY_LINE_LIST = 1,
    VK_PRIMITIVE_TOPOLOGY_LINE_STRIP = 2,
    VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST = 3,
    VK_PRIMITIVE_TOPOLOGY_TRIANGLE_STRIP = 4,
    VK_PRIMITIVE_TOPOLOGY_TRIANGLE_FAN = 5,
    VK_PRIMITIVE_TOPOLOGY_LINE_LIST_WITH_ADJACENCY = 6,
    VK_PRIMITIVE_TOPOLOGY_LINE_STRIP_WITH_ADJACENCY = 7,
    VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST_WITH_ADJACENCY = 8,
    VK_PRIMITIVE_TOPOLOGY_TRIANGLE_STRIP_WITH_ADJACENCY = 9,
    VK_PRIMITIVE_TOPOLOGY_PATCH_LIST = 10,
    VK_PRIMITIVE_TOPOLOGY_MAX_ENUM = 0x7FFFFFFF
} VkPrimitiveTopology;

typedef enum VkPolygonMode {
    VK_POLYGON_MODE_FILL = 0,
    VK_POLYGON_MODE_LINE = 1,
    VK_POLYGON_MODE_POINT = 2,
    VK_POLYGON_MODE_FILL_RECTANGLE_NV = 1000153000,
    VK_POLYGON_MODE_MAX_ENUM = 0x7FFFFFFF
} VkPolygonMode;

typedef enum VkStencilOp {
    VK_STENCIL_OP_KEEP = 0,
    VK_STENCIL_OP_ZERO = 1,
    VK_STENCIL_OP_REPLACE = 2,
    VK_STENCIL_OP_INCREMENT_AND_CLAMP = 3,
    VK_STENCIL_OP_DECREMENT_AND_CLAMP = 4,
    VK_STENCIL_OP_INVERT = 5,
    VK_STENCIL_OP_INCREMENT_AND_WRAP = 6,
    VK_STENCIL_OP_DECREMENT_AND_WRAP = 7,
    VK_STENCIL_OP_MAX_ENUM = 0x7FFFFFFF
} VkStencilOp;

typedef enum VkLogicOp {
    VK_LOGIC_OP_CLEAR = 0,
    VK_LOGIC_OP_AND = 1,
    VK_LOGIC_OP_AND_REVERSE = 2,
    VK_LOGIC_OP_COPY = 3,
    VK_LOGIC_OP_AND_INVERTED = 4,
    VK_LOGIC_OP_NO_OP = 5,
    VK_LOGIC_OP_XOR = 6,
    VK_LOGIC_OP_OR = 7,
    VK_LOGIC_OP_NOR = 8,
    VK_LOGIC_OP_EQUIVALENT = 9,
    VK_LOGIC_OP_INVERT = 10,
    VK_LOGIC_OP_OR_REVERSE = 11,
    VK_LOGIC_OP_COPY_INVERTED = 12,
    VK_LOGIC_OP_OR_INVERTED = 13,
    VK_LOGIC_OP_NAND = 14,
    VK_LOGIC_OP_SET = 15,
    VK_LOGIC_OP_MAX_ENUM = 0x7FFFFFFF
} VkLogicOp;

typedef enum VkBorderColor {
    VK_BORDER_COLOR_FLOAT_TRANSPARENT_BLACK = 0,
    VK_BORDER_COLOR_INT_TRANSPARENT_BLACK = 1,
    VK_BORDER_COLOR_FLOAT_OPAQUE_BLACK = 2,
    VK_BORDER_COLOR_INT_OPAQUE_BLACK = 3,
    VK_BORDER_COLOR_FLOAT_OPAQUE_WHITE = 4,
    VK_BORDER_COLOR_INT_OPAQUE_WHITE = 5,
    VK_BORDER_COLOR_FLOAT_CUSTOM_EXT = 1000287003,
    VK_BORDER_COLOR_INT_CUSTOM_EXT = 1000287004,
    VK_BORDER_COLOR_MAX_ENUM = 0x7FFFFFFF
} VkBorderColor;

typedef enum VkFilter {
    VK_FILTER_NEAREST = 0,
    VK_FILTER_LINEAR = 1,
    VK_FILTER_CUBIC_EXT = 1000015000,
    VK_FILTER_CUBIC_IMG = VK_FILTER_CUBIC_EXT,
    VK_FILTER_MAX_ENUM = 0x7FFFFFFF
} VkFilter;

typedef enum VkSamplerAddressMode {
    VK_SAMPLER_ADDRESS_MODE_REPEAT = 0,
    VK_SAMPLER_ADDRESS_MODE_MIRRORED_REPEAT = 1,
    VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE = 2,
    VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_BORDER = 3,
    VK_SAMPLER_ADDRESS_MODE_MIRROR_CLAMP_TO_EDGE = 4,

    VK_SAMPLER_ADDRESS_MODE_MIRROR_CLAMP_TO_EDGE_KHR = VK_SAMPLER_ADDRESS_MODE_MIRROR_CLAMP_TO_EDGE,
    VK_SAMPLER_ADDRESS_MODE_MAX_ENUM = 0x7FFFFFFF
} VkSamplerAddressMode;

typedef enum VkSamplerMipmapMode {
    VK_SAMPLER_MIPMAP_MODE_NEAREST = 0,
    VK_SAMPLER_MIPMAP_MODE_LINEAR = 1,
    VK_SAMPLER_MIPMAP_MODE_MAX_ENUM = 0x7FFFFFFF
} VkSamplerMipmapMode;

typedef enum VkDescriptorType {
    VK_DESCRIPTOR_TYPE_SAMPLER = 0,
    VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER = 1,
    VK_DESCRIPTOR_TYPE_SAMPLED_IMAGE = 2,
    VK_DESCRIPTOR_TYPE_STORAGE_IMAGE = 3,
    VK_DESCRIPTOR_TYPE_UNIFORM_TEXEL_BUFFER = 4,
    VK_DESCRIPTOR_TYPE_STORAGE_TEXEL_BUFFER = 5,
    VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER = 6,
    VK_DESCRIPTOR_TYPE_STORAGE_BUFFER = 7,
    VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER_DYNAMIC = 8,
    VK_DESCRIPTOR_TYPE_STORAGE_BUFFER_DYNAMIC = 9,
    VK_DESCRIPTOR_TYPE_INPUT_ATTACHMENT = 10,
    VK_DESCRIPTOR_TYPE_INLINE_UNIFORM_BLOCK = 1000138000,
    VK_DESCRIPTOR_TYPE_ACCELERATION_STRUCTURE_KHR = 1000150000,
    VK_DESCRIPTOR_TYPE_ACCELERATION_STRUCTURE_NV = 1000165000,
    VK_DESCRIPTOR_TYPE_SAMPLE_WEIGHT_IMAGE_QCOM = 1000440000,
    VK_DESCRIPTOR_TYPE_BLOCK_MATCH_IMAGE_QCOM = 1000440001,
    VK_DESCRIPTOR_TYPE_MUTABLE_EXT = 1000351000,
    VK_DESCRIPTOR_TYPE_INLINE_UNIFORM_BLOCK_EXT = VK_DESCRIPTOR_TYPE_INLINE_UNIFORM_BLOCK,
    VK_DESCRIPTOR_TYPE_MUTABLE_VALVE = VK_DESCRIPTOR_TYPE_MUTABLE_EXT,
    VK_DESCRIPTOR_TYPE_MAX_ENUM = 0x7FFFFFFF
} VkDescriptorType;

typedef enum VkAttachmentLoadOp {
    VK_ATTACHMENT_LOAD_OP_LOAD = 0,
    VK_ATTACHMENT_LOAD_OP_CLEAR = 1,
    VK_ATTACHMENT_LOAD_OP_DONT_CARE = 2,
    VK_ATTACHMENT_LOAD_OP_NONE = 1000400000,
    VK_ATTACHMENT_LOAD_OP_NONE_EXT = VK_ATTACHMENT_LOAD_OP_NONE,
    VK_ATTACHMENT_LOAD_OP_NONE_KHR = VK_ATTACHMENT_LOAD_OP_NONE,
    VK_ATTACHMENT_LOAD_OP_MAX_ENUM = 0x7FFFFFFF
} VkAttachmentLoadOp;

typedef enum VkAttachmentStoreOp {
    VK_ATTACHMENT_STORE_OP_STORE = 0,
    VK_ATTACHMENT_STORE_OP_DONT_CARE = 1,
    VK_ATTACHMENT_STORE_OP_NONE = 1000301000,
    VK_ATTACHMENT_STORE_OP_NONE_KHR = VK_ATTACHMENT_STORE_OP_NONE,
    VK_ATTACHMENT_STORE_OP_NONE_QCOM = VK_ATTACHMENT_STORE_OP_NONE,
    VK_ATTACHMENT_STORE_OP_NONE_EXT = VK_ATTACHMENT_STORE_OP_NONE,
    VK_ATTACHMENT_STORE_OP_MAX_ENUM = 0x7FFFFFFF
} VkAttachmentStoreOp;

typedef enum VkPipelineBindPoint {
    VK_PIPELINE_BIND_POINT_GRAPHICS = 0,
    VK_PIPELINE_BIND_POINT_COMPUTE = 1,



    VK_PIPELINE_BIND_POINT_RAY_TRACING_KHR = 1000165000,
    VK_PIPELINE_BIND_POINT_SUBPASS_SHADING_HUAWEI = 1000369003,
    VK_PIPELINE_BIND_POINT_RAY_TRACING_NV = VK_PIPELINE_BIND_POINT_RAY_TRACING_KHR,
    VK_PIPELINE_BIND_POINT_MAX_ENUM = 0x7FFFFFFF
} VkPipelineBindPoint;

typedef enum VkCommandBufferLevel {
    VK_COMMAND_BUFFER_LEVEL_PRIMARY = 0,
    VK_COMMAND_BUFFER_LEVEL_SECONDARY = 1,
    VK_COMMAND_BUFFER_LEVEL_MAX_ENUM = 0x7FFFFFFF
} VkCommandBufferLevel;

typedef enum VkIndexType {
    VK_INDEX_TYPE_UINT16 = 0,
    VK_INDEX_TYPE_UINT32 = 1,
    VK_INDEX_TYPE_UINT8 = 1000265000,
    VK_INDEX_TYPE_NONE_KHR = 1000165000,
    VK_INDEX_TYPE_NONE_NV = VK_INDEX_TYPE_NONE_KHR,
    VK_INDEX_TYPE_UINT8_EXT = VK_INDEX_TYPE_UINT8,
    VK_INDEX_TYPE_UINT8_KHR = VK_INDEX_TYPE_UINT8,
    VK_INDEX_TYPE_MAX_ENUM = 0x7FFFFFFF
} VkIndexType;

typedef enum VkSubpassContents {
    VK_SUBPASS_CONTENTS_INLINE = 0,
    VK_SUBPASS_CONTENTS_SECONDARY_COMMAND_BUFFERS = 1,
    VK_SUBPASS_CONTENTS_INLINE_AND_SECONDARY_COMMAND_BUFFERS_KHR = 1000451000,
    VK_SUBPASS_CONTENTS_INLINE_AND_SECONDARY_COMMAND_BUFFERS_EXT = VK_SUBPASS_CONTENTS_INLINE_AND_SECONDARY_COMMAND_BUFFERS_KHR,
    VK_SUBPASS_CONTENTS_MAX_ENUM = 0x7FFFFFFF
} VkSubpassContents;

typedef enum VkAccessFlagBits {
    VK_ACCESS_INDIRECT_COMMAND_READ_BIT = 0x00000001,
    VK_ACCESS_INDEX_READ_BIT = 0x00000002,
    VK_ACCESS_VERTEX_ATTRIBUTE_READ_BIT = 0x00000004,
    VK_ACCESS_UNIFORM_READ_BIT = 0x00000008,
    VK_ACCESS_INPUT_ATTACHMENT_READ_BIT = 0x00000010,
    VK_ACCESS_SHADER_READ_BIT = 0x00000020,
    VK_ACCESS_SHADER_WRITE_BIT = 0x00000040,
    VK_ACCESS_COLOR_ATTACHMENT_READ_BIT = 0x00000080,
    VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT = 0x00000100,
    VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_READ_BIT = 0x00000200,
    VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT = 0x00000400,
    VK_ACCESS_TRANSFER_READ_BIT = 0x00000800,
    VK_ACCESS_TRANSFER_WRITE_BIT = 0x00001000,
    VK_ACCESS_HOST_READ_BIT = 0x00002000,
    VK_ACCESS_HOST_WRITE_BIT = 0x00004000,
    VK_ACCESS_MEMORY_READ_BIT = 0x00008000,
    VK_ACCESS_MEMORY_WRITE_BIT = 0x00010000,
    VK_ACCESS_NONE = 0,
    VK_ACCESS_TRANSFORM_FEEDBACK_WRITE_BIT_EXT = 0x02000000,
    VK_ACCESS_TRANSFORM_FEEDBACK_COUNTER_READ_BIT_EXT = 0x04000000,
    VK_ACCESS_TRANSFORM_FEEDBACK_COUNTER_WRITE_BIT_EXT = 0x08000000,
    VK_ACCESS_CONDITIONAL_RENDERING_READ_BIT_EXT = 0x00100000,
    VK_ACCESS_COLOR_ATTACHMENT_READ_NONCOHERENT_BIT_EXT = 0x00080000,
    VK_ACCESS_ACCELERATION_STRUCTURE_READ_BIT_KHR = 0x00200000,
    VK_ACCESS_ACCELERATION_STRUCTURE_WRITE_BIT_KHR = 0x00400000,
    VK_ACCESS_FRAGMENT_DENSITY_MAP_READ_BIT_EXT = 0x01000000,
    VK_ACCESS_FRAGMENT_SHADING_RATE_ATTACHMENT_READ_BIT_KHR = 0x00800000,
    VK_ACCESS_COMMAND_PREPROCESS_READ_BIT_NV = 0x00020000,
    VK_ACCESS_COMMAND_PREPROCESS_WRITE_BIT_NV = 0x00040000,
    VK_ACCESS_SHADING_RATE_IMAGE_READ_BIT_NV = VK_ACCESS_FRAGMENT_SHADING_RATE_ATTACHMENT_READ_BIT_KHR,
    VK_ACCESS_ACCELERATION_STRUCTURE_READ_BIT_NV = VK_ACCESS_ACCELERATION_STRUCTURE_READ_BIT_KHR,
    VK_ACCESS_ACCELERATION_STRUCTURE_WRITE_BIT_NV = VK_ACCESS_ACCELERATION_STRUCTURE_WRITE_BIT_KHR,
    VK_ACCESS_NONE_KHR = VK_ACCESS_NONE,
    VK_ACCESS_COMMAND_PREPROCESS_READ_BIT_EXT = VK_ACCESS_COMMAND_PREPROCESS_READ_BIT_NV,
    VK_ACCESS_COMMAND_PREPROCESS_WRITE_BIT_EXT = VK_ACCESS_COMMAND_PREPROCESS_WRITE_BIT_NV,
    VK_ACCESS_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkAccessFlagBits;
typedef VkFlags VkAccessFlags;

typedef enum VkImageAspectFlagBits {
    VK_IMAGE_ASPECT_COLOR_BIT = 0x00000001,
    VK_IMAGE_ASPECT_DEPTH_BIT = 0x00000002,
    VK_IMAGE_ASPECT_STENCIL_BIT = 0x00000004,
    VK_IMAGE_ASPECT_METADATA_BIT = 0x00000008,
    VK_IMAGE_ASPECT_PLANE_0_BIT = 0x00000010,
    VK_IMAGE_ASPECT_PLANE_1_BIT = 0x00000020,
    VK_IMAGE_ASPECT_PLANE_2_BIT = 0x00000040,
    VK_IMAGE_ASPECT_NONE = 0,
    VK_IMAGE_ASPECT_MEMORY_PLANE_0_BIT_EXT = 0x00000080,
    VK_IMAGE_ASPECT_MEMORY_PLANE_1_BIT_EXT = 0x00000100,
    VK_IMAGE_ASPECT_MEMORY_PLANE_2_BIT_EXT = 0x00000200,
    VK_IMAGE_ASPECT_MEMORY_PLANE_3_BIT_EXT = 0x00000400,
    VK_IMAGE_ASPECT_PLANE_0_BIT_KHR = VK_IMAGE_ASPECT_PLANE_0_BIT,
    VK_IMAGE_ASPECT_PLANE_1_BIT_KHR = VK_IMAGE_ASPECT_PLANE_1_BIT,
    VK_IMAGE_ASPECT_PLANE_2_BIT_KHR = VK_IMAGE_ASPECT_PLANE_2_BIT,
    VK_IMAGE_ASPECT_NONE_KHR = VK_IMAGE_ASPECT_NONE,
    VK_IMAGE_ASPECT_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkImageAspectFlagBits;
typedef VkFlags VkImageAspectFlags;

typedef enum VkFormatFeatureFlagBits {
    VK_FORMAT_FEATURE_SAMPLED_IMAGE_BIT = 0x00000001,
    VK_FORMAT_FEATURE_STORAGE_IMAGE_BIT = 0x00000002,
    VK_FORMAT_FEATURE_STORAGE_IMAGE_ATOMIC_BIT = 0x00000004,
    VK_FORMAT_FEATURE_UNIFORM_TEXEL_BUFFER_BIT = 0x00000008,
    VK_FORMAT_FEATURE_STORAGE_TEXEL_BUFFER_BIT = 0x00000010,
    VK_FORMAT_FEATURE_STORAGE_TEXEL_BUFFER_ATOMIC_BIT = 0x00000020,
    VK_FORMAT_FEATURE_VERTEX_BUFFER_BIT = 0x00000040,
    VK_FORMAT_FEATURE_COLOR_ATTACHMENT_BIT = 0x00000080,
    VK_FORMAT_FEATURE_COLOR_ATTACHMENT_BLEND_BIT = 0x00000100,
    VK_FORMAT_FEATURE_DEPTH_STENCIL_ATTACHMENT_BIT = 0x00000200,
    VK_FORMAT_FEATURE_BLIT_SRC_BIT = 0x00000400,
    VK_FORMAT_FEATURE_BLIT_DST_BIT = 0x00000800,
    VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_LINEAR_BIT = 0x00001000,
    VK_FORMAT_FEATURE_TRANSFER_SRC_BIT = 0x00004000,
    VK_FORMAT_FEATURE_TRANSFER_DST_BIT = 0x00008000,
    VK_FORMAT_FEATURE_MIDPOINT_CHROMA_SAMPLES_BIT = 0x00020000,
    VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_LINEAR_FILTER_BIT = 0x00040000,
    VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_SEPARATE_RECONSTRUCTION_FILTER_BIT = 0x00080000,
    VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_BIT = 0x00100000,
    VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_FORCEABLE_BIT = 0x00200000,
    VK_FORMAT_FEATURE_DISJOINT_BIT = 0x00400000,
    VK_FORMAT_FEATURE_COSITED_CHROMA_SAMPLES_BIT = 0x00800000,
    VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_MINMAX_BIT = 0x00010000,
    VK_FORMAT_FEATURE_VIDEO_DECODE_OUTPUT_BIT_KHR = 0x02000000,
    VK_FORMAT_FEATURE_VIDEO_DECODE_DPB_BIT_KHR = 0x04000000,
    VK_FORMAT_FEATURE_ACCELERATION_STRUCTURE_VERTEX_BUFFER_BIT_KHR = 0x20000000,
    VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_CUBIC_BIT_EXT = 0x00002000,
    VK_FORMAT_FEATURE_FRAGMENT_DENSITY_MAP_BIT_EXT = 0x01000000,
    VK_FORMAT_FEATURE_FRAGMENT_SHADING_RATE_ATTACHMENT_BIT_KHR = 0x40000000,
    VK_FORMAT_FEATURE_VIDEO_ENCODE_INPUT_BIT_KHR = 0x08000000,
    VK_FORMAT_FEATURE_VIDEO_ENCODE_DPB_BIT_KHR = 0x10000000,
    VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_CUBIC_BIT_IMG = VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_CUBIC_BIT_EXT,
    VK_FORMAT_FEATURE_TRANSFER_SRC_BIT_KHR = VK_FORMAT_FEATURE_TRANSFER_SRC_BIT,
    VK_FORMAT_FEATURE_TRANSFER_DST_BIT_KHR = VK_FORMAT_FEATURE_TRANSFER_DST_BIT,
    VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_MINMAX_BIT_EXT = VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_MINMAX_BIT,
    VK_FORMAT_FEATURE_MIDPOINT_CHROMA_SAMPLES_BIT_KHR = VK_FORMAT_FEATURE_MIDPOINT_CHROMA_SAMPLES_BIT,
    VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_LINEAR_FILTER_BIT_KHR = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_LINEAR_FILTER_BIT,
    VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_SEPARATE_RECONSTRUCTION_FILTER_BIT_KHR = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_SEPARATE_RECONSTRUCTION_FILTER_BIT,
    VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_BIT_KHR = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_BIT,
    VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_FORCEABLE_BIT_KHR = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_FORCEABLE_BIT,
    VK_FORMAT_FEATURE_DISJOINT_BIT_KHR = VK_FORMAT_FEATURE_DISJOINT_BIT,
    VK_FORMAT_FEATURE_COSITED_CHROMA_SAMPLES_BIT_KHR = VK_FORMAT_FEATURE_COSITED_CHROMA_SAMPLES_BIT,
    VK_FORMAT_FEATURE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkFormatFeatureFlagBits;
typedef VkFlags VkFormatFeatureFlags;

typedef enum VkImageCreateFlagBits {
    VK_IMAGE_CREATE_SPARSE_BINDING_BIT = 0x00000001,
    VK_IMAGE_CREATE_SPARSE_RESIDENCY_BIT = 0x00000002,
    VK_IMAGE_CREATE_SPARSE_ALIASED_BIT = 0x00000004,
    VK_IMAGE_CREATE_MUTABLE_FORMAT_BIT = 0x00000008,
    VK_IMAGE_CREATE_CUBE_COMPATIBLE_BIT = 0x00000010,
    VK_IMAGE_CREATE_ALIAS_BIT = 0x00000400,
    VK_IMAGE_CREATE_SPLIT_INSTANCE_BIND_REGIONS_BIT = 0x00000040,
    VK_IMAGE_CREATE_2D_ARRAY_COMPATIBLE_BIT = 0x00000020,
    VK_IMAGE_CREATE_BLOCK_TEXEL_VIEW_COMPATIBLE_BIT = 0x00000080,
    VK_IMAGE_CREATE_EXTENDED_USAGE_BIT = 0x00000100,
    VK_IMAGE_CREATE_PROTECTED_BIT = 0x00000800,
    VK_IMAGE_CREATE_DISJOINT_BIT = 0x00000200,
    VK_IMAGE_CREATE_CORNER_SAMPLED_BIT_NV = 0x00002000,
    VK_IMAGE_CREATE_SAMPLE_LOCATIONS_COMPATIBLE_DEPTH_BIT_EXT = 0x00001000,
    VK_IMAGE_CREATE_SUBSAMPLED_BIT_EXT = 0x00004000,
    VK_IMAGE_CREATE_DESCRIPTOR_BUFFER_CAPTURE_REPLAY_BIT_EXT = 0x00010000,
    VK_IMAGE_CREATE_MULTISAMPLED_RENDER_TO_SINGLE_SAMPLED_BIT_EXT = 0x00040000,
    VK_IMAGE_CREATE_2D_VIEW_COMPATIBLE_BIT_EXT = 0x00020000,
    VK_IMAGE_CREATE_FRAGMENT_DENSITY_MAP_OFFSET_BIT_QCOM = 0x00008000,
    VK_IMAGE_CREATE_VIDEO_PROFILE_INDEPENDENT_BIT_KHR = 0x00100000,
    VK_IMAGE_CREATE_SPLIT_INSTANCE_BIND_REGIONS_BIT_KHR = VK_IMAGE_CREATE_SPLIT_INSTANCE_BIND_REGIONS_BIT,
    VK_IMAGE_CREATE_2D_ARRAY_COMPATIBLE_BIT_KHR = VK_IMAGE_CREATE_2D_ARRAY_COMPATIBLE_BIT,
    VK_IMAGE_CREATE_BLOCK_TEXEL_VIEW_COMPATIBLE_BIT_KHR = VK_IMAGE_CREATE_BLOCK_TEXEL_VIEW_COMPATIBLE_BIT,
    VK_IMAGE_CREATE_EXTENDED_USAGE_BIT_KHR = VK_IMAGE_CREATE_EXTENDED_USAGE_BIT,
    VK_IMAGE_CREATE_DISJOINT_BIT_KHR = VK_IMAGE_CREATE_DISJOINT_BIT,
    VK_IMAGE_CREATE_ALIAS_BIT_KHR = VK_IMAGE_CREATE_ALIAS_BIT,
    VK_IMAGE_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkImageCreateFlagBits;
typedef VkFlags VkImageCreateFlags;

typedef enum VkSampleCountFlagBits {
    VK_SAMPLE_COUNT_1_BIT = 0x00000001,
    VK_SAMPLE_COUNT_2_BIT = 0x00000002,
    VK_SAMPLE_COUNT_4_BIT = 0x00000004,
    VK_SAMPLE_COUNT_8_BIT = 0x00000008,
    VK_SAMPLE_COUNT_16_BIT = 0x00000010,
    VK_SAMPLE_COUNT_32_BIT = 0x00000020,
    VK_SAMPLE_COUNT_64_BIT = 0x00000040,
    VK_SAMPLE_COUNT_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkSampleCountFlagBits;
typedef VkFlags VkSampleCountFlags;

typedef enum VkImageUsageFlagBits {
    VK_IMAGE_USAGE_TRANSFER_SRC_BIT = 0x00000001,
    VK_IMAGE_USAGE_TRANSFER_DST_BIT = 0x00000002,
    VK_IMAGE_USAGE_SAMPLED_BIT = 0x00000004,
    VK_IMAGE_USAGE_STORAGE_BIT = 0x00000008,
    VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT = 0x00000010,
    VK_IMAGE_USAGE_DEPTH_STENCIL_ATTACHMENT_BIT = 0x00000020,
    VK_IMAGE_USAGE_TRANSIENT_ATTACHMENT_BIT = 0x00000040,
    VK_IMAGE_USAGE_INPUT_ATTACHMENT_BIT = 0x00000080,
    VK_IMAGE_USAGE_HOST_TRANSFER_BIT = 0x00400000,
    VK_IMAGE_USAGE_VIDEO_DECODE_DST_BIT_KHR = 0x00000400,
    VK_IMAGE_USAGE_VIDEO_DECODE_SRC_BIT_KHR = 0x00000800,
    VK_IMAGE_USAGE_VIDEO_DECODE_DPB_BIT_KHR = 0x00001000,
    VK_IMAGE_USAGE_FRAGMENT_DENSITY_MAP_BIT_EXT = 0x00000200,
    VK_IMAGE_USAGE_FRAGMENT_SHADING_RATE_ATTACHMENT_BIT_KHR = 0x00000100,
    VK_IMAGE_USAGE_VIDEO_ENCODE_DST_BIT_KHR = 0x00002000,
    VK_IMAGE_USAGE_VIDEO_ENCODE_SRC_BIT_KHR = 0x00004000,
    VK_IMAGE_USAGE_VIDEO_ENCODE_DPB_BIT_KHR = 0x00008000,
    VK_IMAGE_USAGE_ATTACHMENT_FEEDBACK_LOOP_BIT_EXT = 0x00080000,
    VK_IMAGE_USAGE_INVOCATION_MASK_BIT_HUAWEI = 0x00040000,
    VK_IMAGE_USAGE_SAMPLE_WEIGHT_BIT_QCOM = 0x00100000,
    VK_IMAGE_USAGE_SAMPLE_BLOCK_MATCH_BIT_QCOM = 0x00200000,
    VK_IMAGE_USAGE_VIDEO_ENCODE_QUANTIZATION_DELTA_MAP_BIT_KHR = 0x02000000,
    VK_IMAGE_USAGE_VIDEO_ENCODE_EMPHASIS_MAP_BIT_KHR = 0x04000000,
    VK_IMAGE_USAGE_SHADING_RATE_IMAGE_BIT_NV = VK_IMAGE_USAGE_FRAGMENT_SHADING_RATE_ATTACHMENT_BIT_KHR,
    VK_IMAGE_USAGE_HOST_TRANSFER_BIT_EXT = VK_IMAGE_USAGE_HOST_TRANSFER_BIT,
    VK_IMAGE_USAGE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkImageUsageFlagBits;
typedef VkFlags VkImageUsageFlags;

typedef enum VkInstanceCreateFlagBits {
    VK_INSTANCE_CREATE_ENUMERATE_PORTABILITY_BIT_KHR = 0x00000001,
    VK_INSTANCE_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkInstanceCreateFlagBits;
typedef VkFlags VkInstanceCreateFlags;

typedef enum VkMemoryHeapFlagBits {
    VK_MEMORY_HEAP_DEVICE_LOCAL_BIT = 0x00000001,
    VK_MEMORY_HEAP_MULTI_INSTANCE_BIT = 0x00000002,
    VK_MEMORY_HEAP_MULTI_INSTANCE_BIT_KHR = VK_MEMORY_HEAP_MULTI_INSTANCE_BIT,
    VK_MEMORY_HEAP_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkMemoryHeapFlagBits;
typedef VkFlags VkMemoryHeapFlags;

typedef enum VkMemoryPropertyFlagBits {
    VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT = 0x00000001,
    VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT = 0x00000002,
    VK_MEMORY_PROPERTY_HOST_COHERENT_BIT = 0x00000004,
    VK_MEMORY_PROPERTY_HOST_CACHED_BIT = 0x00000008,
    VK_MEMORY_PROPERTY_LAZILY_ALLOCATED_BIT = 0x00000010,
    VK_MEMORY_PROPERTY_PROTECTED_BIT = 0x00000020,
    VK_MEMORY_PROPERTY_DEVICE_COHERENT_BIT_AMD = 0x00000040,
    VK_MEMORY_PROPERTY_DEVICE_UNCACHED_BIT_AMD = 0x00000080,
    VK_MEMORY_PROPERTY_RDMA_CAPABLE_BIT_NV = 0x00000100,
    VK_MEMORY_PROPERTY_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkMemoryPropertyFlagBits;
typedef VkFlags VkMemoryPropertyFlags;

typedef enum VkQueueFlagBits {
    VK_QUEUE_GRAPHICS_BIT = 0x00000001,
    VK_QUEUE_COMPUTE_BIT = 0x00000002,
    VK_QUEUE_TRANSFER_BIT = 0x00000004,
    VK_QUEUE_SPARSE_BINDING_BIT = 0x00000008,
    VK_QUEUE_PROTECTED_BIT = 0x00000010,
    VK_QUEUE_VIDEO_DECODE_BIT_KHR = 0x00000020,
    VK_QUEUE_VIDEO_ENCODE_BIT_KHR = 0x00000040,
    VK_QUEUE_OPTICAL_FLOW_BIT_NV = 0x00000100,
    VK_QUEUE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkQueueFlagBits;
typedef VkFlags VkQueueFlags;
typedef VkFlags VkDeviceCreateFlags;

typedef enum VkDeviceQueueCreateFlagBits {
    VK_DEVICE_QUEUE_CREATE_PROTECTED_BIT = 0x00000001,
    VK_DEVICE_QUEUE_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkDeviceQueueCreateFlagBits;
typedef VkFlags VkDeviceQueueCreateFlags;

typedef enum VkPipelineStageFlagBits {
    VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT = 0x00000001,
    VK_PIPELINE_STAGE_DRAW_INDIRECT_BIT = 0x00000002,
    VK_PIPELINE_STAGE_VERTEX_INPUT_BIT = 0x00000004,
    VK_PIPELINE_STAGE_VERTEX_SHADER_BIT = 0x00000008,
    VK_PIPELINE_STAGE_TESSELLATION_CONTROL_SHADER_BIT = 0x00000010,
    VK_PIPELINE_STAGE_TESSELLATION_EVALUATION_SHADER_BIT = 0x00000020,
    VK_PIPELINE_STAGE_GEOMETRY_SHADER_BIT = 0x00000040,
    VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT = 0x00000080,
    VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT = 0x00000100,
    VK_PIPELINE_STAGE_LATE_FRAGMENT_TESTS_BIT = 0x00000200,
    VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT = 0x00000400,
    VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT = 0x00000800,
    VK_PIPELINE_STAGE_TRANSFER_BIT = 0x00001000,
    VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT = 0x00002000,
    VK_PIPELINE_STAGE_HOST_BIT = 0x00004000,
    VK_PIPELINE_STAGE_ALL_GRAPHICS_BIT = 0x00008000,
    VK_PIPELINE_STAGE_ALL_COMMANDS_BIT = 0x00010000,
    VK_PIPELINE_STAGE_NONE = 0,
    VK_PIPELINE_STAGE_TRANSFORM_FEEDBACK_BIT_EXT = 0x01000000,
    VK_PIPELINE_STAGE_CONDITIONAL_RENDERING_BIT_EXT = 0x00040000,
    VK_PIPELINE_STAGE_ACCELERATION_STRUCTURE_BUILD_BIT_KHR = 0x02000000,
    VK_PIPELINE_STAGE_RAY_TRACING_SHADER_BIT_KHR = 0x00200000,
    VK_PIPELINE_STAGE_FRAGMENT_DENSITY_PROCESS_BIT_EXT = 0x00800000,
    VK_PIPELINE_STAGE_FRAGMENT_SHADING_RATE_ATTACHMENT_BIT_KHR = 0x00400000,
    VK_PIPELINE_STAGE_COMMAND_PREPROCESS_BIT_NV = 0x00020000,
    VK_PIPELINE_STAGE_TASK_SHADER_BIT_EXT = 0x00080000,
    VK_PIPELINE_STAGE_MESH_SHADER_BIT_EXT = 0x00100000,
    VK_PIPELINE_STAGE_SHADING_RATE_IMAGE_BIT_NV = VK_PIPELINE_STAGE_FRAGMENT_SHADING_RATE_ATTACHMENT_BIT_KHR,
    VK_PIPELINE_STAGE_RAY_TRACING_SHADER_BIT_NV = VK_PIPELINE_STAGE_RAY_TRACING_SHADER_BIT_KHR,
    VK_PIPELINE_STAGE_ACCELERATION_STRUCTURE_BUILD_BIT_NV = VK_PIPELINE_STAGE_ACCELERATION_STRUCTURE_BUILD_BIT_KHR,
    VK_PIPELINE_STAGE_TASK_SHADER_BIT_NV = VK_PIPELINE_STAGE_TASK_SHADER_BIT_EXT,
    VK_PIPELINE_STAGE_MESH_SHADER_BIT_NV = VK_PIPELINE_STAGE_MESH_SHADER_BIT_EXT,
    VK_PIPELINE_STAGE_NONE_KHR = VK_PIPELINE_STAGE_NONE,
    VK_PIPELINE_STAGE_COMMAND_PREPROCESS_BIT_EXT = VK_PIPELINE_STAGE_COMMAND_PREPROCESS_BIT_NV,
    VK_PIPELINE_STAGE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkPipelineStageFlagBits;
typedef VkFlags VkPipelineStageFlags;

typedef enum VkMemoryMapFlagBits {
    VK_MEMORY_MAP_PLACED_BIT_EXT = 0x00000001,
    VK_MEMORY_MAP_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkMemoryMapFlagBits;
typedef VkFlags VkMemoryMapFlags;

typedef enum VkSparseMemoryBindFlagBits {
    VK_SPARSE_MEMORY_BIND_METADATA_BIT = 0x00000001,
    VK_SPARSE_MEMORY_BIND_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkSparseMemoryBindFlagBits;
typedef VkFlags VkSparseMemoryBindFlags;

typedef enum VkSparseImageFormatFlagBits {
    VK_SPARSE_IMAGE_FORMAT_SINGLE_MIPTAIL_BIT = 0x00000001,
    VK_SPARSE_IMAGE_FORMAT_ALIGNED_MIP_SIZE_BIT = 0x00000002,
    VK_SPARSE_IMAGE_FORMAT_NONSTANDARD_BLOCK_SIZE_BIT = 0x00000004,
    VK_SPARSE_IMAGE_FORMAT_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkSparseImageFormatFlagBits;
typedef VkFlags VkSparseImageFormatFlags;

typedef enum VkFenceCreateFlagBits {
    VK_FENCE_CREATE_SIGNALED_BIT = 0x00000001,
    VK_FENCE_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkFenceCreateFlagBits;
typedef VkFlags VkFenceCreateFlags;
typedef VkFlags VkSemaphoreCreateFlags;

typedef enum VkEventCreateFlagBits {
    VK_EVENT_CREATE_DEVICE_ONLY_BIT = 0x00000001,
    VK_EVENT_CREATE_DEVICE_ONLY_BIT_KHR = VK_EVENT_CREATE_DEVICE_ONLY_BIT,
    VK_EVENT_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkEventCreateFlagBits;
typedef VkFlags VkEventCreateFlags;

typedef enum VkQueryPipelineStatisticFlagBits {
    VK_QUERY_PIPELINE_STATISTIC_INPUT_ASSEMBLY_VERTICES_BIT = 0x00000001,
    VK_QUERY_PIPELINE_STATISTIC_INPUT_ASSEMBLY_PRIMITIVES_BIT = 0x00000002,
    VK_QUERY_PIPELINE_STATISTIC_VERTEX_SHADER_INVOCATIONS_BIT = 0x00000004,
    VK_QUERY_PIPELINE_STATISTIC_GEOMETRY_SHADER_INVOCATIONS_BIT = 0x00000008,
    VK_QUERY_PIPELINE_STATISTIC_GEOMETRY_SHADER_PRIMITIVES_BIT = 0x00000010,
    VK_QUERY_PIPELINE_STATISTIC_CLIPPING_INVOCATIONS_BIT = 0x00000020,
    VK_QUERY_PIPELINE_STATISTIC_CLIPPING_PRIMITIVES_BIT = 0x00000040,
    VK_QUERY_PIPELINE_STATISTIC_FRAGMENT_SHADER_INVOCATIONS_BIT = 0x00000080,
    VK_QUERY_PIPELINE_STATISTIC_TESSELLATION_CONTROL_SHADER_PATCHES_BIT = 0x00000100,
    VK_QUERY_PIPELINE_STATISTIC_TESSELLATION_EVALUATION_SHADER_INVOCATIONS_BIT = 0x00000200,
    VK_QUERY_PIPELINE_STATISTIC_COMPUTE_SHADER_INVOCATIONS_BIT = 0x00000400,
    VK_QUERY_PIPELINE_STATISTIC_TASK_SHADER_INVOCATIONS_BIT_EXT = 0x00000800,
    VK_QUERY_PIPELINE_STATISTIC_MESH_SHADER_INVOCATIONS_BIT_EXT = 0x00001000,
    VK_QUERY_PIPELINE_STATISTIC_CLUSTER_CULLING_SHADER_INVOCATIONS_BIT_HUAWEI = 0x00002000,
    VK_QUERY_PIPELINE_STATISTIC_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkQueryPipelineStatisticFlagBits;
typedef VkFlags VkQueryPipelineStatisticFlags;
typedef VkFlags VkQueryPoolCreateFlags;

typedef enum VkQueryResultFlagBits {
    VK_QUERY_RESULT_64_BIT = 0x00000001,
    VK_QUERY_RESULT_WAIT_BIT = 0x00000002,
    VK_QUERY_RESULT_WITH_AVAILABILITY_BIT = 0x00000004,
    VK_QUERY_RESULT_PARTIAL_BIT = 0x00000008,
    VK_QUERY_RESULT_WITH_STATUS_BIT_KHR = 0x00000010,
    VK_QUERY_RESULT_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkQueryResultFlagBits;
typedef VkFlags VkQueryResultFlags;

typedef enum VkBufferCreateFlagBits {
    VK_BUFFER_CREATE_SPARSE_BINDING_BIT = 0x00000001,
    VK_BUFFER_CREATE_SPARSE_RESIDENCY_BIT = 0x00000002,
    VK_BUFFER_CREATE_SPARSE_ALIASED_BIT = 0x00000004,
    VK_BUFFER_CREATE_PROTECTED_BIT = 0x00000008,
    VK_BUFFER_CREATE_DEVICE_ADDRESS_CAPTURE_REPLAY_BIT = 0x00000010,
    VK_BUFFER_CREATE_DESCRIPTOR_BUFFER_CAPTURE_REPLAY_BIT_EXT = 0x00000020,
    VK_BUFFER_CREATE_VIDEO_PROFILE_INDEPENDENT_BIT_KHR = 0x00000040,
    VK_BUFFER_CREATE_DEVICE_ADDRESS_CAPTURE_REPLAY_BIT_EXT = VK_BUFFER_CREATE_DEVICE_ADDRESS_CAPTURE_REPLAY_BIT,
    VK_BUFFER_CREATE_DEVICE_ADDRESS_CAPTURE_REPLAY_BIT_KHR = VK_BUFFER_CREATE_DEVICE_ADDRESS_CAPTURE_REPLAY_BIT,
    VK_BUFFER_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkBufferCreateFlagBits;
typedef VkFlags VkBufferCreateFlags;

typedef enum VkBufferUsageFlagBits {
    VK_BUFFER_USAGE_TRANSFER_SRC_BIT = 0x00000001,
    VK_BUFFER_USAGE_TRANSFER_DST_BIT = 0x00000002,
    VK_BUFFER_USAGE_UNIFORM_TEXEL_BUFFER_BIT = 0x00000004,
    VK_BUFFER_USAGE_STORAGE_TEXEL_BUFFER_BIT = 0x00000008,
    VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT = 0x00000010,
    VK_BUFFER_USAGE_STORAGE_BUFFER_BIT = 0x00000020,
    VK_BUFFER_USAGE_INDEX_BUFFER_BIT = 0x00000040,
    VK_BUFFER_USAGE_VERTEX_BUFFER_BIT = 0x00000080,
    VK_BUFFER_USAGE_INDIRECT_BUFFER_BIT = 0x00000100,
    VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT = 0x00020000,
    VK_BUFFER_USAGE_VIDEO_DECODE_SRC_BIT_KHR = 0x00002000,
    VK_BUFFER_USAGE_VIDEO_DECODE_DST_BIT_KHR = 0x00004000,
    VK_BUFFER_USAGE_TRANSFORM_FEEDBACK_BUFFER_BIT_EXT = 0x00000800,
    VK_BUFFER_USAGE_TRANSFORM_FEEDBACK_COUNTER_BUFFER_BIT_EXT = 0x00001000,
    VK_BUFFER_USAGE_CONDITIONAL_RENDERING_BIT_EXT = 0x00000200,



    VK_BUFFER_USAGE_ACCELERATION_STRUCTURE_BUILD_INPUT_READ_ONLY_BIT_KHR = 0x00080000,
    VK_BUFFER_USAGE_ACCELERATION_STRUCTURE_STORAGE_BIT_KHR = 0x00100000,
    VK_BUFFER_USAGE_SHADER_BINDING_TABLE_BIT_KHR = 0x00000400,
    VK_BUFFER_USAGE_VIDEO_ENCODE_DST_BIT_KHR = 0x00008000,
    VK_BUFFER_USAGE_VIDEO_ENCODE_SRC_BIT_KHR = 0x00010000,
    VK_BUFFER_USAGE_SAMPLER_DESCRIPTOR_BUFFER_BIT_EXT = 0x00200000,
    VK_BUFFER_USAGE_RESOURCE_DESCRIPTOR_BUFFER_BIT_EXT = 0x00400000,
    VK_BUFFER_USAGE_PUSH_DESCRIPTORS_DESCRIPTOR_BUFFER_BIT_EXT = 0x04000000,
    VK_BUFFER_USAGE_MICROMAP_BUILD_INPUT_READ_ONLY_BIT_EXT = 0x00800000,
    VK_BUFFER_USAGE_MICROMAP_STORAGE_BIT_EXT = 0x01000000,
    VK_BUFFER_USAGE_RAY_TRACING_BIT_NV = VK_BUFFER_USAGE_SHADER_BINDING_TABLE_BIT_KHR,
    VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT_EXT = VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT,
    VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT_KHR = VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT,
    VK_BUFFER_USAGE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkBufferUsageFlagBits;
typedef VkFlags VkBufferUsageFlags;
typedef VkFlags VkBufferViewCreateFlags;

typedef enum VkImageViewCreateFlagBits {
    VK_IMAGE_VIEW_CREATE_FRAGMENT_DENSITY_MAP_DYNAMIC_BIT_EXT = 0x00000001,
    VK_IMAGE_VIEW_CREATE_DESCRIPTOR_BUFFER_CAPTURE_REPLAY_BIT_EXT = 0x00000004,
    VK_IMAGE_VIEW_CREATE_FRAGMENT_DENSITY_MAP_DEFERRED_BIT_EXT = 0x00000002,
    VK_IMAGE_VIEW_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkImageViewCreateFlagBits;
typedef VkFlags VkImageViewCreateFlags;
typedef VkFlags VkShaderModuleCreateFlags;

typedef enum VkPipelineCacheCreateFlagBits {
    VK_PIPELINE_CACHE_CREATE_EXTERNALLY_SYNCHRONIZED_BIT = 0x00000001,
    VK_PIPELINE_CACHE_CREATE_EXTERNALLY_SYNCHRONIZED_BIT_EXT = VK_PIPELINE_CACHE_CREATE_EXTERNALLY_SYNCHRONIZED_BIT,
    VK_PIPELINE_CACHE_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkPipelineCacheCreateFlagBits;
typedef VkFlags VkPipelineCacheCreateFlags;

typedef enum VkColorComponentFlagBits {
    VK_COLOR_COMPONENT_R_BIT = 0x00000001,
    VK_COLOR_COMPONENT_G_BIT = 0x00000002,
    VK_COLOR_COMPONENT_B_BIT = 0x00000004,
    VK_COLOR_COMPONENT_A_BIT = 0x00000008,
    VK_COLOR_COMPONENT_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkColorComponentFlagBits;
typedef VkFlags VkColorComponentFlags;

typedef enum VkPipelineCreateFlagBits {
    VK_PIPELINE_CREATE_DISABLE_OPTIMIZATION_BIT = 0x00000001,
    VK_PIPELINE_CREATE_ALLOW_DERIVATIVES_BIT = 0x00000002,
    VK_PIPELINE_CREATE_DERIVATIVE_BIT = 0x00000004,
    VK_PIPELINE_CREATE_VIEW_INDEX_FROM_DEVICE_INDEX_BIT = 0x00000008,
    VK_PIPELINE_CREATE_DISPATCH_BASE_BIT = 0x00000010,
    VK_PIPELINE_CREATE_FAIL_ON_PIPELINE_COMPILE_REQUIRED_BIT = 0x00000100,
    VK_PIPELINE_CREATE_EARLY_RETURN_ON_FAILURE_BIT = 0x00000200,
    VK_PIPELINE_CREATE_NO_PROTECTED_ACCESS_BIT = 0x08000000,
    VK_PIPELINE_CREATE_PROTECTED_ACCESS_ONLY_BIT = 0x40000000,
    VK_PIPELINE_CREATE_RAY_TRACING_NO_NULL_ANY_HIT_SHADERS_BIT_KHR = 0x00004000,
    VK_PIPELINE_CREATE_RAY_TRACING_NO_NULL_CLOSEST_HIT_SHADERS_BIT_KHR = 0x00008000,
    VK_PIPELINE_CREATE_RAY_TRACING_NO_NULL_MISS_SHADERS_BIT_KHR = 0x00010000,
    VK_PIPELINE_CREATE_RAY_TRACING_NO_NULL_INTERSECTION_SHADERS_BIT_KHR = 0x00020000,
    VK_PIPELINE_CREATE_RAY_TRACING_SKIP_TRIANGLES_BIT_KHR = 0x00001000,
    VK_PIPELINE_CREATE_RAY_TRACING_SKIP_AABBS_BIT_KHR = 0x00002000,
    VK_PIPELINE_CREATE_RAY_TRACING_SHADER_GROUP_HANDLE_CAPTURE_REPLAY_BIT_KHR = 0x00080000,
    VK_PIPELINE_CREATE_DEFER_COMPILE_BIT_NV = 0x00000020,
    VK_PIPELINE_CREATE_RENDERING_FRAGMENT_DENSITY_MAP_ATTACHMENT_BIT_EXT = 0x00400000,
    VK_PIPELINE_CREATE_RENDERING_FRAGMENT_SHADING_RATE_ATTACHMENT_BIT_KHR = 0x00200000,
    VK_PIPELINE_CREATE_CAPTURE_STATISTICS_BIT_KHR = 0x00000040,
    VK_PIPELINE_CREATE_CAPTURE_INTERNAL_REPRESENTATIONS_BIT_KHR = 0x00000080,
    VK_PIPELINE_CREATE_INDIRECT_BINDABLE_BIT_NV = 0x00040000,
    VK_PIPELINE_CREATE_LIBRARY_BIT_KHR = 0x00000800,
    VK_PIPELINE_CREATE_DESCRIPTOR_BUFFER_BIT_EXT = 0x20000000,
    VK_PIPELINE_CREATE_RETAIN_LINK_TIME_OPTIMIZATION_INFO_BIT_EXT = 0x00800000,
    VK_PIPELINE_CREATE_LINK_TIME_OPTIMIZATION_BIT_EXT = 0x00000400,
    VK_PIPELINE_CREATE_RAY_TRACING_ALLOW_MOTION_BIT_NV = 0x00100000,
    VK_PIPELINE_CREATE_COLOR_ATTACHMENT_FEEDBACK_LOOP_BIT_EXT = 0x02000000,
    VK_PIPELINE_CREATE_DEPTH_STENCIL_ATTACHMENT_FEEDBACK_LOOP_BIT_EXT = 0x04000000,
    VK_PIPELINE_CREATE_RAY_TRACING_OPACITY_MICROMAP_BIT_EXT = 0x01000000,



    VK_PIPELINE_CREATE_DISPATCH_BASE = VK_PIPELINE_CREATE_DISPATCH_BASE_BIT,
    VK_PIPELINE_CREATE_VIEW_INDEX_FROM_DEVICE_INDEX_BIT_KHR = VK_PIPELINE_CREATE_VIEW_INDEX_FROM_DEVICE_INDEX_BIT,
    VK_PIPELINE_CREATE_DISPATCH_BASE_KHR = VK_PIPELINE_CREATE_DISPATCH_BASE,

    VK_PIPELINE_RASTERIZATION_STATE_CREATE_FRAGMENT_DENSITY_MAP_ATTACHMENT_BIT_EXT = VK_PIPELINE_CREATE_RENDERING_FRAGMENT_DENSITY_MAP_ATTACHMENT_BIT_EXT,

    VK_PIPELINE_RASTERIZATION_STATE_CREATE_FRAGMENT_SHADING_RATE_ATTACHMENT_BIT_KHR = VK_PIPELINE_CREATE_RENDERING_FRAGMENT_SHADING_RATE_ATTACHMENT_BIT_KHR,
    VK_PIPELINE_CREATE_FAIL_ON_PIPELINE_COMPILE_REQUIRED_BIT_EXT = VK_PIPELINE_CREATE_FAIL_ON_PIPELINE_COMPILE_REQUIRED_BIT,
    VK_PIPELINE_CREATE_EARLY_RETURN_ON_FAILURE_BIT_EXT = VK_PIPELINE_CREATE_EARLY_RETURN_ON_FAILURE_BIT,
    VK_PIPELINE_CREATE_NO_PROTECTED_ACCESS_BIT_EXT = VK_PIPELINE_CREATE_NO_PROTECTED_ACCESS_BIT,
    VK_PIPELINE_CREATE_PROTECTED_ACCESS_ONLY_BIT_EXT = VK_PIPELINE_CREATE_PROTECTED_ACCESS_ONLY_BIT,
    VK_PIPELINE_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkPipelineCreateFlagBits;
typedef VkFlags VkPipelineCreateFlags;

typedef enum VkPipelineShaderStageCreateFlagBits {
    VK_PIPELINE_SHADER_STAGE_CREATE_ALLOW_VARYING_SUBGROUP_SIZE_BIT = 0x00000001,
    VK_PIPELINE_SHADER_STAGE_CREATE_REQUIRE_FULL_SUBGROUPS_BIT = 0x00000002,
    VK_PIPELINE_SHADER_STAGE_CREATE_ALLOW_VARYING_SUBGROUP_SIZE_BIT_EXT = VK_PIPELINE_SHADER_STAGE_CREATE_ALLOW_VARYING_SUBGROUP_SIZE_BIT,
    VK_PIPELINE_SHADER_STAGE_CREATE_REQUIRE_FULL_SUBGROUPS_BIT_EXT = VK_PIPELINE_SHADER_STAGE_CREATE_REQUIRE_FULL_SUBGROUPS_BIT,
    VK_PIPELINE_SHADER_STAGE_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkPipelineShaderStageCreateFlagBits;
typedef VkFlags VkPipelineShaderStageCreateFlags;

typedef enum VkShaderStageFlagBits {
    VK_SHADER_STAGE_VERTEX_BIT = 0x00000001,
    VK_SHADER_STAGE_TESSELLATION_CONTROL_BIT = 0x00000002,
    VK_SHADER_STAGE_TESSELLATION_EVALUATION_BIT = 0x00000004,
    VK_SHADER_STAGE_GEOMETRY_BIT = 0x00000008,
    VK_SHADER_STAGE_FRAGMENT_BIT = 0x00000010,
    VK_SHADER_STAGE_COMPUTE_BIT = 0x00000020,
    VK_SHADER_STAGE_ALL_GRAPHICS = 0x0000001F,
    VK_SHADER_STAGE_ALL = 0x7FFFFFFF,
    VK_SHADER_STAGE_RAYGEN_BIT_KHR = 0x00000100,
    VK_SHADER_STAGE_ANY_HIT_BIT_KHR = 0x00000200,
    VK_SHADER_STAGE_CLOSEST_HIT_BIT_KHR = 0x00000400,
    VK_SHADER_STAGE_MISS_BIT_KHR = 0x00000800,
    VK_SHADER_STAGE_INTERSECTION_BIT_KHR = 0x00001000,
    VK_SHADER_STAGE_CALLABLE_BIT_KHR = 0x00002000,
    VK_SHADER_STAGE_TASK_BIT_EXT = 0x00000040,
    VK_SHADER_STAGE_MESH_BIT_EXT = 0x00000080,
    VK_SHADER_STAGE_SUBPASS_SHADING_BIT_HUAWEI = 0x00004000,
    VK_SHADER_STAGE_CLUSTER_CULLING_BIT_HUAWEI = 0x00080000,
    VK_SHADER_STAGE_RAYGEN_BIT_NV = VK_SHADER_STAGE_RAYGEN_BIT_KHR,
    VK_SHADER_STAGE_ANY_HIT_BIT_NV = VK_SHADER_STAGE_ANY_HIT_BIT_KHR,
    VK_SHADER_STAGE_CLOSEST_HIT_BIT_NV = VK_SHADER_STAGE_CLOSEST_HIT_BIT_KHR,
    VK_SHADER_STAGE_MISS_BIT_NV = VK_SHADER_STAGE_MISS_BIT_KHR,
    VK_SHADER_STAGE_INTERSECTION_BIT_NV = VK_SHADER_STAGE_INTERSECTION_BIT_KHR,
    VK_SHADER_STAGE_CALLABLE_BIT_NV = VK_SHADER_STAGE_CALLABLE_BIT_KHR,
    VK_SHADER_STAGE_TASK_BIT_NV = VK_SHADER_STAGE_TASK_BIT_EXT,
    VK_SHADER_STAGE_MESH_BIT_NV = VK_SHADER_STAGE_MESH_BIT_EXT,
    VK_SHADER_STAGE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkShaderStageFlagBits;

typedef enum VkCullModeFlagBits {
    VK_CULL_MODE_NONE = 0,
    VK_CULL_MODE_FRONT_BIT = 0x00000001,
    VK_CULL_MODE_BACK_BIT = 0x00000002,
    VK_CULL_MODE_FRONT_AND_BACK = 0x00000003,
    VK_CULL_MODE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkCullModeFlagBits;
typedef VkFlags VkCullModeFlags;
typedef VkFlags VkPipelineVertexInputStateCreateFlags;
typedef VkFlags VkPipelineInputAssemblyStateCreateFlags;
typedef VkFlags VkPipelineTessellationStateCreateFlags;
typedef VkFlags VkPipelineViewportStateCreateFlags;
typedef VkFlags VkPipelineRasterizationStateCreateFlags;
typedef VkFlags VkPipelineMultisampleStateCreateFlags;

typedef enum VkPipelineDepthStencilStateCreateFlagBits {
    VK_PIPELINE_DEPTH_STENCIL_STATE_CREATE_RASTERIZATION_ORDER_ATTACHMENT_DEPTH_ACCESS_BIT_EXT = 0x00000001,
    VK_PIPELINE_DEPTH_STENCIL_STATE_CREATE_RASTERIZATION_ORDER_ATTACHMENT_STENCIL_ACCESS_BIT_EXT = 0x00000002,
    VK_PIPELINE_DEPTH_STENCIL_STATE_CREATE_RASTERIZATION_ORDER_ATTACHMENT_DEPTH_ACCESS_BIT_ARM = VK_PIPELINE_DEPTH_STENCIL_STATE_CREATE_RASTERIZATION_ORDER_ATTACHMENT_DEPTH_ACCESS_BIT_EXT,
    VK_PIPELINE_DEPTH_STENCIL_STATE_CREATE_RASTERIZATION_ORDER_ATTACHMENT_STENCIL_ACCESS_BIT_ARM = VK_PIPELINE_DEPTH_STENCIL_STATE_CREATE_RASTERIZATION_ORDER_ATTACHMENT_STENCIL_ACCESS_BIT_EXT,
    VK_PIPELINE_DEPTH_STENCIL_STATE_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkPipelineDepthStencilStateCreateFlagBits;
typedef VkFlags VkPipelineDepthStencilStateCreateFlags;

typedef enum VkPipelineColorBlendStateCreateFlagBits {
    VK_PIPELINE_COLOR_BLEND_STATE_CREATE_RASTERIZATION_ORDER_ATTACHMENT_ACCESS_BIT_EXT = 0x00000001,
    VK_PIPELINE_COLOR_BLEND_STATE_CREATE_RASTERIZATION_ORDER_ATTACHMENT_ACCESS_BIT_ARM = VK_PIPELINE_COLOR_BLEND_STATE_CREATE_RASTERIZATION_ORDER_ATTACHMENT_ACCESS_BIT_EXT,
    VK_PIPELINE_COLOR_BLEND_STATE_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkPipelineColorBlendStateCreateFlagBits;
typedef VkFlags VkPipelineColorBlendStateCreateFlags;
typedef VkFlags VkPipelineDynamicStateCreateFlags;

typedef enum VkPipelineLayoutCreateFlagBits {
    VK_PIPELINE_LAYOUT_CREATE_INDEPENDENT_SETS_BIT_EXT = 0x00000002,
    VK_PIPELINE_LAYOUT_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkPipelineLayoutCreateFlagBits;
typedef VkFlags VkPipelineLayoutCreateFlags;
typedef VkFlags VkShaderStageFlags;

typedef enum VkSamplerCreateFlagBits {
    VK_SAMPLER_CREATE_SUBSAMPLED_BIT_EXT = 0x00000001,
    VK_SAMPLER_CREATE_SUBSAMPLED_COARSE_RECONSTRUCTION_BIT_EXT = 0x00000002,
    VK_SAMPLER_CREATE_DESCRIPTOR_BUFFER_CAPTURE_REPLAY_BIT_EXT = 0x00000008,
    VK_SAMPLER_CREATE_NON_SEAMLESS_CUBE_MAP_BIT_EXT = 0x00000004,
    VK_SAMPLER_CREATE_IMAGE_PROCESSING_BIT_QCOM = 0x00000010,
    VK_SAMPLER_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkSamplerCreateFlagBits;
typedef VkFlags VkSamplerCreateFlags;

typedef enum VkDescriptorPoolCreateFlagBits {
    VK_DESCRIPTOR_POOL_CREATE_FREE_DESCRIPTOR_SET_BIT = 0x00000001,
    VK_DESCRIPTOR_POOL_CREATE_UPDATE_AFTER_BIND_BIT = 0x00000002,
    VK_DESCRIPTOR_POOL_CREATE_HOST_ONLY_BIT_EXT = 0x00000004,
    VK_DESCRIPTOR_POOL_CREATE_ALLOW_OVERALLOCATION_SETS_BIT_NV = 0x00000008,
    VK_DESCRIPTOR_POOL_CREATE_ALLOW_OVERALLOCATION_POOLS_BIT_NV = 0x00000010,
    VK_DESCRIPTOR_POOL_CREATE_UPDATE_AFTER_BIND_BIT_EXT = VK_DESCRIPTOR_POOL_CREATE_UPDATE_AFTER_BIND_BIT,
    VK_DESCRIPTOR_POOL_CREATE_HOST_ONLY_BIT_VALVE = VK_DESCRIPTOR_POOL_CREATE_HOST_ONLY_BIT_EXT,
    VK_DESCRIPTOR_POOL_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkDescriptorPoolCreateFlagBits;
typedef VkFlags VkDescriptorPoolCreateFlags;
typedef VkFlags VkDescriptorPoolResetFlags;

typedef enum VkDescriptorSetLayoutCreateFlagBits {
    VK_DESCRIPTOR_SET_LAYOUT_CREATE_UPDATE_AFTER_BIND_POOL_BIT = 0x00000002,
    VK_DESCRIPTOR_SET_LAYOUT_CREATE_PUSH_DESCRIPTOR_BIT = 0x00000001,
    VK_DESCRIPTOR_SET_LAYOUT_CREATE_DESCRIPTOR_BUFFER_BIT_EXT = 0x00000010,
    VK_DESCRIPTOR_SET_LAYOUT_CREATE_EMBEDDED_IMMUTABLE_SAMPLERS_BIT_EXT = 0x00000020,
    VK_DESCRIPTOR_SET_LAYOUT_CREATE_INDIRECT_BINDABLE_BIT_NV = 0x00000080,
    VK_DESCRIPTOR_SET_LAYOUT_CREATE_HOST_ONLY_POOL_BIT_EXT = 0x00000004,
    VK_DESCRIPTOR_SET_LAYOUT_CREATE_PER_STAGE_BIT_NV = 0x00000040,
    VK_DESCRIPTOR_SET_LAYOUT_CREATE_PUSH_DESCRIPTOR_BIT_KHR = VK_DESCRIPTOR_SET_LAYOUT_CREATE_PUSH_DESCRIPTOR_BIT,
    VK_DESCRIPTOR_SET_LAYOUT_CREATE_UPDATE_AFTER_BIND_POOL_BIT_EXT = VK_DESCRIPTOR_SET_LAYOUT_CREATE_UPDATE_AFTER_BIND_POOL_BIT,
    VK_DESCRIPTOR_SET_LAYOUT_CREATE_HOST_ONLY_POOL_BIT_VALVE = VK_DESCRIPTOR_SET_LAYOUT_CREATE_HOST_ONLY_POOL_BIT_EXT,
    VK_DESCRIPTOR_SET_LAYOUT_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkDescriptorSetLayoutCreateFlagBits;
typedef VkFlags VkDescriptorSetLayoutCreateFlags;

typedef enum VkAttachmentDescriptionFlagBits {
    VK_ATTACHMENT_DESCRIPTION_MAY_ALIAS_BIT = 0x00000001,
    VK_ATTACHMENT_DESCRIPTION_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkAttachmentDescriptionFlagBits;
typedef VkFlags VkAttachmentDescriptionFlags;

typedef enum VkDependencyFlagBits {
    VK_DEPENDENCY_BY_REGION_BIT = 0x00000001,
    VK_DEPENDENCY_DEVICE_GROUP_BIT = 0x00000004,
    VK_DEPENDENCY_VIEW_LOCAL_BIT = 0x00000002,
    VK_DEPENDENCY_FEEDBACK_LOOP_BIT_EXT = 0x00000008,
    VK_DEPENDENCY_VIEW_LOCAL_BIT_KHR = VK_DEPENDENCY_VIEW_LOCAL_BIT,
    VK_DEPENDENCY_DEVICE_GROUP_BIT_KHR = VK_DEPENDENCY_DEVICE_GROUP_BIT,
    VK_DEPENDENCY_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkDependencyFlagBits;
typedef VkFlags VkDependencyFlags;

typedef enum VkFramebufferCreateFlagBits {
    VK_FRAMEBUFFER_CREATE_IMAGELESS_BIT = 0x00000001,
    VK_FRAMEBUFFER_CREATE_IMAGELESS_BIT_KHR = VK_FRAMEBUFFER_CREATE_IMAGELESS_BIT,
    VK_FRAMEBUFFER_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkFramebufferCreateFlagBits;
typedef VkFlags VkFramebufferCreateFlags;

typedef enum VkRenderPassCreateFlagBits {
    VK_RENDER_PASS_CREATE_TRANSFORM_BIT_QCOM = 0x00000002,
    VK_RENDER_PASS_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkRenderPassCreateFlagBits;
typedef VkFlags VkRenderPassCreateFlags;

typedef enum VkSubpassDescriptionFlagBits {
    VK_SUBPASS_DESCRIPTION_PER_VIEW_ATTRIBUTES_BIT_NVX = 0x00000001,
    VK_SUBPASS_DESCRIPTION_PER_VIEW_POSITION_X_ONLY_BIT_NVX = 0x00000002,
    VK_SUBPASS_DESCRIPTION_FRAGMENT_REGION_BIT_QCOM = 0x00000004,
    VK_SUBPASS_DESCRIPTION_SHADER_RESOLVE_BIT_QCOM = 0x00000008,
    VK_SUBPASS_DESCRIPTION_RASTERIZATION_ORDER_ATTACHMENT_COLOR_ACCESS_BIT_EXT = 0x00000010,
    VK_SUBPASS_DESCRIPTION_RASTERIZATION_ORDER_ATTACHMENT_DEPTH_ACCESS_BIT_EXT = 0x00000020,
    VK_SUBPASS_DESCRIPTION_RASTERIZATION_ORDER_ATTACHMENT_STENCIL_ACCESS_BIT_EXT = 0x00000040,
    VK_SUBPASS_DESCRIPTION_ENABLE_LEGACY_DITHERING_BIT_EXT = 0x00000080,
    VK_SUBPASS_DESCRIPTION_RASTERIZATION_ORDER_ATTACHMENT_COLOR_ACCESS_BIT_ARM = VK_SUBPASS_DESCRIPTION_RASTERIZATION_ORDER_ATTACHMENT_COLOR_ACCESS_BIT_EXT,
    VK_SUBPASS_DESCRIPTION_RASTERIZATION_ORDER_ATTACHMENT_DEPTH_ACCESS_BIT_ARM = VK_SUBPASS_DESCRIPTION_RASTERIZATION_ORDER_ATTACHMENT_DEPTH_ACCESS_BIT_EXT,
    VK_SUBPASS_DESCRIPTION_RASTERIZATION_ORDER_ATTACHMENT_STENCIL_ACCESS_BIT_ARM = VK_SUBPASS_DESCRIPTION_RASTERIZATION_ORDER_ATTACHMENT_STENCIL_ACCESS_BIT_EXT,
    VK_SUBPASS_DESCRIPTION_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkSubpassDescriptionFlagBits;
typedef VkFlags VkSubpassDescriptionFlags;

typedef enum VkCommandPoolCreateFlagBits {
    VK_COMMAND_POOL_CREATE_TRANSIENT_BIT = 0x00000001,
    VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT = 0x00000002,
    VK_COMMAND_POOL_CREATE_PROTECTED_BIT = 0x00000004,
    VK_COMMAND_POOL_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkCommandPoolCreateFlagBits;
typedef VkFlags VkCommandPoolCreateFlags;

typedef enum VkCommandPoolResetFlagBits {
    VK_COMMAND_POOL_RESET_RELEASE_RESOURCES_BIT = 0x00000001,
    VK_COMMAND_POOL_RESET_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkCommandPoolResetFlagBits;
typedef VkFlags VkCommandPoolResetFlags;

typedef enum VkCommandBufferUsageFlagBits {
    VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT = 0x00000001,
    VK_COMMAND_BUFFER_USAGE_RENDER_PASS_CONTINUE_BIT = 0x00000002,
    VK_COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT = 0x00000004,
    VK_COMMAND_BUFFER_USAGE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkCommandBufferUsageFlagBits;
typedef VkFlags VkCommandBufferUsageFlags;

typedef enum VkQueryControlFlagBits {
    VK_QUERY_CONTROL_PRECISE_BIT = 0x00000001,
    VK_QUERY_CONTROL_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkQueryControlFlagBits;
typedef VkFlags VkQueryControlFlags;

typedef enum VkCommandBufferResetFlagBits {
    VK_COMMAND_BUFFER_RESET_RELEASE_RESOURCES_BIT = 0x00000001,
    VK_COMMAND_BUFFER_RESET_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkCommandBufferResetFlagBits;
typedef VkFlags VkCommandBufferResetFlags;

typedef enum VkStencilFaceFlagBits {
    VK_STENCIL_FACE_FRONT_BIT = 0x00000001,
    VK_STENCIL_FACE_BACK_BIT = 0x00000002,
    VK_STENCIL_FACE_FRONT_AND_BACK = 0x00000003,

    VK_STENCIL_FRONT_AND_BACK = VK_STENCIL_FACE_FRONT_AND_BACK,
    VK_STENCIL_FACE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkStencilFaceFlagBits;
typedef VkFlags VkStencilFaceFlags;
typedef struct VkExtent2D {
    uint32_t width;
    uint32_t height;
} VkExtent2D;

typedef struct VkExtent3D {
    uint32_t width;
    uint32_t height;
    uint32_t depth;
} VkExtent3D;

typedef struct VkOffset2D {
    int32_t x;
    int32_t y;
} VkOffset2D;

typedef struct VkOffset3D {
    int32_t x;
    int32_t y;
    int32_t z;
} VkOffset3D;

typedef struct VkRect2D {
    VkOffset2D offset;
    VkExtent2D extent;
} VkRect2D;

typedef struct VkBaseInStructure {
    VkStructureType sType;
    const struct VkBaseInStructure* pNext;
} VkBaseInStructure;

typedef struct VkBaseOutStructure {
    VkStructureType sType;
    struct VkBaseOutStructure* pNext;
} VkBaseOutStructure;

typedef struct VkBufferMemoryBarrier {
    VkStructureType sType;
    const void* pNext;
    VkAccessFlags srcAccessMask;
    VkAccessFlags dstAccessMask;
    uint32_t srcQueueFamilyIndex;
    uint32_t dstQueueFamilyIndex;
    VkBuffer buffer;
    VkDeviceSize offset;
    VkDeviceSize size;
} VkBufferMemoryBarrier;

typedef struct VkDispatchIndirectCommand {
    uint32_t x;
    uint32_t y;
    uint32_t z;
} VkDispatchIndirectCommand;

typedef struct VkDrawIndexedIndirectCommand {
    uint32_t indexCount;
    uint32_t instanceCount;
    uint32_t firstIndex;
    int32_t vertexOffset;
    uint32_t firstInstance;
} VkDrawIndexedIndirectCommand;

typedef struct VkDrawIndirectCommand {
    uint32_t vertexCount;
    uint32_t instanceCount;
    uint32_t firstVertex;
    uint32_t firstInstance;
} VkDrawIndirectCommand;

typedef struct VkImageSubresourceRange {
    VkImageAspectFlags aspectMask;
    uint32_t baseMipLevel;
    uint32_t levelCount;
    uint32_t baseArrayLayer;
    uint32_t layerCount;
} VkImageSubresourceRange;

typedef struct VkImageMemoryBarrier {
    VkStructureType sType;
    const void* pNext;
    VkAccessFlags srcAccessMask;
    VkAccessFlags dstAccessMask;
    VkImageLayout oldLayout;
    VkImageLayout newLayout;
    uint32_t srcQueueFamilyIndex;
    uint32_t dstQueueFamilyIndex;
    VkImage image;
    VkImageSubresourceRange subresourceRange;
} VkImageMemoryBarrier;

typedef struct VkMemoryBarrier {
    VkStructureType sType;
    const void* pNext;
    VkAccessFlags srcAccessMask;
    VkAccessFlags dstAccessMask;
} VkMemoryBarrier;

typedef struct VkPipelineCacheHeaderVersionOne {
    uint32_t headerSize;
    VkPipelineCacheHeaderVersion headerVersion;
    uint32_t vendorID;
    uint32_t deviceID;
    uint8_t pipelineCacheUUID[16U];
} VkPipelineCacheHeaderVersionOne;

typedef void* (__attribute__((__stdcall__)) *PFN_vkAllocationFunction)(
    void* pUserData,
    size_t size,
    size_t alignment,
    VkSystemAllocationScope allocationScope);

typedef void (__attribute__((__stdcall__)) *PFN_vkFreeFunction)(
    void* pUserData,
    void* pMemory);

typedef void (__attribute__((__stdcall__)) *PFN_vkInternalAllocationNotification)(
    void* pUserData,
    size_t size,
    VkInternalAllocationType allocationType,
    VkSystemAllocationScope allocationScope);

typedef void (__attribute__((__stdcall__)) *PFN_vkInternalFreeNotification)(
    void* pUserData,
    size_t size,
    VkInternalAllocationType allocationType,
    VkSystemAllocationScope allocationScope);

typedef void* (__attribute__((__stdcall__)) *PFN_vkReallocationFunction)(
    void* pUserData,
    void* pOriginal,
    size_t size,
    size_t alignment,
    VkSystemAllocationScope allocationScope);

typedef void (__attribute__((__stdcall__)) *PFN_vkVoidFunction)(void);
typedef struct VkAllocationCallbacks {
    void* pUserData;
    PFN_vkAllocationFunction pfnAllocation;
    PFN_vkReallocationFunction pfnReallocation;
    PFN_vkFreeFunction pfnFree;
    PFN_vkInternalAllocationNotification pfnInternalAllocation;
    PFN_vkInternalFreeNotification pfnInternalFree;
} VkAllocationCallbacks;

typedef struct VkApplicationInfo {
    VkStructureType sType;
    const void* pNext;
    const char* pApplicationName;
    uint32_t applicationVersion;
    const char* pEngineName;
    uint32_t engineVersion;
    uint32_t apiVersion;
} VkApplicationInfo;

typedef struct VkFormatProperties {
    VkFormatFeatureFlags linearTilingFeatures;
    VkFormatFeatureFlags optimalTilingFeatures;
    VkFormatFeatureFlags bufferFeatures;
} VkFormatProperties;

typedef struct VkImageFormatProperties {
    VkExtent3D maxExtent;
    uint32_t maxMipLevels;
    uint32_t maxArrayLayers;
    VkSampleCountFlags sampleCounts;
    VkDeviceSize maxResourceSize;
} VkImageFormatProperties;

typedef struct VkInstanceCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkInstanceCreateFlags flags;
    const VkApplicationInfo* pApplicationInfo;
    uint32_t enabledLayerCount;
    const char* const* ppEnabledLayerNames;
    uint32_t enabledExtensionCount;
    const char* const* ppEnabledExtensionNames;
} VkInstanceCreateInfo;

typedef struct VkMemoryHeap {
    VkDeviceSize size;
    VkMemoryHeapFlags flags;
} VkMemoryHeap;

typedef struct VkMemoryType {
    VkMemoryPropertyFlags propertyFlags;
    uint32_t heapIndex;
} VkMemoryType;

typedef struct VkPhysicalDeviceFeatures {
    VkBool32 robustBufferAccess;
    VkBool32 fullDrawIndexUint32;
    VkBool32 imageCubeArray;
    VkBool32 independentBlend;
    VkBool32 geometryShader;
    VkBool32 tessellationShader;
    VkBool32 sampleRateShading;
    VkBool32 dualSrcBlend;
    VkBool32 logicOp;
    VkBool32 multiDrawIndirect;
    VkBool32 drawIndirectFirstInstance;
    VkBool32 depthClamp;
    VkBool32 depthBiasClamp;
    VkBool32 fillModeNonSolid;
    VkBool32 depthBounds;
    VkBool32 wideLines;
    VkBool32 largePoints;
    VkBool32 alphaToOne;
    VkBool32 multiViewport;
    VkBool32 samplerAnisotropy;
    VkBool32 textureCompressionETC2;
    VkBool32 textureCompressionASTC_LDR;
    VkBool32 textureCompressionBC;
    VkBool32 occlusionQueryPrecise;
    VkBool32 pipelineStatisticsQuery;
    VkBool32 vertexPipelineStoresAndAtomics;
    VkBool32 fragmentStoresAndAtomics;
    VkBool32 shaderTessellationAndGeometryPointSize;
    VkBool32 shaderImageGatherExtended;
    VkBool32 shaderStorageImageExtendedFormats;
    VkBool32 shaderStorageImageMultisample;
    VkBool32 shaderStorageImageReadWithoutFormat;
    VkBool32 shaderStorageImageWriteWithoutFormat;
    VkBool32 shaderUniformBufferArrayDynamicIndexing;
    VkBool32 shaderSampledImageArrayDynamicIndexing;
    VkBool32 shaderStorageBufferArrayDynamicIndexing;
    VkBool32 shaderStorageImageArrayDynamicIndexing;
    VkBool32 shaderClipDistance;
    VkBool32 shaderCullDistance;
    VkBool32 shaderFloat64;
    VkBool32 shaderInt64;
    VkBool32 shaderInt16;
    VkBool32 shaderResourceResidency;
    VkBool32 shaderResourceMinLod;
    VkBool32 sparseBinding;
    VkBool32 sparseResidencyBuffer;
    VkBool32 sparseResidencyImage2D;
    VkBool32 sparseResidencyImage3D;
    VkBool32 sparseResidency2Samples;
    VkBool32 sparseResidency4Samples;
    VkBool32 sparseResidency8Samples;
    VkBool32 sparseResidency16Samples;
    VkBool32 sparseResidencyAliased;
    VkBool32 variableMultisampleRate;
    VkBool32 inheritedQueries;
} VkPhysicalDeviceFeatures;

typedef struct VkPhysicalDeviceLimits {
    uint32_t maxImageDimension1D;
    uint32_t maxImageDimension2D;
    uint32_t maxImageDimension3D;
    uint32_t maxImageDimensionCube;
    uint32_t maxImageArrayLayers;
    uint32_t maxTexelBufferElements;
    uint32_t maxUniformBufferRange;
    uint32_t maxStorageBufferRange;
    uint32_t maxPushConstantsSize;
    uint32_t maxMemoryAllocationCount;
    uint32_t maxSamplerAllocationCount;
    VkDeviceSize bufferImageGranularity;
    VkDeviceSize sparseAddressSpaceSize;
    uint32_t maxBoundDescriptorSets;
    uint32_t maxPerStageDescriptorSamplers;
    uint32_t maxPerStageDescriptorUniformBuffers;
    uint32_t maxPerStageDescriptorStorageBuffers;
    uint32_t maxPerStageDescriptorSampledImages;
    uint32_t maxPerStageDescriptorStorageImages;
    uint32_t maxPerStageDescriptorInputAttachments;
    uint32_t maxPerStageResources;
    uint32_t maxDescriptorSetSamplers;
    uint32_t maxDescriptorSetUniformBuffers;
    uint32_t maxDescriptorSetUniformBuffersDynamic;
    uint32_t maxDescriptorSetStorageBuffers;
    uint32_t maxDescriptorSetStorageBuffersDynamic;
    uint32_t maxDescriptorSetSampledImages;
    uint32_t maxDescriptorSetStorageImages;
    uint32_t maxDescriptorSetInputAttachments;
    uint32_t maxVertexInputAttributes;
    uint32_t maxVertexInputBindings;
    uint32_t maxVertexInputAttributeOffset;
    uint32_t maxVertexInputBindingStride;
    uint32_t maxVertexOutputComponents;
    uint32_t maxTessellationGenerationLevel;
    uint32_t maxTessellationPatchSize;
    uint32_t maxTessellationControlPerVertexInputComponents;
    uint32_t maxTessellationControlPerVertexOutputComponents;
    uint32_t maxTessellationControlPerPatchOutputComponents;
    uint32_t maxTessellationControlTotalOutputComponents;
    uint32_t maxTessellationEvaluationInputComponents;
    uint32_t maxTessellationEvaluationOutputComponents;
    uint32_t maxGeometryShaderInvocations;
    uint32_t maxGeometryInputComponents;
    uint32_t maxGeometryOutputComponents;
    uint32_t maxGeometryOutputVertices;
    uint32_t maxGeometryTotalOutputComponents;
    uint32_t maxFragmentInputComponents;
    uint32_t maxFragmentOutputAttachments;
    uint32_t maxFragmentDualSrcAttachments;
    uint32_t maxFragmentCombinedOutputResources;
    uint32_t maxComputeSharedMemorySize;
    uint32_t maxComputeWorkGroupCount[3];
    uint32_t maxComputeWorkGroupInvocations;
    uint32_t maxComputeWorkGroupSize[3];
    uint32_t subPixelPrecisionBits;
    uint32_t subTexelPrecisionBits;
    uint32_t mipmapPrecisionBits;
    uint32_t maxDrawIndexedIndexValue;
    uint32_t maxDrawIndirectCount;
    float maxSamplerLodBias;
    float maxSamplerAnisotropy;
    uint32_t maxViewports;
    uint32_t maxViewportDimensions[2];
    float viewportBoundsRange[2];
    uint32_t viewportSubPixelBits;
    size_t minMemoryMapAlignment;
    VkDeviceSize minTexelBufferOffsetAlignment;
    VkDeviceSize minUniformBufferOffsetAlignment;
    VkDeviceSize minStorageBufferOffsetAlignment;
    int32_t minTexelOffset;
    uint32_t maxTexelOffset;
    int32_t minTexelGatherOffset;
    uint32_t maxTexelGatherOffset;
    float minInterpolationOffset;
    float maxInterpolationOffset;
    uint32_t subPixelInterpolationOffsetBits;
    uint32_t maxFramebufferWidth;
    uint32_t maxFramebufferHeight;
    uint32_t maxFramebufferLayers;
    VkSampleCountFlags framebufferColorSampleCounts;
    VkSampleCountFlags framebufferDepthSampleCounts;
    VkSampleCountFlags framebufferStencilSampleCounts;
    VkSampleCountFlags framebufferNoAttachmentsSampleCounts;
    uint32_t maxColorAttachments;
    VkSampleCountFlags sampledImageColorSampleCounts;
    VkSampleCountFlags sampledImageIntegerSampleCounts;
    VkSampleCountFlags sampledImageDepthSampleCounts;
    VkSampleCountFlags sampledImageStencilSampleCounts;
    VkSampleCountFlags storageImageSampleCounts;
    uint32_t maxSampleMaskWords;
    VkBool32 timestampComputeAndGraphics;
    float timestampPeriod;
    uint32_t maxClipDistances;
    uint32_t maxCullDistances;
    uint32_t maxCombinedClipAndCullDistances;
    uint32_t discreteQueuePriorities;
    float pointSizeRange[2];
    float lineWidthRange[2];
    float pointSizeGranularity;
    float lineWidthGranularity;
    VkBool32 strictLines;
    VkBool32 standardSampleLocations;
    VkDeviceSize optimalBufferCopyOffsetAlignment;
    VkDeviceSize optimalBufferCopyRowPitchAlignment;
    VkDeviceSize nonCoherentAtomSize;
} VkPhysicalDeviceLimits;

typedef struct VkPhysicalDeviceMemoryProperties {
    uint32_t memoryTypeCount;
    VkMemoryType memoryTypes[32U];
    uint32_t memoryHeapCount;
    VkMemoryHeap memoryHeaps[16U];
} VkPhysicalDeviceMemoryProperties;

typedef struct VkPhysicalDeviceSparseProperties {
    VkBool32 residencyStandard2DBlockShape;
    VkBool32 residencyStandard2DMultisampleBlockShape;
    VkBool32 residencyStandard3DBlockShape;
    VkBool32 residencyAlignedMipSize;
    VkBool32 residencyNonResidentStrict;
} VkPhysicalDeviceSparseProperties;

typedef struct VkPhysicalDeviceProperties {
    uint32_t apiVersion;
    uint32_t driverVersion;
    uint32_t vendorID;
    uint32_t deviceID;
    VkPhysicalDeviceType deviceType;
    char deviceName[256U];
    uint8_t pipelineCacheUUID[16U];
    VkPhysicalDeviceLimits limits;
    VkPhysicalDeviceSparseProperties sparseProperties;
} VkPhysicalDeviceProperties;

typedef struct VkQueueFamilyProperties {
    VkQueueFlags queueFlags;
    uint32_t queueCount;
    uint32_t timestampValidBits;
    VkExtent3D minImageTransferGranularity;
} VkQueueFamilyProperties;

typedef struct VkDeviceQueueCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkDeviceQueueCreateFlags flags;
    uint32_t queueFamilyIndex;
    uint32_t queueCount;
    const float* pQueuePriorities;
} VkDeviceQueueCreateInfo;

typedef struct VkDeviceCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkDeviceCreateFlags flags;
    uint32_t queueCreateInfoCount;
    const VkDeviceQueueCreateInfo* pQueueCreateInfos;

    uint32_t enabledLayerCount;

    const char* const* ppEnabledLayerNames;
    uint32_t enabledExtensionCount;
    const char* const* ppEnabledExtensionNames;
    const VkPhysicalDeviceFeatures* pEnabledFeatures;
} VkDeviceCreateInfo;

typedef struct VkExtensionProperties {
    char extensionName[256U];
    uint32_t specVersion;
} VkExtensionProperties;

typedef struct VkLayerProperties {
    char layerName[256U];
    uint32_t specVersion;
    uint32_t implementationVersion;
    char description[256U];
} VkLayerProperties;

typedef struct VkSubmitInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t waitSemaphoreCount;
    const VkSemaphore* pWaitSemaphores;
    const VkPipelineStageFlags* pWaitDstStageMask;
    uint32_t commandBufferCount;
    const VkCommandBuffer* pCommandBuffers;
    uint32_t signalSemaphoreCount;
    const VkSemaphore* pSignalSemaphores;
} VkSubmitInfo;

typedef struct VkMappedMemoryRange {
    VkStructureType sType;
    const void* pNext;
    VkDeviceMemory memory;
    VkDeviceSize offset;
    VkDeviceSize size;
} VkMappedMemoryRange;

typedef struct VkMemoryAllocateInfo {
    VkStructureType sType;
    const void* pNext;
    VkDeviceSize allocationSize;
    uint32_t memoryTypeIndex;
} VkMemoryAllocateInfo;

typedef struct VkMemoryRequirements {
    VkDeviceSize size;
    VkDeviceSize alignment;
    uint32_t memoryTypeBits;
} VkMemoryRequirements;

typedef struct VkSparseMemoryBind {
    VkDeviceSize resourceOffset;
    VkDeviceSize size;
    VkDeviceMemory memory;
    VkDeviceSize memoryOffset;
    VkSparseMemoryBindFlags flags;
} VkSparseMemoryBind;

typedef struct VkSparseBufferMemoryBindInfo {
    VkBuffer buffer;
    uint32_t bindCount;
    const VkSparseMemoryBind* pBinds;
} VkSparseBufferMemoryBindInfo;

typedef struct VkSparseImageOpaqueMemoryBindInfo {
    VkImage image;
    uint32_t bindCount;
    const VkSparseMemoryBind* pBinds;
} VkSparseImageOpaqueMemoryBindInfo;

typedef struct VkImageSubresource {
    VkImageAspectFlags aspectMask;
    uint32_t mipLevel;
    uint32_t arrayLayer;
} VkImageSubresource;

typedef struct VkSparseImageMemoryBind {
    VkImageSubresource subresource;
    VkOffset3D offset;
    VkExtent3D extent;
    VkDeviceMemory memory;
    VkDeviceSize memoryOffset;
    VkSparseMemoryBindFlags flags;
} VkSparseImageMemoryBind;

typedef struct VkSparseImageMemoryBindInfo {
    VkImage image;
    uint32_t bindCount;
    const VkSparseImageMemoryBind* pBinds;
} VkSparseImageMemoryBindInfo;

typedef struct VkBindSparseInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t waitSemaphoreCount;
    const VkSemaphore* pWaitSemaphores;
    uint32_t bufferBindCount;
    const VkSparseBufferMemoryBindInfo* pBufferBinds;
    uint32_t imageOpaqueBindCount;
    const VkSparseImageOpaqueMemoryBindInfo* pImageOpaqueBinds;
    uint32_t imageBindCount;
    const VkSparseImageMemoryBindInfo* pImageBinds;
    uint32_t signalSemaphoreCount;
    const VkSemaphore* pSignalSemaphores;
} VkBindSparseInfo;

typedef struct VkSparseImageFormatProperties {
    VkImageAspectFlags aspectMask;
    VkExtent3D imageGranularity;
    VkSparseImageFormatFlags flags;
} VkSparseImageFormatProperties;

typedef struct VkSparseImageMemoryRequirements {
    VkSparseImageFormatProperties formatProperties;
    uint32_t imageMipTailFirstLod;
    VkDeviceSize imageMipTailSize;
    VkDeviceSize imageMipTailOffset;
    VkDeviceSize imageMipTailStride;
} VkSparseImageMemoryRequirements;

typedef struct VkFenceCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkFenceCreateFlags flags;
} VkFenceCreateInfo;

typedef struct VkSemaphoreCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkSemaphoreCreateFlags flags;
} VkSemaphoreCreateInfo;

typedef struct VkEventCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkEventCreateFlags flags;
} VkEventCreateInfo;

typedef struct VkQueryPoolCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkQueryPoolCreateFlags flags;
    VkQueryType queryType;
    uint32_t queryCount;
    VkQueryPipelineStatisticFlags pipelineStatistics;
} VkQueryPoolCreateInfo;

typedef struct VkBufferCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkBufferCreateFlags flags;
    VkDeviceSize size;
    VkBufferUsageFlags usage;
    VkSharingMode sharingMode;
    uint32_t queueFamilyIndexCount;
    const uint32_t* pQueueFamilyIndices;
} VkBufferCreateInfo;

typedef struct VkBufferViewCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkBufferViewCreateFlags flags;
    VkBuffer buffer;
    VkFormat format;
    VkDeviceSize offset;
    VkDeviceSize range;
} VkBufferViewCreateInfo;

typedef struct VkImageCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkImageCreateFlags flags;
    VkImageType imageType;
    VkFormat format;
    VkExtent3D extent;
    uint32_t mipLevels;
    uint32_t arrayLayers;
    VkSampleCountFlagBits samples;
    VkImageTiling tiling;
    VkImageUsageFlags usage;
    VkSharingMode sharingMode;
    uint32_t queueFamilyIndexCount;
    const uint32_t* pQueueFamilyIndices;
    VkImageLayout initialLayout;
} VkImageCreateInfo;

typedef struct VkSubresourceLayout {
    VkDeviceSize offset;
    VkDeviceSize size;
    VkDeviceSize rowPitch;
    VkDeviceSize arrayPitch;
    VkDeviceSize depthPitch;
} VkSubresourceLayout;

typedef struct VkComponentMapping {
    VkComponentSwizzle r;
    VkComponentSwizzle g;
    VkComponentSwizzle b;
    VkComponentSwizzle a;
} VkComponentMapping;

typedef struct VkImageViewCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkImageViewCreateFlags flags;
    VkImage image;
    VkImageViewType viewType;
    VkFormat format;
    VkComponentMapping components;
    VkImageSubresourceRange subresourceRange;
} VkImageViewCreateInfo;

typedef struct VkShaderModuleCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkShaderModuleCreateFlags flags;
    size_t codeSize;
    const uint32_t* pCode;
} VkShaderModuleCreateInfo;

typedef struct VkPipelineCacheCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkPipelineCacheCreateFlags flags;
    size_t initialDataSize;
    const void* pInitialData;
} VkPipelineCacheCreateInfo;

typedef struct VkSpecializationMapEntry {
    uint32_t constantID;
    uint32_t offset;
    size_t size;
} VkSpecializationMapEntry;

typedef struct VkSpecializationInfo {
    uint32_t mapEntryCount;
    const VkSpecializationMapEntry* pMapEntries;
    size_t dataSize;
    const void* pData;
} VkSpecializationInfo;

typedef struct VkPipelineShaderStageCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkPipelineShaderStageCreateFlags flags;
    VkShaderStageFlagBits stage;
    VkShaderModule module;
    const char* pName;
    const VkSpecializationInfo* pSpecializationInfo;
} VkPipelineShaderStageCreateInfo;

typedef struct VkComputePipelineCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkPipelineCreateFlags flags;
    VkPipelineShaderStageCreateInfo stage;
    VkPipelineLayout layout;
    VkPipeline basePipelineHandle;
    int32_t basePipelineIndex;
} VkComputePipelineCreateInfo;

typedef struct VkVertexInputBindingDescription {
    uint32_t binding;
    uint32_t stride;
    VkVertexInputRate inputRate;
} VkVertexInputBindingDescription;

typedef struct VkVertexInputAttributeDescription {
    uint32_t location;
    uint32_t binding;
    VkFormat format;
    uint32_t offset;
} VkVertexInputAttributeDescription;

typedef struct VkPipelineVertexInputStateCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkPipelineVertexInputStateCreateFlags flags;
    uint32_t vertexBindingDescriptionCount;
    const VkVertexInputBindingDescription* pVertexBindingDescriptions;
    uint32_t vertexAttributeDescriptionCount;
    const VkVertexInputAttributeDescription* pVertexAttributeDescriptions;
} VkPipelineVertexInputStateCreateInfo;

typedef struct VkPipelineInputAssemblyStateCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkPipelineInputAssemblyStateCreateFlags flags;
    VkPrimitiveTopology topology;
    VkBool32 primitiveRestartEnable;
} VkPipelineInputAssemblyStateCreateInfo;

typedef struct VkPipelineTessellationStateCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkPipelineTessellationStateCreateFlags flags;
    uint32_t patchControlPoints;
} VkPipelineTessellationStateCreateInfo;

typedef struct VkViewport {
    float x;
    float y;
    float width;
    float height;
    float minDepth;
    float maxDepth;
} VkViewport;

typedef struct VkPipelineViewportStateCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkPipelineViewportStateCreateFlags flags;
    uint32_t viewportCount;
    const VkViewport* pViewports;
    uint32_t scissorCount;
    const VkRect2D* pScissors;
} VkPipelineViewportStateCreateInfo;

typedef struct VkPipelineRasterizationStateCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkPipelineRasterizationStateCreateFlags flags;
    VkBool32 depthClampEnable;
    VkBool32 rasterizerDiscardEnable;
    VkPolygonMode polygonMode;
    VkCullModeFlags cullMode;
    VkFrontFace frontFace;
    VkBool32 depthBiasEnable;
    float depthBiasConstantFactor;
    float depthBiasClamp;
    float depthBiasSlopeFactor;
    float lineWidth;
} VkPipelineRasterizationStateCreateInfo;

typedef struct VkPipelineMultisampleStateCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkPipelineMultisampleStateCreateFlags flags;
    VkSampleCountFlagBits rasterizationSamples;
    VkBool32 sampleShadingEnable;
    float minSampleShading;
    const VkSampleMask* pSampleMask;
    VkBool32 alphaToCoverageEnable;
    VkBool32 alphaToOneEnable;
} VkPipelineMultisampleStateCreateInfo;

typedef struct VkStencilOpState {
    VkStencilOp failOp;
    VkStencilOp passOp;
    VkStencilOp depthFailOp;
    VkCompareOp compareOp;
    uint32_t compareMask;
    uint32_t writeMask;
    uint32_t reference;
} VkStencilOpState;

typedef struct VkPipelineDepthStencilStateCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkPipelineDepthStencilStateCreateFlags flags;
    VkBool32 depthTestEnable;
    VkBool32 depthWriteEnable;
    VkCompareOp depthCompareOp;
    VkBool32 depthBoundsTestEnable;
    VkBool32 stencilTestEnable;
    VkStencilOpState front;
    VkStencilOpState back;
    float minDepthBounds;
    float maxDepthBounds;
} VkPipelineDepthStencilStateCreateInfo;

typedef struct VkPipelineColorBlendAttachmentState {
    VkBool32 blendEnable;
    VkBlendFactor srcColorBlendFactor;
    VkBlendFactor dstColorBlendFactor;
    VkBlendOp colorBlendOp;
    VkBlendFactor srcAlphaBlendFactor;
    VkBlendFactor dstAlphaBlendFactor;
    VkBlendOp alphaBlendOp;
    VkColorComponentFlags colorWriteMask;
} VkPipelineColorBlendAttachmentState;

typedef struct VkPipelineColorBlendStateCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkPipelineColorBlendStateCreateFlags flags;
    VkBool32 logicOpEnable;
    VkLogicOp logicOp;
    uint32_t attachmentCount;
    const VkPipelineColorBlendAttachmentState* pAttachments;
    float blendConstants[4];
} VkPipelineColorBlendStateCreateInfo;

typedef struct VkPipelineDynamicStateCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkPipelineDynamicStateCreateFlags flags;
    uint32_t dynamicStateCount;
    const VkDynamicState* pDynamicStates;
} VkPipelineDynamicStateCreateInfo;

typedef struct VkGraphicsPipelineCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkPipelineCreateFlags flags;
    uint32_t stageCount;
    const VkPipelineShaderStageCreateInfo* pStages;
    const VkPipelineVertexInputStateCreateInfo* pVertexInputState;
    const VkPipelineInputAssemblyStateCreateInfo* pInputAssemblyState;
    const VkPipelineTessellationStateCreateInfo* pTessellationState;
    const VkPipelineViewportStateCreateInfo* pViewportState;
    const VkPipelineRasterizationStateCreateInfo* pRasterizationState;
    const VkPipelineMultisampleStateCreateInfo* pMultisampleState;
    const VkPipelineDepthStencilStateCreateInfo* pDepthStencilState;
    const VkPipelineColorBlendStateCreateInfo* pColorBlendState;
    const VkPipelineDynamicStateCreateInfo* pDynamicState;
    VkPipelineLayout layout;
    VkRenderPass renderPass;
    uint32_t subpass;
    VkPipeline basePipelineHandle;
    int32_t basePipelineIndex;
} VkGraphicsPipelineCreateInfo;

typedef struct VkPushConstantRange {
    VkShaderStageFlags stageFlags;
    uint32_t offset;
    uint32_t size;
} VkPushConstantRange;

typedef struct VkPipelineLayoutCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkPipelineLayoutCreateFlags flags;
    uint32_t setLayoutCount;
    const VkDescriptorSetLayout* pSetLayouts;
    uint32_t pushConstantRangeCount;
    const VkPushConstantRange* pPushConstantRanges;
} VkPipelineLayoutCreateInfo;

typedef struct VkSamplerCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkSamplerCreateFlags flags;
    VkFilter magFilter;
    VkFilter minFilter;
    VkSamplerMipmapMode mipmapMode;
    VkSamplerAddressMode addressModeU;
    VkSamplerAddressMode addressModeV;
    VkSamplerAddressMode addressModeW;
    float mipLodBias;
    VkBool32 anisotropyEnable;
    float maxAnisotropy;
    VkBool32 compareEnable;
    VkCompareOp compareOp;
    float minLod;
    float maxLod;
    VkBorderColor borderColor;
    VkBool32 unnormalizedCoordinates;
} VkSamplerCreateInfo;

typedef struct VkCopyDescriptorSet {
    VkStructureType sType;
    const void* pNext;
    VkDescriptorSet srcSet;
    uint32_t srcBinding;
    uint32_t srcArrayElement;
    VkDescriptorSet dstSet;
    uint32_t dstBinding;
    uint32_t dstArrayElement;
    uint32_t descriptorCount;
} VkCopyDescriptorSet;

typedef struct VkDescriptorBufferInfo {
    VkBuffer buffer;
    VkDeviceSize offset;
    VkDeviceSize range;
} VkDescriptorBufferInfo;

typedef struct VkDescriptorImageInfo {
    VkSampler sampler;
    VkImageView imageView;
    VkImageLayout imageLayout;
} VkDescriptorImageInfo;

typedef struct VkDescriptorPoolSize {
    VkDescriptorType type;
    uint32_t descriptorCount;
} VkDescriptorPoolSize;

typedef struct VkDescriptorPoolCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkDescriptorPoolCreateFlags flags;
    uint32_t maxSets;
    uint32_t poolSizeCount;
    const VkDescriptorPoolSize* pPoolSizes;
} VkDescriptorPoolCreateInfo;

typedef struct VkDescriptorSetAllocateInfo {
    VkStructureType sType;
    const void* pNext;
    VkDescriptorPool descriptorPool;
    uint32_t descriptorSetCount;
    const VkDescriptorSetLayout* pSetLayouts;
} VkDescriptorSetAllocateInfo;

typedef struct VkDescriptorSetLayoutBinding {
    uint32_t binding;
    VkDescriptorType descriptorType;
    uint32_t descriptorCount;
    VkShaderStageFlags stageFlags;
    const VkSampler* pImmutableSamplers;
} VkDescriptorSetLayoutBinding;

typedef struct VkDescriptorSetLayoutCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkDescriptorSetLayoutCreateFlags flags;
    uint32_t bindingCount;
    const VkDescriptorSetLayoutBinding* pBindings;
} VkDescriptorSetLayoutCreateInfo;

typedef struct VkWriteDescriptorSet {
    VkStructureType sType;
    const void* pNext;
    VkDescriptorSet dstSet;
    uint32_t dstBinding;
    uint32_t dstArrayElement;
    uint32_t descriptorCount;
    VkDescriptorType descriptorType;
    const VkDescriptorImageInfo* pImageInfo;
    const VkDescriptorBufferInfo* pBufferInfo;
    const VkBufferView* pTexelBufferView;
} VkWriteDescriptorSet;

typedef struct VkAttachmentDescription {
    VkAttachmentDescriptionFlags flags;
    VkFormat format;
    VkSampleCountFlagBits samples;
    VkAttachmentLoadOp loadOp;
    VkAttachmentStoreOp storeOp;
    VkAttachmentLoadOp stencilLoadOp;
    VkAttachmentStoreOp stencilStoreOp;
    VkImageLayout initialLayout;
    VkImageLayout finalLayout;
} VkAttachmentDescription;

typedef struct VkAttachmentReference {
    uint32_t attachment;
    VkImageLayout layout;
} VkAttachmentReference;

typedef struct VkFramebufferCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkFramebufferCreateFlags flags;
    VkRenderPass renderPass;
    uint32_t attachmentCount;
    const VkImageView* pAttachments;
    uint32_t width;
    uint32_t height;
    uint32_t layers;
} VkFramebufferCreateInfo;

typedef struct VkSubpassDescription {
    VkSubpassDescriptionFlags flags;
    VkPipelineBindPoint pipelineBindPoint;
    uint32_t inputAttachmentCount;
    const VkAttachmentReference* pInputAttachments;
    uint32_t colorAttachmentCount;
    const VkAttachmentReference* pColorAttachments;
    const VkAttachmentReference* pResolveAttachments;
    const VkAttachmentReference* pDepthStencilAttachment;
    uint32_t preserveAttachmentCount;
    const uint32_t* pPreserveAttachments;
} VkSubpassDescription;

typedef struct VkSubpassDependency {
    uint32_t srcSubpass;
    uint32_t dstSubpass;
    VkPipelineStageFlags srcStageMask;
    VkPipelineStageFlags dstStageMask;
    VkAccessFlags srcAccessMask;
    VkAccessFlags dstAccessMask;
    VkDependencyFlags dependencyFlags;
} VkSubpassDependency;

typedef struct VkRenderPassCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkRenderPassCreateFlags flags;
    uint32_t attachmentCount;
    const VkAttachmentDescription* pAttachments;
    uint32_t subpassCount;
    const VkSubpassDescription* pSubpasses;
    uint32_t dependencyCount;
    const VkSubpassDependency* pDependencies;
} VkRenderPassCreateInfo;

typedef struct VkCommandPoolCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkCommandPoolCreateFlags flags;
    uint32_t queueFamilyIndex;
} VkCommandPoolCreateInfo;

typedef struct VkCommandBufferAllocateInfo {
    VkStructureType sType;
    const void* pNext;
    VkCommandPool commandPool;
    VkCommandBufferLevel level;
    uint32_t commandBufferCount;
} VkCommandBufferAllocateInfo;

typedef struct VkCommandBufferInheritanceInfo {
    VkStructureType sType;
    const void* pNext;
    VkRenderPass renderPass;
    uint32_t subpass;
    VkFramebuffer framebuffer;
    VkBool32 occlusionQueryEnable;
    VkQueryControlFlags queryFlags;
    VkQueryPipelineStatisticFlags pipelineStatistics;
} VkCommandBufferInheritanceInfo;

typedef struct VkCommandBufferBeginInfo {
    VkStructureType sType;
    const void* pNext;
    VkCommandBufferUsageFlags flags;
    const VkCommandBufferInheritanceInfo* pInheritanceInfo;
} VkCommandBufferBeginInfo;

typedef struct VkBufferCopy {
    VkDeviceSize srcOffset;
    VkDeviceSize dstOffset;
    VkDeviceSize size;
} VkBufferCopy;

typedef struct VkImageSubresourceLayers {
    VkImageAspectFlags aspectMask;
    uint32_t mipLevel;
    uint32_t baseArrayLayer;
    uint32_t layerCount;
} VkImageSubresourceLayers;

typedef struct VkBufferImageCopy {
    VkDeviceSize bufferOffset;
    uint32_t bufferRowLength;
    uint32_t bufferImageHeight;
    VkImageSubresourceLayers imageSubresource;
    VkOffset3D imageOffset;
    VkExtent3D imageExtent;
} VkBufferImageCopy;

typedef union VkClearColorValue {
    float float32[4];
    int32_t int32[4];
    uint32_t uint32[4];
} VkClearColorValue;

typedef struct VkClearDepthStencilValue {
    float depth;
    uint32_t stencil;
} VkClearDepthStencilValue;

typedef union VkClearValue {
    VkClearColorValue color;
    VkClearDepthStencilValue depthStencil;
} VkClearValue;

typedef struct VkClearAttachment {
    VkImageAspectFlags aspectMask;
    uint32_t colorAttachment;
    VkClearValue clearValue;
} VkClearAttachment;

typedef struct VkClearRect {
    VkRect2D rect;
    uint32_t baseArrayLayer;
    uint32_t layerCount;
} VkClearRect;

typedef struct VkImageBlit {
    VkImageSubresourceLayers srcSubresource;
    VkOffset3D srcOffsets[2];
    VkImageSubresourceLayers dstSubresource;
    VkOffset3D dstOffsets[2];
} VkImageBlit;

typedef struct VkImageCopy {
    VkImageSubresourceLayers srcSubresource;
    VkOffset3D srcOffset;
    VkImageSubresourceLayers dstSubresource;
    VkOffset3D dstOffset;
    VkExtent3D extent;
} VkImageCopy;

typedef struct VkImageResolve {
    VkImageSubresourceLayers srcSubresource;
    VkOffset3D srcOffset;
    VkImageSubresourceLayers dstSubresource;
    VkOffset3D dstOffset;
    VkExtent3D extent;
} VkImageResolve;

typedef struct VkRenderPassBeginInfo {
    VkStructureType sType;
    const void* pNext;
    VkRenderPass renderPass;
    VkFramebuffer framebuffer;
    VkRect2D renderArea;
    uint32_t clearValueCount;
    const VkClearValue* pClearValues;
} VkRenderPassBeginInfo;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateInstance)(const VkInstanceCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkInstance* pInstance);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyInstance)(VkInstance instance, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkEnumeratePhysicalDevices)(VkInstance instance, uint32_t* pPhysicalDeviceCount, VkPhysicalDevice* pPhysicalDevices);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceFeatures)(VkPhysicalDevice physicalDevice, VkPhysicalDeviceFeatures* pFeatures);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceFormatProperties)(VkPhysicalDevice physicalDevice, VkFormat format, VkFormatProperties* pFormatProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceImageFormatProperties)(VkPhysicalDevice physicalDevice, VkFormat format, VkImageType type, VkImageTiling tiling, VkImageUsageFlags usage, VkImageCreateFlags flags, VkImageFormatProperties* pImageFormatProperties);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceProperties)(VkPhysicalDevice physicalDevice, VkPhysicalDeviceProperties* pProperties);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceQueueFamilyProperties)(VkPhysicalDevice physicalDevice, uint32_t* pQueueFamilyPropertyCount, VkQueueFamilyProperties* pQueueFamilyProperties);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceMemoryProperties)(VkPhysicalDevice physicalDevice, VkPhysicalDeviceMemoryProperties* pMemoryProperties);
typedef PFN_vkVoidFunction (__attribute__((__stdcall__)) *PFN_vkGetInstanceProcAddr)(VkInstance instance, const char* pName);
typedef PFN_vkVoidFunction (__attribute__((__stdcall__)) *PFN_vkGetDeviceProcAddr)(VkDevice device, const char* pName);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateDevice)(VkPhysicalDevice physicalDevice, const VkDeviceCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDevice* pDevice);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyDevice)(VkDevice device, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkEnumerateInstanceExtensionProperties)(const char* pLayerName, uint32_t* pPropertyCount, VkExtensionProperties* pProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkEnumerateDeviceExtensionProperties)(VkPhysicalDevice physicalDevice, const char* pLayerName, uint32_t* pPropertyCount, VkExtensionProperties* pProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkEnumerateInstanceLayerProperties)(uint32_t* pPropertyCount, VkLayerProperties* pProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkEnumerateDeviceLayerProperties)(VkPhysicalDevice physicalDevice, uint32_t* pPropertyCount, VkLayerProperties* pProperties);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetDeviceQueue)(VkDevice device, uint32_t queueFamilyIndex, uint32_t queueIndex, VkQueue* pQueue);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkQueueSubmit)(VkQueue queue, uint32_t submitCount, const VkSubmitInfo* pSubmits, VkFence fence);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkQueueWaitIdle)(VkQueue queue);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkDeviceWaitIdle)(VkDevice device);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkAllocateMemory)(VkDevice device, const VkMemoryAllocateInfo* pAllocateInfo, const VkAllocationCallbacks* pAllocator, VkDeviceMemory* pMemory);
typedef void (__attribute__((__stdcall__)) *PFN_vkFreeMemory)(VkDevice device, VkDeviceMemory memory, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkMapMemory)(VkDevice device, VkDeviceMemory memory, VkDeviceSize offset, VkDeviceSize size, VkMemoryMapFlags flags, void** ppData);
typedef void (__attribute__((__stdcall__)) *PFN_vkUnmapMemory)(VkDevice device, VkDeviceMemory memory);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkFlushMappedMemoryRanges)(VkDevice device, uint32_t memoryRangeCount, const VkMappedMemoryRange* pMemoryRanges);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkInvalidateMappedMemoryRanges)(VkDevice device, uint32_t memoryRangeCount, const VkMappedMemoryRange* pMemoryRanges);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetDeviceMemoryCommitment)(VkDevice device, VkDeviceMemory memory, VkDeviceSize* pCommittedMemoryInBytes);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkBindBufferMemory)(VkDevice device, VkBuffer buffer, VkDeviceMemory memory, VkDeviceSize memoryOffset);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkBindImageMemory)(VkDevice device, VkImage image, VkDeviceMemory memory, VkDeviceSize memoryOffset);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetBufferMemoryRequirements)(VkDevice device, VkBuffer buffer, VkMemoryRequirements* pMemoryRequirements);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetImageMemoryRequirements)(VkDevice device, VkImage image, VkMemoryRequirements* pMemoryRequirements);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetImageSparseMemoryRequirements)(VkDevice device, VkImage image, uint32_t* pSparseMemoryRequirementCount, VkSparseImageMemoryRequirements* pSparseMemoryRequirements);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceSparseImageFormatProperties)(VkPhysicalDevice physicalDevice, VkFormat format, VkImageType type, VkSampleCountFlagBits samples, VkImageUsageFlags usage, VkImageTiling tiling, uint32_t* pPropertyCount, VkSparseImageFormatProperties* pProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkQueueBindSparse)(VkQueue queue, uint32_t bindInfoCount, const VkBindSparseInfo* pBindInfo, VkFence fence);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateFence)(VkDevice device, const VkFenceCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkFence* pFence);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyFence)(VkDevice device, VkFence fence, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkResetFences)(VkDevice device, uint32_t fenceCount, const VkFence* pFences);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetFenceStatus)(VkDevice device, VkFence fence);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkWaitForFences)(VkDevice device, uint32_t fenceCount, const VkFence* pFences, VkBool32 waitAll, uint64_t timeout);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateSemaphore)(VkDevice device, const VkSemaphoreCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSemaphore* pSemaphore);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroySemaphore)(VkDevice device, VkSemaphore semaphore, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateEvent)(VkDevice device, const VkEventCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkEvent* pEvent);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyEvent)(VkDevice device, VkEvent event, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetEventStatus)(VkDevice device, VkEvent event);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkSetEvent)(VkDevice device, VkEvent event);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkResetEvent)(VkDevice device, VkEvent event);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateQueryPool)(VkDevice device, const VkQueryPoolCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkQueryPool* pQueryPool);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyQueryPool)(VkDevice device, VkQueryPool queryPool, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetQueryPoolResults)(VkDevice device, VkQueryPool queryPool, uint32_t firstQuery, uint32_t queryCount, size_t dataSize, void* pData, VkDeviceSize stride, VkQueryResultFlags flags);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateBuffer)(VkDevice device, const VkBufferCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkBuffer* pBuffer);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyBuffer)(VkDevice device, VkBuffer buffer, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateBufferView)(VkDevice device, const VkBufferViewCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkBufferView* pView);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyBufferView)(VkDevice device, VkBufferView bufferView, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateImage)(VkDevice device, const VkImageCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkImage* pImage);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyImage)(VkDevice device, VkImage image, const VkAllocationCallbacks* pAllocator);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetImageSubresourceLayout)(VkDevice device, VkImage image, const VkImageSubresource* pSubresource, VkSubresourceLayout* pLayout);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateImageView)(VkDevice device, const VkImageViewCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkImageView* pView);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyImageView)(VkDevice device, VkImageView imageView, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateShaderModule)(VkDevice device, const VkShaderModuleCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkShaderModule* pShaderModule);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyShaderModule)(VkDevice device, VkShaderModule shaderModule, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreatePipelineCache)(VkDevice device, const VkPipelineCacheCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkPipelineCache* pPipelineCache);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyPipelineCache)(VkDevice device, VkPipelineCache pipelineCache, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPipelineCacheData)(VkDevice device, VkPipelineCache pipelineCache, size_t* pDataSize, void* pData);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkMergePipelineCaches)(VkDevice device, VkPipelineCache dstCache, uint32_t srcCacheCount, const VkPipelineCache* pSrcCaches);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateGraphicsPipelines)(VkDevice device, VkPipelineCache pipelineCache, uint32_t createInfoCount, const VkGraphicsPipelineCreateInfo* pCreateInfos, const VkAllocationCallbacks* pAllocator, VkPipeline* pPipelines);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateComputePipelines)(VkDevice device, VkPipelineCache pipelineCache, uint32_t createInfoCount, const VkComputePipelineCreateInfo* pCreateInfos, const VkAllocationCallbacks* pAllocator, VkPipeline* pPipelines);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyPipeline)(VkDevice device, VkPipeline pipeline, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreatePipelineLayout)(VkDevice device, const VkPipelineLayoutCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkPipelineLayout* pPipelineLayout);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyPipelineLayout)(VkDevice device, VkPipelineLayout pipelineLayout, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateSampler)(VkDevice device, const VkSamplerCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSampler* pSampler);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroySampler)(VkDevice device, VkSampler sampler, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateDescriptorSetLayout)(VkDevice device, const VkDescriptorSetLayoutCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDescriptorSetLayout* pSetLayout);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyDescriptorSetLayout)(VkDevice device, VkDescriptorSetLayout descriptorSetLayout, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateDescriptorPool)(VkDevice device, const VkDescriptorPoolCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDescriptorPool* pDescriptorPool);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyDescriptorPool)(VkDevice device, VkDescriptorPool descriptorPool, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkResetDescriptorPool)(VkDevice device, VkDescriptorPool descriptorPool, VkDescriptorPoolResetFlags flags);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkAllocateDescriptorSets)(VkDevice device, const VkDescriptorSetAllocateInfo* pAllocateInfo, VkDescriptorSet* pDescriptorSets);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkFreeDescriptorSets)(VkDevice device, VkDescriptorPool descriptorPool, uint32_t descriptorSetCount, const VkDescriptorSet* pDescriptorSets);
typedef void (__attribute__((__stdcall__)) *PFN_vkUpdateDescriptorSets)(VkDevice device, uint32_t descriptorWriteCount, const VkWriteDescriptorSet* pDescriptorWrites, uint32_t descriptorCopyCount, const VkCopyDescriptorSet* pDescriptorCopies);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateFramebuffer)(VkDevice device, const VkFramebufferCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkFramebuffer* pFramebuffer);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyFramebuffer)(VkDevice device, VkFramebuffer framebuffer, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateRenderPass)(VkDevice device, const VkRenderPassCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkRenderPass* pRenderPass);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyRenderPass)(VkDevice device, VkRenderPass renderPass, const VkAllocationCallbacks* pAllocator);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetRenderAreaGranularity)(VkDevice device, VkRenderPass renderPass, VkExtent2D* pGranularity);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateCommandPool)(VkDevice device, const VkCommandPoolCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkCommandPool* pCommandPool);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyCommandPool)(VkDevice device, VkCommandPool commandPool, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkResetCommandPool)(VkDevice device, VkCommandPool commandPool, VkCommandPoolResetFlags flags);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkAllocateCommandBuffers)(VkDevice device, const VkCommandBufferAllocateInfo* pAllocateInfo, VkCommandBuffer* pCommandBuffers);
typedef void (__attribute__((__stdcall__)) *PFN_vkFreeCommandBuffers)(VkDevice device, VkCommandPool commandPool, uint32_t commandBufferCount, const VkCommandBuffer* pCommandBuffers);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkBeginCommandBuffer)(VkCommandBuffer commandBuffer, const VkCommandBufferBeginInfo* pBeginInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkEndCommandBuffer)(VkCommandBuffer commandBuffer);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkResetCommandBuffer)(VkCommandBuffer commandBuffer, VkCommandBufferResetFlags flags);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBindPipeline)(VkCommandBuffer commandBuffer, VkPipelineBindPoint pipelineBindPoint, VkPipeline pipeline);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetViewport)(VkCommandBuffer commandBuffer, uint32_t firstViewport, uint32_t viewportCount, const VkViewport* pViewports);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetScissor)(VkCommandBuffer commandBuffer, uint32_t firstScissor, uint32_t scissorCount, const VkRect2D* pScissors);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetLineWidth)(VkCommandBuffer commandBuffer, float lineWidth);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDepthBias)(VkCommandBuffer commandBuffer, float depthBiasConstantFactor, float depthBiasClamp, float depthBiasSlopeFactor);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetBlendConstants)(VkCommandBuffer commandBuffer, const float blendConstants[4]);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDepthBounds)(VkCommandBuffer commandBuffer, float minDepthBounds, float maxDepthBounds);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetStencilCompareMask)(VkCommandBuffer commandBuffer, VkStencilFaceFlags faceMask, uint32_t compareMask);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetStencilWriteMask)(VkCommandBuffer commandBuffer, VkStencilFaceFlags faceMask, uint32_t writeMask);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetStencilReference)(VkCommandBuffer commandBuffer, VkStencilFaceFlags faceMask, uint32_t reference);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBindDescriptorSets)(VkCommandBuffer commandBuffer, VkPipelineBindPoint pipelineBindPoint, VkPipelineLayout layout, uint32_t firstSet, uint32_t descriptorSetCount, const VkDescriptorSet* pDescriptorSets, uint32_t dynamicOffsetCount, const uint32_t* pDynamicOffsets);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBindIndexBuffer)(VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkIndexType indexType);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBindVertexBuffers)(VkCommandBuffer commandBuffer, uint32_t firstBinding, uint32_t bindingCount, const VkBuffer* pBuffers, const VkDeviceSize* pOffsets);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDraw)(VkCommandBuffer commandBuffer, uint32_t vertexCount, uint32_t instanceCount, uint32_t firstVertex, uint32_t firstInstance);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawIndexed)(VkCommandBuffer commandBuffer, uint32_t indexCount, uint32_t instanceCount, uint32_t firstIndex, int32_t vertexOffset, uint32_t firstInstance);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawIndirect)(VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, uint32_t drawCount, uint32_t stride);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawIndexedIndirect)(VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, uint32_t drawCount, uint32_t stride);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDispatch)(VkCommandBuffer commandBuffer, uint32_t groupCountX, uint32_t groupCountY, uint32_t groupCountZ);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDispatchIndirect)(VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyBuffer)(VkCommandBuffer commandBuffer, VkBuffer srcBuffer, VkBuffer dstBuffer, uint32_t regionCount, const VkBufferCopy* pRegions);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyImage)(VkCommandBuffer commandBuffer, VkImage srcImage, VkImageLayout srcImageLayout, VkImage dstImage, VkImageLayout dstImageLayout, uint32_t regionCount, const VkImageCopy* pRegions);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBlitImage)(VkCommandBuffer commandBuffer, VkImage srcImage, VkImageLayout srcImageLayout, VkImage dstImage, VkImageLayout dstImageLayout, uint32_t regionCount, const VkImageBlit* pRegions, VkFilter filter);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyBufferToImage)(VkCommandBuffer commandBuffer, VkBuffer srcBuffer, VkImage dstImage, VkImageLayout dstImageLayout, uint32_t regionCount, const VkBufferImageCopy* pRegions);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyImageToBuffer)(VkCommandBuffer commandBuffer, VkImage srcImage, VkImageLayout srcImageLayout, VkBuffer dstBuffer, uint32_t regionCount, const VkBufferImageCopy* pRegions);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdUpdateBuffer)(VkCommandBuffer commandBuffer, VkBuffer dstBuffer, VkDeviceSize dstOffset, VkDeviceSize dataSize, const void* pData);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdFillBuffer)(VkCommandBuffer commandBuffer, VkBuffer dstBuffer, VkDeviceSize dstOffset, VkDeviceSize size, uint32_t data);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdClearColorImage)(VkCommandBuffer commandBuffer, VkImage image, VkImageLayout imageLayout, const VkClearColorValue* pColor, uint32_t rangeCount, const VkImageSubresourceRange* pRanges);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdClearDepthStencilImage)(VkCommandBuffer commandBuffer, VkImage image, VkImageLayout imageLayout, const VkClearDepthStencilValue* pDepthStencil, uint32_t rangeCount, const VkImageSubresourceRange* pRanges);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdClearAttachments)(VkCommandBuffer commandBuffer, uint32_t attachmentCount, const VkClearAttachment* pAttachments, uint32_t rectCount, const VkClearRect* pRects);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdResolveImage)(VkCommandBuffer commandBuffer, VkImage srcImage, VkImageLayout srcImageLayout, VkImage dstImage, VkImageLayout dstImageLayout, uint32_t regionCount, const VkImageResolve* pRegions);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetEvent)(VkCommandBuffer commandBuffer, VkEvent event, VkPipelineStageFlags stageMask);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdResetEvent)(VkCommandBuffer commandBuffer, VkEvent event, VkPipelineStageFlags stageMask);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdWaitEvents)(VkCommandBuffer commandBuffer, uint32_t eventCount, const VkEvent* pEvents, VkPipelineStageFlags srcStageMask, VkPipelineStageFlags dstStageMask, uint32_t memoryBarrierCount, const VkMemoryBarrier* pMemoryBarriers, uint32_t bufferMemoryBarrierCount, const VkBufferMemoryBarrier* pBufferMemoryBarriers, uint32_t imageMemoryBarrierCount, const VkImageMemoryBarrier* pImageMemoryBarriers);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdPipelineBarrier)(VkCommandBuffer commandBuffer, VkPipelineStageFlags srcStageMask, VkPipelineStageFlags dstStageMask, VkDependencyFlags dependencyFlags, uint32_t memoryBarrierCount, const VkMemoryBarrier* pMemoryBarriers, uint32_t bufferMemoryBarrierCount, const VkBufferMemoryBarrier* pBufferMemoryBarriers, uint32_t imageMemoryBarrierCount, const VkImageMemoryBarrier* pImageMemoryBarriers);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBeginQuery)(VkCommandBuffer commandBuffer, VkQueryPool queryPool, uint32_t query, VkQueryControlFlags flags);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdEndQuery)(VkCommandBuffer commandBuffer, VkQueryPool queryPool, uint32_t query);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdResetQueryPool)(VkCommandBuffer commandBuffer, VkQueryPool queryPool, uint32_t firstQuery, uint32_t queryCount);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdWriteTimestamp)(VkCommandBuffer commandBuffer, VkPipelineStageFlagBits pipelineStage, VkQueryPool queryPool, uint32_t query);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyQueryPoolResults)(VkCommandBuffer commandBuffer, VkQueryPool queryPool, uint32_t firstQuery, uint32_t queryCount, VkBuffer dstBuffer, VkDeviceSize dstOffset, VkDeviceSize stride, VkQueryResultFlags flags);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdPushConstants)(VkCommandBuffer commandBuffer, VkPipelineLayout layout, VkShaderStageFlags stageFlags, uint32_t offset, uint32_t size, const void* pValues);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBeginRenderPass)(VkCommandBuffer commandBuffer, const VkRenderPassBeginInfo* pRenderPassBegin, VkSubpassContents contents);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdNextSubpass)(VkCommandBuffer commandBuffer, VkSubpassContents contents);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdEndRenderPass)(VkCommandBuffer commandBuffer);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdExecuteCommands)(VkCommandBuffer commandBuffer, uint32_t commandBufferCount, const VkCommandBuffer* pCommandBuffers);


 VkResult __attribute__((__stdcall__)) vkCreateInstance(
    const VkInstanceCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkInstance* pInstance);

 void __attribute__((__stdcall__)) vkDestroyInstance(
    VkInstance instance,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkEnumeratePhysicalDevices(
    VkInstance instance,
    uint32_t* pPhysicalDeviceCount,
    VkPhysicalDevice* pPhysicalDevices);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceFeatures(
    VkPhysicalDevice physicalDevice,
    VkPhysicalDeviceFeatures* pFeatures);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceFormatProperties(
    VkPhysicalDevice physicalDevice,
    VkFormat format,
    VkFormatProperties* pFormatProperties);

 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceImageFormatProperties(
    VkPhysicalDevice physicalDevice,
    VkFormat format,
    VkImageType type,
    VkImageTiling tiling,
    VkImageUsageFlags usage,
    VkImageCreateFlags flags,
    VkImageFormatProperties* pImageFormatProperties);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceProperties(
    VkPhysicalDevice physicalDevice,
    VkPhysicalDeviceProperties* pProperties);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceQueueFamilyProperties(
    VkPhysicalDevice physicalDevice,
    uint32_t* pQueueFamilyPropertyCount,
    VkQueueFamilyProperties* pQueueFamilyProperties);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceMemoryProperties(
    VkPhysicalDevice physicalDevice,
    VkPhysicalDeviceMemoryProperties* pMemoryProperties);

 PFN_vkVoidFunction __attribute__((__stdcall__)) vkGetInstanceProcAddr(
    VkInstance instance,
    const char* pName);

 PFN_vkVoidFunction __attribute__((__stdcall__)) vkGetDeviceProcAddr(
    VkDevice device,
    const char* pName);

 VkResult __attribute__((__stdcall__)) vkCreateDevice(
    VkPhysicalDevice physicalDevice,
    const VkDeviceCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkDevice* pDevice);

 void __attribute__((__stdcall__)) vkDestroyDevice(
    VkDevice device,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkEnumerateInstanceExtensionProperties(
    const char* pLayerName,
    uint32_t* pPropertyCount,
    VkExtensionProperties* pProperties);

 VkResult __attribute__((__stdcall__)) vkEnumerateDeviceExtensionProperties(
    VkPhysicalDevice physicalDevice,
    const char* pLayerName,
    uint32_t* pPropertyCount,
    VkExtensionProperties* pProperties);

 VkResult __attribute__((__stdcall__)) vkEnumerateInstanceLayerProperties(
    uint32_t* pPropertyCount,
    VkLayerProperties* pProperties);

 VkResult __attribute__((__stdcall__)) vkEnumerateDeviceLayerProperties(
    VkPhysicalDevice physicalDevice,
    uint32_t* pPropertyCount,
    VkLayerProperties* pProperties);

 void __attribute__((__stdcall__)) vkGetDeviceQueue(
    VkDevice device,
    uint32_t queueFamilyIndex,
    uint32_t queueIndex,
    VkQueue* pQueue);

 VkResult __attribute__((__stdcall__)) vkQueueSubmit(
    VkQueue queue,
    uint32_t submitCount,
    const VkSubmitInfo* pSubmits,
    VkFence fence);

 VkResult __attribute__((__stdcall__)) vkQueueWaitIdle(
    VkQueue queue);

 VkResult __attribute__((__stdcall__)) vkDeviceWaitIdle(
    VkDevice device);

 VkResult __attribute__((__stdcall__)) vkAllocateMemory(
    VkDevice device,
    const VkMemoryAllocateInfo* pAllocateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkDeviceMemory* pMemory);

 void __attribute__((__stdcall__)) vkFreeMemory(
    VkDevice device,
    VkDeviceMemory memory,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkMapMemory(
    VkDevice device,
    VkDeviceMemory memory,
    VkDeviceSize offset,
    VkDeviceSize size,
    VkMemoryMapFlags flags,
    void** ppData);

 void __attribute__((__stdcall__)) vkUnmapMemory(
    VkDevice device,
    VkDeviceMemory memory);

 VkResult __attribute__((__stdcall__)) vkFlushMappedMemoryRanges(
    VkDevice device,
    uint32_t memoryRangeCount,
    const VkMappedMemoryRange* pMemoryRanges);

 VkResult __attribute__((__stdcall__)) vkInvalidateMappedMemoryRanges(
    VkDevice device,
    uint32_t memoryRangeCount,
    const VkMappedMemoryRange* pMemoryRanges);

 void __attribute__((__stdcall__)) vkGetDeviceMemoryCommitment(
    VkDevice device,
    VkDeviceMemory memory,
    VkDeviceSize* pCommittedMemoryInBytes);

 VkResult __attribute__((__stdcall__)) vkBindBufferMemory(
    VkDevice device,
    VkBuffer buffer,
    VkDeviceMemory memory,
    VkDeviceSize memoryOffset);

 VkResult __attribute__((__stdcall__)) vkBindImageMemory(
    VkDevice device,
    VkImage image,
    VkDeviceMemory memory,
    VkDeviceSize memoryOffset);

 void __attribute__((__stdcall__)) vkGetBufferMemoryRequirements(
    VkDevice device,
    VkBuffer buffer,
    VkMemoryRequirements* pMemoryRequirements);

 void __attribute__((__stdcall__)) vkGetImageMemoryRequirements(
    VkDevice device,
    VkImage image,
    VkMemoryRequirements* pMemoryRequirements);

 void __attribute__((__stdcall__)) vkGetImageSparseMemoryRequirements(
    VkDevice device,
    VkImage image,
    uint32_t* pSparseMemoryRequirementCount,
    VkSparseImageMemoryRequirements* pSparseMemoryRequirements);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceSparseImageFormatProperties(
    VkPhysicalDevice physicalDevice,
    VkFormat format,
    VkImageType type,
    VkSampleCountFlagBits samples,
    VkImageUsageFlags usage,
    VkImageTiling tiling,
    uint32_t* pPropertyCount,
    VkSparseImageFormatProperties* pProperties);

 VkResult __attribute__((__stdcall__)) vkQueueBindSparse(
    VkQueue queue,
    uint32_t bindInfoCount,
    const VkBindSparseInfo* pBindInfo,
    VkFence fence);

 VkResult __attribute__((__stdcall__)) vkCreateFence(
    VkDevice device,
    const VkFenceCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkFence* pFence);

 void __attribute__((__stdcall__)) vkDestroyFence(
    VkDevice device,
    VkFence fence,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkResetFences(
    VkDevice device,
    uint32_t fenceCount,
    const VkFence* pFences);

 VkResult __attribute__((__stdcall__)) vkGetFenceStatus(
    VkDevice device,
    VkFence fence);

 VkResult __attribute__((__stdcall__)) vkWaitForFences(
    VkDevice device,
    uint32_t fenceCount,
    const VkFence* pFences,
    VkBool32 waitAll,
    uint64_t timeout);

 VkResult __attribute__((__stdcall__)) vkCreateSemaphore(
    VkDevice device,
    const VkSemaphoreCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkSemaphore* pSemaphore);

 void __attribute__((__stdcall__)) vkDestroySemaphore(
    VkDevice device,
    VkSemaphore semaphore,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkCreateEvent(
    VkDevice device,
    const VkEventCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkEvent* pEvent);

 void __attribute__((__stdcall__)) vkDestroyEvent(
    VkDevice device,
    VkEvent event,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkGetEventStatus(
    VkDevice device,
    VkEvent event);

 VkResult __attribute__((__stdcall__)) vkSetEvent(
    VkDevice device,
    VkEvent event);

 VkResult __attribute__((__stdcall__)) vkResetEvent(
    VkDevice device,
    VkEvent event);

 VkResult __attribute__((__stdcall__)) vkCreateQueryPool(
    VkDevice device,
    const VkQueryPoolCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkQueryPool* pQueryPool);

 void __attribute__((__stdcall__)) vkDestroyQueryPool(
    VkDevice device,
    VkQueryPool queryPool,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkGetQueryPoolResults(
    VkDevice device,
    VkQueryPool queryPool,
    uint32_t firstQuery,
    uint32_t queryCount,
    size_t dataSize,
    void* pData,
    VkDeviceSize stride,
    VkQueryResultFlags flags);

 VkResult __attribute__((__stdcall__)) vkCreateBuffer(
    VkDevice device,
    const VkBufferCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkBuffer* pBuffer);

 void __attribute__((__stdcall__)) vkDestroyBuffer(
    VkDevice device,
    VkBuffer buffer,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkCreateBufferView(
    VkDevice device,
    const VkBufferViewCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkBufferView* pView);

 void __attribute__((__stdcall__)) vkDestroyBufferView(
    VkDevice device,
    VkBufferView bufferView,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkCreateImage(
    VkDevice device,
    const VkImageCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkImage* pImage);

 void __attribute__((__stdcall__)) vkDestroyImage(
    VkDevice device,
    VkImage image,
    const VkAllocationCallbacks* pAllocator);

 void __attribute__((__stdcall__)) vkGetImageSubresourceLayout(
    VkDevice device,
    VkImage image,
    const VkImageSubresource* pSubresource,
    VkSubresourceLayout* pLayout);

 VkResult __attribute__((__stdcall__)) vkCreateImageView(
    VkDevice device,
    const VkImageViewCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkImageView* pView);

 void __attribute__((__stdcall__)) vkDestroyImageView(
    VkDevice device,
    VkImageView imageView,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkCreateShaderModule(
    VkDevice device,
    const VkShaderModuleCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkShaderModule* pShaderModule);

 void __attribute__((__stdcall__)) vkDestroyShaderModule(
    VkDevice device,
    VkShaderModule shaderModule,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkCreatePipelineCache(
    VkDevice device,
    const VkPipelineCacheCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkPipelineCache* pPipelineCache);

 void __attribute__((__stdcall__)) vkDestroyPipelineCache(
    VkDevice device,
    VkPipelineCache pipelineCache,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkGetPipelineCacheData(
    VkDevice device,
    VkPipelineCache pipelineCache,
    size_t* pDataSize,
    void* pData);

 VkResult __attribute__((__stdcall__)) vkMergePipelineCaches(
    VkDevice device,
    VkPipelineCache dstCache,
    uint32_t srcCacheCount,
    const VkPipelineCache* pSrcCaches);

 VkResult __attribute__((__stdcall__)) vkCreateGraphicsPipelines(
    VkDevice device,
    VkPipelineCache pipelineCache,
    uint32_t createInfoCount,
    const VkGraphicsPipelineCreateInfo* pCreateInfos,
    const VkAllocationCallbacks* pAllocator,
    VkPipeline* pPipelines);

 VkResult __attribute__((__stdcall__)) vkCreateComputePipelines(
    VkDevice device,
    VkPipelineCache pipelineCache,
    uint32_t createInfoCount,
    const VkComputePipelineCreateInfo* pCreateInfos,
    const VkAllocationCallbacks* pAllocator,
    VkPipeline* pPipelines);

 void __attribute__((__stdcall__)) vkDestroyPipeline(
    VkDevice device,
    VkPipeline pipeline,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkCreatePipelineLayout(
    VkDevice device,
    const VkPipelineLayoutCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkPipelineLayout* pPipelineLayout);

 void __attribute__((__stdcall__)) vkDestroyPipelineLayout(
    VkDevice device,
    VkPipelineLayout pipelineLayout,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkCreateSampler(
    VkDevice device,
    const VkSamplerCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkSampler* pSampler);

 void __attribute__((__stdcall__)) vkDestroySampler(
    VkDevice device,
    VkSampler sampler,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkCreateDescriptorSetLayout(
    VkDevice device,
    const VkDescriptorSetLayoutCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkDescriptorSetLayout* pSetLayout);

 void __attribute__((__stdcall__)) vkDestroyDescriptorSetLayout(
    VkDevice device,
    VkDescriptorSetLayout descriptorSetLayout,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkCreateDescriptorPool(
    VkDevice device,
    const VkDescriptorPoolCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkDescriptorPool* pDescriptorPool);

 void __attribute__((__stdcall__)) vkDestroyDescriptorPool(
    VkDevice device,
    VkDescriptorPool descriptorPool,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkResetDescriptorPool(
    VkDevice device,
    VkDescriptorPool descriptorPool,
    VkDescriptorPoolResetFlags flags);

 VkResult __attribute__((__stdcall__)) vkAllocateDescriptorSets(
    VkDevice device,
    const VkDescriptorSetAllocateInfo* pAllocateInfo,
    VkDescriptorSet* pDescriptorSets);

 VkResult __attribute__((__stdcall__)) vkFreeDescriptorSets(
    VkDevice device,
    VkDescriptorPool descriptorPool,
    uint32_t descriptorSetCount,
    const VkDescriptorSet* pDescriptorSets);

 void __attribute__((__stdcall__)) vkUpdateDescriptorSets(
    VkDevice device,
    uint32_t descriptorWriteCount,
    const VkWriteDescriptorSet* pDescriptorWrites,
    uint32_t descriptorCopyCount,
    const VkCopyDescriptorSet* pDescriptorCopies);

 VkResult __attribute__((__stdcall__)) vkCreateFramebuffer(
    VkDevice device,
    const VkFramebufferCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkFramebuffer* pFramebuffer);

 void __attribute__((__stdcall__)) vkDestroyFramebuffer(
    VkDevice device,
    VkFramebuffer framebuffer,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkCreateRenderPass(
    VkDevice device,
    const VkRenderPassCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkRenderPass* pRenderPass);

 void __attribute__((__stdcall__)) vkDestroyRenderPass(
    VkDevice device,
    VkRenderPass renderPass,
    const VkAllocationCallbacks* pAllocator);

 void __attribute__((__stdcall__)) vkGetRenderAreaGranularity(
    VkDevice device,
    VkRenderPass renderPass,
    VkExtent2D* pGranularity);

 VkResult __attribute__((__stdcall__)) vkCreateCommandPool(
    VkDevice device,
    const VkCommandPoolCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkCommandPool* pCommandPool);

 void __attribute__((__stdcall__)) vkDestroyCommandPool(
    VkDevice device,
    VkCommandPool commandPool,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkResetCommandPool(
    VkDevice device,
    VkCommandPool commandPool,
    VkCommandPoolResetFlags flags);

 VkResult __attribute__((__stdcall__)) vkAllocateCommandBuffers(
    VkDevice device,
    const VkCommandBufferAllocateInfo* pAllocateInfo,
    VkCommandBuffer* pCommandBuffers);

 void __attribute__((__stdcall__)) vkFreeCommandBuffers(
    VkDevice device,
    VkCommandPool commandPool,
    uint32_t commandBufferCount,
    const VkCommandBuffer* pCommandBuffers);

 VkResult __attribute__((__stdcall__)) vkBeginCommandBuffer(
    VkCommandBuffer commandBuffer,
    const VkCommandBufferBeginInfo* pBeginInfo);

 VkResult __attribute__((__stdcall__)) vkEndCommandBuffer(
    VkCommandBuffer commandBuffer);

 VkResult __attribute__((__stdcall__)) vkResetCommandBuffer(
    VkCommandBuffer commandBuffer,
    VkCommandBufferResetFlags flags);

 void __attribute__((__stdcall__)) vkCmdBindPipeline(
    VkCommandBuffer commandBuffer,
    VkPipelineBindPoint pipelineBindPoint,
    VkPipeline pipeline);

 void __attribute__((__stdcall__)) vkCmdSetViewport(
    VkCommandBuffer commandBuffer,
    uint32_t firstViewport,
    uint32_t viewportCount,
    const VkViewport* pViewports);

 void __attribute__((__stdcall__)) vkCmdSetScissor(
    VkCommandBuffer commandBuffer,
    uint32_t firstScissor,
    uint32_t scissorCount,
    const VkRect2D* pScissors);

 void __attribute__((__stdcall__)) vkCmdSetLineWidth(
    VkCommandBuffer commandBuffer,
    float lineWidth);

 void __attribute__((__stdcall__)) vkCmdSetDepthBias(
    VkCommandBuffer commandBuffer,
    float depthBiasConstantFactor,
    float depthBiasClamp,
    float depthBiasSlopeFactor);

 void __attribute__((__stdcall__)) vkCmdSetBlendConstants(
    VkCommandBuffer commandBuffer,
    const float blendConstants[4]);

 void __attribute__((__stdcall__)) vkCmdSetDepthBounds(
    VkCommandBuffer commandBuffer,
    float minDepthBounds,
    float maxDepthBounds);

 void __attribute__((__stdcall__)) vkCmdSetStencilCompareMask(
    VkCommandBuffer commandBuffer,
    VkStencilFaceFlags faceMask,
    uint32_t compareMask);

 void __attribute__((__stdcall__)) vkCmdSetStencilWriteMask(
    VkCommandBuffer commandBuffer,
    VkStencilFaceFlags faceMask,
    uint32_t writeMask);

 void __attribute__((__stdcall__)) vkCmdSetStencilReference(
    VkCommandBuffer commandBuffer,
    VkStencilFaceFlags faceMask,
    uint32_t reference);

 void __attribute__((__stdcall__)) vkCmdBindDescriptorSets(
    VkCommandBuffer commandBuffer,
    VkPipelineBindPoint pipelineBindPoint,
    VkPipelineLayout layout,
    uint32_t firstSet,
    uint32_t descriptorSetCount,
    const VkDescriptorSet* pDescriptorSets,
    uint32_t dynamicOffsetCount,
    const uint32_t* pDynamicOffsets);

 void __attribute__((__stdcall__)) vkCmdBindIndexBuffer(
    VkCommandBuffer commandBuffer,
    VkBuffer buffer,
    VkDeviceSize offset,
    VkIndexType indexType);

 void __attribute__((__stdcall__)) vkCmdBindVertexBuffers(
    VkCommandBuffer commandBuffer,
    uint32_t firstBinding,
    uint32_t bindingCount,
    const VkBuffer* pBuffers,
    const VkDeviceSize* pOffsets);

 void __attribute__((__stdcall__)) vkCmdDraw(
    VkCommandBuffer commandBuffer,
    uint32_t vertexCount,
    uint32_t instanceCount,
    uint32_t firstVertex,
    uint32_t firstInstance);

 void __attribute__((__stdcall__)) vkCmdDrawIndexed(
    VkCommandBuffer commandBuffer,
    uint32_t indexCount,
    uint32_t instanceCount,
    uint32_t firstIndex,
    int32_t vertexOffset,
    uint32_t firstInstance);

 void __attribute__((__stdcall__)) vkCmdDrawIndirect(
    VkCommandBuffer commandBuffer,
    VkBuffer buffer,
    VkDeviceSize offset,
    uint32_t drawCount,
    uint32_t stride);

 void __attribute__((__stdcall__)) vkCmdDrawIndexedIndirect(
    VkCommandBuffer commandBuffer,
    VkBuffer buffer,
    VkDeviceSize offset,
    uint32_t drawCount,
    uint32_t stride);

 void __attribute__((__stdcall__)) vkCmdDispatch(
    VkCommandBuffer commandBuffer,
    uint32_t groupCountX,
    uint32_t groupCountY,
    uint32_t groupCountZ);

 void __attribute__((__stdcall__)) vkCmdDispatchIndirect(
    VkCommandBuffer commandBuffer,
    VkBuffer buffer,
    VkDeviceSize offset);

 void __attribute__((__stdcall__)) vkCmdCopyBuffer(
    VkCommandBuffer commandBuffer,
    VkBuffer srcBuffer,
    VkBuffer dstBuffer,
    uint32_t regionCount,
    const VkBufferCopy* pRegions);

 void __attribute__((__stdcall__)) vkCmdCopyImage(
    VkCommandBuffer commandBuffer,
    VkImage srcImage,
    VkImageLayout srcImageLayout,
    VkImage dstImage,
    VkImageLayout dstImageLayout,
    uint32_t regionCount,
    const VkImageCopy* pRegions);

 void __attribute__((__stdcall__)) vkCmdBlitImage(
    VkCommandBuffer commandBuffer,
    VkImage srcImage,
    VkImageLayout srcImageLayout,
    VkImage dstImage,
    VkImageLayout dstImageLayout,
    uint32_t regionCount,
    const VkImageBlit* pRegions,
    VkFilter filter);

 void __attribute__((__stdcall__)) vkCmdCopyBufferToImage(
    VkCommandBuffer commandBuffer,
    VkBuffer srcBuffer,
    VkImage dstImage,
    VkImageLayout dstImageLayout,
    uint32_t regionCount,
    const VkBufferImageCopy* pRegions);

 void __attribute__((__stdcall__)) vkCmdCopyImageToBuffer(
    VkCommandBuffer commandBuffer,
    VkImage srcImage,
    VkImageLayout srcImageLayout,
    VkBuffer dstBuffer,
    uint32_t regionCount,
    const VkBufferImageCopy* pRegions);

 void __attribute__((__stdcall__)) vkCmdUpdateBuffer(
    VkCommandBuffer commandBuffer,
    VkBuffer dstBuffer,
    VkDeviceSize dstOffset,
    VkDeviceSize dataSize,
    const void* pData);

 void __attribute__((__stdcall__)) vkCmdFillBuffer(
    VkCommandBuffer commandBuffer,
    VkBuffer dstBuffer,
    VkDeviceSize dstOffset,
    VkDeviceSize size,
    uint32_t data);

 void __attribute__((__stdcall__)) vkCmdClearColorImage(
    VkCommandBuffer commandBuffer,
    VkImage image,
    VkImageLayout imageLayout,
    const VkClearColorValue* pColor,
    uint32_t rangeCount,
    const VkImageSubresourceRange* pRanges);

 void __attribute__((__stdcall__)) vkCmdClearDepthStencilImage(
    VkCommandBuffer commandBuffer,
    VkImage image,
    VkImageLayout imageLayout,
    const VkClearDepthStencilValue* pDepthStencil,
    uint32_t rangeCount,
    const VkImageSubresourceRange* pRanges);

 void __attribute__((__stdcall__)) vkCmdClearAttachments(
    VkCommandBuffer commandBuffer,
    uint32_t attachmentCount,
    const VkClearAttachment* pAttachments,
    uint32_t rectCount,
    const VkClearRect* pRects);

 void __attribute__((__stdcall__)) vkCmdResolveImage(
    VkCommandBuffer commandBuffer,
    VkImage srcImage,
    VkImageLayout srcImageLayout,
    VkImage dstImage,
    VkImageLayout dstImageLayout,
    uint32_t regionCount,
    const VkImageResolve* pRegions);

 void __attribute__((__stdcall__)) vkCmdSetEvent(
    VkCommandBuffer commandBuffer,
    VkEvent event,
    VkPipelineStageFlags stageMask);

 void __attribute__((__stdcall__)) vkCmdResetEvent(
    VkCommandBuffer commandBuffer,
    VkEvent event,
    VkPipelineStageFlags stageMask);

 void __attribute__((__stdcall__)) vkCmdWaitEvents(
    VkCommandBuffer commandBuffer,
    uint32_t eventCount,
    const VkEvent* pEvents,
    VkPipelineStageFlags srcStageMask,
    VkPipelineStageFlags dstStageMask,
    uint32_t memoryBarrierCount,
    const VkMemoryBarrier* pMemoryBarriers,
    uint32_t bufferMemoryBarrierCount,
    const VkBufferMemoryBarrier* pBufferMemoryBarriers,
    uint32_t imageMemoryBarrierCount,
    const VkImageMemoryBarrier* pImageMemoryBarriers);

 void __attribute__((__stdcall__)) vkCmdPipelineBarrier(
    VkCommandBuffer commandBuffer,
    VkPipelineStageFlags srcStageMask,
    VkPipelineStageFlags dstStageMask,
    VkDependencyFlags dependencyFlags,
    uint32_t memoryBarrierCount,
    const VkMemoryBarrier* pMemoryBarriers,
    uint32_t bufferMemoryBarrierCount,
    const VkBufferMemoryBarrier* pBufferMemoryBarriers,
    uint32_t imageMemoryBarrierCount,
    const VkImageMemoryBarrier* pImageMemoryBarriers);

 void __attribute__((__stdcall__)) vkCmdBeginQuery(
    VkCommandBuffer commandBuffer,
    VkQueryPool queryPool,
    uint32_t query,
    VkQueryControlFlags flags);

 void __attribute__((__stdcall__)) vkCmdEndQuery(
    VkCommandBuffer commandBuffer,
    VkQueryPool queryPool,
    uint32_t query);

 void __attribute__((__stdcall__)) vkCmdResetQueryPool(
    VkCommandBuffer commandBuffer,
    VkQueryPool queryPool,
    uint32_t firstQuery,
    uint32_t queryCount);

 void __attribute__((__stdcall__)) vkCmdWriteTimestamp(
    VkCommandBuffer commandBuffer,
    VkPipelineStageFlagBits pipelineStage,
    VkQueryPool queryPool,
    uint32_t query);

 void __attribute__((__stdcall__)) vkCmdCopyQueryPoolResults(
    VkCommandBuffer commandBuffer,
    VkQueryPool queryPool,
    uint32_t firstQuery,
    uint32_t queryCount,
    VkBuffer dstBuffer,
    VkDeviceSize dstOffset,
    VkDeviceSize stride,
    VkQueryResultFlags flags);

 void __attribute__((__stdcall__)) vkCmdPushConstants(
    VkCommandBuffer commandBuffer,
    VkPipelineLayout layout,
    VkShaderStageFlags stageFlags,
    uint32_t offset,
    uint32_t size,
    const void* pValues);

 void __attribute__((__stdcall__)) vkCmdBeginRenderPass(
    VkCommandBuffer commandBuffer,
    const VkRenderPassBeginInfo* pRenderPassBegin,
    VkSubpassContents contents);

 void __attribute__((__stdcall__)) vkCmdNextSubpass(
    VkCommandBuffer commandBuffer,
    VkSubpassContents contents);

 void __attribute__((__stdcall__)) vkCmdEndRenderPass(
    VkCommandBuffer commandBuffer);

 void __attribute__((__stdcall__)) vkCmdExecuteCommands(
    VkCommandBuffer commandBuffer,
    uint32_t commandBufferCount,
    const VkCommandBuffer* pCommandBuffers);
# 5055 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkSamplerYcbcrConversion_T *VkSamplerYcbcrConversion;
typedef struct VkDescriptorUpdateTemplate_T *VkDescriptorUpdateTemplate;




typedef enum VkPointClippingBehavior {
    VK_POINT_CLIPPING_BEHAVIOR_ALL_CLIP_PLANES = 0,
    VK_POINT_CLIPPING_BEHAVIOR_USER_CLIP_PLANES_ONLY = 1,
    VK_POINT_CLIPPING_BEHAVIOR_ALL_CLIP_PLANES_KHR = VK_POINT_CLIPPING_BEHAVIOR_ALL_CLIP_PLANES,
    VK_POINT_CLIPPING_BEHAVIOR_USER_CLIP_PLANES_ONLY_KHR = VK_POINT_CLIPPING_BEHAVIOR_USER_CLIP_PLANES_ONLY,
    VK_POINT_CLIPPING_BEHAVIOR_MAX_ENUM = 0x7FFFFFFF
} VkPointClippingBehavior;

typedef enum VkTessellationDomainOrigin {
    VK_TESSELLATION_DOMAIN_ORIGIN_UPPER_LEFT = 0,
    VK_TESSELLATION_DOMAIN_ORIGIN_LOWER_LEFT = 1,
    VK_TESSELLATION_DOMAIN_ORIGIN_UPPER_LEFT_KHR = VK_TESSELLATION_DOMAIN_ORIGIN_UPPER_LEFT,
    VK_TESSELLATION_DOMAIN_ORIGIN_LOWER_LEFT_KHR = VK_TESSELLATION_DOMAIN_ORIGIN_LOWER_LEFT,
    VK_TESSELLATION_DOMAIN_ORIGIN_MAX_ENUM = 0x7FFFFFFF
} VkTessellationDomainOrigin;

typedef enum VkSamplerYcbcrModelConversion {
    VK_SAMPLER_YCBCR_MODEL_CONVERSION_RGB_IDENTITY = 0,
    VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_IDENTITY = 1,
    VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_709 = 2,
    VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_601 = 3,
    VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_2020 = 4,
    VK_SAMPLER_YCBCR_MODEL_CONVERSION_RGB_IDENTITY_KHR = VK_SAMPLER_YCBCR_MODEL_CONVERSION_RGB_IDENTITY,
    VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_IDENTITY_KHR = VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_IDENTITY,
    VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_709_KHR = VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_709,
    VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_601_KHR = VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_601,
    VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_2020_KHR = VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_2020,
    VK_SAMPLER_YCBCR_MODEL_CONVERSION_MAX_ENUM = 0x7FFFFFFF
} VkSamplerYcbcrModelConversion;

typedef enum VkSamplerYcbcrRange {
    VK_SAMPLER_YCBCR_RANGE_ITU_FULL = 0,
    VK_SAMPLER_YCBCR_RANGE_ITU_NARROW = 1,
    VK_SAMPLER_YCBCR_RANGE_ITU_FULL_KHR = VK_SAMPLER_YCBCR_RANGE_ITU_FULL,
    VK_SAMPLER_YCBCR_RANGE_ITU_NARROW_KHR = VK_SAMPLER_YCBCR_RANGE_ITU_NARROW,
    VK_SAMPLER_YCBCR_RANGE_MAX_ENUM = 0x7FFFFFFF
} VkSamplerYcbcrRange;

typedef enum VkChromaLocation {
    VK_CHROMA_LOCATION_COSITED_EVEN = 0,
    VK_CHROMA_LOCATION_MIDPOINT = 1,
    VK_CHROMA_LOCATION_COSITED_EVEN_KHR = VK_CHROMA_LOCATION_COSITED_EVEN,
    VK_CHROMA_LOCATION_MIDPOINT_KHR = VK_CHROMA_LOCATION_MIDPOINT,
    VK_CHROMA_LOCATION_MAX_ENUM = 0x7FFFFFFF
} VkChromaLocation;

typedef enum VkDescriptorUpdateTemplateType {
    VK_DESCRIPTOR_UPDATE_TEMPLATE_TYPE_DESCRIPTOR_SET = 0,
    VK_DESCRIPTOR_UPDATE_TEMPLATE_TYPE_PUSH_DESCRIPTORS = 1,
    VK_DESCRIPTOR_UPDATE_TEMPLATE_TYPE_PUSH_DESCRIPTORS_KHR = VK_DESCRIPTOR_UPDATE_TEMPLATE_TYPE_PUSH_DESCRIPTORS,
    VK_DESCRIPTOR_UPDATE_TEMPLATE_TYPE_DESCRIPTOR_SET_KHR = VK_DESCRIPTOR_UPDATE_TEMPLATE_TYPE_DESCRIPTOR_SET,
    VK_DESCRIPTOR_UPDATE_TEMPLATE_TYPE_MAX_ENUM = 0x7FFFFFFF
} VkDescriptorUpdateTemplateType;

typedef enum VkSubgroupFeatureFlagBits {
    VK_SUBGROUP_FEATURE_BASIC_BIT = 0x00000001,
    VK_SUBGROUP_FEATURE_VOTE_BIT = 0x00000002,
    VK_SUBGROUP_FEATURE_ARITHMETIC_BIT = 0x00000004,
    VK_SUBGROUP_FEATURE_BALLOT_BIT = 0x00000008,
    VK_SUBGROUP_FEATURE_SHUFFLE_BIT = 0x00000010,
    VK_SUBGROUP_FEATURE_SHUFFLE_RELATIVE_BIT = 0x00000020,
    VK_SUBGROUP_FEATURE_CLUSTERED_BIT = 0x00000040,
    VK_SUBGROUP_FEATURE_QUAD_BIT = 0x00000080,
    VK_SUBGROUP_FEATURE_ROTATE_BIT = 0x00000200,
    VK_SUBGROUP_FEATURE_ROTATE_CLUSTERED_BIT = 0x00000400,
    VK_SUBGROUP_FEATURE_PARTITIONED_BIT_NV = 0x00000100,
    VK_SUBGROUP_FEATURE_ROTATE_BIT_KHR = VK_SUBGROUP_FEATURE_ROTATE_BIT,
    VK_SUBGROUP_FEATURE_ROTATE_CLUSTERED_BIT_KHR = VK_SUBGROUP_FEATURE_ROTATE_CLUSTERED_BIT,
    VK_SUBGROUP_FEATURE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkSubgroupFeatureFlagBits;
typedef VkFlags VkSubgroupFeatureFlags;

typedef enum VkPeerMemoryFeatureFlagBits {
    VK_PEER_MEMORY_FEATURE_COPY_SRC_BIT = 0x00000001,
    VK_PEER_MEMORY_FEATURE_COPY_DST_BIT = 0x00000002,
    VK_PEER_MEMORY_FEATURE_GENERIC_SRC_BIT = 0x00000004,
    VK_PEER_MEMORY_FEATURE_GENERIC_DST_BIT = 0x00000008,
    VK_PEER_MEMORY_FEATURE_COPY_SRC_BIT_KHR = VK_PEER_MEMORY_FEATURE_COPY_SRC_BIT,
    VK_PEER_MEMORY_FEATURE_COPY_DST_BIT_KHR = VK_PEER_MEMORY_FEATURE_COPY_DST_BIT,
    VK_PEER_MEMORY_FEATURE_GENERIC_SRC_BIT_KHR = VK_PEER_MEMORY_FEATURE_GENERIC_SRC_BIT,
    VK_PEER_MEMORY_FEATURE_GENERIC_DST_BIT_KHR = VK_PEER_MEMORY_FEATURE_GENERIC_DST_BIT,
    VK_PEER_MEMORY_FEATURE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkPeerMemoryFeatureFlagBits;
typedef VkFlags VkPeerMemoryFeatureFlags;

typedef enum VkMemoryAllocateFlagBits {
    VK_MEMORY_ALLOCATE_DEVICE_MASK_BIT = 0x00000001,
    VK_MEMORY_ALLOCATE_DEVICE_ADDRESS_BIT = 0x00000002,
    VK_MEMORY_ALLOCATE_DEVICE_ADDRESS_CAPTURE_REPLAY_BIT = 0x00000004,
    VK_MEMORY_ALLOCATE_DEVICE_MASK_BIT_KHR = VK_MEMORY_ALLOCATE_DEVICE_MASK_BIT,
    VK_MEMORY_ALLOCATE_DEVICE_ADDRESS_BIT_KHR = VK_MEMORY_ALLOCATE_DEVICE_ADDRESS_BIT,
    VK_MEMORY_ALLOCATE_DEVICE_ADDRESS_CAPTURE_REPLAY_BIT_KHR = VK_MEMORY_ALLOCATE_DEVICE_ADDRESS_CAPTURE_REPLAY_BIT,
    VK_MEMORY_ALLOCATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkMemoryAllocateFlagBits;
typedef VkFlags VkMemoryAllocateFlags;
typedef VkFlags VkCommandPoolTrimFlags;
typedef VkFlags VkDescriptorUpdateTemplateCreateFlags;

typedef enum VkExternalMemoryHandleTypeFlagBits {
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT = 0x00000001,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_BIT = 0x00000002,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT = 0x00000004,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_BIT = 0x00000008,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_KMT_BIT = 0x00000010,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_HEAP_BIT = 0x00000020,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_RESOURCE_BIT = 0x00000040,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_DMA_BUF_BIT_EXT = 0x00000200,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_ANDROID_HARDWARE_BUFFER_BIT_ANDROID = 0x00000400,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_HOST_ALLOCATION_BIT_EXT = 0x00000080,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_HOST_MAPPED_FOREIGN_MEMORY_BIT_EXT = 0x00000100,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_ZIRCON_VMO_BIT_FUCHSIA = 0x00000800,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_RDMA_ADDRESS_BIT_NV = 0x00001000,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_SCREEN_BUFFER_BIT_QNX = 0x00004000,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT_KHR = VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_BIT_KHR = VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_BIT,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT_KHR = VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_BIT_KHR = VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_BIT,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_KMT_BIT_KHR = VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_KMT_BIT,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_HEAP_BIT_KHR = VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_HEAP_BIT,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_RESOURCE_BIT_KHR = VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_RESOURCE_BIT,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkExternalMemoryHandleTypeFlagBits;
typedef VkFlags VkExternalMemoryHandleTypeFlags;

typedef enum VkExternalMemoryFeatureFlagBits {
    VK_EXTERNAL_MEMORY_FEATURE_DEDICATED_ONLY_BIT = 0x00000001,
    VK_EXTERNAL_MEMORY_FEATURE_EXPORTABLE_BIT = 0x00000002,
    VK_EXTERNAL_MEMORY_FEATURE_IMPORTABLE_BIT = 0x00000004,
    VK_EXTERNAL_MEMORY_FEATURE_DEDICATED_ONLY_BIT_KHR = VK_EXTERNAL_MEMORY_FEATURE_DEDICATED_ONLY_BIT,
    VK_EXTERNAL_MEMORY_FEATURE_EXPORTABLE_BIT_KHR = VK_EXTERNAL_MEMORY_FEATURE_EXPORTABLE_BIT,
    VK_EXTERNAL_MEMORY_FEATURE_IMPORTABLE_BIT_KHR = VK_EXTERNAL_MEMORY_FEATURE_IMPORTABLE_BIT,
    VK_EXTERNAL_MEMORY_FEATURE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkExternalMemoryFeatureFlagBits;
typedef VkFlags VkExternalMemoryFeatureFlags;

typedef enum VkExternalFenceHandleTypeFlagBits {
    VK_EXTERNAL_FENCE_HANDLE_TYPE_OPAQUE_FD_BIT = 0x00000001,
    VK_EXTERNAL_FENCE_HANDLE_TYPE_OPAQUE_WIN32_BIT = 0x00000002,
    VK_EXTERNAL_FENCE_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT = 0x00000004,
    VK_EXTERNAL_FENCE_HANDLE_TYPE_SYNC_FD_BIT = 0x00000008,
    VK_EXTERNAL_FENCE_HANDLE_TYPE_OPAQUE_FD_BIT_KHR = VK_EXTERNAL_FENCE_HANDLE_TYPE_OPAQUE_FD_BIT,
    VK_EXTERNAL_FENCE_HANDLE_TYPE_OPAQUE_WIN32_BIT_KHR = VK_EXTERNAL_FENCE_HANDLE_TYPE_OPAQUE_WIN32_BIT,
    VK_EXTERNAL_FENCE_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT_KHR = VK_EXTERNAL_FENCE_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT,
    VK_EXTERNAL_FENCE_HANDLE_TYPE_SYNC_FD_BIT_KHR = VK_EXTERNAL_FENCE_HANDLE_TYPE_SYNC_FD_BIT,
    VK_EXTERNAL_FENCE_HANDLE_TYPE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkExternalFenceHandleTypeFlagBits;
typedef VkFlags VkExternalFenceHandleTypeFlags;

typedef enum VkExternalFenceFeatureFlagBits {
    VK_EXTERNAL_FENCE_FEATURE_EXPORTABLE_BIT = 0x00000001,
    VK_EXTERNAL_FENCE_FEATURE_IMPORTABLE_BIT = 0x00000002,
    VK_EXTERNAL_FENCE_FEATURE_EXPORTABLE_BIT_KHR = VK_EXTERNAL_FENCE_FEATURE_EXPORTABLE_BIT,
    VK_EXTERNAL_FENCE_FEATURE_IMPORTABLE_BIT_KHR = VK_EXTERNAL_FENCE_FEATURE_IMPORTABLE_BIT,
    VK_EXTERNAL_FENCE_FEATURE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkExternalFenceFeatureFlagBits;
typedef VkFlags VkExternalFenceFeatureFlags;

typedef enum VkFenceImportFlagBits {
    VK_FENCE_IMPORT_TEMPORARY_BIT = 0x00000001,
    VK_FENCE_IMPORT_TEMPORARY_BIT_KHR = VK_FENCE_IMPORT_TEMPORARY_BIT,
    VK_FENCE_IMPORT_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkFenceImportFlagBits;
typedef VkFlags VkFenceImportFlags;

typedef enum VkSemaphoreImportFlagBits {
    VK_SEMAPHORE_IMPORT_TEMPORARY_BIT = 0x00000001,
    VK_SEMAPHORE_IMPORT_TEMPORARY_BIT_KHR = VK_SEMAPHORE_IMPORT_TEMPORARY_BIT,
    VK_SEMAPHORE_IMPORT_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkSemaphoreImportFlagBits;
typedef VkFlags VkSemaphoreImportFlags;

typedef enum VkExternalSemaphoreHandleTypeFlagBits {
    VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT = 0x00000001,
    VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_BIT = 0x00000002,
    VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT = 0x00000004,
    VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT = 0x00000008,
    VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_SYNC_FD_BIT = 0x00000010,
    VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_ZIRCON_EVENT_BIT_FUCHSIA = 0x00000080,
    VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D11_FENCE_BIT = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT,
    VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT_KHR = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT,
    VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_BIT_KHR = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_BIT,
    VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT_KHR = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT,
    VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT_KHR = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT,
    VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_SYNC_FD_BIT_KHR = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_SYNC_FD_BIT,
    VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkExternalSemaphoreHandleTypeFlagBits;
typedef VkFlags VkExternalSemaphoreHandleTypeFlags;

typedef enum VkExternalSemaphoreFeatureFlagBits {
    VK_EXTERNAL_SEMAPHORE_FEATURE_EXPORTABLE_BIT = 0x00000001,
    VK_EXTERNAL_SEMAPHORE_FEATURE_IMPORTABLE_BIT = 0x00000002,
    VK_EXTERNAL_SEMAPHORE_FEATURE_EXPORTABLE_BIT_KHR = VK_EXTERNAL_SEMAPHORE_FEATURE_EXPORTABLE_BIT,
    VK_EXTERNAL_SEMAPHORE_FEATURE_IMPORTABLE_BIT_KHR = VK_EXTERNAL_SEMAPHORE_FEATURE_IMPORTABLE_BIT,
    VK_EXTERNAL_SEMAPHORE_FEATURE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkExternalSemaphoreFeatureFlagBits;
typedef VkFlags VkExternalSemaphoreFeatureFlags;
typedef struct VkPhysicalDeviceSubgroupProperties {
    VkStructureType sType;
    void* pNext;
    uint32_t subgroupSize;
    VkShaderStageFlags supportedStages;
    VkSubgroupFeatureFlags supportedOperations;
    VkBool32 quadOperationsInAllStages;
} VkPhysicalDeviceSubgroupProperties;

typedef struct VkBindBufferMemoryInfo {
    VkStructureType sType;
    const void* pNext;
    VkBuffer buffer;
    VkDeviceMemory memory;
    VkDeviceSize memoryOffset;
} VkBindBufferMemoryInfo;

typedef struct VkBindImageMemoryInfo {
    VkStructureType sType;
    const void* pNext;
    VkImage image;
    VkDeviceMemory memory;
    VkDeviceSize memoryOffset;
} VkBindImageMemoryInfo;

typedef struct VkPhysicalDevice16BitStorageFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 storageBuffer16BitAccess;
    VkBool32 uniformAndStorageBuffer16BitAccess;
    VkBool32 storagePushConstant16;
    VkBool32 storageInputOutput16;
} VkPhysicalDevice16BitStorageFeatures;

typedef struct VkMemoryDedicatedRequirements {
    VkStructureType sType;
    void* pNext;
    VkBool32 prefersDedicatedAllocation;
    VkBool32 requiresDedicatedAllocation;
} VkMemoryDedicatedRequirements;

typedef struct VkMemoryDedicatedAllocateInfo {
    VkStructureType sType;
    const void* pNext;
    VkImage image;
    VkBuffer buffer;
} VkMemoryDedicatedAllocateInfo;

typedef struct VkMemoryAllocateFlagsInfo {
    VkStructureType sType;
    const void* pNext;
    VkMemoryAllocateFlags flags;
    uint32_t deviceMask;
} VkMemoryAllocateFlagsInfo;

typedef struct VkDeviceGroupRenderPassBeginInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t deviceMask;
    uint32_t deviceRenderAreaCount;
    const VkRect2D* pDeviceRenderAreas;
} VkDeviceGroupRenderPassBeginInfo;

typedef struct VkDeviceGroupCommandBufferBeginInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t deviceMask;
} VkDeviceGroupCommandBufferBeginInfo;

typedef struct VkDeviceGroupSubmitInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t waitSemaphoreCount;
    const uint32_t* pWaitSemaphoreDeviceIndices;
    uint32_t commandBufferCount;
    const uint32_t* pCommandBufferDeviceMasks;
    uint32_t signalSemaphoreCount;
    const uint32_t* pSignalSemaphoreDeviceIndices;
} VkDeviceGroupSubmitInfo;

typedef struct VkDeviceGroupBindSparseInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t resourceDeviceIndex;
    uint32_t memoryDeviceIndex;
} VkDeviceGroupBindSparseInfo;

typedef struct VkBindBufferMemoryDeviceGroupInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t deviceIndexCount;
    const uint32_t* pDeviceIndices;
} VkBindBufferMemoryDeviceGroupInfo;

typedef struct VkBindImageMemoryDeviceGroupInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t deviceIndexCount;
    const uint32_t* pDeviceIndices;
    uint32_t splitInstanceBindRegionCount;
    const VkRect2D* pSplitInstanceBindRegions;
} VkBindImageMemoryDeviceGroupInfo;

typedef struct VkPhysicalDeviceGroupProperties {
    VkStructureType sType;
    void* pNext;
    uint32_t physicalDeviceCount;
    VkPhysicalDevice physicalDevices[32U];
    VkBool32 subsetAllocation;
} VkPhysicalDeviceGroupProperties;

typedef struct VkDeviceGroupDeviceCreateInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t physicalDeviceCount;
    const VkPhysicalDevice* pPhysicalDevices;
} VkDeviceGroupDeviceCreateInfo;

typedef struct VkBufferMemoryRequirementsInfo2 {
    VkStructureType sType;
    const void* pNext;
    VkBuffer buffer;
} VkBufferMemoryRequirementsInfo2;

typedef struct VkImageMemoryRequirementsInfo2 {
    VkStructureType sType;
    const void* pNext;
    VkImage image;
} VkImageMemoryRequirementsInfo2;

typedef struct VkImageSparseMemoryRequirementsInfo2 {
    VkStructureType sType;
    const void* pNext;
    VkImage image;
} VkImageSparseMemoryRequirementsInfo2;

typedef struct VkMemoryRequirements2 {
    VkStructureType sType;
    void* pNext;
    VkMemoryRequirements memoryRequirements;
} VkMemoryRequirements2;

typedef struct VkSparseImageMemoryRequirements2 {
    VkStructureType sType;
    void* pNext;
    VkSparseImageMemoryRequirements memoryRequirements;
} VkSparseImageMemoryRequirements2;

typedef struct VkPhysicalDeviceFeatures2 {
    VkStructureType sType;
    void* pNext;
    VkPhysicalDeviceFeatures features;
} VkPhysicalDeviceFeatures2;

typedef struct VkPhysicalDeviceProperties2 {
    VkStructureType sType;
    void* pNext;
    VkPhysicalDeviceProperties properties;
} VkPhysicalDeviceProperties2;

typedef struct VkFormatProperties2 {
    VkStructureType sType;
    void* pNext;
    VkFormatProperties formatProperties;
} VkFormatProperties2;

typedef struct VkImageFormatProperties2 {
    VkStructureType sType;
    void* pNext;
    VkImageFormatProperties imageFormatProperties;
} VkImageFormatProperties2;

typedef struct VkPhysicalDeviceImageFormatInfo2 {
    VkStructureType sType;
    const void* pNext;
    VkFormat format;
    VkImageType type;
    VkImageTiling tiling;
    VkImageUsageFlags usage;
    VkImageCreateFlags flags;
} VkPhysicalDeviceImageFormatInfo2;

typedef struct VkQueueFamilyProperties2 {
    VkStructureType sType;
    void* pNext;
    VkQueueFamilyProperties queueFamilyProperties;
} VkQueueFamilyProperties2;

typedef struct VkPhysicalDeviceMemoryProperties2 {
    VkStructureType sType;
    void* pNext;
    VkPhysicalDeviceMemoryProperties memoryProperties;
} VkPhysicalDeviceMemoryProperties2;

typedef struct VkSparseImageFormatProperties2 {
    VkStructureType sType;
    void* pNext;
    VkSparseImageFormatProperties properties;
} VkSparseImageFormatProperties2;

typedef struct VkPhysicalDeviceSparseImageFormatInfo2 {
    VkStructureType sType;
    const void* pNext;
    VkFormat format;
    VkImageType type;
    VkSampleCountFlagBits samples;
    VkImageUsageFlags usage;
    VkImageTiling tiling;
} VkPhysicalDeviceSparseImageFormatInfo2;

typedef struct VkPhysicalDevicePointClippingProperties {
    VkStructureType sType;
    void* pNext;
    VkPointClippingBehavior pointClippingBehavior;
} VkPhysicalDevicePointClippingProperties;

typedef struct VkInputAttachmentAspectReference {
    uint32_t subpass;
    uint32_t inputAttachmentIndex;
    VkImageAspectFlags aspectMask;
} VkInputAttachmentAspectReference;

typedef struct VkRenderPassInputAttachmentAspectCreateInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t aspectReferenceCount;
    const VkInputAttachmentAspectReference* pAspectReferences;
} VkRenderPassInputAttachmentAspectCreateInfo;

typedef struct VkImageViewUsageCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkImageUsageFlags usage;
} VkImageViewUsageCreateInfo;

typedef struct VkPipelineTessellationDomainOriginStateCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkTessellationDomainOrigin domainOrigin;
} VkPipelineTessellationDomainOriginStateCreateInfo;

typedef struct VkRenderPassMultiviewCreateInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t subpassCount;
    const uint32_t* pViewMasks;
    uint32_t dependencyCount;
    const int32_t* pViewOffsets;
    uint32_t correlationMaskCount;
    const uint32_t* pCorrelationMasks;
} VkRenderPassMultiviewCreateInfo;

typedef struct VkPhysicalDeviceMultiviewFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 multiview;
    VkBool32 multiviewGeometryShader;
    VkBool32 multiviewTessellationShader;
} VkPhysicalDeviceMultiviewFeatures;

typedef struct VkPhysicalDeviceMultiviewProperties {
    VkStructureType sType;
    void* pNext;
    uint32_t maxMultiviewViewCount;
    uint32_t maxMultiviewInstanceIndex;
} VkPhysicalDeviceMultiviewProperties;

typedef struct VkPhysicalDeviceVariablePointersFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 variablePointersStorageBuffer;
    VkBool32 variablePointers;
} VkPhysicalDeviceVariablePointersFeatures;

typedef VkPhysicalDeviceVariablePointersFeatures VkPhysicalDeviceVariablePointerFeatures;

typedef struct VkPhysicalDeviceProtectedMemoryFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 protectedMemory;
} VkPhysicalDeviceProtectedMemoryFeatures;

typedef struct VkPhysicalDeviceProtectedMemoryProperties {
    VkStructureType sType;
    void* pNext;
    VkBool32 protectedNoFault;
} VkPhysicalDeviceProtectedMemoryProperties;

typedef struct VkDeviceQueueInfo2 {
    VkStructureType sType;
    const void* pNext;
    VkDeviceQueueCreateFlags flags;
    uint32_t queueFamilyIndex;
    uint32_t queueIndex;
} VkDeviceQueueInfo2;

typedef struct VkProtectedSubmitInfo {
    VkStructureType sType;
    const void* pNext;
    VkBool32 protectedSubmit;
} VkProtectedSubmitInfo;

typedef struct VkSamplerYcbcrConversionCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkFormat format;
    VkSamplerYcbcrModelConversion ycbcrModel;
    VkSamplerYcbcrRange ycbcrRange;
    VkComponentMapping components;
    VkChromaLocation xChromaOffset;
    VkChromaLocation yChromaOffset;
    VkFilter chromaFilter;
    VkBool32 forceExplicitReconstruction;
} VkSamplerYcbcrConversionCreateInfo;

typedef struct VkSamplerYcbcrConversionInfo {
    VkStructureType sType;
    const void* pNext;
    VkSamplerYcbcrConversion conversion;
} VkSamplerYcbcrConversionInfo;

typedef struct VkBindImagePlaneMemoryInfo {
    VkStructureType sType;
    const void* pNext;
    VkImageAspectFlagBits planeAspect;
} VkBindImagePlaneMemoryInfo;

typedef struct VkImagePlaneMemoryRequirementsInfo {
    VkStructureType sType;
    const void* pNext;
    VkImageAspectFlagBits planeAspect;
} VkImagePlaneMemoryRequirementsInfo;

typedef struct VkPhysicalDeviceSamplerYcbcrConversionFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 samplerYcbcrConversion;
} VkPhysicalDeviceSamplerYcbcrConversionFeatures;

typedef struct VkSamplerYcbcrConversionImageFormatProperties {
    VkStructureType sType;
    void* pNext;
    uint32_t combinedImageSamplerDescriptorCount;
} VkSamplerYcbcrConversionImageFormatProperties;

typedef struct VkDescriptorUpdateTemplateEntry {
    uint32_t dstBinding;
    uint32_t dstArrayElement;
    uint32_t descriptorCount;
    VkDescriptorType descriptorType;
    size_t offset;
    size_t stride;
} VkDescriptorUpdateTemplateEntry;

typedef struct VkDescriptorUpdateTemplateCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkDescriptorUpdateTemplateCreateFlags flags;
    uint32_t descriptorUpdateEntryCount;
    const VkDescriptorUpdateTemplateEntry* pDescriptorUpdateEntries;
    VkDescriptorUpdateTemplateType templateType;
    VkDescriptorSetLayout descriptorSetLayout;
    VkPipelineBindPoint pipelineBindPoint;
    VkPipelineLayout pipelineLayout;
    uint32_t set;
} VkDescriptorUpdateTemplateCreateInfo;

typedef struct VkExternalMemoryProperties {
    VkExternalMemoryFeatureFlags externalMemoryFeatures;
    VkExternalMemoryHandleTypeFlags exportFromImportedHandleTypes;
    VkExternalMemoryHandleTypeFlags compatibleHandleTypes;
} VkExternalMemoryProperties;

typedef struct VkPhysicalDeviceExternalImageFormatInfo {
    VkStructureType sType;
    const void* pNext;
    VkExternalMemoryHandleTypeFlagBits handleType;
} VkPhysicalDeviceExternalImageFormatInfo;

typedef struct VkExternalImageFormatProperties {
    VkStructureType sType;
    void* pNext;
    VkExternalMemoryProperties externalMemoryProperties;
} VkExternalImageFormatProperties;

typedef struct VkPhysicalDeviceExternalBufferInfo {
    VkStructureType sType;
    const void* pNext;
    VkBufferCreateFlags flags;
    VkBufferUsageFlags usage;
    VkExternalMemoryHandleTypeFlagBits handleType;
} VkPhysicalDeviceExternalBufferInfo;

typedef struct VkExternalBufferProperties {
    VkStructureType sType;
    void* pNext;
    VkExternalMemoryProperties externalMemoryProperties;
} VkExternalBufferProperties;

typedef struct VkPhysicalDeviceIDProperties {
    VkStructureType sType;
    void* pNext;
    uint8_t deviceUUID[16U];
    uint8_t driverUUID[16U];
    uint8_t deviceLUID[8U];
    uint32_t deviceNodeMask;
    VkBool32 deviceLUIDValid;
} VkPhysicalDeviceIDProperties;

typedef struct VkExternalMemoryImageCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkExternalMemoryHandleTypeFlags handleTypes;
} VkExternalMemoryImageCreateInfo;

typedef struct VkExternalMemoryBufferCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkExternalMemoryHandleTypeFlags handleTypes;
} VkExternalMemoryBufferCreateInfo;

typedef struct VkExportMemoryAllocateInfo {
    VkStructureType sType;
    const void* pNext;
    VkExternalMemoryHandleTypeFlags handleTypes;
} VkExportMemoryAllocateInfo;

typedef struct VkPhysicalDeviceExternalFenceInfo {
    VkStructureType sType;
    const void* pNext;
    VkExternalFenceHandleTypeFlagBits handleType;
} VkPhysicalDeviceExternalFenceInfo;

typedef struct VkExternalFenceProperties {
    VkStructureType sType;
    void* pNext;
    VkExternalFenceHandleTypeFlags exportFromImportedHandleTypes;
    VkExternalFenceHandleTypeFlags compatibleHandleTypes;
    VkExternalFenceFeatureFlags externalFenceFeatures;
} VkExternalFenceProperties;

typedef struct VkExportFenceCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkExternalFenceHandleTypeFlags handleTypes;
} VkExportFenceCreateInfo;

typedef struct VkExportSemaphoreCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkExternalSemaphoreHandleTypeFlags handleTypes;
} VkExportSemaphoreCreateInfo;

typedef struct VkPhysicalDeviceExternalSemaphoreInfo {
    VkStructureType sType;
    const void* pNext;
    VkExternalSemaphoreHandleTypeFlagBits handleType;
} VkPhysicalDeviceExternalSemaphoreInfo;

typedef struct VkExternalSemaphoreProperties {
    VkStructureType sType;
    void* pNext;
    VkExternalSemaphoreHandleTypeFlags exportFromImportedHandleTypes;
    VkExternalSemaphoreHandleTypeFlags compatibleHandleTypes;
    VkExternalSemaphoreFeatureFlags externalSemaphoreFeatures;
} VkExternalSemaphoreProperties;

typedef struct VkPhysicalDeviceMaintenance3Properties {
    VkStructureType sType;
    void* pNext;
    uint32_t maxPerSetDescriptors;
    VkDeviceSize maxMemoryAllocationSize;
} VkPhysicalDeviceMaintenance3Properties;

typedef struct VkDescriptorSetLayoutSupport {
    VkStructureType sType;
    void* pNext;
    VkBool32 supported;
} VkDescriptorSetLayoutSupport;

typedef struct VkPhysicalDeviceShaderDrawParametersFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderDrawParameters;
} VkPhysicalDeviceShaderDrawParametersFeatures;

typedef VkPhysicalDeviceShaderDrawParametersFeatures VkPhysicalDeviceShaderDrawParameterFeatures;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkEnumerateInstanceVersion)(uint32_t* pApiVersion);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkBindBufferMemory2)(VkDevice device, uint32_t bindInfoCount, const VkBindBufferMemoryInfo* pBindInfos);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkBindImageMemory2)(VkDevice device, uint32_t bindInfoCount, const VkBindImageMemoryInfo* pBindInfos);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetDeviceGroupPeerMemoryFeatures)(VkDevice device, uint32_t heapIndex, uint32_t localDeviceIndex, uint32_t remoteDeviceIndex, VkPeerMemoryFeatureFlags* pPeerMemoryFeatures);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDeviceMask)(VkCommandBuffer commandBuffer, uint32_t deviceMask);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDispatchBase)(VkCommandBuffer commandBuffer, uint32_t baseGroupX, uint32_t baseGroupY, uint32_t baseGroupZ, uint32_t groupCountX, uint32_t groupCountY, uint32_t groupCountZ);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkEnumeratePhysicalDeviceGroups)(VkInstance instance, uint32_t* pPhysicalDeviceGroupCount, VkPhysicalDeviceGroupProperties* pPhysicalDeviceGroupProperties);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetImageMemoryRequirements2)(VkDevice device, const VkImageMemoryRequirementsInfo2* pInfo, VkMemoryRequirements2* pMemoryRequirements);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetBufferMemoryRequirements2)(VkDevice device, const VkBufferMemoryRequirementsInfo2* pInfo, VkMemoryRequirements2* pMemoryRequirements);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetImageSparseMemoryRequirements2)(VkDevice device, const VkImageSparseMemoryRequirementsInfo2* pInfo, uint32_t* pSparseMemoryRequirementCount, VkSparseImageMemoryRequirements2* pSparseMemoryRequirements);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceFeatures2)(VkPhysicalDevice physicalDevice, VkPhysicalDeviceFeatures2* pFeatures);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceProperties2)(VkPhysicalDevice physicalDevice, VkPhysicalDeviceProperties2* pProperties);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceFormatProperties2)(VkPhysicalDevice physicalDevice, VkFormat format, VkFormatProperties2* pFormatProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceImageFormatProperties2)(VkPhysicalDevice physicalDevice, const VkPhysicalDeviceImageFormatInfo2* pImageFormatInfo, VkImageFormatProperties2* pImageFormatProperties);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceQueueFamilyProperties2)(VkPhysicalDevice physicalDevice, uint32_t* pQueueFamilyPropertyCount, VkQueueFamilyProperties2* pQueueFamilyProperties);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceMemoryProperties2)(VkPhysicalDevice physicalDevice, VkPhysicalDeviceMemoryProperties2* pMemoryProperties);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceSparseImageFormatProperties2)(VkPhysicalDevice physicalDevice, const VkPhysicalDeviceSparseImageFormatInfo2* pFormatInfo, uint32_t* pPropertyCount, VkSparseImageFormatProperties2* pProperties);
typedef void (__attribute__((__stdcall__)) *PFN_vkTrimCommandPool)(VkDevice device, VkCommandPool commandPool, VkCommandPoolTrimFlags flags);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetDeviceQueue2)(VkDevice device, const VkDeviceQueueInfo2* pQueueInfo, VkQueue* pQueue);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateSamplerYcbcrConversion)(VkDevice device, const VkSamplerYcbcrConversionCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSamplerYcbcrConversion* pYcbcrConversion);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroySamplerYcbcrConversion)(VkDevice device, VkSamplerYcbcrConversion ycbcrConversion, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateDescriptorUpdateTemplate)(VkDevice device, const VkDescriptorUpdateTemplateCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDescriptorUpdateTemplate* pDescriptorUpdateTemplate);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyDescriptorUpdateTemplate)(VkDevice device, VkDescriptorUpdateTemplate descriptorUpdateTemplate, const VkAllocationCallbacks* pAllocator);
typedef void (__attribute__((__stdcall__)) *PFN_vkUpdateDescriptorSetWithTemplate)(VkDevice device, VkDescriptorSet descriptorSet, VkDescriptorUpdateTemplate descriptorUpdateTemplate, const void* pData);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceExternalBufferProperties)(VkPhysicalDevice physicalDevice, const VkPhysicalDeviceExternalBufferInfo* pExternalBufferInfo, VkExternalBufferProperties* pExternalBufferProperties);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceExternalFenceProperties)(VkPhysicalDevice physicalDevice, const VkPhysicalDeviceExternalFenceInfo* pExternalFenceInfo, VkExternalFenceProperties* pExternalFenceProperties);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceExternalSemaphoreProperties)(VkPhysicalDevice physicalDevice, const VkPhysicalDeviceExternalSemaphoreInfo* pExternalSemaphoreInfo, VkExternalSemaphoreProperties* pExternalSemaphoreProperties);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetDescriptorSetLayoutSupport)(VkDevice device, const VkDescriptorSetLayoutCreateInfo* pCreateInfo, VkDescriptorSetLayoutSupport* pSupport);


 VkResult __attribute__((__stdcall__)) vkEnumerateInstanceVersion(
    uint32_t* pApiVersion);

 VkResult __attribute__((__stdcall__)) vkBindBufferMemory2(
    VkDevice device,
    uint32_t bindInfoCount,
    const VkBindBufferMemoryInfo* pBindInfos);

 VkResult __attribute__((__stdcall__)) vkBindImageMemory2(
    VkDevice device,
    uint32_t bindInfoCount,
    const VkBindImageMemoryInfo* pBindInfos);

 void __attribute__((__stdcall__)) vkGetDeviceGroupPeerMemoryFeatures(
    VkDevice device,
    uint32_t heapIndex,
    uint32_t localDeviceIndex,
    uint32_t remoteDeviceIndex,
    VkPeerMemoryFeatureFlags* pPeerMemoryFeatures);

 void __attribute__((__stdcall__)) vkCmdSetDeviceMask(
    VkCommandBuffer commandBuffer,
    uint32_t deviceMask);

 void __attribute__((__stdcall__)) vkCmdDispatchBase(
    VkCommandBuffer commandBuffer,
    uint32_t baseGroupX,
    uint32_t baseGroupY,
    uint32_t baseGroupZ,
    uint32_t groupCountX,
    uint32_t groupCountY,
    uint32_t groupCountZ);

 VkResult __attribute__((__stdcall__)) vkEnumeratePhysicalDeviceGroups(
    VkInstance instance,
    uint32_t* pPhysicalDeviceGroupCount,
    VkPhysicalDeviceGroupProperties* pPhysicalDeviceGroupProperties);

 void __attribute__((__stdcall__)) vkGetImageMemoryRequirements2(
    VkDevice device,
    const VkImageMemoryRequirementsInfo2* pInfo,
    VkMemoryRequirements2* pMemoryRequirements);

 void __attribute__((__stdcall__)) vkGetBufferMemoryRequirements2(
    VkDevice device,
    const VkBufferMemoryRequirementsInfo2* pInfo,
    VkMemoryRequirements2* pMemoryRequirements);

 void __attribute__((__stdcall__)) vkGetImageSparseMemoryRequirements2(
    VkDevice device,
    const VkImageSparseMemoryRequirementsInfo2* pInfo,
    uint32_t* pSparseMemoryRequirementCount,
    VkSparseImageMemoryRequirements2* pSparseMemoryRequirements);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceFeatures2(
    VkPhysicalDevice physicalDevice,
    VkPhysicalDeviceFeatures2* pFeatures);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceProperties2(
    VkPhysicalDevice physicalDevice,
    VkPhysicalDeviceProperties2* pProperties);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceFormatProperties2(
    VkPhysicalDevice physicalDevice,
    VkFormat format,
    VkFormatProperties2* pFormatProperties);

 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceImageFormatProperties2(
    VkPhysicalDevice physicalDevice,
    const VkPhysicalDeviceImageFormatInfo2* pImageFormatInfo,
    VkImageFormatProperties2* pImageFormatProperties);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceQueueFamilyProperties2(
    VkPhysicalDevice physicalDevice,
    uint32_t* pQueueFamilyPropertyCount,
    VkQueueFamilyProperties2* pQueueFamilyProperties);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceMemoryProperties2(
    VkPhysicalDevice physicalDevice,
    VkPhysicalDeviceMemoryProperties2* pMemoryProperties);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceSparseImageFormatProperties2(
    VkPhysicalDevice physicalDevice,
    const VkPhysicalDeviceSparseImageFormatInfo2* pFormatInfo,
    uint32_t* pPropertyCount,
    VkSparseImageFormatProperties2* pProperties);

 void __attribute__((__stdcall__)) vkTrimCommandPool(
    VkDevice device,
    VkCommandPool commandPool,
    VkCommandPoolTrimFlags flags);

 void __attribute__((__stdcall__)) vkGetDeviceQueue2(
    VkDevice device,
    const VkDeviceQueueInfo2* pQueueInfo,
    VkQueue* pQueue);

 VkResult __attribute__((__stdcall__)) vkCreateSamplerYcbcrConversion(
    VkDevice device,
    const VkSamplerYcbcrConversionCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkSamplerYcbcrConversion* pYcbcrConversion);

 void __attribute__((__stdcall__)) vkDestroySamplerYcbcrConversion(
    VkDevice device,
    VkSamplerYcbcrConversion ycbcrConversion,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkCreateDescriptorUpdateTemplate(
    VkDevice device,
    const VkDescriptorUpdateTemplateCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkDescriptorUpdateTemplate* pDescriptorUpdateTemplate);

 void __attribute__((__stdcall__)) vkDestroyDescriptorUpdateTemplate(
    VkDevice device,
    VkDescriptorUpdateTemplate descriptorUpdateTemplate,
    const VkAllocationCallbacks* pAllocator);

 void __attribute__((__stdcall__)) vkUpdateDescriptorSetWithTemplate(
    VkDevice device,
    VkDescriptorSet descriptorSet,
    VkDescriptorUpdateTemplate descriptorUpdateTemplate,
    const void* pData);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceExternalBufferProperties(
    VkPhysicalDevice physicalDevice,
    const VkPhysicalDeviceExternalBufferInfo* pExternalBufferInfo,
    VkExternalBufferProperties* pExternalBufferProperties);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceExternalFenceProperties(
    VkPhysicalDevice physicalDevice,
    const VkPhysicalDeviceExternalFenceInfo* pExternalFenceInfo,
    VkExternalFenceProperties* pExternalFenceProperties);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceExternalSemaphoreProperties(
    VkPhysicalDevice physicalDevice,
    const VkPhysicalDeviceExternalSemaphoreInfo* pExternalSemaphoreInfo,
    VkExternalSemaphoreProperties* pExternalSemaphoreProperties);

 void __attribute__((__stdcall__)) vkGetDescriptorSetLayoutSupport(
    VkDevice device,
    const VkDescriptorSetLayoutCreateInfo* pCreateInfo,
    VkDescriptorSetLayoutSupport* pSupport);
# 5930 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkDriverId {
    VK_DRIVER_ID_AMD_PROPRIETARY = 1,
    VK_DRIVER_ID_AMD_OPEN_SOURCE = 2,
    VK_DRIVER_ID_MESA_RADV = 3,
    VK_DRIVER_ID_NVIDIA_PROPRIETARY = 4,
    VK_DRIVER_ID_INTEL_PROPRIETARY_WINDOWS = 5,
    VK_DRIVER_ID_INTEL_OPEN_SOURCE_MESA = 6,
    VK_DRIVER_ID_IMAGINATION_PROPRIETARY = 7,
    VK_DRIVER_ID_QUALCOMM_PROPRIETARY = 8,
    VK_DRIVER_ID_ARM_PROPRIETARY = 9,
    VK_DRIVER_ID_GOOGLE_SWIFTSHADER = 10,
    VK_DRIVER_ID_GGP_PROPRIETARY = 11,
    VK_DRIVER_ID_BROADCOM_PROPRIETARY = 12,
    VK_DRIVER_ID_MESA_LLVMPIPE = 13,
    VK_DRIVER_ID_MOLTENVK = 14,
    VK_DRIVER_ID_COREAVI_PROPRIETARY = 15,
    VK_DRIVER_ID_JUICE_PROPRIETARY = 16,
    VK_DRIVER_ID_VERISILICON_PROPRIETARY = 17,
    VK_DRIVER_ID_MESA_TURNIP = 18,
    VK_DRIVER_ID_MESA_V3DV = 19,
    VK_DRIVER_ID_MESA_PANVK = 20,
    VK_DRIVER_ID_SAMSUNG_PROPRIETARY = 21,
    VK_DRIVER_ID_MESA_VENUS = 22,
    VK_DRIVER_ID_MESA_DOZEN = 23,
    VK_DRIVER_ID_MESA_NVK = 24,
    VK_DRIVER_ID_IMAGINATION_OPEN_SOURCE_MESA = 25,
    VK_DRIVER_ID_MESA_HONEYKRISP = 26,
    VK_DRIVER_ID_VULKAN_SC_EMULATION_ON_VULKAN = 27,
    VK_DRIVER_ID_AMD_PROPRIETARY_KHR = VK_DRIVER_ID_AMD_PROPRIETARY,
    VK_DRIVER_ID_AMD_OPEN_SOURCE_KHR = VK_DRIVER_ID_AMD_OPEN_SOURCE,
    VK_DRIVER_ID_MESA_RADV_KHR = VK_DRIVER_ID_MESA_RADV,
    VK_DRIVER_ID_NVIDIA_PROPRIETARY_KHR = VK_DRIVER_ID_NVIDIA_PROPRIETARY,
    VK_DRIVER_ID_INTEL_PROPRIETARY_WINDOWS_KHR = VK_DRIVER_ID_INTEL_PROPRIETARY_WINDOWS,
    VK_DRIVER_ID_INTEL_OPEN_SOURCE_MESA_KHR = VK_DRIVER_ID_INTEL_OPEN_SOURCE_MESA,
    VK_DRIVER_ID_IMAGINATION_PROPRIETARY_KHR = VK_DRIVER_ID_IMAGINATION_PROPRIETARY,
    VK_DRIVER_ID_QUALCOMM_PROPRIETARY_KHR = VK_DRIVER_ID_QUALCOMM_PROPRIETARY,
    VK_DRIVER_ID_ARM_PROPRIETARY_KHR = VK_DRIVER_ID_ARM_PROPRIETARY,
    VK_DRIVER_ID_GOOGLE_SWIFTSHADER_KHR = VK_DRIVER_ID_GOOGLE_SWIFTSHADER,
    VK_DRIVER_ID_GGP_PROPRIETARY_KHR = VK_DRIVER_ID_GGP_PROPRIETARY,
    VK_DRIVER_ID_BROADCOM_PROPRIETARY_KHR = VK_DRIVER_ID_BROADCOM_PROPRIETARY,
    VK_DRIVER_ID_MAX_ENUM = 0x7FFFFFFF
} VkDriverId;

typedef enum VkShaderFloatControlsIndependence {
    VK_SHADER_FLOAT_CONTROLS_INDEPENDENCE_32_BIT_ONLY = 0,
    VK_SHADER_FLOAT_CONTROLS_INDEPENDENCE_ALL = 1,
    VK_SHADER_FLOAT_CONTROLS_INDEPENDENCE_NONE = 2,
    VK_SHADER_FLOAT_CONTROLS_INDEPENDENCE_32_BIT_ONLY_KHR = VK_SHADER_FLOAT_CONTROLS_INDEPENDENCE_32_BIT_ONLY,
    VK_SHADER_FLOAT_CONTROLS_INDEPENDENCE_ALL_KHR = VK_SHADER_FLOAT_CONTROLS_INDEPENDENCE_ALL,
    VK_SHADER_FLOAT_CONTROLS_INDEPENDENCE_NONE_KHR = VK_SHADER_FLOAT_CONTROLS_INDEPENDENCE_NONE,
    VK_SHADER_FLOAT_CONTROLS_INDEPENDENCE_MAX_ENUM = 0x7FFFFFFF
} VkShaderFloatControlsIndependence;

typedef enum VkSamplerReductionMode {
    VK_SAMPLER_REDUCTION_MODE_WEIGHTED_AVERAGE = 0,
    VK_SAMPLER_REDUCTION_MODE_MIN = 1,
    VK_SAMPLER_REDUCTION_MODE_MAX = 2,
    VK_SAMPLER_REDUCTION_MODE_WEIGHTED_AVERAGE_RANGECLAMP_QCOM = 1000521000,
    VK_SAMPLER_REDUCTION_MODE_WEIGHTED_AVERAGE_EXT = VK_SAMPLER_REDUCTION_MODE_WEIGHTED_AVERAGE,
    VK_SAMPLER_REDUCTION_MODE_MIN_EXT = VK_SAMPLER_REDUCTION_MODE_MIN,
    VK_SAMPLER_REDUCTION_MODE_MAX_EXT = VK_SAMPLER_REDUCTION_MODE_MAX,
    VK_SAMPLER_REDUCTION_MODE_MAX_ENUM = 0x7FFFFFFF
} VkSamplerReductionMode;

typedef enum VkSemaphoreType {
    VK_SEMAPHORE_TYPE_BINARY = 0,
    VK_SEMAPHORE_TYPE_TIMELINE = 1,
    VK_SEMAPHORE_TYPE_BINARY_KHR = VK_SEMAPHORE_TYPE_BINARY,
    VK_SEMAPHORE_TYPE_TIMELINE_KHR = VK_SEMAPHORE_TYPE_TIMELINE,
    VK_SEMAPHORE_TYPE_MAX_ENUM = 0x7FFFFFFF
} VkSemaphoreType;

typedef enum VkResolveModeFlagBits {
    VK_RESOLVE_MODE_NONE = 0,
    VK_RESOLVE_MODE_SAMPLE_ZERO_BIT = 0x00000001,
    VK_RESOLVE_MODE_AVERAGE_BIT = 0x00000002,
    VK_RESOLVE_MODE_MIN_BIT = 0x00000004,
    VK_RESOLVE_MODE_MAX_BIT = 0x00000008,
    VK_RESOLVE_MODE_EXTERNAL_FORMAT_DOWNSAMPLE_ANDROID = 0x00000010,
    VK_RESOLVE_MODE_NONE_KHR = VK_RESOLVE_MODE_NONE,
    VK_RESOLVE_MODE_SAMPLE_ZERO_BIT_KHR = VK_RESOLVE_MODE_SAMPLE_ZERO_BIT,
    VK_RESOLVE_MODE_AVERAGE_BIT_KHR = VK_RESOLVE_MODE_AVERAGE_BIT,
    VK_RESOLVE_MODE_MIN_BIT_KHR = VK_RESOLVE_MODE_MIN_BIT,
    VK_RESOLVE_MODE_MAX_BIT_KHR = VK_RESOLVE_MODE_MAX_BIT,
    VK_RESOLVE_MODE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkResolveModeFlagBits;
typedef VkFlags VkResolveModeFlags;

typedef enum VkDescriptorBindingFlagBits {
    VK_DESCRIPTOR_BINDING_UPDATE_AFTER_BIND_BIT = 0x00000001,
    VK_DESCRIPTOR_BINDING_UPDATE_UNUSED_WHILE_PENDING_BIT = 0x00000002,
    VK_DESCRIPTOR_BINDING_PARTIALLY_BOUND_BIT = 0x00000004,
    VK_DESCRIPTOR_BINDING_VARIABLE_DESCRIPTOR_COUNT_BIT = 0x00000008,
    VK_DESCRIPTOR_BINDING_UPDATE_AFTER_BIND_BIT_EXT = VK_DESCRIPTOR_BINDING_UPDATE_AFTER_BIND_BIT,
    VK_DESCRIPTOR_BINDING_UPDATE_UNUSED_WHILE_PENDING_BIT_EXT = VK_DESCRIPTOR_BINDING_UPDATE_UNUSED_WHILE_PENDING_BIT,
    VK_DESCRIPTOR_BINDING_PARTIALLY_BOUND_BIT_EXT = VK_DESCRIPTOR_BINDING_PARTIALLY_BOUND_BIT,
    VK_DESCRIPTOR_BINDING_VARIABLE_DESCRIPTOR_COUNT_BIT_EXT = VK_DESCRIPTOR_BINDING_VARIABLE_DESCRIPTOR_COUNT_BIT,
    VK_DESCRIPTOR_BINDING_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkDescriptorBindingFlagBits;
typedef VkFlags VkDescriptorBindingFlags;

typedef enum VkSemaphoreWaitFlagBits {
    VK_SEMAPHORE_WAIT_ANY_BIT = 0x00000001,
    VK_SEMAPHORE_WAIT_ANY_BIT_KHR = VK_SEMAPHORE_WAIT_ANY_BIT,
    VK_SEMAPHORE_WAIT_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkSemaphoreWaitFlagBits;
typedef VkFlags VkSemaphoreWaitFlags;
typedef struct VkPhysicalDeviceVulkan11Features {
    VkStructureType sType;
    void* pNext;
    VkBool32 storageBuffer16BitAccess;
    VkBool32 uniformAndStorageBuffer16BitAccess;
    VkBool32 storagePushConstant16;
    VkBool32 storageInputOutput16;
    VkBool32 multiview;
    VkBool32 multiviewGeometryShader;
    VkBool32 multiviewTessellationShader;
    VkBool32 variablePointersStorageBuffer;
    VkBool32 variablePointers;
    VkBool32 protectedMemory;
    VkBool32 samplerYcbcrConversion;
    VkBool32 shaderDrawParameters;
} VkPhysicalDeviceVulkan11Features;

typedef struct VkPhysicalDeviceVulkan11Properties {
    VkStructureType sType;
    void* pNext;
    uint8_t deviceUUID[16U];
    uint8_t driverUUID[16U];
    uint8_t deviceLUID[8U];
    uint32_t deviceNodeMask;
    VkBool32 deviceLUIDValid;
    uint32_t subgroupSize;
    VkShaderStageFlags subgroupSupportedStages;
    VkSubgroupFeatureFlags subgroupSupportedOperations;
    VkBool32 subgroupQuadOperationsInAllStages;
    VkPointClippingBehavior pointClippingBehavior;
    uint32_t maxMultiviewViewCount;
    uint32_t maxMultiviewInstanceIndex;
    VkBool32 protectedNoFault;
    uint32_t maxPerSetDescriptors;
    VkDeviceSize maxMemoryAllocationSize;
} VkPhysicalDeviceVulkan11Properties;

typedef struct VkPhysicalDeviceVulkan12Features {
    VkStructureType sType;
    void* pNext;
    VkBool32 samplerMirrorClampToEdge;
    VkBool32 drawIndirectCount;
    VkBool32 storageBuffer8BitAccess;
    VkBool32 uniformAndStorageBuffer8BitAccess;
    VkBool32 storagePushConstant8;
    VkBool32 shaderBufferInt64Atomics;
    VkBool32 shaderSharedInt64Atomics;
    VkBool32 shaderFloat16;
    VkBool32 shaderInt8;
    VkBool32 descriptorIndexing;
    VkBool32 shaderInputAttachmentArrayDynamicIndexing;
    VkBool32 shaderUniformTexelBufferArrayDynamicIndexing;
    VkBool32 shaderStorageTexelBufferArrayDynamicIndexing;
    VkBool32 shaderUniformBufferArrayNonUniformIndexing;
    VkBool32 shaderSampledImageArrayNonUniformIndexing;
    VkBool32 shaderStorageBufferArrayNonUniformIndexing;
    VkBool32 shaderStorageImageArrayNonUniformIndexing;
    VkBool32 shaderInputAttachmentArrayNonUniformIndexing;
    VkBool32 shaderUniformTexelBufferArrayNonUniformIndexing;
    VkBool32 shaderStorageTexelBufferArrayNonUniformIndexing;
    VkBool32 descriptorBindingUniformBufferUpdateAfterBind;
    VkBool32 descriptorBindingSampledImageUpdateAfterBind;
    VkBool32 descriptorBindingStorageImageUpdateAfterBind;
    VkBool32 descriptorBindingStorageBufferUpdateAfterBind;
    VkBool32 descriptorBindingUniformTexelBufferUpdateAfterBind;
    VkBool32 descriptorBindingStorageTexelBufferUpdateAfterBind;
    VkBool32 descriptorBindingUpdateUnusedWhilePending;
    VkBool32 descriptorBindingPartiallyBound;
    VkBool32 descriptorBindingVariableDescriptorCount;
    VkBool32 runtimeDescriptorArray;
    VkBool32 samplerFilterMinmax;
    VkBool32 scalarBlockLayout;
    VkBool32 imagelessFramebuffer;
    VkBool32 uniformBufferStandardLayout;
    VkBool32 shaderSubgroupExtendedTypes;
    VkBool32 separateDepthStencilLayouts;
    VkBool32 hostQueryReset;
    VkBool32 timelineSemaphore;
    VkBool32 bufferDeviceAddress;
    VkBool32 bufferDeviceAddressCaptureReplay;
    VkBool32 bufferDeviceAddressMultiDevice;
    VkBool32 vulkanMemoryModel;
    VkBool32 vulkanMemoryModelDeviceScope;
    VkBool32 vulkanMemoryModelAvailabilityVisibilityChains;
    VkBool32 shaderOutputViewportIndex;
    VkBool32 shaderOutputLayer;
    VkBool32 subgroupBroadcastDynamicId;
} VkPhysicalDeviceVulkan12Features;

typedef struct VkConformanceVersion {
    uint8_t major;
    uint8_t minor;
    uint8_t subminor;
    uint8_t patch;
} VkConformanceVersion;

typedef struct VkPhysicalDeviceVulkan12Properties {
    VkStructureType sType;
    void* pNext;
    VkDriverId driverID;
    char driverName[256U];
    char driverInfo[256U];
    VkConformanceVersion conformanceVersion;
    VkShaderFloatControlsIndependence denormBehaviorIndependence;
    VkShaderFloatControlsIndependence roundingModeIndependence;
    VkBool32 shaderSignedZeroInfNanPreserveFloat16;
    VkBool32 shaderSignedZeroInfNanPreserveFloat32;
    VkBool32 shaderSignedZeroInfNanPreserveFloat64;
    VkBool32 shaderDenormPreserveFloat16;
    VkBool32 shaderDenormPreserveFloat32;
    VkBool32 shaderDenormPreserveFloat64;
    VkBool32 shaderDenormFlushToZeroFloat16;
    VkBool32 shaderDenormFlushToZeroFloat32;
    VkBool32 shaderDenormFlushToZeroFloat64;
    VkBool32 shaderRoundingModeRTEFloat16;
    VkBool32 shaderRoundingModeRTEFloat32;
    VkBool32 shaderRoundingModeRTEFloat64;
    VkBool32 shaderRoundingModeRTZFloat16;
    VkBool32 shaderRoundingModeRTZFloat32;
    VkBool32 shaderRoundingModeRTZFloat64;
    uint32_t maxUpdateAfterBindDescriptorsInAllPools;
    VkBool32 shaderUniformBufferArrayNonUniformIndexingNative;
    VkBool32 shaderSampledImageArrayNonUniformIndexingNative;
    VkBool32 shaderStorageBufferArrayNonUniformIndexingNative;
    VkBool32 shaderStorageImageArrayNonUniformIndexingNative;
    VkBool32 shaderInputAttachmentArrayNonUniformIndexingNative;
    VkBool32 robustBufferAccessUpdateAfterBind;
    VkBool32 quadDivergentImplicitLod;
    uint32_t maxPerStageDescriptorUpdateAfterBindSamplers;
    uint32_t maxPerStageDescriptorUpdateAfterBindUniformBuffers;
    uint32_t maxPerStageDescriptorUpdateAfterBindStorageBuffers;
    uint32_t maxPerStageDescriptorUpdateAfterBindSampledImages;
    uint32_t maxPerStageDescriptorUpdateAfterBindStorageImages;
    uint32_t maxPerStageDescriptorUpdateAfterBindInputAttachments;
    uint32_t maxPerStageUpdateAfterBindResources;
    uint32_t maxDescriptorSetUpdateAfterBindSamplers;
    uint32_t maxDescriptorSetUpdateAfterBindUniformBuffers;
    uint32_t maxDescriptorSetUpdateAfterBindUniformBuffersDynamic;
    uint32_t maxDescriptorSetUpdateAfterBindStorageBuffers;
    uint32_t maxDescriptorSetUpdateAfterBindStorageBuffersDynamic;
    uint32_t maxDescriptorSetUpdateAfterBindSampledImages;
    uint32_t maxDescriptorSetUpdateAfterBindStorageImages;
    uint32_t maxDescriptorSetUpdateAfterBindInputAttachments;
    VkResolveModeFlags supportedDepthResolveModes;
    VkResolveModeFlags supportedStencilResolveModes;
    VkBool32 independentResolveNone;
    VkBool32 independentResolve;
    VkBool32 filterMinmaxSingleComponentFormats;
    VkBool32 filterMinmaxImageComponentMapping;
    uint64_t maxTimelineSemaphoreValueDifference;
    VkSampleCountFlags framebufferIntegerColorSampleCounts;
} VkPhysicalDeviceVulkan12Properties;

typedef struct VkImageFormatListCreateInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t viewFormatCount;
    const VkFormat* pViewFormats;
} VkImageFormatListCreateInfo;

typedef struct VkAttachmentDescription2 {
    VkStructureType sType;
    const void* pNext;
    VkAttachmentDescriptionFlags flags;
    VkFormat format;
    VkSampleCountFlagBits samples;
    VkAttachmentLoadOp loadOp;
    VkAttachmentStoreOp storeOp;
    VkAttachmentLoadOp stencilLoadOp;
    VkAttachmentStoreOp stencilStoreOp;
    VkImageLayout initialLayout;
    VkImageLayout finalLayout;
} VkAttachmentDescription2;

typedef struct VkAttachmentReference2 {
    VkStructureType sType;
    const void* pNext;
    uint32_t attachment;
    VkImageLayout layout;
    VkImageAspectFlags aspectMask;
} VkAttachmentReference2;

typedef struct VkSubpassDescription2 {
    VkStructureType sType;
    const void* pNext;
    VkSubpassDescriptionFlags flags;
    VkPipelineBindPoint pipelineBindPoint;
    uint32_t viewMask;
    uint32_t inputAttachmentCount;
    const VkAttachmentReference2* pInputAttachments;
    uint32_t colorAttachmentCount;
    const VkAttachmentReference2* pColorAttachments;
    const VkAttachmentReference2* pResolveAttachments;
    const VkAttachmentReference2* pDepthStencilAttachment;
    uint32_t preserveAttachmentCount;
    const uint32_t* pPreserveAttachments;
} VkSubpassDescription2;

typedef struct VkSubpassDependency2 {
    VkStructureType sType;
    const void* pNext;
    uint32_t srcSubpass;
    uint32_t dstSubpass;
    VkPipelineStageFlags srcStageMask;
    VkPipelineStageFlags dstStageMask;
    VkAccessFlags srcAccessMask;
    VkAccessFlags dstAccessMask;
    VkDependencyFlags dependencyFlags;
    int32_t viewOffset;
} VkSubpassDependency2;

typedef struct VkRenderPassCreateInfo2 {
    VkStructureType sType;
    const void* pNext;
    VkRenderPassCreateFlags flags;
    uint32_t attachmentCount;
    const VkAttachmentDescription2* pAttachments;
    uint32_t subpassCount;
    const VkSubpassDescription2* pSubpasses;
    uint32_t dependencyCount;
    const VkSubpassDependency2* pDependencies;
    uint32_t correlatedViewMaskCount;
    const uint32_t* pCorrelatedViewMasks;
} VkRenderPassCreateInfo2;

typedef struct VkSubpassBeginInfo {
    VkStructureType sType;
    const void* pNext;
    VkSubpassContents contents;
} VkSubpassBeginInfo;

typedef struct VkSubpassEndInfo {
    VkStructureType sType;
    const void* pNext;
} VkSubpassEndInfo;

typedef struct VkPhysicalDevice8BitStorageFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 storageBuffer8BitAccess;
    VkBool32 uniformAndStorageBuffer8BitAccess;
    VkBool32 storagePushConstant8;
} VkPhysicalDevice8BitStorageFeatures;

typedef struct VkPhysicalDeviceDriverProperties {
    VkStructureType sType;
    void* pNext;
    VkDriverId driverID;
    char driverName[256U];
    char driverInfo[256U];
    VkConformanceVersion conformanceVersion;
} VkPhysicalDeviceDriverProperties;

typedef struct VkPhysicalDeviceShaderAtomicInt64Features {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderBufferInt64Atomics;
    VkBool32 shaderSharedInt64Atomics;
} VkPhysicalDeviceShaderAtomicInt64Features;

typedef struct VkPhysicalDeviceShaderFloat16Int8Features {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderFloat16;
    VkBool32 shaderInt8;
} VkPhysicalDeviceShaderFloat16Int8Features;

typedef struct VkPhysicalDeviceFloatControlsProperties {
    VkStructureType sType;
    void* pNext;
    VkShaderFloatControlsIndependence denormBehaviorIndependence;
    VkShaderFloatControlsIndependence roundingModeIndependence;
    VkBool32 shaderSignedZeroInfNanPreserveFloat16;
    VkBool32 shaderSignedZeroInfNanPreserveFloat32;
    VkBool32 shaderSignedZeroInfNanPreserveFloat64;
    VkBool32 shaderDenormPreserveFloat16;
    VkBool32 shaderDenormPreserveFloat32;
    VkBool32 shaderDenormPreserveFloat64;
    VkBool32 shaderDenormFlushToZeroFloat16;
    VkBool32 shaderDenormFlushToZeroFloat32;
    VkBool32 shaderDenormFlushToZeroFloat64;
    VkBool32 shaderRoundingModeRTEFloat16;
    VkBool32 shaderRoundingModeRTEFloat32;
    VkBool32 shaderRoundingModeRTEFloat64;
    VkBool32 shaderRoundingModeRTZFloat16;
    VkBool32 shaderRoundingModeRTZFloat32;
    VkBool32 shaderRoundingModeRTZFloat64;
} VkPhysicalDeviceFloatControlsProperties;

typedef struct VkDescriptorSetLayoutBindingFlagsCreateInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t bindingCount;
    const VkDescriptorBindingFlags* pBindingFlags;
} VkDescriptorSetLayoutBindingFlagsCreateInfo;

typedef struct VkPhysicalDeviceDescriptorIndexingFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderInputAttachmentArrayDynamicIndexing;
    VkBool32 shaderUniformTexelBufferArrayDynamicIndexing;
    VkBool32 shaderStorageTexelBufferArrayDynamicIndexing;
    VkBool32 shaderUniformBufferArrayNonUniformIndexing;
    VkBool32 shaderSampledImageArrayNonUniformIndexing;
    VkBool32 shaderStorageBufferArrayNonUniformIndexing;
    VkBool32 shaderStorageImageArrayNonUniformIndexing;
    VkBool32 shaderInputAttachmentArrayNonUniformIndexing;
    VkBool32 shaderUniformTexelBufferArrayNonUniformIndexing;
    VkBool32 shaderStorageTexelBufferArrayNonUniformIndexing;
    VkBool32 descriptorBindingUniformBufferUpdateAfterBind;
    VkBool32 descriptorBindingSampledImageUpdateAfterBind;
    VkBool32 descriptorBindingStorageImageUpdateAfterBind;
    VkBool32 descriptorBindingStorageBufferUpdateAfterBind;
    VkBool32 descriptorBindingUniformTexelBufferUpdateAfterBind;
    VkBool32 descriptorBindingStorageTexelBufferUpdateAfterBind;
    VkBool32 descriptorBindingUpdateUnusedWhilePending;
    VkBool32 descriptorBindingPartiallyBound;
    VkBool32 descriptorBindingVariableDescriptorCount;
    VkBool32 runtimeDescriptorArray;
} VkPhysicalDeviceDescriptorIndexingFeatures;

typedef struct VkPhysicalDeviceDescriptorIndexingProperties {
    VkStructureType sType;
    void* pNext;
    uint32_t maxUpdateAfterBindDescriptorsInAllPools;
    VkBool32 shaderUniformBufferArrayNonUniformIndexingNative;
    VkBool32 shaderSampledImageArrayNonUniformIndexingNative;
    VkBool32 shaderStorageBufferArrayNonUniformIndexingNative;
    VkBool32 shaderStorageImageArrayNonUniformIndexingNative;
    VkBool32 shaderInputAttachmentArrayNonUniformIndexingNative;
    VkBool32 robustBufferAccessUpdateAfterBind;
    VkBool32 quadDivergentImplicitLod;
    uint32_t maxPerStageDescriptorUpdateAfterBindSamplers;
    uint32_t maxPerStageDescriptorUpdateAfterBindUniformBuffers;
    uint32_t maxPerStageDescriptorUpdateAfterBindStorageBuffers;
    uint32_t maxPerStageDescriptorUpdateAfterBindSampledImages;
    uint32_t maxPerStageDescriptorUpdateAfterBindStorageImages;
    uint32_t maxPerStageDescriptorUpdateAfterBindInputAttachments;
    uint32_t maxPerStageUpdateAfterBindResources;
    uint32_t maxDescriptorSetUpdateAfterBindSamplers;
    uint32_t maxDescriptorSetUpdateAfterBindUniformBuffers;
    uint32_t maxDescriptorSetUpdateAfterBindUniformBuffersDynamic;
    uint32_t maxDescriptorSetUpdateAfterBindStorageBuffers;
    uint32_t maxDescriptorSetUpdateAfterBindStorageBuffersDynamic;
    uint32_t maxDescriptorSetUpdateAfterBindSampledImages;
    uint32_t maxDescriptorSetUpdateAfterBindStorageImages;
    uint32_t maxDescriptorSetUpdateAfterBindInputAttachments;
} VkPhysicalDeviceDescriptorIndexingProperties;

typedef struct VkDescriptorSetVariableDescriptorCountAllocateInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t descriptorSetCount;
    const uint32_t* pDescriptorCounts;
} VkDescriptorSetVariableDescriptorCountAllocateInfo;

typedef struct VkDescriptorSetVariableDescriptorCountLayoutSupport {
    VkStructureType sType;
    void* pNext;
    uint32_t maxVariableDescriptorCount;
} VkDescriptorSetVariableDescriptorCountLayoutSupport;

typedef struct VkSubpassDescriptionDepthStencilResolve {
    VkStructureType sType;
    const void* pNext;
    VkResolveModeFlagBits depthResolveMode;
    VkResolveModeFlagBits stencilResolveMode;
    const VkAttachmentReference2* pDepthStencilResolveAttachment;
} VkSubpassDescriptionDepthStencilResolve;

typedef struct VkPhysicalDeviceDepthStencilResolveProperties {
    VkStructureType sType;
    void* pNext;
    VkResolveModeFlags supportedDepthResolveModes;
    VkResolveModeFlags supportedStencilResolveModes;
    VkBool32 independentResolveNone;
    VkBool32 independentResolve;
} VkPhysicalDeviceDepthStencilResolveProperties;

typedef struct VkPhysicalDeviceScalarBlockLayoutFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 scalarBlockLayout;
} VkPhysicalDeviceScalarBlockLayoutFeatures;

typedef struct VkImageStencilUsageCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkImageUsageFlags stencilUsage;
} VkImageStencilUsageCreateInfo;

typedef struct VkSamplerReductionModeCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkSamplerReductionMode reductionMode;
} VkSamplerReductionModeCreateInfo;

typedef struct VkPhysicalDeviceSamplerFilterMinmaxProperties {
    VkStructureType sType;
    void* pNext;
    VkBool32 filterMinmaxSingleComponentFormats;
    VkBool32 filterMinmaxImageComponentMapping;
} VkPhysicalDeviceSamplerFilterMinmaxProperties;

typedef struct VkPhysicalDeviceVulkanMemoryModelFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 vulkanMemoryModel;
    VkBool32 vulkanMemoryModelDeviceScope;
    VkBool32 vulkanMemoryModelAvailabilityVisibilityChains;
} VkPhysicalDeviceVulkanMemoryModelFeatures;

typedef struct VkPhysicalDeviceImagelessFramebufferFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 imagelessFramebuffer;
} VkPhysicalDeviceImagelessFramebufferFeatures;

typedef struct VkFramebufferAttachmentImageInfo {
    VkStructureType sType;
    const void* pNext;
    VkImageCreateFlags flags;
    VkImageUsageFlags usage;
    uint32_t width;
    uint32_t height;
    uint32_t layerCount;
    uint32_t viewFormatCount;
    const VkFormat* pViewFormats;
} VkFramebufferAttachmentImageInfo;

typedef struct VkFramebufferAttachmentsCreateInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t attachmentImageInfoCount;
    const VkFramebufferAttachmentImageInfo* pAttachmentImageInfos;
} VkFramebufferAttachmentsCreateInfo;

typedef struct VkRenderPassAttachmentBeginInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t attachmentCount;
    const VkImageView* pAttachments;
} VkRenderPassAttachmentBeginInfo;

typedef struct VkPhysicalDeviceUniformBufferStandardLayoutFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 uniformBufferStandardLayout;
} VkPhysicalDeviceUniformBufferStandardLayoutFeatures;

typedef struct VkPhysicalDeviceShaderSubgroupExtendedTypesFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderSubgroupExtendedTypes;
} VkPhysicalDeviceShaderSubgroupExtendedTypesFeatures;

typedef struct VkPhysicalDeviceSeparateDepthStencilLayoutsFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 separateDepthStencilLayouts;
} VkPhysicalDeviceSeparateDepthStencilLayoutsFeatures;

typedef struct VkAttachmentReferenceStencilLayout {
    VkStructureType sType;
    void* pNext;
    VkImageLayout stencilLayout;
} VkAttachmentReferenceStencilLayout;

typedef struct VkAttachmentDescriptionStencilLayout {
    VkStructureType sType;
    void* pNext;
    VkImageLayout stencilInitialLayout;
    VkImageLayout stencilFinalLayout;
} VkAttachmentDescriptionStencilLayout;

typedef struct VkPhysicalDeviceHostQueryResetFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 hostQueryReset;
} VkPhysicalDeviceHostQueryResetFeatures;

typedef struct VkPhysicalDeviceTimelineSemaphoreFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 timelineSemaphore;
} VkPhysicalDeviceTimelineSemaphoreFeatures;

typedef struct VkPhysicalDeviceTimelineSemaphoreProperties {
    VkStructureType sType;
    void* pNext;
    uint64_t maxTimelineSemaphoreValueDifference;
} VkPhysicalDeviceTimelineSemaphoreProperties;

typedef struct VkSemaphoreTypeCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkSemaphoreType semaphoreType;
    uint64_t initialValue;
} VkSemaphoreTypeCreateInfo;

typedef struct VkTimelineSemaphoreSubmitInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t waitSemaphoreValueCount;
    const uint64_t* pWaitSemaphoreValues;
    uint32_t signalSemaphoreValueCount;
    const uint64_t* pSignalSemaphoreValues;
} VkTimelineSemaphoreSubmitInfo;

typedef struct VkSemaphoreWaitInfo {
    VkStructureType sType;
    const void* pNext;
    VkSemaphoreWaitFlags flags;
    uint32_t semaphoreCount;
    const VkSemaphore* pSemaphores;
    const uint64_t* pValues;
} VkSemaphoreWaitInfo;

typedef struct VkSemaphoreSignalInfo {
    VkStructureType sType;
    const void* pNext;
    VkSemaphore semaphore;
    uint64_t value;
} VkSemaphoreSignalInfo;

typedef struct VkPhysicalDeviceBufferDeviceAddressFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 bufferDeviceAddress;
    VkBool32 bufferDeviceAddressCaptureReplay;
    VkBool32 bufferDeviceAddressMultiDevice;
} VkPhysicalDeviceBufferDeviceAddressFeatures;

typedef struct VkBufferDeviceAddressInfo {
    VkStructureType sType;
    const void* pNext;
    VkBuffer buffer;
} VkBufferDeviceAddressInfo;

typedef struct VkBufferOpaqueCaptureAddressCreateInfo {
    VkStructureType sType;
    const void* pNext;
    uint64_t opaqueCaptureAddress;
} VkBufferOpaqueCaptureAddressCreateInfo;

typedef struct VkMemoryOpaqueCaptureAddressAllocateInfo {
    VkStructureType sType;
    const void* pNext;
    uint64_t opaqueCaptureAddress;
} VkMemoryOpaqueCaptureAddressAllocateInfo;

typedef struct VkDeviceMemoryOpaqueCaptureAddressInfo {
    VkStructureType sType;
    const void* pNext;
    VkDeviceMemory memory;
} VkDeviceMemoryOpaqueCaptureAddressInfo;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawIndirectCount)(VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawIndexedIndirectCount)(VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateRenderPass2)(VkDevice device, const VkRenderPassCreateInfo2* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkRenderPass* pRenderPass);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBeginRenderPass2)(VkCommandBuffer commandBuffer, const VkRenderPassBeginInfo* pRenderPassBegin, const VkSubpassBeginInfo* pSubpassBeginInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdNextSubpass2)(VkCommandBuffer commandBuffer, const VkSubpassBeginInfo* pSubpassBeginInfo, const VkSubpassEndInfo* pSubpassEndInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdEndRenderPass2)(VkCommandBuffer commandBuffer, const VkSubpassEndInfo* pSubpassEndInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkResetQueryPool)(VkDevice device, VkQueryPool queryPool, uint32_t firstQuery, uint32_t queryCount);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetSemaphoreCounterValue)(VkDevice device, VkSemaphore semaphore, uint64_t* pValue);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkWaitSemaphores)(VkDevice device, const VkSemaphoreWaitInfo* pWaitInfo, uint64_t timeout);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkSignalSemaphore)(VkDevice device, const VkSemaphoreSignalInfo* pSignalInfo);
typedef VkDeviceAddress (__attribute__((__stdcall__)) *PFN_vkGetBufferDeviceAddress)(VkDevice device, const VkBufferDeviceAddressInfo* pInfo);
typedef uint64_t (__attribute__((__stdcall__)) *PFN_vkGetBufferOpaqueCaptureAddress)(VkDevice device, const VkBufferDeviceAddressInfo* pInfo);
typedef uint64_t (__attribute__((__stdcall__)) *PFN_vkGetDeviceMemoryOpaqueCaptureAddress)(VkDevice device, const VkDeviceMemoryOpaqueCaptureAddressInfo* pInfo);


 void __attribute__((__stdcall__)) vkCmdDrawIndirectCount(
    VkCommandBuffer commandBuffer,
    VkBuffer buffer,
    VkDeviceSize offset,
    VkBuffer countBuffer,
    VkDeviceSize countBufferOffset,
    uint32_t maxDrawCount,
    uint32_t stride);

 void __attribute__((__stdcall__)) vkCmdDrawIndexedIndirectCount(
    VkCommandBuffer commandBuffer,
    VkBuffer buffer,
    VkDeviceSize offset,
    VkBuffer countBuffer,
    VkDeviceSize countBufferOffset,
    uint32_t maxDrawCount,
    uint32_t stride);

 VkResult __attribute__((__stdcall__)) vkCreateRenderPass2(
    VkDevice device,
    const VkRenderPassCreateInfo2* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkRenderPass* pRenderPass);

 void __attribute__((__stdcall__)) vkCmdBeginRenderPass2(
    VkCommandBuffer commandBuffer,
    const VkRenderPassBeginInfo* pRenderPassBegin,
    const VkSubpassBeginInfo* pSubpassBeginInfo);

 void __attribute__((__stdcall__)) vkCmdNextSubpass2(
    VkCommandBuffer commandBuffer,
    const VkSubpassBeginInfo* pSubpassBeginInfo,
    const VkSubpassEndInfo* pSubpassEndInfo);

 void __attribute__((__stdcall__)) vkCmdEndRenderPass2(
    VkCommandBuffer commandBuffer,
    const VkSubpassEndInfo* pSubpassEndInfo);

 void __attribute__((__stdcall__)) vkResetQueryPool(
    VkDevice device,
    VkQueryPool queryPool,
    uint32_t firstQuery,
    uint32_t queryCount);

 VkResult __attribute__((__stdcall__)) vkGetSemaphoreCounterValue(
    VkDevice device,
    VkSemaphore semaphore,
    uint64_t* pValue);

 VkResult __attribute__((__stdcall__)) vkWaitSemaphores(
    VkDevice device,
    const VkSemaphoreWaitInfo* pWaitInfo,
    uint64_t timeout);

 VkResult __attribute__((__stdcall__)) vkSignalSemaphore(
    VkDevice device,
    const VkSemaphoreSignalInfo* pSignalInfo);

 VkDeviceAddress __attribute__((__stdcall__)) vkGetBufferDeviceAddress(
    VkDevice device,
    const VkBufferDeviceAddressInfo* pInfo);

 uint64_t __attribute__((__stdcall__)) vkGetBufferOpaqueCaptureAddress(
    VkDevice device,
    const VkBufferDeviceAddressInfo* pInfo);

 uint64_t __attribute__((__stdcall__)) vkGetDeviceMemoryOpaqueCaptureAddress(
    VkDevice device,
    const VkDeviceMemoryOpaqueCaptureAddressInfo* pInfo);
# 6686 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef uint64_t VkFlags64;
typedef struct VkPrivateDataSlot_T *VkPrivateDataSlot;

typedef enum VkPipelineCreationFeedbackFlagBits {
    VK_PIPELINE_CREATION_FEEDBACK_VALID_BIT = 0x00000001,
    VK_PIPELINE_CREATION_FEEDBACK_APPLICATION_PIPELINE_CACHE_HIT_BIT = 0x00000002,
    VK_PIPELINE_CREATION_FEEDBACK_BASE_PIPELINE_ACCELERATION_BIT = 0x00000004,
    VK_PIPELINE_CREATION_FEEDBACK_VALID_BIT_EXT = VK_PIPELINE_CREATION_FEEDBACK_VALID_BIT,
    VK_PIPELINE_CREATION_FEEDBACK_APPLICATION_PIPELINE_CACHE_HIT_BIT_EXT = VK_PIPELINE_CREATION_FEEDBACK_APPLICATION_PIPELINE_CACHE_HIT_BIT,
    VK_PIPELINE_CREATION_FEEDBACK_BASE_PIPELINE_ACCELERATION_BIT_EXT = VK_PIPELINE_CREATION_FEEDBACK_BASE_PIPELINE_ACCELERATION_BIT,
    VK_PIPELINE_CREATION_FEEDBACK_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkPipelineCreationFeedbackFlagBits;
typedef VkFlags VkPipelineCreationFeedbackFlags;

typedef enum VkToolPurposeFlagBits {
    VK_TOOL_PURPOSE_VALIDATION_BIT = 0x00000001,
    VK_TOOL_PURPOSE_PROFILING_BIT = 0x00000002,
    VK_TOOL_PURPOSE_TRACING_BIT = 0x00000004,
    VK_TOOL_PURPOSE_ADDITIONAL_FEATURES_BIT = 0x00000008,
    VK_TOOL_PURPOSE_MODIFYING_FEATURES_BIT = 0x00000010,
    VK_TOOL_PURPOSE_DEBUG_REPORTING_BIT_EXT = 0x00000020,
    VK_TOOL_PURPOSE_DEBUG_MARKERS_BIT_EXT = 0x00000040,
    VK_TOOL_PURPOSE_VALIDATION_BIT_EXT = VK_TOOL_PURPOSE_VALIDATION_BIT,
    VK_TOOL_PURPOSE_PROFILING_BIT_EXT = VK_TOOL_PURPOSE_PROFILING_BIT,
    VK_TOOL_PURPOSE_TRACING_BIT_EXT = VK_TOOL_PURPOSE_TRACING_BIT,
    VK_TOOL_PURPOSE_ADDITIONAL_FEATURES_BIT_EXT = VK_TOOL_PURPOSE_ADDITIONAL_FEATURES_BIT,
    VK_TOOL_PURPOSE_MODIFYING_FEATURES_BIT_EXT = VK_TOOL_PURPOSE_MODIFYING_FEATURES_BIT,
    VK_TOOL_PURPOSE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkToolPurposeFlagBits;
typedef VkFlags VkToolPurposeFlags;
typedef VkFlags VkPrivateDataSlotCreateFlags;
typedef VkFlags64 VkPipelineStageFlags2;


typedef VkFlags64 VkPipelineStageFlagBits2;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_NONE = 0ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_TOP_OF_PIPE_BIT = 0x00000001ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_DRAW_INDIRECT_BIT = 0x00000002ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_VERTEX_INPUT_BIT = 0x00000004ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_VERTEX_SHADER_BIT = 0x00000008ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_TESSELLATION_CONTROL_SHADER_BIT = 0x00000010ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_TESSELLATION_EVALUATION_SHADER_BIT = 0x00000020ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_GEOMETRY_SHADER_BIT = 0x00000040ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_FRAGMENT_SHADER_BIT = 0x00000080ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_EARLY_FRAGMENT_TESTS_BIT = 0x00000100ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_LATE_FRAGMENT_TESTS_BIT = 0x00000200ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_COLOR_ATTACHMENT_OUTPUT_BIT = 0x00000400ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT = 0x00000800ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_ALL_TRANSFER_BIT = 0x00001000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_TRANSFER_BIT = 0x00001000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_BOTTOM_OF_PIPE_BIT = 0x00002000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_HOST_BIT = 0x00004000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_ALL_GRAPHICS_BIT = 0x00008000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_ALL_COMMANDS_BIT = 0x00010000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_COPY_BIT = 0x100000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_RESOLVE_BIT = 0x200000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_BLIT_BIT = 0x400000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_CLEAR_BIT = 0x800000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_INDEX_INPUT_BIT = 0x1000000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_VERTEX_ATTRIBUTE_INPUT_BIT = 0x2000000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_PRE_RASTERIZATION_SHADERS_BIT = 0x4000000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_VIDEO_DECODE_BIT_KHR = 0x04000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_VIDEO_ENCODE_BIT_KHR = 0x08000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_NONE_KHR = 0ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_TOP_OF_PIPE_BIT_KHR = 0x00000001ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_DRAW_INDIRECT_BIT_KHR = 0x00000002ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_VERTEX_INPUT_BIT_KHR = 0x00000004ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_VERTEX_SHADER_BIT_KHR = 0x00000008ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_TESSELLATION_CONTROL_SHADER_BIT_KHR = 0x00000010ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_TESSELLATION_EVALUATION_SHADER_BIT_KHR = 0x00000020ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_GEOMETRY_SHADER_BIT_KHR = 0x00000040ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_FRAGMENT_SHADER_BIT_KHR = 0x00000080ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_EARLY_FRAGMENT_TESTS_BIT_KHR = 0x00000100ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_LATE_FRAGMENT_TESTS_BIT_KHR = 0x00000200ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_COLOR_ATTACHMENT_OUTPUT_BIT_KHR = 0x00000400ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT_KHR = 0x00000800ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_ALL_TRANSFER_BIT_KHR = 0x00001000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_TRANSFER_BIT_KHR = 0x00001000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_BOTTOM_OF_PIPE_BIT_KHR = 0x00002000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_HOST_BIT_KHR = 0x00004000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_ALL_GRAPHICS_BIT_KHR = 0x00008000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_ALL_COMMANDS_BIT_KHR = 0x00010000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_COPY_BIT_KHR = 0x100000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_RESOLVE_BIT_KHR = 0x200000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_BLIT_BIT_KHR = 0x400000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_CLEAR_BIT_KHR = 0x800000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_INDEX_INPUT_BIT_KHR = 0x1000000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_VERTEX_ATTRIBUTE_INPUT_BIT_KHR = 0x2000000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_PRE_RASTERIZATION_SHADERS_BIT_KHR = 0x4000000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_TRANSFORM_FEEDBACK_BIT_EXT = 0x01000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_CONDITIONAL_RENDERING_BIT_EXT = 0x00040000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_COMMAND_PREPROCESS_BIT_NV = 0x00020000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_COMMAND_PREPROCESS_BIT_EXT = 0x00020000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_FRAGMENT_SHADING_RATE_ATTACHMENT_BIT_KHR = 0x00400000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_SHADING_RATE_IMAGE_BIT_NV = 0x00400000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_ACCELERATION_STRUCTURE_BUILD_BIT_KHR = 0x02000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_RAY_TRACING_SHADER_BIT_KHR = 0x00200000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_RAY_TRACING_SHADER_BIT_NV = 0x00200000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_ACCELERATION_STRUCTURE_BUILD_BIT_NV = 0x02000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_FRAGMENT_DENSITY_PROCESS_BIT_EXT = 0x00800000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_TASK_SHADER_BIT_NV = 0x00080000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_MESH_SHADER_BIT_NV = 0x00100000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_TASK_SHADER_BIT_EXT = 0x00080000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_MESH_SHADER_BIT_EXT = 0x00100000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_SUBPASS_SHADER_BIT_HUAWEI = 0x8000000000ULL;

static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_SUBPASS_SHADING_BIT_HUAWEI = 0x8000000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_INVOCATION_MASK_BIT_HUAWEI = 0x10000000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_ACCELERATION_STRUCTURE_COPY_BIT_KHR = 0x10000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_MICROMAP_BUILD_BIT_EXT = 0x40000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_CLUSTER_CULLING_SHADER_BIT_HUAWEI = 0x20000000000ULL;
static const VkPipelineStageFlagBits2 VK_PIPELINE_STAGE_2_OPTICAL_FLOW_BIT_NV = 0x20000000ULL;

typedef VkFlags64 VkAccessFlags2;


typedef VkFlags64 VkAccessFlagBits2;
static const VkAccessFlagBits2 VK_ACCESS_2_NONE = 0ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_INDIRECT_COMMAND_READ_BIT = 0x00000001ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_INDEX_READ_BIT = 0x00000002ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_VERTEX_ATTRIBUTE_READ_BIT = 0x00000004ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_UNIFORM_READ_BIT = 0x00000008ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_INPUT_ATTACHMENT_READ_BIT = 0x00000010ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_SHADER_READ_BIT = 0x00000020ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_SHADER_WRITE_BIT = 0x00000040ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_COLOR_ATTACHMENT_READ_BIT = 0x00000080ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_COLOR_ATTACHMENT_WRITE_BIT = 0x00000100ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_DEPTH_STENCIL_ATTACHMENT_READ_BIT = 0x00000200ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT = 0x00000400ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_TRANSFER_READ_BIT = 0x00000800ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_TRANSFER_WRITE_BIT = 0x00001000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_HOST_READ_BIT = 0x00002000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_HOST_WRITE_BIT = 0x00004000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_MEMORY_READ_BIT = 0x00008000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_MEMORY_WRITE_BIT = 0x00010000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_SHADER_SAMPLED_READ_BIT = 0x100000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_SHADER_STORAGE_READ_BIT = 0x200000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_SHADER_STORAGE_WRITE_BIT = 0x400000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_VIDEO_DECODE_READ_BIT_KHR = 0x800000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_VIDEO_DECODE_WRITE_BIT_KHR = 0x1000000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_VIDEO_ENCODE_READ_BIT_KHR = 0x2000000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_VIDEO_ENCODE_WRITE_BIT_KHR = 0x4000000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_NONE_KHR = 0ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_INDIRECT_COMMAND_READ_BIT_KHR = 0x00000001ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_INDEX_READ_BIT_KHR = 0x00000002ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_VERTEX_ATTRIBUTE_READ_BIT_KHR = 0x00000004ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_UNIFORM_READ_BIT_KHR = 0x00000008ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_INPUT_ATTACHMENT_READ_BIT_KHR = 0x00000010ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_SHADER_READ_BIT_KHR = 0x00000020ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_SHADER_WRITE_BIT_KHR = 0x00000040ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_COLOR_ATTACHMENT_READ_BIT_KHR = 0x00000080ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_COLOR_ATTACHMENT_WRITE_BIT_KHR = 0x00000100ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_DEPTH_STENCIL_ATTACHMENT_READ_BIT_KHR = 0x00000200ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT_KHR = 0x00000400ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_TRANSFER_READ_BIT_KHR = 0x00000800ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_TRANSFER_WRITE_BIT_KHR = 0x00001000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_HOST_READ_BIT_KHR = 0x00002000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_HOST_WRITE_BIT_KHR = 0x00004000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_MEMORY_READ_BIT_KHR = 0x00008000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_MEMORY_WRITE_BIT_KHR = 0x00010000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_SHADER_SAMPLED_READ_BIT_KHR = 0x100000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_SHADER_STORAGE_READ_BIT_KHR = 0x200000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_SHADER_STORAGE_WRITE_BIT_KHR = 0x400000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_TRANSFORM_FEEDBACK_WRITE_BIT_EXT = 0x02000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_TRANSFORM_FEEDBACK_COUNTER_READ_BIT_EXT = 0x04000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_TRANSFORM_FEEDBACK_COUNTER_WRITE_BIT_EXT = 0x08000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_CONDITIONAL_RENDERING_READ_BIT_EXT = 0x00100000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_COMMAND_PREPROCESS_READ_BIT_NV = 0x00020000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_COMMAND_PREPROCESS_WRITE_BIT_NV = 0x00040000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_COMMAND_PREPROCESS_READ_BIT_EXT = 0x00020000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_COMMAND_PREPROCESS_WRITE_BIT_EXT = 0x00040000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_FRAGMENT_SHADING_RATE_ATTACHMENT_READ_BIT_KHR = 0x00800000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_SHADING_RATE_IMAGE_READ_BIT_NV = 0x00800000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_ACCELERATION_STRUCTURE_READ_BIT_KHR = 0x00200000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_ACCELERATION_STRUCTURE_WRITE_BIT_KHR = 0x00400000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_ACCELERATION_STRUCTURE_READ_BIT_NV = 0x00200000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_ACCELERATION_STRUCTURE_WRITE_BIT_NV = 0x00400000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_FRAGMENT_DENSITY_MAP_READ_BIT_EXT = 0x01000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_COLOR_ATTACHMENT_READ_NONCOHERENT_BIT_EXT = 0x00080000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_DESCRIPTOR_BUFFER_READ_BIT_EXT = 0x20000000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_INVOCATION_MASK_READ_BIT_HUAWEI = 0x8000000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_SHADER_BINDING_TABLE_READ_BIT_KHR = 0x10000000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_MICROMAP_READ_BIT_EXT = 0x100000000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_MICROMAP_WRITE_BIT_EXT = 0x200000000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_OPTICAL_FLOW_READ_BIT_NV = 0x40000000000ULL;
static const VkAccessFlagBits2 VK_ACCESS_2_OPTICAL_FLOW_WRITE_BIT_NV = 0x80000000000ULL;


typedef enum VkSubmitFlagBits {
    VK_SUBMIT_PROTECTED_BIT = 0x00000001,
    VK_SUBMIT_PROTECTED_BIT_KHR = VK_SUBMIT_PROTECTED_BIT,
    VK_SUBMIT_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkSubmitFlagBits;
typedef VkFlags VkSubmitFlags;

typedef enum VkRenderingFlagBits {
    VK_RENDERING_CONTENTS_SECONDARY_COMMAND_BUFFERS_BIT = 0x00000001,
    VK_RENDERING_SUSPENDING_BIT = 0x00000002,
    VK_RENDERING_RESUMING_BIT = 0x00000004,
    VK_RENDERING_ENABLE_LEGACY_DITHERING_BIT_EXT = 0x00000008,
    VK_RENDERING_CONTENTS_INLINE_BIT_KHR = 0x00000010,
    VK_RENDERING_CONTENTS_SECONDARY_COMMAND_BUFFERS_BIT_KHR = VK_RENDERING_CONTENTS_SECONDARY_COMMAND_BUFFERS_BIT,
    VK_RENDERING_SUSPENDING_BIT_KHR = VK_RENDERING_SUSPENDING_BIT,
    VK_RENDERING_RESUMING_BIT_KHR = VK_RENDERING_RESUMING_BIT,
    VK_RENDERING_CONTENTS_INLINE_BIT_EXT = VK_RENDERING_CONTENTS_INLINE_BIT_KHR,
    VK_RENDERING_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkRenderingFlagBits;
typedef VkFlags VkRenderingFlags;
typedef VkFlags64 VkFormatFeatureFlags2;


typedef VkFlags64 VkFormatFeatureFlagBits2;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_SAMPLED_IMAGE_BIT = 0x00000001ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_STORAGE_IMAGE_BIT = 0x00000002ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_STORAGE_IMAGE_ATOMIC_BIT = 0x00000004ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_UNIFORM_TEXEL_BUFFER_BIT = 0x00000008ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_STORAGE_TEXEL_BUFFER_BIT = 0x00000010ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_STORAGE_TEXEL_BUFFER_ATOMIC_BIT = 0x00000020ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_VERTEX_BUFFER_BIT = 0x00000040ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_COLOR_ATTACHMENT_BIT = 0x00000080ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_COLOR_ATTACHMENT_BLEND_BIT = 0x00000100ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_DEPTH_STENCIL_ATTACHMENT_BIT = 0x00000200ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_BLIT_SRC_BIT = 0x00000400ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_BLIT_DST_BIT = 0x00000800ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_SAMPLED_IMAGE_FILTER_LINEAR_BIT = 0x00001000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_TRANSFER_SRC_BIT = 0x00004000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_TRANSFER_DST_BIT = 0x00008000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_SAMPLED_IMAGE_FILTER_MINMAX_BIT = 0x00010000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_MIDPOINT_CHROMA_SAMPLES_BIT = 0x00020000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_SAMPLED_IMAGE_YCBCR_CONVERSION_LINEAR_FILTER_BIT = 0x00040000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_SAMPLED_IMAGE_YCBCR_CONVERSION_SEPARATE_RECONSTRUCTION_FILTER_BIT = 0x00080000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_BIT = 0x00100000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_FORCEABLE_BIT = 0x00200000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_DISJOINT_BIT = 0x00400000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_COSITED_CHROMA_SAMPLES_BIT = 0x00800000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_STORAGE_READ_WITHOUT_FORMAT_BIT = 0x80000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_STORAGE_WRITE_WITHOUT_FORMAT_BIT = 0x100000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_SAMPLED_IMAGE_DEPTH_COMPARISON_BIT = 0x200000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_SAMPLED_IMAGE_FILTER_CUBIC_BIT = 0x00002000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_HOST_IMAGE_TRANSFER_BIT = 0x400000000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_VIDEO_DECODE_OUTPUT_BIT_KHR = 0x02000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_VIDEO_DECODE_DPB_BIT_KHR = 0x04000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_ACCELERATION_STRUCTURE_VERTEX_BUFFER_BIT_KHR = 0x20000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_FRAGMENT_DENSITY_MAP_BIT_EXT = 0x01000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_FRAGMENT_SHADING_RATE_ATTACHMENT_BIT_KHR = 0x40000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_HOST_IMAGE_TRANSFER_BIT_EXT = 0x400000000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_VIDEO_ENCODE_INPUT_BIT_KHR = 0x08000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_VIDEO_ENCODE_DPB_BIT_KHR = 0x10000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_SAMPLED_IMAGE_BIT_KHR = 0x00000001ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_STORAGE_IMAGE_BIT_KHR = 0x00000002ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_STORAGE_IMAGE_ATOMIC_BIT_KHR = 0x00000004ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_UNIFORM_TEXEL_BUFFER_BIT_KHR = 0x00000008ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_STORAGE_TEXEL_BUFFER_BIT_KHR = 0x00000010ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_STORAGE_TEXEL_BUFFER_ATOMIC_BIT_KHR = 0x00000020ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_VERTEX_BUFFER_BIT_KHR = 0x00000040ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_COLOR_ATTACHMENT_BIT_KHR = 0x00000080ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_COLOR_ATTACHMENT_BLEND_BIT_KHR = 0x00000100ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_DEPTH_STENCIL_ATTACHMENT_BIT_KHR = 0x00000200ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_BLIT_SRC_BIT_KHR = 0x00000400ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_BLIT_DST_BIT_KHR = 0x00000800ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_SAMPLED_IMAGE_FILTER_LINEAR_BIT_KHR = 0x00001000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_TRANSFER_SRC_BIT_KHR = 0x00004000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_TRANSFER_DST_BIT_KHR = 0x00008000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_MIDPOINT_CHROMA_SAMPLES_BIT_KHR = 0x00020000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_SAMPLED_IMAGE_YCBCR_CONVERSION_LINEAR_FILTER_BIT_KHR = 0x00040000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_SAMPLED_IMAGE_YCBCR_CONVERSION_SEPARATE_RECONSTRUCTION_FILTER_BIT_KHR = 0x00080000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_BIT_KHR = 0x00100000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_FORCEABLE_BIT_KHR = 0x00200000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_DISJOINT_BIT_KHR = 0x00400000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_COSITED_CHROMA_SAMPLES_BIT_KHR = 0x00800000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_STORAGE_READ_WITHOUT_FORMAT_BIT_KHR = 0x80000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_STORAGE_WRITE_WITHOUT_FORMAT_BIT_KHR = 0x100000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_SAMPLED_IMAGE_DEPTH_COMPARISON_BIT_KHR = 0x200000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_SAMPLED_IMAGE_FILTER_MINMAX_BIT_KHR = 0x00010000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_SAMPLED_IMAGE_FILTER_CUBIC_BIT_EXT = 0x00002000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_LINEAR_COLOR_ATTACHMENT_BIT_NV = 0x4000000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_WEIGHT_IMAGE_BIT_QCOM = 0x400000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_WEIGHT_SAMPLED_IMAGE_BIT_QCOM = 0x800000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_BLOCK_MATCHING_BIT_QCOM = 0x1000000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_BOX_FILTER_SAMPLED_BIT_QCOM = 0x2000000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_OPTICAL_FLOW_IMAGE_BIT_NV = 0x10000000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_OPTICAL_FLOW_VECTOR_BIT_NV = 0x20000000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_OPTICAL_FLOW_COST_BIT_NV = 0x40000000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_VIDEO_ENCODE_QUANTIZATION_DELTA_MAP_BIT_KHR = 0x2000000000000ULL;
static const VkFormatFeatureFlagBits2 VK_FORMAT_FEATURE_2_VIDEO_ENCODE_EMPHASIS_MAP_BIT_KHR = 0x4000000000000ULL;

typedef struct VkPhysicalDeviceVulkan13Features {
    VkStructureType sType;
    void* pNext;
    VkBool32 robustImageAccess;
    VkBool32 inlineUniformBlock;
    VkBool32 descriptorBindingInlineUniformBlockUpdateAfterBind;
    VkBool32 pipelineCreationCacheControl;
    VkBool32 privateData;
    VkBool32 shaderDemoteToHelperInvocation;
    VkBool32 shaderTerminateInvocation;
    VkBool32 subgroupSizeControl;
    VkBool32 computeFullSubgroups;
    VkBool32 synchronization2;
    VkBool32 textureCompressionASTC_HDR;
    VkBool32 shaderZeroInitializeWorkgroupMemory;
    VkBool32 dynamicRendering;
    VkBool32 shaderIntegerDotProduct;
    VkBool32 maintenance4;
} VkPhysicalDeviceVulkan13Features;

typedef struct VkPhysicalDeviceVulkan13Properties {
    VkStructureType sType;
    void* pNext;
    uint32_t minSubgroupSize;
    uint32_t maxSubgroupSize;
    uint32_t maxComputeWorkgroupSubgroups;
    VkShaderStageFlags requiredSubgroupSizeStages;
    uint32_t maxInlineUniformBlockSize;
    uint32_t maxPerStageDescriptorInlineUniformBlocks;
    uint32_t maxPerStageDescriptorUpdateAfterBindInlineUniformBlocks;
    uint32_t maxDescriptorSetInlineUniformBlocks;
    uint32_t maxDescriptorSetUpdateAfterBindInlineUniformBlocks;
    uint32_t maxInlineUniformTotalSize;
    VkBool32 integerDotProduct8BitUnsignedAccelerated;
    VkBool32 integerDotProduct8BitSignedAccelerated;
    VkBool32 integerDotProduct8BitMixedSignednessAccelerated;
    VkBool32 integerDotProduct4x8BitPackedUnsignedAccelerated;
    VkBool32 integerDotProduct4x8BitPackedSignedAccelerated;
    VkBool32 integerDotProduct4x8BitPackedMixedSignednessAccelerated;
    VkBool32 integerDotProduct16BitUnsignedAccelerated;
    VkBool32 integerDotProduct16BitSignedAccelerated;
    VkBool32 integerDotProduct16BitMixedSignednessAccelerated;
    VkBool32 integerDotProduct32BitUnsignedAccelerated;
    VkBool32 integerDotProduct32BitSignedAccelerated;
    VkBool32 integerDotProduct32BitMixedSignednessAccelerated;
    VkBool32 integerDotProduct64BitUnsignedAccelerated;
    VkBool32 integerDotProduct64BitSignedAccelerated;
    VkBool32 integerDotProduct64BitMixedSignednessAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating8BitUnsignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating8BitSignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating8BitMixedSignednessAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating4x8BitPackedUnsignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating4x8BitPackedSignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating4x8BitPackedMixedSignednessAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating16BitUnsignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating16BitSignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating16BitMixedSignednessAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating32BitUnsignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating32BitSignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating32BitMixedSignednessAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating64BitUnsignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating64BitSignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating64BitMixedSignednessAccelerated;
    VkDeviceSize storageTexelBufferOffsetAlignmentBytes;
    VkBool32 storageTexelBufferOffsetSingleTexelAlignment;
    VkDeviceSize uniformTexelBufferOffsetAlignmentBytes;
    VkBool32 uniformTexelBufferOffsetSingleTexelAlignment;
    VkDeviceSize maxBufferSize;
} VkPhysicalDeviceVulkan13Properties;

typedef struct VkPipelineCreationFeedback {
    VkPipelineCreationFeedbackFlags flags;
    uint64_t duration;
} VkPipelineCreationFeedback;

typedef struct VkPipelineCreationFeedbackCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkPipelineCreationFeedback* pPipelineCreationFeedback;
    uint32_t pipelineStageCreationFeedbackCount;
    VkPipelineCreationFeedback* pPipelineStageCreationFeedbacks;
} VkPipelineCreationFeedbackCreateInfo;

typedef struct VkPhysicalDeviceShaderTerminateInvocationFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderTerminateInvocation;
} VkPhysicalDeviceShaderTerminateInvocationFeatures;

typedef struct VkPhysicalDeviceToolProperties {
    VkStructureType sType;
    void* pNext;
    char name[256U];
    char version[256U];
    VkToolPurposeFlags purposes;
    char description[256U];
    char layer[256U];
} VkPhysicalDeviceToolProperties;

typedef struct VkPhysicalDeviceShaderDemoteToHelperInvocationFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderDemoteToHelperInvocation;
} VkPhysicalDeviceShaderDemoteToHelperInvocationFeatures;

typedef struct VkPhysicalDevicePrivateDataFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 privateData;
} VkPhysicalDevicePrivateDataFeatures;

typedef struct VkDevicePrivateDataCreateInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t privateDataSlotRequestCount;
} VkDevicePrivateDataCreateInfo;

typedef struct VkPrivateDataSlotCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkPrivateDataSlotCreateFlags flags;
} VkPrivateDataSlotCreateInfo;

typedef struct VkPhysicalDevicePipelineCreationCacheControlFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 pipelineCreationCacheControl;
} VkPhysicalDevicePipelineCreationCacheControlFeatures;

typedef struct VkMemoryBarrier2 {
    VkStructureType sType;
    const void* pNext;
    VkPipelineStageFlags2 srcStageMask;
    VkAccessFlags2 srcAccessMask;
    VkPipelineStageFlags2 dstStageMask;
    VkAccessFlags2 dstAccessMask;
} VkMemoryBarrier2;

typedef struct VkBufferMemoryBarrier2 {
    VkStructureType sType;
    const void* pNext;
    VkPipelineStageFlags2 srcStageMask;
    VkAccessFlags2 srcAccessMask;
    VkPipelineStageFlags2 dstStageMask;
    VkAccessFlags2 dstAccessMask;
    uint32_t srcQueueFamilyIndex;
    uint32_t dstQueueFamilyIndex;
    VkBuffer buffer;
    VkDeviceSize offset;
    VkDeviceSize size;
} VkBufferMemoryBarrier2;

typedef struct VkImageMemoryBarrier2 {
    VkStructureType sType;
    const void* pNext;
    VkPipelineStageFlags2 srcStageMask;
    VkAccessFlags2 srcAccessMask;
    VkPipelineStageFlags2 dstStageMask;
    VkAccessFlags2 dstAccessMask;
    VkImageLayout oldLayout;
    VkImageLayout newLayout;
    uint32_t srcQueueFamilyIndex;
    uint32_t dstQueueFamilyIndex;
    VkImage image;
    VkImageSubresourceRange subresourceRange;
} VkImageMemoryBarrier2;

typedef struct VkDependencyInfo {
    VkStructureType sType;
    const void* pNext;
    VkDependencyFlags dependencyFlags;
    uint32_t memoryBarrierCount;
    const VkMemoryBarrier2* pMemoryBarriers;
    uint32_t bufferMemoryBarrierCount;
    const VkBufferMemoryBarrier2* pBufferMemoryBarriers;
    uint32_t imageMemoryBarrierCount;
    const VkImageMemoryBarrier2* pImageMemoryBarriers;
} VkDependencyInfo;

typedef struct VkSemaphoreSubmitInfo {
    VkStructureType sType;
    const void* pNext;
    VkSemaphore semaphore;
    uint64_t value;
    VkPipelineStageFlags2 stageMask;
    uint32_t deviceIndex;
} VkSemaphoreSubmitInfo;

typedef struct VkCommandBufferSubmitInfo {
    VkStructureType sType;
    const void* pNext;
    VkCommandBuffer commandBuffer;
    uint32_t deviceMask;
} VkCommandBufferSubmitInfo;

typedef struct VkSubmitInfo2 {
    VkStructureType sType;
    const void* pNext;
    VkSubmitFlags flags;
    uint32_t waitSemaphoreInfoCount;
    const VkSemaphoreSubmitInfo* pWaitSemaphoreInfos;
    uint32_t commandBufferInfoCount;
    const VkCommandBufferSubmitInfo* pCommandBufferInfos;
    uint32_t signalSemaphoreInfoCount;
    const VkSemaphoreSubmitInfo* pSignalSemaphoreInfos;
} VkSubmitInfo2;

typedef struct VkPhysicalDeviceSynchronization2Features {
    VkStructureType sType;
    void* pNext;
    VkBool32 synchronization2;
} VkPhysicalDeviceSynchronization2Features;

typedef struct VkPhysicalDeviceZeroInitializeWorkgroupMemoryFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderZeroInitializeWorkgroupMemory;
} VkPhysicalDeviceZeroInitializeWorkgroupMemoryFeatures;

typedef struct VkPhysicalDeviceImageRobustnessFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 robustImageAccess;
} VkPhysicalDeviceImageRobustnessFeatures;

typedef struct VkBufferCopy2 {
    VkStructureType sType;
    const void* pNext;
    VkDeviceSize srcOffset;
    VkDeviceSize dstOffset;
    VkDeviceSize size;
} VkBufferCopy2;

typedef struct VkCopyBufferInfo2 {
    VkStructureType sType;
    const void* pNext;
    VkBuffer srcBuffer;
    VkBuffer dstBuffer;
    uint32_t regionCount;
    const VkBufferCopy2* pRegions;
} VkCopyBufferInfo2;

typedef struct VkImageCopy2 {
    VkStructureType sType;
    const void* pNext;
    VkImageSubresourceLayers srcSubresource;
    VkOffset3D srcOffset;
    VkImageSubresourceLayers dstSubresource;
    VkOffset3D dstOffset;
    VkExtent3D extent;
} VkImageCopy2;

typedef struct VkCopyImageInfo2 {
    VkStructureType sType;
    const void* pNext;
    VkImage srcImage;
    VkImageLayout srcImageLayout;
    VkImage dstImage;
    VkImageLayout dstImageLayout;
    uint32_t regionCount;
    const VkImageCopy2* pRegions;
} VkCopyImageInfo2;

typedef struct VkBufferImageCopy2 {
    VkStructureType sType;
    const void* pNext;
    VkDeviceSize bufferOffset;
    uint32_t bufferRowLength;
    uint32_t bufferImageHeight;
    VkImageSubresourceLayers imageSubresource;
    VkOffset3D imageOffset;
    VkExtent3D imageExtent;
} VkBufferImageCopy2;

typedef struct VkCopyBufferToImageInfo2 {
    VkStructureType sType;
    const void* pNext;
    VkBuffer srcBuffer;
    VkImage dstImage;
    VkImageLayout dstImageLayout;
    uint32_t regionCount;
    const VkBufferImageCopy2* pRegions;
} VkCopyBufferToImageInfo2;

typedef struct VkCopyImageToBufferInfo2 {
    VkStructureType sType;
    const void* pNext;
    VkImage srcImage;
    VkImageLayout srcImageLayout;
    VkBuffer dstBuffer;
    uint32_t regionCount;
    const VkBufferImageCopy2* pRegions;
} VkCopyImageToBufferInfo2;

typedef struct VkImageBlit2 {
    VkStructureType sType;
    const void* pNext;
    VkImageSubresourceLayers srcSubresource;
    VkOffset3D srcOffsets[2];
    VkImageSubresourceLayers dstSubresource;
    VkOffset3D dstOffsets[2];
} VkImageBlit2;

typedef struct VkBlitImageInfo2 {
    VkStructureType sType;
    const void* pNext;
    VkImage srcImage;
    VkImageLayout srcImageLayout;
    VkImage dstImage;
    VkImageLayout dstImageLayout;
    uint32_t regionCount;
    const VkImageBlit2* pRegions;
    VkFilter filter;
} VkBlitImageInfo2;

typedef struct VkImageResolve2 {
    VkStructureType sType;
    const void* pNext;
    VkImageSubresourceLayers srcSubresource;
    VkOffset3D srcOffset;
    VkImageSubresourceLayers dstSubresource;
    VkOffset3D dstOffset;
    VkExtent3D extent;
} VkImageResolve2;

typedef struct VkResolveImageInfo2 {
    VkStructureType sType;
    const void* pNext;
    VkImage srcImage;
    VkImageLayout srcImageLayout;
    VkImage dstImage;
    VkImageLayout dstImageLayout;
    uint32_t regionCount;
    const VkImageResolve2* pRegions;
} VkResolveImageInfo2;

typedef struct VkPhysicalDeviceSubgroupSizeControlFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 subgroupSizeControl;
    VkBool32 computeFullSubgroups;
} VkPhysicalDeviceSubgroupSizeControlFeatures;

typedef struct VkPhysicalDeviceSubgroupSizeControlProperties {
    VkStructureType sType;
    void* pNext;
    uint32_t minSubgroupSize;
    uint32_t maxSubgroupSize;
    uint32_t maxComputeWorkgroupSubgroups;
    VkShaderStageFlags requiredSubgroupSizeStages;
} VkPhysicalDeviceSubgroupSizeControlProperties;

typedef struct VkPipelineShaderStageRequiredSubgroupSizeCreateInfo {
    VkStructureType sType;
    void* pNext;
    uint32_t requiredSubgroupSize;
} VkPipelineShaderStageRequiredSubgroupSizeCreateInfo;

typedef struct VkPhysicalDeviceInlineUniformBlockFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 inlineUniformBlock;
    VkBool32 descriptorBindingInlineUniformBlockUpdateAfterBind;
} VkPhysicalDeviceInlineUniformBlockFeatures;

typedef struct VkPhysicalDeviceInlineUniformBlockProperties {
    VkStructureType sType;
    void* pNext;
    uint32_t maxInlineUniformBlockSize;
    uint32_t maxPerStageDescriptorInlineUniformBlocks;
    uint32_t maxPerStageDescriptorUpdateAfterBindInlineUniformBlocks;
    uint32_t maxDescriptorSetInlineUniformBlocks;
    uint32_t maxDescriptorSetUpdateAfterBindInlineUniformBlocks;
} VkPhysicalDeviceInlineUniformBlockProperties;

typedef struct VkWriteDescriptorSetInlineUniformBlock {
    VkStructureType sType;
    const void* pNext;
    uint32_t dataSize;
    const void* pData;
} VkWriteDescriptorSetInlineUniformBlock;

typedef struct VkDescriptorPoolInlineUniformBlockCreateInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t maxInlineUniformBlockBindings;
} VkDescriptorPoolInlineUniformBlockCreateInfo;

typedef struct VkPhysicalDeviceTextureCompressionASTCHDRFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 textureCompressionASTC_HDR;
} VkPhysicalDeviceTextureCompressionASTCHDRFeatures;

typedef struct VkRenderingAttachmentInfo {
    VkStructureType sType;
    const void* pNext;
    VkImageView imageView;
    VkImageLayout imageLayout;
    VkResolveModeFlagBits resolveMode;
    VkImageView resolveImageView;
    VkImageLayout resolveImageLayout;
    VkAttachmentLoadOp loadOp;
    VkAttachmentStoreOp storeOp;
    VkClearValue clearValue;
} VkRenderingAttachmentInfo;

typedef struct VkRenderingInfo {
    VkStructureType sType;
    const void* pNext;
    VkRenderingFlags flags;
    VkRect2D renderArea;
    uint32_t layerCount;
    uint32_t viewMask;
    uint32_t colorAttachmentCount;
    const VkRenderingAttachmentInfo* pColorAttachments;
    const VkRenderingAttachmentInfo* pDepthAttachment;
    const VkRenderingAttachmentInfo* pStencilAttachment;
} VkRenderingInfo;

typedef struct VkPipelineRenderingCreateInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t viewMask;
    uint32_t colorAttachmentCount;
    const VkFormat* pColorAttachmentFormats;
    VkFormat depthAttachmentFormat;
    VkFormat stencilAttachmentFormat;
} VkPipelineRenderingCreateInfo;

typedef struct VkPhysicalDeviceDynamicRenderingFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 dynamicRendering;
} VkPhysicalDeviceDynamicRenderingFeatures;

typedef struct VkCommandBufferInheritanceRenderingInfo {
    VkStructureType sType;
    const void* pNext;
    VkRenderingFlags flags;
    uint32_t viewMask;
    uint32_t colorAttachmentCount;
    const VkFormat* pColorAttachmentFormats;
    VkFormat depthAttachmentFormat;
    VkFormat stencilAttachmentFormat;
    VkSampleCountFlagBits rasterizationSamples;
} VkCommandBufferInheritanceRenderingInfo;

typedef struct VkPhysicalDeviceShaderIntegerDotProductFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderIntegerDotProduct;
} VkPhysicalDeviceShaderIntegerDotProductFeatures;

typedef struct VkPhysicalDeviceShaderIntegerDotProductProperties {
    VkStructureType sType;
    void* pNext;
    VkBool32 integerDotProduct8BitUnsignedAccelerated;
    VkBool32 integerDotProduct8BitSignedAccelerated;
    VkBool32 integerDotProduct8BitMixedSignednessAccelerated;
    VkBool32 integerDotProduct4x8BitPackedUnsignedAccelerated;
    VkBool32 integerDotProduct4x8BitPackedSignedAccelerated;
    VkBool32 integerDotProduct4x8BitPackedMixedSignednessAccelerated;
    VkBool32 integerDotProduct16BitUnsignedAccelerated;
    VkBool32 integerDotProduct16BitSignedAccelerated;
    VkBool32 integerDotProduct16BitMixedSignednessAccelerated;
    VkBool32 integerDotProduct32BitUnsignedAccelerated;
    VkBool32 integerDotProduct32BitSignedAccelerated;
    VkBool32 integerDotProduct32BitMixedSignednessAccelerated;
    VkBool32 integerDotProduct64BitUnsignedAccelerated;
    VkBool32 integerDotProduct64BitSignedAccelerated;
    VkBool32 integerDotProduct64BitMixedSignednessAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating8BitUnsignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating8BitSignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating8BitMixedSignednessAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating4x8BitPackedUnsignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating4x8BitPackedSignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating4x8BitPackedMixedSignednessAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating16BitUnsignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating16BitSignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating16BitMixedSignednessAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating32BitUnsignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating32BitSignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating32BitMixedSignednessAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating64BitUnsignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating64BitSignedAccelerated;
    VkBool32 integerDotProductAccumulatingSaturating64BitMixedSignednessAccelerated;
} VkPhysicalDeviceShaderIntegerDotProductProperties;

typedef struct VkPhysicalDeviceTexelBufferAlignmentProperties {
    VkStructureType sType;
    void* pNext;
    VkDeviceSize storageTexelBufferOffsetAlignmentBytes;
    VkBool32 storageTexelBufferOffsetSingleTexelAlignment;
    VkDeviceSize uniformTexelBufferOffsetAlignmentBytes;
    VkBool32 uniformTexelBufferOffsetSingleTexelAlignment;
} VkPhysicalDeviceTexelBufferAlignmentProperties;

typedef struct VkFormatProperties3 {
    VkStructureType sType;
    void* pNext;
    VkFormatFeatureFlags2 linearTilingFeatures;
    VkFormatFeatureFlags2 optimalTilingFeatures;
    VkFormatFeatureFlags2 bufferFeatures;
} VkFormatProperties3;

typedef struct VkPhysicalDeviceMaintenance4Features {
    VkStructureType sType;
    void* pNext;
    VkBool32 maintenance4;
} VkPhysicalDeviceMaintenance4Features;

typedef struct VkPhysicalDeviceMaintenance4Properties {
    VkStructureType sType;
    void* pNext;
    VkDeviceSize maxBufferSize;
} VkPhysicalDeviceMaintenance4Properties;

typedef struct VkDeviceBufferMemoryRequirements {
    VkStructureType sType;
    const void* pNext;
    const VkBufferCreateInfo* pCreateInfo;
} VkDeviceBufferMemoryRequirements;

typedef struct VkDeviceImageMemoryRequirements {
    VkStructureType sType;
    const void* pNext;
    const VkImageCreateInfo* pCreateInfo;
    VkImageAspectFlagBits planeAspect;
} VkDeviceImageMemoryRequirements;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceToolProperties)(VkPhysicalDevice physicalDevice, uint32_t* pToolCount, VkPhysicalDeviceToolProperties* pToolProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreatePrivateDataSlot)(VkDevice device, const VkPrivateDataSlotCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkPrivateDataSlot* pPrivateDataSlot);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyPrivateDataSlot)(VkDevice device, VkPrivateDataSlot privateDataSlot, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkSetPrivateData)(VkDevice device, VkObjectType objectType, uint64_t objectHandle, VkPrivateDataSlot privateDataSlot, uint64_t data);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPrivateData)(VkDevice device, VkObjectType objectType, uint64_t objectHandle, VkPrivateDataSlot privateDataSlot, uint64_t* pData);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetEvent2)(VkCommandBuffer commandBuffer, VkEvent event, const VkDependencyInfo* pDependencyInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdResetEvent2)(VkCommandBuffer commandBuffer, VkEvent event, VkPipelineStageFlags2 stageMask);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdWaitEvents2)(VkCommandBuffer commandBuffer, uint32_t eventCount, const VkEvent* pEvents, const VkDependencyInfo* pDependencyInfos);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdPipelineBarrier2)(VkCommandBuffer commandBuffer, const VkDependencyInfo* pDependencyInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdWriteTimestamp2)(VkCommandBuffer commandBuffer, VkPipelineStageFlags2 stage, VkQueryPool queryPool, uint32_t query);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkQueueSubmit2)(VkQueue queue, uint32_t submitCount, const VkSubmitInfo2* pSubmits, VkFence fence);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyBuffer2)(VkCommandBuffer commandBuffer, const VkCopyBufferInfo2* pCopyBufferInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyImage2)(VkCommandBuffer commandBuffer, const VkCopyImageInfo2* pCopyImageInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyBufferToImage2)(VkCommandBuffer commandBuffer, const VkCopyBufferToImageInfo2* pCopyBufferToImageInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyImageToBuffer2)(VkCommandBuffer commandBuffer, const VkCopyImageToBufferInfo2* pCopyImageToBufferInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBlitImage2)(VkCommandBuffer commandBuffer, const VkBlitImageInfo2* pBlitImageInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdResolveImage2)(VkCommandBuffer commandBuffer, const VkResolveImageInfo2* pResolveImageInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBeginRendering)(VkCommandBuffer commandBuffer, const VkRenderingInfo* pRenderingInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdEndRendering)(VkCommandBuffer commandBuffer);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetCullMode)(VkCommandBuffer commandBuffer, VkCullModeFlags cullMode);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetFrontFace)(VkCommandBuffer commandBuffer, VkFrontFace frontFace);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetPrimitiveTopology)(VkCommandBuffer commandBuffer, VkPrimitiveTopology primitiveTopology);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetViewportWithCount)(VkCommandBuffer commandBuffer, uint32_t viewportCount, const VkViewport* pViewports);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetScissorWithCount)(VkCommandBuffer commandBuffer, uint32_t scissorCount, const VkRect2D* pScissors);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBindVertexBuffers2)(VkCommandBuffer commandBuffer, uint32_t firstBinding, uint32_t bindingCount, const VkBuffer* pBuffers, const VkDeviceSize* pOffsets, const VkDeviceSize* pSizes, const VkDeviceSize* pStrides);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDepthTestEnable)(VkCommandBuffer commandBuffer, VkBool32 depthTestEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDepthWriteEnable)(VkCommandBuffer commandBuffer, VkBool32 depthWriteEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDepthCompareOp)(VkCommandBuffer commandBuffer, VkCompareOp depthCompareOp);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDepthBoundsTestEnable)(VkCommandBuffer commandBuffer, VkBool32 depthBoundsTestEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetStencilTestEnable)(VkCommandBuffer commandBuffer, VkBool32 stencilTestEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetStencilOp)(VkCommandBuffer commandBuffer, VkStencilFaceFlags faceMask, VkStencilOp failOp, VkStencilOp passOp, VkStencilOp depthFailOp, VkCompareOp compareOp);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetRasterizerDiscardEnable)(VkCommandBuffer commandBuffer, VkBool32 rasterizerDiscardEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDepthBiasEnable)(VkCommandBuffer commandBuffer, VkBool32 depthBiasEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetPrimitiveRestartEnable)(VkCommandBuffer commandBuffer, VkBool32 primitiveRestartEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetDeviceBufferMemoryRequirements)(VkDevice device, const VkDeviceBufferMemoryRequirements* pInfo, VkMemoryRequirements2* pMemoryRequirements);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetDeviceImageMemoryRequirements)(VkDevice device, const VkDeviceImageMemoryRequirements* pInfo, VkMemoryRequirements2* pMemoryRequirements);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetDeviceImageSparseMemoryRequirements)(VkDevice device, const VkDeviceImageMemoryRequirements* pInfo, uint32_t* pSparseMemoryRequirementCount, VkSparseImageMemoryRequirements2* pSparseMemoryRequirements);


 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceToolProperties(
    VkPhysicalDevice physicalDevice,
    uint32_t* pToolCount,
    VkPhysicalDeviceToolProperties* pToolProperties);

 VkResult __attribute__((__stdcall__)) vkCreatePrivateDataSlot(
    VkDevice device,
    const VkPrivateDataSlotCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkPrivateDataSlot* pPrivateDataSlot);

 void __attribute__((__stdcall__)) vkDestroyPrivateDataSlot(
    VkDevice device,
    VkPrivateDataSlot privateDataSlot,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkSetPrivateData(
    VkDevice device,
    VkObjectType objectType,
    uint64_t objectHandle,
    VkPrivateDataSlot privateDataSlot,
    uint64_t data);

 void __attribute__((__stdcall__)) vkGetPrivateData(
    VkDevice device,
    VkObjectType objectType,
    uint64_t objectHandle,
    VkPrivateDataSlot privateDataSlot,
    uint64_t* pData);

 void __attribute__((__stdcall__)) vkCmdSetEvent2(
    VkCommandBuffer commandBuffer,
    VkEvent event,
    const VkDependencyInfo* pDependencyInfo);

 void __attribute__((__stdcall__)) vkCmdResetEvent2(
    VkCommandBuffer commandBuffer,
    VkEvent event,
    VkPipelineStageFlags2 stageMask);

 void __attribute__((__stdcall__)) vkCmdWaitEvents2(
    VkCommandBuffer commandBuffer,
    uint32_t eventCount,
    const VkEvent* pEvents,
    const VkDependencyInfo* pDependencyInfos);

 void __attribute__((__stdcall__)) vkCmdPipelineBarrier2(
    VkCommandBuffer commandBuffer,
    const VkDependencyInfo* pDependencyInfo);

 void __attribute__((__stdcall__)) vkCmdWriteTimestamp2(
    VkCommandBuffer commandBuffer,
    VkPipelineStageFlags2 stage,
    VkQueryPool queryPool,
    uint32_t query);

 VkResult __attribute__((__stdcall__)) vkQueueSubmit2(
    VkQueue queue,
    uint32_t submitCount,
    const VkSubmitInfo2* pSubmits,
    VkFence fence);

 void __attribute__((__stdcall__)) vkCmdCopyBuffer2(
    VkCommandBuffer commandBuffer,
    const VkCopyBufferInfo2* pCopyBufferInfo);

 void __attribute__((__stdcall__)) vkCmdCopyImage2(
    VkCommandBuffer commandBuffer,
    const VkCopyImageInfo2* pCopyImageInfo);

 void __attribute__((__stdcall__)) vkCmdCopyBufferToImage2(
    VkCommandBuffer commandBuffer,
    const VkCopyBufferToImageInfo2* pCopyBufferToImageInfo);

 void __attribute__((__stdcall__)) vkCmdCopyImageToBuffer2(
    VkCommandBuffer commandBuffer,
    const VkCopyImageToBufferInfo2* pCopyImageToBufferInfo);

 void __attribute__((__stdcall__)) vkCmdBlitImage2(
    VkCommandBuffer commandBuffer,
    const VkBlitImageInfo2* pBlitImageInfo);

 void __attribute__((__stdcall__)) vkCmdResolveImage2(
    VkCommandBuffer commandBuffer,
    const VkResolveImageInfo2* pResolveImageInfo);

 void __attribute__((__stdcall__)) vkCmdBeginRendering(
    VkCommandBuffer commandBuffer,
    const VkRenderingInfo* pRenderingInfo);

 void __attribute__((__stdcall__)) vkCmdEndRendering(
    VkCommandBuffer commandBuffer);

 void __attribute__((__stdcall__)) vkCmdSetCullMode(
    VkCommandBuffer commandBuffer,
    VkCullModeFlags cullMode);

 void __attribute__((__stdcall__)) vkCmdSetFrontFace(
    VkCommandBuffer commandBuffer,
    VkFrontFace frontFace);

 void __attribute__((__stdcall__)) vkCmdSetPrimitiveTopology(
    VkCommandBuffer commandBuffer,
    VkPrimitiveTopology primitiveTopology);

 void __attribute__((__stdcall__)) vkCmdSetViewportWithCount(
    VkCommandBuffer commandBuffer,
    uint32_t viewportCount,
    const VkViewport* pViewports);

 void __attribute__((__stdcall__)) vkCmdSetScissorWithCount(
    VkCommandBuffer commandBuffer,
    uint32_t scissorCount,
    const VkRect2D* pScissors);

 void __attribute__((__stdcall__)) vkCmdBindVertexBuffers2(
    VkCommandBuffer commandBuffer,
    uint32_t firstBinding,
    uint32_t bindingCount,
    const VkBuffer* pBuffers,
    const VkDeviceSize* pOffsets,
    const VkDeviceSize* pSizes,
    const VkDeviceSize* pStrides);

 void __attribute__((__stdcall__)) vkCmdSetDepthTestEnable(
    VkCommandBuffer commandBuffer,
    VkBool32 depthTestEnable);

 void __attribute__((__stdcall__)) vkCmdSetDepthWriteEnable(
    VkCommandBuffer commandBuffer,
    VkBool32 depthWriteEnable);

 void __attribute__((__stdcall__)) vkCmdSetDepthCompareOp(
    VkCommandBuffer commandBuffer,
    VkCompareOp depthCompareOp);

 void __attribute__((__stdcall__)) vkCmdSetDepthBoundsTestEnable(
    VkCommandBuffer commandBuffer,
    VkBool32 depthBoundsTestEnable);

 void __attribute__((__stdcall__)) vkCmdSetStencilTestEnable(
    VkCommandBuffer commandBuffer,
    VkBool32 stencilTestEnable);

 void __attribute__((__stdcall__)) vkCmdSetStencilOp(
    VkCommandBuffer commandBuffer,
    VkStencilFaceFlags faceMask,
    VkStencilOp failOp,
    VkStencilOp passOp,
    VkStencilOp depthFailOp,
    VkCompareOp compareOp);

 void __attribute__((__stdcall__)) vkCmdSetRasterizerDiscardEnable(
    VkCommandBuffer commandBuffer,
    VkBool32 rasterizerDiscardEnable);

 void __attribute__((__stdcall__)) vkCmdSetDepthBiasEnable(
    VkCommandBuffer commandBuffer,
    VkBool32 depthBiasEnable);

 void __attribute__((__stdcall__)) vkCmdSetPrimitiveRestartEnable(
    VkCommandBuffer commandBuffer,
    VkBool32 primitiveRestartEnable);

 void __attribute__((__stdcall__)) vkGetDeviceBufferMemoryRequirements(
    VkDevice device,
    const VkDeviceBufferMemoryRequirements* pInfo,
    VkMemoryRequirements2* pMemoryRequirements);

 void __attribute__((__stdcall__)) vkGetDeviceImageMemoryRequirements(
    VkDevice device,
    const VkDeviceImageMemoryRequirements* pInfo,
    VkMemoryRequirements2* pMemoryRequirements);

 void __attribute__((__stdcall__)) vkGetDeviceImageSparseMemoryRequirements(
    VkDevice device,
    const VkDeviceImageMemoryRequirements* pInfo,
    uint32_t* pSparseMemoryRequirementCount,
    VkSparseImageMemoryRequirements2* pSparseMemoryRequirements);
# 7731 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkPipelineRobustnessBufferBehavior {
    VK_PIPELINE_ROBUSTNESS_BUFFER_BEHAVIOR_DEVICE_DEFAULT = 0,
    VK_PIPELINE_ROBUSTNESS_BUFFER_BEHAVIOR_DISABLED = 1,
    VK_PIPELINE_ROBUSTNESS_BUFFER_BEHAVIOR_ROBUST_BUFFER_ACCESS = 2,
    VK_PIPELINE_ROBUSTNESS_BUFFER_BEHAVIOR_ROBUST_BUFFER_ACCESS_2 = 3,
    VK_PIPELINE_ROBUSTNESS_BUFFER_BEHAVIOR_DEVICE_DEFAULT_EXT = VK_PIPELINE_ROBUSTNESS_BUFFER_BEHAVIOR_DEVICE_DEFAULT,
    VK_PIPELINE_ROBUSTNESS_BUFFER_BEHAVIOR_DISABLED_EXT = VK_PIPELINE_ROBUSTNESS_BUFFER_BEHAVIOR_DISABLED,
    VK_PIPELINE_ROBUSTNESS_BUFFER_BEHAVIOR_ROBUST_BUFFER_ACCESS_EXT = VK_PIPELINE_ROBUSTNESS_BUFFER_BEHAVIOR_ROBUST_BUFFER_ACCESS,
    VK_PIPELINE_ROBUSTNESS_BUFFER_BEHAVIOR_ROBUST_BUFFER_ACCESS_2_EXT = VK_PIPELINE_ROBUSTNESS_BUFFER_BEHAVIOR_ROBUST_BUFFER_ACCESS_2,
    VK_PIPELINE_ROBUSTNESS_BUFFER_BEHAVIOR_MAX_ENUM = 0x7FFFFFFF
} VkPipelineRobustnessBufferBehavior;

typedef enum VkPipelineRobustnessImageBehavior {
    VK_PIPELINE_ROBUSTNESS_IMAGE_BEHAVIOR_DEVICE_DEFAULT = 0,
    VK_PIPELINE_ROBUSTNESS_IMAGE_BEHAVIOR_DISABLED = 1,
    VK_PIPELINE_ROBUSTNESS_IMAGE_BEHAVIOR_ROBUST_IMAGE_ACCESS = 2,
    VK_PIPELINE_ROBUSTNESS_IMAGE_BEHAVIOR_ROBUST_IMAGE_ACCESS_2 = 3,
    VK_PIPELINE_ROBUSTNESS_IMAGE_BEHAVIOR_DEVICE_DEFAULT_EXT = VK_PIPELINE_ROBUSTNESS_IMAGE_BEHAVIOR_DEVICE_DEFAULT,
    VK_PIPELINE_ROBUSTNESS_IMAGE_BEHAVIOR_DISABLED_EXT = VK_PIPELINE_ROBUSTNESS_IMAGE_BEHAVIOR_DISABLED,
    VK_PIPELINE_ROBUSTNESS_IMAGE_BEHAVIOR_ROBUST_IMAGE_ACCESS_EXT = VK_PIPELINE_ROBUSTNESS_IMAGE_BEHAVIOR_ROBUST_IMAGE_ACCESS,
    VK_PIPELINE_ROBUSTNESS_IMAGE_BEHAVIOR_ROBUST_IMAGE_ACCESS_2_EXT = VK_PIPELINE_ROBUSTNESS_IMAGE_BEHAVIOR_ROBUST_IMAGE_ACCESS_2,
    VK_PIPELINE_ROBUSTNESS_IMAGE_BEHAVIOR_MAX_ENUM = 0x7FFFFFFF
} VkPipelineRobustnessImageBehavior;

typedef enum VkQueueGlobalPriority {
    VK_QUEUE_GLOBAL_PRIORITY_LOW = 128,
    VK_QUEUE_GLOBAL_PRIORITY_MEDIUM = 256,
    VK_QUEUE_GLOBAL_PRIORITY_HIGH = 512,
    VK_QUEUE_GLOBAL_PRIORITY_REALTIME = 1024,
    VK_QUEUE_GLOBAL_PRIORITY_LOW_EXT = VK_QUEUE_GLOBAL_PRIORITY_LOW,
    VK_QUEUE_GLOBAL_PRIORITY_MEDIUM_EXT = VK_QUEUE_GLOBAL_PRIORITY_MEDIUM,
    VK_QUEUE_GLOBAL_PRIORITY_HIGH_EXT = VK_QUEUE_GLOBAL_PRIORITY_HIGH,
    VK_QUEUE_GLOBAL_PRIORITY_REALTIME_EXT = VK_QUEUE_GLOBAL_PRIORITY_REALTIME,
    VK_QUEUE_GLOBAL_PRIORITY_LOW_KHR = VK_QUEUE_GLOBAL_PRIORITY_LOW,
    VK_QUEUE_GLOBAL_PRIORITY_MEDIUM_KHR = VK_QUEUE_GLOBAL_PRIORITY_MEDIUM,
    VK_QUEUE_GLOBAL_PRIORITY_HIGH_KHR = VK_QUEUE_GLOBAL_PRIORITY_HIGH,
    VK_QUEUE_GLOBAL_PRIORITY_REALTIME_KHR = VK_QUEUE_GLOBAL_PRIORITY_REALTIME,
    VK_QUEUE_GLOBAL_PRIORITY_MAX_ENUM = 0x7FFFFFFF
} VkQueueGlobalPriority;

typedef enum VkLineRasterizationMode {
    VK_LINE_RASTERIZATION_MODE_DEFAULT = 0,
    VK_LINE_RASTERIZATION_MODE_RECTANGULAR = 1,
    VK_LINE_RASTERIZATION_MODE_BRESENHAM = 2,
    VK_LINE_RASTERIZATION_MODE_RECTANGULAR_SMOOTH = 3,
    VK_LINE_RASTERIZATION_MODE_DEFAULT_EXT = VK_LINE_RASTERIZATION_MODE_DEFAULT,
    VK_LINE_RASTERIZATION_MODE_RECTANGULAR_EXT = VK_LINE_RASTERIZATION_MODE_RECTANGULAR,
    VK_LINE_RASTERIZATION_MODE_BRESENHAM_EXT = VK_LINE_RASTERIZATION_MODE_BRESENHAM,
    VK_LINE_RASTERIZATION_MODE_RECTANGULAR_SMOOTH_EXT = VK_LINE_RASTERIZATION_MODE_RECTANGULAR_SMOOTH,
    VK_LINE_RASTERIZATION_MODE_DEFAULT_KHR = VK_LINE_RASTERIZATION_MODE_DEFAULT,
    VK_LINE_RASTERIZATION_MODE_RECTANGULAR_KHR = VK_LINE_RASTERIZATION_MODE_RECTANGULAR,
    VK_LINE_RASTERIZATION_MODE_BRESENHAM_KHR = VK_LINE_RASTERIZATION_MODE_BRESENHAM,
    VK_LINE_RASTERIZATION_MODE_RECTANGULAR_SMOOTH_KHR = VK_LINE_RASTERIZATION_MODE_RECTANGULAR_SMOOTH,
    VK_LINE_RASTERIZATION_MODE_MAX_ENUM = 0x7FFFFFFF
} VkLineRasterizationMode;

typedef enum VkMemoryUnmapFlagBits {
    VK_MEMORY_UNMAP_RESERVE_BIT_EXT = 0x00000001,
    VK_MEMORY_UNMAP_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkMemoryUnmapFlagBits;
typedef VkFlags VkMemoryUnmapFlags;
typedef VkFlags64 VkPipelineCreateFlags2;


typedef VkFlags64 VkPipelineCreateFlagBits2;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_DISABLE_OPTIMIZATION_BIT = 0x00000001ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_ALLOW_DERIVATIVES_BIT = 0x00000002ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_DERIVATIVE_BIT = 0x00000004ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_VIEW_INDEX_FROM_DEVICE_INDEX_BIT = 0x00000008ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_DISPATCH_BASE_BIT = 0x00000010ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_FAIL_ON_PIPELINE_COMPILE_REQUIRED_BIT = 0x00000100ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_EARLY_RETURN_ON_FAILURE_BIT = 0x00000200ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_NO_PROTECTED_ACCESS_BIT = 0x08000000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_PROTECTED_ACCESS_ONLY_BIT = 0x40000000ULL;



static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_ENABLE_LEGACY_DITHERING_BIT_EXT = 0x400000000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_DISABLE_OPTIMIZATION_BIT_KHR = 0x00000001ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_ALLOW_DERIVATIVES_BIT_KHR = 0x00000002ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_DERIVATIVE_BIT_KHR = 0x00000004ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_VIEW_INDEX_FROM_DEVICE_INDEX_BIT_KHR = 0x00000008ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_DISPATCH_BASE_BIT_KHR = 0x00000010ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_DEFER_COMPILE_BIT_NV = 0x00000020ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_CAPTURE_STATISTICS_BIT_KHR = 0x00000040ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_CAPTURE_INTERNAL_REPRESENTATIONS_BIT_KHR = 0x00000080ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_FAIL_ON_PIPELINE_COMPILE_REQUIRED_BIT_KHR = 0x00000100ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_EARLY_RETURN_ON_FAILURE_BIT_KHR = 0x00000200ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_LINK_TIME_OPTIMIZATION_BIT_EXT = 0x00000400ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_RETAIN_LINK_TIME_OPTIMIZATION_INFO_BIT_EXT = 0x00800000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_LIBRARY_BIT_KHR = 0x00000800ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_RAY_TRACING_SKIP_TRIANGLES_BIT_KHR = 0x00001000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_RAY_TRACING_SKIP_AABBS_BIT_KHR = 0x00002000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_RAY_TRACING_NO_NULL_ANY_HIT_SHADERS_BIT_KHR = 0x00004000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_RAY_TRACING_NO_NULL_CLOSEST_HIT_SHADERS_BIT_KHR = 0x00008000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_RAY_TRACING_NO_NULL_MISS_SHADERS_BIT_KHR = 0x00010000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_RAY_TRACING_NO_NULL_INTERSECTION_SHADERS_BIT_KHR = 0x00020000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_RAY_TRACING_SHADER_GROUP_HANDLE_CAPTURE_REPLAY_BIT_KHR = 0x00080000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_INDIRECT_BINDABLE_BIT_NV = 0x00040000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_RAY_TRACING_ALLOW_MOTION_BIT_NV = 0x00100000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_RENDERING_FRAGMENT_SHADING_RATE_ATTACHMENT_BIT_KHR = 0x00200000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_RENDERING_FRAGMENT_DENSITY_MAP_ATTACHMENT_BIT_EXT = 0x00400000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_RAY_TRACING_OPACITY_MICROMAP_BIT_EXT = 0x01000000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_COLOR_ATTACHMENT_FEEDBACK_LOOP_BIT_EXT = 0x02000000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_DEPTH_STENCIL_ATTACHMENT_FEEDBACK_LOOP_BIT_EXT = 0x04000000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_NO_PROTECTED_ACCESS_BIT_EXT = 0x08000000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_PROTECTED_ACCESS_ONLY_BIT_EXT = 0x40000000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_RAY_TRACING_DISPLACEMENT_MICROMAP_BIT_NV = 0x10000000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_DESCRIPTOR_BUFFER_BIT_EXT = 0x20000000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_CAPTURE_DATA_BIT_KHR = 0x80000000ULL;
static const VkPipelineCreateFlagBits2 VK_PIPELINE_CREATE_2_INDIRECT_BINDABLE_BIT_EXT = 0x4000000000ULL;

typedef VkFlags64 VkBufferUsageFlags2;


typedef VkFlags64 VkBufferUsageFlagBits2;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_TRANSFER_SRC_BIT = 0x00000001ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_TRANSFER_DST_BIT = 0x00000002ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_UNIFORM_TEXEL_BUFFER_BIT = 0x00000004ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_STORAGE_TEXEL_BUFFER_BIT = 0x00000008ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_UNIFORM_BUFFER_BIT = 0x00000010ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_STORAGE_BUFFER_BIT = 0x00000020ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_INDEX_BUFFER_BIT = 0x00000040ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_VERTEX_BUFFER_BIT = 0x00000080ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_INDIRECT_BUFFER_BIT = 0x00000100ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_SHADER_DEVICE_ADDRESS_BIT = 0x00020000ULL;



static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_TRANSFER_SRC_BIT_KHR = 0x00000001ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_TRANSFER_DST_BIT_KHR = 0x00000002ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_UNIFORM_TEXEL_BUFFER_BIT_KHR = 0x00000004ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_STORAGE_TEXEL_BUFFER_BIT_KHR = 0x00000008ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_UNIFORM_BUFFER_BIT_KHR = 0x00000010ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_STORAGE_BUFFER_BIT_KHR = 0x00000020ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_INDEX_BUFFER_BIT_KHR = 0x00000040ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_VERTEX_BUFFER_BIT_KHR = 0x00000080ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_INDIRECT_BUFFER_BIT_KHR = 0x00000100ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_CONDITIONAL_RENDERING_BIT_EXT = 0x00000200ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_SHADER_BINDING_TABLE_BIT_KHR = 0x00000400ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_RAY_TRACING_BIT_NV = 0x00000400ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_TRANSFORM_FEEDBACK_BUFFER_BIT_EXT = 0x00000800ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_TRANSFORM_FEEDBACK_COUNTER_BUFFER_BIT_EXT = 0x00001000ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_VIDEO_DECODE_SRC_BIT_KHR = 0x00002000ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_VIDEO_DECODE_DST_BIT_KHR = 0x00004000ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_VIDEO_ENCODE_DST_BIT_KHR = 0x00008000ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_VIDEO_ENCODE_SRC_BIT_KHR = 0x00010000ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_SHADER_DEVICE_ADDRESS_BIT_KHR = 0x00020000ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_ACCELERATION_STRUCTURE_BUILD_INPUT_READ_ONLY_BIT_KHR = 0x00080000ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_ACCELERATION_STRUCTURE_STORAGE_BIT_KHR = 0x00100000ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_SAMPLER_DESCRIPTOR_BUFFER_BIT_EXT = 0x00200000ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_RESOURCE_DESCRIPTOR_BUFFER_BIT_EXT = 0x00400000ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_PUSH_DESCRIPTORS_DESCRIPTOR_BUFFER_BIT_EXT = 0x04000000ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_MICROMAP_BUILD_INPUT_READ_ONLY_BIT_EXT = 0x00800000ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_MICROMAP_STORAGE_BIT_EXT = 0x01000000ULL;
static const VkBufferUsageFlagBits2 VK_BUFFER_USAGE_2_PREPROCESS_BUFFER_BIT_EXT = 0x80000000ULL;


typedef enum VkHostImageCopyFlagBits {
    VK_HOST_IMAGE_COPY_MEMCPY = 0x00000001,
    VK_HOST_IMAGE_COPY_MEMCPY_EXT = VK_HOST_IMAGE_COPY_MEMCPY,
    VK_HOST_IMAGE_COPY_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VkHostImageCopyFlagBits;
typedef VkFlags VkHostImageCopyFlags;
typedef struct VkPhysicalDeviceVulkan14Features {
    VkStructureType sType;
    void* pNext;
    VkBool32 globalPriorityQuery;
    VkBool32 shaderSubgroupRotate;
    VkBool32 shaderSubgroupRotateClustered;
    VkBool32 shaderFloatControls2;
    VkBool32 shaderExpectAssume;
    VkBool32 rectangularLines;
    VkBool32 bresenhamLines;
    VkBool32 smoothLines;
    VkBool32 stippledRectangularLines;
    VkBool32 stippledBresenhamLines;
    VkBool32 stippledSmoothLines;
    VkBool32 vertexAttributeInstanceRateDivisor;
    VkBool32 vertexAttributeInstanceRateZeroDivisor;
    VkBool32 indexTypeUint8;
    VkBool32 dynamicRenderingLocalRead;
    VkBool32 maintenance5;
    VkBool32 maintenance6;
    VkBool32 pipelineProtectedAccess;
    VkBool32 pipelineRobustness;
    VkBool32 hostImageCopy;
    VkBool32 pushDescriptor;
} VkPhysicalDeviceVulkan14Features;

typedef struct VkPhysicalDeviceVulkan14Properties {
    VkStructureType sType;
    void* pNext;
    uint32_t lineSubPixelPrecisionBits;
    uint32_t maxVertexAttribDivisor;
    VkBool32 supportsNonZeroFirstInstance;
    uint32_t maxPushDescriptors;
    VkBool32 dynamicRenderingLocalReadDepthStencilAttachments;
    VkBool32 dynamicRenderingLocalReadMultisampledAttachments;
    VkBool32 earlyFragmentMultisampleCoverageAfterSampleCounting;
    VkBool32 earlyFragmentSampleMaskTestBeforeSampleCounting;
    VkBool32 depthStencilSwizzleOneSupport;
    VkBool32 polygonModePointSize;
    VkBool32 nonStrictSinglePixelWideLinesUseParallelogram;
    VkBool32 nonStrictWideLinesUseParallelogram;
    VkBool32 blockTexelViewCompatibleMultipleLayers;
    uint32_t maxCombinedImageSamplerDescriptorCount;
    VkBool32 fragmentShadingRateClampCombinerInputs;
    VkPipelineRobustnessBufferBehavior defaultRobustnessStorageBuffers;
    VkPipelineRobustnessBufferBehavior defaultRobustnessUniformBuffers;
    VkPipelineRobustnessBufferBehavior defaultRobustnessVertexInputs;
    VkPipelineRobustnessImageBehavior defaultRobustnessImages;
    uint32_t copySrcLayoutCount;
    VkImageLayout* pCopySrcLayouts;
    uint32_t copyDstLayoutCount;
    VkImageLayout* pCopyDstLayouts;
    uint8_t optimalTilingLayoutUUID[16U];
    VkBool32 identicalMemoryTypeRequirements;
} VkPhysicalDeviceVulkan14Properties;

typedef struct VkDeviceQueueGlobalPriorityCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkQueueGlobalPriority globalPriority;
} VkDeviceQueueGlobalPriorityCreateInfo;

typedef struct VkPhysicalDeviceGlobalPriorityQueryFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 globalPriorityQuery;
} VkPhysicalDeviceGlobalPriorityQueryFeatures;

typedef struct VkQueueFamilyGlobalPriorityProperties {
    VkStructureType sType;
    void* pNext;
    uint32_t priorityCount;
    VkQueueGlobalPriority priorities[16U];
} VkQueueFamilyGlobalPriorityProperties;

typedef struct VkPhysicalDeviceShaderSubgroupRotateFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderSubgroupRotate;
    VkBool32 shaderSubgroupRotateClustered;
} VkPhysicalDeviceShaderSubgroupRotateFeatures;

typedef struct VkPhysicalDeviceShaderFloatControls2Features {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderFloatControls2;
} VkPhysicalDeviceShaderFloatControls2Features;

typedef struct VkPhysicalDeviceShaderExpectAssumeFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderExpectAssume;
} VkPhysicalDeviceShaderExpectAssumeFeatures;

typedef struct VkPhysicalDeviceLineRasterizationFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 rectangularLines;
    VkBool32 bresenhamLines;
    VkBool32 smoothLines;
    VkBool32 stippledRectangularLines;
    VkBool32 stippledBresenhamLines;
    VkBool32 stippledSmoothLines;
} VkPhysicalDeviceLineRasterizationFeatures;

typedef struct VkPhysicalDeviceLineRasterizationProperties {
    VkStructureType sType;
    void* pNext;
    uint32_t lineSubPixelPrecisionBits;
} VkPhysicalDeviceLineRasterizationProperties;

typedef struct VkPipelineRasterizationLineStateCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkLineRasterizationMode lineRasterizationMode;
    VkBool32 stippledLineEnable;
    uint32_t lineStippleFactor;
    uint16_t lineStipplePattern;
} VkPipelineRasterizationLineStateCreateInfo;

typedef struct VkPhysicalDeviceVertexAttributeDivisorProperties {
    VkStructureType sType;
    void* pNext;
    uint32_t maxVertexAttribDivisor;
    VkBool32 supportsNonZeroFirstInstance;
} VkPhysicalDeviceVertexAttributeDivisorProperties;

typedef struct VkVertexInputBindingDivisorDescription {
    uint32_t binding;
    uint32_t divisor;
} VkVertexInputBindingDivisorDescription;

typedef struct VkPipelineVertexInputDivisorStateCreateInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t vertexBindingDivisorCount;
    const VkVertexInputBindingDivisorDescription* pVertexBindingDivisors;
} VkPipelineVertexInputDivisorStateCreateInfo;

typedef struct VkPhysicalDeviceVertexAttributeDivisorFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 vertexAttributeInstanceRateDivisor;
    VkBool32 vertexAttributeInstanceRateZeroDivisor;
} VkPhysicalDeviceVertexAttributeDivisorFeatures;

typedef struct VkPhysicalDeviceIndexTypeUint8Features {
    VkStructureType sType;
    void* pNext;
    VkBool32 indexTypeUint8;
} VkPhysicalDeviceIndexTypeUint8Features;

typedef struct VkMemoryMapInfo {
    VkStructureType sType;
    const void* pNext;
    VkMemoryMapFlags flags;
    VkDeviceMemory memory;
    VkDeviceSize offset;
    VkDeviceSize size;
} VkMemoryMapInfo;

typedef struct VkMemoryUnmapInfo {
    VkStructureType sType;
    const void* pNext;
    VkMemoryUnmapFlags flags;
    VkDeviceMemory memory;
} VkMemoryUnmapInfo;

typedef struct VkPhysicalDeviceMaintenance5Features {
    VkStructureType sType;
    void* pNext;
    VkBool32 maintenance5;
} VkPhysicalDeviceMaintenance5Features;

typedef struct VkPhysicalDeviceMaintenance5Properties {
    VkStructureType sType;
    void* pNext;
    VkBool32 earlyFragmentMultisampleCoverageAfterSampleCounting;
    VkBool32 earlyFragmentSampleMaskTestBeforeSampleCounting;
    VkBool32 depthStencilSwizzleOneSupport;
    VkBool32 polygonModePointSize;
    VkBool32 nonStrictSinglePixelWideLinesUseParallelogram;
    VkBool32 nonStrictWideLinesUseParallelogram;
} VkPhysicalDeviceMaintenance5Properties;

typedef struct VkRenderingAreaInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t viewMask;
    uint32_t colorAttachmentCount;
    const VkFormat* pColorAttachmentFormats;
    VkFormat depthAttachmentFormat;
    VkFormat stencilAttachmentFormat;
} VkRenderingAreaInfo;

typedef struct VkImageSubresource2 {
    VkStructureType sType;
    void* pNext;
    VkImageSubresource imageSubresource;
} VkImageSubresource2;

typedef struct VkDeviceImageSubresourceInfo {
    VkStructureType sType;
    const void* pNext;
    const VkImageCreateInfo* pCreateInfo;
    const VkImageSubresource2* pSubresource;
} VkDeviceImageSubresourceInfo;

typedef struct VkSubresourceLayout2 {
    VkStructureType sType;
    void* pNext;
    VkSubresourceLayout subresourceLayout;
} VkSubresourceLayout2;

typedef struct VkPipelineCreateFlags2CreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkPipelineCreateFlags2 flags;
} VkPipelineCreateFlags2CreateInfo;

typedef struct VkBufferUsageFlags2CreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkBufferUsageFlags2 usage;
} VkBufferUsageFlags2CreateInfo;

typedef struct VkPhysicalDevicePushDescriptorProperties {
    VkStructureType sType;
    void* pNext;
    uint32_t maxPushDescriptors;
} VkPhysicalDevicePushDescriptorProperties;

typedef struct VkPhysicalDeviceDynamicRenderingLocalReadFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 dynamicRenderingLocalRead;
} VkPhysicalDeviceDynamicRenderingLocalReadFeatures;

typedef struct VkRenderingAttachmentLocationInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t colorAttachmentCount;
    const uint32_t* pColorAttachmentLocations;
} VkRenderingAttachmentLocationInfo;

typedef struct VkRenderingInputAttachmentIndexInfo {
    VkStructureType sType;
    const void* pNext;
    uint32_t colorAttachmentCount;
    const uint32_t* pColorAttachmentInputIndices;
    const uint32_t* pDepthInputAttachmentIndex;
    const uint32_t* pStencilInputAttachmentIndex;
} VkRenderingInputAttachmentIndexInfo;

typedef struct VkPhysicalDeviceMaintenance6Features {
    VkStructureType sType;
    void* pNext;
    VkBool32 maintenance6;
} VkPhysicalDeviceMaintenance6Features;

typedef struct VkPhysicalDeviceMaintenance6Properties {
    VkStructureType sType;
    void* pNext;
    VkBool32 blockTexelViewCompatibleMultipleLayers;
    uint32_t maxCombinedImageSamplerDescriptorCount;
    VkBool32 fragmentShadingRateClampCombinerInputs;
} VkPhysicalDeviceMaintenance6Properties;

typedef struct VkBindMemoryStatus {
    VkStructureType sType;
    const void* pNext;
    VkResult* pResult;
} VkBindMemoryStatus;

typedef struct VkBindDescriptorSetsInfo {
    VkStructureType sType;
    const void* pNext;
    VkShaderStageFlags stageFlags;
    VkPipelineLayout layout;
    uint32_t firstSet;
    uint32_t descriptorSetCount;
    const VkDescriptorSet* pDescriptorSets;
    uint32_t dynamicOffsetCount;
    const uint32_t* pDynamicOffsets;
} VkBindDescriptorSetsInfo;

typedef struct VkPushConstantsInfo {
    VkStructureType sType;
    const void* pNext;
    VkPipelineLayout layout;
    VkShaderStageFlags stageFlags;
    uint32_t offset;
    uint32_t size;
    const void* pValues;
} VkPushConstantsInfo;

typedef struct VkPushDescriptorSetInfo {
    VkStructureType sType;
    const void* pNext;
    VkShaderStageFlags stageFlags;
    VkPipelineLayout layout;
    uint32_t set;
    uint32_t descriptorWriteCount;
    const VkWriteDescriptorSet* pDescriptorWrites;
} VkPushDescriptorSetInfo;

typedef struct VkPushDescriptorSetWithTemplateInfo {
    VkStructureType sType;
    const void* pNext;
    VkDescriptorUpdateTemplate descriptorUpdateTemplate;
    VkPipelineLayout layout;
    uint32_t set;
    const void* pData;
} VkPushDescriptorSetWithTemplateInfo;

typedef struct VkPhysicalDevicePipelineProtectedAccessFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 pipelineProtectedAccess;
} VkPhysicalDevicePipelineProtectedAccessFeatures;

typedef struct VkPhysicalDevicePipelineRobustnessFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 pipelineRobustness;
} VkPhysicalDevicePipelineRobustnessFeatures;

typedef struct VkPhysicalDevicePipelineRobustnessProperties {
    VkStructureType sType;
    void* pNext;
    VkPipelineRobustnessBufferBehavior defaultRobustnessStorageBuffers;
    VkPipelineRobustnessBufferBehavior defaultRobustnessUniformBuffers;
    VkPipelineRobustnessBufferBehavior defaultRobustnessVertexInputs;
    VkPipelineRobustnessImageBehavior defaultRobustnessImages;
} VkPhysicalDevicePipelineRobustnessProperties;

typedef struct VkPipelineRobustnessCreateInfo {
    VkStructureType sType;
    const void* pNext;
    VkPipelineRobustnessBufferBehavior storageBuffers;
    VkPipelineRobustnessBufferBehavior uniformBuffers;
    VkPipelineRobustnessBufferBehavior vertexInputs;
    VkPipelineRobustnessImageBehavior images;
} VkPipelineRobustnessCreateInfo;

typedef struct VkPhysicalDeviceHostImageCopyFeatures {
    VkStructureType sType;
    void* pNext;
    VkBool32 hostImageCopy;
} VkPhysicalDeviceHostImageCopyFeatures;

typedef struct VkPhysicalDeviceHostImageCopyProperties {
    VkStructureType sType;
    void* pNext;
    uint32_t copySrcLayoutCount;
    VkImageLayout* pCopySrcLayouts;
    uint32_t copyDstLayoutCount;
    VkImageLayout* pCopyDstLayouts;
    uint8_t optimalTilingLayoutUUID[16U];
    VkBool32 identicalMemoryTypeRequirements;
} VkPhysicalDeviceHostImageCopyProperties;

typedef struct VkMemoryToImageCopy {
    VkStructureType sType;
    const void* pNext;
    const void* pHostPointer;
    uint32_t memoryRowLength;
    uint32_t memoryImageHeight;
    VkImageSubresourceLayers imageSubresource;
    VkOffset3D imageOffset;
    VkExtent3D imageExtent;
} VkMemoryToImageCopy;

typedef struct VkImageToMemoryCopy {
    VkStructureType sType;
    const void* pNext;
    void* pHostPointer;
    uint32_t memoryRowLength;
    uint32_t memoryImageHeight;
    VkImageSubresourceLayers imageSubresource;
    VkOffset3D imageOffset;
    VkExtent3D imageExtent;
} VkImageToMemoryCopy;

typedef struct VkCopyMemoryToImageInfo {
    VkStructureType sType;
    const void* pNext;
    VkHostImageCopyFlags flags;
    VkImage dstImage;
    VkImageLayout dstImageLayout;
    uint32_t regionCount;
    const VkMemoryToImageCopy* pRegions;
} VkCopyMemoryToImageInfo;

typedef struct VkCopyImageToMemoryInfo {
    VkStructureType sType;
    const void* pNext;
    VkHostImageCopyFlags flags;
    VkImage srcImage;
    VkImageLayout srcImageLayout;
    uint32_t regionCount;
    const VkImageToMemoryCopy* pRegions;
} VkCopyImageToMemoryInfo;

typedef struct VkCopyImageToImageInfo {
    VkStructureType sType;
    const void* pNext;
    VkHostImageCopyFlags flags;
    VkImage srcImage;
    VkImageLayout srcImageLayout;
    VkImage dstImage;
    VkImageLayout dstImageLayout;
    uint32_t regionCount;
    const VkImageCopy2* pRegions;
} VkCopyImageToImageInfo;

typedef struct VkHostImageLayoutTransitionInfo {
    VkStructureType sType;
    const void* pNext;
    VkImage image;
    VkImageLayout oldLayout;
    VkImageLayout newLayout;
    VkImageSubresourceRange subresourceRange;
} VkHostImageLayoutTransitionInfo;

typedef struct VkSubresourceHostMemcpySize {
    VkStructureType sType;
    void* pNext;
    VkDeviceSize size;
} VkSubresourceHostMemcpySize;

typedef struct VkHostImageCopyDevicePerformanceQuery {
    VkStructureType sType;
    void* pNext;
    VkBool32 optimalDeviceAccess;
    VkBool32 identicalMemoryLayout;
} VkHostImageCopyDevicePerformanceQuery;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetLineStipple)(VkCommandBuffer commandBuffer, uint32_t lineStippleFactor, uint16_t lineStipplePattern);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkMapMemory2)(VkDevice device, const VkMemoryMapInfo* pMemoryMapInfo, void** ppData);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkUnmapMemory2)(VkDevice device, const VkMemoryUnmapInfo* pMemoryUnmapInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBindIndexBuffer2)(VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkDeviceSize size, VkIndexType indexType);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetRenderingAreaGranularity)(VkDevice device, const VkRenderingAreaInfo* pRenderingAreaInfo, VkExtent2D* pGranularity);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetDeviceImageSubresourceLayout)(VkDevice device, const VkDeviceImageSubresourceInfo* pInfo, VkSubresourceLayout2* pLayout);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetImageSubresourceLayout2)(VkDevice device, VkImage image, const VkImageSubresource2* pSubresource, VkSubresourceLayout2* pLayout);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdPushDescriptorSet)(VkCommandBuffer commandBuffer, VkPipelineBindPoint pipelineBindPoint, VkPipelineLayout layout, uint32_t set, uint32_t descriptorWriteCount, const VkWriteDescriptorSet* pDescriptorWrites);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdPushDescriptorSetWithTemplate)(VkCommandBuffer commandBuffer, VkDescriptorUpdateTemplate descriptorUpdateTemplate, VkPipelineLayout layout, uint32_t set, const void* pData);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetRenderingAttachmentLocations)(VkCommandBuffer commandBuffer, const VkRenderingAttachmentLocationInfo* pLocationInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetRenderingInputAttachmentIndices)(VkCommandBuffer commandBuffer, const VkRenderingInputAttachmentIndexInfo* pInputAttachmentIndexInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBindDescriptorSets2)(VkCommandBuffer commandBuffer, const VkBindDescriptorSetsInfo* pBindDescriptorSetsInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdPushConstants2)(VkCommandBuffer commandBuffer, const VkPushConstantsInfo* pPushConstantsInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdPushDescriptorSet2)(VkCommandBuffer commandBuffer, const VkPushDescriptorSetInfo* pPushDescriptorSetInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdPushDescriptorSetWithTemplate2)(VkCommandBuffer commandBuffer, const VkPushDescriptorSetWithTemplateInfo* pPushDescriptorSetWithTemplateInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCopyMemoryToImage)(VkDevice device, const VkCopyMemoryToImageInfo* pCopyMemoryToImageInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCopyImageToMemory)(VkDevice device, const VkCopyImageToMemoryInfo* pCopyImageToMemoryInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCopyImageToImage)(VkDevice device, const VkCopyImageToImageInfo* pCopyImageToImageInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkTransitionImageLayout)(VkDevice device, uint32_t transitionCount, const VkHostImageLayoutTransitionInfo* pTransitions);


 void __attribute__((__stdcall__)) vkCmdSetLineStipple(
    VkCommandBuffer commandBuffer,
    uint32_t lineStippleFactor,
    uint16_t lineStipplePattern);

 VkResult __attribute__((__stdcall__)) vkMapMemory2(
    VkDevice device,
    const VkMemoryMapInfo* pMemoryMapInfo,
    void** ppData);

 VkResult __attribute__((__stdcall__)) vkUnmapMemory2(
    VkDevice device,
    const VkMemoryUnmapInfo* pMemoryUnmapInfo);

 void __attribute__((__stdcall__)) vkCmdBindIndexBuffer2(
    VkCommandBuffer commandBuffer,
    VkBuffer buffer,
    VkDeviceSize offset,
    VkDeviceSize size,
    VkIndexType indexType);

 void __attribute__((__stdcall__)) vkGetRenderingAreaGranularity(
    VkDevice device,
    const VkRenderingAreaInfo* pRenderingAreaInfo,
    VkExtent2D* pGranularity);

 void __attribute__((__stdcall__)) vkGetDeviceImageSubresourceLayout(
    VkDevice device,
    const VkDeviceImageSubresourceInfo* pInfo,
    VkSubresourceLayout2* pLayout);

 void __attribute__((__stdcall__)) vkGetImageSubresourceLayout2(
    VkDevice device,
    VkImage image,
    const VkImageSubresource2* pSubresource,
    VkSubresourceLayout2* pLayout);

 void __attribute__((__stdcall__)) vkCmdPushDescriptorSet(
    VkCommandBuffer commandBuffer,
    VkPipelineBindPoint pipelineBindPoint,
    VkPipelineLayout layout,
    uint32_t set,
    uint32_t descriptorWriteCount,
    const VkWriteDescriptorSet* pDescriptorWrites);

 void __attribute__((__stdcall__)) vkCmdPushDescriptorSetWithTemplate(
    VkCommandBuffer commandBuffer,
    VkDescriptorUpdateTemplate descriptorUpdateTemplate,
    VkPipelineLayout layout,
    uint32_t set,
    const void* pData);

 void __attribute__((__stdcall__)) vkCmdSetRenderingAttachmentLocations(
    VkCommandBuffer commandBuffer,
    const VkRenderingAttachmentLocationInfo* pLocationInfo);

 void __attribute__((__stdcall__)) vkCmdSetRenderingInputAttachmentIndices(
    VkCommandBuffer commandBuffer,
    const VkRenderingInputAttachmentIndexInfo* pInputAttachmentIndexInfo);

 void __attribute__((__stdcall__)) vkCmdBindDescriptorSets2(
    VkCommandBuffer commandBuffer,
    const VkBindDescriptorSetsInfo* pBindDescriptorSetsInfo);

 void __attribute__((__stdcall__)) vkCmdPushConstants2(
    VkCommandBuffer commandBuffer,
    const VkPushConstantsInfo* pPushConstantsInfo);

 void __attribute__((__stdcall__)) vkCmdPushDescriptorSet2(
    VkCommandBuffer commandBuffer,
    const VkPushDescriptorSetInfo* pPushDescriptorSetInfo);

 void __attribute__((__stdcall__)) vkCmdPushDescriptorSetWithTemplate2(
    VkCommandBuffer commandBuffer,
    const VkPushDescriptorSetWithTemplateInfo* pPushDescriptorSetWithTemplateInfo);

 VkResult __attribute__((__stdcall__)) vkCopyMemoryToImage(
    VkDevice device,
    const VkCopyMemoryToImageInfo* pCopyMemoryToImageInfo);

 VkResult __attribute__((__stdcall__)) vkCopyImageToMemory(
    VkDevice device,
    const VkCopyImageToMemoryInfo* pCopyImageToMemoryInfo);

 VkResult __attribute__((__stdcall__)) vkCopyImageToImage(
    VkDevice device,
    const VkCopyImageToImageInfo* pCopyImageToImageInfo);

 VkResult __attribute__((__stdcall__)) vkTransitionImageLayout(
    VkDevice device,
    uint32_t transitionCount,
    const VkHostImageLayoutTransitionInfo* pTransitions);





typedef struct VkSurfaceKHR_T *VkSurfaceKHR;



typedef enum VkPresentModeKHR {
    VK_PRESENT_MODE_IMMEDIATE_KHR = 0,
    VK_PRESENT_MODE_MAILBOX_KHR = 1,
    VK_PRESENT_MODE_FIFO_KHR = 2,
    VK_PRESENT_MODE_FIFO_RELAXED_KHR = 3,
    VK_PRESENT_MODE_SHARED_DEMAND_REFRESH_KHR = 1000111000,
    VK_PRESENT_MODE_SHARED_CONTINUOUS_REFRESH_KHR = 1000111001,
    VK_PRESENT_MODE_FIFO_LATEST_READY_EXT = 1000361000,
    VK_PRESENT_MODE_MAX_ENUM_KHR = 0x7FFFFFFF
} VkPresentModeKHR;

typedef enum VkColorSpaceKHR {
    VK_COLOR_SPACE_SRGB_NONLINEAR_KHR = 0,
    VK_COLOR_SPACE_DISPLAY_P3_NONLINEAR_EXT = 1000104001,
    VK_COLOR_SPACE_EXTENDED_SRGB_LINEAR_EXT = 1000104002,
    VK_COLOR_SPACE_DISPLAY_P3_LINEAR_EXT = 1000104003,
    VK_COLOR_SPACE_DCI_P3_NONLINEAR_EXT = 1000104004,
    VK_COLOR_SPACE_BT709_LINEAR_EXT = 1000104005,
    VK_COLOR_SPACE_BT709_NONLINEAR_EXT = 1000104006,
    VK_COLOR_SPACE_BT2020_LINEAR_EXT = 1000104007,
    VK_COLOR_SPACE_HDR10_ST2084_EXT = 1000104008,

    VK_COLOR_SPACE_DOLBYVISION_EXT = 1000104009,
    VK_COLOR_SPACE_HDR10_HLG_EXT = 1000104010,
    VK_COLOR_SPACE_ADOBERGB_LINEAR_EXT = 1000104011,
    VK_COLOR_SPACE_ADOBERGB_NONLINEAR_EXT = 1000104012,
    VK_COLOR_SPACE_PASS_THROUGH_EXT = 1000104013,
    VK_COLOR_SPACE_EXTENDED_SRGB_NONLINEAR_EXT = 1000104014,
    VK_COLOR_SPACE_DISPLAY_NATIVE_AMD = 1000213000,

    VK_COLORSPACE_SRGB_NONLINEAR_KHR = VK_COLOR_SPACE_SRGB_NONLINEAR_KHR,

    VK_COLOR_SPACE_DCI_P3_LINEAR_EXT = VK_COLOR_SPACE_DISPLAY_P3_LINEAR_EXT,
    VK_COLOR_SPACE_MAX_ENUM_KHR = 0x7FFFFFFF
} VkColorSpaceKHR;

typedef enum VkSurfaceTransformFlagBitsKHR {
    VK_SURFACE_TRANSFORM_IDENTITY_BIT_KHR = 0x00000001,
    VK_SURFACE_TRANSFORM_ROTATE_90_BIT_KHR = 0x00000002,
    VK_SURFACE_TRANSFORM_ROTATE_180_BIT_KHR = 0x00000004,
    VK_SURFACE_TRANSFORM_ROTATE_270_BIT_KHR = 0x00000008,
    VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_BIT_KHR = 0x00000010,
    VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_90_BIT_KHR = 0x00000020,
    VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_180_BIT_KHR = 0x00000040,
    VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_270_BIT_KHR = 0x00000080,
    VK_SURFACE_TRANSFORM_INHERIT_BIT_KHR = 0x00000100,
    VK_SURFACE_TRANSFORM_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkSurfaceTransformFlagBitsKHR;

typedef enum VkCompositeAlphaFlagBitsKHR {
    VK_COMPOSITE_ALPHA_OPAQUE_BIT_KHR = 0x00000001,
    VK_COMPOSITE_ALPHA_PRE_MULTIPLIED_BIT_KHR = 0x00000002,
    VK_COMPOSITE_ALPHA_POST_MULTIPLIED_BIT_KHR = 0x00000004,
    VK_COMPOSITE_ALPHA_INHERIT_BIT_KHR = 0x00000008,
    VK_COMPOSITE_ALPHA_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkCompositeAlphaFlagBitsKHR;
typedef VkFlags VkCompositeAlphaFlagsKHR;
typedef VkFlags VkSurfaceTransformFlagsKHR;
typedef struct VkSurfaceCapabilitiesKHR {
    uint32_t minImageCount;
    uint32_t maxImageCount;
    VkExtent2D currentExtent;
    VkExtent2D minImageExtent;
    VkExtent2D maxImageExtent;
    uint32_t maxImageArrayLayers;
    VkSurfaceTransformFlagsKHR supportedTransforms;
    VkSurfaceTransformFlagBitsKHR currentTransform;
    VkCompositeAlphaFlagsKHR supportedCompositeAlpha;
    VkImageUsageFlags supportedUsageFlags;
} VkSurfaceCapabilitiesKHR;

typedef struct VkSurfaceFormatKHR {
    VkFormat format;
    VkColorSpaceKHR colorSpace;
} VkSurfaceFormatKHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkDestroySurfaceKHR)(VkInstance instance, VkSurfaceKHR surface, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceSurfaceSupportKHR)(VkPhysicalDevice physicalDevice, uint32_t queueFamilyIndex, VkSurfaceKHR surface, VkBool32* pSupported);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceSurfaceCapabilitiesKHR)(VkPhysicalDevice physicalDevice, VkSurfaceKHR surface, VkSurfaceCapabilitiesKHR* pSurfaceCapabilities);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceSurfaceFormatsKHR)(VkPhysicalDevice physicalDevice, VkSurfaceKHR surface, uint32_t* pSurfaceFormatCount, VkSurfaceFormatKHR* pSurfaceFormats);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceSurfacePresentModesKHR)(VkPhysicalDevice physicalDevice, VkSurfaceKHR surface, uint32_t* pPresentModeCount, VkPresentModeKHR* pPresentModes);


 void __attribute__((__stdcall__)) vkDestroySurfaceKHR(
    VkInstance instance,
    VkSurfaceKHR surface,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceSurfaceSupportKHR(
    VkPhysicalDevice physicalDevice,
    uint32_t queueFamilyIndex,
    VkSurfaceKHR surface,
    VkBool32* pSupported);

 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceSurfaceCapabilitiesKHR(
    VkPhysicalDevice physicalDevice,
    VkSurfaceKHR surface,
    VkSurfaceCapabilitiesKHR* pSurfaceCapabilities);

 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceSurfaceFormatsKHR(
    VkPhysicalDevice physicalDevice,
    VkSurfaceKHR surface,
    uint32_t* pSurfaceFormatCount,
    VkSurfaceFormatKHR* pSurfaceFormats);

 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceSurfacePresentModesKHR(
    VkPhysicalDevice physicalDevice,
    VkSurfaceKHR surface,
    uint32_t* pPresentModeCount,
    VkPresentModeKHR* pPresentModes);





typedef struct VkSwapchainKHR_T *VkSwapchainKHR;



typedef enum VkSwapchainCreateFlagBitsKHR {
    VK_SWAPCHAIN_CREATE_SPLIT_INSTANCE_BIND_REGIONS_BIT_KHR = 0x00000001,
    VK_SWAPCHAIN_CREATE_PROTECTED_BIT_KHR = 0x00000002,
    VK_SWAPCHAIN_CREATE_MUTABLE_FORMAT_BIT_KHR = 0x00000004,
    VK_SWAPCHAIN_CREATE_DEFERRED_MEMORY_ALLOCATION_BIT_EXT = 0x00000008,
    VK_SWAPCHAIN_CREATE_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkSwapchainCreateFlagBitsKHR;
typedef VkFlags VkSwapchainCreateFlagsKHR;

typedef enum VkDeviceGroupPresentModeFlagBitsKHR {
    VK_DEVICE_GROUP_PRESENT_MODE_LOCAL_BIT_KHR = 0x00000001,
    VK_DEVICE_GROUP_PRESENT_MODE_REMOTE_BIT_KHR = 0x00000002,
    VK_DEVICE_GROUP_PRESENT_MODE_SUM_BIT_KHR = 0x00000004,
    VK_DEVICE_GROUP_PRESENT_MODE_LOCAL_MULTI_DEVICE_BIT_KHR = 0x00000008,
    VK_DEVICE_GROUP_PRESENT_MODE_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkDeviceGroupPresentModeFlagBitsKHR;
typedef VkFlags VkDeviceGroupPresentModeFlagsKHR;
typedef struct VkSwapchainCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkSwapchainCreateFlagsKHR flags;
    VkSurfaceKHR surface;
    uint32_t minImageCount;
    VkFormat imageFormat;
    VkColorSpaceKHR imageColorSpace;
    VkExtent2D imageExtent;
    uint32_t imageArrayLayers;
    VkImageUsageFlags imageUsage;
    VkSharingMode imageSharingMode;
    uint32_t queueFamilyIndexCount;
    const uint32_t* pQueueFamilyIndices;
    VkSurfaceTransformFlagBitsKHR preTransform;
    VkCompositeAlphaFlagBitsKHR compositeAlpha;
    VkPresentModeKHR presentMode;
    VkBool32 clipped;
    VkSwapchainKHR oldSwapchain;
} VkSwapchainCreateInfoKHR;

typedef struct VkPresentInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t waitSemaphoreCount;
    const VkSemaphore* pWaitSemaphores;
    uint32_t swapchainCount;
    const VkSwapchainKHR* pSwapchains;
    const uint32_t* pImageIndices;
    VkResult* pResults;
} VkPresentInfoKHR;

typedef struct VkImageSwapchainCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkSwapchainKHR swapchain;
} VkImageSwapchainCreateInfoKHR;

typedef struct VkBindImageMemorySwapchainInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkSwapchainKHR swapchain;
    uint32_t imageIndex;
} VkBindImageMemorySwapchainInfoKHR;

typedef struct VkAcquireNextImageInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkSwapchainKHR swapchain;
    uint64_t timeout;
    VkSemaphore semaphore;
    VkFence fence;
    uint32_t deviceMask;
} VkAcquireNextImageInfoKHR;

typedef struct VkDeviceGroupPresentCapabilitiesKHR {
    VkStructureType sType;
    void* pNext;
    uint32_t presentMask[32U];
    VkDeviceGroupPresentModeFlagsKHR modes;
} VkDeviceGroupPresentCapabilitiesKHR;

typedef struct VkDeviceGroupPresentInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t swapchainCount;
    const uint32_t* pDeviceMasks;
    VkDeviceGroupPresentModeFlagBitsKHR mode;
} VkDeviceGroupPresentInfoKHR;

typedef struct VkDeviceGroupSwapchainCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkDeviceGroupPresentModeFlagsKHR modes;
} VkDeviceGroupSwapchainCreateInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateSwapchainKHR)(VkDevice device, const VkSwapchainCreateInfoKHR* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSwapchainKHR* pSwapchain);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroySwapchainKHR)(VkDevice device, VkSwapchainKHR swapchain, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetSwapchainImagesKHR)(VkDevice device, VkSwapchainKHR swapchain, uint32_t* pSwapchainImageCount, VkImage* pSwapchainImages);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkAcquireNextImageKHR)(VkDevice device, VkSwapchainKHR swapchain, uint64_t timeout, VkSemaphore semaphore, VkFence fence, uint32_t* pImageIndex);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkQueuePresentKHR)(VkQueue queue, const VkPresentInfoKHR* pPresentInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetDeviceGroupPresentCapabilitiesKHR)(VkDevice device, VkDeviceGroupPresentCapabilitiesKHR* pDeviceGroupPresentCapabilities);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetDeviceGroupSurfacePresentModesKHR)(VkDevice device, VkSurfaceKHR surface, VkDeviceGroupPresentModeFlagsKHR* pModes);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDevicePresentRectanglesKHR)(VkPhysicalDevice physicalDevice, VkSurfaceKHR surface, uint32_t* pRectCount, VkRect2D* pRects);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkAcquireNextImage2KHR)(VkDevice device, const VkAcquireNextImageInfoKHR* pAcquireInfo, uint32_t* pImageIndex);


 VkResult __attribute__((__stdcall__)) vkCreateSwapchainKHR(
    VkDevice device,
    const VkSwapchainCreateInfoKHR* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkSwapchainKHR* pSwapchain);

 void __attribute__((__stdcall__)) vkDestroySwapchainKHR(
    VkDevice device,
    VkSwapchainKHR swapchain,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkGetSwapchainImagesKHR(
    VkDevice device,
    VkSwapchainKHR swapchain,
    uint32_t* pSwapchainImageCount,
    VkImage* pSwapchainImages);

 VkResult __attribute__((__stdcall__)) vkAcquireNextImageKHR(
    VkDevice device,
    VkSwapchainKHR swapchain,
    uint64_t timeout,
    VkSemaphore semaphore,
    VkFence fence,
    uint32_t* pImageIndex);

 VkResult __attribute__((__stdcall__)) vkQueuePresentKHR(
    VkQueue queue,
    const VkPresentInfoKHR* pPresentInfo);

 VkResult __attribute__((__stdcall__)) vkGetDeviceGroupPresentCapabilitiesKHR(
    VkDevice device,
    VkDeviceGroupPresentCapabilitiesKHR* pDeviceGroupPresentCapabilities);

 VkResult __attribute__((__stdcall__)) vkGetDeviceGroupSurfacePresentModesKHR(
    VkDevice device,
    VkSurfaceKHR surface,
    VkDeviceGroupPresentModeFlagsKHR* pModes);

 VkResult __attribute__((__stdcall__)) vkGetPhysicalDevicePresentRectanglesKHR(
    VkPhysicalDevice physicalDevice,
    VkSurfaceKHR surface,
    uint32_t* pRectCount,
    VkRect2D* pRects);

 VkResult __attribute__((__stdcall__)) vkAcquireNextImage2KHR(
    VkDevice device,
    const VkAcquireNextImageInfoKHR* pAcquireInfo,
    uint32_t* pImageIndex);





typedef struct VkDisplayKHR_T *VkDisplayKHR;
typedef struct VkDisplayModeKHR_T *VkDisplayModeKHR;


typedef VkFlags VkDisplayModeCreateFlagsKHR;

typedef enum VkDisplayPlaneAlphaFlagBitsKHR {
    VK_DISPLAY_PLANE_ALPHA_OPAQUE_BIT_KHR = 0x00000001,
    VK_DISPLAY_PLANE_ALPHA_GLOBAL_BIT_KHR = 0x00000002,
    VK_DISPLAY_PLANE_ALPHA_PER_PIXEL_BIT_KHR = 0x00000004,
    VK_DISPLAY_PLANE_ALPHA_PER_PIXEL_PREMULTIPLIED_BIT_KHR = 0x00000008,
    VK_DISPLAY_PLANE_ALPHA_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkDisplayPlaneAlphaFlagBitsKHR;
typedef VkFlags VkDisplayPlaneAlphaFlagsKHR;
typedef VkFlags VkDisplaySurfaceCreateFlagsKHR;
typedef struct VkDisplayModeParametersKHR {
    VkExtent2D visibleRegion;
    uint32_t refreshRate;
} VkDisplayModeParametersKHR;

typedef struct VkDisplayModeCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkDisplayModeCreateFlagsKHR flags;
    VkDisplayModeParametersKHR parameters;
} VkDisplayModeCreateInfoKHR;

typedef struct VkDisplayModePropertiesKHR {
    VkDisplayModeKHR displayMode;
    VkDisplayModeParametersKHR parameters;
} VkDisplayModePropertiesKHR;

typedef struct VkDisplayPlaneCapabilitiesKHR {
    VkDisplayPlaneAlphaFlagsKHR supportedAlpha;
    VkOffset2D minSrcPosition;
    VkOffset2D maxSrcPosition;
    VkExtent2D minSrcExtent;
    VkExtent2D maxSrcExtent;
    VkOffset2D minDstPosition;
    VkOffset2D maxDstPosition;
    VkExtent2D minDstExtent;
    VkExtent2D maxDstExtent;
} VkDisplayPlaneCapabilitiesKHR;

typedef struct VkDisplayPlanePropertiesKHR {
    VkDisplayKHR currentDisplay;
    uint32_t currentStackIndex;
} VkDisplayPlanePropertiesKHR;

typedef struct VkDisplayPropertiesKHR {
    VkDisplayKHR display;
    const char* displayName;
    VkExtent2D physicalDimensions;
    VkExtent2D physicalResolution;
    VkSurfaceTransformFlagsKHR supportedTransforms;
    VkBool32 planeReorderPossible;
    VkBool32 persistentContent;
} VkDisplayPropertiesKHR;

typedef struct VkDisplaySurfaceCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkDisplaySurfaceCreateFlagsKHR flags;
    VkDisplayModeKHR displayMode;
    uint32_t planeIndex;
    uint32_t planeStackIndex;
    VkSurfaceTransformFlagBitsKHR transform;
    float globalAlpha;
    VkDisplayPlaneAlphaFlagBitsKHR alphaMode;
    VkExtent2D imageExtent;
} VkDisplaySurfaceCreateInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceDisplayPropertiesKHR)(VkPhysicalDevice physicalDevice, uint32_t* pPropertyCount, VkDisplayPropertiesKHR* pProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceDisplayPlanePropertiesKHR)(VkPhysicalDevice physicalDevice, uint32_t* pPropertyCount, VkDisplayPlanePropertiesKHR* pProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetDisplayPlaneSupportedDisplaysKHR)(VkPhysicalDevice physicalDevice, uint32_t planeIndex, uint32_t* pDisplayCount, VkDisplayKHR* pDisplays);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetDisplayModePropertiesKHR)(VkPhysicalDevice physicalDevice, VkDisplayKHR display, uint32_t* pPropertyCount, VkDisplayModePropertiesKHR* pProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateDisplayModeKHR)(VkPhysicalDevice physicalDevice, VkDisplayKHR display, const VkDisplayModeCreateInfoKHR* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDisplayModeKHR* pMode);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetDisplayPlaneCapabilitiesKHR)(VkPhysicalDevice physicalDevice, VkDisplayModeKHR mode, uint32_t planeIndex, VkDisplayPlaneCapabilitiesKHR* pCapabilities);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateDisplayPlaneSurfaceKHR)(VkInstance instance, const VkDisplaySurfaceCreateInfoKHR* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSurfaceKHR* pSurface);


 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceDisplayPropertiesKHR(
    VkPhysicalDevice physicalDevice,
    uint32_t* pPropertyCount,
    VkDisplayPropertiesKHR* pProperties);

 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceDisplayPlanePropertiesKHR(
    VkPhysicalDevice physicalDevice,
    uint32_t* pPropertyCount,
    VkDisplayPlanePropertiesKHR* pProperties);

 VkResult __attribute__((__stdcall__)) vkGetDisplayPlaneSupportedDisplaysKHR(
    VkPhysicalDevice physicalDevice,
    uint32_t planeIndex,
    uint32_t* pDisplayCount,
    VkDisplayKHR* pDisplays);

 VkResult __attribute__((__stdcall__)) vkGetDisplayModePropertiesKHR(
    VkPhysicalDevice physicalDevice,
    VkDisplayKHR display,
    uint32_t* pPropertyCount,
    VkDisplayModePropertiesKHR* pProperties);

 VkResult __attribute__((__stdcall__)) vkCreateDisplayModeKHR(
    VkPhysicalDevice physicalDevice,
    VkDisplayKHR display,
    const VkDisplayModeCreateInfoKHR* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkDisplayModeKHR* pMode);

 VkResult __attribute__((__stdcall__)) vkGetDisplayPlaneCapabilitiesKHR(
    VkPhysicalDevice physicalDevice,
    VkDisplayModeKHR mode,
    uint32_t planeIndex,
    VkDisplayPlaneCapabilitiesKHR* pCapabilities);

 VkResult __attribute__((__stdcall__)) vkCreateDisplayPlaneSurfaceKHR(
    VkInstance instance,
    const VkDisplaySurfaceCreateInfoKHR* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkSurfaceKHR* pSurface);







typedef struct VkDisplayPresentInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkRect2D srcRect;
    VkRect2D dstRect;
    VkBool32 persistent;
} VkDisplayPresentInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateSharedSwapchainsKHR)(VkDevice device, uint32_t swapchainCount, const VkSwapchainCreateInfoKHR* pCreateInfos, const VkAllocationCallbacks* pAllocator, VkSwapchainKHR* pSwapchains);


 VkResult __attribute__((__stdcall__)) vkCreateSharedSwapchainsKHR(
    VkDevice device,
    uint32_t swapchainCount,
    const VkSwapchainCreateInfoKHR* pCreateInfos,
    const VkAllocationCallbacks* pAllocator,
    VkSwapchainKHR* pSwapchains);
# 8887 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkVideoSessionKHR_T *VkVideoSessionKHR;
typedef struct VkVideoSessionParametersKHR_T *VkVideoSessionParametersKHR;



typedef enum VkQueryResultStatusKHR {
    VK_QUERY_RESULT_STATUS_ERROR_KHR = -1,
    VK_QUERY_RESULT_STATUS_NOT_READY_KHR = 0,
    VK_QUERY_RESULT_STATUS_COMPLETE_KHR = 1,
    VK_QUERY_RESULT_STATUS_INSUFFICIENT_BITSTREAM_BUFFER_RANGE_KHR = -1000299000,
    VK_QUERY_RESULT_STATUS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkQueryResultStatusKHR;

typedef enum VkVideoCodecOperationFlagBitsKHR {
    VK_VIDEO_CODEC_OPERATION_NONE_KHR = 0,
    VK_VIDEO_CODEC_OPERATION_ENCODE_H264_BIT_KHR = 0x00010000,
    VK_VIDEO_CODEC_OPERATION_ENCODE_H265_BIT_KHR = 0x00020000,
    VK_VIDEO_CODEC_OPERATION_DECODE_H264_BIT_KHR = 0x00000001,
    VK_VIDEO_CODEC_OPERATION_DECODE_H265_BIT_KHR = 0x00000002,
    VK_VIDEO_CODEC_OPERATION_DECODE_AV1_BIT_KHR = 0x00000004,
    VK_VIDEO_CODEC_OPERATION_ENCODE_AV1_BIT_KHR = 0x00040000,
    VK_VIDEO_CODEC_OPERATION_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoCodecOperationFlagBitsKHR;
typedef VkFlags VkVideoCodecOperationFlagsKHR;

typedef enum VkVideoChromaSubsamplingFlagBitsKHR {
    VK_VIDEO_CHROMA_SUBSAMPLING_INVALID_KHR = 0,
    VK_VIDEO_CHROMA_SUBSAMPLING_MONOCHROME_BIT_KHR = 0x00000001,
    VK_VIDEO_CHROMA_SUBSAMPLING_420_BIT_KHR = 0x00000002,
    VK_VIDEO_CHROMA_SUBSAMPLING_422_BIT_KHR = 0x00000004,
    VK_VIDEO_CHROMA_SUBSAMPLING_444_BIT_KHR = 0x00000008,
    VK_VIDEO_CHROMA_SUBSAMPLING_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoChromaSubsamplingFlagBitsKHR;
typedef VkFlags VkVideoChromaSubsamplingFlagsKHR;

typedef enum VkVideoComponentBitDepthFlagBitsKHR {
    VK_VIDEO_COMPONENT_BIT_DEPTH_INVALID_KHR = 0,
    VK_VIDEO_COMPONENT_BIT_DEPTH_8_BIT_KHR = 0x00000001,
    VK_VIDEO_COMPONENT_BIT_DEPTH_10_BIT_KHR = 0x00000004,
    VK_VIDEO_COMPONENT_BIT_DEPTH_12_BIT_KHR = 0x00000010,
    VK_VIDEO_COMPONENT_BIT_DEPTH_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoComponentBitDepthFlagBitsKHR;
typedef VkFlags VkVideoComponentBitDepthFlagsKHR;

typedef enum VkVideoCapabilityFlagBitsKHR {
    VK_VIDEO_CAPABILITY_PROTECTED_CONTENT_BIT_KHR = 0x00000001,
    VK_VIDEO_CAPABILITY_SEPARATE_REFERENCE_IMAGES_BIT_KHR = 0x00000002,
    VK_VIDEO_CAPABILITY_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoCapabilityFlagBitsKHR;
typedef VkFlags VkVideoCapabilityFlagsKHR;

typedef enum VkVideoSessionCreateFlagBitsKHR {
    VK_VIDEO_SESSION_CREATE_PROTECTED_CONTENT_BIT_KHR = 0x00000001,
    VK_VIDEO_SESSION_CREATE_ALLOW_ENCODE_PARAMETER_OPTIMIZATIONS_BIT_KHR = 0x00000002,
    VK_VIDEO_SESSION_CREATE_INLINE_QUERIES_BIT_KHR = 0x00000004,
    VK_VIDEO_SESSION_CREATE_ALLOW_ENCODE_QUANTIZATION_DELTA_MAP_BIT_KHR = 0x00000008,
    VK_VIDEO_SESSION_CREATE_ALLOW_ENCODE_EMPHASIS_MAP_BIT_KHR = 0x00000010,
    VK_VIDEO_SESSION_CREATE_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoSessionCreateFlagBitsKHR;
typedef VkFlags VkVideoSessionCreateFlagsKHR;

typedef enum VkVideoSessionParametersCreateFlagBitsKHR {
    VK_VIDEO_SESSION_PARAMETERS_CREATE_QUANTIZATION_MAP_COMPATIBLE_BIT_KHR = 0x00000001,
    VK_VIDEO_SESSION_PARAMETERS_CREATE_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoSessionParametersCreateFlagBitsKHR;
typedef VkFlags VkVideoSessionParametersCreateFlagsKHR;
typedef VkFlags VkVideoBeginCodingFlagsKHR;
typedef VkFlags VkVideoEndCodingFlagsKHR;

typedef enum VkVideoCodingControlFlagBitsKHR {
    VK_VIDEO_CODING_CONTROL_RESET_BIT_KHR = 0x00000001,
    VK_VIDEO_CODING_CONTROL_ENCODE_RATE_CONTROL_BIT_KHR = 0x00000002,
    VK_VIDEO_CODING_CONTROL_ENCODE_QUALITY_LEVEL_BIT_KHR = 0x00000004,
    VK_VIDEO_CODING_CONTROL_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoCodingControlFlagBitsKHR;
typedef VkFlags VkVideoCodingControlFlagsKHR;
typedef struct VkQueueFamilyQueryResultStatusPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 queryResultStatusSupport;
} VkQueueFamilyQueryResultStatusPropertiesKHR;

typedef struct VkQueueFamilyVideoPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkVideoCodecOperationFlagsKHR videoCodecOperations;
} VkQueueFamilyVideoPropertiesKHR;

typedef struct VkVideoProfileInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkVideoCodecOperationFlagBitsKHR videoCodecOperation;
    VkVideoChromaSubsamplingFlagsKHR chromaSubsampling;
    VkVideoComponentBitDepthFlagsKHR lumaBitDepth;
    VkVideoComponentBitDepthFlagsKHR chromaBitDepth;
} VkVideoProfileInfoKHR;

typedef struct VkVideoProfileListInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t profileCount;
    const VkVideoProfileInfoKHR* pProfiles;
} VkVideoProfileListInfoKHR;

typedef struct VkVideoCapabilitiesKHR {
    VkStructureType sType;
    void* pNext;
    VkVideoCapabilityFlagsKHR flags;
    VkDeviceSize minBitstreamBufferOffsetAlignment;
    VkDeviceSize minBitstreamBufferSizeAlignment;
    VkExtent2D pictureAccessGranularity;
    VkExtent2D minCodedExtent;
    VkExtent2D maxCodedExtent;
    uint32_t maxDpbSlots;
    uint32_t maxActiveReferencePictures;
    VkExtensionProperties stdHeaderVersion;
} VkVideoCapabilitiesKHR;

typedef struct VkPhysicalDeviceVideoFormatInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkImageUsageFlags imageUsage;
} VkPhysicalDeviceVideoFormatInfoKHR;

typedef struct VkVideoFormatPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkFormat format;
    VkComponentMapping componentMapping;
    VkImageCreateFlags imageCreateFlags;
    VkImageType imageType;
    VkImageTiling imageTiling;
    VkImageUsageFlags imageUsageFlags;
} VkVideoFormatPropertiesKHR;

typedef struct VkVideoPictureResourceInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkOffset2D codedOffset;
    VkExtent2D codedExtent;
    uint32_t baseArrayLayer;
    VkImageView imageViewBinding;
} VkVideoPictureResourceInfoKHR;

typedef struct VkVideoReferenceSlotInfoKHR {
    VkStructureType sType;
    const void* pNext;
    int32_t slotIndex;
    const VkVideoPictureResourceInfoKHR* pPictureResource;
} VkVideoReferenceSlotInfoKHR;

typedef struct VkVideoSessionMemoryRequirementsKHR {
    VkStructureType sType;
    void* pNext;
    uint32_t memoryBindIndex;
    VkMemoryRequirements memoryRequirements;
} VkVideoSessionMemoryRequirementsKHR;

typedef struct VkBindVideoSessionMemoryInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t memoryBindIndex;
    VkDeviceMemory memory;
    VkDeviceSize memoryOffset;
    VkDeviceSize memorySize;
} VkBindVideoSessionMemoryInfoKHR;

typedef struct VkVideoSessionCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t queueFamilyIndex;
    VkVideoSessionCreateFlagsKHR flags;
    const VkVideoProfileInfoKHR* pVideoProfile;
    VkFormat pictureFormat;
    VkExtent2D maxCodedExtent;
    VkFormat referencePictureFormat;
    uint32_t maxDpbSlots;
    uint32_t maxActiveReferencePictures;
    const VkExtensionProperties* pStdHeaderVersion;
} VkVideoSessionCreateInfoKHR;

typedef struct VkVideoSessionParametersCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkVideoSessionParametersCreateFlagsKHR flags;
    VkVideoSessionParametersKHR videoSessionParametersTemplate;
    VkVideoSessionKHR videoSession;
} VkVideoSessionParametersCreateInfoKHR;

typedef struct VkVideoSessionParametersUpdateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t updateSequenceCount;
} VkVideoSessionParametersUpdateInfoKHR;

typedef struct VkVideoBeginCodingInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkVideoBeginCodingFlagsKHR flags;
    VkVideoSessionKHR videoSession;
    VkVideoSessionParametersKHR videoSessionParameters;
    uint32_t referenceSlotCount;
    const VkVideoReferenceSlotInfoKHR* pReferenceSlots;
} VkVideoBeginCodingInfoKHR;

typedef struct VkVideoEndCodingInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkVideoEndCodingFlagsKHR flags;
} VkVideoEndCodingInfoKHR;

typedef struct VkVideoCodingControlInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkVideoCodingControlFlagsKHR flags;
} VkVideoCodingControlInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceVideoCapabilitiesKHR)(VkPhysicalDevice physicalDevice, const VkVideoProfileInfoKHR* pVideoProfile, VkVideoCapabilitiesKHR* pCapabilities);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceVideoFormatPropertiesKHR)(VkPhysicalDevice physicalDevice, const VkPhysicalDeviceVideoFormatInfoKHR* pVideoFormatInfo, uint32_t* pVideoFormatPropertyCount, VkVideoFormatPropertiesKHR* pVideoFormatProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateVideoSessionKHR)(VkDevice device, const VkVideoSessionCreateInfoKHR* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkVideoSessionKHR* pVideoSession);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyVideoSessionKHR)(VkDevice device, VkVideoSessionKHR videoSession, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetVideoSessionMemoryRequirementsKHR)(VkDevice device, VkVideoSessionKHR videoSession, uint32_t* pMemoryRequirementsCount, VkVideoSessionMemoryRequirementsKHR* pMemoryRequirements);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkBindVideoSessionMemoryKHR)(VkDevice device, VkVideoSessionKHR videoSession, uint32_t bindSessionMemoryInfoCount, const VkBindVideoSessionMemoryInfoKHR* pBindSessionMemoryInfos);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateVideoSessionParametersKHR)(VkDevice device, const VkVideoSessionParametersCreateInfoKHR* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkVideoSessionParametersKHR* pVideoSessionParameters);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkUpdateVideoSessionParametersKHR)(VkDevice device, VkVideoSessionParametersKHR videoSessionParameters, const VkVideoSessionParametersUpdateInfoKHR* pUpdateInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyVideoSessionParametersKHR)(VkDevice device, VkVideoSessionParametersKHR videoSessionParameters, const VkAllocationCallbacks* pAllocator);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBeginVideoCodingKHR)(VkCommandBuffer commandBuffer, const VkVideoBeginCodingInfoKHR* pBeginInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdEndVideoCodingKHR)(VkCommandBuffer commandBuffer, const VkVideoEndCodingInfoKHR* pEndCodingInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdControlVideoCodingKHR)(VkCommandBuffer commandBuffer, const VkVideoCodingControlInfoKHR* pCodingControlInfo);


 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceVideoCapabilitiesKHR(
    VkPhysicalDevice physicalDevice,
    const VkVideoProfileInfoKHR* pVideoProfile,
    VkVideoCapabilitiesKHR* pCapabilities);

 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceVideoFormatPropertiesKHR(
    VkPhysicalDevice physicalDevice,
    const VkPhysicalDeviceVideoFormatInfoKHR* pVideoFormatInfo,
    uint32_t* pVideoFormatPropertyCount,
    VkVideoFormatPropertiesKHR* pVideoFormatProperties);

 VkResult __attribute__((__stdcall__)) vkCreateVideoSessionKHR(
    VkDevice device,
    const VkVideoSessionCreateInfoKHR* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkVideoSessionKHR* pVideoSession);

 void __attribute__((__stdcall__)) vkDestroyVideoSessionKHR(
    VkDevice device,
    VkVideoSessionKHR videoSession,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkGetVideoSessionMemoryRequirementsKHR(
    VkDevice device,
    VkVideoSessionKHR videoSession,
    uint32_t* pMemoryRequirementsCount,
    VkVideoSessionMemoryRequirementsKHR* pMemoryRequirements);

 VkResult __attribute__((__stdcall__)) vkBindVideoSessionMemoryKHR(
    VkDevice device,
    VkVideoSessionKHR videoSession,
    uint32_t bindSessionMemoryInfoCount,
    const VkBindVideoSessionMemoryInfoKHR* pBindSessionMemoryInfos);

 VkResult __attribute__((__stdcall__)) vkCreateVideoSessionParametersKHR(
    VkDevice device,
    const VkVideoSessionParametersCreateInfoKHR* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkVideoSessionParametersKHR* pVideoSessionParameters);

 VkResult __attribute__((__stdcall__)) vkUpdateVideoSessionParametersKHR(
    VkDevice device,
    VkVideoSessionParametersKHR videoSessionParameters,
    const VkVideoSessionParametersUpdateInfoKHR* pUpdateInfo);

 void __attribute__((__stdcall__)) vkDestroyVideoSessionParametersKHR(
    VkDevice device,
    VkVideoSessionParametersKHR videoSessionParameters,
    const VkAllocationCallbacks* pAllocator);

 void __attribute__((__stdcall__)) vkCmdBeginVideoCodingKHR(
    VkCommandBuffer commandBuffer,
    const VkVideoBeginCodingInfoKHR* pBeginInfo);

 void __attribute__((__stdcall__)) vkCmdEndVideoCodingKHR(
    VkCommandBuffer commandBuffer,
    const VkVideoEndCodingInfoKHR* pEndCodingInfo);

 void __attribute__((__stdcall__)) vkCmdControlVideoCodingKHR(
    VkCommandBuffer commandBuffer,
    const VkVideoCodingControlInfoKHR* pCodingControlInfo);
# 9187 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkVideoDecodeCapabilityFlagBitsKHR {
    VK_VIDEO_DECODE_CAPABILITY_DPB_AND_OUTPUT_COINCIDE_BIT_KHR = 0x00000001,
    VK_VIDEO_DECODE_CAPABILITY_DPB_AND_OUTPUT_DISTINCT_BIT_KHR = 0x00000002,
    VK_VIDEO_DECODE_CAPABILITY_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoDecodeCapabilityFlagBitsKHR;
typedef VkFlags VkVideoDecodeCapabilityFlagsKHR;

typedef enum VkVideoDecodeUsageFlagBitsKHR {
    VK_VIDEO_DECODE_USAGE_DEFAULT_KHR = 0,
    VK_VIDEO_DECODE_USAGE_TRANSCODING_BIT_KHR = 0x00000001,
    VK_VIDEO_DECODE_USAGE_OFFLINE_BIT_KHR = 0x00000002,
    VK_VIDEO_DECODE_USAGE_STREAMING_BIT_KHR = 0x00000004,
    VK_VIDEO_DECODE_USAGE_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoDecodeUsageFlagBitsKHR;
typedef VkFlags VkVideoDecodeUsageFlagsKHR;
typedef VkFlags VkVideoDecodeFlagsKHR;
typedef struct VkVideoDecodeCapabilitiesKHR {
    VkStructureType sType;
    void* pNext;
    VkVideoDecodeCapabilityFlagsKHR flags;
} VkVideoDecodeCapabilitiesKHR;

typedef struct VkVideoDecodeUsageInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkVideoDecodeUsageFlagsKHR videoUsageHints;
} VkVideoDecodeUsageInfoKHR;

typedef struct VkVideoDecodeInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkVideoDecodeFlagsKHR flags;
    VkBuffer srcBuffer;
    VkDeviceSize srcBufferOffset;
    VkDeviceSize srcBufferRange;
    VkVideoPictureResourceInfoKHR dstPictureResource;
    const VkVideoReferenceSlotInfoKHR* pSetupReferenceSlot;
    uint32_t referenceSlotCount;
    const VkVideoReferenceSlotInfoKHR* pReferenceSlots;
} VkVideoDecodeInfoKHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDecodeVideoKHR)(VkCommandBuffer commandBuffer, const VkVideoDecodeInfoKHR* pDecodeInfo);


 void __attribute__((__stdcall__)) vkCmdDecodeVideoKHR(
    VkCommandBuffer commandBuffer,
    const VkVideoDecodeInfoKHR* pDecodeInfo);





# 1 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h264std.h" 1 3 4
# 17 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h264std.h" 3 4
extern "C" {






# 1 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codecs_common.h" 1 3 4
# 17 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codecs_common.h" 3 4
extern "C" {
# 33 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codecs_common.h" 3 4
}
# 25 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h264std.h" 2 3 4
# 34 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h264std.h" 3 4
typedef enum StdVideoH264ChromaFormatIdc {
    STD_VIDEO_H264_CHROMA_FORMAT_IDC_MONOCHROME = 0,
    STD_VIDEO_H264_CHROMA_FORMAT_IDC_420 = 1,
    STD_VIDEO_H264_CHROMA_FORMAT_IDC_422 = 2,
    STD_VIDEO_H264_CHROMA_FORMAT_IDC_444 = 3,
    STD_VIDEO_H264_CHROMA_FORMAT_IDC_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H264_CHROMA_FORMAT_IDC_MAX_ENUM = 0x7FFFFFFF
} StdVideoH264ChromaFormatIdc;

typedef enum StdVideoH264ProfileIdc {
    STD_VIDEO_H264_PROFILE_IDC_BASELINE = 66,
    STD_VIDEO_H264_PROFILE_IDC_MAIN = 77,
    STD_VIDEO_H264_PROFILE_IDC_HIGH = 100,
    STD_VIDEO_H264_PROFILE_IDC_HIGH_444_PREDICTIVE = 244,
    STD_VIDEO_H264_PROFILE_IDC_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H264_PROFILE_IDC_MAX_ENUM = 0x7FFFFFFF
} StdVideoH264ProfileIdc;

typedef enum StdVideoH264LevelIdc {
    STD_VIDEO_H264_LEVEL_IDC_1_0 = 0,
    STD_VIDEO_H264_LEVEL_IDC_1_1 = 1,
    STD_VIDEO_H264_LEVEL_IDC_1_2 = 2,
    STD_VIDEO_H264_LEVEL_IDC_1_3 = 3,
    STD_VIDEO_H264_LEVEL_IDC_2_0 = 4,
    STD_VIDEO_H264_LEVEL_IDC_2_1 = 5,
    STD_VIDEO_H264_LEVEL_IDC_2_2 = 6,
    STD_VIDEO_H264_LEVEL_IDC_3_0 = 7,
    STD_VIDEO_H264_LEVEL_IDC_3_1 = 8,
    STD_VIDEO_H264_LEVEL_IDC_3_2 = 9,
    STD_VIDEO_H264_LEVEL_IDC_4_0 = 10,
    STD_VIDEO_H264_LEVEL_IDC_4_1 = 11,
    STD_VIDEO_H264_LEVEL_IDC_4_2 = 12,
    STD_VIDEO_H264_LEVEL_IDC_5_0 = 13,
    STD_VIDEO_H264_LEVEL_IDC_5_1 = 14,
    STD_VIDEO_H264_LEVEL_IDC_5_2 = 15,
    STD_VIDEO_H264_LEVEL_IDC_6_0 = 16,
    STD_VIDEO_H264_LEVEL_IDC_6_1 = 17,
    STD_VIDEO_H264_LEVEL_IDC_6_2 = 18,
    STD_VIDEO_H264_LEVEL_IDC_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H264_LEVEL_IDC_MAX_ENUM = 0x7FFFFFFF
} StdVideoH264LevelIdc;

typedef enum StdVideoH264PocType {
    STD_VIDEO_H264_POC_TYPE_0 = 0,
    STD_VIDEO_H264_POC_TYPE_1 = 1,
    STD_VIDEO_H264_POC_TYPE_2 = 2,
    STD_VIDEO_H264_POC_TYPE_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H264_POC_TYPE_MAX_ENUM = 0x7FFFFFFF
} StdVideoH264PocType;

typedef enum StdVideoH264AspectRatioIdc {
    STD_VIDEO_H264_ASPECT_RATIO_IDC_UNSPECIFIED = 0,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_SQUARE = 1,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_12_11 = 2,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_10_11 = 3,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_16_11 = 4,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_40_33 = 5,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_24_11 = 6,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_20_11 = 7,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_32_11 = 8,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_80_33 = 9,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_18_11 = 10,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_15_11 = 11,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_64_33 = 12,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_160_99 = 13,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_4_3 = 14,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_3_2 = 15,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_2_1 = 16,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_EXTENDED_SAR = 255,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H264_ASPECT_RATIO_IDC_MAX_ENUM = 0x7FFFFFFF
} StdVideoH264AspectRatioIdc;

typedef enum StdVideoH264WeightedBipredIdc {
    STD_VIDEO_H264_WEIGHTED_BIPRED_IDC_DEFAULT = 0,
    STD_VIDEO_H264_WEIGHTED_BIPRED_IDC_EXPLICIT = 1,
    STD_VIDEO_H264_WEIGHTED_BIPRED_IDC_IMPLICIT = 2,
    STD_VIDEO_H264_WEIGHTED_BIPRED_IDC_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H264_WEIGHTED_BIPRED_IDC_MAX_ENUM = 0x7FFFFFFF
} StdVideoH264WeightedBipredIdc;

typedef enum StdVideoH264ModificationOfPicNumsIdc {
    STD_VIDEO_H264_MODIFICATION_OF_PIC_NUMS_IDC_SHORT_TERM_SUBTRACT = 0,
    STD_VIDEO_H264_MODIFICATION_OF_PIC_NUMS_IDC_SHORT_TERM_ADD = 1,
    STD_VIDEO_H264_MODIFICATION_OF_PIC_NUMS_IDC_LONG_TERM = 2,
    STD_VIDEO_H264_MODIFICATION_OF_PIC_NUMS_IDC_END = 3,
    STD_VIDEO_H264_MODIFICATION_OF_PIC_NUMS_IDC_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H264_MODIFICATION_OF_PIC_NUMS_IDC_MAX_ENUM = 0x7FFFFFFF
} StdVideoH264ModificationOfPicNumsIdc;

typedef enum StdVideoH264MemMgmtControlOp {
    STD_VIDEO_H264_MEM_MGMT_CONTROL_OP_END = 0,
    STD_VIDEO_H264_MEM_MGMT_CONTROL_OP_UNMARK_SHORT_TERM = 1,
    STD_VIDEO_H264_MEM_MGMT_CONTROL_OP_UNMARK_LONG_TERM = 2,
    STD_VIDEO_H264_MEM_MGMT_CONTROL_OP_MARK_LONG_TERM = 3,
    STD_VIDEO_H264_MEM_MGMT_CONTROL_OP_SET_MAX_LONG_TERM_INDEX = 4,
    STD_VIDEO_H264_MEM_MGMT_CONTROL_OP_UNMARK_ALL = 5,
    STD_VIDEO_H264_MEM_MGMT_CONTROL_OP_MARK_CURRENT_AS_LONG_TERM = 6,
    STD_VIDEO_H264_MEM_MGMT_CONTROL_OP_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H264_MEM_MGMT_CONTROL_OP_MAX_ENUM = 0x7FFFFFFF
} StdVideoH264MemMgmtControlOp;

typedef enum StdVideoH264CabacInitIdc {
    STD_VIDEO_H264_CABAC_INIT_IDC_0 = 0,
    STD_VIDEO_H264_CABAC_INIT_IDC_1 = 1,
    STD_VIDEO_H264_CABAC_INIT_IDC_2 = 2,
    STD_VIDEO_H264_CABAC_INIT_IDC_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H264_CABAC_INIT_IDC_MAX_ENUM = 0x7FFFFFFF
} StdVideoH264CabacInitIdc;

typedef enum StdVideoH264DisableDeblockingFilterIdc {
    STD_VIDEO_H264_DISABLE_DEBLOCKING_FILTER_IDC_DISABLED = 0,
    STD_VIDEO_H264_DISABLE_DEBLOCKING_FILTER_IDC_ENABLED = 1,
    STD_VIDEO_H264_DISABLE_DEBLOCKING_FILTER_IDC_PARTIAL = 2,
    STD_VIDEO_H264_DISABLE_DEBLOCKING_FILTER_IDC_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H264_DISABLE_DEBLOCKING_FILTER_IDC_MAX_ENUM = 0x7FFFFFFF
} StdVideoH264DisableDeblockingFilterIdc;

typedef enum StdVideoH264SliceType {
    STD_VIDEO_H264_SLICE_TYPE_P = 0,
    STD_VIDEO_H264_SLICE_TYPE_B = 1,
    STD_VIDEO_H264_SLICE_TYPE_I = 2,
    STD_VIDEO_H264_SLICE_TYPE_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H264_SLICE_TYPE_MAX_ENUM = 0x7FFFFFFF
} StdVideoH264SliceType;

typedef enum StdVideoH264PictureType {
    STD_VIDEO_H264_PICTURE_TYPE_P = 0,
    STD_VIDEO_H264_PICTURE_TYPE_B = 1,
    STD_VIDEO_H264_PICTURE_TYPE_I = 2,
    STD_VIDEO_H264_PICTURE_TYPE_IDR = 5,
    STD_VIDEO_H264_PICTURE_TYPE_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H264_PICTURE_TYPE_MAX_ENUM = 0x7FFFFFFF
} StdVideoH264PictureType;

typedef enum StdVideoH264NonVclNaluType {
    STD_VIDEO_H264_NON_VCL_NALU_TYPE_SPS = 0,
    STD_VIDEO_H264_NON_VCL_NALU_TYPE_PPS = 1,
    STD_VIDEO_H264_NON_VCL_NALU_TYPE_AUD = 2,
    STD_VIDEO_H264_NON_VCL_NALU_TYPE_PREFIX = 3,
    STD_VIDEO_H264_NON_VCL_NALU_TYPE_END_OF_SEQUENCE = 4,
    STD_VIDEO_H264_NON_VCL_NALU_TYPE_END_OF_STREAM = 5,
    STD_VIDEO_H264_NON_VCL_NALU_TYPE_PRECODED = 6,
    STD_VIDEO_H264_NON_VCL_NALU_TYPE_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H264_NON_VCL_NALU_TYPE_MAX_ENUM = 0x7FFFFFFF
} StdVideoH264NonVclNaluType;
typedef struct StdVideoH264SpsVuiFlags {
    uint32_t aspect_ratio_info_present_flag : 1;
    uint32_t overscan_info_present_flag : 1;
    uint32_t overscan_appropriate_flag : 1;
    uint32_t video_signal_type_present_flag : 1;
    uint32_t video_full_range_flag : 1;
    uint32_t color_description_present_flag : 1;
    uint32_t chroma_loc_info_present_flag : 1;
    uint32_t timing_info_present_flag : 1;
    uint32_t fixed_frame_rate_flag : 1;
    uint32_t bitstream_restriction_flag : 1;
    uint32_t nal_hrd_parameters_present_flag : 1;
    uint32_t vcl_hrd_parameters_present_flag : 1;
} StdVideoH264SpsVuiFlags;

typedef struct StdVideoH264HrdParameters {
    uint8_t cpb_cnt_minus1;
    uint8_t bit_rate_scale;
    uint8_t cpb_size_scale;
    uint8_t reserved1;
    uint32_t bit_rate_value_minus1[32];
    uint32_t cpb_size_value_minus1[32];
    uint8_t cbr_flag[32];
    uint32_t initial_cpb_removal_delay_length_minus1;
    uint32_t cpb_removal_delay_length_minus1;
    uint32_t dpb_output_delay_length_minus1;
    uint32_t time_offset_length;
} StdVideoH264HrdParameters;

typedef struct StdVideoH264SequenceParameterSetVui {
    StdVideoH264SpsVuiFlags flags;
    StdVideoH264AspectRatioIdc aspect_ratio_idc;
    uint16_t sar_width;
    uint16_t sar_height;
    uint8_t video_format;
    uint8_t colour_primaries;
    uint8_t transfer_characteristics;
    uint8_t matrix_coefficients;
    uint32_t num_units_in_tick;
    uint32_t time_scale;
    uint8_t max_num_reorder_frames;
    uint8_t max_dec_frame_buffering;
    uint8_t chroma_sample_loc_type_top_field;
    uint8_t chroma_sample_loc_type_bottom_field;
    uint32_t reserved1;
    const StdVideoH264HrdParameters* pHrdParameters;
} StdVideoH264SequenceParameterSetVui;

typedef struct StdVideoH264SpsFlags {
    uint32_t constraint_set0_flag : 1;
    uint32_t constraint_set1_flag : 1;
    uint32_t constraint_set2_flag : 1;
    uint32_t constraint_set3_flag : 1;
    uint32_t constraint_set4_flag : 1;
    uint32_t constraint_set5_flag : 1;
    uint32_t direct_8x8_inference_flag : 1;
    uint32_t mb_adaptive_frame_field_flag : 1;
    uint32_t frame_mbs_only_flag : 1;
    uint32_t delta_pic_order_always_zero_flag : 1;
    uint32_t separate_colour_plane_flag : 1;
    uint32_t gaps_in_frame_num_value_allowed_flag : 1;
    uint32_t qpprime_y_zero_transform_bypass_flag : 1;
    uint32_t frame_cropping_flag : 1;
    uint32_t seq_scaling_matrix_present_flag : 1;
    uint32_t vui_parameters_present_flag : 1;
} StdVideoH264SpsFlags;

typedef struct StdVideoH264ScalingLists {
    uint16_t scaling_list_present_mask;
    uint16_t use_default_scaling_matrix_mask;
    uint8_t ScalingList4x4[6][16];
    uint8_t ScalingList8x8[6][64];
} StdVideoH264ScalingLists;

typedef struct StdVideoH264SequenceParameterSet {
    StdVideoH264SpsFlags flags;
    StdVideoH264ProfileIdc profile_idc;
    StdVideoH264LevelIdc level_idc;
    StdVideoH264ChromaFormatIdc chroma_format_idc;
    uint8_t seq_parameter_set_id;
    uint8_t bit_depth_luma_minus8;
    uint8_t bit_depth_chroma_minus8;
    uint8_t log2_max_frame_num_minus4;
    StdVideoH264PocType pic_order_cnt_type;
    int32_t offset_for_non_ref_pic;
    int32_t offset_for_top_to_bottom_field;
    uint8_t log2_max_pic_order_cnt_lsb_minus4;
    uint8_t num_ref_frames_in_pic_order_cnt_cycle;
    uint8_t max_num_ref_frames;
    uint8_t reserved1;
    uint32_t pic_width_in_mbs_minus1;
    uint32_t pic_height_in_map_units_minus1;
    uint32_t frame_crop_left_offset;
    uint32_t frame_crop_right_offset;
    uint32_t frame_crop_top_offset;
    uint32_t frame_crop_bottom_offset;
    uint32_t reserved2;
    const int32_t* pOffsetForRefFrame;
    const StdVideoH264ScalingLists* pScalingLists;
    const StdVideoH264SequenceParameterSetVui* pSequenceParameterSetVui;
} StdVideoH264SequenceParameterSet;

typedef struct StdVideoH264PpsFlags {
    uint32_t transform_8x8_mode_flag : 1;
    uint32_t redundant_pic_cnt_present_flag : 1;
    uint32_t constrained_intra_pred_flag : 1;
    uint32_t deblocking_filter_control_present_flag : 1;
    uint32_t weighted_pred_flag : 1;
    uint32_t bottom_field_pic_order_in_frame_present_flag : 1;
    uint32_t entropy_coding_mode_flag : 1;
    uint32_t pic_scaling_matrix_present_flag : 1;
} StdVideoH264PpsFlags;

typedef struct StdVideoH264PictureParameterSet {
    StdVideoH264PpsFlags flags;
    uint8_t seq_parameter_set_id;
    uint8_t pic_parameter_set_id;
    uint8_t num_ref_idx_l0_default_active_minus1;
    uint8_t num_ref_idx_l1_default_active_minus1;
    StdVideoH264WeightedBipredIdc weighted_bipred_idc;
    int8_t pic_init_qp_minus26;
    int8_t pic_init_qs_minus26;
    int8_t chroma_qp_index_offset;
    int8_t second_chroma_qp_index_offset;
    const StdVideoH264ScalingLists* pScalingLists;
} StdVideoH264PictureParameterSet;



}
# 9240 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 2 3 4
# 1 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h264std_encode.h" 1 3 4
# 17 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h264std_encode.h" 3 4
extern "C" {






# 1 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h264std.h" 1 3 4
# 25 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h264std_encode.h" 2 3 4





typedef struct StdVideoEncodeH264WeightTableFlags {
    uint32_t luma_weight_l0_flag;
    uint32_t chroma_weight_l0_flag;
    uint32_t luma_weight_l1_flag;
    uint32_t chroma_weight_l1_flag;
} StdVideoEncodeH264WeightTableFlags;

typedef struct StdVideoEncodeH264WeightTable {
    StdVideoEncodeH264WeightTableFlags flags;
    uint8_t luma_log2_weight_denom;
    uint8_t chroma_log2_weight_denom;
    int8_t luma_weight_l0[32];
    int8_t luma_offset_l0[32];
    int8_t chroma_weight_l0[32][2];
    int8_t chroma_offset_l0[32][2];
    int8_t luma_weight_l1[32];
    int8_t luma_offset_l1[32];
    int8_t chroma_weight_l1[32][2];
    int8_t chroma_offset_l1[32][2];
} StdVideoEncodeH264WeightTable;

typedef struct StdVideoEncodeH264SliceHeaderFlags {
    uint32_t direct_spatial_mv_pred_flag : 1;
    uint32_t num_ref_idx_active_override_flag : 1;
    uint32_t reserved : 30;
} StdVideoEncodeH264SliceHeaderFlags;

typedef struct StdVideoEncodeH264PictureInfoFlags {
    uint32_t IdrPicFlag : 1;
    uint32_t is_reference : 1;
    uint32_t no_output_of_prior_pics_flag : 1;
    uint32_t long_term_reference_flag : 1;
    uint32_t adaptive_ref_pic_marking_mode_flag : 1;
    uint32_t reserved : 27;
} StdVideoEncodeH264PictureInfoFlags;

typedef struct StdVideoEncodeH264ReferenceInfoFlags {
    uint32_t used_for_long_term_reference : 1;
    uint32_t reserved : 31;
} StdVideoEncodeH264ReferenceInfoFlags;

typedef struct StdVideoEncodeH264ReferenceListsInfoFlags {
    uint32_t ref_pic_list_modification_flag_l0 : 1;
    uint32_t ref_pic_list_modification_flag_l1 : 1;
    uint32_t reserved : 30;
} StdVideoEncodeH264ReferenceListsInfoFlags;

typedef struct StdVideoEncodeH264RefListModEntry {
    StdVideoH264ModificationOfPicNumsIdc modification_of_pic_nums_idc;
    uint16_t abs_diff_pic_num_minus1;
    uint16_t long_term_pic_num;
} StdVideoEncodeH264RefListModEntry;

typedef struct StdVideoEncodeH264RefPicMarkingEntry {
    StdVideoH264MemMgmtControlOp memory_management_control_operation;
    uint16_t difference_of_pic_nums_minus1;
    uint16_t long_term_pic_num;
    uint16_t long_term_frame_idx;
    uint16_t max_long_term_frame_idx_plus1;
} StdVideoEncodeH264RefPicMarkingEntry;

typedef struct StdVideoEncodeH264ReferenceListsInfo {
    StdVideoEncodeH264ReferenceListsInfoFlags flags;
    uint8_t num_ref_idx_l0_active_minus1;
    uint8_t num_ref_idx_l1_active_minus1;
    uint8_t RefPicList0[32];
    uint8_t RefPicList1[32];
    uint8_t refList0ModOpCount;
    uint8_t refList1ModOpCount;
    uint8_t refPicMarkingOpCount;
    uint8_t reserved1[7];
    const StdVideoEncodeH264RefListModEntry* pRefList0ModOperations;
    const StdVideoEncodeH264RefListModEntry* pRefList1ModOperations;
    const StdVideoEncodeH264RefPicMarkingEntry* pRefPicMarkingOperations;
} StdVideoEncodeH264ReferenceListsInfo;

typedef struct StdVideoEncodeH264PictureInfo {
    StdVideoEncodeH264PictureInfoFlags flags;
    uint8_t seq_parameter_set_id;
    uint8_t pic_parameter_set_id;
    uint16_t idr_pic_id;
    StdVideoH264PictureType primary_pic_type;
    uint32_t frame_num;
    int32_t PicOrderCnt;
    uint8_t temporal_id;
    uint8_t reserved1[3];
    const StdVideoEncodeH264ReferenceListsInfo* pRefLists;
} StdVideoEncodeH264PictureInfo;

typedef struct StdVideoEncodeH264ReferenceInfo {
    StdVideoEncodeH264ReferenceInfoFlags flags;
    StdVideoH264PictureType primary_pic_type;
    uint32_t FrameNum;
    int32_t PicOrderCnt;
    uint16_t long_term_pic_num;
    uint16_t long_term_frame_idx;
    uint8_t temporal_id;
} StdVideoEncodeH264ReferenceInfo;

typedef struct StdVideoEncodeH264SliceHeader {
    StdVideoEncodeH264SliceHeaderFlags flags;
    uint32_t first_mb_in_slice;
    StdVideoH264SliceType slice_type;
    int8_t slice_alpha_c0_offset_div2;
    int8_t slice_beta_offset_div2;
    int8_t slice_qp_delta;
    uint8_t reserved1;
    StdVideoH264CabacInitIdc cabac_init_idc;
    StdVideoH264DisableDeblockingFilterIdc disable_deblocking_filter_idc;
    const StdVideoEncodeH264WeightTable* pWeightTable;
} StdVideoEncodeH264SliceHeader;



}
# 9241 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 2 3 4



typedef enum VkVideoEncodeH264CapabilityFlagBitsKHR {
    VK_VIDEO_ENCODE_H264_CAPABILITY_HRD_COMPLIANCE_BIT_KHR = 0x00000001,
    VK_VIDEO_ENCODE_H264_CAPABILITY_PREDICTION_WEIGHT_TABLE_GENERATED_BIT_KHR = 0x00000002,
    VK_VIDEO_ENCODE_H264_CAPABILITY_ROW_UNALIGNED_SLICE_BIT_KHR = 0x00000004,
    VK_VIDEO_ENCODE_H264_CAPABILITY_DIFFERENT_SLICE_TYPE_BIT_KHR = 0x00000008,
    VK_VIDEO_ENCODE_H264_CAPABILITY_B_FRAME_IN_L0_LIST_BIT_KHR = 0x00000010,
    VK_VIDEO_ENCODE_H264_CAPABILITY_B_FRAME_IN_L1_LIST_BIT_KHR = 0x00000020,
    VK_VIDEO_ENCODE_H264_CAPABILITY_PER_PICTURE_TYPE_MIN_MAX_QP_BIT_KHR = 0x00000040,
    VK_VIDEO_ENCODE_H264_CAPABILITY_PER_SLICE_CONSTANT_QP_BIT_KHR = 0x00000080,
    VK_VIDEO_ENCODE_H264_CAPABILITY_GENERATE_PREFIX_NALU_BIT_KHR = 0x00000100,
    VK_VIDEO_ENCODE_H264_CAPABILITY_MB_QP_DIFF_WRAPAROUND_BIT_KHR = 0x00000200,
    VK_VIDEO_ENCODE_H264_CAPABILITY_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeH264CapabilityFlagBitsKHR;
typedef VkFlags VkVideoEncodeH264CapabilityFlagsKHR;

typedef enum VkVideoEncodeH264StdFlagBitsKHR {
    VK_VIDEO_ENCODE_H264_STD_SEPARATE_COLOR_PLANE_FLAG_SET_BIT_KHR = 0x00000001,
    VK_VIDEO_ENCODE_H264_STD_QPPRIME_Y_ZERO_TRANSFORM_BYPASS_FLAG_SET_BIT_KHR = 0x00000002,
    VK_VIDEO_ENCODE_H264_STD_SCALING_MATRIX_PRESENT_FLAG_SET_BIT_KHR = 0x00000004,
    VK_VIDEO_ENCODE_H264_STD_CHROMA_QP_INDEX_OFFSET_BIT_KHR = 0x00000008,
    VK_VIDEO_ENCODE_H264_STD_SECOND_CHROMA_QP_INDEX_OFFSET_BIT_KHR = 0x00000010,
    VK_VIDEO_ENCODE_H264_STD_PIC_INIT_QP_MINUS26_BIT_KHR = 0x00000020,
    VK_VIDEO_ENCODE_H264_STD_WEIGHTED_PRED_FLAG_SET_BIT_KHR = 0x00000040,
    VK_VIDEO_ENCODE_H264_STD_WEIGHTED_BIPRED_IDC_EXPLICIT_BIT_KHR = 0x00000080,
    VK_VIDEO_ENCODE_H264_STD_WEIGHTED_BIPRED_IDC_IMPLICIT_BIT_KHR = 0x00000100,
    VK_VIDEO_ENCODE_H264_STD_TRANSFORM_8X8_MODE_FLAG_SET_BIT_KHR = 0x00000200,
    VK_VIDEO_ENCODE_H264_STD_DIRECT_SPATIAL_MV_PRED_FLAG_UNSET_BIT_KHR = 0x00000400,
    VK_VIDEO_ENCODE_H264_STD_ENTROPY_CODING_MODE_FLAG_UNSET_BIT_KHR = 0x00000800,
    VK_VIDEO_ENCODE_H264_STD_ENTROPY_CODING_MODE_FLAG_SET_BIT_KHR = 0x00001000,
    VK_VIDEO_ENCODE_H264_STD_DIRECT_8X8_INFERENCE_FLAG_UNSET_BIT_KHR = 0x00002000,
    VK_VIDEO_ENCODE_H264_STD_CONSTRAINED_INTRA_PRED_FLAG_SET_BIT_KHR = 0x00004000,
    VK_VIDEO_ENCODE_H264_STD_DEBLOCKING_FILTER_DISABLED_BIT_KHR = 0x00008000,
    VK_VIDEO_ENCODE_H264_STD_DEBLOCKING_FILTER_ENABLED_BIT_KHR = 0x00010000,
    VK_VIDEO_ENCODE_H264_STD_DEBLOCKING_FILTER_PARTIAL_BIT_KHR = 0x00020000,
    VK_VIDEO_ENCODE_H264_STD_SLICE_QP_DELTA_BIT_KHR = 0x00080000,
    VK_VIDEO_ENCODE_H264_STD_DIFFERENT_SLICE_QP_DELTA_BIT_KHR = 0x00100000,
    VK_VIDEO_ENCODE_H264_STD_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeH264StdFlagBitsKHR;
typedef VkFlags VkVideoEncodeH264StdFlagsKHR;

typedef enum VkVideoEncodeH264RateControlFlagBitsKHR {
    VK_VIDEO_ENCODE_H264_RATE_CONTROL_ATTEMPT_HRD_COMPLIANCE_BIT_KHR = 0x00000001,
    VK_VIDEO_ENCODE_H264_RATE_CONTROL_REGULAR_GOP_BIT_KHR = 0x00000002,
    VK_VIDEO_ENCODE_H264_RATE_CONTROL_REFERENCE_PATTERN_FLAT_BIT_KHR = 0x00000004,
    VK_VIDEO_ENCODE_H264_RATE_CONTROL_REFERENCE_PATTERN_DYADIC_BIT_KHR = 0x00000008,
    VK_VIDEO_ENCODE_H264_RATE_CONTROL_TEMPORAL_LAYER_PATTERN_DYADIC_BIT_KHR = 0x00000010,
    VK_VIDEO_ENCODE_H264_RATE_CONTROL_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeH264RateControlFlagBitsKHR;
typedef VkFlags VkVideoEncodeH264RateControlFlagsKHR;
typedef struct VkVideoEncodeH264CapabilitiesKHR {
    VkStructureType sType;
    void* pNext;
    VkVideoEncodeH264CapabilityFlagsKHR flags;
    StdVideoH264LevelIdc maxLevelIdc;
    uint32_t maxSliceCount;
    uint32_t maxPPictureL0ReferenceCount;
    uint32_t maxBPictureL0ReferenceCount;
    uint32_t maxL1ReferenceCount;
    uint32_t maxTemporalLayerCount;
    VkBool32 expectDyadicTemporalLayerPattern;
    int32_t minQp;
    int32_t maxQp;
    VkBool32 prefersGopRemainingFrames;
    VkBool32 requiresGopRemainingFrames;
    VkVideoEncodeH264StdFlagsKHR stdSyntaxFlags;
} VkVideoEncodeH264CapabilitiesKHR;

typedef struct VkVideoEncodeH264QpKHR {
    int32_t qpI;
    int32_t qpP;
    int32_t qpB;
} VkVideoEncodeH264QpKHR;

typedef struct VkVideoEncodeH264QualityLevelPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkVideoEncodeH264RateControlFlagsKHR preferredRateControlFlags;
    uint32_t preferredGopFrameCount;
    uint32_t preferredIdrPeriod;
    uint32_t preferredConsecutiveBFrameCount;
    uint32_t preferredTemporalLayerCount;
    VkVideoEncodeH264QpKHR preferredConstantQp;
    uint32_t preferredMaxL0ReferenceCount;
    uint32_t preferredMaxL1ReferenceCount;
    VkBool32 preferredStdEntropyCodingModeFlag;
} VkVideoEncodeH264QualityLevelPropertiesKHR;

typedef struct VkVideoEncodeH264SessionCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkBool32 useMaxLevelIdc;
    StdVideoH264LevelIdc maxLevelIdc;
} VkVideoEncodeH264SessionCreateInfoKHR;

typedef struct VkVideoEncodeH264SessionParametersAddInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t stdSPSCount;
    const StdVideoH264SequenceParameterSet* pStdSPSs;
    uint32_t stdPPSCount;
    const StdVideoH264PictureParameterSet* pStdPPSs;
} VkVideoEncodeH264SessionParametersAddInfoKHR;

typedef struct VkVideoEncodeH264SessionParametersCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t maxStdSPSCount;
    uint32_t maxStdPPSCount;
    const VkVideoEncodeH264SessionParametersAddInfoKHR* pParametersAddInfo;
} VkVideoEncodeH264SessionParametersCreateInfoKHR;

typedef struct VkVideoEncodeH264SessionParametersGetInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkBool32 writeStdSPS;
    VkBool32 writeStdPPS;
    uint32_t stdSPSId;
    uint32_t stdPPSId;
} VkVideoEncodeH264SessionParametersGetInfoKHR;

typedef struct VkVideoEncodeH264SessionParametersFeedbackInfoKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 hasStdSPSOverrides;
    VkBool32 hasStdPPSOverrides;
} VkVideoEncodeH264SessionParametersFeedbackInfoKHR;

typedef struct VkVideoEncodeH264NaluSliceInfoKHR {
    VkStructureType sType;
    const void* pNext;
    int32_t constantQp;
    const StdVideoEncodeH264SliceHeader* pStdSliceHeader;
} VkVideoEncodeH264NaluSliceInfoKHR;

typedef struct VkVideoEncodeH264PictureInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t naluSliceEntryCount;
    const VkVideoEncodeH264NaluSliceInfoKHR* pNaluSliceEntries;
    const StdVideoEncodeH264PictureInfo* pStdPictureInfo;
    VkBool32 generatePrefixNalu;
} VkVideoEncodeH264PictureInfoKHR;

typedef struct VkVideoEncodeH264DpbSlotInfoKHR {
    VkStructureType sType;
    const void* pNext;
    const StdVideoEncodeH264ReferenceInfo* pStdReferenceInfo;
} VkVideoEncodeH264DpbSlotInfoKHR;

typedef struct VkVideoEncodeH264ProfileInfoKHR {
    VkStructureType sType;
    const void* pNext;
    StdVideoH264ProfileIdc stdProfileIdc;
} VkVideoEncodeH264ProfileInfoKHR;

typedef struct VkVideoEncodeH264RateControlInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkVideoEncodeH264RateControlFlagsKHR flags;
    uint32_t gopFrameCount;
    uint32_t idrPeriod;
    uint32_t consecutiveBFrameCount;
    uint32_t temporalLayerCount;
} VkVideoEncodeH264RateControlInfoKHR;

typedef struct VkVideoEncodeH264FrameSizeKHR {
    uint32_t frameISize;
    uint32_t framePSize;
    uint32_t frameBSize;
} VkVideoEncodeH264FrameSizeKHR;

typedef struct VkVideoEncodeH264RateControlLayerInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkBool32 useMinQp;
    VkVideoEncodeH264QpKHR minQp;
    VkBool32 useMaxQp;
    VkVideoEncodeH264QpKHR maxQp;
    VkBool32 useMaxFrameSize;
    VkVideoEncodeH264FrameSizeKHR maxFrameSize;
} VkVideoEncodeH264RateControlLayerInfoKHR;

typedef struct VkVideoEncodeH264GopRemainingFrameInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkBool32 useGopRemainingFrames;
    uint32_t gopRemainingI;
    uint32_t gopRemainingP;
    uint32_t gopRemainingB;
} VkVideoEncodeH264GopRemainingFrameInfoKHR;





# 1 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h265std.h" 1 3 4
# 17 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h265std.h" 3 4
extern "C" {
# 49 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h265std.h" 3 4
typedef enum StdVideoH265ChromaFormatIdc {
    STD_VIDEO_H265_CHROMA_FORMAT_IDC_MONOCHROME = 0,
    STD_VIDEO_H265_CHROMA_FORMAT_IDC_420 = 1,
    STD_VIDEO_H265_CHROMA_FORMAT_IDC_422 = 2,
    STD_VIDEO_H265_CHROMA_FORMAT_IDC_444 = 3,
    STD_VIDEO_H265_CHROMA_FORMAT_IDC_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H265_CHROMA_FORMAT_IDC_MAX_ENUM = 0x7FFFFFFF
} StdVideoH265ChromaFormatIdc;

typedef enum StdVideoH265ProfileIdc {
    STD_VIDEO_H265_PROFILE_IDC_MAIN = 1,
    STD_VIDEO_H265_PROFILE_IDC_MAIN_10 = 2,
    STD_VIDEO_H265_PROFILE_IDC_MAIN_STILL_PICTURE = 3,
    STD_VIDEO_H265_PROFILE_IDC_FORMAT_RANGE_EXTENSIONS = 4,
    STD_VIDEO_H265_PROFILE_IDC_SCC_EXTENSIONS = 9,
    STD_VIDEO_H265_PROFILE_IDC_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H265_PROFILE_IDC_MAX_ENUM = 0x7FFFFFFF
} StdVideoH265ProfileIdc;

typedef enum StdVideoH265LevelIdc {
    STD_VIDEO_H265_LEVEL_IDC_1_0 = 0,
    STD_VIDEO_H265_LEVEL_IDC_2_0 = 1,
    STD_VIDEO_H265_LEVEL_IDC_2_1 = 2,
    STD_VIDEO_H265_LEVEL_IDC_3_0 = 3,
    STD_VIDEO_H265_LEVEL_IDC_3_1 = 4,
    STD_VIDEO_H265_LEVEL_IDC_4_0 = 5,
    STD_VIDEO_H265_LEVEL_IDC_4_1 = 6,
    STD_VIDEO_H265_LEVEL_IDC_5_0 = 7,
    STD_VIDEO_H265_LEVEL_IDC_5_1 = 8,
    STD_VIDEO_H265_LEVEL_IDC_5_2 = 9,
    STD_VIDEO_H265_LEVEL_IDC_6_0 = 10,
    STD_VIDEO_H265_LEVEL_IDC_6_1 = 11,
    STD_VIDEO_H265_LEVEL_IDC_6_2 = 12,
    STD_VIDEO_H265_LEVEL_IDC_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H265_LEVEL_IDC_MAX_ENUM = 0x7FFFFFFF
} StdVideoH265LevelIdc;

typedef enum StdVideoH265SliceType {
    STD_VIDEO_H265_SLICE_TYPE_B = 0,
    STD_VIDEO_H265_SLICE_TYPE_P = 1,
    STD_VIDEO_H265_SLICE_TYPE_I = 2,
    STD_VIDEO_H265_SLICE_TYPE_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H265_SLICE_TYPE_MAX_ENUM = 0x7FFFFFFF
} StdVideoH265SliceType;

typedef enum StdVideoH265PictureType {
    STD_VIDEO_H265_PICTURE_TYPE_P = 0,
    STD_VIDEO_H265_PICTURE_TYPE_B = 1,
    STD_VIDEO_H265_PICTURE_TYPE_I = 2,
    STD_VIDEO_H265_PICTURE_TYPE_IDR = 3,
    STD_VIDEO_H265_PICTURE_TYPE_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H265_PICTURE_TYPE_MAX_ENUM = 0x7FFFFFFF
} StdVideoH265PictureType;

typedef enum StdVideoH265AspectRatioIdc {
    STD_VIDEO_H265_ASPECT_RATIO_IDC_UNSPECIFIED = 0,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_SQUARE = 1,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_12_11 = 2,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_10_11 = 3,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_16_11 = 4,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_40_33 = 5,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_24_11 = 6,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_20_11 = 7,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_32_11 = 8,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_80_33 = 9,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_18_11 = 10,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_15_11 = 11,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_64_33 = 12,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_160_99 = 13,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_4_3 = 14,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_3_2 = 15,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_2_1 = 16,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_EXTENDED_SAR = 255,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_INVALID = 0x7FFFFFFF,
    STD_VIDEO_H265_ASPECT_RATIO_IDC_MAX_ENUM = 0x7FFFFFFF
} StdVideoH265AspectRatioIdc;
typedef struct StdVideoH265DecPicBufMgr {
    uint32_t max_latency_increase_plus1[7];
    uint8_t max_dec_pic_buffering_minus1[7];
    uint8_t max_num_reorder_pics[7];
} StdVideoH265DecPicBufMgr;

typedef struct StdVideoH265SubLayerHrdParameters {
    uint32_t bit_rate_value_minus1[32];
    uint32_t cpb_size_value_minus1[32];
    uint32_t cpb_size_du_value_minus1[32];
    uint32_t bit_rate_du_value_minus1[32];
    uint32_t cbr_flag;
} StdVideoH265SubLayerHrdParameters;

typedef struct StdVideoH265HrdFlags {
    uint32_t nal_hrd_parameters_present_flag : 1;
    uint32_t vcl_hrd_parameters_present_flag : 1;
    uint32_t sub_pic_hrd_params_present_flag : 1;
    uint32_t sub_pic_cpb_params_in_pic_timing_sei_flag : 1;
    uint32_t fixed_pic_rate_general_flag : 8;
    uint32_t fixed_pic_rate_within_cvs_flag : 8;
    uint32_t low_delay_hrd_flag : 8;
} StdVideoH265HrdFlags;

typedef struct StdVideoH265HrdParameters {
    StdVideoH265HrdFlags flags;
    uint8_t tick_divisor_minus2;
    uint8_t du_cpb_removal_delay_increment_length_minus1;
    uint8_t dpb_output_delay_du_length_minus1;
    uint8_t bit_rate_scale;
    uint8_t cpb_size_scale;
    uint8_t cpb_size_du_scale;
    uint8_t initial_cpb_removal_delay_length_minus1;
    uint8_t au_cpb_removal_delay_length_minus1;
    uint8_t dpb_output_delay_length_minus1;
    uint8_t cpb_cnt_minus1[7];
    uint16_t elemental_duration_in_tc_minus1[7];
    uint16_t reserved[3];
    const StdVideoH265SubLayerHrdParameters* pSubLayerHrdParametersNal;
    const StdVideoH265SubLayerHrdParameters* pSubLayerHrdParametersVcl;
} StdVideoH265HrdParameters;

typedef struct StdVideoH265VpsFlags {
    uint32_t vps_temporal_id_nesting_flag : 1;
    uint32_t vps_sub_layer_ordering_info_present_flag : 1;
    uint32_t vps_timing_info_present_flag : 1;
    uint32_t vps_poc_proportional_to_timing_flag : 1;
} StdVideoH265VpsFlags;

typedef struct StdVideoH265ProfileTierLevelFlags {
    uint32_t general_tier_flag : 1;
    uint32_t general_progressive_source_flag : 1;
    uint32_t general_interlaced_source_flag : 1;
    uint32_t general_non_packed_constraint_flag : 1;
    uint32_t general_frame_only_constraint_flag : 1;
} StdVideoH265ProfileTierLevelFlags;

typedef struct StdVideoH265ProfileTierLevel {
    StdVideoH265ProfileTierLevelFlags flags;
    StdVideoH265ProfileIdc general_profile_idc;
    StdVideoH265LevelIdc general_level_idc;
} StdVideoH265ProfileTierLevel;

typedef struct StdVideoH265VideoParameterSet {
    StdVideoH265VpsFlags flags;
    uint8_t vps_video_parameter_set_id;
    uint8_t vps_max_sub_layers_minus1;
    uint8_t reserved1;
    uint8_t reserved2;
    uint32_t vps_num_units_in_tick;
    uint32_t vps_time_scale;
    uint32_t vps_num_ticks_poc_diff_one_minus1;
    uint32_t reserved3;
    const StdVideoH265DecPicBufMgr* pDecPicBufMgr;
    const StdVideoH265HrdParameters* pHrdParameters;
    const StdVideoH265ProfileTierLevel* pProfileTierLevel;
} StdVideoH265VideoParameterSet;

typedef struct StdVideoH265ScalingLists {
    uint8_t ScalingList4x4[6][16];
    uint8_t ScalingList8x8[6][64];
    uint8_t ScalingList16x16[6][64];
    uint8_t ScalingList32x32[2][64];
    uint8_t ScalingListDCCoef16x16[6];
    uint8_t ScalingListDCCoef32x32[2];
} StdVideoH265ScalingLists;

typedef struct StdVideoH265SpsVuiFlags {
    uint32_t aspect_ratio_info_present_flag : 1;
    uint32_t overscan_info_present_flag : 1;
    uint32_t overscan_appropriate_flag : 1;
    uint32_t video_signal_type_present_flag : 1;
    uint32_t video_full_range_flag : 1;
    uint32_t colour_description_present_flag : 1;
    uint32_t chroma_loc_info_present_flag : 1;
    uint32_t neutral_chroma_indication_flag : 1;
    uint32_t field_seq_flag : 1;
    uint32_t frame_field_info_present_flag : 1;
    uint32_t default_display_window_flag : 1;
    uint32_t vui_timing_info_present_flag : 1;
    uint32_t vui_poc_proportional_to_timing_flag : 1;
    uint32_t vui_hrd_parameters_present_flag : 1;
    uint32_t bitstream_restriction_flag : 1;
    uint32_t tiles_fixed_structure_flag : 1;
    uint32_t motion_vectors_over_pic_boundaries_flag : 1;
    uint32_t restricted_ref_pic_lists_flag : 1;
} StdVideoH265SpsVuiFlags;

typedef struct StdVideoH265SequenceParameterSetVui {
    StdVideoH265SpsVuiFlags flags;
    StdVideoH265AspectRatioIdc aspect_ratio_idc;
    uint16_t sar_width;
    uint16_t sar_height;
    uint8_t video_format;
    uint8_t colour_primaries;
    uint8_t transfer_characteristics;
    uint8_t matrix_coeffs;
    uint8_t chroma_sample_loc_type_top_field;
    uint8_t chroma_sample_loc_type_bottom_field;
    uint8_t reserved1;
    uint8_t reserved2;
    uint16_t def_disp_win_left_offset;
    uint16_t def_disp_win_right_offset;
    uint16_t def_disp_win_top_offset;
    uint16_t def_disp_win_bottom_offset;
    uint32_t vui_num_units_in_tick;
    uint32_t vui_time_scale;
    uint32_t vui_num_ticks_poc_diff_one_minus1;
    uint16_t min_spatial_segmentation_idc;
    uint16_t reserved3;
    uint8_t max_bytes_per_pic_denom;
    uint8_t max_bits_per_min_cu_denom;
    uint8_t log2_max_mv_length_horizontal;
    uint8_t log2_max_mv_length_vertical;
    const StdVideoH265HrdParameters* pHrdParameters;
} StdVideoH265SequenceParameterSetVui;

typedef struct StdVideoH265PredictorPaletteEntries {
    uint16_t PredictorPaletteEntries[3][128];
} StdVideoH265PredictorPaletteEntries;

typedef struct StdVideoH265SpsFlags {
    uint32_t sps_temporal_id_nesting_flag : 1;
    uint32_t separate_colour_plane_flag : 1;
    uint32_t conformance_window_flag : 1;
    uint32_t sps_sub_layer_ordering_info_present_flag : 1;
    uint32_t scaling_list_enabled_flag : 1;
    uint32_t sps_scaling_list_data_present_flag : 1;
    uint32_t amp_enabled_flag : 1;
    uint32_t sample_adaptive_offset_enabled_flag : 1;
    uint32_t pcm_enabled_flag : 1;
    uint32_t pcm_loop_filter_disabled_flag : 1;
    uint32_t long_term_ref_pics_present_flag : 1;
    uint32_t sps_temporal_mvp_enabled_flag : 1;
    uint32_t strong_intra_smoothing_enabled_flag : 1;
    uint32_t vui_parameters_present_flag : 1;
    uint32_t sps_extension_present_flag : 1;
    uint32_t sps_range_extension_flag : 1;
    uint32_t transform_skip_rotation_enabled_flag : 1;
    uint32_t transform_skip_context_enabled_flag : 1;
    uint32_t implicit_rdpcm_enabled_flag : 1;
    uint32_t explicit_rdpcm_enabled_flag : 1;
    uint32_t extended_precision_processing_flag : 1;
    uint32_t intra_smoothing_disabled_flag : 1;
    uint32_t high_precision_offsets_enabled_flag : 1;
    uint32_t persistent_rice_adaptation_enabled_flag : 1;
    uint32_t cabac_bypass_alignment_enabled_flag : 1;
    uint32_t sps_scc_extension_flag : 1;
    uint32_t sps_curr_pic_ref_enabled_flag : 1;
    uint32_t palette_mode_enabled_flag : 1;
    uint32_t sps_palette_predictor_initializers_present_flag : 1;
    uint32_t intra_boundary_filtering_disabled_flag : 1;
} StdVideoH265SpsFlags;

typedef struct StdVideoH265ShortTermRefPicSetFlags {
    uint32_t inter_ref_pic_set_prediction_flag : 1;
    uint32_t delta_rps_sign : 1;
} StdVideoH265ShortTermRefPicSetFlags;

typedef struct StdVideoH265ShortTermRefPicSet {
    StdVideoH265ShortTermRefPicSetFlags flags;
    uint32_t delta_idx_minus1;
    uint16_t use_delta_flag;
    uint16_t abs_delta_rps_minus1;
    uint16_t used_by_curr_pic_flag;
    uint16_t used_by_curr_pic_s0_flag;
    uint16_t used_by_curr_pic_s1_flag;
    uint16_t reserved1;
    uint8_t reserved2;
    uint8_t reserved3;
    uint8_t num_negative_pics;
    uint8_t num_positive_pics;
    uint16_t delta_poc_s0_minus1[16];
    uint16_t delta_poc_s1_minus1[16];
} StdVideoH265ShortTermRefPicSet;

typedef struct StdVideoH265LongTermRefPicsSps {
    uint32_t used_by_curr_pic_lt_sps_flag;
    uint32_t lt_ref_pic_poc_lsb_sps[32];
} StdVideoH265LongTermRefPicsSps;

typedef struct StdVideoH265SequenceParameterSet {
    StdVideoH265SpsFlags flags;
    StdVideoH265ChromaFormatIdc chroma_format_idc;
    uint32_t pic_width_in_luma_samples;
    uint32_t pic_height_in_luma_samples;
    uint8_t sps_video_parameter_set_id;
    uint8_t sps_max_sub_layers_minus1;
    uint8_t sps_seq_parameter_set_id;
    uint8_t bit_depth_luma_minus8;
    uint8_t bit_depth_chroma_minus8;
    uint8_t log2_max_pic_order_cnt_lsb_minus4;
    uint8_t log2_min_luma_coding_block_size_minus3;
    uint8_t log2_diff_max_min_luma_coding_block_size;
    uint8_t log2_min_luma_transform_block_size_minus2;
    uint8_t log2_diff_max_min_luma_transform_block_size;
    uint8_t max_transform_hierarchy_depth_inter;
    uint8_t max_transform_hierarchy_depth_intra;
    uint8_t num_short_term_ref_pic_sets;
    uint8_t num_long_term_ref_pics_sps;
    uint8_t pcm_sample_bit_depth_luma_minus1;
    uint8_t pcm_sample_bit_depth_chroma_minus1;
    uint8_t log2_min_pcm_luma_coding_block_size_minus3;
    uint8_t log2_diff_max_min_pcm_luma_coding_block_size;
    uint8_t reserved1;
    uint8_t reserved2;
    uint8_t palette_max_size;
    uint8_t delta_palette_max_predictor_size;
    uint8_t motion_vector_resolution_control_idc;
    uint8_t sps_num_palette_predictor_initializers_minus1;
    uint32_t conf_win_left_offset;
    uint32_t conf_win_right_offset;
    uint32_t conf_win_top_offset;
    uint32_t conf_win_bottom_offset;
    const StdVideoH265ProfileTierLevel* pProfileTierLevel;
    const StdVideoH265DecPicBufMgr* pDecPicBufMgr;
    const StdVideoH265ScalingLists* pScalingLists;
    const StdVideoH265ShortTermRefPicSet* pShortTermRefPicSet;
    const StdVideoH265LongTermRefPicsSps* pLongTermRefPicsSps;
    const StdVideoH265SequenceParameterSetVui* pSequenceParameterSetVui;
    const StdVideoH265PredictorPaletteEntries* pPredictorPaletteEntries;
} StdVideoH265SequenceParameterSet;

typedef struct StdVideoH265PpsFlags {
    uint32_t dependent_slice_segments_enabled_flag : 1;
    uint32_t output_flag_present_flag : 1;
    uint32_t sign_data_hiding_enabled_flag : 1;
    uint32_t cabac_init_present_flag : 1;
    uint32_t constrained_intra_pred_flag : 1;
    uint32_t transform_skip_enabled_flag : 1;
    uint32_t cu_qp_delta_enabled_flag : 1;
    uint32_t pps_slice_chroma_qp_offsets_present_flag : 1;
    uint32_t weighted_pred_flag : 1;
    uint32_t weighted_bipred_flag : 1;
    uint32_t transquant_bypass_enabled_flag : 1;
    uint32_t tiles_enabled_flag : 1;
    uint32_t entropy_coding_sync_enabled_flag : 1;
    uint32_t uniform_spacing_flag : 1;
    uint32_t loop_filter_across_tiles_enabled_flag : 1;
    uint32_t pps_loop_filter_across_slices_enabled_flag : 1;
    uint32_t deblocking_filter_control_present_flag : 1;
    uint32_t deblocking_filter_override_enabled_flag : 1;
    uint32_t pps_deblocking_filter_disabled_flag : 1;
    uint32_t pps_scaling_list_data_present_flag : 1;
    uint32_t lists_modification_present_flag : 1;
    uint32_t slice_segment_header_extension_present_flag : 1;
    uint32_t pps_extension_present_flag : 1;
    uint32_t cross_component_prediction_enabled_flag : 1;
    uint32_t chroma_qp_offset_list_enabled_flag : 1;
    uint32_t pps_curr_pic_ref_enabled_flag : 1;
    uint32_t residual_adaptive_colour_transform_enabled_flag : 1;
    uint32_t pps_slice_act_qp_offsets_present_flag : 1;
    uint32_t pps_palette_predictor_initializers_present_flag : 1;
    uint32_t monochrome_palette_flag : 1;
    uint32_t pps_range_extension_flag : 1;
} StdVideoH265PpsFlags;

typedef struct StdVideoH265PictureParameterSet {
    StdVideoH265PpsFlags flags;
    uint8_t pps_pic_parameter_set_id;
    uint8_t pps_seq_parameter_set_id;
    uint8_t sps_video_parameter_set_id;
    uint8_t num_extra_slice_header_bits;
    uint8_t num_ref_idx_l0_default_active_minus1;
    uint8_t num_ref_idx_l1_default_active_minus1;
    int8_t init_qp_minus26;
    uint8_t diff_cu_qp_delta_depth;
    int8_t pps_cb_qp_offset;
    int8_t pps_cr_qp_offset;
    int8_t pps_beta_offset_div2;
    int8_t pps_tc_offset_div2;
    uint8_t log2_parallel_merge_level_minus2;
    uint8_t log2_max_transform_skip_block_size_minus2;
    uint8_t diff_cu_chroma_qp_offset_depth;
    uint8_t chroma_qp_offset_list_len_minus1;
    int8_t cb_qp_offset_list[6];
    int8_t cr_qp_offset_list[6];
    uint8_t log2_sao_offset_scale_luma;
    uint8_t log2_sao_offset_scale_chroma;
    int8_t pps_act_y_qp_offset_plus5;
    int8_t pps_act_cb_qp_offset_plus5;
    int8_t pps_act_cr_qp_offset_plus3;
    uint8_t pps_num_palette_predictor_initializers;
    uint8_t luma_bit_depth_entry_minus8;
    uint8_t chroma_bit_depth_entry_minus8;
    uint8_t num_tile_columns_minus1;
    uint8_t num_tile_rows_minus1;
    uint8_t reserved1;
    uint8_t reserved2;
    uint16_t column_width_minus1[19];
    uint16_t row_height_minus1[21];
    uint32_t reserved3;
    const StdVideoH265ScalingLists* pScalingLists;
    const StdVideoH265PredictorPaletteEntries* pPredictorPaletteEntries;
} StdVideoH265PictureParameterSet;



}
# 9440 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 2 3 4
# 1 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h265std_encode.h" 1 3 4
# 17 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h265std_encode.h" 3 4
extern "C" {






# 1 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h265std.h" 1 3 4
# 25 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h265std_encode.h" 2 3 4





typedef struct StdVideoEncodeH265WeightTableFlags {
    uint16_t luma_weight_l0_flag;
    uint16_t chroma_weight_l0_flag;
    uint16_t luma_weight_l1_flag;
    uint16_t chroma_weight_l1_flag;
} StdVideoEncodeH265WeightTableFlags;

typedef struct StdVideoEncodeH265WeightTable {
    StdVideoEncodeH265WeightTableFlags flags;
    uint8_t luma_log2_weight_denom;
    int8_t delta_chroma_log2_weight_denom;
    int8_t delta_luma_weight_l0[15];
    int8_t luma_offset_l0[15];
    int8_t delta_chroma_weight_l0[15][2];
    int8_t delta_chroma_offset_l0[15][2];
    int8_t delta_luma_weight_l1[15];
    int8_t luma_offset_l1[15];
    int8_t delta_chroma_weight_l1[15][2];
    int8_t delta_chroma_offset_l1[15][2];
} StdVideoEncodeH265WeightTable;

typedef struct StdVideoEncodeH265SliceSegmentHeaderFlags {
    uint32_t first_slice_segment_in_pic_flag : 1;
    uint32_t dependent_slice_segment_flag : 1;
    uint32_t slice_sao_luma_flag : 1;
    uint32_t slice_sao_chroma_flag : 1;
    uint32_t num_ref_idx_active_override_flag : 1;
    uint32_t mvd_l1_zero_flag : 1;
    uint32_t cabac_init_flag : 1;
    uint32_t cu_chroma_qp_offset_enabled_flag : 1;
    uint32_t deblocking_filter_override_flag : 1;
    uint32_t slice_deblocking_filter_disabled_flag : 1;
    uint32_t collocated_from_l0_flag : 1;
    uint32_t slice_loop_filter_across_slices_enabled_flag : 1;
    uint32_t reserved : 20;
} StdVideoEncodeH265SliceSegmentHeaderFlags;

typedef struct StdVideoEncodeH265SliceSegmentHeader {
    StdVideoEncodeH265SliceSegmentHeaderFlags flags;
    StdVideoH265SliceType slice_type;
    uint32_t slice_segment_address;
    uint8_t collocated_ref_idx;
    uint8_t MaxNumMergeCand;
    int8_t slice_cb_qp_offset;
    int8_t slice_cr_qp_offset;
    int8_t slice_beta_offset_div2;
    int8_t slice_tc_offset_div2;
    int8_t slice_act_y_qp_offset;
    int8_t slice_act_cb_qp_offset;
    int8_t slice_act_cr_qp_offset;
    int8_t slice_qp_delta;
    uint16_t reserved1;
    const StdVideoEncodeH265WeightTable* pWeightTable;
} StdVideoEncodeH265SliceSegmentHeader;

typedef struct StdVideoEncodeH265ReferenceListsInfoFlags {
    uint32_t ref_pic_list_modification_flag_l0 : 1;
    uint32_t ref_pic_list_modification_flag_l1 : 1;
    uint32_t reserved : 30;
} StdVideoEncodeH265ReferenceListsInfoFlags;

typedef struct StdVideoEncodeH265ReferenceListsInfo {
    StdVideoEncodeH265ReferenceListsInfoFlags flags;
    uint8_t num_ref_idx_l0_active_minus1;
    uint8_t num_ref_idx_l1_active_minus1;
    uint8_t RefPicList0[15];
    uint8_t RefPicList1[15];
    uint8_t list_entry_l0[15];
    uint8_t list_entry_l1[15];
} StdVideoEncodeH265ReferenceListsInfo;

typedef struct StdVideoEncodeH265PictureInfoFlags {
    uint32_t is_reference : 1;
    uint32_t IrapPicFlag : 1;
    uint32_t used_for_long_term_reference : 1;
    uint32_t discardable_flag : 1;
    uint32_t cross_layer_bla_flag : 1;
    uint32_t pic_output_flag : 1;
    uint32_t no_output_of_prior_pics_flag : 1;
    uint32_t short_term_ref_pic_set_sps_flag : 1;
    uint32_t slice_temporal_mvp_enabled_flag : 1;
    uint32_t reserved : 23;
} StdVideoEncodeH265PictureInfoFlags;

typedef struct StdVideoEncodeH265LongTermRefPics {
    uint8_t num_long_term_sps;
    uint8_t num_long_term_pics;
    uint8_t lt_idx_sps[32];
    uint8_t poc_lsb_lt[16];
    uint16_t used_by_curr_pic_lt_flag;
    uint8_t delta_poc_msb_present_flag[48];
    uint8_t delta_poc_msb_cycle_lt[48];
} StdVideoEncodeH265LongTermRefPics;

typedef struct StdVideoEncodeH265PictureInfo {
    StdVideoEncodeH265PictureInfoFlags flags;
    StdVideoH265PictureType pic_type;
    uint8_t sps_video_parameter_set_id;
    uint8_t pps_seq_parameter_set_id;
    uint8_t pps_pic_parameter_set_id;
    uint8_t short_term_ref_pic_set_idx;
    int32_t PicOrderCntVal;
    uint8_t TemporalId;
    uint8_t reserved1[7];
    const StdVideoEncodeH265ReferenceListsInfo* pRefLists;
    const StdVideoH265ShortTermRefPicSet* pShortTermRefPicSet;
    const StdVideoEncodeH265LongTermRefPics* pLongTermRefPics;
} StdVideoEncodeH265PictureInfo;

typedef struct StdVideoEncodeH265ReferenceInfoFlags {
    uint32_t used_for_long_term_reference : 1;
    uint32_t unused_for_reference : 1;
    uint32_t reserved : 30;
} StdVideoEncodeH265ReferenceInfoFlags;

typedef struct StdVideoEncodeH265ReferenceInfo {
    StdVideoEncodeH265ReferenceInfoFlags flags;
    StdVideoH265PictureType pic_type;
    int32_t PicOrderCntVal;
    uint8_t TemporalId;
} StdVideoEncodeH265ReferenceInfo;



}
# 9441 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 2 3 4



typedef enum VkVideoEncodeH265CapabilityFlagBitsKHR {
    VK_VIDEO_ENCODE_H265_CAPABILITY_HRD_COMPLIANCE_BIT_KHR = 0x00000001,
    VK_VIDEO_ENCODE_H265_CAPABILITY_PREDICTION_WEIGHT_TABLE_GENERATED_BIT_KHR = 0x00000002,
    VK_VIDEO_ENCODE_H265_CAPABILITY_ROW_UNALIGNED_SLICE_SEGMENT_BIT_KHR = 0x00000004,
    VK_VIDEO_ENCODE_H265_CAPABILITY_DIFFERENT_SLICE_SEGMENT_TYPE_BIT_KHR = 0x00000008,
    VK_VIDEO_ENCODE_H265_CAPABILITY_B_FRAME_IN_L0_LIST_BIT_KHR = 0x00000010,
    VK_VIDEO_ENCODE_H265_CAPABILITY_B_FRAME_IN_L1_LIST_BIT_KHR = 0x00000020,
    VK_VIDEO_ENCODE_H265_CAPABILITY_PER_PICTURE_TYPE_MIN_MAX_QP_BIT_KHR = 0x00000040,
    VK_VIDEO_ENCODE_H265_CAPABILITY_PER_SLICE_SEGMENT_CONSTANT_QP_BIT_KHR = 0x00000080,
    VK_VIDEO_ENCODE_H265_CAPABILITY_MULTIPLE_TILES_PER_SLICE_SEGMENT_BIT_KHR = 0x00000100,
    VK_VIDEO_ENCODE_H265_CAPABILITY_MULTIPLE_SLICE_SEGMENTS_PER_TILE_BIT_KHR = 0x00000200,
    VK_VIDEO_ENCODE_H265_CAPABILITY_CU_QP_DIFF_WRAPAROUND_BIT_KHR = 0x00000400,
    VK_VIDEO_ENCODE_H265_CAPABILITY_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeH265CapabilityFlagBitsKHR;
typedef VkFlags VkVideoEncodeH265CapabilityFlagsKHR;

typedef enum VkVideoEncodeH265StdFlagBitsKHR {
    VK_VIDEO_ENCODE_H265_STD_SEPARATE_COLOR_PLANE_FLAG_SET_BIT_KHR = 0x00000001,
    VK_VIDEO_ENCODE_H265_STD_SAMPLE_ADAPTIVE_OFFSET_ENABLED_FLAG_SET_BIT_KHR = 0x00000002,
    VK_VIDEO_ENCODE_H265_STD_SCALING_LIST_DATA_PRESENT_FLAG_SET_BIT_KHR = 0x00000004,
    VK_VIDEO_ENCODE_H265_STD_PCM_ENABLED_FLAG_SET_BIT_KHR = 0x00000008,
    VK_VIDEO_ENCODE_H265_STD_SPS_TEMPORAL_MVP_ENABLED_FLAG_SET_BIT_KHR = 0x00000010,
    VK_VIDEO_ENCODE_H265_STD_INIT_QP_MINUS26_BIT_KHR = 0x00000020,
    VK_VIDEO_ENCODE_H265_STD_WEIGHTED_PRED_FLAG_SET_BIT_KHR = 0x00000040,
    VK_VIDEO_ENCODE_H265_STD_WEIGHTED_BIPRED_FLAG_SET_BIT_KHR = 0x00000080,
    VK_VIDEO_ENCODE_H265_STD_LOG2_PARALLEL_MERGE_LEVEL_MINUS2_BIT_KHR = 0x00000100,
    VK_VIDEO_ENCODE_H265_STD_SIGN_DATA_HIDING_ENABLED_FLAG_SET_BIT_KHR = 0x00000200,
    VK_VIDEO_ENCODE_H265_STD_TRANSFORM_SKIP_ENABLED_FLAG_SET_BIT_KHR = 0x00000400,
    VK_VIDEO_ENCODE_H265_STD_TRANSFORM_SKIP_ENABLED_FLAG_UNSET_BIT_KHR = 0x00000800,
    VK_VIDEO_ENCODE_H265_STD_PPS_SLICE_CHROMA_QP_OFFSETS_PRESENT_FLAG_SET_BIT_KHR = 0x00001000,
    VK_VIDEO_ENCODE_H265_STD_TRANSQUANT_BYPASS_ENABLED_FLAG_SET_BIT_KHR = 0x00002000,
    VK_VIDEO_ENCODE_H265_STD_CONSTRAINED_INTRA_PRED_FLAG_SET_BIT_KHR = 0x00004000,
    VK_VIDEO_ENCODE_H265_STD_ENTROPY_CODING_SYNC_ENABLED_FLAG_SET_BIT_KHR = 0x00008000,
    VK_VIDEO_ENCODE_H265_STD_DEBLOCKING_FILTER_OVERRIDE_ENABLED_FLAG_SET_BIT_KHR = 0x00010000,
    VK_VIDEO_ENCODE_H265_STD_DEPENDENT_SLICE_SEGMENTS_ENABLED_FLAG_SET_BIT_KHR = 0x00020000,
    VK_VIDEO_ENCODE_H265_STD_DEPENDENT_SLICE_SEGMENT_FLAG_SET_BIT_KHR = 0x00040000,
    VK_VIDEO_ENCODE_H265_STD_SLICE_QP_DELTA_BIT_KHR = 0x00080000,
    VK_VIDEO_ENCODE_H265_STD_DIFFERENT_SLICE_QP_DELTA_BIT_KHR = 0x00100000,
    VK_VIDEO_ENCODE_H265_STD_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeH265StdFlagBitsKHR;
typedef VkFlags VkVideoEncodeH265StdFlagsKHR;

typedef enum VkVideoEncodeH265CtbSizeFlagBitsKHR {
    VK_VIDEO_ENCODE_H265_CTB_SIZE_16_BIT_KHR = 0x00000001,
    VK_VIDEO_ENCODE_H265_CTB_SIZE_32_BIT_KHR = 0x00000002,
    VK_VIDEO_ENCODE_H265_CTB_SIZE_64_BIT_KHR = 0x00000004,
    VK_VIDEO_ENCODE_H265_CTB_SIZE_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeH265CtbSizeFlagBitsKHR;
typedef VkFlags VkVideoEncodeH265CtbSizeFlagsKHR;

typedef enum VkVideoEncodeH265TransformBlockSizeFlagBitsKHR {
    VK_VIDEO_ENCODE_H265_TRANSFORM_BLOCK_SIZE_4_BIT_KHR = 0x00000001,
    VK_VIDEO_ENCODE_H265_TRANSFORM_BLOCK_SIZE_8_BIT_KHR = 0x00000002,
    VK_VIDEO_ENCODE_H265_TRANSFORM_BLOCK_SIZE_16_BIT_KHR = 0x00000004,
    VK_VIDEO_ENCODE_H265_TRANSFORM_BLOCK_SIZE_32_BIT_KHR = 0x00000008,
    VK_VIDEO_ENCODE_H265_TRANSFORM_BLOCK_SIZE_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeH265TransformBlockSizeFlagBitsKHR;
typedef VkFlags VkVideoEncodeH265TransformBlockSizeFlagsKHR;

typedef enum VkVideoEncodeH265RateControlFlagBitsKHR {
    VK_VIDEO_ENCODE_H265_RATE_CONTROL_ATTEMPT_HRD_COMPLIANCE_BIT_KHR = 0x00000001,
    VK_VIDEO_ENCODE_H265_RATE_CONTROL_REGULAR_GOP_BIT_KHR = 0x00000002,
    VK_VIDEO_ENCODE_H265_RATE_CONTROL_REFERENCE_PATTERN_FLAT_BIT_KHR = 0x00000004,
    VK_VIDEO_ENCODE_H265_RATE_CONTROL_REFERENCE_PATTERN_DYADIC_BIT_KHR = 0x00000008,
    VK_VIDEO_ENCODE_H265_RATE_CONTROL_TEMPORAL_SUB_LAYER_PATTERN_DYADIC_BIT_KHR = 0x00000010,
    VK_VIDEO_ENCODE_H265_RATE_CONTROL_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeH265RateControlFlagBitsKHR;
typedef VkFlags VkVideoEncodeH265RateControlFlagsKHR;
typedef struct VkVideoEncodeH265CapabilitiesKHR {
    VkStructureType sType;
    void* pNext;
    VkVideoEncodeH265CapabilityFlagsKHR flags;
    StdVideoH265LevelIdc maxLevelIdc;
    uint32_t maxSliceSegmentCount;
    VkExtent2D maxTiles;
    VkVideoEncodeH265CtbSizeFlagsKHR ctbSizes;
    VkVideoEncodeH265TransformBlockSizeFlagsKHR transformBlockSizes;
    uint32_t maxPPictureL0ReferenceCount;
    uint32_t maxBPictureL0ReferenceCount;
    uint32_t maxL1ReferenceCount;
    uint32_t maxSubLayerCount;
    VkBool32 expectDyadicTemporalSubLayerPattern;
    int32_t minQp;
    int32_t maxQp;
    VkBool32 prefersGopRemainingFrames;
    VkBool32 requiresGopRemainingFrames;
    VkVideoEncodeH265StdFlagsKHR stdSyntaxFlags;
} VkVideoEncodeH265CapabilitiesKHR;

typedef struct VkVideoEncodeH265SessionCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkBool32 useMaxLevelIdc;
    StdVideoH265LevelIdc maxLevelIdc;
} VkVideoEncodeH265SessionCreateInfoKHR;

typedef struct VkVideoEncodeH265QpKHR {
    int32_t qpI;
    int32_t qpP;
    int32_t qpB;
} VkVideoEncodeH265QpKHR;

typedef struct VkVideoEncodeH265QualityLevelPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkVideoEncodeH265RateControlFlagsKHR preferredRateControlFlags;
    uint32_t preferredGopFrameCount;
    uint32_t preferredIdrPeriod;
    uint32_t preferredConsecutiveBFrameCount;
    uint32_t preferredSubLayerCount;
    VkVideoEncodeH265QpKHR preferredConstantQp;
    uint32_t preferredMaxL0ReferenceCount;
    uint32_t preferredMaxL1ReferenceCount;
} VkVideoEncodeH265QualityLevelPropertiesKHR;

typedef struct VkVideoEncodeH265SessionParametersAddInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t stdVPSCount;
    const StdVideoH265VideoParameterSet* pStdVPSs;
    uint32_t stdSPSCount;
    const StdVideoH265SequenceParameterSet* pStdSPSs;
    uint32_t stdPPSCount;
    const StdVideoH265PictureParameterSet* pStdPPSs;
} VkVideoEncodeH265SessionParametersAddInfoKHR;

typedef struct VkVideoEncodeH265SessionParametersCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t maxStdVPSCount;
    uint32_t maxStdSPSCount;
    uint32_t maxStdPPSCount;
    const VkVideoEncodeH265SessionParametersAddInfoKHR* pParametersAddInfo;
} VkVideoEncodeH265SessionParametersCreateInfoKHR;

typedef struct VkVideoEncodeH265SessionParametersGetInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkBool32 writeStdVPS;
    VkBool32 writeStdSPS;
    VkBool32 writeStdPPS;
    uint32_t stdVPSId;
    uint32_t stdSPSId;
    uint32_t stdPPSId;
} VkVideoEncodeH265SessionParametersGetInfoKHR;

typedef struct VkVideoEncodeH265SessionParametersFeedbackInfoKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 hasStdVPSOverrides;
    VkBool32 hasStdSPSOverrides;
    VkBool32 hasStdPPSOverrides;
} VkVideoEncodeH265SessionParametersFeedbackInfoKHR;

typedef struct VkVideoEncodeH265NaluSliceSegmentInfoKHR {
    VkStructureType sType;
    const void* pNext;
    int32_t constantQp;
    const StdVideoEncodeH265SliceSegmentHeader* pStdSliceSegmentHeader;
} VkVideoEncodeH265NaluSliceSegmentInfoKHR;

typedef struct VkVideoEncodeH265PictureInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t naluSliceSegmentEntryCount;
    const VkVideoEncodeH265NaluSliceSegmentInfoKHR* pNaluSliceSegmentEntries;
    const StdVideoEncodeH265PictureInfo* pStdPictureInfo;
} VkVideoEncodeH265PictureInfoKHR;

typedef struct VkVideoEncodeH265DpbSlotInfoKHR {
    VkStructureType sType;
    const void* pNext;
    const StdVideoEncodeH265ReferenceInfo* pStdReferenceInfo;
} VkVideoEncodeH265DpbSlotInfoKHR;

typedef struct VkVideoEncodeH265ProfileInfoKHR {
    VkStructureType sType;
    const void* pNext;
    StdVideoH265ProfileIdc stdProfileIdc;
} VkVideoEncodeH265ProfileInfoKHR;

typedef struct VkVideoEncodeH265RateControlInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkVideoEncodeH265RateControlFlagsKHR flags;
    uint32_t gopFrameCount;
    uint32_t idrPeriod;
    uint32_t consecutiveBFrameCount;
    uint32_t subLayerCount;
} VkVideoEncodeH265RateControlInfoKHR;

typedef struct VkVideoEncodeH265FrameSizeKHR {
    uint32_t frameISize;
    uint32_t framePSize;
    uint32_t frameBSize;
} VkVideoEncodeH265FrameSizeKHR;

typedef struct VkVideoEncodeH265RateControlLayerInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkBool32 useMinQp;
    VkVideoEncodeH265QpKHR minQp;
    VkBool32 useMaxQp;
    VkVideoEncodeH265QpKHR maxQp;
    VkBool32 useMaxFrameSize;
    VkVideoEncodeH265FrameSizeKHR maxFrameSize;
} VkVideoEncodeH265RateControlLayerInfoKHR;

typedef struct VkVideoEncodeH265GopRemainingFrameInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkBool32 useGopRemainingFrames;
    uint32_t gopRemainingI;
    uint32_t gopRemainingP;
    uint32_t gopRemainingB;
} VkVideoEncodeH265GopRemainingFrameInfoKHR;





# 1 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h264std_decode.h" 1 3 4
# 17 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h264std_decode.h" 3 4
extern "C" {
# 32 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h264std_decode.h" 3 4
typedef enum StdVideoDecodeH264FieldOrderCount {
    STD_VIDEO_DECODE_H264_FIELD_ORDER_COUNT_TOP = 0,
    STD_VIDEO_DECODE_H264_FIELD_ORDER_COUNT_BOTTOM = 1,
    STD_VIDEO_DECODE_H264_FIELD_ORDER_COUNT_INVALID = 0x7FFFFFFF,
    STD_VIDEO_DECODE_H264_FIELD_ORDER_COUNT_MAX_ENUM = 0x7FFFFFFF
} StdVideoDecodeH264FieldOrderCount;
typedef struct StdVideoDecodeH264PictureInfoFlags {
    uint32_t field_pic_flag : 1;
    uint32_t is_intra : 1;
    uint32_t IdrPicFlag : 1;
    uint32_t bottom_field_flag : 1;
    uint32_t is_reference : 1;
    uint32_t complementary_field_pair : 1;
} StdVideoDecodeH264PictureInfoFlags;

typedef struct StdVideoDecodeH264PictureInfo {
    StdVideoDecodeH264PictureInfoFlags flags;
    uint8_t seq_parameter_set_id;
    uint8_t pic_parameter_set_id;
    uint8_t reserved1;
    uint8_t reserved2;
    uint16_t frame_num;
    uint16_t idr_pic_id;
    int32_t PicOrderCnt[2];
} StdVideoDecodeH264PictureInfo;

typedef struct StdVideoDecodeH264ReferenceInfoFlags {
    uint32_t top_field_flag : 1;
    uint32_t bottom_field_flag : 1;
    uint32_t used_for_long_term_reference : 1;
    uint32_t is_non_existing : 1;
} StdVideoDecodeH264ReferenceInfoFlags;

typedef struct StdVideoDecodeH264ReferenceInfo {
    StdVideoDecodeH264ReferenceInfoFlags flags;
    uint16_t FrameNum;
    uint16_t reserved;
    int32_t PicOrderCnt[2];
} StdVideoDecodeH264ReferenceInfo;



}
# 9666 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 2 3 4



typedef enum VkVideoDecodeH264PictureLayoutFlagBitsKHR {
    VK_VIDEO_DECODE_H264_PICTURE_LAYOUT_PROGRESSIVE_KHR = 0,
    VK_VIDEO_DECODE_H264_PICTURE_LAYOUT_INTERLACED_INTERLEAVED_LINES_BIT_KHR = 0x00000001,
    VK_VIDEO_DECODE_H264_PICTURE_LAYOUT_INTERLACED_SEPARATE_PLANES_BIT_KHR = 0x00000002,
    VK_VIDEO_DECODE_H264_PICTURE_LAYOUT_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoDecodeH264PictureLayoutFlagBitsKHR;
typedef VkFlags VkVideoDecodeH264PictureLayoutFlagsKHR;
typedef struct VkVideoDecodeH264ProfileInfoKHR {
    VkStructureType sType;
    const void* pNext;
    StdVideoH264ProfileIdc stdProfileIdc;
    VkVideoDecodeH264PictureLayoutFlagBitsKHR pictureLayout;
} VkVideoDecodeH264ProfileInfoKHR;

typedef struct VkVideoDecodeH264CapabilitiesKHR {
    VkStructureType sType;
    void* pNext;
    StdVideoH264LevelIdc maxLevelIdc;
    VkOffset2D fieldOffsetGranularity;
} VkVideoDecodeH264CapabilitiesKHR;

typedef struct VkVideoDecodeH264SessionParametersAddInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t stdSPSCount;
    const StdVideoH264SequenceParameterSet* pStdSPSs;
    uint32_t stdPPSCount;
    const StdVideoH264PictureParameterSet* pStdPPSs;
} VkVideoDecodeH264SessionParametersAddInfoKHR;

typedef struct VkVideoDecodeH264SessionParametersCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t maxStdSPSCount;
    uint32_t maxStdPPSCount;
    const VkVideoDecodeH264SessionParametersAddInfoKHR* pParametersAddInfo;
} VkVideoDecodeH264SessionParametersCreateInfoKHR;

typedef struct VkVideoDecodeH264PictureInfoKHR {
    VkStructureType sType;
    const void* pNext;
    const StdVideoDecodeH264PictureInfo* pStdPictureInfo;
    uint32_t sliceCount;
    const uint32_t* pSliceOffsets;
} VkVideoDecodeH264PictureInfoKHR;

typedef struct VkVideoDecodeH264DpbSlotInfoKHR {
    VkStructureType sType;
    const void* pNext;
    const StdVideoDecodeH264ReferenceInfo* pStdReferenceInfo;
} VkVideoDecodeH264DpbSlotInfoKHR;







typedef VkRenderingFlags VkRenderingFlagsKHR;

typedef VkRenderingFlagBits VkRenderingFlagBitsKHR;

typedef VkRenderingInfo VkRenderingInfoKHR;

typedef VkRenderingAttachmentInfo VkRenderingAttachmentInfoKHR;

typedef VkPipelineRenderingCreateInfo VkPipelineRenderingCreateInfoKHR;

typedef VkPhysicalDeviceDynamicRenderingFeatures VkPhysicalDeviceDynamicRenderingFeaturesKHR;

typedef VkCommandBufferInheritanceRenderingInfo VkCommandBufferInheritanceRenderingInfoKHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBeginRenderingKHR)(VkCommandBuffer commandBuffer, const VkRenderingInfo* pRenderingInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdEndRenderingKHR)(VkCommandBuffer commandBuffer);


 void __attribute__((__stdcall__)) vkCmdBeginRenderingKHR(
    VkCommandBuffer commandBuffer,
    const VkRenderingInfo* pRenderingInfo);

 void __attribute__((__stdcall__)) vkCmdEndRenderingKHR(
    VkCommandBuffer commandBuffer);







typedef VkRenderPassMultiviewCreateInfo VkRenderPassMultiviewCreateInfoKHR;

typedef VkPhysicalDeviceMultiviewFeatures VkPhysicalDeviceMultiviewFeaturesKHR;

typedef VkPhysicalDeviceMultiviewProperties VkPhysicalDeviceMultiviewPropertiesKHR;







typedef VkPhysicalDeviceFeatures2 VkPhysicalDeviceFeatures2KHR;

typedef VkPhysicalDeviceProperties2 VkPhysicalDeviceProperties2KHR;

typedef VkFormatProperties2 VkFormatProperties2KHR;

typedef VkImageFormatProperties2 VkImageFormatProperties2KHR;

typedef VkPhysicalDeviceImageFormatInfo2 VkPhysicalDeviceImageFormatInfo2KHR;

typedef VkQueueFamilyProperties2 VkQueueFamilyProperties2KHR;

typedef VkPhysicalDeviceMemoryProperties2 VkPhysicalDeviceMemoryProperties2KHR;

typedef VkSparseImageFormatProperties2 VkSparseImageFormatProperties2KHR;

typedef VkPhysicalDeviceSparseImageFormatInfo2 VkPhysicalDeviceSparseImageFormatInfo2KHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceFeatures2KHR)(VkPhysicalDevice physicalDevice, VkPhysicalDeviceFeatures2* pFeatures);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceProperties2KHR)(VkPhysicalDevice physicalDevice, VkPhysicalDeviceProperties2* pProperties);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceFormatProperties2KHR)(VkPhysicalDevice physicalDevice, VkFormat format, VkFormatProperties2* pFormatProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceImageFormatProperties2KHR)(VkPhysicalDevice physicalDevice, const VkPhysicalDeviceImageFormatInfo2* pImageFormatInfo, VkImageFormatProperties2* pImageFormatProperties);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceQueueFamilyProperties2KHR)(VkPhysicalDevice physicalDevice, uint32_t* pQueueFamilyPropertyCount, VkQueueFamilyProperties2* pQueueFamilyProperties);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceMemoryProperties2KHR)(VkPhysicalDevice physicalDevice, VkPhysicalDeviceMemoryProperties2* pMemoryProperties);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceSparseImageFormatProperties2KHR)(VkPhysicalDevice physicalDevice, const VkPhysicalDeviceSparseImageFormatInfo2* pFormatInfo, uint32_t* pPropertyCount, VkSparseImageFormatProperties2* pProperties);


 void __attribute__((__stdcall__)) vkGetPhysicalDeviceFeatures2KHR(
    VkPhysicalDevice physicalDevice,
    VkPhysicalDeviceFeatures2* pFeatures);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceProperties2KHR(
    VkPhysicalDevice physicalDevice,
    VkPhysicalDeviceProperties2* pProperties);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceFormatProperties2KHR(
    VkPhysicalDevice physicalDevice,
    VkFormat format,
    VkFormatProperties2* pFormatProperties);

 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceImageFormatProperties2KHR(
    VkPhysicalDevice physicalDevice,
    const VkPhysicalDeviceImageFormatInfo2* pImageFormatInfo,
    VkImageFormatProperties2* pImageFormatProperties);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceQueueFamilyProperties2KHR(
    VkPhysicalDevice physicalDevice,
    uint32_t* pQueueFamilyPropertyCount,
    VkQueueFamilyProperties2* pQueueFamilyProperties);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceMemoryProperties2KHR(
    VkPhysicalDevice physicalDevice,
    VkPhysicalDeviceMemoryProperties2* pMemoryProperties);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceSparseImageFormatProperties2KHR(
    VkPhysicalDevice physicalDevice,
    const VkPhysicalDeviceSparseImageFormatInfo2* pFormatInfo,
    uint32_t* pPropertyCount,
    VkSparseImageFormatProperties2* pProperties);







typedef VkPeerMemoryFeatureFlags VkPeerMemoryFeatureFlagsKHR;

typedef VkPeerMemoryFeatureFlagBits VkPeerMemoryFeatureFlagBitsKHR;

typedef VkMemoryAllocateFlags VkMemoryAllocateFlagsKHR;

typedef VkMemoryAllocateFlagBits VkMemoryAllocateFlagBitsKHR;

typedef VkMemoryAllocateFlagsInfo VkMemoryAllocateFlagsInfoKHR;

typedef VkDeviceGroupRenderPassBeginInfo VkDeviceGroupRenderPassBeginInfoKHR;

typedef VkDeviceGroupCommandBufferBeginInfo VkDeviceGroupCommandBufferBeginInfoKHR;

typedef VkDeviceGroupSubmitInfo VkDeviceGroupSubmitInfoKHR;

typedef VkDeviceGroupBindSparseInfo VkDeviceGroupBindSparseInfoKHR;

typedef VkBindBufferMemoryDeviceGroupInfo VkBindBufferMemoryDeviceGroupInfoKHR;

typedef VkBindImageMemoryDeviceGroupInfo VkBindImageMemoryDeviceGroupInfoKHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkGetDeviceGroupPeerMemoryFeaturesKHR)(VkDevice device, uint32_t heapIndex, uint32_t localDeviceIndex, uint32_t remoteDeviceIndex, VkPeerMemoryFeatureFlags* pPeerMemoryFeatures);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDeviceMaskKHR)(VkCommandBuffer commandBuffer, uint32_t deviceMask);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDispatchBaseKHR)(VkCommandBuffer commandBuffer, uint32_t baseGroupX, uint32_t baseGroupY, uint32_t baseGroupZ, uint32_t groupCountX, uint32_t groupCountY, uint32_t groupCountZ);


 void __attribute__((__stdcall__)) vkGetDeviceGroupPeerMemoryFeaturesKHR(
    VkDevice device,
    uint32_t heapIndex,
    uint32_t localDeviceIndex,
    uint32_t remoteDeviceIndex,
    VkPeerMemoryFeatureFlags* pPeerMemoryFeatures);

 void __attribute__((__stdcall__)) vkCmdSetDeviceMaskKHR(
    VkCommandBuffer commandBuffer,
    uint32_t deviceMask);

 void __attribute__((__stdcall__)) vkCmdDispatchBaseKHR(
    VkCommandBuffer commandBuffer,
    uint32_t baseGroupX,
    uint32_t baseGroupY,
    uint32_t baseGroupZ,
    uint32_t groupCountX,
    uint32_t groupCountY,
    uint32_t groupCountZ);
# 9899 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkCommandPoolTrimFlags VkCommandPoolTrimFlagsKHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkTrimCommandPoolKHR)(VkDevice device, VkCommandPool commandPool, VkCommandPoolTrimFlags flags);


 void __attribute__((__stdcall__)) vkTrimCommandPoolKHR(
    VkDevice device,
    VkCommandPool commandPool,
    VkCommandPoolTrimFlags flags);
# 9916 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkPhysicalDeviceGroupProperties VkPhysicalDeviceGroupPropertiesKHR;

typedef VkDeviceGroupDeviceCreateInfo VkDeviceGroupDeviceCreateInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkEnumeratePhysicalDeviceGroupsKHR)(VkInstance instance, uint32_t* pPhysicalDeviceGroupCount, VkPhysicalDeviceGroupProperties* pPhysicalDeviceGroupProperties);


 VkResult __attribute__((__stdcall__)) vkEnumeratePhysicalDeviceGroupsKHR(
    VkInstance instance,
    uint32_t* pPhysicalDeviceGroupCount,
    VkPhysicalDeviceGroupProperties* pPhysicalDeviceGroupProperties);
# 9935 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkExternalMemoryHandleTypeFlags VkExternalMemoryHandleTypeFlagsKHR;

typedef VkExternalMemoryHandleTypeFlagBits VkExternalMemoryHandleTypeFlagBitsKHR;

typedef VkExternalMemoryFeatureFlags VkExternalMemoryFeatureFlagsKHR;

typedef VkExternalMemoryFeatureFlagBits VkExternalMemoryFeatureFlagBitsKHR;

typedef VkExternalMemoryProperties VkExternalMemoryPropertiesKHR;

typedef VkPhysicalDeviceExternalImageFormatInfo VkPhysicalDeviceExternalImageFormatInfoKHR;

typedef VkExternalImageFormatProperties VkExternalImageFormatPropertiesKHR;

typedef VkPhysicalDeviceExternalBufferInfo VkPhysicalDeviceExternalBufferInfoKHR;

typedef VkExternalBufferProperties VkExternalBufferPropertiesKHR;

typedef VkPhysicalDeviceIDProperties VkPhysicalDeviceIDPropertiesKHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceExternalBufferPropertiesKHR)(VkPhysicalDevice physicalDevice, const VkPhysicalDeviceExternalBufferInfo* pExternalBufferInfo, VkExternalBufferProperties* pExternalBufferProperties);


 void __attribute__((__stdcall__)) vkGetPhysicalDeviceExternalBufferPropertiesKHR(
    VkPhysicalDevice physicalDevice,
    const VkPhysicalDeviceExternalBufferInfo* pExternalBufferInfo,
    VkExternalBufferProperties* pExternalBufferProperties);
# 9970 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkExternalMemoryImageCreateInfo VkExternalMemoryImageCreateInfoKHR;

typedef VkExternalMemoryBufferCreateInfo VkExternalMemoryBufferCreateInfoKHR;

typedef VkExportMemoryAllocateInfo VkExportMemoryAllocateInfoKHR;







typedef struct VkImportMemoryFdInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkExternalMemoryHandleTypeFlagBits handleType;
    int fd;
} VkImportMemoryFdInfoKHR;

typedef struct VkMemoryFdPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    uint32_t memoryTypeBits;
} VkMemoryFdPropertiesKHR;

typedef struct VkMemoryGetFdInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkDeviceMemory memory;
    VkExternalMemoryHandleTypeFlagBits handleType;
} VkMemoryGetFdInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetMemoryFdKHR)(VkDevice device, const VkMemoryGetFdInfoKHR* pGetFdInfo, int* pFd);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetMemoryFdPropertiesKHR)(VkDevice device, VkExternalMemoryHandleTypeFlagBits handleType, int fd, VkMemoryFdPropertiesKHR* pMemoryFdProperties);


 VkResult __attribute__((__stdcall__)) vkGetMemoryFdKHR(
    VkDevice device,
    const VkMemoryGetFdInfoKHR* pGetFdInfo,
    int* pFd);

 VkResult __attribute__((__stdcall__)) vkGetMemoryFdPropertiesKHR(
    VkDevice device,
    VkExternalMemoryHandleTypeFlagBits handleType,
    int fd,
    VkMemoryFdPropertiesKHR* pMemoryFdProperties);







typedef VkExternalSemaphoreHandleTypeFlags VkExternalSemaphoreHandleTypeFlagsKHR;

typedef VkExternalSemaphoreHandleTypeFlagBits VkExternalSemaphoreHandleTypeFlagBitsKHR;

typedef VkExternalSemaphoreFeatureFlags VkExternalSemaphoreFeatureFlagsKHR;

typedef VkExternalSemaphoreFeatureFlagBits VkExternalSemaphoreFeatureFlagBitsKHR;

typedef VkPhysicalDeviceExternalSemaphoreInfo VkPhysicalDeviceExternalSemaphoreInfoKHR;

typedef VkExternalSemaphoreProperties VkExternalSemaphorePropertiesKHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceExternalSemaphorePropertiesKHR)(VkPhysicalDevice physicalDevice, const VkPhysicalDeviceExternalSemaphoreInfo* pExternalSemaphoreInfo, VkExternalSemaphoreProperties* pExternalSemaphoreProperties);


 void __attribute__((__stdcall__)) vkGetPhysicalDeviceExternalSemaphorePropertiesKHR(
    VkPhysicalDevice physicalDevice,
    const VkPhysicalDeviceExternalSemaphoreInfo* pExternalSemaphoreInfo,
    VkExternalSemaphoreProperties* pExternalSemaphoreProperties);







typedef VkSemaphoreImportFlags VkSemaphoreImportFlagsKHR;

typedef VkSemaphoreImportFlagBits VkSemaphoreImportFlagBitsKHR;

typedef VkExportSemaphoreCreateInfo VkExportSemaphoreCreateInfoKHR;







typedef struct VkImportSemaphoreFdInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkSemaphore semaphore;
    VkSemaphoreImportFlags flags;
    VkExternalSemaphoreHandleTypeFlagBits handleType;
    int fd;
} VkImportSemaphoreFdInfoKHR;

typedef struct VkSemaphoreGetFdInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkSemaphore semaphore;
    VkExternalSemaphoreHandleTypeFlagBits handleType;
} VkSemaphoreGetFdInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkImportSemaphoreFdKHR)(VkDevice device, const VkImportSemaphoreFdInfoKHR* pImportSemaphoreFdInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetSemaphoreFdKHR)(VkDevice device, const VkSemaphoreGetFdInfoKHR* pGetFdInfo, int* pFd);


 VkResult __attribute__((__stdcall__)) vkImportSemaphoreFdKHR(
    VkDevice device,
    const VkImportSemaphoreFdInfoKHR* pImportSemaphoreFdInfo);

 VkResult __attribute__((__stdcall__)) vkGetSemaphoreFdKHR(
    VkDevice device,
    const VkSemaphoreGetFdInfoKHR* pGetFdInfo,
    int* pFd);







typedef VkPhysicalDevicePushDescriptorProperties VkPhysicalDevicePushDescriptorPropertiesKHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdPushDescriptorSetKHR)(VkCommandBuffer commandBuffer, VkPipelineBindPoint pipelineBindPoint, VkPipelineLayout layout, uint32_t set, uint32_t descriptorWriteCount, const VkWriteDescriptorSet* pDescriptorWrites);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdPushDescriptorSetWithTemplateKHR)(VkCommandBuffer commandBuffer, VkDescriptorUpdateTemplate descriptorUpdateTemplate, VkPipelineLayout layout, uint32_t set, const void* pData);


 void __attribute__((__stdcall__)) vkCmdPushDescriptorSetKHR(
    VkCommandBuffer commandBuffer,
    VkPipelineBindPoint pipelineBindPoint,
    VkPipelineLayout layout,
    uint32_t set,
    uint32_t descriptorWriteCount,
    const VkWriteDescriptorSet* pDescriptorWrites);

 void __attribute__((__stdcall__)) vkCmdPushDescriptorSetWithTemplateKHR(
    VkCommandBuffer commandBuffer,
    VkDescriptorUpdateTemplate descriptorUpdateTemplate,
    VkPipelineLayout layout,
    uint32_t set,
    const void* pData);







typedef VkPhysicalDeviceShaderFloat16Int8Features VkPhysicalDeviceShaderFloat16Int8FeaturesKHR;

typedef VkPhysicalDeviceShaderFloat16Int8Features VkPhysicalDeviceFloat16Int8FeaturesKHR;







typedef VkPhysicalDevice16BitStorageFeatures VkPhysicalDevice16BitStorageFeaturesKHR;







typedef struct VkRectLayerKHR {
    VkOffset2D offset;
    VkExtent2D extent;
    uint32_t layer;
} VkRectLayerKHR;

typedef struct VkPresentRegionKHR {
    uint32_t rectangleCount;
    const VkRectLayerKHR* pRectangles;
} VkPresentRegionKHR;

typedef struct VkPresentRegionsKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t swapchainCount;
    const VkPresentRegionKHR* pRegions;
} VkPresentRegionsKHR;





typedef VkDescriptorUpdateTemplate VkDescriptorUpdateTemplateKHR;



typedef VkDescriptorUpdateTemplateType VkDescriptorUpdateTemplateTypeKHR;

typedef VkDescriptorUpdateTemplateCreateFlags VkDescriptorUpdateTemplateCreateFlagsKHR;

typedef VkDescriptorUpdateTemplateEntry VkDescriptorUpdateTemplateEntryKHR;

typedef VkDescriptorUpdateTemplateCreateInfo VkDescriptorUpdateTemplateCreateInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateDescriptorUpdateTemplateKHR)(VkDevice device, const VkDescriptorUpdateTemplateCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDescriptorUpdateTemplate* pDescriptorUpdateTemplate);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyDescriptorUpdateTemplateKHR)(VkDevice device, VkDescriptorUpdateTemplate descriptorUpdateTemplate, const VkAllocationCallbacks* pAllocator);
typedef void (__attribute__((__stdcall__)) *PFN_vkUpdateDescriptorSetWithTemplateKHR)(VkDevice device, VkDescriptorSet descriptorSet, VkDescriptorUpdateTemplate descriptorUpdateTemplate, const void* pData);


 VkResult __attribute__((__stdcall__)) vkCreateDescriptorUpdateTemplateKHR(
    VkDevice device,
    const VkDescriptorUpdateTemplateCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkDescriptorUpdateTemplate* pDescriptorUpdateTemplate);

 void __attribute__((__stdcall__)) vkDestroyDescriptorUpdateTemplateKHR(
    VkDevice device,
    VkDescriptorUpdateTemplate descriptorUpdateTemplate,
    const VkAllocationCallbacks* pAllocator);

 void __attribute__((__stdcall__)) vkUpdateDescriptorSetWithTemplateKHR(
    VkDevice device,
    VkDescriptorSet descriptorSet,
    VkDescriptorUpdateTemplate descriptorUpdateTemplate,
    const void* pData);







typedef VkPhysicalDeviceImagelessFramebufferFeatures VkPhysicalDeviceImagelessFramebufferFeaturesKHR;

typedef VkFramebufferAttachmentsCreateInfo VkFramebufferAttachmentsCreateInfoKHR;

typedef VkFramebufferAttachmentImageInfo VkFramebufferAttachmentImageInfoKHR;

typedef VkRenderPassAttachmentBeginInfo VkRenderPassAttachmentBeginInfoKHR;







typedef VkRenderPassCreateInfo2 VkRenderPassCreateInfo2KHR;

typedef VkAttachmentDescription2 VkAttachmentDescription2KHR;

typedef VkAttachmentReference2 VkAttachmentReference2KHR;

typedef VkSubpassDescription2 VkSubpassDescription2KHR;

typedef VkSubpassDependency2 VkSubpassDependency2KHR;

typedef VkSubpassBeginInfo VkSubpassBeginInfoKHR;

typedef VkSubpassEndInfo VkSubpassEndInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateRenderPass2KHR)(VkDevice device, const VkRenderPassCreateInfo2* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkRenderPass* pRenderPass);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBeginRenderPass2KHR)(VkCommandBuffer commandBuffer, const VkRenderPassBeginInfo* pRenderPassBegin, const VkSubpassBeginInfo* pSubpassBeginInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdNextSubpass2KHR)(VkCommandBuffer commandBuffer, const VkSubpassBeginInfo* pSubpassBeginInfo, const VkSubpassEndInfo* pSubpassEndInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdEndRenderPass2KHR)(VkCommandBuffer commandBuffer, const VkSubpassEndInfo* pSubpassEndInfo);


 VkResult __attribute__((__stdcall__)) vkCreateRenderPass2KHR(
    VkDevice device,
    const VkRenderPassCreateInfo2* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkRenderPass* pRenderPass);

 void __attribute__((__stdcall__)) vkCmdBeginRenderPass2KHR(
    VkCommandBuffer commandBuffer,
    const VkRenderPassBeginInfo* pRenderPassBegin,
    const VkSubpassBeginInfo* pSubpassBeginInfo);

 void __attribute__((__stdcall__)) vkCmdNextSubpass2KHR(
    VkCommandBuffer commandBuffer,
    const VkSubpassBeginInfo* pSubpassBeginInfo,
    const VkSubpassEndInfo* pSubpassEndInfo);

 void __attribute__((__stdcall__)) vkCmdEndRenderPass2KHR(
    VkCommandBuffer commandBuffer,
    const VkSubpassEndInfo* pSubpassEndInfo);







typedef struct VkSharedPresentSurfaceCapabilitiesKHR {
    VkStructureType sType;
    void* pNext;
    VkImageUsageFlags sharedPresentSupportedUsageFlags;
} VkSharedPresentSurfaceCapabilitiesKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetSwapchainStatusKHR)(VkDevice device, VkSwapchainKHR swapchain);


 VkResult __attribute__((__stdcall__)) vkGetSwapchainStatusKHR(
    VkDevice device,
    VkSwapchainKHR swapchain);







typedef VkExternalFenceHandleTypeFlags VkExternalFenceHandleTypeFlagsKHR;

typedef VkExternalFenceHandleTypeFlagBits VkExternalFenceHandleTypeFlagBitsKHR;

typedef VkExternalFenceFeatureFlags VkExternalFenceFeatureFlagsKHR;

typedef VkExternalFenceFeatureFlagBits VkExternalFenceFeatureFlagBitsKHR;

typedef VkPhysicalDeviceExternalFenceInfo VkPhysicalDeviceExternalFenceInfoKHR;

typedef VkExternalFenceProperties VkExternalFencePropertiesKHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceExternalFencePropertiesKHR)(VkPhysicalDevice physicalDevice, const VkPhysicalDeviceExternalFenceInfo* pExternalFenceInfo, VkExternalFenceProperties* pExternalFenceProperties);


 void __attribute__((__stdcall__)) vkGetPhysicalDeviceExternalFencePropertiesKHR(
    VkPhysicalDevice physicalDevice,
    const VkPhysicalDeviceExternalFenceInfo* pExternalFenceInfo,
    VkExternalFenceProperties* pExternalFenceProperties);







typedef VkFenceImportFlags VkFenceImportFlagsKHR;

typedef VkFenceImportFlagBits VkFenceImportFlagBitsKHR;

typedef VkExportFenceCreateInfo VkExportFenceCreateInfoKHR;







typedef struct VkImportFenceFdInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkFence fence;
    VkFenceImportFlags flags;
    VkExternalFenceHandleTypeFlagBits handleType;
    int fd;
} VkImportFenceFdInfoKHR;

typedef struct VkFenceGetFdInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkFence fence;
    VkExternalFenceHandleTypeFlagBits handleType;
} VkFenceGetFdInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkImportFenceFdKHR)(VkDevice device, const VkImportFenceFdInfoKHR* pImportFenceFdInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetFenceFdKHR)(VkDevice device, const VkFenceGetFdInfoKHR* pGetFdInfo, int* pFd);


 VkResult __attribute__((__stdcall__)) vkImportFenceFdKHR(
    VkDevice device,
    const VkImportFenceFdInfoKHR* pImportFenceFdInfo);

 VkResult __attribute__((__stdcall__)) vkGetFenceFdKHR(
    VkDevice device,
    const VkFenceGetFdInfoKHR* pGetFdInfo,
    int* pFd);
# 10356 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkPerformanceCounterUnitKHR {
    VK_PERFORMANCE_COUNTER_UNIT_GENERIC_KHR = 0,
    VK_PERFORMANCE_COUNTER_UNIT_PERCENTAGE_KHR = 1,
    VK_PERFORMANCE_COUNTER_UNIT_NANOSECONDS_KHR = 2,
    VK_PERFORMANCE_COUNTER_UNIT_BYTES_KHR = 3,
    VK_PERFORMANCE_COUNTER_UNIT_BYTES_PER_SECOND_KHR = 4,
    VK_PERFORMANCE_COUNTER_UNIT_KELVIN_KHR = 5,
    VK_PERFORMANCE_COUNTER_UNIT_WATTS_KHR = 6,
    VK_PERFORMANCE_COUNTER_UNIT_VOLTS_KHR = 7,
    VK_PERFORMANCE_COUNTER_UNIT_AMPS_KHR = 8,
    VK_PERFORMANCE_COUNTER_UNIT_HERTZ_KHR = 9,
    VK_PERFORMANCE_COUNTER_UNIT_CYCLES_KHR = 10,
    VK_PERFORMANCE_COUNTER_UNIT_MAX_ENUM_KHR = 0x7FFFFFFF
} VkPerformanceCounterUnitKHR;

typedef enum VkPerformanceCounterScopeKHR {
    VK_PERFORMANCE_COUNTER_SCOPE_COMMAND_BUFFER_KHR = 0,
    VK_PERFORMANCE_COUNTER_SCOPE_RENDER_PASS_KHR = 1,
    VK_PERFORMANCE_COUNTER_SCOPE_COMMAND_KHR = 2,

    VK_QUERY_SCOPE_COMMAND_BUFFER_KHR = VK_PERFORMANCE_COUNTER_SCOPE_COMMAND_BUFFER_KHR,

    VK_QUERY_SCOPE_RENDER_PASS_KHR = VK_PERFORMANCE_COUNTER_SCOPE_RENDER_PASS_KHR,

    VK_QUERY_SCOPE_COMMAND_KHR = VK_PERFORMANCE_COUNTER_SCOPE_COMMAND_KHR,
    VK_PERFORMANCE_COUNTER_SCOPE_MAX_ENUM_KHR = 0x7FFFFFFF
} VkPerformanceCounterScopeKHR;

typedef enum VkPerformanceCounterStorageKHR {
    VK_PERFORMANCE_COUNTER_STORAGE_INT32_KHR = 0,
    VK_PERFORMANCE_COUNTER_STORAGE_INT64_KHR = 1,
    VK_PERFORMANCE_COUNTER_STORAGE_UINT32_KHR = 2,
    VK_PERFORMANCE_COUNTER_STORAGE_UINT64_KHR = 3,
    VK_PERFORMANCE_COUNTER_STORAGE_FLOAT32_KHR = 4,
    VK_PERFORMANCE_COUNTER_STORAGE_FLOAT64_KHR = 5,
    VK_PERFORMANCE_COUNTER_STORAGE_MAX_ENUM_KHR = 0x7FFFFFFF
} VkPerformanceCounterStorageKHR;

typedef enum VkPerformanceCounterDescriptionFlagBitsKHR {
    VK_PERFORMANCE_COUNTER_DESCRIPTION_PERFORMANCE_IMPACTING_BIT_KHR = 0x00000001,
    VK_PERFORMANCE_COUNTER_DESCRIPTION_CONCURRENTLY_IMPACTED_BIT_KHR = 0x00000002,

    VK_PERFORMANCE_COUNTER_DESCRIPTION_PERFORMANCE_IMPACTING_KHR = VK_PERFORMANCE_COUNTER_DESCRIPTION_PERFORMANCE_IMPACTING_BIT_KHR,

    VK_PERFORMANCE_COUNTER_DESCRIPTION_CONCURRENTLY_IMPACTED_KHR = VK_PERFORMANCE_COUNTER_DESCRIPTION_CONCURRENTLY_IMPACTED_BIT_KHR,
    VK_PERFORMANCE_COUNTER_DESCRIPTION_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkPerformanceCounterDescriptionFlagBitsKHR;
typedef VkFlags VkPerformanceCounterDescriptionFlagsKHR;

typedef enum VkAcquireProfilingLockFlagBitsKHR {
    VK_ACQUIRE_PROFILING_LOCK_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkAcquireProfilingLockFlagBitsKHR;
typedef VkFlags VkAcquireProfilingLockFlagsKHR;
typedef struct VkPhysicalDevicePerformanceQueryFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 performanceCounterQueryPools;
    VkBool32 performanceCounterMultipleQueryPools;
} VkPhysicalDevicePerformanceQueryFeaturesKHR;

typedef struct VkPhysicalDevicePerformanceQueryPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 allowCommandBufferQueryCopies;
} VkPhysicalDevicePerformanceQueryPropertiesKHR;

typedef struct VkPerformanceCounterKHR {
    VkStructureType sType;
    void* pNext;
    VkPerformanceCounterUnitKHR unit;
    VkPerformanceCounterScopeKHR scope;
    VkPerformanceCounterStorageKHR storage;
    uint8_t uuid[16U];
} VkPerformanceCounterKHR;

typedef struct VkPerformanceCounterDescriptionKHR {
    VkStructureType sType;
    void* pNext;
    VkPerformanceCounterDescriptionFlagsKHR flags;
    char name[256U];
    char category[256U];
    char description[256U];
} VkPerformanceCounterDescriptionKHR;

typedef struct VkQueryPoolPerformanceCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t queueFamilyIndex;
    uint32_t counterIndexCount;
    const uint32_t* pCounterIndices;
} VkQueryPoolPerformanceCreateInfoKHR;

typedef union VkPerformanceCounterResultKHR {
    int32_t int32;
    int64_t int64;
    uint32_t uint32;
    uint64_t uint64;
    float float32;
    double float64;
} VkPerformanceCounterResultKHR;

typedef struct VkAcquireProfilingLockInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkAcquireProfilingLockFlagsKHR flags;
    uint64_t timeout;
} VkAcquireProfilingLockInfoKHR;

typedef struct VkPerformanceQuerySubmitInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t counterPassIndex;
} VkPerformanceQuerySubmitInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkEnumeratePhysicalDeviceQueueFamilyPerformanceQueryCountersKHR)(VkPhysicalDevice physicalDevice, uint32_t queueFamilyIndex, uint32_t* pCounterCount, VkPerformanceCounterKHR* pCounters, VkPerformanceCounterDescriptionKHR* pCounterDescriptions);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceQueueFamilyPerformanceQueryPassesKHR)(VkPhysicalDevice physicalDevice, const VkQueryPoolPerformanceCreateInfoKHR* pPerformanceQueryCreateInfo, uint32_t* pNumPasses);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkAcquireProfilingLockKHR)(VkDevice device, const VkAcquireProfilingLockInfoKHR* pInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkReleaseProfilingLockKHR)(VkDevice device);


 VkResult __attribute__((__stdcall__)) vkEnumeratePhysicalDeviceQueueFamilyPerformanceQueryCountersKHR(
    VkPhysicalDevice physicalDevice,
    uint32_t queueFamilyIndex,
    uint32_t* pCounterCount,
    VkPerformanceCounterKHR* pCounters,
    VkPerformanceCounterDescriptionKHR* pCounterDescriptions);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceQueueFamilyPerformanceQueryPassesKHR(
    VkPhysicalDevice physicalDevice,
    const VkQueryPoolPerformanceCreateInfoKHR* pPerformanceQueryCreateInfo,
    uint32_t* pNumPasses);

 VkResult __attribute__((__stdcall__)) vkAcquireProfilingLockKHR(
    VkDevice device,
    const VkAcquireProfilingLockInfoKHR* pInfo);

 void __attribute__((__stdcall__)) vkReleaseProfilingLockKHR(
    VkDevice device);
# 10505 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkPointClippingBehavior VkPointClippingBehaviorKHR;

typedef VkTessellationDomainOrigin VkTessellationDomainOriginKHR;

typedef VkPhysicalDevicePointClippingProperties VkPhysicalDevicePointClippingPropertiesKHR;

typedef VkRenderPassInputAttachmentAspectCreateInfo VkRenderPassInputAttachmentAspectCreateInfoKHR;

typedef VkInputAttachmentAspectReference VkInputAttachmentAspectReferenceKHR;

typedef VkImageViewUsageCreateInfo VkImageViewUsageCreateInfoKHR;

typedef VkPipelineTessellationDomainOriginStateCreateInfo VkPipelineTessellationDomainOriginStateCreateInfoKHR;







typedef struct VkPhysicalDeviceSurfaceInfo2KHR {
    VkStructureType sType;
    const void* pNext;
    VkSurfaceKHR surface;
} VkPhysicalDeviceSurfaceInfo2KHR;

typedef struct VkSurfaceCapabilities2KHR {
    VkStructureType sType;
    void* pNext;
    VkSurfaceCapabilitiesKHR surfaceCapabilities;
} VkSurfaceCapabilities2KHR;

typedef struct VkSurfaceFormat2KHR {
    VkStructureType sType;
    void* pNext;
    VkSurfaceFormatKHR surfaceFormat;
} VkSurfaceFormat2KHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceSurfaceCapabilities2KHR)(VkPhysicalDevice physicalDevice, const VkPhysicalDeviceSurfaceInfo2KHR* pSurfaceInfo, VkSurfaceCapabilities2KHR* pSurfaceCapabilities);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceSurfaceFormats2KHR)(VkPhysicalDevice physicalDevice, const VkPhysicalDeviceSurfaceInfo2KHR* pSurfaceInfo, uint32_t* pSurfaceFormatCount, VkSurfaceFormat2KHR* pSurfaceFormats);


 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceSurfaceCapabilities2KHR(
    VkPhysicalDevice physicalDevice,
    const VkPhysicalDeviceSurfaceInfo2KHR* pSurfaceInfo,
    VkSurfaceCapabilities2KHR* pSurfaceCapabilities);

 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceSurfaceFormats2KHR(
    VkPhysicalDevice physicalDevice,
    const VkPhysicalDeviceSurfaceInfo2KHR* pSurfaceInfo,
    uint32_t* pSurfaceFormatCount,
    VkSurfaceFormat2KHR* pSurfaceFormats);







typedef VkPhysicalDeviceVariablePointersFeatures VkPhysicalDeviceVariablePointerFeaturesKHR;

typedef VkPhysicalDeviceVariablePointersFeatures VkPhysicalDeviceVariablePointersFeaturesKHR;







typedef struct VkDisplayProperties2KHR {
    VkStructureType sType;
    void* pNext;
    VkDisplayPropertiesKHR displayProperties;
} VkDisplayProperties2KHR;

typedef struct VkDisplayPlaneProperties2KHR {
    VkStructureType sType;
    void* pNext;
    VkDisplayPlanePropertiesKHR displayPlaneProperties;
} VkDisplayPlaneProperties2KHR;

typedef struct VkDisplayModeProperties2KHR {
    VkStructureType sType;
    void* pNext;
    VkDisplayModePropertiesKHR displayModeProperties;
} VkDisplayModeProperties2KHR;

typedef struct VkDisplayPlaneInfo2KHR {
    VkStructureType sType;
    const void* pNext;
    VkDisplayModeKHR mode;
    uint32_t planeIndex;
} VkDisplayPlaneInfo2KHR;

typedef struct VkDisplayPlaneCapabilities2KHR {
    VkStructureType sType;
    void* pNext;
    VkDisplayPlaneCapabilitiesKHR capabilities;
} VkDisplayPlaneCapabilities2KHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceDisplayProperties2KHR)(VkPhysicalDevice physicalDevice, uint32_t* pPropertyCount, VkDisplayProperties2KHR* pProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceDisplayPlaneProperties2KHR)(VkPhysicalDevice physicalDevice, uint32_t* pPropertyCount, VkDisplayPlaneProperties2KHR* pProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetDisplayModeProperties2KHR)(VkPhysicalDevice physicalDevice, VkDisplayKHR display, uint32_t* pPropertyCount, VkDisplayModeProperties2KHR* pProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetDisplayPlaneCapabilities2KHR)(VkPhysicalDevice physicalDevice, const VkDisplayPlaneInfo2KHR* pDisplayPlaneInfo, VkDisplayPlaneCapabilities2KHR* pCapabilities);


 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceDisplayProperties2KHR(
    VkPhysicalDevice physicalDevice,
    uint32_t* pPropertyCount,
    VkDisplayProperties2KHR* pProperties);

 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceDisplayPlaneProperties2KHR(
    VkPhysicalDevice physicalDevice,
    uint32_t* pPropertyCount,
    VkDisplayPlaneProperties2KHR* pProperties);

 VkResult __attribute__((__stdcall__)) vkGetDisplayModeProperties2KHR(
    VkPhysicalDevice physicalDevice,
    VkDisplayKHR display,
    uint32_t* pPropertyCount,
    VkDisplayModeProperties2KHR* pProperties);

 VkResult __attribute__((__stdcall__)) vkGetDisplayPlaneCapabilities2KHR(
    VkPhysicalDevice physicalDevice,
    const VkDisplayPlaneInfo2KHR* pDisplayPlaneInfo,
    VkDisplayPlaneCapabilities2KHR* pCapabilities);







typedef VkMemoryDedicatedRequirements VkMemoryDedicatedRequirementsKHR;

typedef VkMemoryDedicatedAllocateInfo VkMemoryDedicatedAllocateInfoKHR;
# 10660 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkBufferMemoryRequirementsInfo2 VkBufferMemoryRequirementsInfo2KHR;

typedef VkImageMemoryRequirementsInfo2 VkImageMemoryRequirementsInfo2KHR;

typedef VkImageSparseMemoryRequirementsInfo2 VkImageSparseMemoryRequirementsInfo2KHR;

typedef VkMemoryRequirements2 VkMemoryRequirements2KHR;

typedef VkSparseImageMemoryRequirements2 VkSparseImageMemoryRequirements2KHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkGetImageMemoryRequirements2KHR)(VkDevice device, const VkImageMemoryRequirementsInfo2* pInfo, VkMemoryRequirements2* pMemoryRequirements);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetBufferMemoryRequirements2KHR)(VkDevice device, const VkBufferMemoryRequirementsInfo2* pInfo, VkMemoryRequirements2* pMemoryRequirements);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetImageSparseMemoryRequirements2KHR)(VkDevice device, const VkImageSparseMemoryRequirementsInfo2* pInfo, uint32_t* pSparseMemoryRequirementCount, VkSparseImageMemoryRequirements2* pSparseMemoryRequirements);


 void __attribute__((__stdcall__)) vkGetImageMemoryRequirements2KHR(
    VkDevice device,
    const VkImageMemoryRequirementsInfo2* pInfo,
    VkMemoryRequirements2* pMemoryRequirements);

 void __attribute__((__stdcall__)) vkGetBufferMemoryRequirements2KHR(
    VkDevice device,
    const VkBufferMemoryRequirementsInfo2* pInfo,
    VkMemoryRequirements2* pMemoryRequirements);

 void __attribute__((__stdcall__)) vkGetImageSparseMemoryRequirements2KHR(
    VkDevice device,
    const VkImageSparseMemoryRequirementsInfo2* pInfo,
    uint32_t* pSparseMemoryRequirementCount,
    VkSparseImageMemoryRequirements2* pSparseMemoryRequirements);







typedef VkImageFormatListCreateInfo VkImageFormatListCreateInfoKHR;





typedef VkSamplerYcbcrConversion VkSamplerYcbcrConversionKHR;



typedef VkSamplerYcbcrModelConversion VkSamplerYcbcrModelConversionKHR;

typedef VkSamplerYcbcrRange VkSamplerYcbcrRangeKHR;

typedef VkChromaLocation VkChromaLocationKHR;

typedef VkSamplerYcbcrConversionCreateInfo VkSamplerYcbcrConversionCreateInfoKHR;

typedef VkSamplerYcbcrConversionInfo VkSamplerYcbcrConversionInfoKHR;

typedef VkBindImagePlaneMemoryInfo VkBindImagePlaneMemoryInfoKHR;

typedef VkImagePlaneMemoryRequirementsInfo VkImagePlaneMemoryRequirementsInfoKHR;

typedef VkPhysicalDeviceSamplerYcbcrConversionFeatures VkPhysicalDeviceSamplerYcbcrConversionFeaturesKHR;

typedef VkSamplerYcbcrConversionImageFormatProperties VkSamplerYcbcrConversionImageFormatPropertiesKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateSamplerYcbcrConversionKHR)(VkDevice device, const VkSamplerYcbcrConversionCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSamplerYcbcrConversion* pYcbcrConversion);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroySamplerYcbcrConversionKHR)(VkDevice device, VkSamplerYcbcrConversion ycbcrConversion, const VkAllocationCallbacks* pAllocator);


 VkResult __attribute__((__stdcall__)) vkCreateSamplerYcbcrConversionKHR(
    VkDevice device,
    const VkSamplerYcbcrConversionCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkSamplerYcbcrConversion* pYcbcrConversion);

 void __attribute__((__stdcall__)) vkDestroySamplerYcbcrConversionKHR(
    VkDevice device,
    VkSamplerYcbcrConversion ycbcrConversion,
    const VkAllocationCallbacks* pAllocator);







typedef VkBindBufferMemoryInfo VkBindBufferMemoryInfoKHR;

typedef VkBindImageMemoryInfo VkBindImageMemoryInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkBindBufferMemory2KHR)(VkDevice device, uint32_t bindInfoCount, const VkBindBufferMemoryInfo* pBindInfos);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkBindImageMemory2KHR)(VkDevice device, uint32_t bindInfoCount, const VkBindImageMemoryInfo* pBindInfos);


 VkResult __attribute__((__stdcall__)) vkBindBufferMemory2KHR(
    VkDevice device,
    uint32_t bindInfoCount,
    const VkBindBufferMemoryInfo* pBindInfos);

 VkResult __attribute__((__stdcall__)) vkBindImageMemory2KHR(
    VkDevice device,
    uint32_t bindInfoCount,
    const VkBindImageMemoryInfo* pBindInfos);
# 10774 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkPhysicalDeviceMaintenance3Properties VkPhysicalDeviceMaintenance3PropertiesKHR;

typedef VkDescriptorSetLayoutSupport VkDescriptorSetLayoutSupportKHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkGetDescriptorSetLayoutSupportKHR)(VkDevice device, const VkDescriptorSetLayoutCreateInfo* pCreateInfo, VkDescriptorSetLayoutSupport* pSupport);


 void __attribute__((__stdcall__)) vkGetDescriptorSetLayoutSupportKHR(
    VkDevice device,
    const VkDescriptorSetLayoutCreateInfo* pCreateInfo,
    VkDescriptorSetLayoutSupport* pSupport);







typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawIndirectCountKHR)(VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawIndexedIndirectCountKHR)(VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride);


 void __attribute__((__stdcall__)) vkCmdDrawIndirectCountKHR(
    VkCommandBuffer commandBuffer,
    VkBuffer buffer,
    VkDeviceSize offset,
    VkBuffer countBuffer,
    VkDeviceSize countBufferOffset,
    uint32_t maxDrawCount,
    uint32_t stride);

 void __attribute__((__stdcall__)) vkCmdDrawIndexedIndirectCountKHR(
    VkCommandBuffer commandBuffer,
    VkBuffer buffer,
    VkDeviceSize offset,
    VkBuffer countBuffer,
    VkDeviceSize countBufferOffset,
    uint32_t maxDrawCount,
    uint32_t stride);







typedef VkPhysicalDeviceShaderSubgroupExtendedTypesFeatures VkPhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR;







typedef VkPhysicalDevice8BitStorageFeatures VkPhysicalDevice8BitStorageFeaturesKHR;







typedef VkPhysicalDeviceShaderAtomicInt64Features VkPhysicalDeviceShaderAtomicInt64FeaturesKHR;







typedef struct VkPhysicalDeviceShaderClockFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderSubgroupClock;
    VkBool32 shaderDeviceClock;
} VkPhysicalDeviceShaderClockFeaturesKHR;





# 1 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h265std_decode.h" 1 3 4
# 17 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h265std_decode.h" 3 4
extern "C" {
# 31 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_h265std_decode.h" 3 4
typedef struct StdVideoDecodeH265PictureInfoFlags {
    uint32_t IrapPicFlag : 1;
    uint32_t IdrPicFlag : 1;
    uint32_t IsReference : 1;
    uint32_t short_term_ref_pic_set_sps_flag : 1;
} StdVideoDecodeH265PictureInfoFlags;

typedef struct StdVideoDecodeH265PictureInfo {
    StdVideoDecodeH265PictureInfoFlags flags;
    uint8_t sps_video_parameter_set_id;
    uint8_t pps_seq_parameter_set_id;
    uint8_t pps_pic_parameter_set_id;
    uint8_t NumDeltaPocsOfRefRpsIdx;
    int32_t PicOrderCntVal;
    uint16_t NumBitsForSTRefPicSetInSlice;
    uint16_t reserved;
    uint8_t RefPicSetStCurrBefore[8];
    uint8_t RefPicSetStCurrAfter[8];
    uint8_t RefPicSetLtCurr[8];
} StdVideoDecodeH265PictureInfo;

typedef struct StdVideoDecodeH265ReferenceInfoFlags {
    uint32_t used_for_long_term_reference : 1;
    uint32_t unused_for_reference : 1;
} StdVideoDecodeH265ReferenceInfoFlags;

typedef struct StdVideoDecodeH265ReferenceInfo {
    StdVideoDecodeH265ReferenceInfoFlags flags;
    int32_t PicOrderCntVal;
} StdVideoDecodeH265ReferenceInfo;



}
# 10856 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 2 3 4


typedef struct VkVideoDecodeH265ProfileInfoKHR {
    VkStructureType sType;
    const void* pNext;
    StdVideoH265ProfileIdc stdProfileIdc;
} VkVideoDecodeH265ProfileInfoKHR;

typedef struct VkVideoDecodeH265CapabilitiesKHR {
    VkStructureType sType;
    void* pNext;
    StdVideoH265LevelIdc maxLevelIdc;
} VkVideoDecodeH265CapabilitiesKHR;

typedef struct VkVideoDecodeH265SessionParametersAddInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t stdVPSCount;
    const StdVideoH265VideoParameterSet* pStdVPSs;
    uint32_t stdSPSCount;
    const StdVideoH265SequenceParameterSet* pStdSPSs;
    uint32_t stdPPSCount;
    const StdVideoH265PictureParameterSet* pStdPPSs;
} VkVideoDecodeH265SessionParametersAddInfoKHR;

typedef struct VkVideoDecodeH265SessionParametersCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t maxStdVPSCount;
    uint32_t maxStdSPSCount;
    uint32_t maxStdPPSCount;
    const VkVideoDecodeH265SessionParametersAddInfoKHR* pParametersAddInfo;
} VkVideoDecodeH265SessionParametersCreateInfoKHR;

typedef struct VkVideoDecodeH265PictureInfoKHR {
    VkStructureType sType;
    const void* pNext;
    const StdVideoDecodeH265PictureInfo* pStdPictureInfo;
    uint32_t sliceSegmentCount;
    const uint32_t* pSliceSegmentOffsets;
} VkVideoDecodeH265PictureInfoKHR;

typedef struct VkVideoDecodeH265DpbSlotInfoKHR {
    VkStructureType sType;
    const void* pNext;
    const StdVideoDecodeH265ReferenceInfo* pStdReferenceInfo;
} VkVideoDecodeH265DpbSlotInfoKHR;
# 10911 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkQueueGlobalPriority VkQueueGlobalPriorityKHR;

typedef VkDeviceQueueGlobalPriorityCreateInfo VkDeviceQueueGlobalPriorityCreateInfoKHR;

typedef VkPhysicalDeviceGlobalPriorityQueryFeatures VkPhysicalDeviceGlobalPriorityQueryFeaturesKHR;

typedef VkQueueFamilyGlobalPriorityProperties VkQueueFamilyGlobalPriorityPropertiesKHR;
# 10927 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkDriverId VkDriverIdKHR;

typedef VkConformanceVersion VkConformanceVersionKHR;

typedef VkPhysicalDeviceDriverProperties VkPhysicalDeviceDriverPropertiesKHR;







typedef VkShaderFloatControlsIndependence VkShaderFloatControlsIndependenceKHR;

typedef VkPhysicalDeviceFloatControlsProperties VkPhysicalDeviceFloatControlsPropertiesKHR;







typedef VkResolveModeFlagBits VkResolveModeFlagBitsKHR;

typedef VkResolveModeFlags VkResolveModeFlagsKHR;

typedef VkSubpassDescriptionDepthStencilResolve VkSubpassDescriptionDepthStencilResolveKHR;

typedef VkPhysicalDeviceDepthStencilResolveProperties VkPhysicalDeviceDepthStencilResolvePropertiesKHR;
# 10969 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkSemaphoreType VkSemaphoreTypeKHR;

typedef VkSemaphoreWaitFlagBits VkSemaphoreWaitFlagBitsKHR;

typedef VkSemaphoreWaitFlags VkSemaphoreWaitFlagsKHR;

typedef VkPhysicalDeviceTimelineSemaphoreFeatures VkPhysicalDeviceTimelineSemaphoreFeaturesKHR;

typedef VkPhysicalDeviceTimelineSemaphoreProperties VkPhysicalDeviceTimelineSemaphorePropertiesKHR;

typedef VkSemaphoreTypeCreateInfo VkSemaphoreTypeCreateInfoKHR;

typedef VkTimelineSemaphoreSubmitInfo VkTimelineSemaphoreSubmitInfoKHR;

typedef VkSemaphoreWaitInfo VkSemaphoreWaitInfoKHR;

typedef VkSemaphoreSignalInfo VkSemaphoreSignalInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetSemaphoreCounterValueKHR)(VkDevice device, VkSemaphore semaphore, uint64_t* pValue);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkWaitSemaphoresKHR)(VkDevice device, const VkSemaphoreWaitInfo* pWaitInfo, uint64_t timeout);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkSignalSemaphoreKHR)(VkDevice device, const VkSemaphoreSignalInfo* pSignalInfo);


 VkResult __attribute__((__stdcall__)) vkGetSemaphoreCounterValueKHR(
    VkDevice device,
    VkSemaphore semaphore,
    uint64_t* pValue);

 VkResult __attribute__((__stdcall__)) vkWaitSemaphoresKHR(
    VkDevice device,
    const VkSemaphoreWaitInfo* pWaitInfo,
    uint64_t timeout);

 VkResult __attribute__((__stdcall__)) vkSignalSemaphoreKHR(
    VkDevice device,
    const VkSemaphoreSignalInfo* pSignalInfo);







typedef VkPhysicalDeviceVulkanMemoryModelFeatures VkPhysicalDeviceVulkanMemoryModelFeaturesKHR;







typedef VkPhysicalDeviceShaderTerminateInvocationFeatures VkPhysicalDeviceShaderTerminateInvocationFeaturesKHR;
# 11029 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkFragmentShadingRateCombinerOpKHR {
    VK_FRAGMENT_SHADING_RATE_COMBINER_OP_KEEP_KHR = 0,
    VK_FRAGMENT_SHADING_RATE_COMBINER_OP_REPLACE_KHR = 1,
    VK_FRAGMENT_SHADING_RATE_COMBINER_OP_MIN_KHR = 2,
    VK_FRAGMENT_SHADING_RATE_COMBINER_OP_MAX_KHR = 3,
    VK_FRAGMENT_SHADING_RATE_COMBINER_OP_MUL_KHR = 4,
    VK_FRAGMENT_SHADING_RATE_COMBINER_OP_MAX_ENUM_KHR = 0x7FFFFFFF
} VkFragmentShadingRateCombinerOpKHR;
typedef struct VkFragmentShadingRateAttachmentInfoKHR {
    VkStructureType sType;
    const void* pNext;
    const VkAttachmentReference2* pFragmentShadingRateAttachment;
    VkExtent2D shadingRateAttachmentTexelSize;
} VkFragmentShadingRateAttachmentInfoKHR;

typedef struct VkPipelineFragmentShadingRateStateCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkExtent2D fragmentSize;
    VkFragmentShadingRateCombinerOpKHR combinerOps[2];
} VkPipelineFragmentShadingRateStateCreateInfoKHR;

typedef struct VkPhysicalDeviceFragmentShadingRateFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 pipelineFragmentShadingRate;
    VkBool32 primitiveFragmentShadingRate;
    VkBool32 attachmentFragmentShadingRate;
} VkPhysicalDeviceFragmentShadingRateFeaturesKHR;

typedef struct VkPhysicalDeviceFragmentShadingRatePropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkExtent2D minFragmentShadingRateAttachmentTexelSize;
    VkExtent2D maxFragmentShadingRateAttachmentTexelSize;
    uint32_t maxFragmentShadingRateAttachmentTexelSizeAspectRatio;
    VkBool32 primitiveFragmentShadingRateWithMultipleViewports;
    VkBool32 layeredShadingRateAttachments;
    VkBool32 fragmentShadingRateNonTrivialCombinerOps;
    VkExtent2D maxFragmentSize;
    uint32_t maxFragmentSizeAspectRatio;
    uint32_t maxFragmentShadingRateCoverageSamples;
    VkSampleCountFlagBits maxFragmentShadingRateRasterizationSamples;
    VkBool32 fragmentShadingRateWithShaderDepthStencilWrites;
    VkBool32 fragmentShadingRateWithSampleMask;
    VkBool32 fragmentShadingRateWithShaderSampleMask;
    VkBool32 fragmentShadingRateWithConservativeRasterization;
    VkBool32 fragmentShadingRateWithFragmentShaderInterlock;
    VkBool32 fragmentShadingRateWithCustomSampleLocations;
    VkBool32 fragmentShadingRateStrictMultiplyCombiner;
} VkPhysicalDeviceFragmentShadingRatePropertiesKHR;

typedef struct VkPhysicalDeviceFragmentShadingRateKHR {
    VkStructureType sType;
    void* pNext;
    VkSampleCountFlags sampleCounts;
    VkExtent2D fragmentSize;
} VkPhysicalDeviceFragmentShadingRateKHR;

typedef struct VkRenderingFragmentShadingRateAttachmentInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkImageView imageView;
    VkImageLayout imageLayout;
    VkExtent2D shadingRateAttachmentTexelSize;
} VkRenderingFragmentShadingRateAttachmentInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceFragmentShadingRatesKHR)(VkPhysicalDevice physicalDevice, uint32_t* pFragmentShadingRateCount, VkPhysicalDeviceFragmentShadingRateKHR* pFragmentShadingRates);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetFragmentShadingRateKHR)(VkCommandBuffer commandBuffer, const VkExtent2D* pFragmentSize, const VkFragmentShadingRateCombinerOpKHR combinerOps[2]);


 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceFragmentShadingRatesKHR(
    VkPhysicalDevice physicalDevice,
    uint32_t* pFragmentShadingRateCount,
    VkPhysicalDeviceFragmentShadingRateKHR* pFragmentShadingRates);

 void __attribute__((__stdcall__)) vkCmdSetFragmentShadingRateKHR(
    VkCommandBuffer commandBuffer,
    const VkExtent2D* pFragmentSize,
    const VkFragmentShadingRateCombinerOpKHR combinerOps[2]);







typedef VkPhysicalDeviceDynamicRenderingLocalReadFeatures VkPhysicalDeviceDynamicRenderingLocalReadFeaturesKHR;

typedef VkRenderingAttachmentLocationInfo VkRenderingAttachmentLocationInfoKHR;

typedef VkRenderingInputAttachmentIndexInfo VkRenderingInputAttachmentIndexInfoKHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetRenderingAttachmentLocationsKHR)(VkCommandBuffer commandBuffer, const VkRenderingAttachmentLocationInfo* pLocationInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetRenderingInputAttachmentIndicesKHR)(VkCommandBuffer commandBuffer, const VkRenderingInputAttachmentIndexInfo* pInputAttachmentIndexInfo);


 void __attribute__((__stdcall__)) vkCmdSetRenderingAttachmentLocationsKHR(
    VkCommandBuffer commandBuffer,
    const VkRenderingAttachmentLocationInfo* pLocationInfo);

 void __attribute__((__stdcall__)) vkCmdSetRenderingInputAttachmentIndicesKHR(
    VkCommandBuffer commandBuffer,
    const VkRenderingInputAttachmentIndexInfo* pInputAttachmentIndexInfo);







typedef struct VkPhysicalDeviceShaderQuadControlFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderQuadControl;
} VkPhysicalDeviceShaderQuadControlFeaturesKHR;
# 11158 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkSurfaceProtectedCapabilitiesKHR {
    VkStructureType sType;
    const void* pNext;
    VkBool32 supportsProtected;
} VkSurfaceProtectedCapabilitiesKHR;







typedef VkPhysicalDeviceSeparateDepthStencilLayoutsFeatures VkPhysicalDeviceSeparateDepthStencilLayoutsFeaturesKHR;

typedef VkAttachmentReferenceStencilLayout VkAttachmentReferenceStencilLayoutKHR;

typedef VkAttachmentDescriptionStencilLayout VkAttachmentDescriptionStencilLayoutKHR;







typedef struct VkPhysicalDevicePresentWaitFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 presentWait;
} VkPhysicalDevicePresentWaitFeaturesKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkWaitForPresentKHR)(VkDevice device, VkSwapchainKHR swapchain, uint64_t presentId, uint64_t timeout);


 VkResult __attribute__((__stdcall__)) vkWaitForPresentKHR(
    VkDevice device,
    VkSwapchainKHR swapchain,
    uint64_t presentId,
    uint64_t timeout);







typedef VkPhysicalDeviceUniformBufferStandardLayoutFeatures VkPhysicalDeviceUniformBufferStandardLayoutFeaturesKHR;







typedef VkPhysicalDeviceBufferDeviceAddressFeatures VkPhysicalDeviceBufferDeviceAddressFeaturesKHR;

typedef VkBufferDeviceAddressInfo VkBufferDeviceAddressInfoKHR;

typedef VkBufferOpaqueCaptureAddressCreateInfo VkBufferOpaqueCaptureAddressCreateInfoKHR;

typedef VkMemoryOpaqueCaptureAddressAllocateInfo VkMemoryOpaqueCaptureAddressAllocateInfoKHR;

typedef VkDeviceMemoryOpaqueCaptureAddressInfo VkDeviceMemoryOpaqueCaptureAddressInfoKHR;

typedef VkDeviceAddress (__attribute__((__stdcall__)) *PFN_vkGetBufferDeviceAddressKHR)(VkDevice device, const VkBufferDeviceAddressInfo* pInfo);
typedef uint64_t (__attribute__((__stdcall__)) *PFN_vkGetBufferOpaqueCaptureAddressKHR)(VkDevice device, const VkBufferDeviceAddressInfo* pInfo);
typedef uint64_t (__attribute__((__stdcall__)) *PFN_vkGetDeviceMemoryOpaqueCaptureAddressKHR)(VkDevice device, const VkDeviceMemoryOpaqueCaptureAddressInfo* pInfo);


 VkDeviceAddress __attribute__((__stdcall__)) vkGetBufferDeviceAddressKHR(
    VkDevice device,
    const VkBufferDeviceAddressInfo* pInfo);

 uint64_t __attribute__((__stdcall__)) vkGetBufferOpaqueCaptureAddressKHR(
    VkDevice device,
    const VkBufferDeviceAddressInfo* pInfo);

 uint64_t __attribute__((__stdcall__)) vkGetDeviceMemoryOpaqueCaptureAddressKHR(
    VkDevice device,
    const VkDeviceMemoryOpaqueCaptureAddressInfo* pInfo);





typedef struct VkDeferredOperationKHR_T *VkDeferredOperationKHR;


typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateDeferredOperationKHR)(VkDevice device, const VkAllocationCallbacks* pAllocator, VkDeferredOperationKHR* pDeferredOperation);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyDeferredOperationKHR)(VkDevice device, VkDeferredOperationKHR operation, const VkAllocationCallbacks* pAllocator);
typedef uint32_t (__attribute__((__stdcall__)) *PFN_vkGetDeferredOperationMaxConcurrencyKHR)(VkDevice device, VkDeferredOperationKHR operation);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetDeferredOperationResultKHR)(VkDevice device, VkDeferredOperationKHR operation);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkDeferredOperationJoinKHR)(VkDevice device, VkDeferredOperationKHR operation);


 VkResult __attribute__((__stdcall__)) vkCreateDeferredOperationKHR(
    VkDevice device,
    const VkAllocationCallbacks* pAllocator,
    VkDeferredOperationKHR* pDeferredOperation);

 void __attribute__((__stdcall__)) vkDestroyDeferredOperationKHR(
    VkDevice device,
    VkDeferredOperationKHR operation,
    const VkAllocationCallbacks* pAllocator);

 uint32_t __attribute__((__stdcall__)) vkGetDeferredOperationMaxConcurrencyKHR(
    VkDevice device,
    VkDeferredOperationKHR operation);

 VkResult __attribute__((__stdcall__)) vkGetDeferredOperationResultKHR(
    VkDevice device,
    VkDeferredOperationKHR operation);

 VkResult __attribute__((__stdcall__)) vkDeferredOperationJoinKHR(
    VkDevice device,
    VkDeferredOperationKHR operation);
# 11281 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkPipelineExecutableStatisticFormatKHR {
    VK_PIPELINE_EXECUTABLE_STATISTIC_FORMAT_BOOL32_KHR = 0,
    VK_PIPELINE_EXECUTABLE_STATISTIC_FORMAT_INT64_KHR = 1,
    VK_PIPELINE_EXECUTABLE_STATISTIC_FORMAT_UINT64_KHR = 2,
    VK_PIPELINE_EXECUTABLE_STATISTIC_FORMAT_FLOAT64_KHR = 3,
    VK_PIPELINE_EXECUTABLE_STATISTIC_FORMAT_MAX_ENUM_KHR = 0x7FFFFFFF
} VkPipelineExecutableStatisticFormatKHR;
typedef struct VkPhysicalDevicePipelineExecutablePropertiesFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 pipelineExecutableInfo;
} VkPhysicalDevicePipelineExecutablePropertiesFeaturesKHR;

typedef struct VkPipelineInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkPipeline pipeline;
} VkPipelineInfoKHR;

typedef struct VkPipelineExecutablePropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkShaderStageFlags stages;
    char name[256U];
    char description[256U];
    uint32_t subgroupSize;
} VkPipelineExecutablePropertiesKHR;

typedef struct VkPipelineExecutableInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkPipeline pipeline;
    uint32_t executableIndex;
} VkPipelineExecutableInfoKHR;

typedef union VkPipelineExecutableStatisticValueKHR {
    VkBool32 b32;
    int64_t i64;
    uint64_t u64;
    double f64;
} VkPipelineExecutableStatisticValueKHR;

typedef struct VkPipelineExecutableStatisticKHR {
    VkStructureType sType;
    void* pNext;
    char name[256U];
    char description[256U];
    VkPipelineExecutableStatisticFormatKHR format;
    VkPipelineExecutableStatisticValueKHR value;
} VkPipelineExecutableStatisticKHR;

typedef struct VkPipelineExecutableInternalRepresentationKHR {
    VkStructureType sType;
    void* pNext;
    char name[256U];
    char description[256U];
    VkBool32 isText;
    size_t dataSize;
    void* pData;
} VkPipelineExecutableInternalRepresentationKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPipelineExecutablePropertiesKHR)(VkDevice device, const VkPipelineInfoKHR* pPipelineInfo, uint32_t* pExecutableCount, VkPipelineExecutablePropertiesKHR* pProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPipelineExecutableStatisticsKHR)(VkDevice device, const VkPipelineExecutableInfoKHR* pExecutableInfo, uint32_t* pStatisticCount, VkPipelineExecutableStatisticKHR* pStatistics);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPipelineExecutableInternalRepresentationsKHR)(VkDevice device, const VkPipelineExecutableInfoKHR* pExecutableInfo, uint32_t* pInternalRepresentationCount, VkPipelineExecutableInternalRepresentationKHR* pInternalRepresentations);


 VkResult __attribute__((__stdcall__)) vkGetPipelineExecutablePropertiesKHR(
    VkDevice device,
    const VkPipelineInfoKHR* pPipelineInfo,
    uint32_t* pExecutableCount,
    VkPipelineExecutablePropertiesKHR* pProperties);

 VkResult __attribute__((__stdcall__)) vkGetPipelineExecutableStatisticsKHR(
    VkDevice device,
    const VkPipelineExecutableInfoKHR* pExecutableInfo,
    uint32_t* pStatisticCount,
    VkPipelineExecutableStatisticKHR* pStatistics);

 VkResult __attribute__((__stdcall__)) vkGetPipelineExecutableInternalRepresentationsKHR(
    VkDevice device,
    const VkPipelineExecutableInfoKHR* pExecutableInfo,
    uint32_t* pInternalRepresentationCount,
    VkPipelineExecutableInternalRepresentationKHR* pInternalRepresentations);







typedef VkMemoryUnmapFlagBits VkMemoryUnmapFlagBitsKHR;

typedef VkMemoryUnmapFlags VkMemoryUnmapFlagsKHR;

typedef VkMemoryMapInfo VkMemoryMapInfoKHR;

typedef VkMemoryUnmapInfo VkMemoryUnmapInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkMapMemory2KHR)(VkDevice device, const VkMemoryMapInfo* pMemoryMapInfo, void** ppData);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkUnmapMemory2KHR)(VkDevice device, const VkMemoryUnmapInfo* pMemoryUnmapInfo);


 VkResult __attribute__((__stdcall__)) vkMapMemory2KHR(
    VkDevice device,
    const VkMemoryMapInfo* pMemoryMapInfo,
    void** ppData);

 VkResult __attribute__((__stdcall__)) vkUnmapMemory2KHR(
    VkDevice device,
    const VkMemoryUnmapInfo* pMemoryUnmapInfo);







typedef VkPhysicalDeviceShaderIntegerDotProductFeatures VkPhysicalDeviceShaderIntegerDotProductFeaturesKHR;

typedef VkPhysicalDeviceShaderIntegerDotProductProperties VkPhysicalDeviceShaderIntegerDotProductPropertiesKHR;







typedef struct VkPipelineLibraryCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t libraryCount;
    const VkPipeline* pLibraries;
} VkPipelineLibraryCreateInfoKHR;
# 11427 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkPresentIdKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t swapchainCount;
    const uint64_t* pPresentIds;
} VkPresentIdKHR;

typedef struct VkPhysicalDevicePresentIdFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 presentId;
} VkPhysicalDevicePresentIdFeaturesKHR;
# 11447 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkVideoEncodeTuningModeKHR {
    VK_VIDEO_ENCODE_TUNING_MODE_DEFAULT_KHR = 0,
    VK_VIDEO_ENCODE_TUNING_MODE_HIGH_QUALITY_KHR = 1,
    VK_VIDEO_ENCODE_TUNING_MODE_LOW_LATENCY_KHR = 2,
    VK_VIDEO_ENCODE_TUNING_MODE_ULTRA_LOW_LATENCY_KHR = 3,
    VK_VIDEO_ENCODE_TUNING_MODE_LOSSLESS_KHR = 4,
    VK_VIDEO_ENCODE_TUNING_MODE_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeTuningModeKHR;

typedef enum VkVideoEncodeFlagBitsKHR {
    VK_VIDEO_ENCODE_WITH_QUANTIZATION_DELTA_MAP_BIT_KHR = 0x00000001,
    VK_VIDEO_ENCODE_WITH_EMPHASIS_MAP_BIT_KHR = 0x00000002,
    VK_VIDEO_ENCODE_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeFlagBitsKHR;
typedef VkFlags VkVideoEncodeFlagsKHR;

typedef enum VkVideoEncodeCapabilityFlagBitsKHR {
    VK_VIDEO_ENCODE_CAPABILITY_PRECEDING_EXTERNALLY_ENCODED_BYTES_BIT_KHR = 0x00000001,
    VK_VIDEO_ENCODE_CAPABILITY_INSUFFICIENT_BITSTREAM_BUFFER_RANGE_DETECTION_BIT_KHR = 0x00000002,
    VK_VIDEO_ENCODE_CAPABILITY_QUANTIZATION_DELTA_MAP_BIT_KHR = 0x00000004,
    VK_VIDEO_ENCODE_CAPABILITY_EMPHASIS_MAP_BIT_KHR = 0x00000008,
    VK_VIDEO_ENCODE_CAPABILITY_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeCapabilityFlagBitsKHR;
typedef VkFlags VkVideoEncodeCapabilityFlagsKHR;

typedef enum VkVideoEncodeRateControlModeFlagBitsKHR {
    VK_VIDEO_ENCODE_RATE_CONTROL_MODE_DEFAULT_KHR = 0,
    VK_VIDEO_ENCODE_RATE_CONTROL_MODE_DISABLED_BIT_KHR = 0x00000001,
    VK_VIDEO_ENCODE_RATE_CONTROL_MODE_CBR_BIT_KHR = 0x00000002,
    VK_VIDEO_ENCODE_RATE_CONTROL_MODE_VBR_BIT_KHR = 0x00000004,
    VK_VIDEO_ENCODE_RATE_CONTROL_MODE_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeRateControlModeFlagBitsKHR;
typedef VkFlags VkVideoEncodeRateControlModeFlagsKHR;

typedef enum VkVideoEncodeFeedbackFlagBitsKHR {
    VK_VIDEO_ENCODE_FEEDBACK_BITSTREAM_BUFFER_OFFSET_BIT_KHR = 0x00000001,
    VK_VIDEO_ENCODE_FEEDBACK_BITSTREAM_BYTES_WRITTEN_BIT_KHR = 0x00000002,
    VK_VIDEO_ENCODE_FEEDBACK_BITSTREAM_HAS_OVERRIDES_BIT_KHR = 0x00000004,
    VK_VIDEO_ENCODE_FEEDBACK_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeFeedbackFlagBitsKHR;
typedef VkFlags VkVideoEncodeFeedbackFlagsKHR;

typedef enum VkVideoEncodeUsageFlagBitsKHR {
    VK_VIDEO_ENCODE_USAGE_DEFAULT_KHR = 0,
    VK_VIDEO_ENCODE_USAGE_TRANSCODING_BIT_KHR = 0x00000001,
    VK_VIDEO_ENCODE_USAGE_STREAMING_BIT_KHR = 0x00000002,
    VK_VIDEO_ENCODE_USAGE_RECORDING_BIT_KHR = 0x00000004,
    VK_VIDEO_ENCODE_USAGE_CONFERENCING_BIT_KHR = 0x00000008,
    VK_VIDEO_ENCODE_USAGE_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeUsageFlagBitsKHR;
typedef VkFlags VkVideoEncodeUsageFlagsKHR;

typedef enum VkVideoEncodeContentFlagBitsKHR {
    VK_VIDEO_ENCODE_CONTENT_DEFAULT_KHR = 0,
    VK_VIDEO_ENCODE_CONTENT_CAMERA_BIT_KHR = 0x00000001,
    VK_VIDEO_ENCODE_CONTENT_DESKTOP_BIT_KHR = 0x00000002,
    VK_VIDEO_ENCODE_CONTENT_RENDERED_BIT_KHR = 0x00000004,
    VK_VIDEO_ENCODE_CONTENT_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeContentFlagBitsKHR;
typedef VkFlags VkVideoEncodeContentFlagsKHR;
typedef VkFlags VkVideoEncodeRateControlFlagsKHR;
typedef struct VkVideoEncodeInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkVideoEncodeFlagsKHR flags;
    VkBuffer dstBuffer;
    VkDeviceSize dstBufferOffset;
    VkDeviceSize dstBufferRange;
    VkVideoPictureResourceInfoKHR srcPictureResource;
    const VkVideoReferenceSlotInfoKHR* pSetupReferenceSlot;
    uint32_t referenceSlotCount;
    const VkVideoReferenceSlotInfoKHR* pReferenceSlots;
    uint32_t precedingExternallyEncodedBytes;
} VkVideoEncodeInfoKHR;

typedef struct VkVideoEncodeCapabilitiesKHR {
    VkStructureType sType;
    void* pNext;
    VkVideoEncodeCapabilityFlagsKHR flags;
    VkVideoEncodeRateControlModeFlagsKHR rateControlModes;
    uint32_t maxRateControlLayers;
    uint64_t maxBitrate;
    uint32_t maxQualityLevels;
    VkExtent2D encodeInputPictureGranularity;
    VkVideoEncodeFeedbackFlagsKHR supportedEncodeFeedbackFlags;
} VkVideoEncodeCapabilitiesKHR;

typedef struct VkQueryPoolVideoEncodeFeedbackCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkVideoEncodeFeedbackFlagsKHR encodeFeedbackFlags;
} VkQueryPoolVideoEncodeFeedbackCreateInfoKHR;

typedef struct VkVideoEncodeUsageInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkVideoEncodeUsageFlagsKHR videoUsageHints;
    VkVideoEncodeContentFlagsKHR videoContentHints;
    VkVideoEncodeTuningModeKHR tuningMode;
} VkVideoEncodeUsageInfoKHR;

typedef struct VkVideoEncodeRateControlLayerInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint64_t averageBitrate;
    uint64_t maxBitrate;
    uint32_t frameRateNumerator;
    uint32_t frameRateDenominator;
} VkVideoEncodeRateControlLayerInfoKHR;

typedef struct VkVideoEncodeRateControlInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkVideoEncodeRateControlFlagsKHR flags;
    VkVideoEncodeRateControlModeFlagBitsKHR rateControlMode;
    uint32_t layerCount;
    const VkVideoEncodeRateControlLayerInfoKHR* pLayers;
    uint32_t virtualBufferSizeInMs;
    uint32_t initialVirtualBufferSizeInMs;
} VkVideoEncodeRateControlInfoKHR;

typedef struct VkPhysicalDeviceVideoEncodeQualityLevelInfoKHR {
    VkStructureType sType;
    const void* pNext;
    const VkVideoProfileInfoKHR* pVideoProfile;
    uint32_t qualityLevel;
} VkPhysicalDeviceVideoEncodeQualityLevelInfoKHR;

typedef struct VkVideoEncodeQualityLevelPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkVideoEncodeRateControlModeFlagBitsKHR preferredRateControlMode;
    uint32_t preferredRateControlLayerCount;
} VkVideoEncodeQualityLevelPropertiesKHR;

typedef struct VkVideoEncodeQualityLevelInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t qualityLevel;
} VkVideoEncodeQualityLevelInfoKHR;

typedef struct VkVideoEncodeSessionParametersGetInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkVideoSessionParametersKHR videoSessionParameters;
} VkVideoEncodeSessionParametersGetInfoKHR;

typedef struct VkVideoEncodeSessionParametersFeedbackInfoKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 hasOverrides;
} VkVideoEncodeSessionParametersFeedbackInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceVideoEncodeQualityLevelPropertiesKHR)(VkPhysicalDevice physicalDevice, const VkPhysicalDeviceVideoEncodeQualityLevelInfoKHR* pQualityLevelInfo, VkVideoEncodeQualityLevelPropertiesKHR* pQualityLevelProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetEncodedVideoSessionParametersKHR)(VkDevice device, const VkVideoEncodeSessionParametersGetInfoKHR* pVideoSessionParametersInfo, VkVideoEncodeSessionParametersFeedbackInfoKHR* pFeedbackInfo, size_t* pDataSize, void* pData);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdEncodeVideoKHR)(VkCommandBuffer commandBuffer, const VkVideoEncodeInfoKHR* pEncodeInfo);


 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceVideoEncodeQualityLevelPropertiesKHR(
    VkPhysicalDevice physicalDevice,
    const VkPhysicalDeviceVideoEncodeQualityLevelInfoKHR* pQualityLevelInfo,
    VkVideoEncodeQualityLevelPropertiesKHR* pQualityLevelProperties);

 VkResult __attribute__((__stdcall__)) vkGetEncodedVideoSessionParametersKHR(
    VkDevice device,
    const VkVideoEncodeSessionParametersGetInfoKHR* pVideoSessionParametersInfo,
    VkVideoEncodeSessionParametersFeedbackInfoKHR* pFeedbackInfo,
    size_t* pDataSize,
    void* pData);

 void __attribute__((__stdcall__)) vkCmdEncodeVideoKHR(
    VkCommandBuffer commandBuffer,
    const VkVideoEncodeInfoKHR* pEncodeInfo);







typedef VkPipelineStageFlags2 VkPipelineStageFlags2KHR;

typedef VkPipelineStageFlagBits2 VkPipelineStageFlagBits2KHR;

typedef VkAccessFlags2 VkAccessFlags2KHR;

typedef VkAccessFlagBits2 VkAccessFlagBits2KHR;

typedef VkSubmitFlagBits VkSubmitFlagBitsKHR;

typedef VkSubmitFlags VkSubmitFlagsKHR;

typedef VkMemoryBarrier2 VkMemoryBarrier2KHR;

typedef VkBufferMemoryBarrier2 VkBufferMemoryBarrier2KHR;

typedef VkImageMemoryBarrier2 VkImageMemoryBarrier2KHR;

typedef VkDependencyInfo VkDependencyInfoKHR;

typedef VkSubmitInfo2 VkSubmitInfo2KHR;

typedef VkSemaphoreSubmitInfo VkSemaphoreSubmitInfoKHR;

typedef VkCommandBufferSubmitInfo VkCommandBufferSubmitInfoKHR;

typedef VkPhysicalDeviceSynchronization2Features VkPhysicalDeviceSynchronization2FeaturesKHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetEvent2KHR)(VkCommandBuffer commandBuffer, VkEvent event, const VkDependencyInfo* pDependencyInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdResetEvent2KHR)(VkCommandBuffer commandBuffer, VkEvent event, VkPipelineStageFlags2 stageMask);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdWaitEvents2KHR)(VkCommandBuffer commandBuffer, uint32_t eventCount, const VkEvent* pEvents, const VkDependencyInfo* pDependencyInfos);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdPipelineBarrier2KHR)(VkCommandBuffer commandBuffer, const VkDependencyInfo* pDependencyInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdWriteTimestamp2KHR)(VkCommandBuffer commandBuffer, VkPipelineStageFlags2 stage, VkQueryPool queryPool, uint32_t query);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkQueueSubmit2KHR)(VkQueue queue, uint32_t submitCount, const VkSubmitInfo2* pSubmits, VkFence fence);


 void __attribute__((__stdcall__)) vkCmdSetEvent2KHR(
    VkCommandBuffer commandBuffer,
    VkEvent event,
    const VkDependencyInfo* pDependencyInfo);

 void __attribute__((__stdcall__)) vkCmdResetEvent2KHR(
    VkCommandBuffer commandBuffer,
    VkEvent event,
    VkPipelineStageFlags2 stageMask);

 void __attribute__((__stdcall__)) vkCmdWaitEvents2KHR(
    VkCommandBuffer commandBuffer,
    uint32_t eventCount,
    const VkEvent* pEvents,
    const VkDependencyInfo* pDependencyInfos);

 void __attribute__((__stdcall__)) vkCmdPipelineBarrier2KHR(
    VkCommandBuffer commandBuffer,
    const VkDependencyInfo* pDependencyInfo);

 void __attribute__((__stdcall__)) vkCmdWriteTimestamp2KHR(
    VkCommandBuffer commandBuffer,
    VkPipelineStageFlags2 stage,
    VkQueryPool queryPool,
    uint32_t query);

 VkResult __attribute__((__stdcall__)) vkQueueSubmit2KHR(
    VkQueue queue,
    uint32_t submitCount,
    const VkSubmitInfo2* pSubmits,
    VkFence fence);







typedef struct VkPhysicalDeviceFragmentShaderBarycentricFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 fragmentShaderBarycentric;
} VkPhysicalDeviceFragmentShaderBarycentricFeaturesKHR;

typedef struct VkPhysicalDeviceFragmentShaderBarycentricPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 triStripVertexOrderIndependentOfProvokingVertex;
} VkPhysicalDeviceFragmentShaderBarycentricPropertiesKHR;







typedef struct VkPhysicalDeviceShaderSubgroupUniformControlFlowFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderSubgroupUniformControlFlow;
} VkPhysicalDeviceShaderSubgroupUniformControlFlowFeaturesKHR;







typedef VkPhysicalDeviceZeroInitializeWorkgroupMemoryFeatures VkPhysicalDeviceZeroInitializeWorkgroupMemoryFeaturesKHR;







typedef struct VkPhysicalDeviceWorkgroupMemoryExplicitLayoutFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 workgroupMemoryExplicitLayout;
    VkBool32 workgroupMemoryExplicitLayoutScalarBlockLayout;
    VkBool32 workgroupMemoryExplicitLayout8BitAccess;
    VkBool32 workgroupMemoryExplicitLayout16BitAccess;
} VkPhysicalDeviceWorkgroupMemoryExplicitLayoutFeaturesKHR;







typedef VkCopyBufferInfo2 VkCopyBufferInfo2KHR;

typedef VkCopyImageInfo2 VkCopyImageInfo2KHR;

typedef VkCopyBufferToImageInfo2 VkCopyBufferToImageInfo2KHR;

typedef VkCopyImageToBufferInfo2 VkCopyImageToBufferInfo2KHR;

typedef VkBlitImageInfo2 VkBlitImageInfo2KHR;

typedef VkResolveImageInfo2 VkResolveImageInfo2KHR;

typedef VkBufferCopy2 VkBufferCopy2KHR;

typedef VkImageCopy2 VkImageCopy2KHR;

typedef VkImageBlit2 VkImageBlit2KHR;

typedef VkBufferImageCopy2 VkBufferImageCopy2KHR;

typedef VkImageResolve2 VkImageResolve2KHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyBuffer2KHR)(VkCommandBuffer commandBuffer, const VkCopyBufferInfo2* pCopyBufferInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyImage2KHR)(VkCommandBuffer commandBuffer, const VkCopyImageInfo2* pCopyImageInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyBufferToImage2KHR)(VkCommandBuffer commandBuffer, const VkCopyBufferToImageInfo2* pCopyBufferToImageInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyImageToBuffer2KHR)(VkCommandBuffer commandBuffer, const VkCopyImageToBufferInfo2* pCopyImageToBufferInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBlitImage2KHR)(VkCommandBuffer commandBuffer, const VkBlitImageInfo2* pBlitImageInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdResolveImage2KHR)(VkCommandBuffer commandBuffer, const VkResolveImageInfo2* pResolveImageInfo);


 void __attribute__((__stdcall__)) vkCmdCopyBuffer2KHR(
    VkCommandBuffer commandBuffer,
    const VkCopyBufferInfo2* pCopyBufferInfo);

 void __attribute__((__stdcall__)) vkCmdCopyImage2KHR(
    VkCommandBuffer commandBuffer,
    const VkCopyImageInfo2* pCopyImageInfo);

 void __attribute__((__stdcall__)) vkCmdCopyBufferToImage2KHR(
    VkCommandBuffer commandBuffer,
    const VkCopyBufferToImageInfo2* pCopyBufferToImageInfo);

 void __attribute__((__stdcall__)) vkCmdCopyImageToBuffer2KHR(
    VkCommandBuffer commandBuffer,
    const VkCopyImageToBufferInfo2* pCopyImageToBufferInfo);

 void __attribute__((__stdcall__)) vkCmdBlitImage2KHR(
    VkCommandBuffer commandBuffer,
    const VkBlitImageInfo2* pBlitImageInfo);

 void __attribute__((__stdcall__)) vkCmdResolveImage2KHR(
    VkCommandBuffer commandBuffer,
    const VkResolveImageInfo2* pResolveImageInfo);







typedef VkFormatFeatureFlags2 VkFormatFeatureFlags2KHR;

typedef VkFormatFeatureFlagBits2 VkFormatFeatureFlagBits2KHR;

typedef VkFormatProperties3 VkFormatProperties3KHR;







typedef struct VkPhysicalDeviceRayTracingMaintenance1FeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 rayTracingMaintenance1;
    VkBool32 rayTracingPipelineTraceRaysIndirect2;
} VkPhysicalDeviceRayTracingMaintenance1FeaturesKHR;

typedef struct VkTraceRaysIndirectCommand2KHR {
    VkDeviceAddress raygenShaderRecordAddress;
    VkDeviceSize raygenShaderRecordSize;
    VkDeviceAddress missShaderBindingTableAddress;
    VkDeviceSize missShaderBindingTableSize;
    VkDeviceSize missShaderBindingTableStride;
    VkDeviceAddress hitShaderBindingTableAddress;
    VkDeviceSize hitShaderBindingTableSize;
    VkDeviceSize hitShaderBindingTableStride;
    VkDeviceAddress callableShaderBindingTableAddress;
    VkDeviceSize callableShaderBindingTableSize;
    VkDeviceSize callableShaderBindingTableStride;
    uint32_t width;
    uint32_t height;
    uint32_t depth;
} VkTraceRaysIndirectCommand2KHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdTraceRaysIndirect2KHR)(VkCommandBuffer commandBuffer, VkDeviceAddress indirectDeviceAddress);


 void __attribute__((__stdcall__)) vkCmdTraceRaysIndirect2KHR(
    VkCommandBuffer commandBuffer,
    VkDeviceAddress indirectDeviceAddress);
# 11869 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkPhysicalDeviceMaintenance4Features VkPhysicalDeviceMaintenance4FeaturesKHR;

typedef VkPhysicalDeviceMaintenance4Properties VkPhysicalDeviceMaintenance4PropertiesKHR;

typedef VkDeviceBufferMemoryRequirements VkDeviceBufferMemoryRequirementsKHR;

typedef VkDeviceImageMemoryRequirements VkDeviceImageMemoryRequirementsKHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkGetDeviceBufferMemoryRequirementsKHR)(VkDevice device, const VkDeviceBufferMemoryRequirements* pInfo, VkMemoryRequirements2* pMemoryRequirements);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetDeviceImageMemoryRequirementsKHR)(VkDevice device, const VkDeviceImageMemoryRequirements* pInfo, VkMemoryRequirements2* pMemoryRequirements);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetDeviceImageSparseMemoryRequirementsKHR)(VkDevice device, const VkDeviceImageMemoryRequirements* pInfo, uint32_t* pSparseMemoryRequirementCount, VkSparseImageMemoryRequirements2* pSparseMemoryRequirements);


 void __attribute__((__stdcall__)) vkGetDeviceBufferMemoryRequirementsKHR(
    VkDevice device,
    const VkDeviceBufferMemoryRequirements* pInfo,
    VkMemoryRequirements2* pMemoryRequirements);

 void __attribute__((__stdcall__)) vkGetDeviceImageMemoryRequirementsKHR(
    VkDevice device,
    const VkDeviceImageMemoryRequirements* pInfo,
    VkMemoryRequirements2* pMemoryRequirements);

 void __attribute__((__stdcall__)) vkGetDeviceImageSparseMemoryRequirementsKHR(
    VkDevice device,
    const VkDeviceImageMemoryRequirements* pInfo,
    uint32_t* pSparseMemoryRequirementCount,
    VkSparseImageMemoryRequirements2* pSparseMemoryRequirements);







typedef VkPhysicalDeviceShaderSubgroupRotateFeatures VkPhysicalDeviceShaderSubgroupRotateFeaturesKHR;







typedef struct VkPhysicalDeviceShaderMaximalReconvergenceFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderMaximalReconvergence;
} VkPhysicalDeviceShaderMaximalReconvergenceFeaturesKHR;







typedef VkPipelineCreateFlags2 VkPipelineCreateFlags2KHR;

typedef VkPipelineCreateFlagBits2 VkPipelineCreateFlagBits2KHR;

typedef VkBufferUsageFlags2 VkBufferUsageFlags2KHR;

typedef VkBufferUsageFlagBits2 VkBufferUsageFlagBits2KHR;

typedef VkPhysicalDeviceMaintenance5Features VkPhysicalDeviceMaintenance5FeaturesKHR;

typedef VkPhysicalDeviceMaintenance5Properties VkPhysicalDeviceMaintenance5PropertiesKHR;

typedef VkRenderingAreaInfo VkRenderingAreaInfoKHR;

typedef VkDeviceImageSubresourceInfo VkDeviceImageSubresourceInfoKHR;

typedef VkImageSubresource2 VkImageSubresource2KHR;

typedef VkSubresourceLayout2 VkSubresourceLayout2KHR;

typedef VkPipelineCreateFlags2CreateInfo VkPipelineCreateFlags2CreateInfoKHR;

typedef VkBufferUsageFlags2CreateInfo VkBufferUsageFlags2CreateInfoKHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBindIndexBuffer2KHR)(VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkDeviceSize size, VkIndexType indexType);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetRenderingAreaGranularityKHR)(VkDevice device, const VkRenderingAreaInfo* pRenderingAreaInfo, VkExtent2D* pGranularity);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetDeviceImageSubresourceLayoutKHR)(VkDevice device, const VkDeviceImageSubresourceInfo* pInfo, VkSubresourceLayout2* pLayout);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetImageSubresourceLayout2KHR)(VkDevice device, VkImage image, const VkImageSubresource2* pSubresource, VkSubresourceLayout2* pLayout);


 void __attribute__((__stdcall__)) vkCmdBindIndexBuffer2KHR(
    VkCommandBuffer commandBuffer,
    VkBuffer buffer,
    VkDeviceSize offset,
    VkDeviceSize size,
    VkIndexType indexType);

 void __attribute__((__stdcall__)) vkGetRenderingAreaGranularityKHR(
    VkDevice device,
    const VkRenderingAreaInfo* pRenderingAreaInfo,
    VkExtent2D* pGranularity);

 void __attribute__((__stdcall__)) vkGetDeviceImageSubresourceLayoutKHR(
    VkDevice device,
    const VkDeviceImageSubresourceInfo* pInfo,
    VkSubresourceLayout2* pLayout);

 void __attribute__((__stdcall__)) vkGetImageSubresourceLayout2KHR(
    VkDevice device,
    VkImage image,
    const VkImageSubresource2* pSubresource,
    VkSubresourceLayout2* pLayout);







typedef struct VkPhysicalDeviceRayTracingPositionFetchFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 rayTracingPositionFetch;
} VkPhysicalDeviceRayTracingPositionFetchFeaturesKHR;





typedef struct VkPipelineBinaryKHR_T *VkPipelineBinaryKHR;



typedef struct VkPhysicalDevicePipelineBinaryFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 pipelineBinaries;
} VkPhysicalDevicePipelineBinaryFeaturesKHR;

typedef struct VkPhysicalDevicePipelineBinaryPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 pipelineBinaryInternalCache;
    VkBool32 pipelineBinaryInternalCacheControl;
    VkBool32 pipelineBinaryPrefersInternalCache;
    VkBool32 pipelineBinaryPrecompiledInternalCache;
    VkBool32 pipelineBinaryCompressedData;
} VkPhysicalDevicePipelineBinaryPropertiesKHR;

typedef struct VkDevicePipelineBinaryInternalCacheControlKHR {
    VkStructureType sType;
    const void* pNext;
    VkBool32 disableInternalCache;
} VkDevicePipelineBinaryInternalCacheControlKHR;

typedef struct VkPipelineBinaryKeyKHR {
    VkStructureType sType;
    void* pNext;
    uint32_t keySize;
    uint8_t key[32U];
} VkPipelineBinaryKeyKHR;

typedef struct VkPipelineBinaryDataKHR {
    size_t dataSize;
    void* pData;
} VkPipelineBinaryDataKHR;

typedef struct VkPipelineBinaryKeysAndDataKHR {
    uint32_t binaryCount;
    const VkPipelineBinaryKeyKHR* pPipelineBinaryKeys;
    const VkPipelineBinaryDataKHR* pPipelineBinaryData;
} VkPipelineBinaryKeysAndDataKHR;

typedef struct VkPipelineCreateInfoKHR {
    VkStructureType sType;
    void* pNext;
} VkPipelineCreateInfoKHR;

typedef struct VkPipelineBinaryCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    const VkPipelineBinaryKeysAndDataKHR* pKeysAndDataInfo;
    VkPipeline pipeline;
    const VkPipelineCreateInfoKHR* pPipelineCreateInfo;
} VkPipelineBinaryCreateInfoKHR;

typedef struct VkPipelineBinaryInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t binaryCount;
    const VkPipelineBinaryKHR* pPipelineBinaries;
} VkPipelineBinaryInfoKHR;

typedef struct VkReleaseCapturedPipelineDataInfoKHR {
    VkStructureType sType;
    void* pNext;
    VkPipeline pipeline;
} VkReleaseCapturedPipelineDataInfoKHR;

typedef struct VkPipelineBinaryDataInfoKHR {
    VkStructureType sType;
    void* pNext;
    VkPipelineBinaryKHR pipelineBinary;
} VkPipelineBinaryDataInfoKHR;

typedef struct VkPipelineBinaryHandlesInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t pipelineBinaryCount;
    VkPipelineBinaryKHR* pPipelineBinaries;
} VkPipelineBinaryHandlesInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreatePipelineBinariesKHR)(VkDevice device, const VkPipelineBinaryCreateInfoKHR* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkPipelineBinaryHandlesInfoKHR* pBinaries);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyPipelineBinaryKHR)(VkDevice device, VkPipelineBinaryKHR pipelineBinary, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPipelineKeyKHR)(VkDevice device, const VkPipelineCreateInfoKHR* pPipelineCreateInfo, VkPipelineBinaryKeyKHR* pPipelineKey);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPipelineBinaryDataKHR)(VkDevice device, const VkPipelineBinaryDataInfoKHR* pInfo, VkPipelineBinaryKeyKHR* pPipelineBinaryKey, size_t* pPipelineBinaryDataSize, void* pPipelineBinaryData);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkReleaseCapturedPipelineDataKHR)(VkDevice device, const VkReleaseCapturedPipelineDataInfoKHR* pInfo, const VkAllocationCallbacks* pAllocator);


 VkResult __attribute__((__stdcall__)) vkCreatePipelineBinariesKHR(
    VkDevice device,
    const VkPipelineBinaryCreateInfoKHR* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkPipelineBinaryHandlesInfoKHR* pBinaries);

 void __attribute__((__stdcall__)) vkDestroyPipelineBinaryKHR(
    VkDevice device,
    VkPipelineBinaryKHR pipelineBinary,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkGetPipelineKeyKHR(
    VkDevice device,
    const VkPipelineCreateInfoKHR* pPipelineCreateInfo,
    VkPipelineBinaryKeyKHR* pPipelineKey);

 VkResult __attribute__((__stdcall__)) vkGetPipelineBinaryDataKHR(
    VkDevice device,
    const VkPipelineBinaryDataInfoKHR* pInfo,
    VkPipelineBinaryKeyKHR* pPipelineBinaryKey,
    size_t* pPipelineBinaryDataSize,
    void* pPipelineBinaryData);

 VkResult __attribute__((__stdcall__)) vkReleaseCapturedPipelineDataKHR(
    VkDevice device,
    const VkReleaseCapturedPipelineDataInfoKHR* pInfo,
    const VkAllocationCallbacks* pAllocator);
# 12118 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkComponentTypeKHR {
    VK_COMPONENT_TYPE_FLOAT16_KHR = 0,
    VK_COMPONENT_TYPE_FLOAT32_KHR = 1,
    VK_COMPONENT_TYPE_FLOAT64_KHR = 2,
    VK_COMPONENT_TYPE_SINT8_KHR = 3,
    VK_COMPONENT_TYPE_SINT16_KHR = 4,
    VK_COMPONENT_TYPE_SINT32_KHR = 5,
    VK_COMPONENT_TYPE_SINT64_KHR = 6,
    VK_COMPONENT_TYPE_UINT8_KHR = 7,
    VK_COMPONENT_TYPE_UINT16_KHR = 8,
    VK_COMPONENT_TYPE_UINT32_KHR = 9,
    VK_COMPONENT_TYPE_UINT64_KHR = 10,
    VK_COMPONENT_TYPE_FLOAT16_NV = VK_COMPONENT_TYPE_FLOAT16_KHR,
    VK_COMPONENT_TYPE_FLOAT32_NV = VK_COMPONENT_TYPE_FLOAT32_KHR,
    VK_COMPONENT_TYPE_FLOAT64_NV = VK_COMPONENT_TYPE_FLOAT64_KHR,
    VK_COMPONENT_TYPE_SINT8_NV = VK_COMPONENT_TYPE_SINT8_KHR,
    VK_COMPONENT_TYPE_SINT16_NV = VK_COMPONENT_TYPE_SINT16_KHR,
    VK_COMPONENT_TYPE_SINT32_NV = VK_COMPONENT_TYPE_SINT32_KHR,
    VK_COMPONENT_TYPE_SINT64_NV = VK_COMPONENT_TYPE_SINT64_KHR,
    VK_COMPONENT_TYPE_UINT8_NV = VK_COMPONENT_TYPE_UINT8_KHR,
    VK_COMPONENT_TYPE_UINT16_NV = VK_COMPONENT_TYPE_UINT16_KHR,
    VK_COMPONENT_TYPE_UINT32_NV = VK_COMPONENT_TYPE_UINT32_KHR,
    VK_COMPONENT_TYPE_UINT64_NV = VK_COMPONENT_TYPE_UINT64_KHR,
    VK_COMPONENT_TYPE_MAX_ENUM_KHR = 0x7FFFFFFF
} VkComponentTypeKHR;

typedef enum VkScopeKHR {
    VK_SCOPE_DEVICE_KHR = 1,
    VK_SCOPE_WORKGROUP_KHR = 2,
    VK_SCOPE_SUBGROUP_KHR = 3,
    VK_SCOPE_QUEUE_FAMILY_KHR = 5,
    VK_SCOPE_DEVICE_NV = VK_SCOPE_DEVICE_KHR,
    VK_SCOPE_WORKGROUP_NV = VK_SCOPE_WORKGROUP_KHR,
    VK_SCOPE_SUBGROUP_NV = VK_SCOPE_SUBGROUP_KHR,
    VK_SCOPE_QUEUE_FAMILY_NV = VK_SCOPE_QUEUE_FAMILY_KHR,
    VK_SCOPE_MAX_ENUM_KHR = 0x7FFFFFFF
} VkScopeKHR;
typedef struct VkCooperativeMatrixPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    uint32_t MSize;
    uint32_t NSize;
    uint32_t KSize;
    VkComponentTypeKHR AType;
    VkComponentTypeKHR BType;
    VkComponentTypeKHR CType;
    VkComponentTypeKHR ResultType;
    VkBool32 saturatingAccumulation;
    VkScopeKHR scope;
} VkCooperativeMatrixPropertiesKHR;

typedef struct VkPhysicalDeviceCooperativeMatrixFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 cooperativeMatrix;
    VkBool32 cooperativeMatrixRobustBufferAccess;
} VkPhysicalDeviceCooperativeMatrixFeaturesKHR;

typedef struct VkPhysicalDeviceCooperativeMatrixPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkShaderStageFlags cooperativeMatrixSupportedStages;
} VkPhysicalDeviceCooperativeMatrixPropertiesKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceCooperativeMatrixPropertiesKHR)(VkPhysicalDevice physicalDevice, uint32_t* pPropertyCount, VkCooperativeMatrixPropertiesKHR* pProperties);


 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceCooperativeMatrixPropertiesKHR(
    VkPhysicalDevice physicalDevice,
    uint32_t* pPropertyCount,
    VkCooperativeMatrixPropertiesKHR* pProperties);







typedef struct VkPhysicalDeviceComputeShaderDerivativesFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 computeDerivativeGroupQuads;
    VkBool32 computeDerivativeGroupLinear;
} VkPhysicalDeviceComputeShaderDerivativesFeaturesKHR;

typedef struct VkPhysicalDeviceComputeShaderDerivativesPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 meshAndTaskShaderDerivatives;
} VkPhysicalDeviceComputeShaderDerivativesPropertiesKHR;





# 1 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_av1std.h" 1 3 4
# 17 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_av1std.h" 3 4
extern "C" {
# 47 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_av1std.h" 3 4
typedef enum StdVideoAV1Profile {
    STD_VIDEO_AV1_PROFILE_MAIN = 0,
    STD_VIDEO_AV1_PROFILE_HIGH = 1,
    STD_VIDEO_AV1_PROFILE_PROFESSIONAL = 2,
    STD_VIDEO_AV1_PROFILE_INVALID = 0x7FFFFFFF,
    STD_VIDEO_AV1_PROFILE_MAX_ENUM = 0x7FFFFFFF
} StdVideoAV1Profile;

typedef enum StdVideoAV1Level {
    STD_VIDEO_AV1_LEVEL_2_0 = 0,
    STD_VIDEO_AV1_LEVEL_2_1 = 1,
    STD_VIDEO_AV1_LEVEL_2_2 = 2,
    STD_VIDEO_AV1_LEVEL_2_3 = 3,
    STD_VIDEO_AV1_LEVEL_3_0 = 4,
    STD_VIDEO_AV1_LEVEL_3_1 = 5,
    STD_VIDEO_AV1_LEVEL_3_2 = 6,
    STD_VIDEO_AV1_LEVEL_3_3 = 7,
    STD_VIDEO_AV1_LEVEL_4_0 = 8,
    STD_VIDEO_AV1_LEVEL_4_1 = 9,
    STD_VIDEO_AV1_LEVEL_4_2 = 10,
    STD_VIDEO_AV1_LEVEL_4_3 = 11,
    STD_VIDEO_AV1_LEVEL_5_0 = 12,
    STD_VIDEO_AV1_LEVEL_5_1 = 13,
    STD_VIDEO_AV1_LEVEL_5_2 = 14,
    STD_VIDEO_AV1_LEVEL_5_3 = 15,
    STD_VIDEO_AV1_LEVEL_6_0 = 16,
    STD_VIDEO_AV1_LEVEL_6_1 = 17,
    STD_VIDEO_AV1_LEVEL_6_2 = 18,
    STD_VIDEO_AV1_LEVEL_6_3 = 19,
    STD_VIDEO_AV1_LEVEL_7_0 = 20,
    STD_VIDEO_AV1_LEVEL_7_1 = 21,
    STD_VIDEO_AV1_LEVEL_7_2 = 22,
    STD_VIDEO_AV1_LEVEL_7_3 = 23,
    STD_VIDEO_AV1_LEVEL_INVALID = 0x7FFFFFFF,
    STD_VIDEO_AV1_LEVEL_MAX_ENUM = 0x7FFFFFFF
} StdVideoAV1Level;

typedef enum StdVideoAV1FrameType {
    STD_VIDEO_AV1_FRAME_TYPE_KEY = 0,
    STD_VIDEO_AV1_FRAME_TYPE_INTER = 1,
    STD_VIDEO_AV1_FRAME_TYPE_INTRA_ONLY = 2,
    STD_VIDEO_AV1_FRAME_TYPE_SWITCH = 3,
    STD_VIDEO_AV1_FRAME_TYPE_INVALID = 0x7FFFFFFF,
    STD_VIDEO_AV1_FRAME_TYPE_MAX_ENUM = 0x7FFFFFFF
} StdVideoAV1FrameType;

typedef enum StdVideoAV1ReferenceName {
    STD_VIDEO_AV1_REFERENCE_NAME_INTRA_FRAME = 0,
    STD_VIDEO_AV1_REFERENCE_NAME_LAST_FRAME = 1,
    STD_VIDEO_AV1_REFERENCE_NAME_LAST2_FRAME = 2,
    STD_VIDEO_AV1_REFERENCE_NAME_LAST3_FRAME = 3,
    STD_VIDEO_AV1_REFERENCE_NAME_GOLDEN_FRAME = 4,
    STD_VIDEO_AV1_REFERENCE_NAME_BWDREF_FRAME = 5,
    STD_VIDEO_AV1_REFERENCE_NAME_ALTREF2_FRAME = 6,
    STD_VIDEO_AV1_REFERENCE_NAME_ALTREF_FRAME = 7,
    STD_VIDEO_AV1_REFERENCE_NAME_INVALID = 0x7FFFFFFF,
    STD_VIDEO_AV1_REFERENCE_NAME_MAX_ENUM = 0x7FFFFFFF
} StdVideoAV1ReferenceName;

typedef enum StdVideoAV1InterpolationFilter {
    STD_VIDEO_AV1_INTERPOLATION_FILTER_EIGHTTAP = 0,
    STD_VIDEO_AV1_INTERPOLATION_FILTER_EIGHTTAP_SMOOTH = 1,
    STD_VIDEO_AV1_INTERPOLATION_FILTER_EIGHTTAP_SHARP = 2,
    STD_VIDEO_AV1_INTERPOLATION_FILTER_BILINEAR = 3,
    STD_VIDEO_AV1_INTERPOLATION_FILTER_SWITCHABLE = 4,
    STD_VIDEO_AV1_INTERPOLATION_FILTER_INVALID = 0x7FFFFFFF,
    STD_VIDEO_AV1_INTERPOLATION_FILTER_MAX_ENUM = 0x7FFFFFFF
} StdVideoAV1InterpolationFilter;

typedef enum StdVideoAV1TxMode {
    STD_VIDEO_AV1_TX_MODE_ONLY_4X4 = 0,
    STD_VIDEO_AV1_TX_MODE_LARGEST = 1,
    STD_VIDEO_AV1_TX_MODE_SELECT = 2,
    STD_VIDEO_AV1_TX_MODE_INVALID = 0x7FFFFFFF,
    STD_VIDEO_AV1_TX_MODE_MAX_ENUM = 0x7FFFFFFF
} StdVideoAV1TxMode;

typedef enum StdVideoAV1FrameRestorationType {
    STD_VIDEO_AV1_FRAME_RESTORATION_TYPE_NONE = 0,
    STD_VIDEO_AV1_FRAME_RESTORATION_TYPE_WIENER = 1,
    STD_VIDEO_AV1_FRAME_RESTORATION_TYPE_SGRPROJ = 2,
    STD_VIDEO_AV1_FRAME_RESTORATION_TYPE_SWITCHABLE = 3,
    STD_VIDEO_AV1_FRAME_RESTORATION_TYPE_INVALID = 0x7FFFFFFF,
    STD_VIDEO_AV1_FRAME_RESTORATION_TYPE_MAX_ENUM = 0x7FFFFFFF
} StdVideoAV1FrameRestorationType;

typedef enum StdVideoAV1ColorPrimaries {
    STD_VIDEO_AV1_COLOR_PRIMARIES_BT_709 = 1,
    STD_VIDEO_AV1_COLOR_PRIMARIES_UNSPECIFIED = 2,
    STD_VIDEO_AV1_COLOR_PRIMARIES_BT_470_M = 4,
    STD_VIDEO_AV1_COLOR_PRIMARIES_BT_470_B_G = 5,
    STD_VIDEO_AV1_COLOR_PRIMARIES_BT_601 = 6,
    STD_VIDEO_AV1_COLOR_PRIMARIES_SMPTE_240 = 7,
    STD_VIDEO_AV1_COLOR_PRIMARIES_GENERIC_FILM = 8,
    STD_VIDEO_AV1_COLOR_PRIMARIES_BT_2020 = 9,
    STD_VIDEO_AV1_COLOR_PRIMARIES_XYZ = 10,
    STD_VIDEO_AV1_COLOR_PRIMARIES_SMPTE_431 = 11,
    STD_VIDEO_AV1_COLOR_PRIMARIES_SMPTE_432 = 12,
    STD_VIDEO_AV1_COLOR_PRIMARIES_EBU_3213 = 22,
    STD_VIDEO_AV1_COLOR_PRIMARIES_INVALID = 0x7FFFFFFF,

    STD_VIDEO_AV1_COLOR_PRIMARIES_BT_UNSPECIFIED = STD_VIDEO_AV1_COLOR_PRIMARIES_UNSPECIFIED,
    STD_VIDEO_AV1_COLOR_PRIMARIES_MAX_ENUM = 0x7FFFFFFF
} StdVideoAV1ColorPrimaries;

typedef enum StdVideoAV1TransferCharacteristics {
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_RESERVED_0 = 0,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_BT_709 = 1,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_UNSPECIFIED = 2,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_RESERVED_3 = 3,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_BT_470_M = 4,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_BT_470_B_G = 5,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_BT_601 = 6,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_SMPTE_240 = 7,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_LINEAR = 8,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_LOG_100 = 9,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_LOG_100_SQRT10 = 10,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_IEC_61966 = 11,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_BT_1361 = 12,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_SRGB = 13,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_BT_2020_10_BIT = 14,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_BT_2020_12_BIT = 15,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_SMPTE_2084 = 16,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_SMPTE_428 = 17,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_HLG = 18,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_INVALID = 0x7FFFFFFF,
    STD_VIDEO_AV1_TRANSFER_CHARACTERISTICS_MAX_ENUM = 0x7FFFFFFF
} StdVideoAV1TransferCharacteristics;

typedef enum StdVideoAV1MatrixCoefficients {
    STD_VIDEO_AV1_MATRIX_COEFFICIENTS_IDENTITY = 0,
    STD_VIDEO_AV1_MATRIX_COEFFICIENTS_BT_709 = 1,
    STD_VIDEO_AV1_MATRIX_COEFFICIENTS_UNSPECIFIED = 2,
    STD_VIDEO_AV1_MATRIX_COEFFICIENTS_RESERVED_3 = 3,
    STD_VIDEO_AV1_MATRIX_COEFFICIENTS_FCC = 4,
    STD_VIDEO_AV1_MATRIX_COEFFICIENTS_BT_470_B_G = 5,
    STD_VIDEO_AV1_MATRIX_COEFFICIENTS_BT_601 = 6,
    STD_VIDEO_AV1_MATRIX_COEFFICIENTS_SMPTE_240 = 7,
    STD_VIDEO_AV1_MATRIX_COEFFICIENTS_SMPTE_YCGCO = 8,
    STD_VIDEO_AV1_MATRIX_COEFFICIENTS_BT_2020_NCL = 9,
    STD_VIDEO_AV1_MATRIX_COEFFICIENTS_BT_2020_CL = 10,
    STD_VIDEO_AV1_MATRIX_COEFFICIENTS_SMPTE_2085 = 11,
    STD_VIDEO_AV1_MATRIX_COEFFICIENTS_CHROMAT_NCL = 12,
    STD_VIDEO_AV1_MATRIX_COEFFICIENTS_CHROMAT_CL = 13,
    STD_VIDEO_AV1_MATRIX_COEFFICIENTS_ICTCP = 14,
    STD_VIDEO_AV1_MATRIX_COEFFICIENTS_INVALID = 0x7FFFFFFF,
    STD_VIDEO_AV1_MATRIX_COEFFICIENTS_MAX_ENUM = 0x7FFFFFFF
} StdVideoAV1MatrixCoefficients;

typedef enum StdVideoAV1ChromaSamplePosition {
    STD_VIDEO_AV1_CHROMA_SAMPLE_POSITION_UNKNOWN = 0,
    STD_VIDEO_AV1_CHROMA_SAMPLE_POSITION_VERTICAL = 1,
    STD_VIDEO_AV1_CHROMA_SAMPLE_POSITION_COLOCATED = 2,
    STD_VIDEO_AV1_CHROMA_SAMPLE_POSITION_RESERVED = 3,
    STD_VIDEO_AV1_CHROMA_SAMPLE_POSITION_INVALID = 0x7FFFFFFF,
    STD_VIDEO_AV1_CHROMA_SAMPLE_POSITION_MAX_ENUM = 0x7FFFFFFF
} StdVideoAV1ChromaSamplePosition;
typedef struct StdVideoAV1ColorConfigFlags {
    uint32_t mono_chrome : 1;
    uint32_t color_range : 1;
    uint32_t separate_uv_delta_q : 1;
    uint32_t color_description_present_flag : 1;
    uint32_t reserved : 28;
} StdVideoAV1ColorConfigFlags;

typedef struct StdVideoAV1ColorConfig {
    StdVideoAV1ColorConfigFlags flags;
    uint8_t BitDepth;
    uint8_t subsampling_x;
    uint8_t subsampling_y;
    uint8_t reserved1;
    StdVideoAV1ColorPrimaries color_primaries;
    StdVideoAV1TransferCharacteristics transfer_characteristics;
    StdVideoAV1MatrixCoefficients matrix_coefficients;
    StdVideoAV1ChromaSamplePosition chroma_sample_position;
} StdVideoAV1ColorConfig;

typedef struct StdVideoAV1TimingInfoFlags {
    uint32_t equal_picture_interval : 1;
    uint32_t reserved : 31;
} StdVideoAV1TimingInfoFlags;

typedef struct StdVideoAV1TimingInfo {
    StdVideoAV1TimingInfoFlags flags;
    uint32_t num_units_in_display_tick;
    uint32_t time_scale;
    uint32_t num_ticks_per_picture_minus_1;
} StdVideoAV1TimingInfo;

typedef struct StdVideoAV1LoopFilterFlags {
    uint32_t loop_filter_delta_enabled : 1;
    uint32_t loop_filter_delta_update : 1;
    uint32_t reserved : 30;
} StdVideoAV1LoopFilterFlags;

typedef struct StdVideoAV1LoopFilter {
    StdVideoAV1LoopFilterFlags flags;
    uint8_t loop_filter_level[4];
    uint8_t loop_filter_sharpness;
    uint8_t update_ref_delta;
    int8_t loop_filter_ref_deltas[8];
    uint8_t update_mode_delta;
    int8_t loop_filter_mode_deltas[2];
} StdVideoAV1LoopFilter;

typedef struct StdVideoAV1QuantizationFlags {
    uint32_t using_qmatrix : 1;
    uint32_t diff_uv_delta : 1;
    uint32_t reserved : 30;
} StdVideoAV1QuantizationFlags;

typedef struct StdVideoAV1Quantization {
    StdVideoAV1QuantizationFlags flags;
    uint8_t base_q_idx;
    int8_t DeltaQYDc;
    int8_t DeltaQUDc;
    int8_t DeltaQUAc;
    int8_t DeltaQVDc;
    int8_t DeltaQVAc;
    uint8_t qm_y;
    uint8_t qm_u;
    uint8_t qm_v;
} StdVideoAV1Quantization;

typedef struct StdVideoAV1Segmentation {
    uint8_t FeatureEnabled[8];
    int16_t FeatureData[8][8];
} StdVideoAV1Segmentation;

typedef struct StdVideoAV1TileInfoFlags {
    uint32_t uniform_tile_spacing_flag : 1;
    uint32_t reserved : 31;
} StdVideoAV1TileInfoFlags;

typedef struct StdVideoAV1TileInfo {
    StdVideoAV1TileInfoFlags flags;
    uint8_t TileCols;
    uint8_t TileRows;
    uint16_t context_update_tile_id;
    uint8_t tile_size_bytes_minus_1;
    uint8_t reserved1[7];
    const uint16_t* pMiColStarts;
    const uint16_t* pMiRowStarts;
    const uint16_t* pWidthInSbsMinus1;
    const uint16_t* pHeightInSbsMinus1;
} StdVideoAV1TileInfo;

typedef struct StdVideoAV1CDEF {
    uint8_t cdef_damping_minus_3;
    uint8_t cdef_bits;
    uint8_t cdef_y_pri_strength[8];
    uint8_t cdef_y_sec_strength[8];
    uint8_t cdef_uv_pri_strength[8];
    uint8_t cdef_uv_sec_strength[8];
} StdVideoAV1CDEF;

typedef struct StdVideoAV1LoopRestoration {
    StdVideoAV1FrameRestorationType FrameRestorationType[3];
    uint16_t LoopRestorationSize[3];
} StdVideoAV1LoopRestoration;

typedef struct StdVideoAV1GlobalMotion {
    uint8_t GmType[8];
    int32_t gm_params[8][6];
} StdVideoAV1GlobalMotion;

typedef struct StdVideoAV1FilmGrainFlags {
    uint32_t chroma_scaling_from_luma : 1;
    uint32_t overlap_flag : 1;
    uint32_t clip_to_restricted_range : 1;
    uint32_t update_grain : 1;
    uint32_t reserved : 28;
} StdVideoAV1FilmGrainFlags;

typedef struct StdVideoAV1FilmGrain {
    StdVideoAV1FilmGrainFlags flags;
    uint8_t grain_scaling_minus_8;
    uint8_t ar_coeff_lag;
    uint8_t ar_coeff_shift_minus_6;
    uint8_t grain_scale_shift;
    uint16_t grain_seed;
    uint8_t film_grain_params_ref_idx;
    uint8_t num_y_points;
    uint8_t point_y_value[14];
    uint8_t point_y_scaling[14];
    uint8_t num_cb_points;
    uint8_t point_cb_value[10];
    uint8_t point_cb_scaling[10];
    uint8_t num_cr_points;
    uint8_t point_cr_value[10];
    uint8_t point_cr_scaling[10];
    int8_t ar_coeffs_y_plus_128[24];
    int8_t ar_coeffs_cb_plus_128[25];
    int8_t ar_coeffs_cr_plus_128[25];
    uint8_t cb_mult;
    uint8_t cb_luma_mult;
    uint16_t cb_offset;
    uint8_t cr_mult;
    uint8_t cr_luma_mult;
    uint16_t cr_offset;
} StdVideoAV1FilmGrain;

typedef struct StdVideoAV1SequenceHeaderFlags {
    uint32_t still_picture : 1;
    uint32_t reduced_still_picture_header : 1;
    uint32_t use_128x128_superblock : 1;
    uint32_t enable_filter_intra : 1;
    uint32_t enable_intra_edge_filter : 1;
    uint32_t enable_interintra_compound : 1;
    uint32_t enable_masked_compound : 1;
    uint32_t enable_warped_motion : 1;
    uint32_t enable_dual_filter : 1;
    uint32_t enable_order_hint : 1;
    uint32_t enable_jnt_comp : 1;
    uint32_t enable_ref_frame_mvs : 1;
    uint32_t frame_id_numbers_present_flag : 1;
    uint32_t enable_superres : 1;
    uint32_t enable_cdef : 1;
    uint32_t enable_restoration : 1;
    uint32_t film_grain_params_present : 1;
    uint32_t timing_info_present_flag : 1;
    uint32_t initial_display_delay_present_flag : 1;
    uint32_t reserved : 13;
} StdVideoAV1SequenceHeaderFlags;

typedef struct StdVideoAV1SequenceHeader {
    StdVideoAV1SequenceHeaderFlags flags;
    StdVideoAV1Profile seq_profile;
    uint8_t frame_width_bits_minus_1;
    uint8_t frame_height_bits_minus_1;
    uint16_t max_frame_width_minus_1;
    uint16_t max_frame_height_minus_1;
    uint8_t delta_frame_id_length_minus_2;
    uint8_t additional_frame_id_length_minus_1;
    uint8_t order_hint_bits_minus_1;
    uint8_t seq_force_integer_mv;
    uint8_t seq_force_screen_content_tools;
    uint8_t reserved1[5];
    const StdVideoAV1ColorConfig* pColorConfig;
    const StdVideoAV1TimingInfo* pTimingInfo;
} StdVideoAV1SequenceHeader;



}
# 12214 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 2 3 4
# 1 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_av1std_decode.h" 1 3 4
# 17 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_av1std_decode.h" 3 4
extern "C" {






# 1 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_av1std.h" 1 3 4
# 25 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_av1std_decode.h" 2 3 4





typedef struct StdVideoDecodeAV1PictureInfoFlags {
    uint32_t error_resilient_mode : 1;
    uint32_t disable_cdf_update : 1;
    uint32_t use_superres : 1;
    uint32_t render_and_frame_size_different : 1;
    uint32_t allow_screen_content_tools : 1;
    uint32_t is_filter_switchable : 1;
    uint32_t force_integer_mv : 1;
    uint32_t frame_size_override_flag : 1;
    uint32_t buffer_removal_time_present_flag : 1;
    uint32_t allow_intrabc : 1;
    uint32_t frame_refs_short_signaling : 1;
    uint32_t allow_high_precision_mv : 1;
    uint32_t is_motion_mode_switchable : 1;
    uint32_t use_ref_frame_mvs : 1;
    uint32_t disable_frame_end_update_cdf : 1;
    uint32_t allow_warped_motion : 1;
    uint32_t reduced_tx_set : 1;
    uint32_t reference_select : 1;
    uint32_t skip_mode_present : 1;
    uint32_t delta_q_present : 1;
    uint32_t delta_lf_present : 1;
    uint32_t delta_lf_multi : 1;
    uint32_t segmentation_enabled : 1;
    uint32_t segmentation_update_map : 1;
    uint32_t segmentation_temporal_update : 1;
    uint32_t segmentation_update_data : 1;
    uint32_t UsesLr : 1;
    uint32_t usesChromaLr : 1;
    uint32_t apply_grain : 1;
    uint32_t reserved : 3;
} StdVideoDecodeAV1PictureInfoFlags;

typedef struct StdVideoDecodeAV1PictureInfo {
    StdVideoDecodeAV1PictureInfoFlags flags;
    StdVideoAV1FrameType frame_type;
    uint32_t current_frame_id;
    uint8_t OrderHint;
    uint8_t primary_ref_frame;
    uint8_t refresh_frame_flags;
    uint8_t reserved1;
    StdVideoAV1InterpolationFilter interpolation_filter;
    StdVideoAV1TxMode TxMode;
    uint8_t delta_q_res;
    uint8_t delta_lf_res;
    uint8_t SkipModeFrame[2];
    uint8_t coded_denom;
    uint8_t reserved2[3];
    uint8_t OrderHints[8];
    uint32_t expectedFrameId[8];
    const StdVideoAV1TileInfo* pTileInfo;
    const StdVideoAV1Quantization* pQuantization;
    const StdVideoAV1Segmentation* pSegmentation;
    const StdVideoAV1LoopFilter* pLoopFilter;
    const StdVideoAV1CDEF* pCDEF;
    const StdVideoAV1LoopRestoration* pLoopRestoration;
    const StdVideoAV1GlobalMotion* pGlobalMotion;
    const StdVideoAV1FilmGrain* pFilmGrain;
} StdVideoDecodeAV1PictureInfo;

typedef struct StdVideoDecodeAV1ReferenceInfoFlags {
    uint32_t disable_frame_end_update_cdf : 1;
    uint32_t segmentation_enabled : 1;
    uint32_t reserved : 30;
} StdVideoDecodeAV1ReferenceInfoFlags;

typedef struct StdVideoDecodeAV1ReferenceInfo {
    StdVideoDecodeAV1ReferenceInfoFlags flags;
    uint8_t frame_type;
    uint8_t RefFrameSignBias;
    uint8_t OrderHint;
    uint8_t SavedOrderHints[8];
} StdVideoDecodeAV1ReferenceInfo;



}
# 12215 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 2 3 4



typedef struct VkVideoDecodeAV1ProfileInfoKHR {
    VkStructureType sType;
    const void* pNext;
    StdVideoAV1Profile stdProfile;
    VkBool32 filmGrainSupport;
} VkVideoDecodeAV1ProfileInfoKHR;

typedef struct VkVideoDecodeAV1CapabilitiesKHR {
    VkStructureType sType;
    void* pNext;
    StdVideoAV1Level maxLevel;
} VkVideoDecodeAV1CapabilitiesKHR;

typedef struct VkVideoDecodeAV1SessionParametersCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    const StdVideoAV1SequenceHeader* pStdSequenceHeader;
} VkVideoDecodeAV1SessionParametersCreateInfoKHR;

typedef struct VkVideoDecodeAV1PictureInfoKHR {
    VkStructureType sType;
    const void* pNext;
    const StdVideoDecodeAV1PictureInfo* pStdPictureInfo;
    int32_t referenceNameSlotIndices[7U];
    uint32_t frameHeaderOffset;
    uint32_t tileCount;
    const uint32_t* pTileOffsets;
    const uint32_t* pTileSizes;
} VkVideoDecodeAV1PictureInfoKHR;

typedef struct VkVideoDecodeAV1DpbSlotInfoKHR {
    VkStructureType sType;
    const void* pNext;
    const StdVideoDecodeAV1ReferenceInfo* pStdReferenceInfo;
} VkVideoDecodeAV1DpbSlotInfoKHR;





# 1 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_av1std_encode.h" 1 3 4
# 17 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_av1std_encode.h" 3 4
extern "C" {
# 30 "C:/VulkanSDK/1.4.304.1/include/vk_video/vulkan_video_codec_av1std_encode.h" 3 4
typedef struct StdVideoEncodeAV1DecoderModelInfo {
    uint8_t buffer_delay_length_minus_1;
    uint8_t buffer_removal_time_length_minus_1;
    uint8_t frame_presentation_time_length_minus_1;
    uint8_t reserved1;
    uint32_t num_units_in_decoding_tick;
} StdVideoEncodeAV1DecoderModelInfo;

typedef struct StdVideoEncodeAV1ExtensionHeader {
    uint8_t temporal_id;
    uint8_t spatial_id;
} StdVideoEncodeAV1ExtensionHeader;

typedef struct StdVideoEncodeAV1OperatingPointInfoFlags {
    uint32_t decoder_model_present_for_this_op : 1;
    uint32_t low_delay_mode_flag : 1;
    uint32_t initial_display_delay_present_for_this_op : 1;
    uint32_t reserved : 29;
} StdVideoEncodeAV1OperatingPointInfoFlags;

typedef struct StdVideoEncodeAV1OperatingPointInfo {
    StdVideoEncodeAV1OperatingPointInfoFlags flags;
    uint16_t operating_point_idc;
    uint8_t seq_level_idx;
    uint8_t seq_tier;
    uint32_t decoder_buffer_delay;
    uint32_t encoder_buffer_delay;
    uint8_t initial_display_delay_minus_1;
} StdVideoEncodeAV1OperatingPointInfo;

typedef struct StdVideoEncodeAV1PictureInfoFlags {
    uint32_t error_resilient_mode : 1;
    uint32_t disable_cdf_update : 1;
    uint32_t use_superres : 1;
    uint32_t render_and_frame_size_different : 1;
    uint32_t allow_screen_content_tools : 1;
    uint32_t is_filter_switchable : 1;
    uint32_t force_integer_mv : 1;
    uint32_t frame_size_override_flag : 1;
    uint32_t buffer_removal_time_present_flag : 1;
    uint32_t allow_intrabc : 1;
    uint32_t frame_refs_short_signaling : 1;
    uint32_t allow_high_precision_mv : 1;
    uint32_t is_motion_mode_switchable : 1;
    uint32_t use_ref_frame_mvs : 1;
    uint32_t disable_frame_end_update_cdf : 1;
    uint32_t allow_warped_motion : 1;
    uint32_t reduced_tx_set : 1;
    uint32_t skip_mode_present : 1;
    uint32_t delta_q_present : 1;
    uint32_t delta_lf_present : 1;
    uint32_t delta_lf_multi : 1;
    uint32_t segmentation_enabled : 1;
    uint32_t segmentation_update_map : 1;
    uint32_t segmentation_temporal_update : 1;
    uint32_t segmentation_update_data : 1;
    uint32_t UsesLr : 1;
    uint32_t usesChromaLr : 1;
    uint32_t show_frame : 1;
    uint32_t showable_frame : 1;
    uint32_t reserved : 3;
} StdVideoEncodeAV1PictureInfoFlags;

typedef struct StdVideoEncodeAV1PictureInfo {
    StdVideoEncodeAV1PictureInfoFlags flags;
    StdVideoAV1FrameType frame_type;
    uint32_t frame_presentation_time;
    uint32_t current_frame_id;
    uint8_t order_hint;
    uint8_t primary_ref_frame;
    uint8_t refresh_frame_flags;
    uint8_t coded_denom;
    uint16_t render_width_minus_1;
    uint16_t render_height_minus_1;
    StdVideoAV1InterpolationFilter interpolation_filter;
    StdVideoAV1TxMode TxMode;
    uint8_t delta_q_res;
    uint8_t delta_lf_res;
    uint8_t ref_order_hint[8];
    int8_t ref_frame_idx[7];
    uint8_t reserved1[3];
    uint32_t delta_frame_id_minus_1[7];
    const StdVideoAV1TileInfo* pTileInfo;
    const StdVideoAV1Quantization* pQuantization;
    const StdVideoAV1Segmentation* pSegmentation;
    const StdVideoAV1LoopFilter* pLoopFilter;
    const StdVideoAV1CDEF* pCDEF;
    const StdVideoAV1LoopRestoration* pLoopRestoration;
    const StdVideoAV1GlobalMotion* pGlobalMotion;
    const StdVideoEncodeAV1ExtensionHeader* pExtensionHeader;
    const uint32_t* pBufferRemovalTimes;
} StdVideoEncodeAV1PictureInfo;

typedef struct StdVideoEncodeAV1ReferenceInfoFlags {
    uint32_t disable_frame_end_update_cdf : 1;
    uint32_t segmentation_enabled : 1;
    uint32_t reserved : 30;
} StdVideoEncodeAV1ReferenceInfoFlags;

typedef struct StdVideoEncodeAV1ReferenceInfo {
    StdVideoEncodeAV1ReferenceInfoFlags flags;
    uint32_t RefFrameId;
    StdVideoAV1FrameType frame_type;
    uint8_t OrderHint;
    uint8_t reserved1[3];
    const StdVideoEncodeAV1ExtensionHeader* pExtensionHeader;
} StdVideoEncodeAV1ReferenceInfo;



}
# 12259 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 2 3 4



typedef enum VkVideoEncodeAV1PredictionModeKHR {
    VK_VIDEO_ENCODE_AV1_PREDICTION_MODE_INTRA_ONLY_KHR = 0,
    VK_VIDEO_ENCODE_AV1_PREDICTION_MODE_SINGLE_REFERENCE_KHR = 1,
    VK_VIDEO_ENCODE_AV1_PREDICTION_MODE_UNIDIRECTIONAL_COMPOUND_KHR = 2,
    VK_VIDEO_ENCODE_AV1_PREDICTION_MODE_BIDIRECTIONAL_COMPOUND_KHR = 3,
    VK_VIDEO_ENCODE_AV1_PREDICTION_MODE_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeAV1PredictionModeKHR;

typedef enum VkVideoEncodeAV1RateControlGroupKHR {
    VK_VIDEO_ENCODE_AV1_RATE_CONTROL_GROUP_INTRA_KHR = 0,
    VK_VIDEO_ENCODE_AV1_RATE_CONTROL_GROUP_PREDICTIVE_KHR = 1,
    VK_VIDEO_ENCODE_AV1_RATE_CONTROL_GROUP_BIPREDICTIVE_KHR = 2,
    VK_VIDEO_ENCODE_AV1_RATE_CONTROL_GROUP_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeAV1RateControlGroupKHR;

typedef enum VkVideoEncodeAV1CapabilityFlagBitsKHR {
    VK_VIDEO_ENCODE_AV1_CAPABILITY_PER_RATE_CONTROL_GROUP_MIN_MAX_Q_INDEX_BIT_KHR = 0x00000001,
    VK_VIDEO_ENCODE_AV1_CAPABILITY_GENERATE_OBU_EXTENSION_HEADER_BIT_KHR = 0x00000002,
    VK_VIDEO_ENCODE_AV1_CAPABILITY_PRIMARY_REFERENCE_CDF_ONLY_BIT_KHR = 0x00000004,
    VK_VIDEO_ENCODE_AV1_CAPABILITY_FRAME_SIZE_OVERRIDE_BIT_KHR = 0x00000008,
    VK_VIDEO_ENCODE_AV1_CAPABILITY_MOTION_VECTOR_SCALING_BIT_KHR = 0x00000010,
    VK_VIDEO_ENCODE_AV1_CAPABILITY_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeAV1CapabilityFlagBitsKHR;
typedef VkFlags VkVideoEncodeAV1CapabilityFlagsKHR;

typedef enum VkVideoEncodeAV1StdFlagBitsKHR {
    VK_VIDEO_ENCODE_AV1_STD_UNIFORM_TILE_SPACING_FLAG_SET_BIT_KHR = 0x00000001,
    VK_VIDEO_ENCODE_AV1_STD_SKIP_MODE_PRESENT_UNSET_BIT_KHR = 0x00000002,
    VK_VIDEO_ENCODE_AV1_STD_PRIMARY_REF_FRAME_BIT_KHR = 0x00000004,
    VK_VIDEO_ENCODE_AV1_STD_DELTA_Q_BIT_KHR = 0x00000008,
    VK_VIDEO_ENCODE_AV1_STD_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeAV1StdFlagBitsKHR;
typedef VkFlags VkVideoEncodeAV1StdFlagsKHR;

typedef enum VkVideoEncodeAV1SuperblockSizeFlagBitsKHR {
    VK_VIDEO_ENCODE_AV1_SUPERBLOCK_SIZE_64_BIT_KHR = 0x00000001,
    VK_VIDEO_ENCODE_AV1_SUPERBLOCK_SIZE_128_BIT_KHR = 0x00000002,
    VK_VIDEO_ENCODE_AV1_SUPERBLOCK_SIZE_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeAV1SuperblockSizeFlagBitsKHR;
typedef VkFlags VkVideoEncodeAV1SuperblockSizeFlagsKHR;

typedef enum VkVideoEncodeAV1RateControlFlagBitsKHR {
    VK_VIDEO_ENCODE_AV1_RATE_CONTROL_REGULAR_GOP_BIT_KHR = 0x00000001,
    VK_VIDEO_ENCODE_AV1_RATE_CONTROL_TEMPORAL_LAYER_PATTERN_DYADIC_BIT_KHR = 0x00000002,
    VK_VIDEO_ENCODE_AV1_RATE_CONTROL_REFERENCE_PATTERN_FLAT_BIT_KHR = 0x00000004,
    VK_VIDEO_ENCODE_AV1_RATE_CONTROL_REFERENCE_PATTERN_DYADIC_BIT_KHR = 0x00000008,
    VK_VIDEO_ENCODE_AV1_RATE_CONTROL_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkVideoEncodeAV1RateControlFlagBitsKHR;
typedef VkFlags VkVideoEncodeAV1RateControlFlagsKHR;
typedef struct VkPhysicalDeviceVideoEncodeAV1FeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 videoEncodeAV1;
} VkPhysicalDeviceVideoEncodeAV1FeaturesKHR;

typedef struct VkVideoEncodeAV1CapabilitiesKHR {
    VkStructureType sType;
    void* pNext;
    VkVideoEncodeAV1CapabilityFlagsKHR flags;
    StdVideoAV1Level maxLevel;
    VkExtent2D codedPictureAlignment;
    VkExtent2D maxTiles;
    VkExtent2D minTileSize;
    VkExtent2D maxTileSize;
    VkVideoEncodeAV1SuperblockSizeFlagsKHR superblockSizes;
    uint32_t maxSingleReferenceCount;
    uint32_t singleReferenceNameMask;
    uint32_t maxUnidirectionalCompoundReferenceCount;
    uint32_t maxUnidirectionalCompoundGroup1ReferenceCount;
    uint32_t unidirectionalCompoundReferenceNameMask;
    uint32_t maxBidirectionalCompoundReferenceCount;
    uint32_t maxBidirectionalCompoundGroup1ReferenceCount;
    uint32_t maxBidirectionalCompoundGroup2ReferenceCount;
    uint32_t bidirectionalCompoundReferenceNameMask;
    uint32_t maxTemporalLayerCount;
    uint32_t maxSpatialLayerCount;
    uint32_t maxOperatingPoints;
    uint32_t minQIndex;
    uint32_t maxQIndex;
    VkBool32 prefersGopRemainingFrames;
    VkBool32 requiresGopRemainingFrames;
    VkVideoEncodeAV1StdFlagsKHR stdSyntaxFlags;
} VkVideoEncodeAV1CapabilitiesKHR;

typedef struct VkVideoEncodeAV1QIndexKHR {
    uint32_t intraQIndex;
    uint32_t predictiveQIndex;
    uint32_t bipredictiveQIndex;
} VkVideoEncodeAV1QIndexKHR;

typedef struct VkVideoEncodeAV1QualityLevelPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkVideoEncodeAV1RateControlFlagsKHR preferredRateControlFlags;
    uint32_t preferredGopFrameCount;
    uint32_t preferredKeyFramePeriod;
    uint32_t preferredConsecutiveBipredictiveFrameCount;
    uint32_t preferredTemporalLayerCount;
    VkVideoEncodeAV1QIndexKHR preferredConstantQIndex;
    uint32_t preferredMaxSingleReferenceCount;
    uint32_t preferredSingleReferenceNameMask;
    uint32_t preferredMaxUnidirectionalCompoundReferenceCount;
    uint32_t preferredMaxUnidirectionalCompoundGroup1ReferenceCount;
    uint32_t preferredUnidirectionalCompoundReferenceNameMask;
    uint32_t preferredMaxBidirectionalCompoundReferenceCount;
    uint32_t preferredMaxBidirectionalCompoundGroup1ReferenceCount;
    uint32_t preferredMaxBidirectionalCompoundGroup2ReferenceCount;
    uint32_t preferredBidirectionalCompoundReferenceNameMask;
} VkVideoEncodeAV1QualityLevelPropertiesKHR;

typedef struct VkVideoEncodeAV1SessionCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkBool32 useMaxLevel;
    StdVideoAV1Level maxLevel;
} VkVideoEncodeAV1SessionCreateInfoKHR;

typedef struct VkVideoEncodeAV1SessionParametersCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    const StdVideoAV1SequenceHeader* pStdSequenceHeader;
    const StdVideoEncodeAV1DecoderModelInfo* pStdDecoderModelInfo;
    uint32_t stdOperatingPointCount;
    const StdVideoEncodeAV1OperatingPointInfo* pStdOperatingPoints;
} VkVideoEncodeAV1SessionParametersCreateInfoKHR;

typedef struct VkVideoEncodeAV1PictureInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkVideoEncodeAV1PredictionModeKHR predictionMode;
    VkVideoEncodeAV1RateControlGroupKHR rateControlGroup;
    uint32_t constantQIndex;
    const StdVideoEncodeAV1PictureInfo* pStdPictureInfo;
    int32_t referenceNameSlotIndices[7U];
    VkBool32 primaryReferenceCdfOnly;
    VkBool32 generateObuExtensionHeader;
} VkVideoEncodeAV1PictureInfoKHR;

typedef struct VkVideoEncodeAV1DpbSlotInfoKHR {
    VkStructureType sType;
    const void* pNext;
    const StdVideoEncodeAV1ReferenceInfo* pStdReferenceInfo;
} VkVideoEncodeAV1DpbSlotInfoKHR;

typedef struct VkVideoEncodeAV1ProfileInfoKHR {
    VkStructureType sType;
    const void* pNext;
    StdVideoAV1Profile stdProfile;
} VkVideoEncodeAV1ProfileInfoKHR;

typedef struct VkVideoEncodeAV1FrameSizeKHR {
    uint32_t intraFrameSize;
    uint32_t predictiveFrameSize;
    uint32_t bipredictiveFrameSize;
} VkVideoEncodeAV1FrameSizeKHR;

typedef struct VkVideoEncodeAV1GopRemainingFrameInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkBool32 useGopRemainingFrames;
    uint32_t gopRemainingIntra;
    uint32_t gopRemainingPredictive;
    uint32_t gopRemainingBipredictive;
} VkVideoEncodeAV1GopRemainingFrameInfoKHR;

typedef struct VkVideoEncodeAV1RateControlInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkVideoEncodeAV1RateControlFlagsKHR flags;
    uint32_t gopFrameCount;
    uint32_t keyFramePeriod;
    uint32_t consecutiveBipredictiveFrameCount;
    uint32_t temporalLayerCount;
} VkVideoEncodeAV1RateControlInfoKHR;

typedef struct VkVideoEncodeAV1RateControlLayerInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkBool32 useMinQIndex;
    VkVideoEncodeAV1QIndexKHR minQIndex;
    VkBool32 useMaxQIndex;
    VkVideoEncodeAV1QIndexKHR maxQIndex;
    VkBool32 useMaxFrameSize;
    VkVideoEncodeAV1FrameSizeKHR maxFrameSize;
} VkVideoEncodeAV1RateControlLayerInfoKHR;







typedef struct VkPhysicalDeviceVideoMaintenance1FeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 videoMaintenance1;
} VkPhysicalDeviceVideoMaintenance1FeaturesKHR;

typedef struct VkVideoInlineQueryInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkQueryPool queryPool;
    uint32_t firstQuery;
    uint32_t queryCount;
} VkVideoInlineQueryInfoKHR;







typedef VkPhysicalDeviceVertexAttributeDivisorProperties VkPhysicalDeviceVertexAttributeDivisorPropertiesKHR;

typedef VkVertexInputBindingDivisorDescription VkVertexInputBindingDivisorDescriptionKHR;

typedef VkPipelineVertexInputDivisorStateCreateInfo VkPipelineVertexInputDivisorStateCreateInfoKHR;

typedef VkPhysicalDeviceVertexAttributeDivisorFeatures VkPhysicalDeviceVertexAttributeDivisorFeaturesKHR;
# 12494 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkPhysicalDeviceShaderFloatControls2Features VkPhysicalDeviceShaderFloatControls2FeaturesKHR;







typedef VkPhysicalDeviceIndexTypeUint8Features VkPhysicalDeviceIndexTypeUint8FeaturesKHR;







typedef VkLineRasterizationMode VkLineRasterizationModeKHR;

typedef VkPhysicalDeviceLineRasterizationFeatures VkPhysicalDeviceLineRasterizationFeaturesKHR;

typedef VkPhysicalDeviceLineRasterizationProperties VkPhysicalDeviceLineRasterizationPropertiesKHR;

typedef VkPipelineRasterizationLineStateCreateInfo VkPipelineRasterizationLineStateCreateInfoKHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetLineStippleKHR)(VkCommandBuffer commandBuffer, uint32_t lineStippleFactor, uint16_t lineStipplePattern);


 void __attribute__((__stdcall__)) vkCmdSetLineStippleKHR(
    VkCommandBuffer commandBuffer,
    uint32_t lineStippleFactor,
    uint16_t lineStipplePattern);
# 12533 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkTimeDomainKHR {
    VK_TIME_DOMAIN_DEVICE_KHR = 0,
    VK_TIME_DOMAIN_CLOCK_MONOTONIC_KHR = 1,
    VK_TIME_DOMAIN_CLOCK_MONOTONIC_RAW_KHR = 2,
    VK_TIME_DOMAIN_QUERY_PERFORMANCE_COUNTER_KHR = 3,
    VK_TIME_DOMAIN_DEVICE_EXT = VK_TIME_DOMAIN_DEVICE_KHR,
    VK_TIME_DOMAIN_CLOCK_MONOTONIC_EXT = VK_TIME_DOMAIN_CLOCK_MONOTONIC_KHR,
    VK_TIME_DOMAIN_CLOCK_MONOTONIC_RAW_EXT = VK_TIME_DOMAIN_CLOCK_MONOTONIC_RAW_KHR,
    VK_TIME_DOMAIN_QUERY_PERFORMANCE_COUNTER_EXT = VK_TIME_DOMAIN_QUERY_PERFORMANCE_COUNTER_KHR,
    VK_TIME_DOMAIN_MAX_ENUM_KHR = 0x7FFFFFFF
} VkTimeDomainKHR;
typedef struct VkCalibratedTimestampInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkTimeDomainKHR timeDomain;
} VkCalibratedTimestampInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceCalibrateableTimeDomainsKHR)(VkPhysicalDevice physicalDevice, uint32_t* pTimeDomainCount, VkTimeDomainKHR* pTimeDomains);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetCalibratedTimestampsKHR)(VkDevice device, uint32_t timestampCount, const VkCalibratedTimestampInfoKHR* pTimestampInfos, uint64_t* pTimestamps, uint64_t* pMaxDeviation);


 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceCalibrateableTimeDomainsKHR(
    VkPhysicalDevice physicalDevice,
    uint32_t* pTimeDomainCount,
    VkTimeDomainKHR* pTimeDomains);

 VkResult __attribute__((__stdcall__)) vkGetCalibratedTimestampsKHR(
    VkDevice device,
    uint32_t timestampCount,
    const VkCalibratedTimestampInfoKHR* pTimestampInfos,
    uint64_t* pTimestamps,
    uint64_t* pMaxDeviation);







typedef VkPhysicalDeviceShaderExpectAssumeFeatures VkPhysicalDeviceShaderExpectAssumeFeaturesKHR;







typedef VkPhysicalDeviceMaintenance6Features VkPhysicalDeviceMaintenance6FeaturesKHR;

typedef VkPhysicalDeviceMaintenance6Properties VkPhysicalDeviceMaintenance6PropertiesKHR;

typedef VkBindMemoryStatus VkBindMemoryStatusKHR;

typedef VkBindDescriptorSetsInfo VkBindDescriptorSetsInfoKHR;

typedef VkPushConstantsInfo VkPushConstantsInfoKHR;

typedef VkPushDescriptorSetInfo VkPushDescriptorSetInfoKHR;

typedef VkPushDescriptorSetWithTemplateInfo VkPushDescriptorSetWithTemplateInfoKHR;

typedef struct VkSetDescriptorBufferOffsetsInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkShaderStageFlags stageFlags;
    VkPipelineLayout layout;
    uint32_t firstSet;
    uint32_t setCount;
    const uint32_t* pBufferIndices;
    const VkDeviceSize* pOffsets;
} VkSetDescriptorBufferOffsetsInfoEXT;

typedef struct VkBindDescriptorBufferEmbeddedSamplersInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkShaderStageFlags stageFlags;
    VkPipelineLayout layout;
    uint32_t set;
} VkBindDescriptorBufferEmbeddedSamplersInfoEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBindDescriptorSets2KHR)(VkCommandBuffer commandBuffer, const VkBindDescriptorSetsInfo* pBindDescriptorSetsInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdPushConstants2KHR)(VkCommandBuffer commandBuffer, const VkPushConstantsInfo* pPushConstantsInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdPushDescriptorSet2KHR)(VkCommandBuffer commandBuffer, const VkPushDescriptorSetInfo* pPushDescriptorSetInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdPushDescriptorSetWithTemplate2KHR)(VkCommandBuffer commandBuffer, const VkPushDescriptorSetWithTemplateInfo* pPushDescriptorSetWithTemplateInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDescriptorBufferOffsets2EXT)(VkCommandBuffer commandBuffer, const VkSetDescriptorBufferOffsetsInfoEXT* pSetDescriptorBufferOffsetsInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBindDescriptorBufferEmbeddedSamplers2EXT)(VkCommandBuffer commandBuffer, const VkBindDescriptorBufferEmbeddedSamplersInfoEXT* pBindDescriptorBufferEmbeddedSamplersInfo);


 void __attribute__((__stdcall__)) vkCmdBindDescriptorSets2KHR(
    VkCommandBuffer commandBuffer,
    const VkBindDescriptorSetsInfo* pBindDescriptorSetsInfo);

 void __attribute__((__stdcall__)) vkCmdPushConstants2KHR(
    VkCommandBuffer commandBuffer,
    const VkPushConstantsInfo* pPushConstantsInfo);

 void __attribute__((__stdcall__)) vkCmdPushDescriptorSet2KHR(
    VkCommandBuffer commandBuffer,
    const VkPushDescriptorSetInfo* pPushDescriptorSetInfo);

 void __attribute__((__stdcall__)) vkCmdPushDescriptorSetWithTemplate2KHR(
    VkCommandBuffer commandBuffer,
    const VkPushDescriptorSetWithTemplateInfo* pPushDescriptorSetWithTemplateInfo);

 void __attribute__((__stdcall__)) vkCmdSetDescriptorBufferOffsets2EXT(
    VkCommandBuffer commandBuffer,
    const VkSetDescriptorBufferOffsetsInfoEXT* pSetDescriptorBufferOffsetsInfo);

 void __attribute__((__stdcall__)) vkCmdBindDescriptorBufferEmbeddedSamplers2EXT(
    VkCommandBuffer commandBuffer,
    const VkBindDescriptorBufferEmbeddedSamplersInfoEXT* pBindDescriptorBufferEmbeddedSamplersInfo);







typedef struct VkVideoEncodeQuantizationMapCapabilitiesKHR {
    VkStructureType sType;
    void* pNext;
    VkExtent2D maxQuantizationMapExtent;
} VkVideoEncodeQuantizationMapCapabilitiesKHR;

typedef struct VkVideoFormatQuantizationMapPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkExtent2D quantizationMapTexelSize;
} VkVideoFormatQuantizationMapPropertiesKHR;

typedef struct VkVideoEncodeQuantizationMapInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkImageView quantizationMap;
    VkExtent2D quantizationMapExtent;
} VkVideoEncodeQuantizationMapInfoKHR;

typedef struct VkVideoEncodeQuantizationMapSessionParametersCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkExtent2D quantizationMapTexelSize;
} VkVideoEncodeQuantizationMapSessionParametersCreateInfoKHR;

typedef struct VkPhysicalDeviceVideoEncodeQuantizationMapFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 videoEncodeQuantizationMap;
} VkPhysicalDeviceVideoEncodeQuantizationMapFeaturesKHR;

typedef struct VkVideoEncodeH264QuantizationMapCapabilitiesKHR {
    VkStructureType sType;
    void* pNext;
    int32_t minQpDelta;
    int32_t maxQpDelta;
} VkVideoEncodeH264QuantizationMapCapabilitiesKHR;

typedef struct VkVideoEncodeH265QuantizationMapCapabilitiesKHR {
    VkStructureType sType;
    void* pNext;
    int32_t minQpDelta;
    int32_t maxQpDelta;
} VkVideoEncodeH265QuantizationMapCapabilitiesKHR;

typedef struct VkVideoFormatH265QuantizationMapPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkVideoEncodeH265CtbSizeFlagsKHR compatibleCtbSizes;
} VkVideoFormatH265QuantizationMapPropertiesKHR;

typedef struct VkVideoEncodeAV1QuantizationMapCapabilitiesKHR {
    VkStructureType sType;
    void* pNext;
    int32_t minQIndexDelta;
    int32_t maxQIndexDelta;
} VkVideoEncodeAV1QuantizationMapCapabilitiesKHR;

typedef struct VkVideoFormatAV1QuantizationMapPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkVideoEncodeAV1SuperblockSizeFlagsKHR compatibleSuperblockSizes;
} VkVideoFormatAV1QuantizationMapPropertiesKHR;







typedef struct VkPhysicalDeviceShaderRelaxedExtendedInstructionFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderRelaxedExtendedInstruction;
} VkPhysicalDeviceShaderRelaxedExtendedInstructionFeaturesKHR;
# 12734 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkPhysicalDeviceLayeredApiKHR {
    VK_PHYSICAL_DEVICE_LAYERED_API_VULKAN_KHR = 0,
    VK_PHYSICAL_DEVICE_LAYERED_API_D3D12_KHR = 1,
    VK_PHYSICAL_DEVICE_LAYERED_API_METAL_KHR = 2,
    VK_PHYSICAL_DEVICE_LAYERED_API_OPENGL_KHR = 3,
    VK_PHYSICAL_DEVICE_LAYERED_API_OPENGLES_KHR = 4,
    VK_PHYSICAL_DEVICE_LAYERED_API_MAX_ENUM_KHR = 0x7FFFFFFF
} VkPhysicalDeviceLayeredApiKHR;
typedef struct VkPhysicalDeviceMaintenance7FeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 maintenance7;
} VkPhysicalDeviceMaintenance7FeaturesKHR;

typedef struct VkPhysicalDeviceMaintenance7PropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 robustFragmentShadingRateAttachmentAccess;
    VkBool32 separateDepthStencilAttachmentAccess;
    uint32_t maxDescriptorSetTotalUniformBuffersDynamic;
    uint32_t maxDescriptorSetTotalStorageBuffersDynamic;
    uint32_t maxDescriptorSetTotalBuffersDynamic;
    uint32_t maxDescriptorSetUpdateAfterBindTotalUniformBuffersDynamic;
    uint32_t maxDescriptorSetUpdateAfterBindTotalStorageBuffersDynamic;
    uint32_t maxDescriptorSetUpdateAfterBindTotalBuffersDynamic;
} VkPhysicalDeviceMaintenance7PropertiesKHR;

typedef struct VkPhysicalDeviceLayeredApiPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    uint32_t vendorID;
    uint32_t deviceID;
    VkPhysicalDeviceLayeredApiKHR layeredAPI;
    char deviceName[256U];
} VkPhysicalDeviceLayeredApiPropertiesKHR;

typedef struct VkPhysicalDeviceLayeredApiPropertiesListKHR {
    VkStructureType sType;
    void* pNext;
    uint32_t layeredApiCount;
    VkPhysicalDeviceLayeredApiPropertiesKHR* pLayeredApis;
} VkPhysicalDeviceLayeredApiPropertiesListKHR;

typedef struct VkPhysicalDeviceLayeredApiVulkanPropertiesKHR {
    VkStructureType sType;
    void* pNext;
    VkPhysicalDeviceProperties2 properties;
} VkPhysicalDeviceLayeredApiVulkanPropertiesKHR;





typedef struct VkDebugReportCallbackEXT_T *VkDebugReportCallbackEXT;



typedef enum VkDebugReportObjectTypeEXT {
    VK_DEBUG_REPORT_OBJECT_TYPE_UNKNOWN_EXT = 0,
    VK_DEBUG_REPORT_OBJECT_TYPE_INSTANCE_EXT = 1,
    VK_DEBUG_REPORT_OBJECT_TYPE_PHYSICAL_DEVICE_EXT = 2,
    VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_EXT = 3,
    VK_DEBUG_REPORT_OBJECT_TYPE_QUEUE_EXT = 4,
    VK_DEBUG_REPORT_OBJECT_TYPE_SEMAPHORE_EXT = 5,
    VK_DEBUG_REPORT_OBJECT_TYPE_COMMAND_BUFFER_EXT = 6,
    VK_DEBUG_REPORT_OBJECT_TYPE_FENCE_EXT = 7,
    VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_MEMORY_EXT = 8,
    VK_DEBUG_REPORT_OBJECT_TYPE_BUFFER_EXT = 9,
    VK_DEBUG_REPORT_OBJECT_TYPE_IMAGE_EXT = 10,
    VK_DEBUG_REPORT_OBJECT_TYPE_EVENT_EXT = 11,
    VK_DEBUG_REPORT_OBJECT_TYPE_QUERY_POOL_EXT = 12,
    VK_DEBUG_REPORT_OBJECT_TYPE_BUFFER_VIEW_EXT = 13,
    VK_DEBUG_REPORT_OBJECT_TYPE_IMAGE_VIEW_EXT = 14,
    VK_DEBUG_REPORT_OBJECT_TYPE_SHADER_MODULE_EXT = 15,
    VK_DEBUG_REPORT_OBJECT_TYPE_PIPELINE_CACHE_EXT = 16,
    VK_DEBUG_REPORT_OBJECT_TYPE_PIPELINE_LAYOUT_EXT = 17,
    VK_DEBUG_REPORT_OBJECT_TYPE_RENDER_PASS_EXT = 18,
    VK_DEBUG_REPORT_OBJECT_TYPE_PIPELINE_EXT = 19,
    VK_DEBUG_REPORT_OBJECT_TYPE_DESCRIPTOR_SET_LAYOUT_EXT = 20,
    VK_DEBUG_REPORT_OBJECT_TYPE_SAMPLER_EXT = 21,
    VK_DEBUG_REPORT_OBJECT_TYPE_DESCRIPTOR_POOL_EXT = 22,
    VK_DEBUG_REPORT_OBJECT_TYPE_DESCRIPTOR_SET_EXT = 23,
    VK_DEBUG_REPORT_OBJECT_TYPE_FRAMEBUFFER_EXT = 24,
    VK_DEBUG_REPORT_OBJECT_TYPE_COMMAND_POOL_EXT = 25,
    VK_DEBUG_REPORT_OBJECT_TYPE_SURFACE_KHR_EXT = 26,
    VK_DEBUG_REPORT_OBJECT_TYPE_SWAPCHAIN_KHR_EXT = 27,
    VK_DEBUG_REPORT_OBJECT_TYPE_DEBUG_REPORT_CALLBACK_EXT_EXT = 28,
    VK_DEBUG_REPORT_OBJECT_TYPE_DISPLAY_KHR_EXT = 29,
    VK_DEBUG_REPORT_OBJECT_TYPE_DISPLAY_MODE_KHR_EXT = 30,
    VK_DEBUG_REPORT_OBJECT_TYPE_VALIDATION_CACHE_EXT_EXT = 33,
    VK_DEBUG_REPORT_OBJECT_TYPE_SAMPLER_YCBCR_CONVERSION_EXT = 1000156000,
    VK_DEBUG_REPORT_OBJECT_TYPE_DESCRIPTOR_UPDATE_TEMPLATE_EXT = 1000085000,
    VK_DEBUG_REPORT_OBJECT_TYPE_CU_MODULE_NVX_EXT = 1000029000,
    VK_DEBUG_REPORT_OBJECT_TYPE_CU_FUNCTION_NVX_EXT = 1000029001,
    VK_DEBUG_REPORT_OBJECT_TYPE_ACCELERATION_STRUCTURE_KHR_EXT = 1000150000,
    VK_DEBUG_REPORT_OBJECT_TYPE_ACCELERATION_STRUCTURE_NV_EXT = 1000165000,
    VK_DEBUG_REPORT_OBJECT_TYPE_CUDA_MODULE_NV_EXT = 1000307000,
    VK_DEBUG_REPORT_OBJECT_TYPE_CUDA_FUNCTION_NV_EXT = 1000307001,
    VK_DEBUG_REPORT_OBJECT_TYPE_BUFFER_COLLECTION_FUCHSIA_EXT = 1000366000,

    VK_DEBUG_REPORT_OBJECT_TYPE_DEBUG_REPORT_EXT = VK_DEBUG_REPORT_OBJECT_TYPE_DEBUG_REPORT_CALLBACK_EXT_EXT,

    VK_DEBUG_REPORT_OBJECT_TYPE_VALIDATION_CACHE_EXT = VK_DEBUG_REPORT_OBJECT_TYPE_VALIDATION_CACHE_EXT_EXT,
    VK_DEBUG_REPORT_OBJECT_TYPE_DESCRIPTOR_UPDATE_TEMPLATE_KHR_EXT = VK_DEBUG_REPORT_OBJECT_TYPE_DESCRIPTOR_UPDATE_TEMPLATE_EXT,
    VK_DEBUG_REPORT_OBJECT_TYPE_SAMPLER_YCBCR_CONVERSION_KHR_EXT = VK_DEBUG_REPORT_OBJECT_TYPE_SAMPLER_YCBCR_CONVERSION_EXT,
    VK_DEBUG_REPORT_OBJECT_TYPE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkDebugReportObjectTypeEXT;

typedef enum VkDebugReportFlagBitsEXT {
    VK_DEBUG_REPORT_INFORMATION_BIT_EXT = 0x00000001,
    VK_DEBUG_REPORT_WARNING_BIT_EXT = 0x00000002,
    VK_DEBUG_REPORT_PERFORMANCE_WARNING_BIT_EXT = 0x00000004,
    VK_DEBUG_REPORT_ERROR_BIT_EXT = 0x00000008,
    VK_DEBUG_REPORT_DEBUG_BIT_EXT = 0x00000010,
    VK_DEBUG_REPORT_FLAG_BITS_MAX_ENUM_EXT = 0x7FFFFFFF
} VkDebugReportFlagBitsEXT;
typedef VkFlags VkDebugReportFlagsEXT;
typedef VkBool32 (__attribute__((__stdcall__)) *PFN_vkDebugReportCallbackEXT)(
    VkDebugReportFlagsEXT flags,
    VkDebugReportObjectTypeEXT objectType,
    uint64_t object,
    size_t location,
    int32_t messageCode,
    const char* pLayerPrefix,
    const char* pMessage,
    void* pUserData);

typedef struct VkDebugReportCallbackCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkDebugReportFlagsEXT flags;
    PFN_vkDebugReportCallbackEXT pfnCallback;
    void* pUserData;
} VkDebugReportCallbackCreateInfoEXT;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateDebugReportCallbackEXT)(VkInstance instance, const VkDebugReportCallbackCreateInfoEXT* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDebugReportCallbackEXT* pCallback);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyDebugReportCallbackEXT)(VkInstance instance, VkDebugReportCallbackEXT callback, const VkAllocationCallbacks* pAllocator);
typedef void (__attribute__((__stdcall__)) *PFN_vkDebugReportMessageEXT)(VkInstance instance, VkDebugReportFlagsEXT flags, VkDebugReportObjectTypeEXT objectType, uint64_t object, size_t location, int32_t messageCode, const char* pLayerPrefix, const char* pMessage);


 VkResult __attribute__((__stdcall__)) vkCreateDebugReportCallbackEXT(
    VkInstance instance,
    const VkDebugReportCallbackCreateInfoEXT* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkDebugReportCallbackEXT* pCallback);

 void __attribute__((__stdcall__)) vkDestroyDebugReportCallbackEXT(
    VkInstance instance,
    VkDebugReportCallbackEXT callback,
    const VkAllocationCallbacks* pAllocator);

 void __attribute__((__stdcall__)) vkDebugReportMessageEXT(
    VkInstance instance,
    VkDebugReportFlagsEXT flags,
    VkDebugReportObjectTypeEXT objectType,
    uint64_t object,
    size_t location,
    int32_t messageCode,
    const char* pLayerPrefix,
    const char* pMessage);
# 12920 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkRasterizationOrderAMD {
    VK_RASTERIZATION_ORDER_STRICT_AMD = 0,
    VK_RASTERIZATION_ORDER_RELAXED_AMD = 1,
    VK_RASTERIZATION_ORDER_MAX_ENUM_AMD = 0x7FFFFFFF
} VkRasterizationOrderAMD;
typedef struct VkPipelineRasterizationStateRasterizationOrderAMD {
    VkStructureType sType;
    const void* pNext;
    VkRasterizationOrderAMD rasterizationOrder;
} VkPipelineRasterizationStateRasterizationOrderAMD;
# 12949 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkDebugMarkerObjectNameInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkDebugReportObjectTypeEXT objectType;
    uint64_t object;
    const char* pObjectName;
} VkDebugMarkerObjectNameInfoEXT;

typedef struct VkDebugMarkerObjectTagInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkDebugReportObjectTypeEXT objectType;
    uint64_t object;
    uint64_t tagName;
    size_t tagSize;
    const void* pTag;
} VkDebugMarkerObjectTagInfoEXT;

typedef struct VkDebugMarkerMarkerInfoEXT {
    VkStructureType sType;
    const void* pNext;
    const char* pMarkerName;
    float color[4];
} VkDebugMarkerMarkerInfoEXT;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkDebugMarkerSetObjectTagEXT)(VkDevice device, const VkDebugMarkerObjectTagInfoEXT* pTagInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkDebugMarkerSetObjectNameEXT)(VkDevice device, const VkDebugMarkerObjectNameInfoEXT* pNameInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDebugMarkerBeginEXT)(VkCommandBuffer commandBuffer, const VkDebugMarkerMarkerInfoEXT* pMarkerInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDebugMarkerEndEXT)(VkCommandBuffer commandBuffer);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDebugMarkerInsertEXT)(VkCommandBuffer commandBuffer, const VkDebugMarkerMarkerInfoEXT* pMarkerInfo);


 VkResult __attribute__((__stdcall__)) vkDebugMarkerSetObjectTagEXT(
    VkDevice device,
    const VkDebugMarkerObjectTagInfoEXT* pTagInfo);

 VkResult __attribute__((__stdcall__)) vkDebugMarkerSetObjectNameEXT(
    VkDevice device,
    const VkDebugMarkerObjectNameInfoEXT* pNameInfo);

 void __attribute__((__stdcall__)) vkCmdDebugMarkerBeginEXT(
    VkCommandBuffer commandBuffer,
    const VkDebugMarkerMarkerInfoEXT* pMarkerInfo);

 void __attribute__((__stdcall__)) vkCmdDebugMarkerEndEXT(
    VkCommandBuffer commandBuffer);

 void __attribute__((__stdcall__)) vkCmdDebugMarkerInsertEXT(
    VkCommandBuffer commandBuffer,
    const VkDebugMarkerMarkerInfoEXT* pMarkerInfo);
# 13012 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkDedicatedAllocationImageCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkBool32 dedicatedAllocation;
} VkDedicatedAllocationImageCreateInfoNV;

typedef struct VkDedicatedAllocationBufferCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkBool32 dedicatedAllocation;
} VkDedicatedAllocationBufferCreateInfoNV;

typedef struct VkDedicatedAllocationMemoryAllocateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkImage image;
    VkBuffer buffer;
} VkDedicatedAllocationMemoryAllocateInfoNV;







typedef VkFlags VkPipelineRasterizationStateStreamCreateFlagsEXT;
typedef struct VkPhysicalDeviceTransformFeedbackFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 transformFeedback;
    VkBool32 geometryStreams;
} VkPhysicalDeviceTransformFeedbackFeaturesEXT;

typedef struct VkPhysicalDeviceTransformFeedbackPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    uint32_t maxTransformFeedbackStreams;
    uint32_t maxTransformFeedbackBuffers;
    VkDeviceSize maxTransformFeedbackBufferSize;
    uint32_t maxTransformFeedbackStreamDataSize;
    uint32_t maxTransformFeedbackBufferDataSize;
    uint32_t maxTransformFeedbackBufferDataStride;
    VkBool32 transformFeedbackQueries;
    VkBool32 transformFeedbackStreamsLinesTriangles;
    VkBool32 transformFeedbackRasterizationStreamSelect;
    VkBool32 transformFeedbackDraw;
} VkPhysicalDeviceTransformFeedbackPropertiesEXT;

typedef struct VkPipelineRasterizationStateStreamCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkPipelineRasterizationStateStreamCreateFlagsEXT flags;
    uint32_t rasterizationStream;
} VkPipelineRasterizationStateStreamCreateInfoEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBindTransformFeedbackBuffersEXT)(VkCommandBuffer commandBuffer, uint32_t firstBinding, uint32_t bindingCount, const VkBuffer* pBuffers, const VkDeviceSize* pOffsets, const VkDeviceSize* pSizes);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBeginTransformFeedbackEXT)(VkCommandBuffer commandBuffer, uint32_t firstCounterBuffer, uint32_t counterBufferCount, const VkBuffer* pCounterBuffers, const VkDeviceSize* pCounterBufferOffsets);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdEndTransformFeedbackEXT)(VkCommandBuffer commandBuffer, uint32_t firstCounterBuffer, uint32_t counterBufferCount, const VkBuffer* pCounterBuffers, const VkDeviceSize* pCounterBufferOffsets);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBeginQueryIndexedEXT)(VkCommandBuffer commandBuffer, VkQueryPool queryPool, uint32_t query, VkQueryControlFlags flags, uint32_t index);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdEndQueryIndexedEXT)(VkCommandBuffer commandBuffer, VkQueryPool queryPool, uint32_t query, uint32_t index);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawIndirectByteCountEXT)(VkCommandBuffer commandBuffer, uint32_t instanceCount, uint32_t firstInstance, VkBuffer counterBuffer, VkDeviceSize counterBufferOffset, uint32_t counterOffset, uint32_t vertexStride);


 void __attribute__((__stdcall__)) vkCmdBindTransformFeedbackBuffersEXT(
    VkCommandBuffer commandBuffer,
    uint32_t firstBinding,
    uint32_t bindingCount,
    const VkBuffer* pBuffers,
    const VkDeviceSize* pOffsets,
    const VkDeviceSize* pSizes);

 void __attribute__((__stdcall__)) vkCmdBeginTransformFeedbackEXT(
    VkCommandBuffer commandBuffer,
    uint32_t firstCounterBuffer,
    uint32_t counterBufferCount,
    const VkBuffer* pCounterBuffers,
    const VkDeviceSize* pCounterBufferOffsets);

 void __attribute__((__stdcall__)) vkCmdEndTransformFeedbackEXT(
    VkCommandBuffer commandBuffer,
    uint32_t firstCounterBuffer,
    uint32_t counterBufferCount,
    const VkBuffer* pCounterBuffers,
    const VkDeviceSize* pCounterBufferOffsets);

 void __attribute__((__stdcall__)) vkCmdBeginQueryIndexedEXT(
    VkCommandBuffer commandBuffer,
    VkQueryPool queryPool,
    uint32_t query,
    VkQueryControlFlags flags,
    uint32_t index);

 void __attribute__((__stdcall__)) vkCmdEndQueryIndexedEXT(
    VkCommandBuffer commandBuffer,
    VkQueryPool queryPool,
    uint32_t query,
    uint32_t index);

 void __attribute__((__stdcall__)) vkCmdDrawIndirectByteCountEXT(
    VkCommandBuffer commandBuffer,
    uint32_t instanceCount,
    uint32_t firstInstance,
    VkBuffer counterBuffer,
    VkDeviceSize counterBufferOffset,
    uint32_t counterOffset,
    uint32_t vertexStride);





typedef struct VkCuModuleNVX_T *VkCuModuleNVX;
typedef struct VkCuFunctionNVX_T *VkCuFunctionNVX;


typedef struct VkCuModuleCreateInfoNVX {
    VkStructureType sType;
    const void* pNext;
    size_t dataSize;
    const void* pData;
} VkCuModuleCreateInfoNVX;

typedef struct VkCuModuleTexturingModeCreateInfoNVX {
    VkStructureType sType;
    const void* pNext;
    VkBool32 use64bitTexturing;
} VkCuModuleTexturingModeCreateInfoNVX;

typedef struct VkCuFunctionCreateInfoNVX {
    VkStructureType sType;
    const void* pNext;
    VkCuModuleNVX module;
    const char* pName;
} VkCuFunctionCreateInfoNVX;

typedef struct VkCuLaunchInfoNVX {
    VkStructureType sType;
    const void* pNext;
    VkCuFunctionNVX function;
    uint32_t gridDimX;
    uint32_t gridDimY;
    uint32_t gridDimZ;
    uint32_t blockDimX;
    uint32_t blockDimY;
    uint32_t blockDimZ;
    uint32_t sharedMemBytes;
    size_t paramCount;
    const void* const * pParams;
    size_t extraCount;
    const void* const * pExtras;
} VkCuLaunchInfoNVX;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateCuModuleNVX)(VkDevice device, const VkCuModuleCreateInfoNVX* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkCuModuleNVX* pModule);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateCuFunctionNVX)(VkDevice device, const VkCuFunctionCreateInfoNVX* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkCuFunctionNVX* pFunction);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyCuModuleNVX)(VkDevice device, VkCuModuleNVX module, const VkAllocationCallbacks* pAllocator);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyCuFunctionNVX)(VkDevice device, VkCuFunctionNVX function, const VkAllocationCallbacks* pAllocator);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCuLaunchKernelNVX)(VkCommandBuffer commandBuffer, const VkCuLaunchInfoNVX* pLaunchInfo);


 VkResult __attribute__((__stdcall__)) vkCreateCuModuleNVX(
    VkDevice device,
    const VkCuModuleCreateInfoNVX* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkCuModuleNVX* pModule);

 VkResult __attribute__((__stdcall__)) vkCreateCuFunctionNVX(
    VkDevice device,
    const VkCuFunctionCreateInfoNVX* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkCuFunctionNVX* pFunction);

 void __attribute__((__stdcall__)) vkDestroyCuModuleNVX(
    VkDevice device,
    VkCuModuleNVX module,
    const VkAllocationCallbacks* pAllocator);

 void __attribute__((__stdcall__)) vkDestroyCuFunctionNVX(
    VkDevice device,
    VkCuFunctionNVX function,
    const VkAllocationCallbacks* pAllocator);

 void __attribute__((__stdcall__)) vkCmdCuLaunchKernelNVX(
    VkCommandBuffer commandBuffer,
    const VkCuLaunchInfoNVX* pLaunchInfo);







typedef struct VkImageViewHandleInfoNVX {
    VkStructureType sType;
    const void* pNext;
    VkImageView imageView;
    VkDescriptorType descriptorType;
    VkSampler sampler;
} VkImageViewHandleInfoNVX;

typedef struct VkImageViewAddressPropertiesNVX {
    VkStructureType sType;
    void* pNext;
    VkDeviceAddress deviceAddress;
    VkDeviceSize size;
} VkImageViewAddressPropertiesNVX;

typedef uint32_t (__attribute__((__stdcall__)) *PFN_vkGetImageViewHandleNVX)(VkDevice device, const VkImageViewHandleInfoNVX* pInfo);
typedef uint64_t (__attribute__((__stdcall__)) *PFN_vkGetImageViewHandle64NVX)(VkDevice device, const VkImageViewHandleInfoNVX* pInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetImageViewAddressNVX)(VkDevice device, VkImageView imageView, VkImageViewAddressPropertiesNVX* pProperties);


 uint32_t __attribute__((__stdcall__)) vkGetImageViewHandleNVX(
    VkDevice device,
    const VkImageViewHandleInfoNVX* pInfo);

 uint64_t __attribute__((__stdcall__)) vkGetImageViewHandle64NVX(
    VkDevice device,
    const VkImageViewHandleInfoNVX* pInfo);

 VkResult __attribute__((__stdcall__)) vkGetImageViewAddressNVX(
    VkDevice device,
    VkImageView imageView,
    VkImageViewAddressPropertiesNVX* pProperties);







typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawIndirectCountAMD)(VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawIndexedIndirectCountAMD)(VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride);


 void __attribute__((__stdcall__)) vkCmdDrawIndirectCountAMD(
    VkCommandBuffer commandBuffer,
    VkBuffer buffer,
    VkDeviceSize offset,
    VkBuffer countBuffer,
    VkDeviceSize countBufferOffset,
    uint32_t maxDrawCount,
    uint32_t stride);

 void __attribute__((__stdcall__)) vkCmdDrawIndexedIndirectCountAMD(
    VkCommandBuffer commandBuffer,
    VkBuffer buffer,
    VkDeviceSize offset,
    VkBuffer countBuffer,
    VkDeviceSize countBufferOffset,
    uint32_t maxDrawCount,
    uint32_t stride);
# 13288 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkTextureLODGatherFormatPropertiesAMD {
    VkStructureType sType;
    void* pNext;
    VkBool32 supportsTextureGatherLODBiasAMD;
} VkTextureLODGatherFormatPropertiesAMD;
# 13301 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkShaderInfoTypeAMD {
    VK_SHADER_INFO_TYPE_STATISTICS_AMD = 0,
    VK_SHADER_INFO_TYPE_BINARY_AMD = 1,
    VK_SHADER_INFO_TYPE_DISASSEMBLY_AMD = 2,
    VK_SHADER_INFO_TYPE_MAX_ENUM_AMD = 0x7FFFFFFF
} VkShaderInfoTypeAMD;
typedef struct VkShaderResourceUsageAMD {
    uint32_t numUsedVgprs;
    uint32_t numUsedSgprs;
    uint32_t ldsSizePerLocalWorkGroup;
    size_t ldsUsageSizeInBytes;
    size_t scratchMemUsageInBytes;
} VkShaderResourceUsageAMD;

typedef struct VkShaderStatisticsInfoAMD {
    VkShaderStageFlags shaderStageMask;
    VkShaderResourceUsageAMD resourceUsage;
    uint32_t numPhysicalVgprs;
    uint32_t numPhysicalSgprs;
    uint32_t numAvailableVgprs;
    uint32_t numAvailableSgprs;
    uint32_t computeWorkGroupSize[3];
} VkShaderStatisticsInfoAMD;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetShaderInfoAMD)(VkDevice device, VkPipeline pipeline, VkShaderStageFlagBits shaderStage, VkShaderInfoTypeAMD infoType, size_t* pInfoSize, void* pInfo);


 VkResult __attribute__((__stdcall__)) vkGetShaderInfoAMD(
    VkDevice device,
    VkPipeline pipeline,
    VkShaderStageFlagBits shaderStage,
    VkShaderInfoTypeAMD infoType,
    size_t* pInfoSize,
    void* pInfo);
# 13348 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkPhysicalDeviceCornerSampledImageFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 cornerSampledImage;
} VkPhysicalDeviceCornerSampledImageFeaturesNV;
# 13367 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkExternalMemoryHandleTypeFlagBitsNV {
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_BIT_NV = 0x00000001,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT_NV = 0x00000002,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_IMAGE_BIT_NV = 0x00000004,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_IMAGE_KMT_BIT_NV = 0x00000008,
    VK_EXTERNAL_MEMORY_HANDLE_TYPE_FLAG_BITS_MAX_ENUM_NV = 0x7FFFFFFF
} VkExternalMemoryHandleTypeFlagBitsNV;
typedef VkFlags VkExternalMemoryHandleTypeFlagsNV;

typedef enum VkExternalMemoryFeatureFlagBitsNV {
    VK_EXTERNAL_MEMORY_FEATURE_DEDICATED_ONLY_BIT_NV = 0x00000001,
    VK_EXTERNAL_MEMORY_FEATURE_EXPORTABLE_BIT_NV = 0x00000002,
    VK_EXTERNAL_MEMORY_FEATURE_IMPORTABLE_BIT_NV = 0x00000004,
    VK_EXTERNAL_MEMORY_FEATURE_FLAG_BITS_MAX_ENUM_NV = 0x7FFFFFFF
} VkExternalMemoryFeatureFlagBitsNV;
typedef VkFlags VkExternalMemoryFeatureFlagsNV;
typedef struct VkExternalImageFormatPropertiesNV {
    VkImageFormatProperties imageFormatProperties;
    VkExternalMemoryFeatureFlagsNV externalMemoryFeatures;
    VkExternalMemoryHandleTypeFlagsNV exportFromImportedHandleTypes;
    VkExternalMemoryHandleTypeFlagsNV compatibleHandleTypes;
} VkExternalImageFormatPropertiesNV;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceExternalImageFormatPropertiesNV)(VkPhysicalDevice physicalDevice, VkFormat format, VkImageType type, VkImageTiling tiling, VkImageUsageFlags usage, VkImageCreateFlags flags, VkExternalMemoryHandleTypeFlagsNV externalHandleType, VkExternalImageFormatPropertiesNV* pExternalImageFormatProperties);


 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceExternalImageFormatPropertiesNV(
    VkPhysicalDevice physicalDevice,
    VkFormat format,
    VkImageType type,
    VkImageTiling tiling,
    VkImageUsageFlags usage,
    VkImageCreateFlags flags,
    VkExternalMemoryHandleTypeFlagsNV externalHandleType,
    VkExternalImageFormatPropertiesNV* pExternalImageFormatProperties);







typedef struct VkExternalMemoryImageCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkExternalMemoryHandleTypeFlagsNV handleTypes;
} VkExternalMemoryImageCreateInfoNV;

typedef struct VkExportMemoryAllocateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkExternalMemoryHandleTypeFlagsNV handleTypes;
} VkExportMemoryAllocateInfoNV;
# 13428 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkValidationCheckEXT {
    VK_VALIDATION_CHECK_ALL_EXT = 0,
    VK_VALIDATION_CHECK_SHADERS_EXT = 1,
    VK_VALIDATION_CHECK_MAX_ENUM_EXT = 0x7FFFFFFF
} VkValidationCheckEXT;
typedef struct VkValidationFlagsEXT {
    VkStructureType sType;
    const void* pNext;
    uint32_t disabledValidationCheckCount;
    const VkValidationCheckEXT* pDisabledValidationChecks;
} VkValidationFlagsEXT;
# 13458 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkPhysicalDeviceTextureCompressionASTCHDRFeatures VkPhysicalDeviceTextureCompressionASTCHDRFeaturesEXT;







typedef struct VkImageViewASTCDecodeModeEXT {
    VkStructureType sType;
    const void* pNext;
    VkFormat decodeMode;
} VkImageViewASTCDecodeModeEXT;

typedef struct VkPhysicalDeviceASTCDecodeFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 decodeModeSharedExponent;
} VkPhysicalDeviceASTCDecodeFeaturesEXT;







typedef VkPipelineRobustnessBufferBehavior VkPipelineRobustnessBufferBehaviorEXT;

typedef VkPipelineRobustnessImageBehavior VkPipelineRobustnessImageBehaviorEXT;

typedef VkPhysicalDevicePipelineRobustnessFeatures VkPhysicalDevicePipelineRobustnessFeaturesEXT;

typedef VkPhysicalDevicePipelineRobustnessProperties VkPhysicalDevicePipelineRobustnessPropertiesEXT;

typedef VkPipelineRobustnessCreateInfo VkPipelineRobustnessCreateInfoEXT;
# 13501 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkConditionalRenderingFlagBitsEXT {
    VK_CONDITIONAL_RENDERING_INVERTED_BIT_EXT = 0x00000001,
    VK_CONDITIONAL_RENDERING_FLAG_BITS_MAX_ENUM_EXT = 0x7FFFFFFF
} VkConditionalRenderingFlagBitsEXT;
typedef VkFlags VkConditionalRenderingFlagsEXT;
typedef struct VkConditionalRenderingBeginInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkBuffer buffer;
    VkDeviceSize offset;
    VkConditionalRenderingFlagsEXT flags;
} VkConditionalRenderingBeginInfoEXT;

typedef struct VkPhysicalDeviceConditionalRenderingFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 conditionalRendering;
    VkBool32 inheritedConditionalRendering;
} VkPhysicalDeviceConditionalRenderingFeaturesEXT;

typedef struct VkCommandBufferInheritanceConditionalRenderingInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkBool32 conditionalRenderingEnable;
} VkCommandBufferInheritanceConditionalRenderingInfoEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBeginConditionalRenderingEXT)(VkCommandBuffer commandBuffer, const VkConditionalRenderingBeginInfoEXT* pConditionalRenderingBegin);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdEndConditionalRenderingEXT)(VkCommandBuffer commandBuffer);


 void __attribute__((__stdcall__)) vkCmdBeginConditionalRenderingEXT(
    VkCommandBuffer commandBuffer,
    const VkConditionalRenderingBeginInfoEXT* pConditionalRenderingBegin);

 void __attribute__((__stdcall__)) vkCmdEndConditionalRenderingEXT(
    VkCommandBuffer commandBuffer);







typedef struct VkViewportWScalingNV {
    float xcoeff;
    float ycoeff;
} VkViewportWScalingNV;

typedef struct VkPipelineViewportWScalingStateCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkBool32 viewportWScalingEnable;
    uint32_t viewportCount;
    const VkViewportWScalingNV* pViewportWScalings;
} VkPipelineViewportWScalingStateCreateInfoNV;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetViewportWScalingNV)(VkCommandBuffer commandBuffer, uint32_t firstViewport, uint32_t viewportCount, const VkViewportWScalingNV* pViewportWScalings);


 void __attribute__((__stdcall__)) vkCmdSetViewportWScalingNV(
    VkCommandBuffer commandBuffer,
    uint32_t firstViewport,
    uint32_t viewportCount,
    const VkViewportWScalingNV* pViewportWScalings);







typedef VkResult (__attribute__((__stdcall__)) *PFN_vkReleaseDisplayEXT)(VkPhysicalDevice physicalDevice, VkDisplayKHR display);


 VkResult __attribute__((__stdcall__)) vkReleaseDisplayEXT(
    VkPhysicalDevice physicalDevice,
    VkDisplayKHR display);
# 13586 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkSurfaceCounterFlagBitsEXT {
    VK_SURFACE_COUNTER_VBLANK_BIT_EXT = 0x00000001,

    VK_SURFACE_COUNTER_VBLANK_EXT = VK_SURFACE_COUNTER_VBLANK_BIT_EXT,
    VK_SURFACE_COUNTER_FLAG_BITS_MAX_ENUM_EXT = 0x7FFFFFFF
} VkSurfaceCounterFlagBitsEXT;
typedef VkFlags VkSurfaceCounterFlagsEXT;
typedef struct VkSurfaceCapabilities2EXT {
    VkStructureType sType;
    void* pNext;
    uint32_t minImageCount;
    uint32_t maxImageCount;
    VkExtent2D currentExtent;
    VkExtent2D minImageExtent;
    VkExtent2D maxImageExtent;
    uint32_t maxImageArrayLayers;
    VkSurfaceTransformFlagsKHR supportedTransforms;
    VkSurfaceTransformFlagBitsKHR currentTransform;
    VkCompositeAlphaFlagsKHR supportedCompositeAlpha;
    VkImageUsageFlags supportedUsageFlags;
    VkSurfaceCounterFlagsEXT supportedSurfaceCounters;
} VkSurfaceCapabilities2EXT;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceSurfaceCapabilities2EXT)(VkPhysicalDevice physicalDevice, VkSurfaceKHR surface, VkSurfaceCapabilities2EXT* pSurfaceCapabilities);


 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceSurfaceCapabilities2EXT(
    VkPhysicalDevice physicalDevice,
    VkSurfaceKHR surface,
    VkSurfaceCapabilities2EXT* pSurfaceCapabilities);
# 13624 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkDisplayPowerStateEXT {
    VK_DISPLAY_POWER_STATE_OFF_EXT = 0,
    VK_DISPLAY_POWER_STATE_SUSPEND_EXT = 1,
    VK_DISPLAY_POWER_STATE_ON_EXT = 2,
    VK_DISPLAY_POWER_STATE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkDisplayPowerStateEXT;

typedef enum VkDeviceEventTypeEXT {
    VK_DEVICE_EVENT_TYPE_DISPLAY_HOTPLUG_EXT = 0,
    VK_DEVICE_EVENT_TYPE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkDeviceEventTypeEXT;

typedef enum VkDisplayEventTypeEXT {
    VK_DISPLAY_EVENT_TYPE_FIRST_PIXEL_OUT_EXT = 0,
    VK_DISPLAY_EVENT_TYPE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkDisplayEventTypeEXT;
typedef struct VkDisplayPowerInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkDisplayPowerStateEXT powerState;
} VkDisplayPowerInfoEXT;

typedef struct VkDeviceEventInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkDeviceEventTypeEXT deviceEvent;
} VkDeviceEventInfoEXT;

typedef struct VkDisplayEventInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkDisplayEventTypeEXT displayEvent;
} VkDisplayEventInfoEXT;

typedef struct VkSwapchainCounterCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkSurfaceCounterFlagsEXT surfaceCounters;
} VkSwapchainCounterCreateInfoEXT;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkDisplayPowerControlEXT)(VkDevice device, VkDisplayKHR display, const VkDisplayPowerInfoEXT* pDisplayPowerInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkRegisterDeviceEventEXT)(VkDevice device, const VkDeviceEventInfoEXT* pDeviceEventInfo, const VkAllocationCallbacks* pAllocator, VkFence* pFence);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkRegisterDisplayEventEXT)(VkDevice device, VkDisplayKHR display, const VkDisplayEventInfoEXT* pDisplayEventInfo, const VkAllocationCallbacks* pAllocator, VkFence* pFence);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetSwapchainCounterEXT)(VkDevice device, VkSwapchainKHR swapchain, VkSurfaceCounterFlagBitsEXT counter, uint64_t* pCounterValue);


 VkResult __attribute__((__stdcall__)) vkDisplayPowerControlEXT(
    VkDevice device,
    VkDisplayKHR display,
    const VkDisplayPowerInfoEXT* pDisplayPowerInfo);

 VkResult __attribute__((__stdcall__)) vkRegisterDeviceEventEXT(
    VkDevice device,
    const VkDeviceEventInfoEXT* pDeviceEventInfo,
    const VkAllocationCallbacks* pAllocator,
    VkFence* pFence);

 VkResult __attribute__((__stdcall__)) vkRegisterDisplayEventEXT(
    VkDevice device,
    VkDisplayKHR display,
    const VkDisplayEventInfoEXT* pDisplayEventInfo,
    const VkAllocationCallbacks* pAllocator,
    VkFence* pFence);

 VkResult __attribute__((__stdcall__)) vkGetSwapchainCounterEXT(
    VkDevice device,
    VkSwapchainKHR swapchain,
    VkSurfaceCounterFlagBitsEXT counter,
    uint64_t* pCounterValue);







typedef struct VkRefreshCycleDurationGOOGLE {
    uint64_t refreshDuration;
} VkRefreshCycleDurationGOOGLE;

typedef struct VkPastPresentationTimingGOOGLE {
    uint32_t presentID;
    uint64_t desiredPresentTime;
    uint64_t actualPresentTime;
    uint64_t earliestPresentTime;
    uint64_t presentMargin;
} VkPastPresentationTimingGOOGLE;

typedef struct VkPresentTimeGOOGLE {
    uint32_t presentID;
    uint64_t desiredPresentTime;
} VkPresentTimeGOOGLE;

typedef struct VkPresentTimesInfoGOOGLE {
    VkStructureType sType;
    const void* pNext;
    uint32_t swapchainCount;
    const VkPresentTimeGOOGLE* pTimes;
} VkPresentTimesInfoGOOGLE;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetRefreshCycleDurationGOOGLE)(VkDevice device, VkSwapchainKHR swapchain, VkRefreshCycleDurationGOOGLE* pDisplayTimingProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPastPresentationTimingGOOGLE)(VkDevice device, VkSwapchainKHR swapchain, uint32_t* pPresentationTimingCount, VkPastPresentationTimingGOOGLE* pPresentationTimings);


 VkResult __attribute__((__stdcall__)) vkGetRefreshCycleDurationGOOGLE(
    VkDevice device,
    VkSwapchainKHR swapchain,
    VkRefreshCycleDurationGOOGLE* pDisplayTimingProperties);

 VkResult __attribute__((__stdcall__)) vkGetPastPresentationTimingGOOGLE(
    VkDevice device,
    VkSwapchainKHR swapchain,
    uint32_t* pPresentationTimingCount,
    VkPastPresentationTimingGOOGLE* pPresentationTimings);
# 13767 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkPhysicalDeviceMultiviewPerViewAttributesPropertiesNVX {
    VkStructureType sType;
    void* pNext;
    VkBool32 perViewPositionAllComponents;
} VkPhysicalDeviceMultiviewPerViewAttributesPropertiesNVX;

typedef struct VkMultiviewPerViewAttributesInfoNVX {
    VkStructureType sType;
    const void* pNext;
    VkBool32 perViewAttributes;
    VkBool32 perViewAttributesPositionXOnly;
} VkMultiviewPerViewAttributesInfoNVX;
# 13787 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkViewportCoordinateSwizzleNV {
    VK_VIEWPORT_COORDINATE_SWIZZLE_POSITIVE_X_NV = 0,
    VK_VIEWPORT_COORDINATE_SWIZZLE_NEGATIVE_X_NV = 1,
    VK_VIEWPORT_COORDINATE_SWIZZLE_POSITIVE_Y_NV = 2,
    VK_VIEWPORT_COORDINATE_SWIZZLE_NEGATIVE_Y_NV = 3,
    VK_VIEWPORT_COORDINATE_SWIZZLE_POSITIVE_Z_NV = 4,
    VK_VIEWPORT_COORDINATE_SWIZZLE_NEGATIVE_Z_NV = 5,
    VK_VIEWPORT_COORDINATE_SWIZZLE_POSITIVE_W_NV = 6,
    VK_VIEWPORT_COORDINATE_SWIZZLE_NEGATIVE_W_NV = 7,
    VK_VIEWPORT_COORDINATE_SWIZZLE_MAX_ENUM_NV = 0x7FFFFFFF
} VkViewportCoordinateSwizzleNV;
typedef VkFlags VkPipelineViewportSwizzleStateCreateFlagsNV;
typedef struct VkViewportSwizzleNV {
    VkViewportCoordinateSwizzleNV x;
    VkViewportCoordinateSwizzleNV y;
    VkViewportCoordinateSwizzleNV z;
    VkViewportCoordinateSwizzleNV w;
} VkViewportSwizzleNV;

typedef struct VkPipelineViewportSwizzleStateCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkPipelineViewportSwizzleStateCreateFlagsNV flags;
    uint32_t viewportCount;
    const VkViewportSwizzleNV* pViewportSwizzles;
} VkPipelineViewportSwizzleStateCreateInfoNV;
# 13821 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkDiscardRectangleModeEXT {
    VK_DISCARD_RECTANGLE_MODE_INCLUSIVE_EXT = 0,
    VK_DISCARD_RECTANGLE_MODE_EXCLUSIVE_EXT = 1,
    VK_DISCARD_RECTANGLE_MODE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkDiscardRectangleModeEXT;
typedef VkFlags VkPipelineDiscardRectangleStateCreateFlagsEXT;
typedef struct VkPhysicalDeviceDiscardRectanglePropertiesEXT {
    VkStructureType sType;
    void* pNext;
    uint32_t maxDiscardRectangles;
} VkPhysicalDeviceDiscardRectanglePropertiesEXT;

typedef struct VkPipelineDiscardRectangleStateCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkPipelineDiscardRectangleStateCreateFlagsEXT flags;
    VkDiscardRectangleModeEXT discardRectangleMode;
    uint32_t discardRectangleCount;
    const VkRect2D* pDiscardRectangles;
} VkPipelineDiscardRectangleStateCreateInfoEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDiscardRectangleEXT)(VkCommandBuffer commandBuffer, uint32_t firstDiscardRectangle, uint32_t discardRectangleCount, const VkRect2D* pDiscardRectangles);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDiscardRectangleEnableEXT)(VkCommandBuffer commandBuffer, VkBool32 discardRectangleEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDiscardRectangleModeEXT)(VkCommandBuffer commandBuffer, VkDiscardRectangleModeEXT discardRectangleMode);


 void __attribute__((__stdcall__)) vkCmdSetDiscardRectangleEXT(
    VkCommandBuffer commandBuffer,
    uint32_t firstDiscardRectangle,
    uint32_t discardRectangleCount,
    const VkRect2D* pDiscardRectangles);

 void __attribute__((__stdcall__)) vkCmdSetDiscardRectangleEnableEXT(
    VkCommandBuffer commandBuffer,
    VkBool32 discardRectangleEnable);

 void __attribute__((__stdcall__)) vkCmdSetDiscardRectangleModeEXT(
    VkCommandBuffer commandBuffer,
    VkDiscardRectangleModeEXT discardRectangleMode);
# 13868 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkConservativeRasterizationModeEXT {
    VK_CONSERVATIVE_RASTERIZATION_MODE_DISABLED_EXT = 0,
    VK_CONSERVATIVE_RASTERIZATION_MODE_OVERESTIMATE_EXT = 1,
    VK_CONSERVATIVE_RASTERIZATION_MODE_UNDERESTIMATE_EXT = 2,
    VK_CONSERVATIVE_RASTERIZATION_MODE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkConservativeRasterizationModeEXT;
typedef VkFlags VkPipelineRasterizationConservativeStateCreateFlagsEXT;
typedef struct VkPhysicalDeviceConservativeRasterizationPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    float primitiveOverestimationSize;
    float maxExtraPrimitiveOverestimationSize;
    float extraPrimitiveOverestimationSizeGranularity;
    VkBool32 primitiveUnderestimation;
    VkBool32 conservativePointAndLineRasterization;
    VkBool32 degenerateTrianglesRasterized;
    VkBool32 degenerateLinesRasterized;
    VkBool32 fullyCoveredFragmentShaderInputVariable;
    VkBool32 conservativeRasterizationPostDepthCoverage;
} VkPhysicalDeviceConservativeRasterizationPropertiesEXT;

typedef struct VkPipelineRasterizationConservativeStateCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkPipelineRasterizationConservativeStateCreateFlagsEXT flags;
    VkConservativeRasterizationModeEXT conservativeRasterizationMode;
    float extraPrimitiveOverestimationSize;
} VkPipelineRasterizationConservativeStateCreateInfoEXT;







typedef VkFlags VkPipelineRasterizationDepthClipStateCreateFlagsEXT;
typedef struct VkPhysicalDeviceDepthClipEnableFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 depthClipEnable;
} VkPhysicalDeviceDepthClipEnableFeaturesEXT;

typedef struct VkPipelineRasterizationDepthClipStateCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkPipelineRasterizationDepthClipStateCreateFlagsEXT flags;
    VkBool32 depthClipEnable;
} VkPipelineRasterizationDepthClipStateCreateInfoEXT;
# 13929 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkXYColorEXT {
    float x;
    float y;
} VkXYColorEXT;

typedef struct VkHdrMetadataEXT {
    VkStructureType sType;
    const void* pNext;
    VkXYColorEXT displayPrimaryRed;
    VkXYColorEXT displayPrimaryGreen;
    VkXYColorEXT displayPrimaryBlue;
    VkXYColorEXT whitePoint;
    float maxLuminance;
    float minLuminance;
    float maxContentLightLevel;
    float maxFrameAverageLightLevel;
} VkHdrMetadataEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkSetHdrMetadataEXT)(VkDevice device, uint32_t swapchainCount, const VkSwapchainKHR* pSwapchains, const VkHdrMetadataEXT* pMetadata);


 void __attribute__((__stdcall__)) vkSetHdrMetadataEXT(
    VkDevice device,
    uint32_t swapchainCount,
    const VkSwapchainKHR* pSwapchains,
    const VkHdrMetadataEXT* pMetadata);







typedef struct VkPhysicalDeviceRelaxedLineRasterizationFeaturesIMG {
    VkStructureType sType;
    void* pNext;
    VkBool32 relaxedLineRasterization;
} VkPhysicalDeviceRelaxedLineRasterizationFeaturesIMG;
# 13985 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkDebugUtilsMessengerEXT_T *VkDebugUtilsMessengerEXT;


typedef VkFlags VkDebugUtilsMessengerCallbackDataFlagsEXT;

typedef enum VkDebugUtilsMessageSeverityFlagBitsEXT {
    VK_DEBUG_UTILS_MESSAGE_SEVERITY_VERBOSE_BIT_EXT = 0x00000001,
    VK_DEBUG_UTILS_MESSAGE_SEVERITY_INFO_BIT_EXT = 0x00000010,
    VK_DEBUG_UTILS_MESSAGE_SEVERITY_WARNING_BIT_EXT = 0x00000100,
    VK_DEBUG_UTILS_MESSAGE_SEVERITY_ERROR_BIT_EXT = 0x00001000,
    VK_DEBUG_UTILS_MESSAGE_SEVERITY_FLAG_BITS_MAX_ENUM_EXT = 0x7FFFFFFF
} VkDebugUtilsMessageSeverityFlagBitsEXT;

typedef enum VkDebugUtilsMessageTypeFlagBitsEXT {
    VK_DEBUG_UTILS_MESSAGE_TYPE_GENERAL_BIT_EXT = 0x00000001,
    VK_DEBUG_UTILS_MESSAGE_TYPE_VALIDATION_BIT_EXT = 0x00000002,
    VK_DEBUG_UTILS_MESSAGE_TYPE_PERFORMANCE_BIT_EXT = 0x00000004,
    VK_DEBUG_UTILS_MESSAGE_TYPE_DEVICE_ADDRESS_BINDING_BIT_EXT = 0x00000008,
    VK_DEBUG_UTILS_MESSAGE_TYPE_FLAG_BITS_MAX_ENUM_EXT = 0x7FFFFFFF
} VkDebugUtilsMessageTypeFlagBitsEXT;
typedef VkFlags VkDebugUtilsMessageTypeFlagsEXT;
typedef VkFlags VkDebugUtilsMessageSeverityFlagsEXT;
typedef VkFlags VkDebugUtilsMessengerCreateFlagsEXT;
typedef struct VkDebugUtilsLabelEXT {
    VkStructureType sType;
    const void* pNext;
    const char* pLabelName;
    float color[4];
} VkDebugUtilsLabelEXT;

typedef struct VkDebugUtilsObjectNameInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkObjectType objectType;
    uint64_t objectHandle;
    const char* pObjectName;
} VkDebugUtilsObjectNameInfoEXT;

typedef struct VkDebugUtilsMessengerCallbackDataEXT {
    VkStructureType sType;
    const void* pNext;
    VkDebugUtilsMessengerCallbackDataFlagsEXT flags;
    const char* pMessageIdName;
    int32_t messageIdNumber;
    const char* pMessage;
    uint32_t queueLabelCount;
    const VkDebugUtilsLabelEXT* pQueueLabels;
    uint32_t cmdBufLabelCount;
    const VkDebugUtilsLabelEXT* pCmdBufLabels;
    uint32_t objectCount;
    const VkDebugUtilsObjectNameInfoEXT* pObjects;
} VkDebugUtilsMessengerCallbackDataEXT;

typedef VkBool32 (__attribute__((__stdcall__)) *PFN_vkDebugUtilsMessengerCallbackEXT)(
    VkDebugUtilsMessageSeverityFlagBitsEXT messageSeverity,
    VkDebugUtilsMessageTypeFlagsEXT messageTypes,
    const VkDebugUtilsMessengerCallbackDataEXT* pCallbackData,
    void* pUserData);

typedef struct VkDebugUtilsMessengerCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkDebugUtilsMessengerCreateFlagsEXT flags;
    VkDebugUtilsMessageSeverityFlagsEXT messageSeverity;
    VkDebugUtilsMessageTypeFlagsEXT messageType;
    PFN_vkDebugUtilsMessengerCallbackEXT pfnUserCallback;
    void* pUserData;
} VkDebugUtilsMessengerCreateInfoEXT;

typedef struct VkDebugUtilsObjectTagInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkObjectType objectType;
    uint64_t objectHandle;
    uint64_t tagName;
    size_t tagSize;
    const void* pTag;
} VkDebugUtilsObjectTagInfoEXT;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkSetDebugUtilsObjectNameEXT)(VkDevice device, const VkDebugUtilsObjectNameInfoEXT* pNameInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkSetDebugUtilsObjectTagEXT)(VkDevice device, const VkDebugUtilsObjectTagInfoEXT* pTagInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkQueueBeginDebugUtilsLabelEXT)(VkQueue queue, const VkDebugUtilsLabelEXT* pLabelInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkQueueEndDebugUtilsLabelEXT)(VkQueue queue);
typedef void (__attribute__((__stdcall__)) *PFN_vkQueueInsertDebugUtilsLabelEXT)(VkQueue queue, const VkDebugUtilsLabelEXT* pLabelInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBeginDebugUtilsLabelEXT)(VkCommandBuffer commandBuffer, const VkDebugUtilsLabelEXT* pLabelInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdEndDebugUtilsLabelEXT)(VkCommandBuffer commandBuffer);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdInsertDebugUtilsLabelEXT)(VkCommandBuffer commandBuffer, const VkDebugUtilsLabelEXT* pLabelInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateDebugUtilsMessengerEXT)(VkInstance instance, const VkDebugUtilsMessengerCreateInfoEXT* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDebugUtilsMessengerEXT* pMessenger);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyDebugUtilsMessengerEXT)(VkInstance instance, VkDebugUtilsMessengerEXT messenger, const VkAllocationCallbacks* pAllocator);
typedef void (__attribute__((__stdcall__)) *PFN_vkSubmitDebugUtilsMessageEXT)(VkInstance instance, VkDebugUtilsMessageSeverityFlagBitsEXT messageSeverity, VkDebugUtilsMessageTypeFlagsEXT messageTypes, const VkDebugUtilsMessengerCallbackDataEXT* pCallbackData);


 VkResult __attribute__((__stdcall__)) vkSetDebugUtilsObjectNameEXT(
    VkDevice device,
    const VkDebugUtilsObjectNameInfoEXT* pNameInfo);

 VkResult __attribute__((__stdcall__)) vkSetDebugUtilsObjectTagEXT(
    VkDevice device,
    const VkDebugUtilsObjectTagInfoEXT* pTagInfo);

 void __attribute__((__stdcall__)) vkQueueBeginDebugUtilsLabelEXT(
    VkQueue queue,
    const VkDebugUtilsLabelEXT* pLabelInfo);

 void __attribute__((__stdcall__)) vkQueueEndDebugUtilsLabelEXT(
    VkQueue queue);

 void __attribute__((__stdcall__)) vkQueueInsertDebugUtilsLabelEXT(
    VkQueue queue,
    const VkDebugUtilsLabelEXT* pLabelInfo);

 void __attribute__((__stdcall__)) vkCmdBeginDebugUtilsLabelEXT(
    VkCommandBuffer commandBuffer,
    const VkDebugUtilsLabelEXT* pLabelInfo);

 void __attribute__((__stdcall__)) vkCmdEndDebugUtilsLabelEXT(
    VkCommandBuffer commandBuffer);

 void __attribute__((__stdcall__)) vkCmdInsertDebugUtilsLabelEXT(
    VkCommandBuffer commandBuffer,
    const VkDebugUtilsLabelEXT* pLabelInfo);

 VkResult __attribute__((__stdcall__)) vkCreateDebugUtilsMessengerEXT(
    VkInstance instance,
    const VkDebugUtilsMessengerCreateInfoEXT* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkDebugUtilsMessengerEXT* pMessenger);

 void __attribute__((__stdcall__)) vkDestroyDebugUtilsMessengerEXT(
    VkInstance instance,
    VkDebugUtilsMessengerEXT messenger,
    const VkAllocationCallbacks* pAllocator);

 void __attribute__((__stdcall__)) vkSubmitDebugUtilsMessageEXT(
    VkInstance instance,
    VkDebugUtilsMessageSeverityFlagBitsEXT messageSeverity,
    VkDebugUtilsMessageTypeFlagsEXT messageTypes,
    const VkDebugUtilsMessengerCallbackDataEXT* pCallbackData);







typedef VkSamplerReductionMode VkSamplerReductionModeEXT;

typedef VkSamplerReductionModeCreateInfo VkSamplerReductionModeCreateInfoEXT;

typedef VkPhysicalDeviceSamplerFilterMinmaxProperties VkPhysicalDeviceSamplerFilterMinmaxPropertiesEXT;
# 14148 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkAttachmentSampleCountInfoAMD {
    VkStructureType sType;
    const void* pNext;
    uint32_t colorAttachmentCount;
    const VkSampleCountFlagBits* pColorAttachmentSamples;
    VkSampleCountFlagBits depthStencilAttachmentSamples;
} VkAttachmentSampleCountInfoAMD;
# 14168 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkPhysicalDeviceInlineUniformBlockFeatures VkPhysicalDeviceInlineUniformBlockFeaturesEXT;

typedef VkPhysicalDeviceInlineUniformBlockProperties VkPhysicalDeviceInlineUniformBlockPropertiesEXT;

typedef VkWriteDescriptorSetInlineUniformBlock VkWriteDescriptorSetInlineUniformBlockEXT;

typedef VkDescriptorPoolInlineUniformBlockCreateInfo VkDescriptorPoolInlineUniformBlockCreateInfoEXT;
# 14188 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkSampleLocationEXT {
    float x;
    float y;
} VkSampleLocationEXT;

typedef struct VkSampleLocationsInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkSampleCountFlagBits sampleLocationsPerPixel;
    VkExtent2D sampleLocationGridSize;
    uint32_t sampleLocationsCount;
    const VkSampleLocationEXT* pSampleLocations;
} VkSampleLocationsInfoEXT;

typedef struct VkAttachmentSampleLocationsEXT {
    uint32_t attachmentIndex;
    VkSampleLocationsInfoEXT sampleLocationsInfo;
} VkAttachmentSampleLocationsEXT;

typedef struct VkSubpassSampleLocationsEXT {
    uint32_t subpassIndex;
    VkSampleLocationsInfoEXT sampleLocationsInfo;
} VkSubpassSampleLocationsEXT;

typedef struct VkRenderPassSampleLocationsBeginInfoEXT {
    VkStructureType sType;
    const void* pNext;
    uint32_t attachmentInitialSampleLocationsCount;
    const VkAttachmentSampleLocationsEXT* pAttachmentInitialSampleLocations;
    uint32_t postSubpassSampleLocationsCount;
    const VkSubpassSampleLocationsEXT* pPostSubpassSampleLocations;
} VkRenderPassSampleLocationsBeginInfoEXT;

typedef struct VkPipelineSampleLocationsStateCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkBool32 sampleLocationsEnable;
    VkSampleLocationsInfoEXT sampleLocationsInfo;
} VkPipelineSampleLocationsStateCreateInfoEXT;

typedef struct VkPhysicalDeviceSampleLocationsPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    VkSampleCountFlags sampleLocationSampleCounts;
    VkExtent2D maxSampleLocationGridSize;
    float sampleLocationCoordinateRange[2];
    uint32_t sampleLocationSubPixelBits;
    VkBool32 variableSampleLocations;
} VkPhysicalDeviceSampleLocationsPropertiesEXT;

typedef struct VkMultisamplePropertiesEXT {
    VkStructureType sType;
    void* pNext;
    VkExtent2D maxSampleLocationGridSize;
} VkMultisamplePropertiesEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetSampleLocationsEXT)(VkCommandBuffer commandBuffer, const VkSampleLocationsInfoEXT* pSampleLocationsInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceMultisamplePropertiesEXT)(VkPhysicalDevice physicalDevice, VkSampleCountFlagBits samples, VkMultisamplePropertiesEXT* pMultisampleProperties);


 void __attribute__((__stdcall__)) vkCmdSetSampleLocationsEXT(
    VkCommandBuffer commandBuffer,
    const VkSampleLocationsInfoEXT* pSampleLocationsInfo);

 void __attribute__((__stdcall__)) vkGetPhysicalDeviceMultisamplePropertiesEXT(
    VkPhysicalDevice physicalDevice,
    VkSampleCountFlagBits samples,
    VkMultisamplePropertiesEXT* pMultisampleProperties);
# 14264 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkBlendOverlapEXT {
    VK_BLEND_OVERLAP_UNCORRELATED_EXT = 0,
    VK_BLEND_OVERLAP_DISJOINT_EXT = 1,
    VK_BLEND_OVERLAP_CONJOINT_EXT = 2,
    VK_BLEND_OVERLAP_MAX_ENUM_EXT = 0x7FFFFFFF
} VkBlendOverlapEXT;
typedef struct VkPhysicalDeviceBlendOperationAdvancedFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 advancedBlendCoherentOperations;
} VkPhysicalDeviceBlendOperationAdvancedFeaturesEXT;

typedef struct VkPhysicalDeviceBlendOperationAdvancedPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    uint32_t advancedBlendMaxColorAttachments;
    VkBool32 advancedBlendIndependentBlend;
    VkBool32 advancedBlendNonPremultipliedSrcColor;
    VkBool32 advancedBlendNonPremultipliedDstColor;
    VkBool32 advancedBlendCorrelatedOverlap;
    VkBool32 advancedBlendAllOperations;
} VkPhysicalDeviceBlendOperationAdvancedPropertiesEXT;

typedef struct VkPipelineColorBlendAdvancedStateCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkBool32 srcPremultiplied;
    VkBool32 dstPremultiplied;
    VkBlendOverlapEXT blendOverlap;
} VkPipelineColorBlendAdvancedStateCreateInfoEXT;







typedef VkFlags VkPipelineCoverageToColorStateCreateFlagsNV;
typedef struct VkPipelineCoverageToColorStateCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkPipelineCoverageToColorStateCreateFlagsNV flags;
    VkBool32 coverageToColorEnable;
    uint32_t coverageToColorLocation;
} VkPipelineCoverageToColorStateCreateInfoNV;
# 14317 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkCoverageModulationModeNV {
    VK_COVERAGE_MODULATION_MODE_NONE_NV = 0,
    VK_COVERAGE_MODULATION_MODE_RGB_NV = 1,
    VK_COVERAGE_MODULATION_MODE_ALPHA_NV = 2,
    VK_COVERAGE_MODULATION_MODE_RGBA_NV = 3,
    VK_COVERAGE_MODULATION_MODE_MAX_ENUM_NV = 0x7FFFFFFF
} VkCoverageModulationModeNV;
typedef VkFlags VkPipelineCoverageModulationStateCreateFlagsNV;
typedef struct VkPipelineCoverageModulationStateCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkPipelineCoverageModulationStateCreateFlagsNV flags;
    VkCoverageModulationModeNV coverageModulationMode;
    VkBool32 coverageModulationTableEnable;
    uint32_t coverageModulationTableCount;
    const float* pCoverageModulationTable;
} VkPipelineCoverageModulationStateCreateInfoNV;

typedef VkAttachmentSampleCountInfoAMD VkAttachmentSampleCountInfoNV;
# 14349 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkPhysicalDeviceShaderSMBuiltinsPropertiesNV {
    VkStructureType sType;
    void* pNext;
    uint32_t shaderSMCount;
    uint32_t shaderWarpsPerSM;
} VkPhysicalDeviceShaderSMBuiltinsPropertiesNV;

typedef struct VkPhysicalDeviceShaderSMBuiltinsFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderSMBuiltins;
} VkPhysicalDeviceShaderSMBuiltinsFeaturesNV;
# 14374 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkDrmFormatModifierPropertiesEXT {
    uint64_t drmFormatModifier;
    uint32_t drmFormatModifierPlaneCount;
    VkFormatFeatureFlags drmFormatModifierTilingFeatures;
} VkDrmFormatModifierPropertiesEXT;

typedef struct VkDrmFormatModifierPropertiesListEXT {
    VkStructureType sType;
    void* pNext;
    uint32_t drmFormatModifierCount;
    VkDrmFormatModifierPropertiesEXT* pDrmFormatModifierProperties;
} VkDrmFormatModifierPropertiesListEXT;

typedef struct VkPhysicalDeviceImageDrmFormatModifierInfoEXT {
    VkStructureType sType;
    const void* pNext;
    uint64_t drmFormatModifier;
    VkSharingMode sharingMode;
    uint32_t queueFamilyIndexCount;
    const uint32_t* pQueueFamilyIndices;
} VkPhysicalDeviceImageDrmFormatModifierInfoEXT;

typedef struct VkImageDrmFormatModifierListCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    uint32_t drmFormatModifierCount;
    const uint64_t* pDrmFormatModifiers;
} VkImageDrmFormatModifierListCreateInfoEXT;

typedef struct VkImageDrmFormatModifierExplicitCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    uint64_t drmFormatModifier;
    uint32_t drmFormatModifierPlaneCount;
    const VkSubresourceLayout* pPlaneLayouts;
} VkImageDrmFormatModifierExplicitCreateInfoEXT;

typedef struct VkImageDrmFormatModifierPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    uint64_t drmFormatModifier;
} VkImageDrmFormatModifierPropertiesEXT;

typedef struct VkDrmFormatModifierProperties2EXT {
    uint64_t drmFormatModifier;
    uint32_t drmFormatModifierPlaneCount;
    VkFormatFeatureFlags2 drmFormatModifierTilingFeatures;
} VkDrmFormatModifierProperties2EXT;

typedef struct VkDrmFormatModifierPropertiesList2EXT {
    VkStructureType sType;
    void* pNext;
    uint32_t drmFormatModifierCount;
    VkDrmFormatModifierProperties2EXT* pDrmFormatModifierProperties;
} VkDrmFormatModifierPropertiesList2EXT;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetImageDrmFormatModifierPropertiesEXT)(VkDevice device, VkImage image, VkImageDrmFormatModifierPropertiesEXT* pProperties);


 VkResult __attribute__((__stdcall__)) vkGetImageDrmFormatModifierPropertiesEXT(
    VkDevice device,
    VkImage image,
    VkImageDrmFormatModifierPropertiesEXT* pProperties);





typedef struct VkValidationCacheEXT_T *VkValidationCacheEXT;



typedef enum VkValidationCacheHeaderVersionEXT {
    VK_VALIDATION_CACHE_HEADER_VERSION_ONE_EXT = 1,
    VK_VALIDATION_CACHE_HEADER_VERSION_MAX_ENUM_EXT = 0x7FFFFFFF
} VkValidationCacheHeaderVersionEXT;
typedef VkFlags VkValidationCacheCreateFlagsEXT;
typedef struct VkValidationCacheCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkValidationCacheCreateFlagsEXT flags;
    size_t initialDataSize;
    const void* pInitialData;
} VkValidationCacheCreateInfoEXT;

typedef struct VkShaderModuleValidationCacheCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkValidationCacheEXT validationCache;
} VkShaderModuleValidationCacheCreateInfoEXT;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateValidationCacheEXT)(VkDevice device, const VkValidationCacheCreateInfoEXT* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkValidationCacheEXT* pValidationCache);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyValidationCacheEXT)(VkDevice device, VkValidationCacheEXT validationCache, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkMergeValidationCachesEXT)(VkDevice device, VkValidationCacheEXT dstCache, uint32_t srcCacheCount, const VkValidationCacheEXT* pSrcCaches);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetValidationCacheDataEXT)(VkDevice device, VkValidationCacheEXT validationCache, size_t* pDataSize, void* pData);


 VkResult __attribute__((__stdcall__)) vkCreateValidationCacheEXT(
    VkDevice device,
    const VkValidationCacheCreateInfoEXT* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkValidationCacheEXT* pValidationCache);

 void __attribute__((__stdcall__)) vkDestroyValidationCacheEXT(
    VkDevice device,
    VkValidationCacheEXT validationCache,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkMergeValidationCachesEXT(
    VkDevice device,
    VkValidationCacheEXT dstCache,
    uint32_t srcCacheCount,
    const VkValidationCacheEXT* pSrcCaches);

 VkResult __attribute__((__stdcall__)) vkGetValidationCacheDataEXT(
    VkDevice device,
    VkValidationCacheEXT validationCache,
    size_t* pDataSize,
    void* pData);







typedef VkDescriptorBindingFlagBits VkDescriptorBindingFlagBitsEXT;

typedef VkDescriptorBindingFlags VkDescriptorBindingFlagsEXT;

typedef VkDescriptorSetLayoutBindingFlagsCreateInfo VkDescriptorSetLayoutBindingFlagsCreateInfoEXT;

typedef VkPhysicalDeviceDescriptorIndexingFeatures VkPhysicalDeviceDescriptorIndexingFeaturesEXT;

typedef VkPhysicalDeviceDescriptorIndexingProperties VkPhysicalDeviceDescriptorIndexingPropertiesEXT;

typedef VkDescriptorSetVariableDescriptorCountAllocateInfo VkDescriptorSetVariableDescriptorCountAllocateInfoEXT;

typedef VkDescriptorSetVariableDescriptorCountLayoutSupport VkDescriptorSetVariableDescriptorCountLayoutSupportEXT;
# 14527 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkShadingRatePaletteEntryNV {
    VK_SHADING_RATE_PALETTE_ENTRY_NO_INVOCATIONS_NV = 0,
    VK_SHADING_RATE_PALETTE_ENTRY_16_INVOCATIONS_PER_PIXEL_NV = 1,
    VK_SHADING_RATE_PALETTE_ENTRY_8_INVOCATIONS_PER_PIXEL_NV = 2,
    VK_SHADING_RATE_PALETTE_ENTRY_4_INVOCATIONS_PER_PIXEL_NV = 3,
    VK_SHADING_RATE_PALETTE_ENTRY_2_INVOCATIONS_PER_PIXEL_NV = 4,
    VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_PIXEL_NV = 5,
    VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_2X1_PIXELS_NV = 6,
    VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_1X2_PIXELS_NV = 7,
    VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_2X2_PIXELS_NV = 8,
    VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_4X2_PIXELS_NV = 9,
    VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_2X4_PIXELS_NV = 10,
    VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_4X4_PIXELS_NV = 11,
    VK_SHADING_RATE_PALETTE_ENTRY_MAX_ENUM_NV = 0x7FFFFFFF
} VkShadingRatePaletteEntryNV;

typedef enum VkCoarseSampleOrderTypeNV {
    VK_COARSE_SAMPLE_ORDER_TYPE_DEFAULT_NV = 0,
    VK_COARSE_SAMPLE_ORDER_TYPE_CUSTOM_NV = 1,
    VK_COARSE_SAMPLE_ORDER_TYPE_PIXEL_MAJOR_NV = 2,
    VK_COARSE_SAMPLE_ORDER_TYPE_SAMPLE_MAJOR_NV = 3,
    VK_COARSE_SAMPLE_ORDER_TYPE_MAX_ENUM_NV = 0x7FFFFFFF
} VkCoarseSampleOrderTypeNV;
typedef struct VkShadingRatePaletteNV {
    uint32_t shadingRatePaletteEntryCount;
    const VkShadingRatePaletteEntryNV* pShadingRatePaletteEntries;
} VkShadingRatePaletteNV;

typedef struct VkPipelineViewportShadingRateImageStateCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkBool32 shadingRateImageEnable;
    uint32_t viewportCount;
    const VkShadingRatePaletteNV* pShadingRatePalettes;
} VkPipelineViewportShadingRateImageStateCreateInfoNV;

typedef struct VkPhysicalDeviceShadingRateImageFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 shadingRateImage;
    VkBool32 shadingRateCoarseSampleOrder;
} VkPhysicalDeviceShadingRateImageFeaturesNV;

typedef struct VkPhysicalDeviceShadingRateImagePropertiesNV {
    VkStructureType sType;
    void* pNext;
    VkExtent2D shadingRateTexelSize;
    uint32_t shadingRatePaletteSize;
    uint32_t shadingRateMaxCoarseSamples;
} VkPhysicalDeviceShadingRateImagePropertiesNV;

typedef struct VkCoarseSampleLocationNV {
    uint32_t pixelX;
    uint32_t pixelY;
    uint32_t sample;
} VkCoarseSampleLocationNV;

typedef struct VkCoarseSampleOrderCustomNV {
    VkShadingRatePaletteEntryNV shadingRate;
    uint32_t sampleCount;
    uint32_t sampleLocationCount;
    const VkCoarseSampleLocationNV* pSampleLocations;
} VkCoarseSampleOrderCustomNV;

typedef struct VkPipelineViewportCoarseSampleOrderStateCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkCoarseSampleOrderTypeNV sampleOrderType;
    uint32_t customSampleOrderCount;
    const VkCoarseSampleOrderCustomNV* pCustomSampleOrders;
} VkPipelineViewportCoarseSampleOrderStateCreateInfoNV;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBindShadingRateImageNV)(VkCommandBuffer commandBuffer, VkImageView imageView, VkImageLayout imageLayout);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetViewportShadingRatePaletteNV)(VkCommandBuffer commandBuffer, uint32_t firstViewport, uint32_t viewportCount, const VkShadingRatePaletteNV* pShadingRatePalettes);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetCoarseSampleOrderNV)(VkCommandBuffer commandBuffer, VkCoarseSampleOrderTypeNV sampleOrderType, uint32_t customSampleOrderCount, const VkCoarseSampleOrderCustomNV* pCustomSampleOrders);


 void __attribute__((__stdcall__)) vkCmdBindShadingRateImageNV(
    VkCommandBuffer commandBuffer,
    VkImageView imageView,
    VkImageLayout imageLayout);

 void __attribute__((__stdcall__)) vkCmdSetViewportShadingRatePaletteNV(
    VkCommandBuffer commandBuffer,
    uint32_t firstViewport,
    uint32_t viewportCount,
    const VkShadingRatePaletteNV* pShadingRatePalettes);

 void __attribute__((__stdcall__)) vkCmdSetCoarseSampleOrderNV(
    VkCommandBuffer commandBuffer,
    VkCoarseSampleOrderTypeNV sampleOrderType,
    uint32_t customSampleOrderCount,
    const VkCoarseSampleOrderCustomNV* pCustomSampleOrders);





typedef struct VkAccelerationStructureNV_T *VkAccelerationStructureNV;





typedef enum VkRayTracingShaderGroupTypeKHR {
    VK_RAY_TRACING_SHADER_GROUP_TYPE_GENERAL_KHR = 0,
    VK_RAY_TRACING_SHADER_GROUP_TYPE_TRIANGLES_HIT_GROUP_KHR = 1,
    VK_RAY_TRACING_SHADER_GROUP_TYPE_PROCEDURAL_HIT_GROUP_KHR = 2,
    VK_RAY_TRACING_SHADER_GROUP_TYPE_GENERAL_NV = VK_RAY_TRACING_SHADER_GROUP_TYPE_GENERAL_KHR,
    VK_RAY_TRACING_SHADER_GROUP_TYPE_TRIANGLES_HIT_GROUP_NV = VK_RAY_TRACING_SHADER_GROUP_TYPE_TRIANGLES_HIT_GROUP_KHR,
    VK_RAY_TRACING_SHADER_GROUP_TYPE_PROCEDURAL_HIT_GROUP_NV = VK_RAY_TRACING_SHADER_GROUP_TYPE_PROCEDURAL_HIT_GROUP_KHR,
    VK_RAY_TRACING_SHADER_GROUP_TYPE_MAX_ENUM_KHR = 0x7FFFFFFF
} VkRayTracingShaderGroupTypeKHR;
typedef VkRayTracingShaderGroupTypeKHR VkRayTracingShaderGroupTypeNV;


typedef enum VkGeometryTypeKHR {
    VK_GEOMETRY_TYPE_TRIANGLES_KHR = 0,
    VK_GEOMETRY_TYPE_AABBS_KHR = 1,
    VK_GEOMETRY_TYPE_INSTANCES_KHR = 2,
    VK_GEOMETRY_TYPE_TRIANGLES_NV = VK_GEOMETRY_TYPE_TRIANGLES_KHR,
    VK_GEOMETRY_TYPE_AABBS_NV = VK_GEOMETRY_TYPE_AABBS_KHR,
    VK_GEOMETRY_TYPE_MAX_ENUM_KHR = 0x7FFFFFFF
} VkGeometryTypeKHR;
typedef VkGeometryTypeKHR VkGeometryTypeNV;


typedef enum VkAccelerationStructureTypeKHR {
    VK_ACCELERATION_STRUCTURE_TYPE_TOP_LEVEL_KHR = 0,
    VK_ACCELERATION_STRUCTURE_TYPE_BOTTOM_LEVEL_KHR = 1,
    VK_ACCELERATION_STRUCTURE_TYPE_GENERIC_KHR = 2,
    VK_ACCELERATION_STRUCTURE_TYPE_TOP_LEVEL_NV = VK_ACCELERATION_STRUCTURE_TYPE_TOP_LEVEL_KHR,
    VK_ACCELERATION_STRUCTURE_TYPE_BOTTOM_LEVEL_NV = VK_ACCELERATION_STRUCTURE_TYPE_BOTTOM_LEVEL_KHR,
    VK_ACCELERATION_STRUCTURE_TYPE_MAX_ENUM_KHR = 0x7FFFFFFF
} VkAccelerationStructureTypeKHR;
typedef VkAccelerationStructureTypeKHR VkAccelerationStructureTypeNV;


typedef enum VkCopyAccelerationStructureModeKHR {
    VK_COPY_ACCELERATION_STRUCTURE_MODE_CLONE_KHR = 0,
    VK_COPY_ACCELERATION_STRUCTURE_MODE_COMPACT_KHR = 1,
    VK_COPY_ACCELERATION_STRUCTURE_MODE_SERIALIZE_KHR = 2,
    VK_COPY_ACCELERATION_STRUCTURE_MODE_DESERIALIZE_KHR = 3,
    VK_COPY_ACCELERATION_STRUCTURE_MODE_CLONE_NV = VK_COPY_ACCELERATION_STRUCTURE_MODE_CLONE_KHR,
    VK_COPY_ACCELERATION_STRUCTURE_MODE_COMPACT_NV = VK_COPY_ACCELERATION_STRUCTURE_MODE_COMPACT_KHR,
    VK_COPY_ACCELERATION_STRUCTURE_MODE_MAX_ENUM_KHR = 0x7FFFFFFF
} VkCopyAccelerationStructureModeKHR;
typedef VkCopyAccelerationStructureModeKHR VkCopyAccelerationStructureModeNV;


typedef enum VkAccelerationStructureMemoryRequirementsTypeNV {
    VK_ACCELERATION_STRUCTURE_MEMORY_REQUIREMENTS_TYPE_OBJECT_NV = 0,
    VK_ACCELERATION_STRUCTURE_MEMORY_REQUIREMENTS_TYPE_BUILD_SCRATCH_NV = 1,
    VK_ACCELERATION_STRUCTURE_MEMORY_REQUIREMENTS_TYPE_UPDATE_SCRATCH_NV = 2,
    VK_ACCELERATION_STRUCTURE_MEMORY_REQUIREMENTS_TYPE_MAX_ENUM_NV = 0x7FFFFFFF
} VkAccelerationStructureMemoryRequirementsTypeNV;

typedef enum VkGeometryFlagBitsKHR {
    VK_GEOMETRY_OPAQUE_BIT_KHR = 0x00000001,
    VK_GEOMETRY_NO_DUPLICATE_ANY_HIT_INVOCATION_BIT_KHR = 0x00000002,
    VK_GEOMETRY_OPAQUE_BIT_NV = VK_GEOMETRY_OPAQUE_BIT_KHR,
    VK_GEOMETRY_NO_DUPLICATE_ANY_HIT_INVOCATION_BIT_NV = VK_GEOMETRY_NO_DUPLICATE_ANY_HIT_INVOCATION_BIT_KHR,
    VK_GEOMETRY_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkGeometryFlagBitsKHR;
typedef VkFlags VkGeometryFlagsKHR;
typedef VkGeometryFlagsKHR VkGeometryFlagsNV;

typedef VkGeometryFlagBitsKHR VkGeometryFlagBitsNV;


typedef enum VkGeometryInstanceFlagBitsKHR {
    VK_GEOMETRY_INSTANCE_TRIANGLE_FACING_CULL_DISABLE_BIT_KHR = 0x00000001,
    VK_GEOMETRY_INSTANCE_TRIANGLE_FLIP_FACING_BIT_KHR = 0x00000002,
    VK_GEOMETRY_INSTANCE_FORCE_OPAQUE_BIT_KHR = 0x00000004,
    VK_GEOMETRY_INSTANCE_FORCE_NO_OPAQUE_BIT_KHR = 0x00000008,
    VK_GEOMETRY_INSTANCE_FORCE_OPACITY_MICROMAP_2_STATE_EXT = 0x00000010,
    VK_GEOMETRY_INSTANCE_DISABLE_OPACITY_MICROMAPS_EXT = 0x00000020,
    VK_GEOMETRY_INSTANCE_TRIANGLE_FRONT_COUNTERCLOCKWISE_BIT_KHR = VK_GEOMETRY_INSTANCE_TRIANGLE_FLIP_FACING_BIT_KHR,
    VK_GEOMETRY_INSTANCE_TRIANGLE_CULL_DISABLE_BIT_NV = VK_GEOMETRY_INSTANCE_TRIANGLE_FACING_CULL_DISABLE_BIT_KHR,
    VK_GEOMETRY_INSTANCE_TRIANGLE_FRONT_COUNTERCLOCKWISE_BIT_NV = VK_GEOMETRY_INSTANCE_TRIANGLE_FRONT_COUNTERCLOCKWISE_BIT_KHR,
    VK_GEOMETRY_INSTANCE_FORCE_OPAQUE_BIT_NV = VK_GEOMETRY_INSTANCE_FORCE_OPAQUE_BIT_KHR,
    VK_GEOMETRY_INSTANCE_FORCE_NO_OPAQUE_BIT_NV = VK_GEOMETRY_INSTANCE_FORCE_NO_OPAQUE_BIT_KHR,
    VK_GEOMETRY_INSTANCE_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkGeometryInstanceFlagBitsKHR;
typedef VkFlags VkGeometryInstanceFlagsKHR;
typedef VkGeometryInstanceFlagsKHR VkGeometryInstanceFlagsNV;

typedef VkGeometryInstanceFlagBitsKHR VkGeometryInstanceFlagBitsNV;


typedef enum VkBuildAccelerationStructureFlagBitsKHR {
    VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_UPDATE_BIT_KHR = 0x00000001,
    VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_COMPACTION_BIT_KHR = 0x00000002,
    VK_BUILD_ACCELERATION_STRUCTURE_PREFER_FAST_TRACE_BIT_KHR = 0x00000004,
    VK_BUILD_ACCELERATION_STRUCTURE_PREFER_FAST_BUILD_BIT_KHR = 0x00000008,
    VK_BUILD_ACCELERATION_STRUCTURE_LOW_MEMORY_BIT_KHR = 0x00000010,
    VK_BUILD_ACCELERATION_STRUCTURE_MOTION_BIT_NV = 0x00000020,
    VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_OPACITY_MICROMAP_UPDATE_EXT = 0x00000040,
    VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_DISABLE_OPACITY_MICROMAPS_EXT = 0x00000080,
    VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_OPACITY_MICROMAP_DATA_UPDATE_EXT = 0x00000100,



    VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_DATA_ACCESS_KHR = 0x00000800,
    VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_UPDATE_BIT_NV = VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_UPDATE_BIT_KHR,
    VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_COMPACTION_BIT_NV = VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_COMPACTION_BIT_KHR,
    VK_BUILD_ACCELERATION_STRUCTURE_PREFER_FAST_TRACE_BIT_NV = VK_BUILD_ACCELERATION_STRUCTURE_PREFER_FAST_TRACE_BIT_KHR,
    VK_BUILD_ACCELERATION_STRUCTURE_PREFER_FAST_BUILD_BIT_NV = VK_BUILD_ACCELERATION_STRUCTURE_PREFER_FAST_BUILD_BIT_KHR,
    VK_BUILD_ACCELERATION_STRUCTURE_LOW_MEMORY_BIT_NV = VK_BUILD_ACCELERATION_STRUCTURE_LOW_MEMORY_BIT_KHR,
    VK_BUILD_ACCELERATION_STRUCTURE_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkBuildAccelerationStructureFlagBitsKHR;
typedef VkFlags VkBuildAccelerationStructureFlagsKHR;
typedef VkBuildAccelerationStructureFlagsKHR VkBuildAccelerationStructureFlagsNV;

typedef VkBuildAccelerationStructureFlagBitsKHR VkBuildAccelerationStructureFlagBitsNV;

typedef struct VkRayTracingShaderGroupCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkRayTracingShaderGroupTypeKHR type;
    uint32_t generalShader;
    uint32_t closestHitShader;
    uint32_t anyHitShader;
    uint32_t intersectionShader;
} VkRayTracingShaderGroupCreateInfoNV;

typedef struct VkRayTracingPipelineCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkPipelineCreateFlags flags;
    uint32_t stageCount;
    const VkPipelineShaderStageCreateInfo* pStages;
    uint32_t groupCount;
    const VkRayTracingShaderGroupCreateInfoNV* pGroups;
    uint32_t maxRecursionDepth;
    VkPipelineLayout layout;
    VkPipeline basePipelineHandle;
    int32_t basePipelineIndex;
} VkRayTracingPipelineCreateInfoNV;

typedef struct VkGeometryTrianglesNV {
    VkStructureType sType;
    const void* pNext;
    VkBuffer vertexData;
    VkDeviceSize vertexOffset;
    uint32_t vertexCount;
    VkDeviceSize vertexStride;
    VkFormat vertexFormat;
    VkBuffer indexData;
    VkDeviceSize indexOffset;
    uint32_t indexCount;
    VkIndexType indexType;
    VkBuffer transformData;
    VkDeviceSize transformOffset;
} VkGeometryTrianglesNV;

typedef struct VkGeometryAABBNV {
    VkStructureType sType;
    const void* pNext;
    VkBuffer aabbData;
    uint32_t numAABBs;
    uint32_t stride;
    VkDeviceSize offset;
} VkGeometryAABBNV;

typedef struct VkGeometryDataNV {
    VkGeometryTrianglesNV triangles;
    VkGeometryAABBNV aabbs;
} VkGeometryDataNV;

typedef struct VkGeometryNV {
    VkStructureType sType;
    const void* pNext;
    VkGeometryTypeKHR geometryType;
    VkGeometryDataNV geometry;
    VkGeometryFlagsKHR flags;
} VkGeometryNV;

typedef struct VkAccelerationStructureInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkAccelerationStructureTypeNV type;
    VkBuildAccelerationStructureFlagsNV flags;
    uint32_t instanceCount;
    uint32_t geometryCount;
    const VkGeometryNV* pGeometries;
} VkAccelerationStructureInfoNV;

typedef struct VkAccelerationStructureCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkDeviceSize compactedSize;
    VkAccelerationStructureInfoNV info;
} VkAccelerationStructureCreateInfoNV;

typedef struct VkBindAccelerationStructureMemoryInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkAccelerationStructureNV accelerationStructure;
    VkDeviceMemory memory;
    VkDeviceSize memoryOffset;
    uint32_t deviceIndexCount;
    const uint32_t* pDeviceIndices;
} VkBindAccelerationStructureMemoryInfoNV;

typedef struct VkWriteDescriptorSetAccelerationStructureNV {
    VkStructureType sType;
    const void* pNext;
    uint32_t accelerationStructureCount;
    const VkAccelerationStructureNV* pAccelerationStructures;
} VkWriteDescriptorSetAccelerationStructureNV;

typedef struct VkAccelerationStructureMemoryRequirementsInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkAccelerationStructureMemoryRequirementsTypeNV type;
    VkAccelerationStructureNV accelerationStructure;
} VkAccelerationStructureMemoryRequirementsInfoNV;

typedef struct VkPhysicalDeviceRayTracingPropertiesNV {
    VkStructureType sType;
    void* pNext;
    uint32_t shaderGroupHandleSize;
    uint32_t maxRecursionDepth;
    uint32_t maxShaderGroupStride;
    uint32_t shaderGroupBaseAlignment;
    uint64_t maxGeometryCount;
    uint64_t maxInstanceCount;
    uint64_t maxTriangleCount;
    uint32_t maxDescriptorSetAccelerationStructures;
} VkPhysicalDeviceRayTracingPropertiesNV;

typedef struct VkTransformMatrixKHR {
    float matrix[3][4];
} VkTransformMatrixKHR;

typedef VkTransformMatrixKHR VkTransformMatrixNV;

typedef struct VkAabbPositionsKHR {
    float minX;
    float minY;
    float minZ;
    float maxX;
    float maxY;
    float maxZ;
} VkAabbPositionsKHR;

typedef VkAabbPositionsKHR VkAabbPositionsNV;

typedef struct VkAccelerationStructureInstanceKHR {
    VkTransformMatrixKHR transform;
    uint32_t instanceCustomIndex:24;
    uint32_t mask:8;
    uint32_t instanceShaderBindingTableRecordOffset:24;
    VkGeometryInstanceFlagsKHR flags:8;
    uint64_t accelerationStructureReference;
} VkAccelerationStructureInstanceKHR;

typedef VkAccelerationStructureInstanceKHR VkAccelerationStructureInstanceNV;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateAccelerationStructureNV)(VkDevice device, const VkAccelerationStructureCreateInfoNV* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkAccelerationStructureNV* pAccelerationStructure);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyAccelerationStructureNV)(VkDevice device, VkAccelerationStructureNV accelerationStructure, const VkAllocationCallbacks* pAllocator);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetAccelerationStructureMemoryRequirementsNV)(VkDevice device, const VkAccelerationStructureMemoryRequirementsInfoNV* pInfo, VkMemoryRequirements2KHR* pMemoryRequirements);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkBindAccelerationStructureMemoryNV)(VkDevice device, uint32_t bindInfoCount, const VkBindAccelerationStructureMemoryInfoNV* pBindInfos);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBuildAccelerationStructureNV)(VkCommandBuffer commandBuffer, const VkAccelerationStructureInfoNV* pInfo, VkBuffer instanceData, VkDeviceSize instanceOffset, VkBool32 update, VkAccelerationStructureNV dst, VkAccelerationStructureNV src, VkBuffer scratch, VkDeviceSize scratchOffset);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyAccelerationStructureNV)(VkCommandBuffer commandBuffer, VkAccelerationStructureNV dst, VkAccelerationStructureNV src, VkCopyAccelerationStructureModeKHR mode);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdTraceRaysNV)(VkCommandBuffer commandBuffer, VkBuffer raygenShaderBindingTableBuffer, VkDeviceSize raygenShaderBindingOffset, VkBuffer missShaderBindingTableBuffer, VkDeviceSize missShaderBindingOffset, VkDeviceSize missShaderBindingStride, VkBuffer hitShaderBindingTableBuffer, VkDeviceSize hitShaderBindingOffset, VkDeviceSize hitShaderBindingStride, VkBuffer callableShaderBindingTableBuffer, VkDeviceSize callableShaderBindingOffset, VkDeviceSize callableShaderBindingStride, uint32_t width, uint32_t height, uint32_t depth);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateRayTracingPipelinesNV)(VkDevice device, VkPipelineCache pipelineCache, uint32_t createInfoCount, const VkRayTracingPipelineCreateInfoNV* pCreateInfos, const VkAllocationCallbacks* pAllocator, VkPipeline* pPipelines);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetRayTracingShaderGroupHandlesKHR)(VkDevice device, VkPipeline pipeline, uint32_t firstGroup, uint32_t groupCount, size_t dataSize, void* pData);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetRayTracingShaderGroupHandlesNV)(VkDevice device, VkPipeline pipeline, uint32_t firstGroup, uint32_t groupCount, size_t dataSize, void* pData);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetAccelerationStructureHandleNV)(VkDevice device, VkAccelerationStructureNV accelerationStructure, size_t dataSize, void* pData);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdWriteAccelerationStructuresPropertiesNV)(VkCommandBuffer commandBuffer, uint32_t accelerationStructureCount, const VkAccelerationStructureNV* pAccelerationStructures, VkQueryType queryType, VkQueryPool queryPool, uint32_t firstQuery);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCompileDeferredNV)(VkDevice device, VkPipeline pipeline, uint32_t shader);


 VkResult __attribute__((__stdcall__)) vkCreateAccelerationStructureNV(
    VkDevice device,
    const VkAccelerationStructureCreateInfoNV* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkAccelerationStructureNV* pAccelerationStructure);

 void __attribute__((__stdcall__)) vkDestroyAccelerationStructureNV(
    VkDevice device,
    VkAccelerationStructureNV accelerationStructure,
    const VkAllocationCallbacks* pAllocator);

 void __attribute__((__stdcall__)) vkGetAccelerationStructureMemoryRequirementsNV(
    VkDevice device,
    const VkAccelerationStructureMemoryRequirementsInfoNV* pInfo,
    VkMemoryRequirements2KHR* pMemoryRequirements);

 VkResult __attribute__((__stdcall__)) vkBindAccelerationStructureMemoryNV(
    VkDevice device,
    uint32_t bindInfoCount,
    const VkBindAccelerationStructureMemoryInfoNV* pBindInfos);

 void __attribute__((__stdcall__)) vkCmdBuildAccelerationStructureNV(
    VkCommandBuffer commandBuffer,
    const VkAccelerationStructureInfoNV* pInfo,
    VkBuffer instanceData,
    VkDeviceSize instanceOffset,
    VkBool32 update,
    VkAccelerationStructureNV dst,
    VkAccelerationStructureNV src,
    VkBuffer scratch,
    VkDeviceSize scratchOffset);

 void __attribute__((__stdcall__)) vkCmdCopyAccelerationStructureNV(
    VkCommandBuffer commandBuffer,
    VkAccelerationStructureNV dst,
    VkAccelerationStructureNV src,
    VkCopyAccelerationStructureModeKHR mode);

 void __attribute__((__stdcall__)) vkCmdTraceRaysNV(
    VkCommandBuffer commandBuffer,
    VkBuffer raygenShaderBindingTableBuffer,
    VkDeviceSize raygenShaderBindingOffset,
    VkBuffer missShaderBindingTableBuffer,
    VkDeviceSize missShaderBindingOffset,
    VkDeviceSize missShaderBindingStride,
    VkBuffer hitShaderBindingTableBuffer,
    VkDeviceSize hitShaderBindingOffset,
    VkDeviceSize hitShaderBindingStride,
    VkBuffer callableShaderBindingTableBuffer,
    VkDeviceSize callableShaderBindingOffset,
    VkDeviceSize callableShaderBindingStride,
    uint32_t width,
    uint32_t height,
    uint32_t depth);

 VkResult __attribute__((__stdcall__)) vkCreateRayTracingPipelinesNV(
    VkDevice device,
    VkPipelineCache pipelineCache,
    uint32_t createInfoCount,
    const VkRayTracingPipelineCreateInfoNV* pCreateInfos,
    const VkAllocationCallbacks* pAllocator,
    VkPipeline* pPipelines);

 VkResult __attribute__((__stdcall__)) vkGetRayTracingShaderGroupHandlesKHR(
    VkDevice device,
    VkPipeline pipeline,
    uint32_t firstGroup,
    uint32_t groupCount,
    size_t dataSize,
    void* pData);

 VkResult __attribute__((__stdcall__)) vkGetRayTracingShaderGroupHandlesNV(
    VkDevice device,
    VkPipeline pipeline,
    uint32_t firstGroup,
    uint32_t groupCount,
    size_t dataSize,
    void* pData);

 VkResult __attribute__((__stdcall__)) vkGetAccelerationStructureHandleNV(
    VkDevice device,
    VkAccelerationStructureNV accelerationStructure,
    size_t dataSize,
    void* pData);

 void __attribute__((__stdcall__)) vkCmdWriteAccelerationStructuresPropertiesNV(
    VkCommandBuffer commandBuffer,
    uint32_t accelerationStructureCount,
    const VkAccelerationStructureNV* pAccelerationStructures,
    VkQueryType queryType,
    VkQueryPool queryPool,
    uint32_t firstQuery);

 VkResult __attribute__((__stdcall__)) vkCompileDeferredNV(
    VkDevice device,
    VkPipeline pipeline,
    uint32_t shader);







typedef struct VkPhysicalDeviceRepresentativeFragmentTestFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 representativeFragmentTest;
} VkPhysicalDeviceRepresentativeFragmentTestFeaturesNV;

typedef struct VkPipelineRepresentativeFragmentTestStateCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkBool32 representativeFragmentTestEnable;
} VkPipelineRepresentativeFragmentTestStateCreateInfoNV;







typedef struct VkPhysicalDeviceImageViewImageFormatInfoEXT {
    VkStructureType sType;
    void* pNext;
    VkImageViewType imageViewType;
} VkPhysicalDeviceImageViewImageFormatInfoEXT;

typedef struct VkFilterCubicImageViewImageFormatPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 filterCubic;
    VkBool32 filterCubicMinmax;
} VkFilterCubicImageViewImageFormatPropertiesEXT;
# 15049 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkQueueGlobalPriority VkQueueGlobalPriorityEXT;

typedef VkDeviceQueueGlobalPriorityCreateInfo VkDeviceQueueGlobalPriorityCreateInfoEXT;







typedef struct VkImportMemoryHostPointerInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkExternalMemoryHandleTypeFlagBits handleType;
    void* pHostPointer;
} VkImportMemoryHostPointerInfoEXT;

typedef struct VkMemoryHostPointerPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    uint32_t memoryTypeBits;
} VkMemoryHostPointerPropertiesEXT;

typedef struct VkPhysicalDeviceExternalMemoryHostPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    VkDeviceSize minImportedHostPointerAlignment;
} VkPhysicalDeviceExternalMemoryHostPropertiesEXT;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetMemoryHostPointerPropertiesEXT)(VkDevice device, VkExternalMemoryHandleTypeFlagBits handleType, const void* pHostPointer, VkMemoryHostPointerPropertiesEXT* pMemoryHostPointerProperties);


 VkResult __attribute__((__stdcall__)) vkGetMemoryHostPointerPropertiesEXT(
    VkDevice device,
    VkExternalMemoryHandleTypeFlagBits handleType,
    const void* pHostPointer,
    VkMemoryHostPointerPropertiesEXT* pMemoryHostPointerProperties);







typedef void (__attribute__((__stdcall__)) *PFN_vkCmdWriteBufferMarkerAMD)(VkCommandBuffer commandBuffer, VkPipelineStageFlagBits pipelineStage, VkBuffer dstBuffer, VkDeviceSize dstOffset, uint32_t marker);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdWriteBufferMarker2AMD)(VkCommandBuffer commandBuffer, VkPipelineStageFlags2 stage, VkBuffer dstBuffer, VkDeviceSize dstOffset, uint32_t marker);


 void __attribute__((__stdcall__)) vkCmdWriteBufferMarkerAMD(
    VkCommandBuffer commandBuffer,
    VkPipelineStageFlagBits pipelineStage,
    VkBuffer dstBuffer,
    VkDeviceSize dstOffset,
    uint32_t marker);

 void __attribute__((__stdcall__)) vkCmdWriteBufferMarker2AMD(
    VkCommandBuffer commandBuffer,
    VkPipelineStageFlags2 stage,
    VkBuffer dstBuffer,
    VkDeviceSize dstOffset,
    uint32_t marker);
# 15118 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkPipelineCompilerControlFlagBitsAMD {
    VK_PIPELINE_COMPILER_CONTROL_FLAG_BITS_MAX_ENUM_AMD = 0x7FFFFFFF
} VkPipelineCompilerControlFlagBitsAMD;
typedef VkFlags VkPipelineCompilerControlFlagsAMD;
typedef struct VkPipelineCompilerControlCreateInfoAMD {
    VkStructureType sType;
    const void* pNext;
    VkPipelineCompilerControlFlagsAMD compilerControlFlags;
} VkPipelineCompilerControlCreateInfoAMD;







typedef VkTimeDomainKHR VkTimeDomainEXT;

typedef VkCalibratedTimestampInfoKHR VkCalibratedTimestampInfoEXT;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceCalibrateableTimeDomainsEXT)(VkPhysicalDevice physicalDevice, uint32_t* pTimeDomainCount, VkTimeDomainKHR* pTimeDomains);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetCalibratedTimestampsEXT)(VkDevice device, uint32_t timestampCount, const VkCalibratedTimestampInfoKHR* pTimestampInfos, uint64_t* pTimestamps, uint64_t* pMaxDeviation);


 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceCalibrateableTimeDomainsEXT(
    VkPhysicalDevice physicalDevice,
    uint32_t* pTimeDomainCount,
    VkTimeDomainKHR* pTimeDomains);

 VkResult __attribute__((__stdcall__)) vkGetCalibratedTimestampsEXT(
    VkDevice device,
    uint32_t timestampCount,
    const VkCalibratedTimestampInfoKHR* pTimestampInfos,
    uint64_t* pTimestamps,
    uint64_t* pMaxDeviation);







typedef struct VkPhysicalDeviceShaderCorePropertiesAMD {
    VkStructureType sType;
    void* pNext;
    uint32_t shaderEngineCount;
    uint32_t shaderArraysPerEngineCount;
    uint32_t computeUnitsPerShaderArray;
    uint32_t simdPerComputeUnit;
    uint32_t wavefrontsPerSimd;
    uint32_t wavefrontSize;
    uint32_t sgprsPerSimd;
    uint32_t minSgprAllocation;
    uint32_t maxSgprAllocation;
    uint32_t sgprAllocationGranularity;
    uint32_t vgprsPerSimd;
    uint32_t minVgprAllocation;
    uint32_t maxVgprAllocation;
    uint32_t vgprAllocationGranularity;
} VkPhysicalDeviceShaderCorePropertiesAMD;
# 15186 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkMemoryOverallocationBehaviorAMD {
    VK_MEMORY_OVERALLOCATION_BEHAVIOR_DEFAULT_AMD = 0,
    VK_MEMORY_OVERALLOCATION_BEHAVIOR_ALLOWED_AMD = 1,
    VK_MEMORY_OVERALLOCATION_BEHAVIOR_DISALLOWED_AMD = 2,
    VK_MEMORY_OVERALLOCATION_BEHAVIOR_MAX_ENUM_AMD = 0x7FFFFFFF
} VkMemoryOverallocationBehaviorAMD;
typedef struct VkDeviceMemoryOverallocationCreateInfoAMD {
    VkStructureType sType;
    const void* pNext;
    VkMemoryOverallocationBehaviorAMD overallocationBehavior;
} VkDeviceMemoryOverallocationCreateInfoAMD;







typedef struct VkPhysicalDeviceVertexAttributeDivisorPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    uint32_t maxVertexAttribDivisor;
} VkPhysicalDeviceVertexAttributeDivisorPropertiesEXT;

typedef VkVertexInputBindingDivisorDescription VkVertexInputBindingDivisorDescriptionEXT;

typedef VkPipelineVertexInputDivisorStateCreateInfo VkPipelineVertexInputDivisorStateCreateInfoEXT;

typedef VkPhysicalDeviceVertexAttributeDivisorFeatures VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT;







typedef VkPipelineCreationFeedbackFlagBits VkPipelineCreationFeedbackFlagBitsEXT;

typedef VkPipelineCreationFeedbackFlags VkPipelineCreationFeedbackFlagsEXT;

typedef VkPipelineCreationFeedbackCreateInfo VkPipelineCreationFeedbackCreateInfoEXT;

typedef VkPipelineCreationFeedback VkPipelineCreationFeedbackEXT;
# 15242 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkPhysicalDeviceComputeShaderDerivativesFeaturesKHR VkPhysicalDeviceComputeShaderDerivativesFeaturesNV;







typedef struct VkPhysicalDeviceMeshShaderFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 taskShader;
    VkBool32 meshShader;
} VkPhysicalDeviceMeshShaderFeaturesNV;

typedef struct VkPhysicalDeviceMeshShaderPropertiesNV {
    VkStructureType sType;
    void* pNext;
    uint32_t maxDrawMeshTasksCount;
    uint32_t maxTaskWorkGroupInvocations;
    uint32_t maxTaskWorkGroupSize[3];
    uint32_t maxTaskTotalMemorySize;
    uint32_t maxTaskOutputCount;
    uint32_t maxMeshWorkGroupInvocations;
    uint32_t maxMeshWorkGroupSize[3];
    uint32_t maxMeshTotalMemorySize;
    uint32_t maxMeshOutputVertices;
    uint32_t maxMeshOutputPrimitives;
    uint32_t maxMeshMultiviewViewCount;
    uint32_t meshOutputPerVertexGranularity;
    uint32_t meshOutputPerPrimitiveGranularity;
} VkPhysicalDeviceMeshShaderPropertiesNV;

typedef struct VkDrawMeshTasksIndirectCommandNV {
    uint32_t taskCount;
    uint32_t firstTask;
} VkDrawMeshTasksIndirectCommandNV;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawMeshTasksNV)(VkCommandBuffer commandBuffer, uint32_t taskCount, uint32_t firstTask);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawMeshTasksIndirectNV)(VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, uint32_t drawCount, uint32_t stride);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawMeshTasksIndirectCountNV)(VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride);


 void __attribute__((__stdcall__)) vkCmdDrawMeshTasksNV(
    VkCommandBuffer commandBuffer,
    uint32_t taskCount,
    uint32_t firstTask);

 void __attribute__((__stdcall__)) vkCmdDrawMeshTasksIndirectNV(
    VkCommandBuffer commandBuffer,
    VkBuffer buffer,
    VkDeviceSize offset,
    uint32_t drawCount,
    uint32_t stride);

 void __attribute__((__stdcall__)) vkCmdDrawMeshTasksIndirectCountNV(
    VkCommandBuffer commandBuffer,
    VkBuffer buffer,
    VkDeviceSize offset,
    VkBuffer countBuffer,
    VkDeviceSize countBufferOffset,
    uint32_t maxDrawCount,
    uint32_t stride);







typedef VkPhysicalDeviceFragmentShaderBarycentricFeaturesKHR VkPhysicalDeviceFragmentShaderBarycentricFeaturesNV;







typedef struct VkPhysicalDeviceShaderImageFootprintFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 imageFootprint;
} VkPhysicalDeviceShaderImageFootprintFeaturesNV;







typedef struct VkPipelineViewportExclusiveScissorStateCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    uint32_t exclusiveScissorCount;
    const VkRect2D* pExclusiveScissors;
} VkPipelineViewportExclusiveScissorStateCreateInfoNV;

typedef struct VkPhysicalDeviceExclusiveScissorFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 exclusiveScissor;
} VkPhysicalDeviceExclusiveScissorFeaturesNV;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetExclusiveScissorEnableNV)(VkCommandBuffer commandBuffer, uint32_t firstExclusiveScissor, uint32_t exclusiveScissorCount, const VkBool32* pExclusiveScissorEnables);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetExclusiveScissorNV)(VkCommandBuffer commandBuffer, uint32_t firstExclusiveScissor, uint32_t exclusiveScissorCount, const VkRect2D* pExclusiveScissors);


 void __attribute__((__stdcall__)) vkCmdSetExclusiveScissorEnableNV(
    VkCommandBuffer commandBuffer,
    uint32_t firstExclusiveScissor,
    uint32_t exclusiveScissorCount,
    const VkBool32* pExclusiveScissorEnables);

 void __attribute__((__stdcall__)) vkCmdSetExclusiveScissorNV(
    VkCommandBuffer commandBuffer,
    uint32_t firstExclusiveScissor,
    uint32_t exclusiveScissorCount,
    const VkRect2D* pExclusiveScissors);







typedef struct VkQueueFamilyCheckpointPropertiesNV {
    VkStructureType sType;
    void* pNext;
    VkPipelineStageFlags checkpointExecutionStageMask;
} VkQueueFamilyCheckpointPropertiesNV;

typedef struct VkCheckpointDataNV {
    VkStructureType sType;
    void* pNext;
    VkPipelineStageFlagBits stage;
    void* pCheckpointMarker;
} VkCheckpointDataNV;

typedef struct VkQueueFamilyCheckpointProperties2NV {
    VkStructureType sType;
    void* pNext;
    VkPipelineStageFlags2 checkpointExecutionStageMask;
} VkQueueFamilyCheckpointProperties2NV;

typedef struct VkCheckpointData2NV {
    VkStructureType sType;
    void* pNext;
    VkPipelineStageFlags2 stage;
    void* pCheckpointMarker;
} VkCheckpointData2NV;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetCheckpointNV)(VkCommandBuffer commandBuffer, const void* pCheckpointMarker);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetQueueCheckpointDataNV)(VkQueue queue, uint32_t* pCheckpointDataCount, VkCheckpointDataNV* pCheckpointData);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetQueueCheckpointData2NV)(VkQueue queue, uint32_t* pCheckpointDataCount, VkCheckpointData2NV* pCheckpointData);


 void __attribute__((__stdcall__)) vkCmdSetCheckpointNV(
    VkCommandBuffer commandBuffer,
    const void* pCheckpointMarker);

 void __attribute__((__stdcall__)) vkGetQueueCheckpointDataNV(
    VkQueue queue,
    uint32_t* pCheckpointDataCount,
    VkCheckpointDataNV* pCheckpointData);

 void __attribute__((__stdcall__)) vkGetQueueCheckpointData2NV(
    VkQueue queue,
    uint32_t* pCheckpointDataCount,
    VkCheckpointData2NV* pCheckpointData);







typedef struct VkPhysicalDeviceShaderIntegerFunctions2FeaturesINTEL {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderIntegerFunctions2;
} VkPhysicalDeviceShaderIntegerFunctions2FeaturesINTEL;





typedef struct VkPerformanceConfigurationINTEL_T *VkPerformanceConfigurationINTEL;



typedef enum VkPerformanceConfigurationTypeINTEL {
    VK_PERFORMANCE_CONFIGURATION_TYPE_COMMAND_QUEUE_METRICS_DISCOVERY_ACTIVATED_INTEL = 0,
    VK_PERFORMANCE_CONFIGURATION_TYPE_MAX_ENUM_INTEL = 0x7FFFFFFF
} VkPerformanceConfigurationTypeINTEL;

typedef enum VkQueryPoolSamplingModeINTEL {
    VK_QUERY_POOL_SAMPLING_MODE_MANUAL_INTEL = 0,
    VK_QUERY_POOL_SAMPLING_MODE_MAX_ENUM_INTEL = 0x7FFFFFFF
} VkQueryPoolSamplingModeINTEL;

typedef enum VkPerformanceOverrideTypeINTEL {
    VK_PERFORMANCE_OVERRIDE_TYPE_NULL_HARDWARE_INTEL = 0,
    VK_PERFORMANCE_OVERRIDE_TYPE_FLUSH_GPU_CACHES_INTEL = 1,
    VK_PERFORMANCE_OVERRIDE_TYPE_MAX_ENUM_INTEL = 0x7FFFFFFF
} VkPerformanceOverrideTypeINTEL;

typedef enum VkPerformanceParameterTypeINTEL {
    VK_PERFORMANCE_PARAMETER_TYPE_HW_COUNTERS_SUPPORTED_INTEL = 0,
    VK_PERFORMANCE_PARAMETER_TYPE_STREAM_MARKER_VALID_BITS_INTEL = 1,
    VK_PERFORMANCE_PARAMETER_TYPE_MAX_ENUM_INTEL = 0x7FFFFFFF
} VkPerformanceParameterTypeINTEL;

typedef enum VkPerformanceValueTypeINTEL {
    VK_PERFORMANCE_VALUE_TYPE_UINT32_INTEL = 0,
    VK_PERFORMANCE_VALUE_TYPE_UINT64_INTEL = 1,
    VK_PERFORMANCE_VALUE_TYPE_FLOAT_INTEL = 2,
    VK_PERFORMANCE_VALUE_TYPE_BOOL_INTEL = 3,
    VK_PERFORMANCE_VALUE_TYPE_STRING_INTEL = 4,
    VK_PERFORMANCE_VALUE_TYPE_MAX_ENUM_INTEL = 0x7FFFFFFF
} VkPerformanceValueTypeINTEL;
typedef union VkPerformanceValueDataINTEL {
    uint32_t value32;
    uint64_t value64;
    float valueFloat;
    VkBool32 valueBool;
    const char* valueString;
} VkPerformanceValueDataINTEL;

typedef struct VkPerformanceValueINTEL {
    VkPerformanceValueTypeINTEL type;
    VkPerformanceValueDataINTEL data;
} VkPerformanceValueINTEL;

typedef struct VkInitializePerformanceApiInfoINTEL {
    VkStructureType sType;
    const void* pNext;
    void* pUserData;
} VkInitializePerformanceApiInfoINTEL;

typedef struct VkQueryPoolPerformanceQueryCreateInfoINTEL {
    VkStructureType sType;
    const void* pNext;
    VkQueryPoolSamplingModeINTEL performanceCountersSampling;
} VkQueryPoolPerformanceQueryCreateInfoINTEL;

typedef VkQueryPoolPerformanceQueryCreateInfoINTEL VkQueryPoolCreateInfoINTEL;

typedef struct VkPerformanceMarkerInfoINTEL {
    VkStructureType sType;
    const void* pNext;
    uint64_t marker;
} VkPerformanceMarkerInfoINTEL;

typedef struct VkPerformanceStreamMarkerInfoINTEL {
    VkStructureType sType;
    const void* pNext;
    uint32_t marker;
} VkPerformanceStreamMarkerInfoINTEL;

typedef struct VkPerformanceOverrideInfoINTEL {
    VkStructureType sType;
    const void* pNext;
    VkPerformanceOverrideTypeINTEL type;
    VkBool32 enable;
    uint64_t parameter;
} VkPerformanceOverrideInfoINTEL;

typedef struct VkPerformanceConfigurationAcquireInfoINTEL {
    VkStructureType sType;
    const void* pNext;
    VkPerformanceConfigurationTypeINTEL type;
} VkPerformanceConfigurationAcquireInfoINTEL;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkInitializePerformanceApiINTEL)(VkDevice device, const VkInitializePerformanceApiInfoINTEL* pInitializeInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkUninitializePerformanceApiINTEL)(VkDevice device);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCmdSetPerformanceMarkerINTEL)(VkCommandBuffer commandBuffer, const VkPerformanceMarkerInfoINTEL* pMarkerInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCmdSetPerformanceStreamMarkerINTEL)(VkCommandBuffer commandBuffer, const VkPerformanceStreamMarkerInfoINTEL* pMarkerInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCmdSetPerformanceOverrideINTEL)(VkCommandBuffer commandBuffer, const VkPerformanceOverrideInfoINTEL* pOverrideInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkAcquirePerformanceConfigurationINTEL)(VkDevice device, const VkPerformanceConfigurationAcquireInfoINTEL* pAcquireInfo, VkPerformanceConfigurationINTEL* pConfiguration);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkReleasePerformanceConfigurationINTEL)(VkDevice device, VkPerformanceConfigurationINTEL configuration);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkQueueSetPerformanceConfigurationINTEL)(VkQueue queue, VkPerformanceConfigurationINTEL configuration);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPerformanceParameterINTEL)(VkDevice device, VkPerformanceParameterTypeINTEL parameter, VkPerformanceValueINTEL* pValue);


 VkResult __attribute__((__stdcall__)) vkInitializePerformanceApiINTEL(
    VkDevice device,
    const VkInitializePerformanceApiInfoINTEL* pInitializeInfo);

 void __attribute__((__stdcall__)) vkUninitializePerformanceApiINTEL(
    VkDevice device);

 VkResult __attribute__((__stdcall__)) vkCmdSetPerformanceMarkerINTEL(
    VkCommandBuffer commandBuffer,
    const VkPerformanceMarkerInfoINTEL* pMarkerInfo);

 VkResult __attribute__((__stdcall__)) vkCmdSetPerformanceStreamMarkerINTEL(
    VkCommandBuffer commandBuffer,
    const VkPerformanceStreamMarkerInfoINTEL* pMarkerInfo);

 VkResult __attribute__((__stdcall__)) vkCmdSetPerformanceOverrideINTEL(
    VkCommandBuffer commandBuffer,
    const VkPerformanceOverrideInfoINTEL* pOverrideInfo);

 VkResult __attribute__((__stdcall__)) vkAcquirePerformanceConfigurationINTEL(
    VkDevice device,
    const VkPerformanceConfigurationAcquireInfoINTEL* pAcquireInfo,
    VkPerformanceConfigurationINTEL* pConfiguration);

 VkResult __attribute__((__stdcall__)) vkReleasePerformanceConfigurationINTEL(
    VkDevice device,
    VkPerformanceConfigurationINTEL configuration);

 VkResult __attribute__((__stdcall__)) vkQueueSetPerformanceConfigurationINTEL(
    VkQueue queue,
    VkPerformanceConfigurationINTEL configuration);

 VkResult __attribute__((__stdcall__)) vkGetPerformanceParameterINTEL(
    VkDevice device,
    VkPerformanceParameterTypeINTEL parameter,
    VkPerformanceValueINTEL* pValue);







typedef struct VkPhysicalDevicePCIBusInfoPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    uint32_t pciDomain;
    uint32_t pciBus;
    uint32_t pciDevice;
    uint32_t pciFunction;
} VkPhysicalDevicePCIBusInfoPropertiesEXT;







typedef struct VkDisplayNativeHdrSurfaceCapabilitiesAMD {
    VkStructureType sType;
    void* pNext;
    VkBool32 localDimmingSupport;
} VkDisplayNativeHdrSurfaceCapabilitiesAMD;

typedef struct VkSwapchainDisplayNativeHdrCreateInfoAMD {
    VkStructureType sType;
    const void* pNext;
    VkBool32 localDimmingEnable;
} VkSwapchainDisplayNativeHdrCreateInfoAMD;

typedef void (__attribute__((__stdcall__)) *PFN_vkSetLocalDimmingAMD)(VkDevice device, VkSwapchainKHR swapChain, VkBool32 localDimmingEnable);


 void __attribute__((__stdcall__)) vkSetLocalDimmingAMD(
    VkDevice device,
    VkSwapchainKHR swapChain,
    VkBool32 localDimmingEnable);







typedef struct VkPhysicalDeviceFragmentDensityMapFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 fragmentDensityMap;
    VkBool32 fragmentDensityMapDynamic;
    VkBool32 fragmentDensityMapNonSubsampledImages;
} VkPhysicalDeviceFragmentDensityMapFeaturesEXT;

typedef struct VkPhysicalDeviceFragmentDensityMapPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    VkExtent2D minFragmentDensityTexelSize;
    VkExtent2D maxFragmentDensityTexelSize;
    VkBool32 fragmentDensityInvocations;
} VkPhysicalDeviceFragmentDensityMapPropertiesEXT;

typedef struct VkRenderPassFragmentDensityMapCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkAttachmentReference fragmentDensityMapAttachment;
} VkRenderPassFragmentDensityMapCreateInfoEXT;

typedef struct VkRenderingFragmentDensityMapAttachmentInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkImageView imageView;
    VkImageLayout imageLayout;
} VkRenderingFragmentDensityMapAttachmentInfoEXT;







typedef VkPhysicalDeviceScalarBlockLayoutFeatures VkPhysicalDeviceScalarBlockLayoutFeaturesEXT;
# 15669 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkPhysicalDeviceSubgroupSizeControlFeatures VkPhysicalDeviceSubgroupSizeControlFeaturesEXT;

typedef VkPhysicalDeviceSubgroupSizeControlProperties VkPhysicalDeviceSubgroupSizeControlPropertiesEXT;

typedef VkPipelineShaderStageRequiredSubgroupSizeCreateInfo VkPipelineShaderStageRequiredSubgroupSizeCreateInfoEXT;
# 15682 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkShaderCorePropertiesFlagBitsAMD {
    VK_SHADER_CORE_PROPERTIES_FLAG_BITS_MAX_ENUM_AMD = 0x7FFFFFFF
} VkShaderCorePropertiesFlagBitsAMD;
typedef VkFlags VkShaderCorePropertiesFlagsAMD;
typedef struct VkPhysicalDeviceShaderCoreProperties2AMD {
    VkStructureType sType;
    void* pNext;
    VkShaderCorePropertiesFlagsAMD shaderCoreFeatures;
    uint32_t activeComputeUnitCount;
} VkPhysicalDeviceShaderCoreProperties2AMD;







typedef struct VkPhysicalDeviceCoherentMemoryFeaturesAMD {
    VkStructureType sType;
    void* pNext;
    VkBool32 deviceCoherentMemory;
} VkPhysicalDeviceCoherentMemoryFeaturesAMD;







typedef struct VkPhysicalDeviceShaderImageAtomicInt64FeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderImageInt64Atomics;
    VkBool32 sparseImageInt64Atomics;
} VkPhysicalDeviceShaderImageAtomicInt64FeaturesEXT;







typedef struct VkPhysicalDeviceMemoryBudgetPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    VkDeviceSize heapBudget[16U];
    VkDeviceSize heapUsage[16U];
} VkPhysicalDeviceMemoryBudgetPropertiesEXT;







typedef struct VkPhysicalDeviceMemoryPriorityFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 memoryPriority;
} VkPhysicalDeviceMemoryPriorityFeaturesEXT;

typedef struct VkMemoryPriorityAllocateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    float priority;
} VkMemoryPriorityAllocateInfoEXT;







typedef struct VkPhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 dedicatedAllocationImageAliasing;
} VkPhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV;







typedef struct VkPhysicalDeviceBufferDeviceAddressFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 bufferDeviceAddress;
    VkBool32 bufferDeviceAddressCaptureReplay;
    VkBool32 bufferDeviceAddressMultiDevice;
} VkPhysicalDeviceBufferDeviceAddressFeaturesEXT;

typedef VkPhysicalDeviceBufferDeviceAddressFeaturesEXT VkPhysicalDeviceBufferAddressFeaturesEXT;

typedef VkBufferDeviceAddressInfo VkBufferDeviceAddressInfoEXT;

typedef struct VkBufferDeviceAddressCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkDeviceAddress deviceAddress;
} VkBufferDeviceAddressCreateInfoEXT;

typedef VkDeviceAddress (__attribute__((__stdcall__)) *PFN_vkGetBufferDeviceAddressEXT)(VkDevice device, const VkBufferDeviceAddressInfo* pInfo);


 VkDeviceAddress __attribute__((__stdcall__)) vkGetBufferDeviceAddressEXT(
    VkDevice device,
    const VkBufferDeviceAddressInfo* pInfo);







typedef VkToolPurposeFlagBits VkToolPurposeFlagBitsEXT;

typedef VkToolPurposeFlags VkToolPurposeFlagsEXT;

typedef VkPhysicalDeviceToolProperties VkPhysicalDeviceToolPropertiesEXT;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceToolPropertiesEXT)(VkPhysicalDevice physicalDevice, uint32_t* pToolCount, VkPhysicalDeviceToolProperties* pToolProperties);


 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceToolPropertiesEXT(
    VkPhysicalDevice physicalDevice,
    uint32_t* pToolCount,
    VkPhysicalDeviceToolProperties* pToolProperties);







typedef VkImageStencilUsageCreateInfo VkImageStencilUsageCreateInfoEXT;
# 15827 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkValidationFeatureEnableEXT {
    VK_VALIDATION_FEATURE_ENABLE_GPU_ASSISTED_EXT = 0,
    VK_VALIDATION_FEATURE_ENABLE_GPU_ASSISTED_RESERVE_BINDING_SLOT_EXT = 1,
    VK_VALIDATION_FEATURE_ENABLE_BEST_PRACTICES_EXT = 2,
    VK_VALIDATION_FEATURE_ENABLE_DEBUG_PRINTF_EXT = 3,
    VK_VALIDATION_FEATURE_ENABLE_SYNCHRONIZATION_VALIDATION_EXT = 4,
    VK_VALIDATION_FEATURE_ENABLE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkValidationFeatureEnableEXT;

typedef enum VkValidationFeatureDisableEXT {
    VK_VALIDATION_FEATURE_DISABLE_ALL_EXT = 0,
    VK_VALIDATION_FEATURE_DISABLE_SHADERS_EXT = 1,
    VK_VALIDATION_FEATURE_DISABLE_THREAD_SAFETY_EXT = 2,
    VK_VALIDATION_FEATURE_DISABLE_API_PARAMETERS_EXT = 3,
    VK_VALIDATION_FEATURE_DISABLE_OBJECT_LIFETIMES_EXT = 4,
    VK_VALIDATION_FEATURE_DISABLE_CORE_CHECKS_EXT = 5,
    VK_VALIDATION_FEATURE_DISABLE_UNIQUE_HANDLES_EXT = 6,
    VK_VALIDATION_FEATURE_DISABLE_SHADER_VALIDATION_CACHE_EXT = 7,
    VK_VALIDATION_FEATURE_DISABLE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkValidationFeatureDisableEXT;
typedef struct VkValidationFeaturesEXT {
    VkStructureType sType;
    const void* pNext;
    uint32_t enabledValidationFeatureCount;
    const VkValidationFeatureEnableEXT* pEnabledValidationFeatures;
    uint32_t disabledValidationFeatureCount;
    const VkValidationFeatureDisableEXT* pDisabledValidationFeatures;
} VkValidationFeaturesEXT;







typedef VkComponentTypeKHR VkComponentTypeNV;

typedef VkScopeKHR VkScopeNV;

typedef struct VkCooperativeMatrixPropertiesNV {
    VkStructureType sType;
    void* pNext;
    uint32_t MSize;
    uint32_t NSize;
    uint32_t KSize;
    VkComponentTypeNV AType;
    VkComponentTypeNV BType;
    VkComponentTypeNV CType;
    VkComponentTypeNV DType;
    VkScopeNV scope;
} VkCooperativeMatrixPropertiesNV;

typedef struct VkPhysicalDeviceCooperativeMatrixFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 cooperativeMatrix;
    VkBool32 cooperativeMatrixRobustBufferAccess;
} VkPhysicalDeviceCooperativeMatrixFeaturesNV;

typedef struct VkPhysicalDeviceCooperativeMatrixPropertiesNV {
    VkStructureType sType;
    void* pNext;
    VkShaderStageFlags cooperativeMatrixSupportedStages;
} VkPhysicalDeviceCooperativeMatrixPropertiesNV;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceCooperativeMatrixPropertiesNV)(VkPhysicalDevice physicalDevice, uint32_t* pPropertyCount, VkCooperativeMatrixPropertiesNV* pProperties);


 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceCooperativeMatrixPropertiesNV(
    VkPhysicalDevice physicalDevice,
    uint32_t* pPropertyCount,
    VkCooperativeMatrixPropertiesNV* pProperties);
# 15907 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkCoverageReductionModeNV {
    VK_COVERAGE_REDUCTION_MODE_MERGE_NV = 0,
    VK_COVERAGE_REDUCTION_MODE_TRUNCATE_NV = 1,
    VK_COVERAGE_REDUCTION_MODE_MAX_ENUM_NV = 0x7FFFFFFF
} VkCoverageReductionModeNV;
typedef VkFlags VkPipelineCoverageReductionStateCreateFlagsNV;
typedef struct VkPhysicalDeviceCoverageReductionModeFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 coverageReductionMode;
} VkPhysicalDeviceCoverageReductionModeFeaturesNV;

typedef struct VkPipelineCoverageReductionStateCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkPipelineCoverageReductionStateCreateFlagsNV flags;
    VkCoverageReductionModeNV coverageReductionMode;
} VkPipelineCoverageReductionStateCreateInfoNV;

typedef struct VkFramebufferMixedSamplesCombinationNV {
    VkStructureType sType;
    void* pNext;
    VkCoverageReductionModeNV coverageReductionMode;
    VkSampleCountFlagBits rasterizationSamples;
    VkSampleCountFlags depthStencilSamples;
    VkSampleCountFlags colorSamples;
} VkFramebufferMixedSamplesCombinationNV;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceSupportedFramebufferMixedSamplesCombinationsNV)(VkPhysicalDevice physicalDevice, uint32_t* pCombinationCount, VkFramebufferMixedSamplesCombinationNV* pCombinations);


 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceSupportedFramebufferMixedSamplesCombinationsNV(
    VkPhysicalDevice physicalDevice,
    uint32_t* pCombinationCount,
    VkFramebufferMixedSamplesCombinationNV* pCombinations);







typedef struct VkPhysicalDeviceFragmentShaderInterlockFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 fragmentShaderSampleInterlock;
    VkBool32 fragmentShaderPixelInterlock;
    VkBool32 fragmentShaderShadingRateInterlock;
} VkPhysicalDeviceFragmentShaderInterlockFeaturesEXT;







typedef struct VkPhysicalDeviceYcbcrImageArraysFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 ycbcrImageArrays;
} VkPhysicalDeviceYcbcrImageArraysFeaturesEXT;
# 15976 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkProvokingVertexModeEXT {
    VK_PROVOKING_VERTEX_MODE_FIRST_VERTEX_EXT = 0,
    VK_PROVOKING_VERTEX_MODE_LAST_VERTEX_EXT = 1,
    VK_PROVOKING_VERTEX_MODE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkProvokingVertexModeEXT;
typedef struct VkPhysicalDeviceProvokingVertexFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 provokingVertexLast;
    VkBool32 transformFeedbackPreservesProvokingVertex;
} VkPhysicalDeviceProvokingVertexFeaturesEXT;

typedef struct VkPhysicalDeviceProvokingVertexPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 provokingVertexModePerPipeline;
    VkBool32 transformFeedbackPreservesTriangleFanProvokingVertex;
} VkPhysicalDeviceProvokingVertexPropertiesEXT;

typedef struct VkPipelineRasterizationProvokingVertexStateCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkProvokingVertexModeEXT provokingVertexMode;
} VkPipelineRasterizationProvokingVertexStateCreateInfoEXT;







typedef VkFlags VkHeadlessSurfaceCreateFlagsEXT;
typedef struct VkHeadlessSurfaceCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkHeadlessSurfaceCreateFlagsEXT flags;
} VkHeadlessSurfaceCreateInfoEXT;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateHeadlessSurfaceEXT)(VkInstance instance, const VkHeadlessSurfaceCreateInfoEXT* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSurfaceKHR* pSurface);


 VkResult __attribute__((__stdcall__)) vkCreateHeadlessSurfaceEXT(
    VkInstance instance,
    const VkHeadlessSurfaceCreateInfoEXT* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkSurfaceKHR* pSurface);







typedef VkLineRasterizationMode VkLineRasterizationModeEXT;

typedef VkPhysicalDeviceLineRasterizationFeatures VkPhysicalDeviceLineRasterizationFeaturesEXT;

typedef VkPhysicalDeviceLineRasterizationProperties VkPhysicalDeviceLineRasterizationPropertiesEXT;

typedef VkPipelineRasterizationLineStateCreateInfo VkPipelineRasterizationLineStateCreateInfoEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetLineStippleEXT)(VkCommandBuffer commandBuffer, uint32_t lineStippleFactor, uint16_t lineStipplePattern);


 void __attribute__((__stdcall__)) vkCmdSetLineStippleEXT(
    VkCommandBuffer commandBuffer,
    uint32_t lineStippleFactor,
    uint16_t lineStipplePattern);







typedef struct VkPhysicalDeviceShaderAtomicFloatFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderBufferFloat32Atomics;
    VkBool32 shaderBufferFloat32AtomicAdd;
    VkBool32 shaderBufferFloat64Atomics;
    VkBool32 shaderBufferFloat64AtomicAdd;
    VkBool32 shaderSharedFloat32Atomics;
    VkBool32 shaderSharedFloat32AtomicAdd;
    VkBool32 shaderSharedFloat64Atomics;
    VkBool32 shaderSharedFloat64AtomicAdd;
    VkBool32 shaderImageFloat32Atomics;
    VkBool32 shaderImageFloat32AtomicAdd;
    VkBool32 sparseImageFloat32Atomics;
    VkBool32 sparseImageFloat32AtomicAdd;
} VkPhysicalDeviceShaderAtomicFloatFeaturesEXT;







typedef VkPhysicalDeviceHostQueryResetFeatures VkPhysicalDeviceHostQueryResetFeaturesEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkResetQueryPoolEXT)(VkDevice device, VkQueryPool queryPool, uint32_t firstQuery, uint32_t queryCount);


 void __attribute__((__stdcall__)) vkResetQueryPoolEXT(
    VkDevice device,
    VkQueryPool queryPool,
    uint32_t firstQuery,
    uint32_t queryCount);







typedef VkPhysicalDeviceIndexTypeUint8Features VkPhysicalDeviceIndexTypeUint8FeaturesEXT;







typedef struct VkPhysicalDeviceExtendedDynamicStateFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 extendedDynamicState;
} VkPhysicalDeviceExtendedDynamicStateFeaturesEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetCullModeEXT)(VkCommandBuffer commandBuffer, VkCullModeFlags cullMode);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetFrontFaceEXT)(VkCommandBuffer commandBuffer, VkFrontFace frontFace);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetPrimitiveTopologyEXT)(VkCommandBuffer commandBuffer, VkPrimitiveTopology primitiveTopology);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetViewportWithCountEXT)(VkCommandBuffer commandBuffer, uint32_t viewportCount, const VkViewport* pViewports);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetScissorWithCountEXT)(VkCommandBuffer commandBuffer, uint32_t scissorCount, const VkRect2D* pScissors);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBindVertexBuffers2EXT)(VkCommandBuffer commandBuffer, uint32_t firstBinding, uint32_t bindingCount, const VkBuffer* pBuffers, const VkDeviceSize* pOffsets, const VkDeviceSize* pSizes, const VkDeviceSize* pStrides);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDepthTestEnableEXT)(VkCommandBuffer commandBuffer, VkBool32 depthTestEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDepthWriteEnableEXT)(VkCommandBuffer commandBuffer, VkBool32 depthWriteEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDepthCompareOpEXT)(VkCommandBuffer commandBuffer, VkCompareOp depthCompareOp);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDepthBoundsTestEnableEXT)(VkCommandBuffer commandBuffer, VkBool32 depthBoundsTestEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetStencilTestEnableEXT)(VkCommandBuffer commandBuffer, VkBool32 stencilTestEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetStencilOpEXT)(VkCommandBuffer commandBuffer, VkStencilFaceFlags faceMask, VkStencilOp failOp, VkStencilOp passOp, VkStencilOp depthFailOp, VkCompareOp compareOp);


 void __attribute__((__stdcall__)) vkCmdSetCullModeEXT(
    VkCommandBuffer commandBuffer,
    VkCullModeFlags cullMode);

 void __attribute__((__stdcall__)) vkCmdSetFrontFaceEXT(
    VkCommandBuffer commandBuffer,
    VkFrontFace frontFace);

 void __attribute__((__stdcall__)) vkCmdSetPrimitiveTopologyEXT(
    VkCommandBuffer commandBuffer,
    VkPrimitiveTopology primitiveTopology);

 void __attribute__((__stdcall__)) vkCmdSetViewportWithCountEXT(
    VkCommandBuffer commandBuffer,
    uint32_t viewportCount,
    const VkViewport* pViewports);

 void __attribute__((__stdcall__)) vkCmdSetScissorWithCountEXT(
    VkCommandBuffer commandBuffer,
    uint32_t scissorCount,
    const VkRect2D* pScissors);

 void __attribute__((__stdcall__)) vkCmdBindVertexBuffers2EXT(
    VkCommandBuffer commandBuffer,
    uint32_t firstBinding,
    uint32_t bindingCount,
    const VkBuffer* pBuffers,
    const VkDeviceSize* pOffsets,
    const VkDeviceSize* pSizes,
    const VkDeviceSize* pStrides);

 void __attribute__((__stdcall__)) vkCmdSetDepthTestEnableEXT(
    VkCommandBuffer commandBuffer,
    VkBool32 depthTestEnable);

 void __attribute__((__stdcall__)) vkCmdSetDepthWriteEnableEXT(
    VkCommandBuffer commandBuffer,
    VkBool32 depthWriteEnable);

 void __attribute__((__stdcall__)) vkCmdSetDepthCompareOpEXT(
    VkCommandBuffer commandBuffer,
    VkCompareOp depthCompareOp);

 void __attribute__((__stdcall__)) vkCmdSetDepthBoundsTestEnableEXT(
    VkCommandBuffer commandBuffer,
    VkBool32 depthBoundsTestEnable);

 void __attribute__((__stdcall__)) vkCmdSetStencilTestEnableEXT(
    VkCommandBuffer commandBuffer,
    VkBool32 stencilTestEnable);

 void __attribute__((__stdcall__)) vkCmdSetStencilOpEXT(
    VkCommandBuffer commandBuffer,
    VkStencilFaceFlags faceMask,
    VkStencilOp failOp,
    VkStencilOp passOp,
    VkStencilOp depthFailOp,
    VkCompareOp compareOp);







typedef VkHostImageCopyFlagBits VkHostImageCopyFlagBitsEXT;

typedef VkHostImageCopyFlags VkHostImageCopyFlagsEXT;

typedef VkPhysicalDeviceHostImageCopyFeatures VkPhysicalDeviceHostImageCopyFeaturesEXT;

typedef VkPhysicalDeviceHostImageCopyProperties VkPhysicalDeviceHostImageCopyPropertiesEXT;

typedef VkMemoryToImageCopy VkMemoryToImageCopyEXT;

typedef VkImageToMemoryCopy VkImageToMemoryCopyEXT;

typedef VkCopyMemoryToImageInfo VkCopyMemoryToImageInfoEXT;

typedef VkCopyImageToMemoryInfo VkCopyImageToMemoryInfoEXT;

typedef VkCopyImageToImageInfo VkCopyImageToImageInfoEXT;

typedef VkHostImageLayoutTransitionInfo VkHostImageLayoutTransitionInfoEXT;

typedef VkSubresourceHostMemcpySize VkSubresourceHostMemcpySizeEXT;

typedef VkHostImageCopyDevicePerformanceQuery VkHostImageCopyDevicePerformanceQueryEXT;

typedef VkSubresourceLayout2 VkSubresourceLayout2EXT;

typedef VkImageSubresource2 VkImageSubresource2EXT;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCopyMemoryToImageEXT)(VkDevice device, const VkCopyMemoryToImageInfo* pCopyMemoryToImageInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCopyImageToMemoryEXT)(VkDevice device, const VkCopyImageToMemoryInfo* pCopyImageToMemoryInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCopyImageToImageEXT)(VkDevice device, const VkCopyImageToImageInfo* pCopyImageToImageInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkTransitionImageLayoutEXT)(VkDevice device, uint32_t transitionCount, const VkHostImageLayoutTransitionInfo* pTransitions);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetImageSubresourceLayout2EXT)(VkDevice device, VkImage image, const VkImageSubresource2* pSubresource, VkSubresourceLayout2* pLayout);


 VkResult __attribute__((__stdcall__)) vkCopyMemoryToImageEXT(
    VkDevice device,
    const VkCopyMemoryToImageInfo* pCopyMemoryToImageInfo);

 VkResult __attribute__((__stdcall__)) vkCopyImageToMemoryEXT(
    VkDevice device,
    const VkCopyImageToMemoryInfo* pCopyImageToMemoryInfo);

 VkResult __attribute__((__stdcall__)) vkCopyImageToImageEXT(
    VkDevice device,
    const VkCopyImageToImageInfo* pCopyImageToImageInfo);

 VkResult __attribute__((__stdcall__)) vkTransitionImageLayoutEXT(
    VkDevice device,
    uint32_t transitionCount,
    const VkHostImageLayoutTransitionInfo* pTransitions);

 void __attribute__((__stdcall__)) vkGetImageSubresourceLayout2EXT(
    VkDevice device,
    VkImage image,
    const VkImageSubresource2* pSubresource,
    VkSubresourceLayout2* pLayout);







typedef struct VkPhysicalDeviceMapMemoryPlacedFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 memoryMapPlaced;
    VkBool32 memoryMapRangePlaced;
    VkBool32 memoryUnmapReserve;
} VkPhysicalDeviceMapMemoryPlacedFeaturesEXT;

typedef struct VkPhysicalDeviceMapMemoryPlacedPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    VkDeviceSize minPlacedMemoryMapAlignment;
} VkPhysicalDeviceMapMemoryPlacedPropertiesEXT;

typedef struct VkMemoryMapPlacedInfoEXT {
    VkStructureType sType;
    const void* pNext;
    void* pPlacedAddress;
} VkMemoryMapPlacedInfoEXT;







typedef struct VkPhysicalDeviceShaderAtomicFloat2FeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderBufferFloat16Atomics;
    VkBool32 shaderBufferFloat16AtomicAdd;
    VkBool32 shaderBufferFloat16AtomicMinMax;
    VkBool32 shaderBufferFloat32AtomicMinMax;
    VkBool32 shaderBufferFloat64AtomicMinMax;
    VkBool32 shaderSharedFloat16Atomics;
    VkBool32 shaderSharedFloat16AtomicAdd;
    VkBool32 shaderSharedFloat16AtomicMinMax;
    VkBool32 shaderSharedFloat32AtomicMinMax;
    VkBool32 shaderSharedFloat64AtomicMinMax;
    VkBool32 shaderImageFloat32AtomicMinMax;
    VkBool32 sparseImageFloat32AtomicMinMax;
} VkPhysicalDeviceShaderAtomicFloat2FeaturesEXT;
# 16298 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkPresentScalingFlagBitsEXT {
    VK_PRESENT_SCALING_ONE_TO_ONE_BIT_EXT = 0x00000001,
    VK_PRESENT_SCALING_ASPECT_RATIO_STRETCH_BIT_EXT = 0x00000002,
    VK_PRESENT_SCALING_STRETCH_BIT_EXT = 0x00000004,
    VK_PRESENT_SCALING_FLAG_BITS_MAX_ENUM_EXT = 0x7FFFFFFF
} VkPresentScalingFlagBitsEXT;
typedef VkFlags VkPresentScalingFlagsEXT;

typedef enum VkPresentGravityFlagBitsEXT {
    VK_PRESENT_GRAVITY_MIN_BIT_EXT = 0x00000001,
    VK_PRESENT_GRAVITY_MAX_BIT_EXT = 0x00000002,
    VK_PRESENT_GRAVITY_CENTERED_BIT_EXT = 0x00000004,
    VK_PRESENT_GRAVITY_FLAG_BITS_MAX_ENUM_EXT = 0x7FFFFFFF
} VkPresentGravityFlagBitsEXT;
typedef VkFlags VkPresentGravityFlagsEXT;
typedef struct VkSurfacePresentModeEXT {
    VkStructureType sType;
    void* pNext;
    VkPresentModeKHR presentMode;
} VkSurfacePresentModeEXT;

typedef struct VkSurfacePresentScalingCapabilitiesEXT {
    VkStructureType sType;
    void* pNext;
    VkPresentScalingFlagsEXT supportedPresentScaling;
    VkPresentGravityFlagsEXT supportedPresentGravityX;
    VkPresentGravityFlagsEXT supportedPresentGravityY;
    VkExtent2D minScaledImageExtent;
    VkExtent2D maxScaledImageExtent;
} VkSurfacePresentScalingCapabilitiesEXT;

typedef struct VkSurfacePresentModeCompatibilityEXT {
    VkStructureType sType;
    void* pNext;
    uint32_t presentModeCount;
    VkPresentModeKHR* pPresentModes;
} VkSurfacePresentModeCompatibilityEXT;







typedef struct VkPhysicalDeviceSwapchainMaintenance1FeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 swapchainMaintenance1;
} VkPhysicalDeviceSwapchainMaintenance1FeaturesEXT;

typedef struct VkSwapchainPresentFenceInfoEXT {
    VkStructureType sType;
    const void* pNext;
    uint32_t swapchainCount;
    const VkFence* pFences;
} VkSwapchainPresentFenceInfoEXT;

typedef struct VkSwapchainPresentModesCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    uint32_t presentModeCount;
    const VkPresentModeKHR* pPresentModes;
} VkSwapchainPresentModesCreateInfoEXT;

typedef struct VkSwapchainPresentModeInfoEXT {
    VkStructureType sType;
    const void* pNext;
    uint32_t swapchainCount;
    const VkPresentModeKHR* pPresentModes;
} VkSwapchainPresentModeInfoEXT;

typedef struct VkSwapchainPresentScalingCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkPresentScalingFlagsEXT scalingBehavior;
    VkPresentGravityFlagsEXT presentGravityX;
    VkPresentGravityFlagsEXT presentGravityY;
} VkSwapchainPresentScalingCreateInfoEXT;

typedef struct VkReleaseSwapchainImagesInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkSwapchainKHR swapchain;
    uint32_t imageIndexCount;
    const uint32_t* pImageIndices;
} VkReleaseSwapchainImagesInfoEXT;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkReleaseSwapchainImagesEXT)(VkDevice device, const VkReleaseSwapchainImagesInfoEXT* pReleaseInfo);


 VkResult __attribute__((__stdcall__)) vkReleaseSwapchainImagesEXT(
    VkDevice device,
    const VkReleaseSwapchainImagesInfoEXT* pReleaseInfo);







typedef VkPhysicalDeviceShaderDemoteToHelperInvocationFeatures VkPhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT;





typedef struct VkIndirectCommandsLayoutNV_T *VkIndirectCommandsLayoutNV;



typedef enum VkIndirectCommandsTokenTypeNV {
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_SHADER_GROUP_NV = 0,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_STATE_FLAGS_NV = 1,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_INDEX_BUFFER_NV = 2,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_VERTEX_BUFFER_NV = 3,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_PUSH_CONSTANT_NV = 4,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_DRAW_INDEXED_NV = 5,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_DRAW_NV = 6,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_DRAW_TASKS_NV = 7,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_DRAW_MESH_TASKS_NV = 1000328000,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_PIPELINE_NV = 1000428003,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_DISPATCH_NV = 1000428004,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_MAX_ENUM_NV = 0x7FFFFFFF
} VkIndirectCommandsTokenTypeNV;

typedef enum VkIndirectStateFlagBitsNV {
    VK_INDIRECT_STATE_FLAG_FRONTFACE_BIT_NV = 0x00000001,
    VK_INDIRECT_STATE_FLAG_BITS_MAX_ENUM_NV = 0x7FFFFFFF
} VkIndirectStateFlagBitsNV;
typedef VkFlags VkIndirectStateFlagsNV;

typedef enum VkIndirectCommandsLayoutUsageFlagBitsNV {
    VK_INDIRECT_COMMANDS_LAYOUT_USAGE_EXPLICIT_PREPROCESS_BIT_NV = 0x00000001,
    VK_INDIRECT_COMMANDS_LAYOUT_USAGE_INDEXED_SEQUENCES_BIT_NV = 0x00000002,
    VK_INDIRECT_COMMANDS_LAYOUT_USAGE_UNORDERED_SEQUENCES_BIT_NV = 0x00000004,
    VK_INDIRECT_COMMANDS_LAYOUT_USAGE_FLAG_BITS_MAX_ENUM_NV = 0x7FFFFFFF
} VkIndirectCommandsLayoutUsageFlagBitsNV;
typedef VkFlags VkIndirectCommandsLayoutUsageFlagsNV;
typedef struct VkPhysicalDeviceDeviceGeneratedCommandsPropertiesNV {
    VkStructureType sType;
    void* pNext;
    uint32_t maxGraphicsShaderGroupCount;
    uint32_t maxIndirectSequenceCount;
    uint32_t maxIndirectCommandsTokenCount;
    uint32_t maxIndirectCommandsStreamCount;
    uint32_t maxIndirectCommandsTokenOffset;
    uint32_t maxIndirectCommandsStreamStride;
    uint32_t minSequencesCountBufferOffsetAlignment;
    uint32_t minSequencesIndexBufferOffsetAlignment;
    uint32_t minIndirectCommandsBufferOffsetAlignment;
} VkPhysicalDeviceDeviceGeneratedCommandsPropertiesNV;

typedef struct VkPhysicalDeviceDeviceGeneratedCommandsFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 deviceGeneratedCommands;
} VkPhysicalDeviceDeviceGeneratedCommandsFeaturesNV;

typedef struct VkGraphicsShaderGroupCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    uint32_t stageCount;
    const VkPipelineShaderStageCreateInfo* pStages;
    const VkPipelineVertexInputStateCreateInfo* pVertexInputState;
    const VkPipelineTessellationStateCreateInfo* pTessellationState;
} VkGraphicsShaderGroupCreateInfoNV;

typedef struct VkGraphicsPipelineShaderGroupsCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    uint32_t groupCount;
    const VkGraphicsShaderGroupCreateInfoNV* pGroups;
    uint32_t pipelineCount;
    const VkPipeline* pPipelines;
} VkGraphicsPipelineShaderGroupsCreateInfoNV;

typedef struct VkBindShaderGroupIndirectCommandNV {
    uint32_t groupIndex;
} VkBindShaderGroupIndirectCommandNV;

typedef struct VkBindIndexBufferIndirectCommandNV {
    VkDeviceAddress bufferAddress;
    uint32_t size;
    VkIndexType indexType;
} VkBindIndexBufferIndirectCommandNV;

typedef struct VkBindVertexBufferIndirectCommandNV {
    VkDeviceAddress bufferAddress;
    uint32_t size;
    uint32_t stride;
} VkBindVertexBufferIndirectCommandNV;

typedef struct VkSetStateFlagsIndirectCommandNV {
    uint32_t data;
} VkSetStateFlagsIndirectCommandNV;

typedef struct VkIndirectCommandsStreamNV {
    VkBuffer buffer;
    VkDeviceSize offset;
} VkIndirectCommandsStreamNV;

typedef struct VkIndirectCommandsLayoutTokenNV {
    VkStructureType sType;
    const void* pNext;
    VkIndirectCommandsTokenTypeNV tokenType;
    uint32_t stream;
    uint32_t offset;
    uint32_t vertexBindingUnit;
    VkBool32 vertexDynamicStride;
    VkPipelineLayout pushconstantPipelineLayout;
    VkShaderStageFlags pushconstantShaderStageFlags;
    uint32_t pushconstantOffset;
    uint32_t pushconstantSize;
    VkIndirectStateFlagsNV indirectStateFlags;
    uint32_t indexTypeCount;
    const VkIndexType* pIndexTypes;
    const uint32_t* pIndexTypeValues;
} VkIndirectCommandsLayoutTokenNV;

typedef struct VkIndirectCommandsLayoutCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkIndirectCommandsLayoutUsageFlagsNV flags;
    VkPipelineBindPoint pipelineBindPoint;
    uint32_t tokenCount;
    const VkIndirectCommandsLayoutTokenNV* pTokens;
    uint32_t streamCount;
    const uint32_t* pStreamStrides;
} VkIndirectCommandsLayoutCreateInfoNV;

typedef struct VkGeneratedCommandsInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkPipelineBindPoint pipelineBindPoint;
    VkPipeline pipeline;
    VkIndirectCommandsLayoutNV indirectCommandsLayout;
    uint32_t streamCount;
    const VkIndirectCommandsStreamNV* pStreams;
    uint32_t sequencesCount;
    VkBuffer preprocessBuffer;
    VkDeviceSize preprocessOffset;
    VkDeviceSize preprocessSize;
    VkBuffer sequencesCountBuffer;
    VkDeviceSize sequencesCountOffset;
    VkBuffer sequencesIndexBuffer;
    VkDeviceSize sequencesIndexOffset;
} VkGeneratedCommandsInfoNV;

typedef struct VkGeneratedCommandsMemoryRequirementsInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkPipelineBindPoint pipelineBindPoint;
    VkPipeline pipeline;
    VkIndirectCommandsLayoutNV indirectCommandsLayout;
    uint32_t maxSequencesCount;
} VkGeneratedCommandsMemoryRequirementsInfoNV;

typedef void (__attribute__((__stdcall__)) *PFN_vkGetGeneratedCommandsMemoryRequirementsNV)(VkDevice device, const VkGeneratedCommandsMemoryRequirementsInfoNV* pInfo, VkMemoryRequirements2* pMemoryRequirements);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdPreprocessGeneratedCommandsNV)(VkCommandBuffer commandBuffer, const VkGeneratedCommandsInfoNV* pGeneratedCommandsInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdExecuteGeneratedCommandsNV)(VkCommandBuffer commandBuffer, VkBool32 isPreprocessed, const VkGeneratedCommandsInfoNV* pGeneratedCommandsInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBindPipelineShaderGroupNV)(VkCommandBuffer commandBuffer, VkPipelineBindPoint pipelineBindPoint, VkPipeline pipeline, uint32_t groupIndex);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateIndirectCommandsLayoutNV)(VkDevice device, const VkIndirectCommandsLayoutCreateInfoNV* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkIndirectCommandsLayoutNV* pIndirectCommandsLayout);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyIndirectCommandsLayoutNV)(VkDevice device, VkIndirectCommandsLayoutNV indirectCommandsLayout, const VkAllocationCallbacks* pAllocator);


 void __attribute__((__stdcall__)) vkGetGeneratedCommandsMemoryRequirementsNV(
    VkDevice device,
    const VkGeneratedCommandsMemoryRequirementsInfoNV* pInfo,
    VkMemoryRequirements2* pMemoryRequirements);

 void __attribute__((__stdcall__)) vkCmdPreprocessGeneratedCommandsNV(
    VkCommandBuffer commandBuffer,
    const VkGeneratedCommandsInfoNV* pGeneratedCommandsInfo);

 void __attribute__((__stdcall__)) vkCmdExecuteGeneratedCommandsNV(
    VkCommandBuffer commandBuffer,
    VkBool32 isPreprocessed,
    const VkGeneratedCommandsInfoNV* pGeneratedCommandsInfo);

 void __attribute__((__stdcall__)) vkCmdBindPipelineShaderGroupNV(
    VkCommandBuffer commandBuffer,
    VkPipelineBindPoint pipelineBindPoint,
    VkPipeline pipeline,
    uint32_t groupIndex);

 VkResult __attribute__((__stdcall__)) vkCreateIndirectCommandsLayoutNV(
    VkDevice device,
    const VkIndirectCommandsLayoutCreateInfoNV* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkIndirectCommandsLayoutNV* pIndirectCommandsLayout);

 void __attribute__((__stdcall__)) vkDestroyIndirectCommandsLayoutNV(
    VkDevice device,
    VkIndirectCommandsLayoutNV indirectCommandsLayout,
    const VkAllocationCallbacks* pAllocator);







typedef struct VkPhysicalDeviceInheritedViewportScissorFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 inheritedViewportScissor2D;
} VkPhysicalDeviceInheritedViewportScissorFeaturesNV;

typedef struct VkCommandBufferInheritanceViewportScissorInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkBool32 viewportScissor2D;
    uint32_t viewportDepthCount;
    const VkViewport* pViewportDepths;
} VkCommandBufferInheritanceViewportScissorInfoNV;







typedef struct VkPhysicalDeviceTexelBufferAlignmentFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 texelBufferAlignment;
} VkPhysicalDeviceTexelBufferAlignmentFeaturesEXT;

typedef VkPhysicalDeviceTexelBufferAlignmentProperties VkPhysicalDeviceTexelBufferAlignmentPropertiesEXT;







typedef struct VkRenderPassTransformBeginInfoQCOM {
    VkStructureType sType;
    void* pNext;
    VkSurfaceTransformFlagBitsKHR transform;
} VkRenderPassTransformBeginInfoQCOM;

typedef struct VkCommandBufferInheritanceRenderPassTransformInfoQCOM {
    VkStructureType sType;
    void* pNext;
    VkSurfaceTransformFlagBitsKHR transform;
    VkRect2D renderArea;
} VkCommandBufferInheritanceRenderPassTransformInfoQCOM;
# 16654 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkDepthBiasRepresentationEXT {
    VK_DEPTH_BIAS_REPRESENTATION_LEAST_REPRESENTABLE_VALUE_FORMAT_EXT = 0,
    VK_DEPTH_BIAS_REPRESENTATION_LEAST_REPRESENTABLE_VALUE_FORCE_UNORM_EXT = 1,
    VK_DEPTH_BIAS_REPRESENTATION_FLOAT_EXT = 2,
    VK_DEPTH_BIAS_REPRESENTATION_MAX_ENUM_EXT = 0x7FFFFFFF
} VkDepthBiasRepresentationEXT;
typedef struct VkPhysicalDeviceDepthBiasControlFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 depthBiasControl;
    VkBool32 leastRepresentableValueForceUnormRepresentation;
    VkBool32 floatRepresentation;
    VkBool32 depthBiasExact;
} VkPhysicalDeviceDepthBiasControlFeaturesEXT;

typedef struct VkDepthBiasInfoEXT {
    VkStructureType sType;
    const void* pNext;
    float depthBiasConstantFactor;
    float depthBiasClamp;
    float depthBiasSlopeFactor;
} VkDepthBiasInfoEXT;

typedef struct VkDepthBiasRepresentationInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkDepthBiasRepresentationEXT depthBiasRepresentation;
    VkBool32 depthBiasExact;
} VkDepthBiasRepresentationInfoEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDepthBias2EXT)(VkCommandBuffer commandBuffer, const VkDepthBiasInfoEXT* pDepthBiasInfo);


 void __attribute__((__stdcall__)) vkCmdSetDepthBias2EXT(
    VkCommandBuffer commandBuffer,
    const VkDepthBiasInfoEXT* pDepthBiasInfo);
# 16698 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkDeviceMemoryReportEventTypeEXT {
    VK_DEVICE_MEMORY_REPORT_EVENT_TYPE_ALLOCATE_EXT = 0,
    VK_DEVICE_MEMORY_REPORT_EVENT_TYPE_FREE_EXT = 1,
    VK_DEVICE_MEMORY_REPORT_EVENT_TYPE_IMPORT_EXT = 2,
    VK_DEVICE_MEMORY_REPORT_EVENT_TYPE_UNIMPORT_EXT = 3,
    VK_DEVICE_MEMORY_REPORT_EVENT_TYPE_ALLOCATION_FAILED_EXT = 4,
    VK_DEVICE_MEMORY_REPORT_EVENT_TYPE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkDeviceMemoryReportEventTypeEXT;
typedef VkFlags VkDeviceMemoryReportFlagsEXT;
typedef struct VkPhysicalDeviceDeviceMemoryReportFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 deviceMemoryReport;
} VkPhysicalDeviceDeviceMemoryReportFeaturesEXT;

typedef struct VkDeviceMemoryReportCallbackDataEXT {
    VkStructureType sType;
    void* pNext;
    VkDeviceMemoryReportFlagsEXT flags;
    VkDeviceMemoryReportEventTypeEXT type;
    uint64_t memoryObjectId;
    VkDeviceSize size;
    VkObjectType objectType;
    uint64_t objectHandle;
    uint32_t heapIndex;
} VkDeviceMemoryReportCallbackDataEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkDeviceMemoryReportCallbackEXT)(
    const VkDeviceMemoryReportCallbackDataEXT* pCallbackData,
    void* pUserData);

typedef struct VkDeviceDeviceMemoryReportCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkDeviceMemoryReportFlagsEXT flags;
    PFN_vkDeviceMemoryReportCallbackEXT pfnUserCallback;
    void* pUserData;
} VkDeviceDeviceMemoryReportCreateInfoEXT;







typedef VkResult (__attribute__((__stdcall__)) *PFN_vkAcquireDrmDisplayEXT)(VkPhysicalDevice physicalDevice, int32_t drmFd, VkDisplayKHR display);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetDrmDisplayEXT)(VkPhysicalDevice physicalDevice, int32_t drmFd, uint32_t connectorId, VkDisplayKHR* display);


 VkResult __attribute__((__stdcall__)) vkAcquireDrmDisplayEXT(
    VkPhysicalDevice physicalDevice,
    int32_t drmFd,
    VkDisplayKHR display);

 VkResult __attribute__((__stdcall__)) vkGetDrmDisplayEXT(
    VkPhysicalDevice physicalDevice,
    int32_t drmFd,
    uint32_t connectorId,
    VkDisplayKHR* display);







typedef struct VkPhysicalDeviceRobustness2FeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 robustBufferAccess2;
    VkBool32 robustImageAccess2;
    VkBool32 nullDescriptor;
} VkPhysicalDeviceRobustness2FeaturesEXT;

typedef struct VkPhysicalDeviceRobustness2PropertiesEXT {
    VkStructureType sType;
    void* pNext;
    VkDeviceSize robustStorageBufferAccessSizeAlignment;
    VkDeviceSize robustUniformBufferAccessSizeAlignment;
} VkPhysicalDeviceRobustness2PropertiesEXT;







typedef struct VkSamplerCustomBorderColorCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkClearColorValue customBorderColor;
    VkFormat format;
} VkSamplerCustomBorderColorCreateInfoEXT;

typedef struct VkPhysicalDeviceCustomBorderColorPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    uint32_t maxCustomBorderColorSamplers;
} VkPhysicalDeviceCustomBorderColorPropertiesEXT;

typedef struct VkPhysicalDeviceCustomBorderColorFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 customBorderColors;
    VkBool32 customBorderColorWithoutFormat;
} VkPhysicalDeviceCustomBorderColorFeaturesEXT;
# 16817 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkPhysicalDevicePresentBarrierFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 presentBarrier;
} VkPhysicalDevicePresentBarrierFeaturesNV;

typedef struct VkSurfaceCapabilitiesPresentBarrierNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 presentBarrierSupported;
} VkSurfaceCapabilitiesPresentBarrierNV;

typedef struct VkSwapchainPresentBarrierCreateInfoNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 presentBarrierEnable;
} VkSwapchainPresentBarrierCreateInfoNV;





typedef VkPrivateDataSlot VkPrivateDataSlotEXT;



typedef VkPrivateDataSlotCreateFlags VkPrivateDataSlotCreateFlagsEXT;

typedef VkPhysicalDevicePrivateDataFeatures VkPhysicalDevicePrivateDataFeaturesEXT;

typedef VkDevicePrivateDataCreateInfo VkDevicePrivateDataCreateInfoEXT;

typedef VkPrivateDataSlotCreateInfo VkPrivateDataSlotCreateInfoEXT;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreatePrivateDataSlotEXT)(VkDevice device, const VkPrivateDataSlotCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkPrivateDataSlot* pPrivateDataSlot);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyPrivateDataSlotEXT)(VkDevice device, VkPrivateDataSlot privateDataSlot, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkSetPrivateDataEXT)(VkDevice device, VkObjectType objectType, uint64_t objectHandle, VkPrivateDataSlot privateDataSlot, uint64_t data);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetPrivateDataEXT)(VkDevice device, VkObjectType objectType, uint64_t objectHandle, VkPrivateDataSlot privateDataSlot, uint64_t* pData);


 VkResult __attribute__((__stdcall__)) vkCreatePrivateDataSlotEXT(
    VkDevice device,
    const VkPrivateDataSlotCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkPrivateDataSlot* pPrivateDataSlot);

 void __attribute__((__stdcall__)) vkDestroyPrivateDataSlotEXT(
    VkDevice device,
    VkPrivateDataSlot privateDataSlot,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkSetPrivateDataEXT(
    VkDevice device,
    VkObjectType objectType,
    uint64_t objectHandle,
    VkPrivateDataSlot privateDataSlot,
    uint64_t data);

 void __attribute__((__stdcall__)) vkGetPrivateDataEXT(
    VkDevice device,
    VkObjectType objectType,
    uint64_t objectHandle,
    VkPrivateDataSlot privateDataSlot,
    uint64_t* pData);







typedef VkPhysicalDevicePipelineCreationCacheControlFeatures VkPhysicalDevicePipelineCreationCacheControlFeaturesEXT;
# 16897 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkDeviceDiagnosticsConfigFlagBitsNV {
    VK_DEVICE_DIAGNOSTICS_CONFIG_ENABLE_SHADER_DEBUG_INFO_BIT_NV = 0x00000001,
    VK_DEVICE_DIAGNOSTICS_CONFIG_ENABLE_RESOURCE_TRACKING_BIT_NV = 0x00000002,
    VK_DEVICE_DIAGNOSTICS_CONFIG_ENABLE_AUTOMATIC_CHECKPOINTS_BIT_NV = 0x00000004,
    VK_DEVICE_DIAGNOSTICS_CONFIG_ENABLE_SHADER_ERROR_REPORTING_BIT_NV = 0x00000008,
    VK_DEVICE_DIAGNOSTICS_CONFIG_FLAG_BITS_MAX_ENUM_NV = 0x7FFFFFFF
} VkDeviceDiagnosticsConfigFlagBitsNV;
typedef VkFlags VkDeviceDiagnosticsConfigFlagsNV;
typedef struct VkPhysicalDeviceDiagnosticsConfigFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 diagnosticsConfig;
} VkPhysicalDeviceDiagnosticsConfigFeaturesNV;

typedef struct VkDeviceDiagnosticsConfigCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkDeviceDiagnosticsConfigFlagsNV flags;
} VkDeviceDiagnosticsConfigCreateInfoNV;
# 16927 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkCudaModuleNV_T *VkCudaModuleNV;
typedef struct VkCudaFunctionNV_T *VkCudaFunctionNV;


typedef struct VkCudaModuleCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    size_t dataSize;
    const void* pData;
} VkCudaModuleCreateInfoNV;

typedef struct VkCudaFunctionCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkCudaModuleNV module;
    const char* pName;
} VkCudaFunctionCreateInfoNV;

typedef struct VkCudaLaunchInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkCudaFunctionNV function;
    uint32_t gridDimX;
    uint32_t gridDimY;
    uint32_t gridDimZ;
    uint32_t blockDimX;
    uint32_t blockDimY;
    uint32_t blockDimZ;
    uint32_t sharedMemBytes;
    size_t paramCount;
    const void* const * pParams;
    size_t extraCount;
    const void* const * pExtras;
} VkCudaLaunchInfoNV;

typedef struct VkPhysicalDeviceCudaKernelLaunchFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 cudaKernelLaunchFeatures;
} VkPhysicalDeviceCudaKernelLaunchFeaturesNV;

typedef struct VkPhysicalDeviceCudaKernelLaunchPropertiesNV {
    VkStructureType sType;
    void* pNext;
    uint32_t computeCapabilityMinor;
    uint32_t computeCapabilityMajor;
} VkPhysicalDeviceCudaKernelLaunchPropertiesNV;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateCudaModuleNV)(VkDevice device, const VkCudaModuleCreateInfoNV* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkCudaModuleNV* pModule);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetCudaModuleCacheNV)(VkDevice device, VkCudaModuleNV module, size_t* pCacheSize, void* pCacheData);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateCudaFunctionNV)(VkDevice device, const VkCudaFunctionCreateInfoNV* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkCudaFunctionNV* pFunction);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyCudaModuleNV)(VkDevice device, VkCudaModuleNV module, const VkAllocationCallbacks* pAllocator);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyCudaFunctionNV)(VkDevice device, VkCudaFunctionNV function, const VkAllocationCallbacks* pAllocator);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCudaLaunchKernelNV)(VkCommandBuffer commandBuffer, const VkCudaLaunchInfoNV* pLaunchInfo);


 VkResult __attribute__((__stdcall__)) vkCreateCudaModuleNV(
    VkDevice device,
    const VkCudaModuleCreateInfoNV* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkCudaModuleNV* pModule);

 VkResult __attribute__((__stdcall__)) vkGetCudaModuleCacheNV(
    VkDevice device,
    VkCudaModuleNV module,
    size_t* pCacheSize,
    void* pCacheData);

 VkResult __attribute__((__stdcall__)) vkCreateCudaFunctionNV(
    VkDevice device,
    const VkCudaFunctionCreateInfoNV* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkCudaFunctionNV* pFunction);

 void __attribute__((__stdcall__)) vkDestroyCudaModuleNV(
    VkDevice device,
    VkCudaModuleNV module,
    const VkAllocationCallbacks* pAllocator);

 void __attribute__((__stdcall__)) vkDestroyCudaFunctionNV(
    VkDevice device,
    VkCudaFunctionNV function,
    const VkAllocationCallbacks* pAllocator);

 void __attribute__((__stdcall__)) vkCmdCudaLaunchKernelNV(
    VkCommandBuffer commandBuffer,
    const VkCudaLaunchInfoNV* pLaunchInfo);







typedef struct VkQueryLowLatencySupportNV {
    VkStructureType sType;
    const void* pNext;
    void* pQueriedLowLatencyData;
} VkQueryLowLatencySupportNV;





typedef struct VkAccelerationStructureKHR_T *VkAccelerationStructureKHR;


typedef struct VkPhysicalDeviceDescriptorBufferPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 combinedImageSamplerDescriptorSingleArray;
    VkBool32 bufferlessPushDescriptors;
    VkBool32 allowSamplerImageViewPostSubmitCreation;
    VkDeviceSize descriptorBufferOffsetAlignment;
    uint32_t maxDescriptorBufferBindings;
    uint32_t maxResourceDescriptorBufferBindings;
    uint32_t maxSamplerDescriptorBufferBindings;
    uint32_t maxEmbeddedImmutableSamplerBindings;
    uint32_t maxEmbeddedImmutableSamplers;
    size_t bufferCaptureReplayDescriptorDataSize;
    size_t imageCaptureReplayDescriptorDataSize;
    size_t imageViewCaptureReplayDescriptorDataSize;
    size_t samplerCaptureReplayDescriptorDataSize;
    size_t accelerationStructureCaptureReplayDescriptorDataSize;
    size_t samplerDescriptorSize;
    size_t combinedImageSamplerDescriptorSize;
    size_t sampledImageDescriptorSize;
    size_t storageImageDescriptorSize;
    size_t uniformTexelBufferDescriptorSize;
    size_t robustUniformTexelBufferDescriptorSize;
    size_t storageTexelBufferDescriptorSize;
    size_t robustStorageTexelBufferDescriptorSize;
    size_t uniformBufferDescriptorSize;
    size_t robustUniformBufferDescriptorSize;
    size_t storageBufferDescriptorSize;
    size_t robustStorageBufferDescriptorSize;
    size_t inputAttachmentDescriptorSize;
    size_t accelerationStructureDescriptorSize;
    VkDeviceSize maxSamplerDescriptorBufferRange;
    VkDeviceSize maxResourceDescriptorBufferRange;
    VkDeviceSize samplerDescriptorBufferAddressSpaceSize;
    VkDeviceSize resourceDescriptorBufferAddressSpaceSize;
    VkDeviceSize descriptorBufferAddressSpaceSize;
} VkPhysicalDeviceDescriptorBufferPropertiesEXT;

typedef struct VkPhysicalDeviceDescriptorBufferDensityMapPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    size_t combinedImageSamplerDensityMapDescriptorSize;
} VkPhysicalDeviceDescriptorBufferDensityMapPropertiesEXT;

typedef struct VkPhysicalDeviceDescriptorBufferFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 descriptorBuffer;
    VkBool32 descriptorBufferCaptureReplay;
    VkBool32 descriptorBufferImageLayoutIgnored;
    VkBool32 descriptorBufferPushDescriptors;
} VkPhysicalDeviceDescriptorBufferFeaturesEXT;

typedef struct VkDescriptorAddressInfoEXT {
    VkStructureType sType;
    void* pNext;
    VkDeviceAddress address;
    VkDeviceSize range;
    VkFormat format;
} VkDescriptorAddressInfoEXT;

typedef struct VkDescriptorBufferBindingInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkDeviceAddress address;
    VkBufferUsageFlags usage;
} VkDescriptorBufferBindingInfoEXT;

typedef struct VkDescriptorBufferBindingPushDescriptorBufferHandleEXT {
    VkStructureType sType;
    const void* pNext;
    VkBuffer buffer;
} VkDescriptorBufferBindingPushDescriptorBufferHandleEXT;

typedef union VkDescriptorDataEXT {
    const VkSampler* pSampler;
    const VkDescriptorImageInfo* pCombinedImageSampler;
    const VkDescriptorImageInfo* pInputAttachmentImage;
    const VkDescriptorImageInfo* pSampledImage;
    const VkDescriptorImageInfo* pStorageImage;
    const VkDescriptorAddressInfoEXT* pUniformTexelBuffer;
    const VkDescriptorAddressInfoEXT* pStorageTexelBuffer;
    const VkDescriptorAddressInfoEXT* pUniformBuffer;
    const VkDescriptorAddressInfoEXT* pStorageBuffer;
    VkDeviceAddress accelerationStructure;
} VkDescriptorDataEXT;

typedef struct VkDescriptorGetInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkDescriptorType type;
    VkDescriptorDataEXT data;
} VkDescriptorGetInfoEXT;

typedef struct VkBufferCaptureDescriptorDataInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkBuffer buffer;
} VkBufferCaptureDescriptorDataInfoEXT;

typedef struct VkImageCaptureDescriptorDataInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkImage image;
} VkImageCaptureDescriptorDataInfoEXT;

typedef struct VkImageViewCaptureDescriptorDataInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkImageView imageView;
} VkImageViewCaptureDescriptorDataInfoEXT;

typedef struct VkSamplerCaptureDescriptorDataInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkSampler sampler;
} VkSamplerCaptureDescriptorDataInfoEXT;

typedef struct VkOpaqueCaptureDescriptorDataCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    const void* opaqueCaptureDescriptorData;
} VkOpaqueCaptureDescriptorDataCreateInfoEXT;

typedef struct VkAccelerationStructureCaptureDescriptorDataInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkAccelerationStructureKHR accelerationStructure;
    VkAccelerationStructureNV accelerationStructureNV;
} VkAccelerationStructureCaptureDescriptorDataInfoEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkGetDescriptorSetLayoutSizeEXT)(VkDevice device, VkDescriptorSetLayout layout, VkDeviceSize* pLayoutSizeInBytes);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetDescriptorSetLayoutBindingOffsetEXT)(VkDevice device, VkDescriptorSetLayout layout, uint32_t binding, VkDeviceSize* pOffset);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetDescriptorEXT)(VkDevice device, const VkDescriptorGetInfoEXT* pDescriptorInfo, size_t dataSize, void* pDescriptor);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBindDescriptorBuffersEXT)(VkCommandBuffer commandBuffer, uint32_t bufferCount, const VkDescriptorBufferBindingInfoEXT* pBindingInfos);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDescriptorBufferOffsetsEXT)(VkCommandBuffer commandBuffer, VkPipelineBindPoint pipelineBindPoint, VkPipelineLayout layout, uint32_t firstSet, uint32_t setCount, const uint32_t* pBufferIndices, const VkDeviceSize* pOffsets);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBindDescriptorBufferEmbeddedSamplersEXT)(VkCommandBuffer commandBuffer, VkPipelineBindPoint pipelineBindPoint, VkPipelineLayout layout, uint32_t set);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetBufferOpaqueCaptureDescriptorDataEXT)(VkDevice device, const VkBufferCaptureDescriptorDataInfoEXT* pInfo, void* pData);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetImageOpaqueCaptureDescriptorDataEXT)(VkDevice device, const VkImageCaptureDescriptorDataInfoEXT* pInfo, void* pData);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetImageViewOpaqueCaptureDescriptorDataEXT)(VkDevice device, const VkImageViewCaptureDescriptorDataInfoEXT* pInfo, void* pData);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetSamplerOpaqueCaptureDescriptorDataEXT)(VkDevice device, const VkSamplerCaptureDescriptorDataInfoEXT* pInfo, void* pData);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetAccelerationStructureOpaqueCaptureDescriptorDataEXT)(VkDevice device, const VkAccelerationStructureCaptureDescriptorDataInfoEXT* pInfo, void* pData);


 void __attribute__((__stdcall__)) vkGetDescriptorSetLayoutSizeEXT(
    VkDevice device,
    VkDescriptorSetLayout layout,
    VkDeviceSize* pLayoutSizeInBytes);

 void __attribute__((__stdcall__)) vkGetDescriptorSetLayoutBindingOffsetEXT(
    VkDevice device,
    VkDescriptorSetLayout layout,
    uint32_t binding,
    VkDeviceSize* pOffset);

 void __attribute__((__stdcall__)) vkGetDescriptorEXT(
    VkDevice device,
    const VkDescriptorGetInfoEXT* pDescriptorInfo,
    size_t dataSize,
    void* pDescriptor);

 void __attribute__((__stdcall__)) vkCmdBindDescriptorBuffersEXT(
    VkCommandBuffer commandBuffer,
    uint32_t bufferCount,
    const VkDescriptorBufferBindingInfoEXT* pBindingInfos);

 void __attribute__((__stdcall__)) vkCmdSetDescriptorBufferOffsetsEXT(
    VkCommandBuffer commandBuffer,
    VkPipelineBindPoint pipelineBindPoint,
    VkPipelineLayout layout,
    uint32_t firstSet,
    uint32_t setCount,
    const uint32_t* pBufferIndices,
    const VkDeviceSize* pOffsets);

 void __attribute__((__stdcall__)) vkCmdBindDescriptorBufferEmbeddedSamplersEXT(
    VkCommandBuffer commandBuffer,
    VkPipelineBindPoint pipelineBindPoint,
    VkPipelineLayout layout,
    uint32_t set);

 VkResult __attribute__((__stdcall__)) vkGetBufferOpaqueCaptureDescriptorDataEXT(
    VkDevice device,
    const VkBufferCaptureDescriptorDataInfoEXT* pInfo,
    void* pData);

 VkResult __attribute__((__stdcall__)) vkGetImageOpaqueCaptureDescriptorDataEXT(
    VkDevice device,
    const VkImageCaptureDescriptorDataInfoEXT* pInfo,
    void* pData);

 VkResult __attribute__((__stdcall__)) vkGetImageViewOpaqueCaptureDescriptorDataEXT(
    VkDevice device,
    const VkImageViewCaptureDescriptorDataInfoEXT* pInfo,
    void* pData);

 VkResult __attribute__((__stdcall__)) vkGetSamplerOpaqueCaptureDescriptorDataEXT(
    VkDevice device,
    const VkSamplerCaptureDescriptorDataInfoEXT* pInfo,
    void* pData);

 VkResult __attribute__((__stdcall__)) vkGetAccelerationStructureOpaqueCaptureDescriptorDataEXT(
    VkDevice device,
    const VkAccelerationStructureCaptureDescriptorDataInfoEXT* pInfo,
    void* pData);
# 17247 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkGraphicsPipelineLibraryFlagBitsEXT {
    VK_GRAPHICS_PIPELINE_LIBRARY_VERTEX_INPUT_INTERFACE_BIT_EXT = 0x00000001,
    VK_GRAPHICS_PIPELINE_LIBRARY_PRE_RASTERIZATION_SHADERS_BIT_EXT = 0x00000002,
    VK_GRAPHICS_PIPELINE_LIBRARY_FRAGMENT_SHADER_BIT_EXT = 0x00000004,
    VK_GRAPHICS_PIPELINE_LIBRARY_FRAGMENT_OUTPUT_INTERFACE_BIT_EXT = 0x00000008,
    VK_GRAPHICS_PIPELINE_LIBRARY_FLAG_BITS_MAX_ENUM_EXT = 0x7FFFFFFF
} VkGraphicsPipelineLibraryFlagBitsEXT;
typedef VkFlags VkGraphicsPipelineLibraryFlagsEXT;
typedef struct VkPhysicalDeviceGraphicsPipelineLibraryFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 graphicsPipelineLibrary;
} VkPhysicalDeviceGraphicsPipelineLibraryFeaturesEXT;

typedef struct VkPhysicalDeviceGraphicsPipelineLibraryPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 graphicsPipelineLibraryFastLinking;
    VkBool32 graphicsPipelineLibraryIndependentInterpolationDecoration;
} VkPhysicalDeviceGraphicsPipelineLibraryPropertiesEXT;

typedef struct VkGraphicsPipelineLibraryCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkGraphicsPipelineLibraryFlagsEXT flags;
} VkGraphicsPipelineLibraryCreateInfoEXT;







typedef struct VkPhysicalDeviceShaderEarlyAndLateFragmentTestsFeaturesAMD {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderEarlyAndLateFragmentTests;
} VkPhysicalDeviceShaderEarlyAndLateFragmentTestsFeaturesAMD;
# 17293 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkFragmentShadingRateTypeNV {
    VK_FRAGMENT_SHADING_RATE_TYPE_FRAGMENT_SIZE_NV = 0,
    VK_FRAGMENT_SHADING_RATE_TYPE_ENUMS_NV = 1,
    VK_FRAGMENT_SHADING_RATE_TYPE_MAX_ENUM_NV = 0x7FFFFFFF
} VkFragmentShadingRateTypeNV;

typedef enum VkFragmentShadingRateNV {
    VK_FRAGMENT_SHADING_RATE_1_INVOCATION_PER_PIXEL_NV = 0,
    VK_FRAGMENT_SHADING_RATE_1_INVOCATION_PER_1X2_PIXELS_NV = 1,
    VK_FRAGMENT_SHADING_RATE_1_INVOCATION_PER_2X1_PIXELS_NV = 4,
    VK_FRAGMENT_SHADING_RATE_1_INVOCATION_PER_2X2_PIXELS_NV = 5,
    VK_FRAGMENT_SHADING_RATE_1_INVOCATION_PER_2X4_PIXELS_NV = 6,
    VK_FRAGMENT_SHADING_RATE_1_INVOCATION_PER_4X2_PIXELS_NV = 9,
    VK_FRAGMENT_SHADING_RATE_1_INVOCATION_PER_4X4_PIXELS_NV = 10,
    VK_FRAGMENT_SHADING_RATE_2_INVOCATIONS_PER_PIXEL_NV = 11,
    VK_FRAGMENT_SHADING_RATE_4_INVOCATIONS_PER_PIXEL_NV = 12,
    VK_FRAGMENT_SHADING_RATE_8_INVOCATIONS_PER_PIXEL_NV = 13,
    VK_FRAGMENT_SHADING_RATE_16_INVOCATIONS_PER_PIXEL_NV = 14,
    VK_FRAGMENT_SHADING_RATE_NO_INVOCATIONS_NV = 15,
    VK_FRAGMENT_SHADING_RATE_MAX_ENUM_NV = 0x7FFFFFFF
} VkFragmentShadingRateNV;
typedef struct VkPhysicalDeviceFragmentShadingRateEnumsFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 fragmentShadingRateEnums;
    VkBool32 supersampleFragmentShadingRates;
    VkBool32 noInvocationFragmentShadingRates;
} VkPhysicalDeviceFragmentShadingRateEnumsFeaturesNV;

typedef struct VkPhysicalDeviceFragmentShadingRateEnumsPropertiesNV {
    VkStructureType sType;
    void* pNext;
    VkSampleCountFlagBits maxFragmentShadingRateInvocationCount;
} VkPhysicalDeviceFragmentShadingRateEnumsPropertiesNV;

typedef struct VkPipelineFragmentShadingRateEnumStateCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkFragmentShadingRateTypeNV shadingRateType;
    VkFragmentShadingRateNV shadingRate;
    VkFragmentShadingRateCombinerOpKHR combinerOps[2];
} VkPipelineFragmentShadingRateEnumStateCreateInfoNV;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetFragmentShadingRateEnumNV)(VkCommandBuffer commandBuffer, VkFragmentShadingRateNV shadingRate, const VkFragmentShadingRateCombinerOpKHR combinerOps[2]);


 void __attribute__((__stdcall__)) vkCmdSetFragmentShadingRateEnumNV(
    VkCommandBuffer commandBuffer,
    VkFragmentShadingRateNV shadingRate,
    const VkFragmentShadingRateCombinerOpKHR combinerOps[2]);
# 17351 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkAccelerationStructureMotionInstanceTypeNV {
    VK_ACCELERATION_STRUCTURE_MOTION_INSTANCE_TYPE_STATIC_NV = 0,
    VK_ACCELERATION_STRUCTURE_MOTION_INSTANCE_TYPE_MATRIX_MOTION_NV = 1,
    VK_ACCELERATION_STRUCTURE_MOTION_INSTANCE_TYPE_SRT_MOTION_NV = 2,
    VK_ACCELERATION_STRUCTURE_MOTION_INSTANCE_TYPE_MAX_ENUM_NV = 0x7FFFFFFF
} VkAccelerationStructureMotionInstanceTypeNV;
typedef VkFlags VkAccelerationStructureMotionInfoFlagsNV;
typedef VkFlags VkAccelerationStructureMotionInstanceFlagsNV;
typedef union VkDeviceOrHostAddressConstKHR {
    VkDeviceAddress deviceAddress;
    const void* hostAddress;
} VkDeviceOrHostAddressConstKHR;

typedef struct VkAccelerationStructureGeometryMotionTrianglesDataNV {
    VkStructureType sType;
    const void* pNext;
    VkDeviceOrHostAddressConstKHR vertexData;
} VkAccelerationStructureGeometryMotionTrianglesDataNV;

typedef struct VkAccelerationStructureMotionInfoNV {
    VkStructureType sType;
    const void* pNext;
    uint32_t maxInstances;
    VkAccelerationStructureMotionInfoFlagsNV flags;
} VkAccelerationStructureMotionInfoNV;

typedef struct VkAccelerationStructureMatrixMotionInstanceNV {
    VkTransformMatrixKHR transformT0;
    VkTransformMatrixKHR transformT1;
    uint32_t instanceCustomIndex:24;
    uint32_t mask:8;
    uint32_t instanceShaderBindingTableRecordOffset:24;
    VkGeometryInstanceFlagsKHR flags:8;
    uint64_t accelerationStructureReference;
} VkAccelerationStructureMatrixMotionInstanceNV;

typedef struct VkSRTDataNV {
    float sx;
    float a;
    float b;
    float pvx;
    float sy;
    float c;
    float pvy;
    float sz;
    float pvz;
    float qx;
    float qy;
    float qz;
    float qw;
    float tx;
    float ty;
    float tz;
} VkSRTDataNV;

typedef struct VkAccelerationStructureSRTMotionInstanceNV {
    VkSRTDataNV transformT0;
    VkSRTDataNV transformT1;
    uint32_t instanceCustomIndex:24;
    uint32_t mask:8;
    uint32_t instanceShaderBindingTableRecordOffset:24;
    VkGeometryInstanceFlagsKHR flags:8;
    uint64_t accelerationStructureReference;
} VkAccelerationStructureSRTMotionInstanceNV;

typedef union VkAccelerationStructureMotionInstanceDataNV {
    VkAccelerationStructureInstanceKHR staticInstance;
    VkAccelerationStructureMatrixMotionInstanceNV matrixMotionInstance;
    VkAccelerationStructureSRTMotionInstanceNV srtMotionInstance;
} VkAccelerationStructureMotionInstanceDataNV;

typedef struct VkAccelerationStructureMotionInstanceNV {
    VkAccelerationStructureMotionInstanceTypeNV type;
    VkAccelerationStructureMotionInstanceFlagsNV flags;
    VkAccelerationStructureMotionInstanceDataNV data;
} VkAccelerationStructureMotionInstanceNV;

typedef struct VkPhysicalDeviceRayTracingMotionBlurFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 rayTracingMotionBlur;
    VkBool32 rayTracingMotionBlurPipelineTraceRaysIndirect;
} VkPhysicalDeviceRayTracingMotionBlurFeaturesNV;







typedef struct VkPhysicalDeviceYcbcr2Plane444FormatsFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 ycbcr2plane444Formats;
} VkPhysicalDeviceYcbcr2Plane444FormatsFeaturesEXT;







typedef struct VkPhysicalDeviceFragmentDensityMap2FeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 fragmentDensityMapDeferred;
} VkPhysicalDeviceFragmentDensityMap2FeaturesEXT;

typedef struct VkPhysicalDeviceFragmentDensityMap2PropertiesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 subsampledLoads;
    VkBool32 subsampledCoarseReconstructionEarlyAccess;
    uint32_t maxSubsampledArrayLayers;
    uint32_t maxDescriptorSetSubsampledSamplers;
} VkPhysicalDeviceFragmentDensityMap2PropertiesEXT;







typedef struct VkCopyCommandTransformInfoQCOM {
    VkStructureType sType;
    const void* pNext;
    VkSurfaceTransformFlagBitsKHR transform;
} VkCopyCommandTransformInfoQCOM;







typedef VkPhysicalDeviceImageRobustnessFeatures VkPhysicalDeviceImageRobustnessFeaturesEXT;
# 17495 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkImageCompressionFlagBitsEXT {
    VK_IMAGE_COMPRESSION_DEFAULT_EXT = 0,
    VK_IMAGE_COMPRESSION_FIXED_RATE_DEFAULT_EXT = 0x00000001,
    VK_IMAGE_COMPRESSION_FIXED_RATE_EXPLICIT_EXT = 0x00000002,
    VK_IMAGE_COMPRESSION_DISABLED_EXT = 0x00000004,
    VK_IMAGE_COMPRESSION_FLAG_BITS_MAX_ENUM_EXT = 0x7FFFFFFF
} VkImageCompressionFlagBitsEXT;
typedef VkFlags VkImageCompressionFlagsEXT;

typedef enum VkImageCompressionFixedRateFlagBitsEXT {
    VK_IMAGE_COMPRESSION_FIXED_RATE_NONE_EXT = 0,
    VK_IMAGE_COMPRESSION_FIXED_RATE_1BPC_BIT_EXT = 0x00000001,
    VK_IMAGE_COMPRESSION_FIXED_RATE_2BPC_BIT_EXT = 0x00000002,
    VK_IMAGE_COMPRESSION_FIXED_RATE_3BPC_BIT_EXT = 0x00000004,
    VK_IMAGE_COMPRESSION_FIXED_RATE_4BPC_BIT_EXT = 0x00000008,
    VK_IMAGE_COMPRESSION_FIXED_RATE_5BPC_BIT_EXT = 0x00000010,
    VK_IMAGE_COMPRESSION_FIXED_RATE_6BPC_BIT_EXT = 0x00000020,
    VK_IMAGE_COMPRESSION_FIXED_RATE_7BPC_BIT_EXT = 0x00000040,
    VK_IMAGE_COMPRESSION_FIXED_RATE_8BPC_BIT_EXT = 0x00000080,
    VK_IMAGE_COMPRESSION_FIXED_RATE_9BPC_BIT_EXT = 0x00000100,
    VK_IMAGE_COMPRESSION_FIXED_RATE_10BPC_BIT_EXT = 0x00000200,
    VK_IMAGE_COMPRESSION_FIXED_RATE_11BPC_BIT_EXT = 0x00000400,
    VK_IMAGE_COMPRESSION_FIXED_RATE_12BPC_BIT_EXT = 0x00000800,
    VK_IMAGE_COMPRESSION_FIXED_RATE_13BPC_BIT_EXT = 0x00001000,
    VK_IMAGE_COMPRESSION_FIXED_RATE_14BPC_BIT_EXT = 0x00002000,
    VK_IMAGE_COMPRESSION_FIXED_RATE_15BPC_BIT_EXT = 0x00004000,
    VK_IMAGE_COMPRESSION_FIXED_RATE_16BPC_BIT_EXT = 0x00008000,
    VK_IMAGE_COMPRESSION_FIXED_RATE_17BPC_BIT_EXT = 0x00010000,
    VK_IMAGE_COMPRESSION_FIXED_RATE_18BPC_BIT_EXT = 0x00020000,
    VK_IMAGE_COMPRESSION_FIXED_RATE_19BPC_BIT_EXT = 0x00040000,
    VK_IMAGE_COMPRESSION_FIXED_RATE_20BPC_BIT_EXT = 0x00080000,
    VK_IMAGE_COMPRESSION_FIXED_RATE_21BPC_BIT_EXT = 0x00100000,
    VK_IMAGE_COMPRESSION_FIXED_RATE_22BPC_BIT_EXT = 0x00200000,
    VK_IMAGE_COMPRESSION_FIXED_RATE_23BPC_BIT_EXT = 0x00400000,
    VK_IMAGE_COMPRESSION_FIXED_RATE_24BPC_BIT_EXT = 0x00800000,
    VK_IMAGE_COMPRESSION_FIXED_RATE_FLAG_BITS_MAX_ENUM_EXT = 0x7FFFFFFF
} VkImageCompressionFixedRateFlagBitsEXT;
typedef VkFlags VkImageCompressionFixedRateFlagsEXT;
typedef struct VkPhysicalDeviceImageCompressionControlFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 imageCompressionControl;
} VkPhysicalDeviceImageCompressionControlFeaturesEXT;

typedef struct VkImageCompressionControlEXT {
    VkStructureType sType;
    const void* pNext;
    VkImageCompressionFlagsEXT flags;
    uint32_t compressionControlPlaneCount;
    VkImageCompressionFixedRateFlagsEXT* pFixedRateFlags;
} VkImageCompressionControlEXT;

typedef struct VkImageCompressionPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    VkImageCompressionFlagsEXT imageCompressionFlags;
    VkImageCompressionFixedRateFlagsEXT imageCompressionFixedRateFlags;
} VkImageCompressionPropertiesEXT;







typedef struct VkPhysicalDeviceAttachmentFeedbackLoopLayoutFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 attachmentFeedbackLoopLayout;
} VkPhysicalDeviceAttachmentFeedbackLoopLayoutFeaturesEXT;







typedef struct VkPhysicalDevice4444FormatsFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 formatA4R4G4B4;
    VkBool32 formatA4B4G4R4;
} VkPhysicalDevice4444FormatsFeaturesEXT;
# 17586 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkDeviceFaultAddressTypeEXT {
    VK_DEVICE_FAULT_ADDRESS_TYPE_NONE_EXT = 0,
    VK_DEVICE_FAULT_ADDRESS_TYPE_READ_INVALID_EXT = 1,
    VK_DEVICE_FAULT_ADDRESS_TYPE_WRITE_INVALID_EXT = 2,
    VK_DEVICE_FAULT_ADDRESS_TYPE_EXECUTE_INVALID_EXT = 3,
    VK_DEVICE_FAULT_ADDRESS_TYPE_INSTRUCTION_POINTER_UNKNOWN_EXT = 4,
    VK_DEVICE_FAULT_ADDRESS_TYPE_INSTRUCTION_POINTER_INVALID_EXT = 5,
    VK_DEVICE_FAULT_ADDRESS_TYPE_INSTRUCTION_POINTER_FAULT_EXT = 6,
    VK_DEVICE_FAULT_ADDRESS_TYPE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkDeviceFaultAddressTypeEXT;

typedef enum VkDeviceFaultVendorBinaryHeaderVersionEXT {
    VK_DEVICE_FAULT_VENDOR_BINARY_HEADER_VERSION_ONE_EXT = 1,
    VK_DEVICE_FAULT_VENDOR_BINARY_HEADER_VERSION_MAX_ENUM_EXT = 0x7FFFFFFF
} VkDeviceFaultVendorBinaryHeaderVersionEXT;
typedef struct VkPhysicalDeviceFaultFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 deviceFault;
    VkBool32 deviceFaultVendorBinary;
} VkPhysicalDeviceFaultFeaturesEXT;

typedef struct VkDeviceFaultCountsEXT {
    VkStructureType sType;
    void* pNext;
    uint32_t addressInfoCount;
    uint32_t vendorInfoCount;
    VkDeviceSize vendorBinarySize;
} VkDeviceFaultCountsEXT;

typedef struct VkDeviceFaultAddressInfoEXT {
    VkDeviceFaultAddressTypeEXT addressType;
    VkDeviceAddress reportedAddress;
    VkDeviceSize addressPrecision;
} VkDeviceFaultAddressInfoEXT;

typedef struct VkDeviceFaultVendorInfoEXT {
    char description[256U];
    uint64_t vendorFaultCode;
    uint64_t vendorFaultData;
} VkDeviceFaultVendorInfoEXT;

typedef struct VkDeviceFaultInfoEXT {
    VkStructureType sType;
    void* pNext;
    char description[256U];
    VkDeviceFaultAddressInfoEXT* pAddressInfos;
    VkDeviceFaultVendorInfoEXT* pVendorInfos;
    void* pVendorBinaryData;
} VkDeviceFaultInfoEXT;

typedef struct VkDeviceFaultVendorBinaryHeaderVersionOneEXT {
    uint32_t headerSize;
    VkDeviceFaultVendorBinaryHeaderVersionEXT headerVersion;
    uint32_t vendorID;
    uint32_t deviceID;
    uint32_t driverVersion;
    uint8_t pipelineCacheUUID[16U];
    uint32_t applicationNameOffset;
    uint32_t applicationVersion;
    uint32_t engineNameOffset;
    uint32_t engineVersion;
    uint32_t apiVersion;
} VkDeviceFaultVendorBinaryHeaderVersionOneEXT;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetDeviceFaultInfoEXT)(VkDevice device, VkDeviceFaultCountsEXT* pFaultCounts, VkDeviceFaultInfoEXT* pFaultInfo);


 VkResult __attribute__((__stdcall__)) vkGetDeviceFaultInfoEXT(
    VkDevice device,
    VkDeviceFaultCountsEXT* pFaultCounts,
    VkDeviceFaultInfoEXT* pFaultInfo);







typedef struct VkPhysicalDeviceRasterizationOrderAttachmentAccessFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 rasterizationOrderColorAttachmentAccess;
    VkBool32 rasterizationOrderDepthAttachmentAccess;
    VkBool32 rasterizationOrderStencilAttachmentAccess;
} VkPhysicalDeviceRasterizationOrderAttachmentAccessFeaturesEXT;

typedef VkPhysicalDeviceRasterizationOrderAttachmentAccessFeaturesEXT VkPhysicalDeviceRasterizationOrderAttachmentAccessFeaturesARM;







typedef struct VkPhysicalDeviceRGBA10X6FormatsFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 formatRgba10x6WithoutYCbCrSampler;
} VkPhysicalDeviceRGBA10X6FormatsFeaturesEXT;







typedef struct VkPhysicalDeviceMutableDescriptorTypeFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 mutableDescriptorType;
} VkPhysicalDeviceMutableDescriptorTypeFeaturesEXT;

typedef VkPhysicalDeviceMutableDescriptorTypeFeaturesEXT VkPhysicalDeviceMutableDescriptorTypeFeaturesVALVE;

typedef struct VkMutableDescriptorTypeListEXT {
    uint32_t descriptorTypeCount;
    const VkDescriptorType* pDescriptorTypes;
} VkMutableDescriptorTypeListEXT;

typedef VkMutableDescriptorTypeListEXT VkMutableDescriptorTypeListVALVE;

typedef struct VkMutableDescriptorTypeCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    uint32_t mutableDescriptorTypeListCount;
    const VkMutableDescriptorTypeListEXT* pMutableDescriptorTypeLists;
} VkMutableDescriptorTypeCreateInfoEXT;

typedef VkMutableDescriptorTypeCreateInfoEXT VkMutableDescriptorTypeCreateInfoVALVE;







typedef struct VkPhysicalDeviceVertexInputDynamicStateFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 vertexInputDynamicState;
} VkPhysicalDeviceVertexInputDynamicStateFeaturesEXT;

typedef struct VkVertexInputBindingDescription2EXT {
    VkStructureType sType;
    void* pNext;
    uint32_t binding;
    uint32_t stride;
    VkVertexInputRate inputRate;
    uint32_t divisor;
} VkVertexInputBindingDescription2EXT;

typedef struct VkVertexInputAttributeDescription2EXT {
    VkStructureType sType;
    void* pNext;
    uint32_t location;
    uint32_t binding;
    VkFormat format;
    uint32_t offset;
} VkVertexInputAttributeDescription2EXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetVertexInputEXT)(VkCommandBuffer commandBuffer, uint32_t vertexBindingDescriptionCount, const VkVertexInputBindingDescription2EXT* pVertexBindingDescriptions, uint32_t vertexAttributeDescriptionCount, const VkVertexInputAttributeDescription2EXT* pVertexAttributeDescriptions);


 void __attribute__((__stdcall__)) vkCmdSetVertexInputEXT(
    VkCommandBuffer commandBuffer,
    uint32_t vertexBindingDescriptionCount,
    const VkVertexInputBindingDescription2EXT* pVertexBindingDescriptions,
    uint32_t vertexAttributeDescriptionCount,
    const VkVertexInputAttributeDescription2EXT* pVertexAttributeDescriptions);







typedef struct VkPhysicalDeviceDrmPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 hasPrimary;
    VkBool32 hasRender;
    int64_t primaryMajor;
    int64_t primaryMinor;
    int64_t renderMajor;
    int64_t renderMinor;
} VkPhysicalDeviceDrmPropertiesEXT;
# 17781 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkDeviceAddressBindingTypeEXT {
    VK_DEVICE_ADDRESS_BINDING_TYPE_BIND_EXT = 0,
    VK_DEVICE_ADDRESS_BINDING_TYPE_UNBIND_EXT = 1,
    VK_DEVICE_ADDRESS_BINDING_TYPE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkDeviceAddressBindingTypeEXT;

typedef enum VkDeviceAddressBindingFlagBitsEXT {
    VK_DEVICE_ADDRESS_BINDING_INTERNAL_OBJECT_BIT_EXT = 0x00000001,
    VK_DEVICE_ADDRESS_BINDING_FLAG_BITS_MAX_ENUM_EXT = 0x7FFFFFFF
} VkDeviceAddressBindingFlagBitsEXT;
typedef VkFlags VkDeviceAddressBindingFlagsEXT;
typedef struct VkPhysicalDeviceAddressBindingReportFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 reportAddressBinding;
} VkPhysicalDeviceAddressBindingReportFeaturesEXT;

typedef struct VkDeviceAddressBindingCallbackDataEXT {
    VkStructureType sType;
    void* pNext;
    VkDeviceAddressBindingFlagsEXT flags;
    VkDeviceAddress baseAddress;
    VkDeviceSize size;
    VkDeviceAddressBindingTypeEXT bindingType;
} VkDeviceAddressBindingCallbackDataEXT;







typedef struct VkPhysicalDeviceDepthClipControlFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 depthClipControl;
} VkPhysicalDeviceDepthClipControlFeaturesEXT;

typedef struct VkPipelineViewportDepthClipControlCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkBool32 negativeOneToOne;
} VkPipelineViewportDepthClipControlCreateInfoEXT;







typedef struct VkPhysicalDevicePrimitiveTopologyListRestartFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 primitiveTopologyListRestart;
    VkBool32 primitiveTopologyPatchListRestart;
} VkPhysicalDevicePrimitiveTopologyListRestartFeaturesEXT;







typedef struct VkPhysicalDevicePresentModeFifoLatestReadyFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 presentModeFifoLatestReady;
} VkPhysicalDevicePresentModeFifoLatestReadyFeaturesEXT;







typedef struct VkSubpassShadingPipelineCreateInfoHUAWEI {
    VkStructureType sType;
    void* pNext;
    VkRenderPass renderPass;
    uint32_t subpass;
} VkSubpassShadingPipelineCreateInfoHUAWEI;

typedef struct VkPhysicalDeviceSubpassShadingFeaturesHUAWEI {
    VkStructureType sType;
    void* pNext;
    VkBool32 subpassShading;
} VkPhysicalDeviceSubpassShadingFeaturesHUAWEI;

typedef struct VkPhysicalDeviceSubpassShadingPropertiesHUAWEI {
    VkStructureType sType;
    void* pNext;
    uint32_t maxSubpassShadingWorkgroupSizeAspectRatio;
} VkPhysicalDeviceSubpassShadingPropertiesHUAWEI;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetDeviceSubpassShadingMaxWorkgroupSizeHUAWEI)(VkDevice device, VkRenderPass renderpass, VkExtent2D* pMaxWorkgroupSize);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSubpassShadingHUAWEI)(VkCommandBuffer commandBuffer);


 VkResult __attribute__((__stdcall__)) vkGetDeviceSubpassShadingMaxWorkgroupSizeHUAWEI(
    VkDevice device,
    VkRenderPass renderpass,
    VkExtent2D* pMaxWorkgroupSize);

 void __attribute__((__stdcall__)) vkCmdSubpassShadingHUAWEI(
    VkCommandBuffer commandBuffer);







typedef struct VkPhysicalDeviceInvocationMaskFeaturesHUAWEI {
    VkStructureType sType;
    void* pNext;
    VkBool32 invocationMask;
} VkPhysicalDeviceInvocationMaskFeaturesHUAWEI;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBindInvocationMaskHUAWEI)(VkCommandBuffer commandBuffer, VkImageView imageView, VkImageLayout imageLayout);


 void __attribute__((__stdcall__)) vkCmdBindInvocationMaskHUAWEI(
    VkCommandBuffer commandBuffer,
    VkImageView imageView,
    VkImageLayout imageLayout);





typedef void* VkRemoteAddressNV;


typedef struct VkMemoryGetRemoteAddressInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkDeviceMemory memory;
    VkExternalMemoryHandleTypeFlagBits handleType;
} VkMemoryGetRemoteAddressInfoNV;

typedef struct VkPhysicalDeviceExternalMemoryRDMAFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 externalMemoryRDMA;
} VkPhysicalDeviceExternalMemoryRDMAFeaturesNV;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetMemoryRemoteAddressNV)(VkDevice device, const VkMemoryGetRemoteAddressInfoNV* pMemoryGetRemoteAddressInfo, VkRemoteAddressNV* pAddress);


 VkResult __attribute__((__stdcall__)) vkGetMemoryRemoteAddressNV(
    VkDevice device,
    const VkMemoryGetRemoteAddressInfoNV* pMemoryGetRemoteAddressInfo,
    VkRemoteAddressNV* pAddress);







typedef VkPipelineInfoKHR VkPipelineInfoEXT;

typedef struct VkPipelinePropertiesIdentifierEXT {
    VkStructureType sType;
    void* pNext;
    uint8_t pipelineIdentifier[16U];
} VkPipelinePropertiesIdentifierEXT;

typedef struct VkPhysicalDevicePipelinePropertiesFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 pipelinePropertiesIdentifier;
} VkPhysicalDevicePipelinePropertiesFeaturesEXT;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPipelinePropertiesEXT)(VkDevice device, const VkPipelineInfoEXT* pPipelineInfo, VkBaseOutStructure* pPipelineProperties);


 VkResult __attribute__((__stdcall__)) vkGetPipelinePropertiesEXT(
    VkDevice device,
    const VkPipelineInfoEXT* pPipelineInfo,
    VkBaseOutStructure* pPipelineProperties);
# 17970 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkFrameBoundaryFlagBitsEXT {
    VK_FRAME_BOUNDARY_FRAME_END_BIT_EXT = 0x00000001,
    VK_FRAME_BOUNDARY_FLAG_BITS_MAX_ENUM_EXT = 0x7FFFFFFF
} VkFrameBoundaryFlagBitsEXT;
typedef VkFlags VkFrameBoundaryFlagsEXT;
typedef struct VkPhysicalDeviceFrameBoundaryFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 frameBoundary;
} VkPhysicalDeviceFrameBoundaryFeaturesEXT;

typedef struct VkFrameBoundaryEXT {
    VkStructureType sType;
    const void* pNext;
    VkFrameBoundaryFlagsEXT flags;
    uint64_t frameID;
    uint32_t imageCount;
    const VkImage* pImages;
    uint32_t bufferCount;
    const VkBuffer* pBuffers;
    uint64_t tagName;
    size_t tagSize;
    const void* pTag;
} VkFrameBoundaryEXT;







typedef struct VkPhysicalDeviceMultisampledRenderToSingleSampledFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 multisampledRenderToSingleSampled;
} VkPhysicalDeviceMultisampledRenderToSingleSampledFeaturesEXT;

typedef struct VkSubpassResolvePerformanceQueryEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 optimal;
} VkSubpassResolvePerformanceQueryEXT;

typedef struct VkMultisampledRenderToSingleSampledInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkBool32 multisampledRenderToSingleSampledEnable;
    VkSampleCountFlagBits rasterizationSamples;
} VkMultisampledRenderToSingleSampledInfoEXT;







typedef struct VkPhysicalDeviceExtendedDynamicState2FeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 extendedDynamicState2;
    VkBool32 extendedDynamicState2LogicOp;
    VkBool32 extendedDynamicState2PatchControlPoints;
} VkPhysicalDeviceExtendedDynamicState2FeaturesEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetPatchControlPointsEXT)(VkCommandBuffer commandBuffer, uint32_t patchControlPoints);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetRasterizerDiscardEnableEXT)(VkCommandBuffer commandBuffer, VkBool32 rasterizerDiscardEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDepthBiasEnableEXT)(VkCommandBuffer commandBuffer, VkBool32 depthBiasEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetLogicOpEXT)(VkCommandBuffer commandBuffer, VkLogicOp logicOp);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetPrimitiveRestartEnableEXT)(VkCommandBuffer commandBuffer, VkBool32 primitiveRestartEnable);


 void __attribute__((__stdcall__)) vkCmdSetPatchControlPointsEXT(
    VkCommandBuffer commandBuffer,
    uint32_t patchControlPoints);

 void __attribute__((__stdcall__)) vkCmdSetRasterizerDiscardEnableEXT(
    VkCommandBuffer commandBuffer,
    VkBool32 rasterizerDiscardEnable);

 void __attribute__((__stdcall__)) vkCmdSetDepthBiasEnableEXT(
    VkCommandBuffer commandBuffer,
    VkBool32 depthBiasEnable);

 void __attribute__((__stdcall__)) vkCmdSetLogicOpEXT(
    VkCommandBuffer commandBuffer,
    VkLogicOp logicOp);

 void __attribute__((__stdcall__)) vkCmdSetPrimitiveRestartEnableEXT(
    VkCommandBuffer commandBuffer,
    VkBool32 primitiveRestartEnable);







typedef struct VkPhysicalDeviceColorWriteEnableFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 colorWriteEnable;
} VkPhysicalDeviceColorWriteEnableFeaturesEXT;

typedef struct VkPipelineColorWriteCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    uint32_t attachmentCount;
    const VkBool32* pColorWriteEnables;
} VkPipelineColorWriteCreateInfoEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetColorWriteEnableEXT)(VkCommandBuffer commandBuffer, uint32_t attachmentCount, const VkBool32* pColorWriteEnables);


 void __attribute__((__stdcall__)) vkCmdSetColorWriteEnableEXT(
    VkCommandBuffer commandBuffer,
    uint32_t attachmentCount,
    const VkBool32* pColorWriteEnables);







typedef struct VkPhysicalDevicePrimitivesGeneratedQueryFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 primitivesGeneratedQuery;
    VkBool32 primitivesGeneratedQueryWithRasterizerDiscard;
    VkBool32 primitivesGeneratedQueryWithNonZeroStreams;
} VkPhysicalDevicePrimitivesGeneratedQueryFeaturesEXT;
# 18109 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkPhysicalDeviceGlobalPriorityQueryFeatures VkPhysicalDeviceGlobalPriorityQueryFeaturesEXT;

typedef VkQueueFamilyGlobalPriorityProperties VkQueueFamilyGlobalPriorityPropertiesEXT;







typedef struct VkPhysicalDeviceImageViewMinLodFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 minLod;
} VkPhysicalDeviceImageViewMinLodFeaturesEXT;

typedef struct VkImageViewMinLodCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    float minLod;
} VkImageViewMinLodCreateInfoEXT;







typedef struct VkPhysicalDeviceMultiDrawFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 multiDraw;
} VkPhysicalDeviceMultiDrawFeaturesEXT;

typedef struct VkPhysicalDeviceMultiDrawPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    uint32_t maxMultiDrawCount;
} VkPhysicalDeviceMultiDrawPropertiesEXT;

typedef struct VkMultiDrawInfoEXT {
    uint32_t firstVertex;
    uint32_t vertexCount;
} VkMultiDrawInfoEXT;

typedef struct VkMultiDrawIndexedInfoEXT {
    uint32_t firstIndex;
    uint32_t indexCount;
    int32_t vertexOffset;
} VkMultiDrawIndexedInfoEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawMultiEXT)(VkCommandBuffer commandBuffer, uint32_t drawCount, const VkMultiDrawInfoEXT* pVertexInfo, uint32_t instanceCount, uint32_t firstInstance, uint32_t stride);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawMultiIndexedEXT)(VkCommandBuffer commandBuffer, uint32_t drawCount, const VkMultiDrawIndexedInfoEXT* pIndexInfo, uint32_t instanceCount, uint32_t firstInstance, uint32_t stride, const int32_t* pVertexOffset);


 void __attribute__((__stdcall__)) vkCmdDrawMultiEXT(
    VkCommandBuffer commandBuffer,
    uint32_t drawCount,
    const VkMultiDrawInfoEXT* pVertexInfo,
    uint32_t instanceCount,
    uint32_t firstInstance,
    uint32_t stride);

 void __attribute__((__stdcall__)) vkCmdDrawMultiIndexedEXT(
    VkCommandBuffer commandBuffer,
    uint32_t drawCount,
    const VkMultiDrawIndexedInfoEXT* pIndexInfo,
    uint32_t instanceCount,
    uint32_t firstInstance,
    uint32_t stride,
    const int32_t* pVertexOffset);







typedef struct VkPhysicalDeviceImage2DViewOf3DFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 image2DViewOf3D;
    VkBool32 sampler2DViewOf3D;
} VkPhysicalDeviceImage2DViewOf3DFeaturesEXT;







typedef struct VkPhysicalDeviceShaderTileImageFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderTileImageColorReadAccess;
    VkBool32 shaderTileImageDepthReadAccess;
    VkBool32 shaderTileImageStencilReadAccess;
} VkPhysicalDeviceShaderTileImageFeaturesEXT;

typedef struct VkPhysicalDeviceShaderTileImagePropertiesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderTileImageCoherentReadAccelerated;
    VkBool32 shaderTileImageReadSampleFromPixelRateInvocation;
    VkBool32 shaderTileImageReadFromHelperInvocation;
} VkPhysicalDeviceShaderTileImagePropertiesEXT;





typedef struct VkMicromapEXT_T *VkMicromapEXT;



typedef enum VkMicromapTypeEXT {
    VK_MICROMAP_TYPE_OPACITY_MICROMAP_EXT = 0,



    VK_MICROMAP_TYPE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkMicromapTypeEXT;

typedef enum VkBuildMicromapModeEXT {
    VK_BUILD_MICROMAP_MODE_BUILD_EXT = 0,
    VK_BUILD_MICROMAP_MODE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkBuildMicromapModeEXT;

typedef enum VkCopyMicromapModeEXT {
    VK_COPY_MICROMAP_MODE_CLONE_EXT = 0,
    VK_COPY_MICROMAP_MODE_SERIALIZE_EXT = 1,
    VK_COPY_MICROMAP_MODE_DESERIALIZE_EXT = 2,
    VK_COPY_MICROMAP_MODE_COMPACT_EXT = 3,
    VK_COPY_MICROMAP_MODE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkCopyMicromapModeEXT;

typedef enum VkOpacityMicromapFormatEXT {
    VK_OPACITY_MICROMAP_FORMAT_2_STATE_EXT = 1,
    VK_OPACITY_MICROMAP_FORMAT_4_STATE_EXT = 2,
    VK_OPACITY_MICROMAP_FORMAT_MAX_ENUM_EXT = 0x7FFFFFFF
} VkOpacityMicromapFormatEXT;

typedef enum VkOpacityMicromapSpecialIndexEXT {
    VK_OPACITY_MICROMAP_SPECIAL_INDEX_FULLY_TRANSPARENT_EXT = -1,
    VK_OPACITY_MICROMAP_SPECIAL_INDEX_FULLY_OPAQUE_EXT = -2,
    VK_OPACITY_MICROMAP_SPECIAL_INDEX_FULLY_UNKNOWN_TRANSPARENT_EXT = -3,
    VK_OPACITY_MICROMAP_SPECIAL_INDEX_FULLY_UNKNOWN_OPAQUE_EXT = -4,
    VK_OPACITY_MICROMAP_SPECIAL_INDEX_MAX_ENUM_EXT = 0x7FFFFFFF
} VkOpacityMicromapSpecialIndexEXT;

typedef enum VkAccelerationStructureCompatibilityKHR {
    VK_ACCELERATION_STRUCTURE_COMPATIBILITY_COMPATIBLE_KHR = 0,
    VK_ACCELERATION_STRUCTURE_COMPATIBILITY_INCOMPATIBLE_KHR = 1,
    VK_ACCELERATION_STRUCTURE_COMPATIBILITY_MAX_ENUM_KHR = 0x7FFFFFFF
} VkAccelerationStructureCompatibilityKHR;

typedef enum VkAccelerationStructureBuildTypeKHR {
    VK_ACCELERATION_STRUCTURE_BUILD_TYPE_HOST_KHR = 0,
    VK_ACCELERATION_STRUCTURE_BUILD_TYPE_DEVICE_KHR = 1,
    VK_ACCELERATION_STRUCTURE_BUILD_TYPE_HOST_OR_DEVICE_KHR = 2,
    VK_ACCELERATION_STRUCTURE_BUILD_TYPE_MAX_ENUM_KHR = 0x7FFFFFFF
} VkAccelerationStructureBuildTypeKHR;

typedef enum VkBuildMicromapFlagBitsEXT {
    VK_BUILD_MICROMAP_PREFER_FAST_TRACE_BIT_EXT = 0x00000001,
    VK_BUILD_MICROMAP_PREFER_FAST_BUILD_BIT_EXT = 0x00000002,
    VK_BUILD_MICROMAP_ALLOW_COMPACTION_BIT_EXT = 0x00000004,
    VK_BUILD_MICROMAP_FLAG_BITS_MAX_ENUM_EXT = 0x7FFFFFFF
} VkBuildMicromapFlagBitsEXT;
typedef VkFlags VkBuildMicromapFlagsEXT;

typedef enum VkMicromapCreateFlagBitsEXT {
    VK_MICROMAP_CREATE_DEVICE_ADDRESS_CAPTURE_REPLAY_BIT_EXT = 0x00000001,
    VK_MICROMAP_CREATE_FLAG_BITS_MAX_ENUM_EXT = 0x7FFFFFFF
} VkMicromapCreateFlagBitsEXT;
typedef VkFlags VkMicromapCreateFlagsEXT;
typedef struct VkMicromapUsageEXT {
    uint32_t count;
    uint32_t subdivisionLevel;
    uint32_t format;
} VkMicromapUsageEXT;

typedef union VkDeviceOrHostAddressKHR {
    VkDeviceAddress deviceAddress;
    void* hostAddress;
} VkDeviceOrHostAddressKHR;

typedef struct VkMicromapBuildInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkMicromapTypeEXT type;
    VkBuildMicromapFlagsEXT flags;
    VkBuildMicromapModeEXT mode;
    VkMicromapEXT dstMicromap;
    uint32_t usageCountsCount;
    const VkMicromapUsageEXT* pUsageCounts;
    const VkMicromapUsageEXT* const* ppUsageCounts;
    VkDeviceOrHostAddressConstKHR data;
    VkDeviceOrHostAddressKHR scratchData;
    VkDeviceOrHostAddressConstKHR triangleArray;
    VkDeviceSize triangleArrayStride;
} VkMicromapBuildInfoEXT;

typedef struct VkMicromapCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkMicromapCreateFlagsEXT createFlags;
    VkBuffer buffer;
    VkDeviceSize offset;
    VkDeviceSize size;
    VkMicromapTypeEXT type;
    VkDeviceAddress deviceAddress;
} VkMicromapCreateInfoEXT;

typedef struct VkPhysicalDeviceOpacityMicromapFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 micromap;
    VkBool32 micromapCaptureReplay;
    VkBool32 micromapHostCommands;
} VkPhysicalDeviceOpacityMicromapFeaturesEXT;

typedef struct VkPhysicalDeviceOpacityMicromapPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    uint32_t maxOpacity2StateSubdivisionLevel;
    uint32_t maxOpacity4StateSubdivisionLevel;
} VkPhysicalDeviceOpacityMicromapPropertiesEXT;

typedef struct VkMicromapVersionInfoEXT {
    VkStructureType sType;
    const void* pNext;
    const uint8_t* pVersionData;
} VkMicromapVersionInfoEXT;

typedef struct VkCopyMicromapToMemoryInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkMicromapEXT src;
    VkDeviceOrHostAddressKHR dst;
    VkCopyMicromapModeEXT mode;
} VkCopyMicromapToMemoryInfoEXT;

typedef struct VkCopyMemoryToMicromapInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkDeviceOrHostAddressConstKHR src;
    VkMicromapEXT dst;
    VkCopyMicromapModeEXT mode;
} VkCopyMemoryToMicromapInfoEXT;

typedef struct VkCopyMicromapInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkMicromapEXT src;
    VkMicromapEXT dst;
    VkCopyMicromapModeEXT mode;
} VkCopyMicromapInfoEXT;

typedef struct VkMicromapBuildSizesInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkDeviceSize micromapSize;
    VkDeviceSize buildScratchSize;
    VkBool32 discardable;
} VkMicromapBuildSizesInfoEXT;

typedef struct VkAccelerationStructureTrianglesOpacityMicromapEXT {
    VkStructureType sType;
    void* pNext;
    VkIndexType indexType;
    VkDeviceOrHostAddressConstKHR indexBuffer;
    VkDeviceSize indexStride;
    uint32_t baseTriangle;
    uint32_t usageCountsCount;
    const VkMicromapUsageEXT* pUsageCounts;
    const VkMicromapUsageEXT* const* ppUsageCounts;
    VkMicromapEXT micromap;
} VkAccelerationStructureTrianglesOpacityMicromapEXT;

typedef struct VkMicromapTriangleEXT {
    uint32_t dataOffset;
    uint16_t subdivisionLevel;
    uint16_t format;
} VkMicromapTriangleEXT;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateMicromapEXT)(VkDevice device, const VkMicromapCreateInfoEXT* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkMicromapEXT* pMicromap);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyMicromapEXT)(VkDevice device, VkMicromapEXT micromap, const VkAllocationCallbacks* pAllocator);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBuildMicromapsEXT)(VkCommandBuffer commandBuffer, uint32_t infoCount, const VkMicromapBuildInfoEXT* pInfos);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkBuildMicromapsEXT)(VkDevice device, VkDeferredOperationKHR deferredOperation, uint32_t infoCount, const VkMicromapBuildInfoEXT* pInfos);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCopyMicromapEXT)(VkDevice device, VkDeferredOperationKHR deferredOperation, const VkCopyMicromapInfoEXT* pInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCopyMicromapToMemoryEXT)(VkDevice device, VkDeferredOperationKHR deferredOperation, const VkCopyMicromapToMemoryInfoEXT* pInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCopyMemoryToMicromapEXT)(VkDevice device, VkDeferredOperationKHR deferredOperation, const VkCopyMemoryToMicromapInfoEXT* pInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkWriteMicromapsPropertiesEXT)(VkDevice device, uint32_t micromapCount, const VkMicromapEXT* pMicromaps, VkQueryType queryType, size_t dataSize, void* pData, size_t stride);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyMicromapEXT)(VkCommandBuffer commandBuffer, const VkCopyMicromapInfoEXT* pInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyMicromapToMemoryEXT)(VkCommandBuffer commandBuffer, const VkCopyMicromapToMemoryInfoEXT* pInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyMemoryToMicromapEXT)(VkCommandBuffer commandBuffer, const VkCopyMemoryToMicromapInfoEXT* pInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdWriteMicromapsPropertiesEXT)(VkCommandBuffer commandBuffer, uint32_t micromapCount, const VkMicromapEXT* pMicromaps, VkQueryType queryType, VkQueryPool queryPool, uint32_t firstQuery);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetDeviceMicromapCompatibilityEXT)(VkDevice device, const VkMicromapVersionInfoEXT* pVersionInfo, VkAccelerationStructureCompatibilityKHR* pCompatibility);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetMicromapBuildSizesEXT)(VkDevice device, VkAccelerationStructureBuildTypeKHR buildType, const VkMicromapBuildInfoEXT* pBuildInfo, VkMicromapBuildSizesInfoEXT* pSizeInfo);


 VkResult __attribute__((__stdcall__)) vkCreateMicromapEXT(
    VkDevice device,
    const VkMicromapCreateInfoEXT* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkMicromapEXT* pMicromap);

 void __attribute__((__stdcall__)) vkDestroyMicromapEXT(
    VkDevice device,
    VkMicromapEXT micromap,
    const VkAllocationCallbacks* pAllocator);

 void __attribute__((__stdcall__)) vkCmdBuildMicromapsEXT(
    VkCommandBuffer commandBuffer,
    uint32_t infoCount,
    const VkMicromapBuildInfoEXT* pInfos);

 VkResult __attribute__((__stdcall__)) vkBuildMicromapsEXT(
    VkDevice device,
    VkDeferredOperationKHR deferredOperation,
    uint32_t infoCount,
    const VkMicromapBuildInfoEXT* pInfos);

 VkResult __attribute__((__stdcall__)) vkCopyMicromapEXT(
    VkDevice device,
    VkDeferredOperationKHR deferredOperation,
    const VkCopyMicromapInfoEXT* pInfo);

 VkResult __attribute__((__stdcall__)) vkCopyMicromapToMemoryEXT(
    VkDevice device,
    VkDeferredOperationKHR deferredOperation,
    const VkCopyMicromapToMemoryInfoEXT* pInfo);

 VkResult __attribute__((__stdcall__)) vkCopyMemoryToMicromapEXT(
    VkDevice device,
    VkDeferredOperationKHR deferredOperation,
    const VkCopyMemoryToMicromapInfoEXT* pInfo);

 VkResult __attribute__((__stdcall__)) vkWriteMicromapsPropertiesEXT(
    VkDevice device,
    uint32_t micromapCount,
    const VkMicromapEXT* pMicromaps,
    VkQueryType queryType,
    size_t dataSize,
    void* pData,
    size_t stride);

 void __attribute__((__stdcall__)) vkCmdCopyMicromapEXT(
    VkCommandBuffer commandBuffer,
    const VkCopyMicromapInfoEXT* pInfo);

 void __attribute__((__stdcall__)) vkCmdCopyMicromapToMemoryEXT(
    VkCommandBuffer commandBuffer,
    const VkCopyMicromapToMemoryInfoEXT* pInfo);

 void __attribute__((__stdcall__)) vkCmdCopyMemoryToMicromapEXT(
    VkCommandBuffer commandBuffer,
    const VkCopyMemoryToMicromapInfoEXT* pInfo);

 void __attribute__((__stdcall__)) vkCmdWriteMicromapsPropertiesEXT(
    VkCommandBuffer commandBuffer,
    uint32_t micromapCount,
    const VkMicromapEXT* pMicromaps,
    VkQueryType queryType,
    VkQueryPool queryPool,
    uint32_t firstQuery);

 void __attribute__((__stdcall__)) vkGetDeviceMicromapCompatibilityEXT(
    VkDevice device,
    const VkMicromapVersionInfoEXT* pVersionInfo,
    VkAccelerationStructureCompatibilityKHR* pCompatibility);

 void __attribute__((__stdcall__)) vkGetMicromapBuildSizesEXT(
    VkDevice device,
    VkAccelerationStructureBuildTypeKHR buildType,
    const VkMicromapBuildInfoEXT* pBuildInfo,
    VkMicromapBuildSizesInfoEXT* pSizeInfo);
# 18500 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkPhysicalDeviceClusterCullingShaderFeaturesHUAWEI {
    VkStructureType sType;
    void* pNext;
    VkBool32 clustercullingShader;
    VkBool32 multiviewClusterCullingShader;
} VkPhysicalDeviceClusterCullingShaderFeaturesHUAWEI;

typedef struct VkPhysicalDeviceClusterCullingShaderPropertiesHUAWEI {
    VkStructureType sType;
    void* pNext;
    uint32_t maxWorkGroupCount[3];
    uint32_t maxWorkGroupSize[3];
    uint32_t maxOutputClusterCount;
    VkDeviceSize indirectBufferOffsetAlignment;
} VkPhysicalDeviceClusterCullingShaderPropertiesHUAWEI;

typedef struct VkPhysicalDeviceClusterCullingShaderVrsFeaturesHUAWEI {
    VkStructureType sType;
    void* pNext;
    VkBool32 clusterShadingRate;
} VkPhysicalDeviceClusterCullingShaderVrsFeaturesHUAWEI;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawClusterHUAWEI)(VkCommandBuffer commandBuffer, uint32_t groupCountX, uint32_t groupCountY, uint32_t groupCountZ);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawClusterIndirectHUAWEI)(VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset);


 void __attribute__((__stdcall__)) vkCmdDrawClusterHUAWEI(
    VkCommandBuffer commandBuffer,
    uint32_t groupCountX,
    uint32_t groupCountY,
    uint32_t groupCountZ);

 void __attribute__((__stdcall__)) vkCmdDrawClusterIndirectHUAWEI(
    VkCommandBuffer commandBuffer,
    VkBuffer buffer,
    VkDeviceSize offset);







typedef struct VkPhysicalDeviceBorderColorSwizzleFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 borderColorSwizzle;
    VkBool32 borderColorSwizzleFromImage;
} VkPhysicalDeviceBorderColorSwizzleFeaturesEXT;

typedef struct VkSamplerBorderColorComponentMappingCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkComponentMapping components;
    VkBool32 srgb;
} VkSamplerBorderColorComponentMappingCreateInfoEXT;







typedef struct VkPhysicalDevicePageableDeviceLocalMemoryFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 pageableDeviceLocalMemory;
} VkPhysicalDevicePageableDeviceLocalMemoryFeaturesEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkSetDeviceMemoryPriorityEXT)(VkDevice device, VkDeviceMemory memory, float priority);


 void __attribute__((__stdcall__)) vkSetDeviceMemoryPriorityEXT(
    VkDevice device,
    VkDeviceMemory memory,
    float priority);







typedef struct VkPhysicalDeviceShaderCorePropertiesARM {
    VkStructureType sType;
    void* pNext;
    uint32_t pixelRate;
    uint32_t texelRate;
    uint32_t fmaRate;
} VkPhysicalDeviceShaderCorePropertiesARM;







typedef VkFlags64 VkPhysicalDeviceSchedulingControlsFlagsARM;


typedef VkFlags64 VkPhysicalDeviceSchedulingControlsFlagBitsARM;
static const VkPhysicalDeviceSchedulingControlsFlagBitsARM VK_PHYSICAL_DEVICE_SCHEDULING_CONTROLS_SHADER_CORE_COUNT_ARM = 0x00000001ULL;

typedef struct VkDeviceQueueShaderCoreControlCreateInfoARM {
    VkStructureType sType;
    void* pNext;
    uint32_t shaderCoreCount;
} VkDeviceQueueShaderCoreControlCreateInfoARM;

typedef struct VkPhysicalDeviceSchedulingControlsFeaturesARM {
    VkStructureType sType;
    void* pNext;
    VkBool32 schedulingControls;
} VkPhysicalDeviceSchedulingControlsFeaturesARM;

typedef struct VkPhysicalDeviceSchedulingControlsPropertiesARM {
    VkStructureType sType;
    void* pNext;
    VkPhysicalDeviceSchedulingControlsFlagsARM schedulingControlsFlags;
} VkPhysicalDeviceSchedulingControlsPropertiesARM;
# 18628 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkPhysicalDeviceImageSlicedViewOf3DFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 imageSlicedViewOf3D;
} VkPhysicalDeviceImageSlicedViewOf3DFeaturesEXT;

typedef struct VkImageViewSlicedCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    uint32_t sliceOffset;
    uint32_t sliceCount;
} VkImageViewSlicedCreateInfoEXT;







typedef struct VkPhysicalDeviceDescriptorSetHostMappingFeaturesVALVE {
    VkStructureType sType;
    void* pNext;
    VkBool32 descriptorSetHostMapping;
} VkPhysicalDeviceDescriptorSetHostMappingFeaturesVALVE;

typedef struct VkDescriptorSetBindingReferenceVALVE {
    VkStructureType sType;
    const void* pNext;
    VkDescriptorSetLayout descriptorSetLayout;
    uint32_t binding;
} VkDescriptorSetBindingReferenceVALVE;

typedef struct VkDescriptorSetLayoutHostMappingInfoVALVE {
    VkStructureType sType;
    void* pNext;
    size_t descriptorOffset;
    uint32_t descriptorSize;
} VkDescriptorSetLayoutHostMappingInfoVALVE;

typedef void (__attribute__((__stdcall__)) *PFN_vkGetDescriptorSetLayoutHostMappingInfoVALVE)(VkDevice device, const VkDescriptorSetBindingReferenceVALVE* pBindingReference, VkDescriptorSetLayoutHostMappingInfoVALVE* pHostMapping);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetDescriptorSetHostMappingVALVE)(VkDevice device, VkDescriptorSet descriptorSet, void** ppData);


 void __attribute__((__stdcall__)) vkGetDescriptorSetLayoutHostMappingInfoVALVE(
    VkDevice device,
    const VkDescriptorSetBindingReferenceVALVE* pBindingReference,
    VkDescriptorSetLayoutHostMappingInfoVALVE* pHostMapping);

 void __attribute__((__stdcall__)) vkGetDescriptorSetHostMappingVALVE(
    VkDevice device,
    VkDescriptorSet descriptorSet,
    void** ppData);







typedef struct VkPhysicalDeviceDepthClampZeroOneFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 depthClampZeroOne;
} VkPhysicalDeviceDepthClampZeroOneFeaturesEXT;







typedef struct VkPhysicalDeviceNonSeamlessCubeMapFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 nonSeamlessCubeMap;
} VkPhysicalDeviceNonSeamlessCubeMapFeaturesEXT;







typedef struct VkPhysicalDeviceRenderPassStripedFeaturesARM {
    VkStructureType sType;
    void* pNext;
    VkBool32 renderPassStriped;
} VkPhysicalDeviceRenderPassStripedFeaturesARM;

typedef struct VkPhysicalDeviceRenderPassStripedPropertiesARM {
    VkStructureType sType;
    void* pNext;
    VkExtent2D renderPassStripeGranularity;
    uint32_t maxRenderPassStripes;
} VkPhysicalDeviceRenderPassStripedPropertiesARM;

typedef struct VkRenderPassStripeInfoARM {
    VkStructureType sType;
    const void* pNext;
    VkRect2D stripeArea;
} VkRenderPassStripeInfoARM;

typedef struct VkRenderPassStripeBeginInfoARM {
    VkStructureType sType;
    const void* pNext;
    uint32_t stripeInfoCount;
    const VkRenderPassStripeInfoARM* pStripeInfos;
} VkRenderPassStripeBeginInfoARM;

typedef struct VkRenderPassStripeSubmitInfoARM {
    VkStructureType sType;
    const void* pNext;
    uint32_t stripeSemaphoreInfoCount;
    const VkSemaphoreSubmitInfo* pStripeSemaphoreInfos;
} VkRenderPassStripeSubmitInfoARM;







typedef struct VkPhysicalDeviceFragmentDensityMapOffsetFeaturesQCOM {
    VkStructureType sType;
    void* pNext;
    VkBool32 fragmentDensityMapOffset;
} VkPhysicalDeviceFragmentDensityMapOffsetFeaturesQCOM;

typedef struct VkPhysicalDeviceFragmentDensityMapOffsetPropertiesQCOM {
    VkStructureType sType;
    void* pNext;
    VkExtent2D fragmentDensityOffsetGranularity;
} VkPhysicalDeviceFragmentDensityMapOffsetPropertiesQCOM;

typedef struct VkSubpassFragmentDensityMapOffsetEndInfoQCOM {
    VkStructureType sType;
    const void* pNext;
    uint32_t fragmentDensityOffsetCount;
    const VkOffset2D* pFragmentDensityOffsets;
} VkSubpassFragmentDensityMapOffsetEndInfoQCOM;







typedef struct VkCopyMemoryIndirectCommandNV {
    VkDeviceAddress srcAddress;
    VkDeviceAddress dstAddress;
    VkDeviceSize size;
} VkCopyMemoryIndirectCommandNV;

typedef struct VkCopyMemoryToImageIndirectCommandNV {
    VkDeviceAddress srcAddress;
    uint32_t bufferRowLength;
    uint32_t bufferImageHeight;
    VkImageSubresourceLayers imageSubresource;
    VkOffset3D imageOffset;
    VkExtent3D imageExtent;
} VkCopyMemoryToImageIndirectCommandNV;

typedef struct VkPhysicalDeviceCopyMemoryIndirectFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 indirectCopy;
} VkPhysicalDeviceCopyMemoryIndirectFeaturesNV;

typedef struct VkPhysicalDeviceCopyMemoryIndirectPropertiesNV {
    VkStructureType sType;
    void* pNext;
    VkQueueFlags supportedQueues;
} VkPhysicalDeviceCopyMemoryIndirectPropertiesNV;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyMemoryIndirectNV)(VkCommandBuffer commandBuffer, VkDeviceAddress copyBufferAddress, uint32_t copyCount, uint32_t stride);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyMemoryToImageIndirectNV)(VkCommandBuffer commandBuffer, VkDeviceAddress copyBufferAddress, uint32_t copyCount, uint32_t stride, VkImage dstImage, VkImageLayout dstImageLayout, const VkImageSubresourceLayers* pImageSubresources);


 void __attribute__((__stdcall__)) vkCmdCopyMemoryIndirectNV(
    VkCommandBuffer commandBuffer,
    VkDeviceAddress copyBufferAddress,
    uint32_t copyCount,
    uint32_t stride);

 void __attribute__((__stdcall__)) vkCmdCopyMemoryToImageIndirectNV(
    VkCommandBuffer commandBuffer,
    VkDeviceAddress copyBufferAddress,
    uint32_t copyCount,
    uint32_t stride,
    VkImage dstImage,
    VkImageLayout dstImageLayout,
    const VkImageSubresourceLayers* pImageSubresources);
# 18829 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef VkFlags64 VkMemoryDecompressionMethodFlagBitsNV;
static const VkMemoryDecompressionMethodFlagBitsNV VK_MEMORY_DECOMPRESSION_METHOD_GDEFLATE_1_0_BIT_NV = 0x00000001ULL;

typedef VkFlags64 VkMemoryDecompressionMethodFlagsNV;
typedef struct VkDecompressMemoryRegionNV {
    VkDeviceAddress srcAddress;
    VkDeviceAddress dstAddress;
    VkDeviceSize compressedSize;
    VkDeviceSize decompressedSize;
    VkMemoryDecompressionMethodFlagsNV decompressionMethod;
} VkDecompressMemoryRegionNV;

typedef struct VkPhysicalDeviceMemoryDecompressionFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 memoryDecompression;
} VkPhysicalDeviceMemoryDecompressionFeaturesNV;

typedef struct VkPhysicalDeviceMemoryDecompressionPropertiesNV {
    VkStructureType sType;
    void* pNext;
    VkMemoryDecompressionMethodFlagsNV decompressionMethods;
    uint64_t maxDecompressionIndirectCount;
} VkPhysicalDeviceMemoryDecompressionPropertiesNV;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDecompressMemoryNV)(VkCommandBuffer commandBuffer, uint32_t decompressRegionCount, const VkDecompressMemoryRegionNV* pDecompressMemoryRegions);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDecompressMemoryIndirectCountNV)(VkCommandBuffer commandBuffer, VkDeviceAddress indirectCommandsAddress, VkDeviceAddress indirectCommandsCountAddress, uint32_t stride);


 void __attribute__((__stdcall__)) vkCmdDecompressMemoryNV(
    VkCommandBuffer commandBuffer,
    uint32_t decompressRegionCount,
    const VkDecompressMemoryRegionNV* pDecompressMemoryRegions);

 void __attribute__((__stdcall__)) vkCmdDecompressMemoryIndirectCountNV(
    VkCommandBuffer commandBuffer,
    VkDeviceAddress indirectCommandsAddress,
    VkDeviceAddress indirectCommandsCountAddress,
    uint32_t stride);







typedef struct VkPhysicalDeviceDeviceGeneratedCommandsComputeFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 deviceGeneratedCompute;
    VkBool32 deviceGeneratedComputePipelines;
    VkBool32 deviceGeneratedComputeCaptureReplay;
} VkPhysicalDeviceDeviceGeneratedCommandsComputeFeaturesNV;

typedef struct VkComputePipelineIndirectBufferInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkDeviceAddress deviceAddress;
    VkDeviceSize size;
    VkDeviceAddress pipelineDeviceAddressCaptureReplay;
} VkComputePipelineIndirectBufferInfoNV;

typedef struct VkPipelineIndirectDeviceAddressInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkPipelineBindPoint pipelineBindPoint;
    VkPipeline pipeline;
} VkPipelineIndirectDeviceAddressInfoNV;

typedef struct VkBindPipelineIndirectCommandNV {
    VkDeviceAddress pipelineAddress;
} VkBindPipelineIndirectCommandNV;

typedef void (__attribute__((__stdcall__)) *PFN_vkGetPipelineIndirectMemoryRequirementsNV)(VkDevice device, const VkComputePipelineCreateInfo* pCreateInfo, VkMemoryRequirements2* pMemoryRequirements);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdUpdatePipelineIndirectBufferNV)(VkCommandBuffer commandBuffer, VkPipelineBindPoint pipelineBindPoint, VkPipeline pipeline);
typedef VkDeviceAddress (__attribute__((__stdcall__)) *PFN_vkGetPipelineIndirectDeviceAddressNV)(VkDevice device, const VkPipelineIndirectDeviceAddressInfoNV* pInfo);


 void __attribute__((__stdcall__)) vkGetPipelineIndirectMemoryRequirementsNV(
    VkDevice device,
    const VkComputePipelineCreateInfo* pCreateInfo,
    VkMemoryRequirements2* pMemoryRequirements);

 void __attribute__((__stdcall__)) vkCmdUpdatePipelineIndirectBufferNV(
    VkCommandBuffer commandBuffer,
    VkPipelineBindPoint pipelineBindPoint,
    VkPipeline pipeline);

 VkDeviceAddress __attribute__((__stdcall__)) vkGetPipelineIndirectDeviceAddressNV(
    VkDevice device,
    const VkPipelineIndirectDeviceAddressInfoNV* pInfo);







typedef struct VkPhysicalDeviceLinearColorAttachmentFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 linearColorAttachment;
} VkPhysicalDeviceLinearColorAttachmentFeaturesNV;
# 18945 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkPhysicalDeviceImageCompressionControlSwapchainFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 imageCompressionControlSwapchain;
} VkPhysicalDeviceImageCompressionControlSwapchainFeaturesEXT;







typedef struct VkImageViewSampleWeightCreateInfoQCOM {
    VkStructureType sType;
    const void* pNext;
    VkOffset2D filterCenter;
    VkExtent2D filterSize;
    uint32_t numPhases;
} VkImageViewSampleWeightCreateInfoQCOM;

typedef struct VkPhysicalDeviceImageProcessingFeaturesQCOM {
    VkStructureType sType;
    void* pNext;
    VkBool32 textureSampleWeighted;
    VkBool32 textureBoxFilter;
    VkBool32 textureBlockMatch;
} VkPhysicalDeviceImageProcessingFeaturesQCOM;

typedef struct VkPhysicalDeviceImageProcessingPropertiesQCOM {
    VkStructureType sType;
    void* pNext;
    uint32_t maxWeightFilterPhases;
    VkExtent2D maxWeightFilterDimension;
    VkExtent2D maxBlockMatchRegion;
    VkExtent2D maxBoxFilterBlockSize;
} VkPhysicalDeviceImageProcessingPropertiesQCOM;







typedef struct VkPhysicalDeviceNestedCommandBufferFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 nestedCommandBuffer;
    VkBool32 nestedCommandBufferRendering;
    VkBool32 nestedCommandBufferSimultaneousUse;
} VkPhysicalDeviceNestedCommandBufferFeaturesEXT;

typedef struct VkPhysicalDeviceNestedCommandBufferPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    uint32_t maxCommandBufferNestingLevel;
} VkPhysicalDeviceNestedCommandBufferPropertiesEXT;







typedef struct VkExternalMemoryAcquireUnmodifiedEXT {
    VkStructureType sType;
    const void* pNext;
    VkBool32 acquireUnmodifiedMemory;
} VkExternalMemoryAcquireUnmodifiedEXT;







typedef struct VkPhysicalDeviceExtendedDynamicState3FeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 extendedDynamicState3TessellationDomainOrigin;
    VkBool32 extendedDynamicState3DepthClampEnable;
    VkBool32 extendedDynamicState3PolygonMode;
    VkBool32 extendedDynamicState3RasterizationSamples;
    VkBool32 extendedDynamicState3SampleMask;
    VkBool32 extendedDynamicState3AlphaToCoverageEnable;
    VkBool32 extendedDynamicState3AlphaToOneEnable;
    VkBool32 extendedDynamicState3LogicOpEnable;
    VkBool32 extendedDynamicState3ColorBlendEnable;
    VkBool32 extendedDynamicState3ColorBlendEquation;
    VkBool32 extendedDynamicState3ColorWriteMask;
    VkBool32 extendedDynamicState3RasterizationStream;
    VkBool32 extendedDynamicState3ConservativeRasterizationMode;
    VkBool32 extendedDynamicState3ExtraPrimitiveOverestimationSize;
    VkBool32 extendedDynamicState3DepthClipEnable;
    VkBool32 extendedDynamicState3SampleLocationsEnable;
    VkBool32 extendedDynamicState3ColorBlendAdvanced;
    VkBool32 extendedDynamicState3ProvokingVertexMode;
    VkBool32 extendedDynamicState3LineRasterizationMode;
    VkBool32 extendedDynamicState3LineStippleEnable;
    VkBool32 extendedDynamicState3DepthClipNegativeOneToOne;
    VkBool32 extendedDynamicState3ViewportWScalingEnable;
    VkBool32 extendedDynamicState3ViewportSwizzle;
    VkBool32 extendedDynamicState3CoverageToColorEnable;
    VkBool32 extendedDynamicState3CoverageToColorLocation;
    VkBool32 extendedDynamicState3CoverageModulationMode;
    VkBool32 extendedDynamicState3CoverageModulationTableEnable;
    VkBool32 extendedDynamicState3CoverageModulationTable;
    VkBool32 extendedDynamicState3CoverageReductionMode;
    VkBool32 extendedDynamicState3RepresentativeFragmentTestEnable;
    VkBool32 extendedDynamicState3ShadingRateImageEnable;
} VkPhysicalDeviceExtendedDynamicState3FeaturesEXT;

typedef struct VkPhysicalDeviceExtendedDynamicState3PropertiesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 dynamicPrimitiveTopologyUnrestricted;
} VkPhysicalDeviceExtendedDynamicState3PropertiesEXT;

typedef struct VkColorBlendEquationEXT {
    VkBlendFactor srcColorBlendFactor;
    VkBlendFactor dstColorBlendFactor;
    VkBlendOp colorBlendOp;
    VkBlendFactor srcAlphaBlendFactor;
    VkBlendFactor dstAlphaBlendFactor;
    VkBlendOp alphaBlendOp;
} VkColorBlendEquationEXT;

typedef struct VkColorBlendAdvancedEXT {
    VkBlendOp advancedBlendOp;
    VkBool32 srcPremultiplied;
    VkBool32 dstPremultiplied;
    VkBlendOverlapEXT blendOverlap;
    VkBool32 clampResults;
} VkColorBlendAdvancedEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDepthClampEnableEXT)(VkCommandBuffer commandBuffer, VkBool32 depthClampEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetPolygonModeEXT)(VkCommandBuffer commandBuffer, VkPolygonMode polygonMode);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetRasterizationSamplesEXT)(VkCommandBuffer commandBuffer, VkSampleCountFlagBits rasterizationSamples);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetSampleMaskEXT)(VkCommandBuffer commandBuffer, VkSampleCountFlagBits samples, const VkSampleMask* pSampleMask);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetAlphaToCoverageEnableEXT)(VkCommandBuffer commandBuffer, VkBool32 alphaToCoverageEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetAlphaToOneEnableEXT)(VkCommandBuffer commandBuffer, VkBool32 alphaToOneEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetLogicOpEnableEXT)(VkCommandBuffer commandBuffer, VkBool32 logicOpEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetColorBlendEnableEXT)(VkCommandBuffer commandBuffer, uint32_t firstAttachment, uint32_t attachmentCount, const VkBool32* pColorBlendEnables);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetColorBlendEquationEXT)(VkCommandBuffer commandBuffer, uint32_t firstAttachment, uint32_t attachmentCount, const VkColorBlendEquationEXT* pColorBlendEquations);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetColorWriteMaskEXT)(VkCommandBuffer commandBuffer, uint32_t firstAttachment, uint32_t attachmentCount, const VkColorComponentFlags* pColorWriteMasks);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetTessellationDomainOriginEXT)(VkCommandBuffer commandBuffer, VkTessellationDomainOrigin domainOrigin);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetRasterizationStreamEXT)(VkCommandBuffer commandBuffer, uint32_t rasterizationStream);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetConservativeRasterizationModeEXT)(VkCommandBuffer commandBuffer, VkConservativeRasterizationModeEXT conservativeRasterizationMode);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetExtraPrimitiveOverestimationSizeEXT)(VkCommandBuffer commandBuffer, float extraPrimitiveOverestimationSize);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDepthClipEnableEXT)(VkCommandBuffer commandBuffer, VkBool32 depthClipEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetSampleLocationsEnableEXT)(VkCommandBuffer commandBuffer, VkBool32 sampleLocationsEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetColorBlendAdvancedEXT)(VkCommandBuffer commandBuffer, uint32_t firstAttachment, uint32_t attachmentCount, const VkColorBlendAdvancedEXT* pColorBlendAdvanced);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetProvokingVertexModeEXT)(VkCommandBuffer commandBuffer, VkProvokingVertexModeEXT provokingVertexMode);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetLineRasterizationModeEXT)(VkCommandBuffer commandBuffer, VkLineRasterizationModeEXT lineRasterizationMode);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetLineStippleEnableEXT)(VkCommandBuffer commandBuffer, VkBool32 stippledLineEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDepthClipNegativeOneToOneEXT)(VkCommandBuffer commandBuffer, VkBool32 negativeOneToOne);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetViewportWScalingEnableNV)(VkCommandBuffer commandBuffer, VkBool32 viewportWScalingEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetViewportSwizzleNV)(VkCommandBuffer commandBuffer, uint32_t firstViewport, uint32_t viewportCount, const VkViewportSwizzleNV* pViewportSwizzles);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetCoverageToColorEnableNV)(VkCommandBuffer commandBuffer, VkBool32 coverageToColorEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetCoverageToColorLocationNV)(VkCommandBuffer commandBuffer, uint32_t coverageToColorLocation);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetCoverageModulationModeNV)(VkCommandBuffer commandBuffer, VkCoverageModulationModeNV coverageModulationMode);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetCoverageModulationTableEnableNV)(VkCommandBuffer commandBuffer, VkBool32 coverageModulationTableEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetCoverageModulationTableNV)(VkCommandBuffer commandBuffer, uint32_t coverageModulationTableCount, const float* pCoverageModulationTable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetShadingRateImageEnableNV)(VkCommandBuffer commandBuffer, VkBool32 shadingRateImageEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetRepresentativeFragmentTestEnableNV)(VkCommandBuffer commandBuffer, VkBool32 representativeFragmentTestEnable);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetCoverageReductionModeNV)(VkCommandBuffer commandBuffer, VkCoverageReductionModeNV coverageReductionMode);


 void __attribute__((__stdcall__)) vkCmdSetDepthClampEnableEXT(
    VkCommandBuffer commandBuffer,
    VkBool32 depthClampEnable);

 void __attribute__((__stdcall__)) vkCmdSetPolygonModeEXT(
    VkCommandBuffer commandBuffer,
    VkPolygonMode polygonMode);

 void __attribute__((__stdcall__)) vkCmdSetRasterizationSamplesEXT(
    VkCommandBuffer commandBuffer,
    VkSampleCountFlagBits rasterizationSamples);

 void __attribute__((__stdcall__)) vkCmdSetSampleMaskEXT(
    VkCommandBuffer commandBuffer,
    VkSampleCountFlagBits samples,
    const VkSampleMask* pSampleMask);

 void __attribute__((__stdcall__)) vkCmdSetAlphaToCoverageEnableEXT(
    VkCommandBuffer commandBuffer,
    VkBool32 alphaToCoverageEnable);

 void __attribute__((__stdcall__)) vkCmdSetAlphaToOneEnableEXT(
    VkCommandBuffer commandBuffer,
    VkBool32 alphaToOneEnable);

 void __attribute__((__stdcall__)) vkCmdSetLogicOpEnableEXT(
    VkCommandBuffer commandBuffer,
    VkBool32 logicOpEnable);

 void __attribute__((__stdcall__)) vkCmdSetColorBlendEnableEXT(
    VkCommandBuffer commandBuffer,
    uint32_t firstAttachment,
    uint32_t attachmentCount,
    const VkBool32* pColorBlendEnables);

 void __attribute__((__stdcall__)) vkCmdSetColorBlendEquationEXT(
    VkCommandBuffer commandBuffer,
    uint32_t firstAttachment,
    uint32_t attachmentCount,
    const VkColorBlendEquationEXT* pColorBlendEquations);

 void __attribute__((__stdcall__)) vkCmdSetColorWriteMaskEXT(
    VkCommandBuffer commandBuffer,
    uint32_t firstAttachment,
    uint32_t attachmentCount,
    const VkColorComponentFlags* pColorWriteMasks);

 void __attribute__((__stdcall__)) vkCmdSetTessellationDomainOriginEXT(
    VkCommandBuffer commandBuffer,
    VkTessellationDomainOrigin domainOrigin);

 void __attribute__((__stdcall__)) vkCmdSetRasterizationStreamEXT(
    VkCommandBuffer commandBuffer,
    uint32_t rasterizationStream);

 void __attribute__((__stdcall__)) vkCmdSetConservativeRasterizationModeEXT(
    VkCommandBuffer commandBuffer,
    VkConservativeRasterizationModeEXT conservativeRasterizationMode);

 void __attribute__((__stdcall__)) vkCmdSetExtraPrimitiveOverestimationSizeEXT(
    VkCommandBuffer commandBuffer,
    float extraPrimitiveOverestimationSize);

 void __attribute__((__stdcall__)) vkCmdSetDepthClipEnableEXT(
    VkCommandBuffer commandBuffer,
    VkBool32 depthClipEnable);

 void __attribute__((__stdcall__)) vkCmdSetSampleLocationsEnableEXT(
    VkCommandBuffer commandBuffer,
    VkBool32 sampleLocationsEnable);

 void __attribute__((__stdcall__)) vkCmdSetColorBlendAdvancedEXT(
    VkCommandBuffer commandBuffer,
    uint32_t firstAttachment,
    uint32_t attachmentCount,
    const VkColorBlendAdvancedEXT* pColorBlendAdvanced);

 void __attribute__((__stdcall__)) vkCmdSetProvokingVertexModeEXT(
    VkCommandBuffer commandBuffer,
    VkProvokingVertexModeEXT provokingVertexMode);

 void __attribute__((__stdcall__)) vkCmdSetLineRasterizationModeEXT(
    VkCommandBuffer commandBuffer,
    VkLineRasterizationModeEXT lineRasterizationMode);

 void __attribute__((__stdcall__)) vkCmdSetLineStippleEnableEXT(
    VkCommandBuffer commandBuffer,
    VkBool32 stippledLineEnable);

 void __attribute__((__stdcall__)) vkCmdSetDepthClipNegativeOneToOneEXT(
    VkCommandBuffer commandBuffer,
    VkBool32 negativeOneToOne);

 void __attribute__((__stdcall__)) vkCmdSetViewportWScalingEnableNV(
    VkCommandBuffer commandBuffer,
    VkBool32 viewportWScalingEnable);

 void __attribute__((__stdcall__)) vkCmdSetViewportSwizzleNV(
    VkCommandBuffer commandBuffer,
    uint32_t firstViewport,
    uint32_t viewportCount,
    const VkViewportSwizzleNV* pViewportSwizzles);

 void __attribute__((__stdcall__)) vkCmdSetCoverageToColorEnableNV(
    VkCommandBuffer commandBuffer,
    VkBool32 coverageToColorEnable);

 void __attribute__((__stdcall__)) vkCmdSetCoverageToColorLocationNV(
    VkCommandBuffer commandBuffer,
    uint32_t coverageToColorLocation);

 void __attribute__((__stdcall__)) vkCmdSetCoverageModulationModeNV(
    VkCommandBuffer commandBuffer,
    VkCoverageModulationModeNV coverageModulationMode);

 void __attribute__((__stdcall__)) vkCmdSetCoverageModulationTableEnableNV(
    VkCommandBuffer commandBuffer,
    VkBool32 coverageModulationTableEnable);

 void __attribute__((__stdcall__)) vkCmdSetCoverageModulationTableNV(
    VkCommandBuffer commandBuffer,
    uint32_t coverageModulationTableCount,
    const float* pCoverageModulationTable);

 void __attribute__((__stdcall__)) vkCmdSetShadingRateImageEnableNV(
    VkCommandBuffer commandBuffer,
    VkBool32 shadingRateImageEnable);

 void __attribute__((__stdcall__)) vkCmdSetRepresentativeFragmentTestEnableNV(
    VkCommandBuffer commandBuffer,
    VkBool32 representativeFragmentTestEnable);

 void __attribute__((__stdcall__)) vkCmdSetCoverageReductionModeNV(
    VkCommandBuffer commandBuffer,
    VkCoverageReductionModeNV coverageReductionMode);
# 19255 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkSubpassMergeStatusEXT {
    VK_SUBPASS_MERGE_STATUS_MERGED_EXT = 0,
    VK_SUBPASS_MERGE_STATUS_DISALLOWED_EXT = 1,
    VK_SUBPASS_MERGE_STATUS_NOT_MERGED_SIDE_EFFECTS_EXT = 2,
    VK_SUBPASS_MERGE_STATUS_NOT_MERGED_SAMPLES_MISMATCH_EXT = 3,
    VK_SUBPASS_MERGE_STATUS_NOT_MERGED_VIEWS_MISMATCH_EXT = 4,
    VK_SUBPASS_MERGE_STATUS_NOT_MERGED_ALIASING_EXT = 5,
    VK_SUBPASS_MERGE_STATUS_NOT_MERGED_DEPENDENCIES_EXT = 6,
    VK_SUBPASS_MERGE_STATUS_NOT_MERGED_INCOMPATIBLE_INPUT_ATTACHMENT_EXT = 7,
    VK_SUBPASS_MERGE_STATUS_NOT_MERGED_TOO_MANY_ATTACHMENTS_EXT = 8,
    VK_SUBPASS_MERGE_STATUS_NOT_MERGED_INSUFFICIENT_STORAGE_EXT = 9,
    VK_SUBPASS_MERGE_STATUS_NOT_MERGED_DEPTH_STENCIL_COUNT_EXT = 10,
    VK_SUBPASS_MERGE_STATUS_NOT_MERGED_RESOLVE_ATTACHMENT_REUSE_EXT = 11,
    VK_SUBPASS_MERGE_STATUS_NOT_MERGED_SINGLE_SUBPASS_EXT = 12,
    VK_SUBPASS_MERGE_STATUS_NOT_MERGED_UNSPECIFIED_EXT = 13,
    VK_SUBPASS_MERGE_STATUS_MAX_ENUM_EXT = 0x7FFFFFFF
} VkSubpassMergeStatusEXT;
typedef struct VkPhysicalDeviceSubpassMergeFeedbackFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 subpassMergeFeedback;
} VkPhysicalDeviceSubpassMergeFeedbackFeaturesEXT;

typedef struct VkRenderPassCreationControlEXT {
    VkStructureType sType;
    const void* pNext;
    VkBool32 disallowMerging;
} VkRenderPassCreationControlEXT;

typedef struct VkRenderPassCreationFeedbackInfoEXT {
    uint32_t postMergeSubpassCount;
} VkRenderPassCreationFeedbackInfoEXT;

typedef struct VkRenderPassCreationFeedbackCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkRenderPassCreationFeedbackInfoEXT* pRenderPassFeedback;
} VkRenderPassCreationFeedbackCreateInfoEXT;

typedef struct VkRenderPassSubpassFeedbackInfoEXT {
    VkSubpassMergeStatusEXT subpassMergeStatus;
    char description[256U];
    uint32_t postMergeIndex;
} VkRenderPassSubpassFeedbackInfoEXT;

typedef struct VkRenderPassSubpassFeedbackCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkRenderPassSubpassFeedbackInfoEXT* pSubpassFeedback;
} VkRenderPassSubpassFeedbackCreateInfoEXT;
# 19313 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkDirectDriverLoadingModeLUNARG {
    VK_DIRECT_DRIVER_LOADING_MODE_EXCLUSIVE_LUNARG = 0,
    VK_DIRECT_DRIVER_LOADING_MODE_INCLUSIVE_LUNARG = 1,
    VK_DIRECT_DRIVER_LOADING_MODE_MAX_ENUM_LUNARG = 0x7FFFFFFF
} VkDirectDriverLoadingModeLUNARG;
typedef VkFlags VkDirectDriverLoadingFlagsLUNARG;
typedef PFN_vkVoidFunction (__attribute__((__stdcall__)) *PFN_vkGetInstanceProcAddrLUNARG)(
    VkInstance instance, const char* pName);

typedef struct VkDirectDriverLoadingInfoLUNARG {
    VkStructureType sType;
    void* pNext;
    VkDirectDriverLoadingFlagsLUNARG flags;
    PFN_vkGetInstanceProcAddrLUNARG pfnGetInstanceProcAddr;
} VkDirectDriverLoadingInfoLUNARG;

typedef struct VkDirectDriverLoadingListLUNARG {
    VkStructureType sType;
    const void* pNext;
    VkDirectDriverLoadingModeLUNARG mode;
    uint32_t driverCount;
    const VkDirectDriverLoadingInfoLUNARG* pDrivers;
} VkDirectDriverLoadingListLUNARG;
# 19344 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkPhysicalDeviceShaderModuleIdentifierFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderModuleIdentifier;
} VkPhysicalDeviceShaderModuleIdentifierFeaturesEXT;

typedef struct VkPhysicalDeviceShaderModuleIdentifierPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    uint8_t shaderModuleIdentifierAlgorithmUUID[16U];
} VkPhysicalDeviceShaderModuleIdentifierPropertiesEXT;

typedef struct VkPipelineShaderStageModuleIdentifierCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    uint32_t identifierSize;
    const uint8_t* pIdentifier;
} VkPipelineShaderStageModuleIdentifierCreateInfoEXT;

typedef struct VkShaderModuleIdentifierEXT {
    VkStructureType sType;
    void* pNext;
    uint32_t identifierSize;
    uint8_t identifier[32U];
} VkShaderModuleIdentifierEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkGetShaderModuleIdentifierEXT)(VkDevice device, VkShaderModule shaderModule, VkShaderModuleIdentifierEXT* pIdentifier);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetShaderModuleCreateInfoIdentifierEXT)(VkDevice device, const VkShaderModuleCreateInfo* pCreateInfo, VkShaderModuleIdentifierEXT* pIdentifier);


 void __attribute__((__stdcall__)) vkGetShaderModuleIdentifierEXT(
    VkDevice device,
    VkShaderModule shaderModule,
    VkShaderModuleIdentifierEXT* pIdentifier);

 void __attribute__((__stdcall__)) vkGetShaderModuleCreateInfoIdentifierEXT(
    VkDevice device,
    const VkShaderModuleCreateInfo* pCreateInfo,
    VkShaderModuleIdentifierEXT* pIdentifier);
# 19394 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkOpticalFlowSessionNV_T *VkOpticalFlowSessionNV;



typedef enum VkOpticalFlowPerformanceLevelNV {
    VK_OPTICAL_FLOW_PERFORMANCE_LEVEL_UNKNOWN_NV = 0,
    VK_OPTICAL_FLOW_PERFORMANCE_LEVEL_SLOW_NV = 1,
    VK_OPTICAL_FLOW_PERFORMANCE_LEVEL_MEDIUM_NV = 2,
    VK_OPTICAL_FLOW_PERFORMANCE_LEVEL_FAST_NV = 3,
    VK_OPTICAL_FLOW_PERFORMANCE_LEVEL_MAX_ENUM_NV = 0x7FFFFFFF
} VkOpticalFlowPerformanceLevelNV;

typedef enum VkOpticalFlowSessionBindingPointNV {
    VK_OPTICAL_FLOW_SESSION_BINDING_POINT_UNKNOWN_NV = 0,
    VK_OPTICAL_FLOW_SESSION_BINDING_POINT_INPUT_NV = 1,
    VK_OPTICAL_FLOW_SESSION_BINDING_POINT_REFERENCE_NV = 2,
    VK_OPTICAL_FLOW_SESSION_BINDING_POINT_HINT_NV = 3,
    VK_OPTICAL_FLOW_SESSION_BINDING_POINT_FLOW_VECTOR_NV = 4,
    VK_OPTICAL_FLOW_SESSION_BINDING_POINT_BACKWARD_FLOW_VECTOR_NV = 5,
    VK_OPTICAL_FLOW_SESSION_BINDING_POINT_COST_NV = 6,
    VK_OPTICAL_FLOW_SESSION_BINDING_POINT_BACKWARD_COST_NV = 7,
    VK_OPTICAL_FLOW_SESSION_BINDING_POINT_GLOBAL_FLOW_NV = 8,
    VK_OPTICAL_FLOW_SESSION_BINDING_POINT_MAX_ENUM_NV = 0x7FFFFFFF
} VkOpticalFlowSessionBindingPointNV;

typedef enum VkOpticalFlowGridSizeFlagBitsNV {
    VK_OPTICAL_FLOW_GRID_SIZE_UNKNOWN_NV = 0,
    VK_OPTICAL_FLOW_GRID_SIZE_1X1_BIT_NV = 0x00000001,
    VK_OPTICAL_FLOW_GRID_SIZE_2X2_BIT_NV = 0x00000002,
    VK_OPTICAL_FLOW_GRID_SIZE_4X4_BIT_NV = 0x00000004,
    VK_OPTICAL_FLOW_GRID_SIZE_8X8_BIT_NV = 0x00000008,
    VK_OPTICAL_FLOW_GRID_SIZE_FLAG_BITS_MAX_ENUM_NV = 0x7FFFFFFF
} VkOpticalFlowGridSizeFlagBitsNV;
typedef VkFlags VkOpticalFlowGridSizeFlagsNV;

typedef enum VkOpticalFlowUsageFlagBitsNV {
    VK_OPTICAL_FLOW_USAGE_UNKNOWN_NV = 0,
    VK_OPTICAL_FLOW_USAGE_INPUT_BIT_NV = 0x00000001,
    VK_OPTICAL_FLOW_USAGE_OUTPUT_BIT_NV = 0x00000002,
    VK_OPTICAL_FLOW_USAGE_HINT_BIT_NV = 0x00000004,
    VK_OPTICAL_FLOW_USAGE_COST_BIT_NV = 0x00000008,
    VK_OPTICAL_FLOW_USAGE_GLOBAL_FLOW_BIT_NV = 0x00000010,
    VK_OPTICAL_FLOW_USAGE_FLAG_BITS_MAX_ENUM_NV = 0x7FFFFFFF
} VkOpticalFlowUsageFlagBitsNV;
typedef VkFlags VkOpticalFlowUsageFlagsNV;

typedef enum VkOpticalFlowSessionCreateFlagBitsNV {
    VK_OPTICAL_FLOW_SESSION_CREATE_ENABLE_HINT_BIT_NV = 0x00000001,
    VK_OPTICAL_FLOW_SESSION_CREATE_ENABLE_COST_BIT_NV = 0x00000002,
    VK_OPTICAL_FLOW_SESSION_CREATE_ENABLE_GLOBAL_FLOW_BIT_NV = 0x00000004,
    VK_OPTICAL_FLOW_SESSION_CREATE_ALLOW_REGIONS_BIT_NV = 0x00000008,
    VK_OPTICAL_FLOW_SESSION_CREATE_BOTH_DIRECTIONS_BIT_NV = 0x00000010,
    VK_OPTICAL_FLOW_SESSION_CREATE_FLAG_BITS_MAX_ENUM_NV = 0x7FFFFFFF
} VkOpticalFlowSessionCreateFlagBitsNV;
typedef VkFlags VkOpticalFlowSessionCreateFlagsNV;

typedef enum VkOpticalFlowExecuteFlagBitsNV {
    VK_OPTICAL_FLOW_EXECUTE_DISABLE_TEMPORAL_HINTS_BIT_NV = 0x00000001,
    VK_OPTICAL_FLOW_EXECUTE_FLAG_BITS_MAX_ENUM_NV = 0x7FFFFFFF
} VkOpticalFlowExecuteFlagBitsNV;
typedef VkFlags VkOpticalFlowExecuteFlagsNV;
typedef struct VkPhysicalDeviceOpticalFlowFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 opticalFlow;
} VkPhysicalDeviceOpticalFlowFeaturesNV;

typedef struct VkPhysicalDeviceOpticalFlowPropertiesNV {
    VkStructureType sType;
    void* pNext;
    VkOpticalFlowGridSizeFlagsNV supportedOutputGridSizes;
    VkOpticalFlowGridSizeFlagsNV supportedHintGridSizes;
    VkBool32 hintSupported;
    VkBool32 costSupported;
    VkBool32 bidirectionalFlowSupported;
    VkBool32 globalFlowSupported;
    uint32_t minWidth;
    uint32_t minHeight;
    uint32_t maxWidth;
    uint32_t maxHeight;
    uint32_t maxNumRegionsOfInterest;
} VkPhysicalDeviceOpticalFlowPropertiesNV;

typedef struct VkOpticalFlowImageFormatInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkOpticalFlowUsageFlagsNV usage;
} VkOpticalFlowImageFormatInfoNV;

typedef struct VkOpticalFlowImageFormatPropertiesNV {
    VkStructureType sType;
    const void* pNext;
    VkFormat format;
} VkOpticalFlowImageFormatPropertiesNV;

typedef struct VkOpticalFlowSessionCreateInfoNV {
    VkStructureType sType;
    void* pNext;
    uint32_t width;
    uint32_t height;
    VkFormat imageFormat;
    VkFormat flowVectorFormat;
    VkFormat costFormat;
    VkOpticalFlowGridSizeFlagsNV outputGridSize;
    VkOpticalFlowGridSizeFlagsNV hintGridSize;
    VkOpticalFlowPerformanceLevelNV performanceLevel;
    VkOpticalFlowSessionCreateFlagsNV flags;
} VkOpticalFlowSessionCreateInfoNV;

typedef struct VkOpticalFlowSessionCreatePrivateDataInfoNV {
    VkStructureType sType;
    void* pNext;
    uint32_t id;
    uint32_t size;
    const void* pPrivateData;
} VkOpticalFlowSessionCreatePrivateDataInfoNV;

typedef struct VkOpticalFlowExecuteInfoNV {
    VkStructureType sType;
    void* pNext;
    VkOpticalFlowExecuteFlagsNV flags;
    uint32_t regionCount;
    const VkRect2D* pRegions;
} VkOpticalFlowExecuteInfoNV;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceOpticalFlowImageFormatsNV)(VkPhysicalDevice physicalDevice, const VkOpticalFlowImageFormatInfoNV* pOpticalFlowImageFormatInfo, uint32_t* pFormatCount, VkOpticalFlowImageFormatPropertiesNV* pImageFormatProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateOpticalFlowSessionNV)(VkDevice device, const VkOpticalFlowSessionCreateInfoNV* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkOpticalFlowSessionNV* pSession);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyOpticalFlowSessionNV)(VkDevice device, VkOpticalFlowSessionNV session, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkBindOpticalFlowSessionImageNV)(VkDevice device, VkOpticalFlowSessionNV session, VkOpticalFlowSessionBindingPointNV bindingPoint, VkImageView view, VkImageLayout layout);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdOpticalFlowExecuteNV)(VkCommandBuffer commandBuffer, VkOpticalFlowSessionNV session, const VkOpticalFlowExecuteInfoNV* pExecuteInfo);


 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceOpticalFlowImageFormatsNV(
    VkPhysicalDevice physicalDevice,
    const VkOpticalFlowImageFormatInfoNV* pOpticalFlowImageFormatInfo,
    uint32_t* pFormatCount,
    VkOpticalFlowImageFormatPropertiesNV* pImageFormatProperties);

 VkResult __attribute__((__stdcall__)) vkCreateOpticalFlowSessionNV(
    VkDevice device,
    const VkOpticalFlowSessionCreateInfoNV* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkOpticalFlowSessionNV* pSession);

 void __attribute__((__stdcall__)) vkDestroyOpticalFlowSessionNV(
    VkDevice device,
    VkOpticalFlowSessionNV session,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkBindOpticalFlowSessionImageNV(
    VkDevice device,
    VkOpticalFlowSessionNV session,
    VkOpticalFlowSessionBindingPointNV bindingPoint,
    VkImageView view,
    VkImageLayout layout);

 void __attribute__((__stdcall__)) vkCmdOpticalFlowExecuteNV(
    VkCommandBuffer commandBuffer,
    VkOpticalFlowSessionNV session,
    const VkOpticalFlowExecuteInfoNV* pExecuteInfo);







typedef struct VkPhysicalDeviceLegacyDitheringFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 legacyDithering;
} VkPhysicalDeviceLegacyDitheringFeaturesEXT;







typedef VkPhysicalDevicePipelineProtectedAccessFeatures VkPhysicalDevicePipelineProtectedAccessFeaturesEXT;
# 19582 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkAntiLagModeAMD {
    VK_ANTI_LAG_MODE_DRIVER_CONTROL_AMD = 0,
    VK_ANTI_LAG_MODE_ON_AMD = 1,
    VK_ANTI_LAG_MODE_OFF_AMD = 2,
    VK_ANTI_LAG_MODE_MAX_ENUM_AMD = 0x7FFFFFFF
} VkAntiLagModeAMD;

typedef enum VkAntiLagStageAMD {
    VK_ANTI_LAG_STAGE_INPUT_AMD = 0,
    VK_ANTI_LAG_STAGE_PRESENT_AMD = 1,
    VK_ANTI_LAG_STAGE_MAX_ENUM_AMD = 0x7FFFFFFF
} VkAntiLagStageAMD;
typedef struct VkPhysicalDeviceAntiLagFeaturesAMD {
    VkStructureType sType;
    void* pNext;
    VkBool32 antiLag;
} VkPhysicalDeviceAntiLagFeaturesAMD;

typedef struct VkAntiLagPresentationInfoAMD {
    VkStructureType sType;
    void* pNext;
    VkAntiLagStageAMD stage;
    uint64_t frameIndex;
} VkAntiLagPresentationInfoAMD;

typedef struct VkAntiLagDataAMD {
    VkStructureType sType;
    const void* pNext;
    VkAntiLagModeAMD mode;
    uint32_t maxFPS;
    const VkAntiLagPresentationInfoAMD* pPresentationInfo;
} VkAntiLagDataAMD;

typedef void (__attribute__((__stdcall__)) *PFN_vkAntiLagUpdateAMD)(VkDevice device, const VkAntiLagDataAMD* pData);


 void __attribute__((__stdcall__)) vkAntiLagUpdateAMD(
    VkDevice device,
    const VkAntiLagDataAMD* pData);





typedef struct VkShaderEXT_T *VkShaderEXT;



typedef enum VkShaderCodeTypeEXT {
    VK_SHADER_CODE_TYPE_BINARY_EXT = 0,
    VK_SHADER_CODE_TYPE_SPIRV_EXT = 1,
    VK_SHADER_CODE_TYPE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkShaderCodeTypeEXT;

typedef enum VkDepthClampModeEXT {
    VK_DEPTH_CLAMP_MODE_VIEWPORT_RANGE_EXT = 0,
    VK_DEPTH_CLAMP_MODE_USER_DEFINED_RANGE_EXT = 1,
    VK_DEPTH_CLAMP_MODE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkDepthClampModeEXT;

typedef enum VkShaderCreateFlagBitsEXT {
    VK_SHADER_CREATE_LINK_STAGE_BIT_EXT = 0x00000001,
    VK_SHADER_CREATE_ALLOW_VARYING_SUBGROUP_SIZE_BIT_EXT = 0x00000002,
    VK_SHADER_CREATE_REQUIRE_FULL_SUBGROUPS_BIT_EXT = 0x00000004,
    VK_SHADER_CREATE_NO_TASK_SHADER_BIT_EXT = 0x00000008,
    VK_SHADER_CREATE_DISPATCH_BASE_BIT_EXT = 0x00000010,
    VK_SHADER_CREATE_FRAGMENT_SHADING_RATE_ATTACHMENT_BIT_EXT = 0x00000020,
    VK_SHADER_CREATE_FRAGMENT_DENSITY_MAP_ATTACHMENT_BIT_EXT = 0x00000040,
    VK_SHADER_CREATE_INDIRECT_BINDABLE_BIT_EXT = 0x00000080,
    VK_SHADER_CREATE_FLAG_BITS_MAX_ENUM_EXT = 0x7FFFFFFF
} VkShaderCreateFlagBitsEXT;
typedef VkFlags VkShaderCreateFlagsEXT;
typedef struct VkPhysicalDeviceShaderObjectFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderObject;
} VkPhysicalDeviceShaderObjectFeaturesEXT;

typedef struct VkPhysicalDeviceShaderObjectPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    uint8_t shaderBinaryUUID[16U];
    uint32_t shaderBinaryVersion;
} VkPhysicalDeviceShaderObjectPropertiesEXT;

typedef struct VkShaderCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkShaderCreateFlagsEXT flags;
    VkShaderStageFlagBits stage;
    VkShaderStageFlags nextStage;
    VkShaderCodeTypeEXT codeType;
    size_t codeSize;
    const void* pCode;
    const char* pName;
    uint32_t setLayoutCount;
    const VkDescriptorSetLayout* pSetLayouts;
    uint32_t pushConstantRangeCount;
    const VkPushConstantRange* pPushConstantRanges;
    const VkSpecializationInfo* pSpecializationInfo;
} VkShaderCreateInfoEXT;

typedef VkPipelineShaderStageRequiredSubgroupSizeCreateInfo VkShaderRequiredSubgroupSizeCreateInfoEXT;

typedef struct VkDepthClampRangeEXT {
    float minDepthClamp;
    float maxDepthClamp;
} VkDepthClampRangeEXT;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateShadersEXT)(VkDevice device, uint32_t createInfoCount, const VkShaderCreateInfoEXT* pCreateInfos, const VkAllocationCallbacks* pAllocator, VkShaderEXT* pShaders);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyShaderEXT)(VkDevice device, VkShaderEXT shader, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetShaderBinaryDataEXT)(VkDevice device, VkShaderEXT shader, size_t* pDataSize, void* pData);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBindShadersEXT)(VkCommandBuffer commandBuffer, uint32_t stageCount, const VkShaderStageFlagBits* pStages, const VkShaderEXT* pShaders);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetDepthClampRangeEXT)(VkCommandBuffer commandBuffer, VkDepthClampModeEXT depthClampMode, const VkDepthClampRangeEXT* pDepthClampRange);


 VkResult __attribute__((__stdcall__)) vkCreateShadersEXT(
    VkDevice device,
    uint32_t createInfoCount,
    const VkShaderCreateInfoEXT* pCreateInfos,
    const VkAllocationCallbacks* pAllocator,
    VkShaderEXT* pShaders);

 void __attribute__((__stdcall__)) vkDestroyShaderEXT(
    VkDevice device,
    VkShaderEXT shader,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkGetShaderBinaryDataEXT(
    VkDevice device,
    VkShaderEXT shader,
    size_t* pDataSize,
    void* pData);

 void __attribute__((__stdcall__)) vkCmdBindShadersEXT(
    VkCommandBuffer commandBuffer,
    uint32_t stageCount,
    const VkShaderStageFlagBits* pStages,
    const VkShaderEXT* pShaders);

 void __attribute__((__stdcall__)) vkCmdSetDepthClampRangeEXT(
    VkCommandBuffer commandBuffer,
    VkDepthClampModeEXT depthClampMode,
    const VkDepthClampRangeEXT* pDepthClampRange);







typedef struct VkPhysicalDeviceTilePropertiesFeaturesQCOM {
    VkStructureType sType;
    void* pNext;
    VkBool32 tileProperties;
} VkPhysicalDeviceTilePropertiesFeaturesQCOM;

typedef struct VkTilePropertiesQCOM {
    VkStructureType sType;
    void* pNext;
    VkExtent3D tileSize;
    VkExtent2D apronSize;
    VkOffset2D origin;
} VkTilePropertiesQCOM;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetFramebufferTilePropertiesQCOM)(VkDevice device, VkFramebuffer framebuffer, uint32_t* pPropertiesCount, VkTilePropertiesQCOM* pProperties);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetDynamicRenderingTilePropertiesQCOM)(VkDevice device, const VkRenderingInfo* pRenderingInfo, VkTilePropertiesQCOM* pProperties);


 VkResult __attribute__((__stdcall__)) vkGetFramebufferTilePropertiesQCOM(
    VkDevice device,
    VkFramebuffer framebuffer,
    uint32_t* pPropertiesCount,
    VkTilePropertiesQCOM* pProperties);

 VkResult __attribute__((__stdcall__)) vkGetDynamicRenderingTilePropertiesQCOM(
    VkDevice device,
    const VkRenderingInfo* pRenderingInfo,
    VkTilePropertiesQCOM* pProperties);







typedef struct VkPhysicalDeviceAmigoProfilingFeaturesSEC {
    VkStructureType sType;
    void* pNext;
    VkBool32 amigoProfiling;
} VkPhysicalDeviceAmigoProfilingFeaturesSEC;

typedef struct VkAmigoProfilingSubmitInfoSEC {
    VkStructureType sType;
    const void* pNext;
    uint64_t firstDrawTimestamp;
    uint64_t swapBufferTimestamp;
} VkAmigoProfilingSubmitInfoSEC;







typedef struct VkPhysicalDeviceMultiviewPerViewViewportsFeaturesQCOM {
    VkStructureType sType;
    void* pNext;
    VkBool32 multiviewPerViewViewports;
} VkPhysicalDeviceMultiviewPerViewViewportsFeaturesQCOM;
# 19800 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkRayTracingInvocationReorderModeNV {
    VK_RAY_TRACING_INVOCATION_REORDER_MODE_NONE_NV = 0,
    VK_RAY_TRACING_INVOCATION_REORDER_MODE_REORDER_NV = 1,
    VK_RAY_TRACING_INVOCATION_REORDER_MODE_MAX_ENUM_NV = 0x7FFFFFFF
} VkRayTracingInvocationReorderModeNV;
typedef struct VkPhysicalDeviceRayTracingInvocationReorderPropertiesNV {
    VkStructureType sType;
    void* pNext;
    VkRayTracingInvocationReorderModeNV rayTracingInvocationReorderReorderingHint;
} VkPhysicalDeviceRayTracingInvocationReorderPropertiesNV;

typedef struct VkPhysicalDeviceRayTracingInvocationReorderFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 rayTracingInvocationReorder;
} VkPhysicalDeviceRayTracingInvocationReorderFeaturesNV;







typedef struct VkPhysicalDeviceExtendedSparseAddressSpaceFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 extendedSparseAddressSpace;
} VkPhysicalDeviceExtendedSparseAddressSpaceFeaturesNV;

typedef struct VkPhysicalDeviceExtendedSparseAddressSpacePropertiesNV {
    VkStructureType sType;
    void* pNext;
    VkDeviceSize extendedSparseAddressSpaceSize;
    VkImageUsageFlags extendedSparseImageUsageFlags;
    VkBufferUsageFlags extendedSparseBufferUsageFlags;
} VkPhysicalDeviceExtendedSparseAddressSpacePropertiesNV;
# 19849 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef struct VkPhysicalDeviceLegacyVertexAttributesFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 legacyVertexAttributes;
} VkPhysicalDeviceLegacyVertexAttributesFeaturesEXT;

typedef struct VkPhysicalDeviceLegacyVertexAttributesPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 nativeUnalignedPerformance;
} VkPhysicalDeviceLegacyVertexAttributesPropertiesEXT;
# 19868 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkLayerSettingTypeEXT {
    VK_LAYER_SETTING_TYPE_BOOL32_EXT = 0,
    VK_LAYER_SETTING_TYPE_INT32_EXT = 1,
    VK_LAYER_SETTING_TYPE_INT64_EXT = 2,
    VK_LAYER_SETTING_TYPE_UINT32_EXT = 3,
    VK_LAYER_SETTING_TYPE_UINT64_EXT = 4,
    VK_LAYER_SETTING_TYPE_FLOAT32_EXT = 5,
    VK_LAYER_SETTING_TYPE_FLOAT64_EXT = 6,
    VK_LAYER_SETTING_TYPE_STRING_EXT = 7,
    VK_LAYER_SETTING_TYPE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkLayerSettingTypeEXT;
typedef struct VkLayerSettingEXT {
    const char* pLayerName;
    const char* pSettingName;
    VkLayerSettingTypeEXT type;
    uint32_t valueCount;
    const void* pValues;
} VkLayerSettingEXT;

typedef struct VkLayerSettingsCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    uint32_t settingCount;
    const VkLayerSettingEXT* pSettings;
} VkLayerSettingsCreateInfoEXT;







typedef struct VkPhysicalDeviceShaderCoreBuiltinsFeaturesARM {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderCoreBuiltins;
} VkPhysicalDeviceShaderCoreBuiltinsFeaturesARM;

typedef struct VkPhysicalDeviceShaderCoreBuiltinsPropertiesARM {
    VkStructureType sType;
    void* pNext;
    uint64_t shaderCoreMask;
    uint32_t shaderCoreCount;
    uint32_t shaderWarpsPerCore;
} VkPhysicalDeviceShaderCoreBuiltinsPropertiesARM;







typedef struct VkPhysicalDevicePipelineLibraryGroupHandlesFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 pipelineLibraryGroupHandles;
} VkPhysicalDevicePipelineLibraryGroupHandlesFeaturesEXT;







typedef struct VkPhysicalDeviceDynamicRenderingUnusedAttachmentsFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 dynamicRenderingUnusedAttachments;
} VkPhysicalDeviceDynamicRenderingUnusedAttachmentsFeaturesEXT;
# 19945 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkLatencyMarkerNV {
    VK_LATENCY_MARKER_SIMULATION_START_NV = 0,
    VK_LATENCY_MARKER_SIMULATION_END_NV = 1,
    VK_LATENCY_MARKER_RENDERSUBMIT_START_NV = 2,
    VK_LATENCY_MARKER_RENDERSUBMIT_END_NV = 3,
    VK_LATENCY_MARKER_PRESENT_START_NV = 4,
    VK_LATENCY_MARKER_PRESENT_END_NV = 5,
    VK_LATENCY_MARKER_INPUT_SAMPLE_NV = 6,
    VK_LATENCY_MARKER_TRIGGER_FLASH_NV = 7,
    VK_LATENCY_MARKER_OUT_OF_BAND_RENDERSUBMIT_START_NV = 8,
    VK_LATENCY_MARKER_OUT_OF_BAND_RENDERSUBMIT_END_NV = 9,
    VK_LATENCY_MARKER_OUT_OF_BAND_PRESENT_START_NV = 10,
    VK_LATENCY_MARKER_OUT_OF_BAND_PRESENT_END_NV = 11,
    VK_LATENCY_MARKER_MAX_ENUM_NV = 0x7FFFFFFF
} VkLatencyMarkerNV;

typedef enum VkOutOfBandQueueTypeNV {
    VK_OUT_OF_BAND_QUEUE_TYPE_RENDER_NV = 0,
    VK_OUT_OF_BAND_QUEUE_TYPE_PRESENT_NV = 1,
    VK_OUT_OF_BAND_QUEUE_TYPE_MAX_ENUM_NV = 0x7FFFFFFF
} VkOutOfBandQueueTypeNV;
typedef struct VkLatencySleepModeInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkBool32 lowLatencyMode;
    VkBool32 lowLatencyBoost;
    uint32_t minimumIntervalUs;
} VkLatencySleepModeInfoNV;

typedef struct VkLatencySleepInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkSemaphore signalSemaphore;
    uint64_t value;
} VkLatencySleepInfoNV;

typedef struct VkSetLatencyMarkerInfoNV {
    VkStructureType sType;
    const void* pNext;
    uint64_t presentID;
    VkLatencyMarkerNV marker;
} VkSetLatencyMarkerInfoNV;

typedef struct VkLatencyTimingsFrameReportNV {
    VkStructureType sType;
    const void* pNext;
    uint64_t presentID;
    uint64_t inputSampleTimeUs;
    uint64_t simStartTimeUs;
    uint64_t simEndTimeUs;
    uint64_t renderSubmitStartTimeUs;
    uint64_t renderSubmitEndTimeUs;
    uint64_t presentStartTimeUs;
    uint64_t presentEndTimeUs;
    uint64_t driverStartTimeUs;
    uint64_t driverEndTimeUs;
    uint64_t osRenderQueueStartTimeUs;
    uint64_t osRenderQueueEndTimeUs;
    uint64_t gpuRenderStartTimeUs;
    uint64_t gpuRenderEndTimeUs;
} VkLatencyTimingsFrameReportNV;

typedef struct VkGetLatencyMarkerInfoNV {
    VkStructureType sType;
    const void* pNext;
    uint32_t timingCount;
    VkLatencyTimingsFrameReportNV* pTimings;
} VkGetLatencyMarkerInfoNV;

typedef struct VkLatencySubmissionPresentIdNV {
    VkStructureType sType;
    const void* pNext;
    uint64_t presentID;
} VkLatencySubmissionPresentIdNV;

typedef struct VkSwapchainLatencyCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkBool32 latencyModeEnable;
} VkSwapchainLatencyCreateInfoNV;

typedef struct VkOutOfBandQueueTypeInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkOutOfBandQueueTypeNV queueType;
} VkOutOfBandQueueTypeInfoNV;

typedef struct VkLatencySurfaceCapabilitiesNV {
    VkStructureType sType;
    const void* pNext;
    uint32_t presentModeCount;
    VkPresentModeKHR* pPresentModes;
} VkLatencySurfaceCapabilitiesNV;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkSetLatencySleepModeNV)(VkDevice device, VkSwapchainKHR swapchain, const VkLatencySleepModeInfoNV* pSleepModeInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkLatencySleepNV)(VkDevice device, VkSwapchainKHR swapchain, const VkLatencySleepInfoNV* pSleepInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkSetLatencyMarkerNV)(VkDevice device, VkSwapchainKHR swapchain, const VkSetLatencyMarkerInfoNV* pLatencyMarkerInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetLatencyTimingsNV)(VkDevice device, VkSwapchainKHR swapchain, VkGetLatencyMarkerInfoNV* pLatencyMarkerInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkQueueNotifyOutOfBandNV)(VkQueue queue, const VkOutOfBandQueueTypeInfoNV* pQueueTypeInfo);


 VkResult __attribute__((__stdcall__)) vkSetLatencySleepModeNV(
    VkDevice device,
    VkSwapchainKHR swapchain,
    const VkLatencySleepModeInfoNV* pSleepModeInfo);

 VkResult __attribute__((__stdcall__)) vkLatencySleepNV(
    VkDevice device,
    VkSwapchainKHR swapchain,
    const VkLatencySleepInfoNV* pSleepInfo);

 void __attribute__((__stdcall__)) vkSetLatencyMarkerNV(
    VkDevice device,
    VkSwapchainKHR swapchain,
    const VkSetLatencyMarkerInfoNV* pLatencyMarkerInfo);

 void __attribute__((__stdcall__)) vkGetLatencyTimingsNV(
    VkDevice device,
    VkSwapchainKHR swapchain,
    VkGetLatencyMarkerInfoNV* pLatencyMarkerInfo);

 void __attribute__((__stdcall__)) vkQueueNotifyOutOfBandNV(
    VkQueue queue,
    const VkOutOfBandQueueTypeInfoNV* pQueueTypeInfo);







typedef struct VkPhysicalDeviceMultiviewPerViewRenderAreasFeaturesQCOM {
    VkStructureType sType;
    void* pNext;
    VkBool32 multiviewPerViewRenderAreas;
} VkPhysicalDeviceMultiviewPerViewRenderAreasFeaturesQCOM;

typedef struct VkMultiviewPerViewRenderAreasRenderPassBeginInfoQCOM {
    VkStructureType sType;
    const void* pNext;
    uint32_t perViewRenderAreaCount;
    const VkRect2D* pPerViewRenderAreas;
} VkMultiviewPerViewRenderAreasRenderPassBeginInfoQCOM;







typedef struct VkPhysicalDevicePerStageDescriptorSetFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 perStageDescriptorSet;
    VkBool32 dynamicPipelineLayout;
} VkPhysicalDevicePerStageDescriptorSetFeaturesNV;
# 20109 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkBlockMatchWindowCompareModeQCOM {
    VK_BLOCK_MATCH_WINDOW_COMPARE_MODE_MIN_QCOM = 0,
    VK_BLOCK_MATCH_WINDOW_COMPARE_MODE_MAX_QCOM = 1,
    VK_BLOCK_MATCH_WINDOW_COMPARE_MODE_MAX_ENUM_QCOM = 0x7FFFFFFF
} VkBlockMatchWindowCompareModeQCOM;
typedef struct VkPhysicalDeviceImageProcessing2FeaturesQCOM {
    VkStructureType sType;
    void* pNext;
    VkBool32 textureBlockMatch2;
} VkPhysicalDeviceImageProcessing2FeaturesQCOM;

typedef struct VkPhysicalDeviceImageProcessing2PropertiesQCOM {
    VkStructureType sType;
    void* pNext;
    VkExtent2D maxBlockMatchWindow;
} VkPhysicalDeviceImageProcessing2PropertiesQCOM;

typedef struct VkSamplerBlockMatchWindowCreateInfoQCOM {
    VkStructureType sType;
    const void* pNext;
    VkExtent2D windowExtent;
    VkBlockMatchWindowCompareModeQCOM windowCompareMode;
} VkSamplerBlockMatchWindowCreateInfoQCOM;
# 20140 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkCubicFilterWeightsQCOM {
    VK_CUBIC_FILTER_WEIGHTS_CATMULL_ROM_QCOM = 0,
    VK_CUBIC_FILTER_WEIGHTS_ZERO_TANGENT_CARDINAL_QCOM = 1,
    VK_CUBIC_FILTER_WEIGHTS_B_SPLINE_QCOM = 2,
    VK_CUBIC_FILTER_WEIGHTS_MITCHELL_NETRAVALI_QCOM = 3,
    VK_CUBIC_FILTER_WEIGHTS_MAX_ENUM_QCOM = 0x7FFFFFFF
} VkCubicFilterWeightsQCOM;
typedef struct VkPhysicalDeviceCubicWeightsFeaturesQCOM {
    VkStructureType sType;
    void* pNext;
    VkBool32 selectableCubicWeights;
} VkPhysicalDeviceCubicWeightsFeaturesQCOM;

typedef struct VkSamplerCubicWeightsCreateInfoQCOM {
    VkStructureType sType;
    const void* pNext;
    VkCubicFilterWeightsQCOM cubicWeights;
} VkSamplerCubicWeightsCreateInfoQCOM;

typedef struct VkBlitImageCubicWeightsInfoQCOM {
    VkStructureType sType;
    const void* pNext;
    VkCubicFilterWeightsQCOM cubicWeights;
} VkBlitImageCubicWeightsInfoQCOM;







typedef struct VkPhysicalDeviceYcbcrDegammaFeaturesQCOM {
    VkStructureType sType;
    void* pNext;
    VkBool32 ycbcrDegamma;
} VkPhysicalDeviceYcbcrDegammaFeaturesQCOM;

typedef struct VkSamplerYcbcrConversionYcbcrDegammaCreateInfoQCOM {
    VkStructureType sType;
    void* pNext;
    VkBool32 enableYDegamma;
    VkBool32 enableCbCrDegamma;
} VkSamplerYcbcrConversionYcbcrDegammaCreateInfoQCOM;







typedef struct VkPhysicalDeviceCubicClampFeaturesQCOM {
    VkStructureType sType;
    void* pNext;
    VkBool32 cubicRangeClamp;
} VkPhysicalDeviceCubicClampFeaturesQCOM;







typedef struct VkPhysicalDeviceAttachmentFeedbackLoopDynamicStateFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 attachmentFeedbackLoopDynamicState;
} VkPhysicalDeviceAttachmentFeedbackLoopDynamicStateFeaturesEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetAttachmentFeedbackLoopEnableEXT)(VkCommandBuffer commandBuffer, VkImageAspectFlags aspectMask);


 void __attribute__((__stdcall__)) vkCmdSetAttachmentFeedbackLoopEnableEXT(
    VkCommandBuffer commandBuffer,
    VkImageAspectFlags aspectMask);
# 20222 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkLayeredDriverUnderlyingApiMSFT {
    VK_LAYERED_DRIVER_UNDERLYING_API_NONE_MSFT = 0,
    VK_LAYERED_DRIVER_UNDERLYING_API_D3D12_MSFT = 1,
    VK_LAYERED_DRIVER_UNDERLYING_API_MAX_ENUM_MSFT = 0x7FFFFFFF
} VkLayeredDriverUnderlyingApiMSFT;
typedef struct VkPhysicalDeviceLayeredDriverPropertiesMSFT {
    VkStructureType sType;
    void* pNext;
    VkLayeredDriverUnderlyingApiMSFT underlyingAPI;
} VkPhysicalDeviceLayeredDriverPropertiesMSFT;







typedef struct VkPhysicalDeviceDescriptorPoolOverallocationFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 descriptorPoolOverallocation;
} VkPhysicalDeviceDescriptorPoolOverallocationFeaturesNV;
# 20252 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkDisplaySurfaceStereoTypeNV {
    VK_DISPLAY_SURFACE_STEREO_TYPE_NONE_NV = 0,
    VK_DISPLAY_SURFACE_STEREO_TYPE_ONBOARD_DIN_NV = 1,
    VK_DISPLAY_SURFACE_STEREO_TYPE_HDMI_3D_NV = 2,
    VK_DISPLAY_SURFACE_STEREO_TYPE_INBAND_DISPLAYPORT_NV = 3,
    VK_DISPLAY_SURFACE_STEREO_TYPE_MAX_ENUM_NV = 0x7FFFFFFF
} VkDisplaySurfaceStereoTypeNV;
typedef struct VkDisplaySurfaceStereoCreateInfoNV {
    VkStructureType sType;
    const void* pNext;
    VkDisplaySurfaceStereoTypeNV stereoType;
} VkDisplaySurfaceStereoCreateInfoNV;

typedef struct VkDisplayModeStereoPropertiesNV {
    VkStructureType sType;
    const void* pNext;
    VkBool32 hdmi3DSupported;
} VkDisplayModeStereoPropertiesNV;







typedef struct VkPhysicalDeviceRawAccessChainsFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderRawAccessChains;
} VkPhysicalDeviceRawAccessChainsFeaturesNV;







typedef struct VkPhysicalDeviceCommandBufferInheritanceFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 commandBufferInheritance;
} VkPhysicalDeviceCommandBufferInheritanceFeaturesNV;







typedef struct VkPhysicalDeviceShaderAtomicFloat16VectorFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderFloat16VectorAtomics;
} VkPhysicalDeviceShaderAtomicFloat16VectorFeaturesNV;







typedef struct VkPhysicalDeviceShaderReplicatedCompositesFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 shaderReplicatedComposites;
} VkPhysicalDeviceShaderReplicatedCompositesFeaturesEXT;







typedef struct VkPhysicalDeviceRayTracingValidationFeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 rayTracingValidation;
} VkPhysicalDeviceRayTracingValidationFeaturesNV;





typedef struct VkIndirectExecutionSetEXT_T *VkIndirectExecutionSetEXT;
typedef struct VkIndirectCommandsLayoutEXT_T *VkIndirectCommandsLayoutEXT;



typedef enum VkIndirectExecutionSetInfoTypeEXT {
    VK_INDIRECT_EXECUTION_SET_INFO_TYPE_PIPELINES_EXT = 0,
    VK_INDIRECT_EXECUTION_SET_INFO_TYPE_SHADER_OBJECTS_EXT = 1,
    VK_INDIRECT_EXECUTION_SET_INFO_TYPE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkIndirectExecutionSetInfoTypeEXT;

typedef enum VkIndirectCommandsTokenTypeEXT {
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_EXECUTION_SET_EXT = 0,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_PUSH_CONSTANT_EXT = 1,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_SEQUENCE_INDEX_EXT = 2,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_INDEX_BUFFER_EXT = 3,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_VERTEX_BUFFER_EXT = 4,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_DRAW_INDEXED_EXT = 5,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_DRAW_EXT = 6,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_DRAW_INDEXED_COUNT_EXT = 7,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_DRAW_COUNT_EXT = 8,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_DISPATCH_EXT = 9,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_DRAW_MESH_TASKS_NV_EXT = 1000202002,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_DRAW_MESH_TASKS_COUNT_NV_EXT = 1000202003,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_DRAW_MESH_TASKS_EXT = 1000328000,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_DRAW_MESH_TASKS_COUNT_EXT = 1000328001,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_TRACE_RAYS2_EXT = 1000386004,
    VK_INDIRECT_COMMANDS_TOKEN_TYPE_MAX_ENUM_EXT = 0x7FFFFFFF
} VkIndirectCommandsTokenTypeEXT;

typedef enum VkIndirectCommandsInputModeFlagBitsEXT {
    VK_INDIRECT_COMMANDS_INPUT_MODE_VULKAN_INDEX_BUFFER_EXT = 0x00000001,
    VK_INDIRECT_COMMANDS_INPUT_MODE_DXGI_INDEX_BUFFER_EXT = 0x00000002,
    VK_INDIRECT_COMMANDS_INPUT_MODE_FLAG_BITS_MAX_ENUM_EXT = 0x7FFFFFFF
} VkIndirectCommandsInputModeFlagBitsEXT;
typedef VkFlags VkIndirectCommandsInputModeFlagsEXT;

typedef enum VkIndirectCommandsLayoutUsageFlagBitsEXT {
    VK_INDIRECT_COMMANDS_LAYOUT_USAGE_EXPLICIT_PREPROCESS_BIT_EXT = 0x00000001,
    VK_INDIRECT_COMMANDS_LAYOUT_USAGE_UNORDERED_SEQUENCES_BIT_EXT = 0x00000002,
    VK_INDIRECT_COMMANDS_LAYOUT_USAGE_FLAG_BITS_MAX_ENUM_EXT = 0x7FFFFFFF
} VkIndirectCommandsLayoutUsageFlagBitsEXT;
typedef VkFlags VkIndirectCommandsLayoutUsageFlagsEXT;
typedef struct VkPhysicalDeviceDeviceGeneratedCommandsFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 deviceGeneratedCommands;
    VkBool32 dynamicGeneratedPipelineLayout;
} VkPhysicalDeviceDeviceGeneratedCommandsFeaturesEXT;

typedef struct VkPhysicalDeviceDeviceGeneratedCommandsPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    uint32_t maxIndirectPipelineCount;
    uint32_t maxIndirectShaderObjectCount;
    uint32_t maxIndirectSequenceCount;
    uint32_t maxIndirectCommandsTokenCount;
    uint32_t maxIndirectCommandsTokenOffset;
    uint32_t maxIndirectCommandsIndirectStride;
    VkIndirectCommandsInputModeFlagsEXT supportedIndirectCommandsInputModes;
    VkShaderStageFlags supportedIndirectCommandsShaderStages;
    VkShaderStageFlags supportedIndirectCommandsShaderStagesPipelineBinding;
    VkShaderStageFlags supportedIndirectCommandsShaderStagesShaderBinding;
    VkBool32 deviceGeneratedCommandsTransformFeedback;
    VkBool32 deviceGeneratedCommandsMultiDrawIndirectCount;
} VkPhysicalDeviceDeviceGeneratedCommandsPropertiesEXT;

typedef struct VkGeneratedCommandsMemoryRequirementsInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkIndirectExecutionSetEXT indirectExecutionSet;
    VkIndirectCommandsLayoutEXT indirectCommandsLayout;
    uint32_t maxSequenceCount;
    uint32_t maxDrawCount;
} VkGeneratedCommandsMemoryRequirementsInfoEXT;

typedef struct VkIndirectExecutionSetPipelineInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkPipeline initialPipeline;
    uint32_t maxPipelineCount;
} VkIndirectExecutionSetPipelineInfoEXT;

typedef struct VkIndirectExecutionSetShaderLayoutInfoEXT {
    VkStructureType sType;
    const void* pNext;
    uint32_t setLayoutCount;
    const VkDescriptorSetLayout* pSetLayouts;
} VkIndirectExecutionSetShaderLayoutInfoEXT;

typedef struct VkIndirectExecutionSetShaderInfoEXT {
    VkStructureType sType;
    const void* pNext;
    uint32_t shaderCount;
    const VkShaderEXT* pInitialShaders;
    const VkIndirectExecutionSetShaderLayoutInfoEXT* pSetLayoutInfos;
    uint32_t maxShaderCount;
    uint32_t pushConstantRangeCount;
    const VkPushConstantRange* pPushConstantRanges;
} VkIndirectExecutionSetShaderInfoEXT;

typedef union VkIndirectExecutionSetInfoEXT {
    const VkIndirectExecutionSetPipelineInfoEXT* pPipelineInfo;
    const VkIndirectExecutionSetShaderInfoEXT* pShaderInfo;
} VkIndirectExecutionSetInfoEXT;

typedef struct VkIndirectExecutionSetCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkIndirectExecutionSetInfoTypeEXT type;
    VkIndirectExecutionSetInfoEXT info;
} VkIndirectExecutionSetCreateInfoEXT;

typedef struct VkGeneratedCommandsInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkShaderStageFlags shaderStages;
    VkIndirectExecutionSetEXT indirectExecutionSet;
    VkIndirectCommandsLayoutEXT indirectCommandsLayout;
    VkDeviceAddress indirectAddress;
    VkDeviceSize indirectAddressSize;
    VkDeviceAddress preprocessAddress;
    VkDeviceSize preprocessSize;
    uint32_t maxSequenceCount;
    VkDeviceAddress sequenceCountAddress;
    uint32_t maxDrawCount;
} VkGeneratedCommandsInfoEXT;

typedef struct VkWriteIndirectExecutionSetPipelineEXT {
    VkStructureType sType;
    const void* pNext;
    uint32_t index;
    VkPipeline pipeline;
} VkWriteIndirectExecutionSetPipelineEXT;

typedef struct VkIndirectCommandsPushConstantTokenEXT {
    VkPushConstantRange updateRange;
} VkIndirectCommandsPushConstantTokenEXT;

typedef struct VkIndirectCommandsVertexBufferTokenEXT {
    uint32_t vertexBindingUnit;
} VkIndirectCommandsVertexBufferTokenEXT;

typedef struct VkIndirectCommandsIndexBufferTokenEXT {
    VkIndirectCommandsInputModeFlagBitsEXT mode;
} VkIndirectCommandsIndexBufferTokenEXT;

typedef struct VkIndirectCommandsExecutionSetTokenEXT {
    VkIndirectExecutionSetInfoTypeEXT type;
    VkShaderStageFlags shaderStages;
} VkIndirectCommandsExecutionSetTokenEXT;

typedef union VkIndirectCommandsTokenDataEXT {
    const VkIndirectCommandsPushConstantTokenEXT* pPushConstant;
    const VkIndirectCommandsVertexBufferTokenEXT* pVertexBuffer;
    const VkIndirectCommandsIndexBufferTokenEXT* pIndexBuffer;
    const VkIndirectCommandsExecutionSetTokenEXT* pExecutionSet;
} VkIndirectCommandsTokenDataEXT;

typedef struct VkIndirectCommandsLayoutTokenEXT {
    VkStructureType sType;
    const void* pNext;
    VkIndirectCommandsTokenTypeEXT type;
    VkIndirectCommandsTokenDataEXT data;
    uint32_t offset;
} VkIndirectCommandsLayoutTokenEXT;

typedef struct VkIndirectCommandsLayoutCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkIndirectCommandsLayoutUsageFlagsEXT flags;
    VkShaderStageFlags shaderStages;
    uint32_t indirectStride;
    VkPipelineLayout pipelineLayout;
    uint32_t tokenCount;
    const VkIndirectCommandsLayoutTokenEXT* pTokens;
} VkIndirectCommandsLayoutCreateInfoEXT;

typedef struct VkDrawIndirectCountIndirectCommandEXT {
    VkDeviceAddress bufferAddress;
    uint32_t stride;
    uint32_t commandCount;
} VkDrawIndirectCountIndirectCommandEXT;

typedef struct VkBindVertexBufferIndirectCommandEXT {
    VkDeviceAddress bufferAddress;
    uint32_t size;
    uint32_t stride;
} VkBindVertexBufferIndirectCommandEXT;

typedef struct VkBindIndexBufferIndirectCommandEXT {
    VkDeviceAddress bufferAddress;
    uint32_t size;
    VkIndexType indexType;
} VkBindIndexBufferIndirectCommandEXT;

typedef struct VkGeneratedCommandsPipelineInfoEXT {
    VkStructureType sType;
    void* pNext;
    VkPipeline pipeline;
} VkGeneratedCommandsPipelineInfoEXT;

typedef struct VkGeneratedCommandsShaderInfoEXT {
    VkStructureType sType;
    void* pNext;
    uint32_t shaderCount;
    const VkShaderEXT* pShaders;
} VkGeneratedCommandsShaderInfoEXT;

typedef struct VkWriteIndirectExecutionSetShaderEXT {
    VkStructureType sType;
    const void* pNext;
    uint32_t index;
    VkShaderEXT shader;
} VkWriteIndirectExecutionSetShaderEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkGetGeneratedCommandsMemoryRequirementsEXT)(VkDevice device, const VkGeneratedCommandsMemoryRequirementsInfoEXT* pInfo, VkMemoryRequirements2* pMemoryRequirements);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdPreprocessGeneratedCommandsEXT)(VkCommandBuffer commandBuffer, const VkGeneratedCommandsInfoEXT* pGeneratedCommandsInfo, VkCommandBuffer stateCommandBuffer);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdExecuteGeneratedCommandsEXT)(VkCommandBuffer commandBuffer, VkBool32 isPreprocessed, const VkGeneratedCommandsInfoEXT* pGeneratedCommandsInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateIndirectCommandsLayoutEXT)(VkDevice device, const VkIndirectCommandsLayoutCreateInfoEXT* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkIndirectCommandsLayoutEXT* pIndirectCommandsLayout);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyIndirectCommandsLayoutEXT)(VkDevice device, VkIndirectCommandsLayoutEXT indirectCommandsLayout, const VkAllocationCallbacks* pAllocator);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateIndirectExecutionSetEXT)(VkDevice device, const VkIndirectExecutionSetCreateInfoEXT* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkIndirectExecutionSetEXT* pIndirectExecutionSet);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyIndirectExecutionSetEXT)(VkDevice device, VkIndirectExecutionSetEXT indirectExecutionSet, const VkAllocationCallbacks* pAllocator);
typedef void (__attribute__((__stdcall__)) *PFN_vkUpdateIndirectExecutionSetPipelineEXT)(VkDevice device, VkIndirectExecutionSetEXT indirectExecutionSet, uint32_t executionSetWriteCount, const VkWriteIndirectExecutionSetPipelineEXT* pExecutionSetWrites);
typedef void (__attribute__((__stdcall__)) *PFN_vkUpdateIndirectExecutionSetShaderEXT)(VkDevice device, VkIndirectExecutionSetEXT indirectExecutionSet, uint32_t executionSetWriteCount, const VkWriteIndirectExecutionSetShaderEXT* pExecutionSetWrites);


 void __attribute__((__stdcall__)) vkGetGeneratedCommandsMemoryRequirementsEXT(
    VkDevice device,
    const VkGeneratedCommandsMemoryRequirementsInfoEXT* pInfo,
    VkMemoryRequirements2* pMemoryRequirements);

 void __attribute__((__stdcall__)) vkCmdPreprocessGeneratedCommandsEXT(
    VkCommandBuffer commandBuffer,
    const VkGeneratedCommandsInfoEXT* pGeneratedCommandsInfo,
    VkCommandBuffer stateCommandBuffer);

 void __attribute__((__stdcall__)) vkCmdExecuteGeneratedCommandsEXT(
    VkCommandBuffer commandBuffer,
    VkBool32 isPreprocessed,
    const VkGeneratedCommandsInfoEXT* pGeneratedCommandsInfo);

 VkResult __attribute__((__stdcall__)) vkCreateIndirectCommandsLayoutEXT(
    VkDevice device,
    const VkIndirectCommandsLayoutCreateInfoEXT* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkIndirectCommandsLayoutEXT* pIndirectCommandsLayout);

 void __attribute__((__stdcall__)) vkDestroyIndirectCommandsLayoutEXT(
    VkDevice device,
    VkIndirectCommandsLayoutEXT indirectCommandsLayout,
    const VkAllocationCallbacks* pAllocator);

 VkResult __attribute__((__stdcall__)) vkCreateIndirectExecutionSetEXT(
    VkDevice device,
    const VkIndirectExecutionSetCreateInfoEXT* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkIndirectExecutionSetEXT* pIndirectExecutionSet);

 void __attribute__((__stdcall__)) vkDestroyIndirectExecutionSetEXT(
    VkDevice device,
    VkIndirectExecutionSetEXT indirectExecutionSet,
    const VkAllocationCallbacks* pAllocator);

 void __attribute__((__stdcall__)) vkUpdateIndirectExecutionSetPipelineEXT(
    VkDevice device,
    VkIndirectExecutionSetEXT indirectExecutionSet,
    uint32_t executionSetWriteCount,
    const VkWriteIndirectExecutionSetPipelineEXT* pExecutionSetWrites);

 void __attribute__((__stdcall__)) vkUpdateIndirectExecutionSetShaderEXT(
    VkDevice device,
    VkIndirectExecutionSetEXT indirectExecutionSet,
    uint32_t executionSetWriteCount,
    const VkWriteIndirectExecutionSetShaderEXT* pExecutionSetWrites);







typedef struct VkPhysicalDeviceImageAlignmentControlFeaturesMESA {
    VkStructureType sType;
    void* pNext;
    VkBool32 imageAlignmentControl;
} VkPhysicalDeviceImageAlignmentControlFeaturesMESA;

typedef struct VkPhysicalDeviceImageAlignmentControlPropertiesMESA {
    VkStructureType sType;
    void* pNext;
    uint32_t supportedImageAlignmentMask;
} VkPhysicalDeviceImageAlignmentControlPropertiesMESA;

typedef struct VkImageAlignmentControlCreateInfoMESA {
    VkStructureType sType;
    const void* pNext;
    uint32_t maximumRequestedAlignment;
} VkImageAlignmentControlCreateInfoMESA;







typedef struct VkPhysicalDeviceDepthClampControlFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 depthClampControl;
} VkPhysicalDeviceDepthClampControlFeaturesEXT;

typedef struct VkPipelineViewportDepthClampControlCreateInfoEXT {
    VkStructureType sType;
    const void* pNext;
    VkDepthClampModeEXT depthClampMode;
    const VkDepthClampRangeEXT* pDepthClampRange;
} VkPipelineViewportDepthClampControlCreateInfoEXT;







typedef struct VkPhysicalDeviceHdrVividFeaturesHUAWEI {
    VkStructureType sType;
    void* pNext;
    VkBool32 hdrVivid;
} VkPhysicalDeviceHdrVividFeaturesHUAWEI;

typedef struct VkHdrVividDynamicMetadataHUAWEI {
    VkStructureType sType;
    const void* pNext;
    size_t dynamicMetadataSize;
    const void* pDynamicMetadata;
} VkHdrVividDynamicMetadataHUAWEI;







typedef struct VkCooperativeMatrixFlexibleDimensionsPropertiesNV {
    VkStructureType sType;
    void* pNext;
    uint32_t MGranularity;
    uint32_t NGranularity;
    uint32_t KGranularity;
    VkComponentTypeKHR AType;
    VkComponentTypeKHR BType;
    VkComponentTypeKHR CType;
    VkComponentTypeKHR ResultType;
    VkBool32 saturatingAccumulation;
    VkScopeKHR scope;
    uint32_t workgroupInvocations;
} VkCooperativeMatrixFlexibleDimensionsPropertiesNV;

typedef struct VkPhysicalDeviceCooperativeMatrix2FeaturesNV {
    VkStructureType sType;
    void* pNext;
    VkBool32 cooperativeMatrixWorkgroupScope;
    VkBool32 cooperativeMatrixFlexibleDimensions;
    VkBool32 cooperativeMatrixReductions;
    VkBool32 cooperativeMatrixConversions;
    VkBool32 cooperativeMatrixPerElementOperations;
    VkBool32 cooperativeMatrixTensorAddressing;
    VkBool32 cooperativeMatrixBlockLoads;
} VkPhysicalDeviceCooperativeMatrix2FeaturesNV;

typedef struct VkPhysicalDeviceCooperativeMatrix2PropertiesNV {
    VkStructureType sType;
    void* pNext;
    uint32_t cooperativeMatrixWorkgroupScopeMaxWorkgroupSize;
    uint32_t cooperativeMatrixFlexibleDimensionsMaxDimension;
    uint32_t cooperativeMatrixWorkgroupScopeReservedSharedMemory;
} VkPhysicalDeviceCooperativeMatrix2PropertiesNV;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetPhysicalDeviceCooperativeMatrixFlexibleDimensionsPropertiesNV)(VkPhysicalDevice physicalDevice, uint32_t* pPropertyCount, VkCooperativeMatrixFlexibleDimensionsPropertiesNV* pProperties);


 VkResult __attribute__((__stdcall__)) vkGetPhysicalDeviceCooperativeMatrixFlexibleDimensionsPropertiesNV(
    VkPhysicalDevice physicalDevice,
    uint32_t* pPropertyCount,
    VkCooperativeMatrixFlexibleDimensionsPropertiesNV* pProperties);







typedef struct VkPhysicalDeviceVertexAttributeRobustnessFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 vertexAttributeRobustness;
} VkPhysicalDeviceVertexAttributeRobustnessFeaturesEXT;
# 20741 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkBuildAccelerationStructureModeKHR {
    VK_BUILD_ACCELERATION_STRUCTURE_MODE_BUILD_KHR = 0,
    VK_BUILD_ACCELERATION_STRUCTURE_MODE_UPDATE_KHR = 1,
    VK_BUILD_ACCELERATION_STRUCTURE_MODE_MAX_ENUM_KHR = 0x7FFFFFFF
} VkBuildAccelerationStructureModeKHR;

typedef enum VkAccelerationStructureCreateFlagBitsKHR {
    VK_ACCELERATION_STRUCTURE_CREATE_DEVICE_ADDRESS_CAPTURE_REPLAY_BIT_KHR = 0x00000001,
    VK_ACCELERATION_STRUCTURE_CREATE_DESCRIPTOR_BUFFER_CAPTURE_REPLAY_BIT_EXT = 0x00000008,
    VK_ACCELERATION_STRUCTURE_CREATE_MOTION_BIT_NV = 0x00000004,
    VK_ACCELERATION_STRUCTURE_CREATE_FLAG_BITS_MAX_ENUM_KHR = 0x7FFFFFFF
} VkAccelerationStructureCreateFlagBitsKHR;
typedef VkFlags VkAccelerationStructureCreateFlagsKHR;
typedef struct VkAccelerationStructureBuildRangeInfoKHR {
    uint32_t primitiveCount;
    uint32_t primitiveOffset;
    uint32_t firstVertex;
    uint32_t transformOffset;
} VkAccelerationStructureBuildRangeInfoKHR;

typedef struct VkAccelerationStructureGeometryTrianglesDataKHR {
    VkStructureType sType;
    const void* pNext;
    VkFormat vertexFormat;
    VkDeviceOrHostAddressConstKHR vertexData;
    VkDeviceSize vertexStride;
    uint32_t maxVertex;
    VkIndexType indexType;
    VkDeviceOrHostAddressConstKHR indexData;
    VkDeviceOrHostAddressConstKHR transformData;
} VkAccelerationStructureGeometryTrianglesDataKHR;

typedef struct VkAccelerationStructureGeometryAabbsDataKHR {
    VkStructureType sType;
    const void* pNext;
    VkDeviceOrHostAddressConstKHR data;
    VkDeviceSize stride;
} VkAccelerationStructureGeometryAabbsDataKHR;

typedef struct VkAccelerationStructureGeometryInstancesDataKHR {
    VkStructureType sType;
    const void* pNext;
    VkBool32 arrayOfPointers;
    VkDeviceOrHostAddressConstKHR data;
} VkAccelerationStructureGeometryInstancesDataKHR;

typedef union VkAccelerationStructureGeometryDataKHR {
    VkAccelerationStructureGeometryTrianglesDataKHR triangles;
    VkAccelerationStructureGeometryAabbsDataKHR aabbs;
    VkAccelerationStructureGeometryInstancesDataKHR instances;
} VkAccelerationStructureGeometryDataKHR;

typedef struct VkAccelerationStructureGeometryKHR {
    VkStructureType sType;
    const void* pNext;
    VkGeometryTypeKHR geometryType;
    VkAccelerationStructureGeometryDataKHR geometry;
    VkGeometryFlagsKHR flags;
} VkAccelerationStructureGeometryKHR;

typedef struct VkAccelerationStructureBuildGeometryInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkAccelerationStructureTypeKHR type;
    VkBuildAccelerationStructureFlagsKHR flags;
    VkBuildAccelerationStructureModeKHR mode;
    VkAccelerationStructureKHR srcAccelerationStructure;
    VkAccelerationStructureKHR dstAccelerationStructure;
    uint32_t geometryCount;
    const VkAccelerationStructureGeometryKHR* pGeometries;
    const VkAccelerationStructureGeometryKHR* const* ppGeometries;
    VkDeviceOrHostAddressKHR scratchData;
} VkAccelerationStructureBuildGeometryInfoKHR;

typedef struct VkAccelerationStructureCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkAccelerationStructureCreateFlagsKHR createFlags;
    VkBuffer buffer;
    VkDeviceSize offset;
    VkDeviceSize size;
    VkAccelerationStructureTypeKHR type;
    VkDeviceAddress deviceAddress;
} VkAccelerationStructureCreateInfoKHR;

typedef struct VkWriteDescriptorSetAccelerationStructureKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t accelerationStructureCount;
    const VkAccelerationStructureKHR* pAccelerationStructures;
} VkWriteDescriptorSetAccelerationStructureKHR;

typedef struct VkPhysicalDeviceAccelerationStructureFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 accelerationStructure;
    VkBool32 accelerationStructureCaptureReplay;
    VkBool32 accelerationStructureIndirectBuild;
    VkBool32 accelerationStructureHostCommands;
    VkBool32 descriptorBindingAccelerationStructureUpdateAfterBind;
} VkPhysicalDeviceAccelerationStructureFeaturesKHR;

typedef struct VkPhysicalDeviceAccelerationStructurePropertiesKHR {
    VkStructureType sType;
    void* pNext;
    uint64_t maxGeometryCount;
    uint64_t maxInstanceCount;
    uint64_t maxPrimitiveCount;
    uint32_t maxPerStageDescriptorAccelerationStructures;
    uint32_t maxPerStageDescriptorUpdateAfterBindAccelerationStructures;
    uint32_t maxDescriptorSetAccelerationStructures;
    uint32_t maxDescriptorSetUpdateAfterBindAccelerationStructures;
    uint32_t minAccelerationStructureScratchOffsetAlignment;
} VkPhysicalDeviceAccelerationStructurePropertiesKHR;

typedef struct VkAccelerationStructureDeviceAddressInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkAccelerationStructureKHR accelerationStructure;
} VkAccelerationStructureDeviceAddressInfoKHR;

typedef struct VkAccelerationStructureVersionInfoKHR {
    VkStructureType sType;
    const void* pNext;
    const uint8_t* pVersionData;
} VkAccelerationStructureVersionInfoKHR;

typedef struct VkCopyAccelerationStructureToMemoryInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkAccelerationStructureKHR src;
    VkDeviceOrHostAddressKHR dst;
    VkCopyAccelerationStructureModeKHR mode;
} VkCopyAccelerationStructureToMemoryInfoKHR;

typedef struct VkCopyMemoryToAccelerationStructureInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkDeviceOrHostAddressConstKHR src;
    VkAccelerationStructureKHR dst;
    VkCopyAccelerationStructureModeKHR mode;
} VkCopyMemoryToAccelerationStructureInfoKHR;

typedef struct VkCopyAccelerationStructureInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkAccelerationStructureKHR src;
    VkAccelerationStructureKHR dst;
    VkCopyAccelerationStructureModeKHR mode;
} VkCopyAccelerationStructureInfoKHR;

typedef struct VkAccelerationStructureBuildSizesInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkDeviceSize accelerationStructureSize;
    VkDeviceSize updateScratchSize;
    VkDeviceSize buildScratchSize;
} VkAccelerationStructureBuildSizesInfoKHR;

typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateAccelerationStructureKHR)(VkDevice device, const VkAccelerationStructureCreateInfoKHR* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkAccelerationStructureKHR* pAccelerationStructure);
typedef void (__attribute__((__stdcall__)) *PFN_vkDestroyAccelerationStructureKHR)(VkDevice device, VkAccelerationStructureKHR accelerationStructure, const VkAllocationCallbacks* pAllocator);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBuildAccelerationStructuresKHR)(VkCommandBuffer commandBuffer, uint32_t infoCount, const VkAccelerationStructureBuildGeometryInfoKHR* pInfos, const VkAccelerationStructureBuildRangeInfoKHR* const* ppBuildRangeInfos);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdBuildAccelerationStructuresIndirectKHR)(VkCommandBuffer commandBuffer, uint32_t infoCount, const VkAccelerationStructureBuildGeometryInfoKHR* pInfos, const VkDeviceAddress* pIndirectDeviceAddresses, const uint32_t* pIndirectStrides, const uint32_t* const* ppMaxPrimitiveCounts);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkBuildAccelerationStructuresKHR)(VkDevice device, VkDeferredOperationKHR deferredOperation, uint32_t infoCount, const VkAccelerationStructureBuildGeometryInfoKHR* pInfos, const VkAccelerationStructureBuildRangeInfoKHR* const* ppBuildRangeInfos);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCopyAccelerationStructureKHR)(VkDevice device, VkDeferredOperationKHR deferredOperation, const VkCopyAccelerationStructureInfoKHR* pInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCopyAccelerationStructureToMemoryKHR)(VkDevice device, VkDeferredOperationKHR deferredOperation, const VkCopyAccelerationStructureToMemoryInfoKHR* pInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCopyMemoryToAccelerationStructureKHR)(VkDevice device, VkDeferredOperationKHR deferredOperation, const VkCopyMemoryToAccelerationStructureInfoKHR* pInfo);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkWriteAccelerationStructuresPropertiesKHR)(VkDevice device, uint32_t accelerationStructureCount, const VkAccelerationStructureKHR* pAccelerationStructures, VkQueryType queryType, size_t dataSize, void* pData, size_t stride);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyAccelerationStructureKHR)(VkCommandBuffer commandBuffer, const VkCopyAccelerationStructureInfoKHR* pInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyAccelerationStructureToMemoryKHR)(VkCommandBuffer commandBuffer, const VkCopyAccelerationStructureToMemoryInfoKHR* pInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdCopyMemoryToAccelerationStructureKHR)(VkCommandBuffer commandBuffer, const VkCopyMemoryToAccelerationStructureInfoKHR* pInfo);
typedef VkDeviceAddress (__attribute__((__stdcall__)) *PFN_vkGetAccelerationStructureDeviceAddressKHR)(VkDevice device, const VkAccelerationStructureDeviceAddressInfoKHR* pInfo);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdWriteAccelerationStructuresPropertiesKHR)(VkCommandBuffer commandBuffer, uint32_t accelerationStructureCount, const VkAccelerationStructureKHR* pAccelerationStructures, VkQueryType queryType, VkQueryPool queryPool, uint32_t firstQuery);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetDeviceAccelerationStructureCompatibilityKHR)(VkDevice device, const VkAccelerationStructureVersionInfoKHR* pVersionInfo, VkAccelerationStructureCompatibilityKHR* pCompatibility);
typedef void (__attribute__((__stdcall__)) *PFN_vkGetAccelerationStructureBuildSizesKHR)(VkDevice device, VkAccelerationStructureBuildTypeKHR buildType, const VkAccelerationStructureBuildGeometryInfoKHR* pBuildInfo, const uint32_t* pMaxPrimitiveCounts, VkAccelerationStructureBuildSizesInfoKHR* pSizeInfo);


 VkResult __attribute__((__stdcall__)) vkCreateAccelerationStructureKHR(
    VkDevice device,
    const VkAccelerationStructureCreateInfoKHR* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkAccelerationStructureKHR* pAccelerationStructure);

 void __attribute__((__stdcall__)) vkDestroyAccelerationStructureKHR(
    VkDevice device,
    VkAccelerationStructureKHR accelerationStructure,
    const VkAllocationCallbacks* pAllocator);

 void __attribute__((__stdcall__)) vkCmdBuildAccelerationStructuresKHR(
    VkCommandBuffer commandBuffer,
    uint32_t infoCount,
    const VkAccelerationStructureBuildGeometryInfoKHR* pInfos,
    const VkAccelerationStructureBuildRangeInfoKHR* const* ppBuildRangeInfos);

 void __attribute__((__stdcall__)) vkCmdBuildAccelerationStructuresIndirectKHR(
    VkCommandBuffer commandBuffer,
    uint32_t infoCount,
    const VkAccelerationStructureBuildGeometryInfoKHR* pInfos,
    const VkDeviceAddress* pIndirectDeviceAddresses,
    const uint32_t* pIndirectStrides,
    const uint32_t* const* ppMaxPrimitiveCounts);

 VkResult __attribute__((__stdcall__)) vkBuildAccelerationStructuresKHR(
    VkDevice device,
    VkDeferredOperationKHR deferredOperation,
    uint32_t infoCount,
    const VkAccelerationStructureBuildGeometryInfoKHR* pInfos,
    const VkAccelerationStructureBuildRangeInfoKHR* const* ppBuildRangeInfos);

 VkResult __attribute__((__stdcall__)) vkCopyAccelerationStructureKHR(
    VkDevice device,
    VkDeferredOperationKHR deferredOperation,
    const VkCopyAccelerationStructureInfoKHR* pInfo);

 VkResult __attribute__((__stdcall__)) vkCopyAccelerationStructureToMemoryKHR(
    VkDevice device,
    VkDeferredOperationKHR deferredOperation,
    const VkCopyAccelerationStructureToMemoryInfoKHR* pInfo);

 VkResult __attribute__((__stdcall__)) vkCopyMemoryToAccelerationStructureKHR(
    VkDevice device,
    VkDeferredOperationKHR deferredOperation,
    const VkCopyMemoryToAccelerationStructureInfoKHR* pInfo);

 VkResult __attribute__((__stdcall__)) vkWriteAccelerationStructuresPropertiesKHR(
    VkDevice device,
    uint32_t accelerationStructureCount,
    const VkAccelerationStructureKHR* pAccelerationStructures,
    VkQueryType queryType,
    size_t dataSize,
    void* pData,
    size_t stride);

 void __attribute__((__stdcall__)) vkCmdCopyAccelerationStructureKHR(
    VkCommandBuffer commandBuffer,
    const VkCopyAccelerationStructureInfoKHR* pInfo);

 void __attribute__((__stdcall__)) vkCmdCopyAccelerationStructureToMemoryKHR(
    VkCommandBuffer commandBuffer,
    const VkCopyAccelerationStructureToMemoryInfoKHR* pInfo);

 void __attribute__((__stdcall__)) vkCmdCopyMemoryToAccelerationStructureKHR(
    VkCommandBuffer commandBuffer,
    const VkCopyMemoryToAccelerationStructureInfoKHR* pInfo);

 VkDeviceAddress __attribute__((__stdcall__)) vkGetAccelerationStructureDeviceAddressKHR(
    VkDevice device,
    const VkAccelerationStructureDeviceAddressInfoKHR* pInfo);

 void __attribute__((__stdcall__)) vkCmdWriteAccelerationStructuresPropertiesKHR(
    VkCommandBuffer commandBuffer,
    uint32_t accelerationStructureCount,
    const VkAccelerationStructureKHR* pAccelerationStructures,
    VkQueryType queryType,
    VkQueryPool queryPool,
    uint32_t firstQuery);

 void __attribute__((__stdcall__)) vkGetDeviceAccelerationStructureCompatibilityKHR(
    VkDevice device,
    const VkAccelerationStructureVersionInfoKHR* pVersionInfo,
    VkAccelerationStructureCompatibilityKHR* pCompatibility);

 void __attribute__((__stdcall__)) vkGetAccelerationStructureBuildSizesKHR(
    VkDevice device,
    VkAccelerationStructureBuildTypeKHR buildType,
    const VkAccelerationStructureBuildGeometryInfoKHR* pBuildInfo,
    const uint32_t* pMaxPrimitiveCounts,
    VkAccelerationStructureBuildSizesInfoKHR* pSizeInfo);
# 21017 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan_core.h" 3 4
typedef enum VkShaderGroupShaderKHR {
    VK_SHADER_GROUP_SHADER_GENERAL_KHR = 0,
    VK_SHADER_GROUP_SHADER_CLOSEST_HIT_KHR = 1,
    VK_SHADER_GROUP_SHADER_ANY_HIT_KHR = 2,
    VK_SHADER_GROUP_SHADER_INTERSECTION_KHR = 3,
    VK_SHADER_GROUP_SHADER_MAX_ENUM_KHR = 0x7FFFFFFF
} VkShaderGroupShaderKHR;
typedef struct VkRayTracingShaderGroupCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkRayTracingShaderGroupTypeKHR type;
    uint32_t generalShader;
    uint32_t closestHitShader;
    uint32_t anyHitShader;
    uint32_t intersectionShader;
    const void* pShaderGroupCaptureReplayHandle;
} VkRayTracingShaderGroupCreateInfoKHR;

typedef struct VkRayTracingPipelineInterfaceCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    uint32_t maxPipelineRayPayloadSize;
    uint32_t maxPipelineRayHitAttributeSize;
} VkRayTracingPipelineInterfaceCreateInfoKHR;

typedef struct VkRayTracingPipelineCreateInfoKHR {
    VkStructureType sType;
    const void* pNext;
    VkPipelineCreateFlags flags;
    uint32_t stageCount;
    const VkPipelineShaderStageCreateInfo* pStages;
    uint32_t groupCount;
    const VkRayTracingShaderGroupCreateInfoKHR* pGroups;
    uint32_t maxPipelineRayRecursionDepth;
    const VkPipelineLibraryCreateInfoKHR* pLibraryInfo;
    const VkRayTracingPipelineInterfaceCreateInfoKHR* pLibraryInterface;
    const VkPipelineDynamicStateCreateInfo* pDynamicState;
    VkPipelineLayout layout;
    VkPipeline basePipelineHandle;
    int32_t basePipelineIndex;
} VkRayTracingPipelineCreateInfoKHR;

typedef struct VkPhysicalDeviceRayTracingPipelineFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 rayTracingPipeline;
    VkBool32 rayTracingPipelineShaderGroupHandleCaptureReplay;
    VkBool32 rayTracingPipelineShaderGroupHandleCaptureReplayMixed;
    VkBool32 rayTracingPipelineTraceRaysIndirect;
    VkBool32 rayTraversalPrimitiveCulling;
} VkPhysicalDeviceRayTracingPipelineFeaturesKHR;

typedef struct VkPhysicalDeviceRayTracingPipelinePropertiesKHR {
    VkStructureType sType;
    void* pNext;
    uint32_t shaderGroupHandleSize;
    uint32_t maxRayRecursionDepth;
    uint32_t maxShaderGroupStride;
    uint32_t shaderGroupBaseAlignment;
    uint32_t shaderGroupHandleCaptureReplaySize;
    uint32_t maxRayDispatchInvocationCount;
    uint32_t shaderGroupHandleAlignment;
    uint32_t maxRayHitAttributeSize;
} VkPhysicalDeviceRayTracingPipelinePropertiesKHR;

typedef struct VkStridedDeviceAddressRegionKHR {
    VkDeviceAddress deviceAddress;
    VkDeviceSize stride;
    VkDeviceSize size;
} VkStridedDeviceAddressRegionKHR;

typedef struct VkTraceRaysIndirectCommandKHR {
    uint32_t width;
    uint32_t height;
    uint32_t depth;
} VkTraceRaysIndirectCommandKHR;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdTraceRaysKHR)(VkCommandBuffer commandBuffer, const VkStridedDeviceAddressRegionKHR* pRaygenShaderBindingTable, const VkStridedDeviceAddressRegionKHR* pMissShaderBindingTable, const VkStridedDeviceAddressRegionKHR* pHitShaderBindingTable, const VkStridedDeviceAddressRegionKHR* pCallableShaderBindingTable, uint32_t width, uint32_t height, uint32_t depth);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkCreateRayTracingPipelinesKHR)(VkDevice device, VkDeferredOperationKHR deferredOperation, VkPipelineCache pipelineCache, uint32_t createInfoCount, const VkRayTracingPipelineCreateInfoKHR* pCreateInfos, const VkAllocationCallbacks* pAllocator, VkPipeline* pPipelines);
typedef VkResult (__attribute__((__stdcall__)) *PFN_vkGetRayTracingCaptureReplayShaderGroupHandlesKHR)(VkDevice device, VkPipeline pipeline, uint32_t firstGroup, uint32_t groupCount, size_t dataSize, void* pData);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdTraceRaysIndirectKHR)(VkCommandBuffer commandBuffer, const VkStridedDeviceAddressRegionKHR* pRaygenShaderBindingTable, const VkStridedDeviceAddressRegionKHR* pMissShaderBindingTable, const VkStridedDeviceAddressRegionKHR* pHitShaderBindingTable, const VkStridedDeviceAddressRegionKHR* pCallableShaderBindingTable, VkDeviceAddress indirectDeviceAddress);
typedef VkDeviceSize (__attribute__((__stdcall__)) *PFN_vkGetRayTracingShaderGroupStackSizeKHR)(VkDevice device, VkPipeline pipeline, uint32_t group, VkShaderGroupShaderKHR groupShader);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdSetRayTracingPipelineStackSizeKHR)(VkCommandBuffer commandBuffer, uint32_t pipelineStackSize);


 void __attribute__((__stdcall__)) vkCmdTraceRaysKHR(
    VkCommandBuffer commandBuffer,
    const VkStridedDeviceAddressRegionKHR* pRaygenShaderBindingTable,
    const VkStridedDeviceAddressRegionKHR* pMissShaderBindingTable,
    const VkStridedDeviceAddressRegionKHR* pHitShaderBindingTable,
    const VkStridedDeviceAddressRegionKHR* pCallableShaderBindingTable,
    uint32_t width,
    uint32_t height,
    uint32_t depth);

 VkResult __attribute__((__stdcall__)) vkCreateRayTracingPipelinesKHR(
    VkDevice device,
    VkDeferredOperationKHR deferredOperation,
    VkPipelineCache pipelineCache,
    uint32_t createInfoCount,
    const VkRayTracingPipelineCreateInfoKHR* pCreateInfos,
    const VkAllocationCallbacks* pAllocator,
    VkPipeline* pPipelines);

 VkResult __attribute__((__stdcall__)) vkGetRayTracingCaptureReplayShaderGroupHandlesKHR(
    VkDevice device,
    VkPipeline pipeline,
    uint32_t firstGroup,
    uint32_t groupCount,
    size_t dataSize,
    void* pData);

 void __attribute__((__stdcall__)) vkCmdTraceRaysIndirectKHR(
    VkCommandBuffer commandBuffer,
    const VkStridedDeviceAddressRegionKHR* pRaygenShaderBindingTable,
    const VkStridedDeviceAddressRegionKHR* pMissShaderBindingTable,
    const VkStridedDeviceAddressRegionKHR* pHitShaderBindingTable,
    const VkStridedDeviceAddressRegionKHR* pCallableShaderBindingTable,
    VkDeviceAddress indirectDeviceAddress);

 VkDeviceSize __attribute__((__stdcall__)) vkGetRayTracingShaderGroupStackSizeKHR(
    VkDevice device,
    VkPipeline pipeline,
    uint32_t group,
    VkShaderGroupShaderKHR groupShader);

 void __attribute__((__stdcall__)) vkCmdSetRayTracingPipelineStackSizeKHR(
    VkCommandBuffer commandBuffer,
    uint32_t pipelineStackSize);







typedef struct VkPhysicalDeviceRayQueryFeaturesKHR {
    VkStructureType sType;
    void* pNext;
    VkBool32 rayQuery;
} VkPhysicalDeviceRayQueryFeaturesKHR;







typedef struct VkPhysicalDeviceMeshShaderFeaturesEXT {
    VkStructureType sType;
    void* pNext;
    VkBool32 taskShader;
    VkBool32 meshShader;
    VkBool32 multiviewMeshShader;
    VkBool32 primitiveFragmentShadingRateMeshShader;
    VkBool32 meshShaderQueries;
} VkPhysicalDeviceMeshShaderFeaturesEXT;

typedef struct VkPhysicalDeviceMeshShaderPropertiesEXT {
    VkStructureType sType;
    void* pNext;
    uint32_t maxTaskWorkGroupTotalCount;
    uint32_t maxTaskWorkGroupCount[3];
    uint32_t maxTaskWorkGroupInvocations;
    uint32_t maxTaskWorkGroupSize[3];
    uint32_t maxTaskPayloadSize;
    uint32_t maxTaskSharedMemorySize;
    uint32_t maxTaskPayloadAndSharedMemorySize;
    uint32_t maxMeshWorkGroupTotalCount;
    uint32_t maxMeshWorkGroupCount[3];
    uint32_t maxMeshWorkGroupInvocations;
    uint32_t maxMeshWorkGroupSize[3];
    uint32_t maxMeshSharedMemorySize;
    uint32_t maxMeshPayloadAndSharedMemorySize;
    uint32_t maxMeshOutputMemorySize;
    uint32_t maxMeshPayloadAndOutputMemorySize;
    uint32_t maxMeshOutputComponents;
    uint32_t maxMeshOutputVertices;
    uint32_t maxMeshOutputPrimitives;
    uint32_t maxMeshOutputLayers;
    uint32_t maxMeshMultiviewViewCount;
    uint32_t meshOutputPerVertexGranularity;
    uint32_t meshOutputPerPrimitiveGranularity;
    uint32_t maxPreferredTaskWorkGroupInvocations;
    uint32_t maxPreferredMeshWorkGroupInvocations;
    VkBool32 prefersLocalInvocationVertexOutput;
    VkBool32 prefersLocalInvocationPrimitiveOutput;
    VkBool32 prefersCompactVertexOutput;
    VkBool32 prefersCompactPrimitiveOutput;
} VkPhysicalDeviceMeshShaderPropertiesEXT;

typedef struct VkDrawMeshTasksIndirectCommandEXT {
    uint32_t groupCountX;
    uint32_t groupCountY;
    uint32_t groupCountZ;
} VkDrawMeshTasksIndirectCommandEXT;

typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawMeshTasksEXT)(VkCommandBuffer commandBuffer, uint32_t groupCountX, uint32_t groupCountY, uint32_t groupCountZ);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawMeshTasksIndirectEXT)(VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, uint32_t drawCount, uint32_t stride);
typedef void (__attribute__((__stdcall__)) *PFN_vkCmdDrawMeshTasksIndirectCountEXT)(VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride);


 void __attribute__((__stdcall__)) vkCmdDrawMeshTasksEXT(
    VkCommandBuffer commandBuffer,
    uint32_t groupCountX,
    uint32_t groupCountY,
    uint32_t groupCountZ);

 void __attribute__((__stdcall__)) vkCmdDrawMeshTasksIndirectEXT(
    VkCommandBuffer commandBuffer,
    VkBuffer buffer,
    VkDeviceSize offset,
    uint32_t drawCount,
    uint32_t stride);

 void __attribute__((__stdcall__)) vkCmdDrawMeshTasksIndirectCountEXT(
    VkCommandBuffer commandBuffer,
    VkBuffer buffer,
    VkDeviceSize offset,
    VkBuffer countBuffer,
    VkDeviceSize countBufferOffset,
    uint32_t maxDrawCount,
    uint32_t stride);



}
# 12 "C:/VulkanSDK/1.4.304.1/include/vulkan/vulkan.h" 2 3 4
# 133 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 2
# 349 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"

# 349 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
typedef enum VmaAllocatorCreateFlagBits
{




    VMA_ALLOCATOR_CREATE_EXTERNALLY_SYNCHRONIZED_BIT = 0x00000001,
# 380 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_ALLOCATOR_CREATE_KHR_DEDICATED_ALLOCATION_BIT = 0x00000002,
# 395 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_ALLOCATOR_CREATE_KHR_BIND_MEMORY2_BIT = 0x00000004,
# 407 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_ALLOCATOR_CREATE_EXT_MEMORY_BUDGET_BIT = 0x00000008,
# 425 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_ALLOCATOR_CREATE_AMD_DEVICE_COHERENT_MEMORY_BIT = 0x00000010,
# 443 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_ALLOCATOR_CREATE_BUFFER_DEVICE_ADDRESS_BIT = 0x00000020,
# 460 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_ALLOCATOR_CREATE_EXT_MEMORY_PRIORITY_BIT = 0x00000040,






    VMA_ALLOCATOR_CREATE_KHR_MAINTENANCE4_BIT = 0x00000080,






    VMA_ALLOCATOR_CREATE_KHR_MAINTENANCE5_BIT = 0x00000100,
# 483 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_ALLOCATOR_CREATE_KHR_EXTERNAL_MEMORY_WIN32_BIT = 0x00000200,

    VMA_ALLOCATOR_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VmaAllocatorCreateFlagBits;

typedef VkFlags VmaAllocatorCreateFlags;
# 498 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
typedef enum VmaMemoryUsage
{



    VMA_MEMORY_USAGE_UNKNOWN = 0,




    VMA_MEMORY_USAGE_GPU_ONLY = 1,




    VMA_MEMORY_USAGE_CPU_ONLY = 2,




    VMA_MEMORY_USAGE_CPU_TO_GPU = 3,




    VMA_MEMORY_USAGE_GPU_TO_CPU = 4,




    VMA_MEMORY_USAGE_CPU_COPY = 5,
# 537 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_MEMORY_USAGE_GPU_LAZILY_ALLOCATED = 6,
# 550 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_MEMORY_USAGE_AUTO = 7,
# 562 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_MEMORY_USAGE_AUTO_PREFER_DEVICE = 8,
# 574 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_MEMORY_USAGE_AUTO_PREFER_HOST = 9,

    VMA_MEMORY_USAGE_MAX_ENUM = 0x7FFFFFFF
} VmaMemoryUsage;


typedef enum VmaAllocationCreateFlagBits
{







    VMA_ALLOCATION_CREATE_DEDICATED_MEMORY_BIT = 0x00000001,
# 599 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_ALLOCATION_CREATE_NEVER_ALLOCATE_BIT = 0x00000002,
# 610 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_ALLOCATION_CREATE_MAPPED_BIT = 0x00000004,







    VMA_ALLOCATION_CREATE_USER_DATA_COPY_STRING_BIT = 0x00000020,




    VMA_ALLOCATION_CREATE_UPPER_ADDRESS_BIT = 0x00000040,
# 633 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_ALLOCATION_CREATE_DONT_BIND_BIT = 0x00000080,



    VMA_ALLOCATION_CREATE_WITHIN_BUDGET_BIT = 0x00000100,





    VMA_ALLOCATION_CREATE_CAN_ALIAS_BIT = 0x00000200,
# 659 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT = 0x00000400,
# 671 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT = 0x00000800,
# 683 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_ALLOCATION_CREATE_HOST_ACCESS_ALLOW_TRANSFER_INSTEAD_BIT = 0x00001000,



    VMA_ALLOCATION_CREATE_STRATEGY_MIN_MEMORY_BIT = 0x00010000,




    VMA_ALLOCATION_CREATE_STRATEGY_MIN_TIME_BIT = 0x00020000,




    VMA_ALLOCATION_CREATE_STRATEGY_MIN_OFFSET_BIT = 0x00040000,


    VMA_ALLOCATION_CREATE_STRATEGY_BEST_FIT_BIT = VMA_ALLOCATION_CREATE_STRATEGY_MIN_MEMORY_BIT,


    VMA_ALLOCATION_CREATE_STRATEGY_FIRST_FIT_BIT = VMA_ALLOCATION_CREATE_STRATEGY_MIN_TIME_BIT,


    VMA_ALLOCATION_CREATE_STRATEGY_MASK =
        VMA_ALLOCATION_CREATE_STRATEGY_MIN_MEMORY_BIT |
        VMA_ALLOCATION_CREATE_STRATEGY_MIN_TIME_BIT |
        VMA_ALLOCATION_CREATE_STRATEGY_MIN_OFFSET_BIT,

    VMA_ALLOCATION_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VmaAllocationCreateFlagBits;

typedef VkFlags VmaAllocationCreateFlags;


typedef enum VmaPoolCreateFlagBits
{
# 736 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_POOL_CREATE_IGNORE_BUFFER_IMAGE_GRANULARITY_BIT = 0x00000002,
# 749 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_POOL_CREATE_LINEAR_ALGORITHM_BIT = 0x00000004,



    VMA_POOL_CREATE_ALGORITHM_MASK =
        VMA_POOL_CREATE_LINEAR_ALGORITHM_BIT,

    VMA_POOL_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VmaPoolCreateFlagBits;

typedef VkFlags VmaPoolCreateFlags;


typedef enum VmaDefragmentationFlagBits
{



    VMA_DEFRAGMENTATION_FLAG_ALGORITHM_FAST_BIT = 0x1,



    VMA_DEFRAGMENTATION_FLAG_ALGORITHM_BALANCED_BIT = 0x2,



    VMA_DEFRAGMENTATION_FLAG_ALGORITHM_FULL_BIT = 0x4,





    VMA_DEFRAGMENTATION_FLAG_ALGORITHM_EXTENSIVE_BIT = 0x8,


    VMA_DEFRAGMENTATION_FLAG_ALGORITHM_MASK =
        VMA_DEFRAGMENTATION_FLAG_ALGORITHM_FAST_BIT |
        VMA_DEFRAGMENTATION_FLAG_ALGORITHM_BALANCED_BIT |
        VMA_DEFRAGMENTATION_FLAG_ALGORITHM_FULL_BIT |
        VMA_DEFRAGMENTATION_FLAG_ALGORITHM_EXTENSIVE_BIT,

    VMA_DEFRAGMENTATION_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VmaDefragmentationFlagBits;

typedef VkFlags VmaDefragmentationFlags;


typedef enum VmaDefragmentationMoveOperation
{

    VMA_DEFRAGMENTATION_MOVE_OPERATION_COPY = 0,

    VMA_DEFRAGMENTATION_MOVE_OPERATION_IGNORE = 1,

    VMA_DEFRAGMENTATION_MOVE_OPERATION_DESTROY = 2,
} VmaDefragmentationMoveOperation;
# 814 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
typedef enum VmaVirtualBlockCreateFlagBits
{
# 827 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VMA_VIRTUAL_BLOCK_CREATE_LINEAR_ALGORITHM_BIT = 0x00000001,



    VMA_VIRTUAL_BLOCK_CREATE_ALGORITHM_MASK =
        VMA_VIRTUAL_BLOCK_CREATE_LINEAR_ALGORITHM_BIT,

    VMA_VIRTUAL_BLOCK_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VmaVirtualBlockCreateFlagBits;

typedef VkFlags VmaVirtualBlockCreateFlags;


typedef enum VmaVirtualAllocationCreateFlagBits
{




    VMA_VIRTUAL_ALLOCATION_CREATE_UPPER_ADDRESS_BIT = VMA_ALLOCATION_CREATE_UPPER_ADDRESS_BIT,


    VMA_VIRTUAL_ALLOCATION_CREATE_STRATEGY_MIN_MEMORY_BIT = VMA_ALLOCATION_CREATE_STRATEGY_MIN_MEMORY_BIT,


    VMA_VIRTUAL_ALLOCATION_CREATE_STRATEGY_MIN_TIME_BIT = VMA_ALLOCATION_CREATE_STRATEGY_MIN_TIME_BIT,



    VMA_VIRTUAL_ALLOCATION_CREATE_STRATEGY_MIN_OFFSET_BIT = VMA_ALLOCATION_CREATE_STRATEGY_MIN_OFFSET_BIT,




    VMA_VIRTUAL_ALLOCATION_CREATE_STRATEGY_MASK = VMA_ALLOCATION_CREATE_STRATEGY_MASK,

    VMA_VIRTUAL_ALLOCATION_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF
} VmaVirtualAllocationCreateFlagBits;

typedef VkFlags VmaVirtualAllocationCreateFlags;
# 887 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"

# 887 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
typedef struct 
# 887 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
VmaAllocator_T
# 887 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
* 
# 887 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
VmaAllocator
# 887 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
;
# 904 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
typedef struct 
# 904 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
VmaPool_T
# 904 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
* 
# 904 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
VmaPool
# 904 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
;
# 927 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
typedef struct 
# 927 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
VmaAllocation_T
# 927 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
* 
# 927 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
VmaAllocation
# 927 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
;







typedef struct 
# 935 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
VmaDefragmentationContext_T
# 935 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
* 
# 935 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
VmaDefragmentationContext
# 935 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
;
# 951 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
typedef struct 
# 951 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
VmaVirtualAllocation_T 
# 951 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
*
# 951 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
VmaVirtualAllocation
# 951 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
;
# 968 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
typedef struct 
# 968 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
VmaVirtualBlock_T
# 968 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
* 
# 968 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
VmaVirtualBlock
# 968 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
;
# 978 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"

# 978 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
typedef void (__attribute__((__stdcall__))
# 978 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                      * PFN_vmaAllocateDeviceMemoryFunction)(
    VmaAllocator allocator,
    uint32_t memoryType,
    VkDeviceMemory memory,
    VkDeviceSize size,
    void* pUserData);


typedef void (__attribute__((__stdcall__))
# 986 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                      * PFN_vmaFreeDeviceMemoryFunction)(
    VmaAllocator allocator,
    uint32_t memoryType,
    VkDeviceMemory memory,
    VkDeviceSize size,
    void* pUserData);
# 1000 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
typedef struct VmaDeviceMemoryCallbacks
{

    PFN_vmaAllocateDeviceMemoryFunction pfnAllocate;

    PFN_vmaFreeDeviceMemoryFunction pfnFree;

    void* pUserData;
} VmaDeviceMemoryCallbacks;





typedef struct VmaVulkanFunctions
{

    PFN_vkGetInstanceProcAddr vkGetInstanceProcAddr;

    PFN_vkGetDeviceProcAddr vkGetDeviceProcAddr;
    PFN_vkGetPhysicalDeviceProperties vkGetPhysicalDeviceProperties;
    PFN_vkGetPhysicalDeviceMemoryProperties vkGetPhysicalDeviceMemoryProperties;
    PFN_vkAllocateMemory vkAllocateMemory;
    PFN_vkFreeMemory vkFreeMemory;
    PFN_vkMapMemory vkMapMemory;
    PFN_vkUnmapMemory vkUnmapMemory;
    PFN_vkFlushMappedMemoryRanges vkFlushMappedMemoryRanges;
    PFN_vkInvalidateMappedMemoryRanges vkInvalidateMappedMemoryRanges;
    PFN_vkBindBufferMemory vkBindBufferMemory;
    PFN_vkBindImageMemory vkBindImageMemory;
    PFN_vkGetBufferMemoryRequirements vkGetBufferMemoryRequirements;
    PFN_vkGetImageMemoryRequirements vkGetImageMemoryRequirements;
    PFN_vkCreateBuffer vkCreateBuffer;
    PFN_vkDestroyBuffer vkDestroyBuffer;
    PFN_vkCreateImage vkCreateImage;
    PFN_vkDestroyImage vkDestroyImage;
    PFN_vkCmdCopyBuffer vkCmdCopyBuffer;


    PFN_vkGetBufferMemoryRequirements2KHR vkGetBufferMemoryRequirements2KHR;

    PFN_vkGetImageMemoryRequirements2KHR vkGetImageMemoryRequirements2KHR;



    PFN_vkBindBufferMemory2KHR vkBindBufferMemory2KHR;

    PFN_vkBindImageMemory2KHR vkBindImageMemory2KHR;



    PFN_vkGetPhysicalDeviceMemoryProperties2KHR vkGetPhysicalDeviceMemoryProperties2KHR;



    PFN_vkGetDeviceBufferMemoryRequirementsKHR vkGetDeviceBufferMemoryRequirements;

    PFN_vkGetDeviceImageMemoryRequirementsKHR vkGetDeviceImageMemoryRequirements;




    void* vkGetMemoryWin32HandleKHR;

} VmaVulkanFunctions;


typedef struct VmaAllocatorCreateInfo
{

    VmaAllocatorCreateFlags flags;


    VkPhysicalDevice physicalDevice;


    VkDevice device;


    VkDeviceSize preferredLargeHeapBlockSize;


    const VkAllocationCallbacks* pAllocationCallbacks;


    const VmaDeviceMemoryCallbacks* pDeviceMemoryCallbacks;
# 1110 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    const VkDeviceSize* pHeapSizeLimit;





    const VmaVulkanFunctions* pVulkanFunctions;




    VkInstance instance;
# 1132 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    uint32_t vulkanApiVersion;
# 1143 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    const VkExternalMemoryHandleTypeFlagsKHR* pTypeExternalMemoryHandleTypes;

} VmaAllocatorCreateInfo;


typedef struct VmaAllocatorInfo
{




    VkInstance instance;




    VkPhysicalDevice physicalDevice;




    VkDevice device;
} VmaAllocatorInfo;
# 1179 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
typedef struct VmaStatistics
{


    uint32_t blockCount;




    uint32_t allocationCount;






    VkDeviceSize blockBytes;






    VkDeviceSize allocationBytes;
} VmaStatistics;
# 1219 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
typedef struct VmaDetailedStatistics
{

    VmaStatistics statistics;

    uint32_t unusedRangeCount;

    VkDeviceSize allocationSizeMin;

    VkDeviceSize allocationSizeMax;

    VkDeviceSize unusedRangeSizeMin;

    VkDeviceSize unusedRangeSizeMax;
} VmaDetailedStatistics;







typedef struct VmaTotalStatistics
{
    VmaDetailedStatistics memoryType[
# 1243 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                    32U
# 1243 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                       ];
    VmaDetailedStatistics memoryHeap[
# 1244 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                    16U
# 1244 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                       ];
    VmaDetailedStatistics total;
} VmaTotalStatistics;






typedef struct VmaBudget
{


    VmaStatistics statistics;
# 1266 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VkDeviceSize usage;
# 1276 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VkDeviceSize budget;
} VmaBudget;
# 1290 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
typedef struct VmaAllocationCreateInfo
{

    VmaAllocationCreateFlags flags;





    VmaMemoryUsage usage;




    VkMemoryPropertyFlags requiredFlags;




    VkMemoryPropertyFlags preferredFlags;







    uint32_t memoryTypeBits;





    VmaPool pool;






    void* pUserData;






    float priority;
} VmaAllocationCreateInfo;


typedef struct VmaPoolCreateInfo
{


    uint32_t memoryTypeIndex;


    VmaPoolCreateFlags flags;
# 1358 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VkDeviceSize blockSize;




    size_t minBlockCount;







    size_t maxBlockCount;





    float priority;






    VkDeviceSize minAllocationAlignment;
# 1394 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    void* pMemoryAllocateNext;
} VmaPoolCreateInfo;
# 1409 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
typedef struct VmaAllocationInfo
{




    uint32_t memoryType;






    VkDeviceMemory deviceMemory;
# 1432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VkDeviceSize offset;
# 1443 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VkDeviceSize size;
# 1452 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    void* pMappedData;




    void* pUserData;







    const char* pName;
} VmaAllocationInfo;


typedef struct VmaAllocationInfo2
{




    VmaAllocationInfo allocationInfo;




    VkDeviceSize blockSize;





    VkBool32 dedicatedMemory;
} VmaAllocationInfo2;





typedef VkBool32 (__attribute__((__stdcall__))
# 1493 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                          * PFN_vmaCheckDefragmentationBreakFunction)(void* pUserData);





typedef struct VmaDefragmentationInfo
{

    VmaDefragmentationFlags flags;




    VmaPool pool;




    VkDeviceSize maxBytesPerPass;




    uint32_t maxAllocationsPerPass;




    PFN_vmaCheckDefragmentationBreakFunction pfnBreakCallback;

    void* pBreakCallbackUserData;
} VmaDefragmentationInfo;


typedef struct VmaDefragmentationMove
{

    VmaDefragmentationMoveOperation operation;

    VmaAllocation srcAllocation;






    VmaAllocation dstTmpAllocation;
} VmaDefragmentationMove;





typedef struct VmaDefragmentationPassMoveInfo
{

    uint32_t moveCount;
# 1574 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    VmaDefragmentationMove* pMoves;
} VmaDefragmentationPassMoveInfo;


typedef struct VmaDefragmentationStats
{

    VkDeviceSize bytesMoved;

    VkDeviceSize bytesFreed;

    uint32_t allocationsMoved;

    uint32_t deviceMemoryBlocksFreed;
} VmaDefragmentationStats;
# 1598 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
typedef struct VmaVirtualBlockCreateInfo
{





    VkDeviceSize size;



    VmaVirtualBlockCreateFlags flags;





    const VkAllocationCallbacks* pAllocationCallbacks;
} VmaVirtualBlockCreateInfo;


typedef struct VmaVirtualAllocationCreateInfo
{




    VkDeviceSize size;




    VkDeviceSize alignment;


    VmaVirtualAllocationCreateFlags flags;




    void* pUserData;
} VmaVirtualAllocationCreateInfo;


typedef struct VmaVirtualAllocationInfo
{




    VkDeviceSize offset;




    VkDeviceSize size;




    void* pUserData;
} VmaVirtualAllocationInfo;
# 1673 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaCreateAllocator(
    const VmaAllocatorCreateInfo* pCreateInfo,
    VmaAllocator * pAllocator);


 void vmaDestroyAllocator(
    VmaAllocator allocator);






 void vmaGetAllocatorInfo(
    VmaAllocator allocator,
    VmaAllocatorInfo* pAllocatorInfo);





 void vmaGetPhysicalDeviceProperties(
    VmaAllocator allocator,
    const VkPhysicalDeviceProperties* * ppPhysicalDeviceProperties);





 void vmaGetMemoryProperties(
    VmaAllocator allocator,
    const VkPhysicalDeviceMemoryProperties* * ppPhysicalDeviceMemoryProperties);







 void vmaGetMemoryTypeProperties(
    VmaAllocator allocator,
    uint32_t memoryTypeIndex,
    VkMemoryPropertyFlags* pFlags);



 void vmaSetCurrentFrameIndex(
    VmaAllocator allocator,
    uint32_t frameIndex);
# 1740 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 void vmaCalculateStatistics(
    VmaAllocator allocator,
    VmaTotalStatistics* pStats);
# 1755 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 void vmaGetHeapBudgets(
    VmaAllocator allocator,
    VmaBudget* pBudgets);
# 1782 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaFindMemoryTypeIndex(
    VmaAllocator allocator,
    uint32_t memoryTypeBits,
    const VmaAllocationCreateInfo* pAllocationCreateInfo,
    uint32_t* pMemoryTypeIndex);







 VkResult vmaFindMemoryTypeIndexForBufferInfo(
    VmaAllocator allocator,
    const VkBufferCreateInfo* pBufferCreateInfo,
    const VmaAllocationCreateInfo* pAllocationCreateInfo,
    uint32_t* pMemoryTypeIndex);







 VkResult vmaFindMemoryTypeIndexForImageInfo(
    VmaAllocator allocator,
    const VkImageCreateInfo* pImageCreateInfo,
    const VmaAllocationCreateInfo* pAllocationCreateInfo,
    uint32_t* pMemoryTypeIndex);







 VkResult vmaCreatePool(
    VmaAllocator allocator,
    const VmaPoolCreateInfo* pCreateInfo,
    VmaPool * pPool);



 void vmaDestroyPool(
    VmaAllocator allocator,
    VmaPool pool);
# 1845 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 void vmaGetPoolStatistics(
    VmaAllocator allocator,
    VmaPool pool,
    VmaStatistics* pPoolStats);







 void vmaCalculatePoolStatistics(
    VmaAllocator allocator,
    VmaPool pool,
    VmaDetailedStatistics* pPoolStats);
# 1882 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaCheckPoolCorruption(
    VmaAllocator allocator,
    VmaPool pool);







 void vmaGetPoolName(
    VmaAllocator allocator,
    VmaPool pool,
    const char* * ppName);






 void vmaSetPoolName(
    VmaAllocator allocator,
    VmaPool pool,
    const char* pName);
# 1920 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaAllocateMemory(
    VmaAllocator allocator,
    const VkMemoryRequirements* pVkMemoryRequirements,
    const VmaAllocationCreateInfo* pCreateInfo,
    VmaAllocation * pAllocation,
    VmaAllocationInfo* pAllocationInfo);
# 1946 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaAllocateMemoryPages(
    VmaAllocator allocator,
    const VkMemoryRequirements* pVkMemoryRequirements,
    const VmaAllocationCreateInfo* pCreateInfo,
    size_t allocationCount,
    VmaAllocation * pAllocations,
    VmaAllocationInfo* pAllocationInfo);
# 1968 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaAllocateMemoryForBuffer(
    VmaAllocator allocator,
    VkBuffer buffer,
    const VmaAllocationCreateInfo* pCreateInfo,
    VmaAllocation * pAllocation,
    VmaAllocationInfo* pAllocationInfo);
# 1989 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaAllocateMemoryForImage(
    VmaAllocator allocator,
    VkImage image,
    const VmaAllocationCreateInfo* pCreateInfo,
    VmaAllocation * pAllocation,
    VmaAllocationInfo* pAllocationInfo);





 void vmaFreeMemory(
    VmaAllocator allocator,
    const VmaAllocation allocation);
# 2014 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 void vmaFreeMemoryPages(
    VmaAllocator allocator,
    size_t allocationCount,
    const VmaAllocation * pAllocations);
# 2032 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 void vmaGetAllocationInfo(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VmaAllocationInfo* pAllocationInfo);
# 2044 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 void vmaGetAllocationInfo2(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VmaAllocationInfo2* pAllocationInfo);







 void vmaSetAllocationUserData(
    VmaAllocator allocator,
    VmaAllocation allocation,
    void* pUserData);
# 2068 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 void vmaSetAllocationName(
    VmaAllocator allocator,
    VmaAllocation allocation,
    const char* pName);







 void vmaGetAllocationMemoryProperties(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VkMemoryPropertyFlags* pFlags);
# 2155 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaMapMemory(
    VmaAllocator allocator,
    VmaAllocation allocation,
    void* * ppData);
# 2168 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 void vmaUnmapMemory(
    VmaAllocator allocator,
    VmaAllocation allocation);
# 2193 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaFlushAllocation(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VkDeviceSize offset,
    VkDeviceSize size);
# 2220 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaInvalidateAllocation(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VkDeviceSize offset,
    VkDeviceSize size);
# 2240 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaFlushAllocations(
    VmaAllocator allocator,
    uint32_t allocationCount,
    const VmaAllocation * allocations,
    const VkDeviceSize* offsets,
    const VkDeviceSize* sizes);
# 2261 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaInvalidateAllocations(
    VmaAllocator allocator,
    uint32_t allocationCount,
    const VmaAllocation * allocations,
    const VkDeviceSize* offsets,
    const VkDeviceSize* sizes);
# 2288 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaCopyMemoryToAllocation(
    VmaAllocator allocator,
    const void* pSrcHostPointer,
    VmaAllocation dstAllocation,
    VkDeviceSize dstAllocationLocalOffset,
    VkDeviceSize size);
# 2316 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaCopyAllocationToMemory(
    VmaAllocator allocator,
    VmaAllocation srcAllocation,
    VkDeviceSize srcAllocationLocalOffset,
    void* pDstHostPointer,
    VkDeviceSize size);
# 2340 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaCheckCorruption(
    VmaAllocator allocator,
    uint32_t memoryTypeBits);
# 2356 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaBeginDefragmentation(
    VmaAllocator allocator,
    const VmaDefragmentationInfo* pInfo,
    VmaDefragmentationContext * pContext);
# 2369 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 void vmaEndDefragmentation(
    VmaAllocator allocator,
    VmaDefragmentationContext context,
    VmaDefragmentationStats* pStats);
# 2384 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaBeginDefragmentationPass(
    VmaAllocator allocator,
    VmaDefragmentationContext context,
    VmaDefragmentationPassMoveInfo* pPassInfo);
# 2407 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaEndDefragmentationPass(
    VmaAllocator allocator,
    VmaDefragmentationContext context,
    VmaDefragmentationPassMoveInfo* pPassInfo);
# 2424 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaBindBufferMemory(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VkBuffer buffer);
# 2442 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaBindBufferMemory2(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VkDeviceSize allocationLocalOffset,
    VkBuffer buffer,
    const void* pNext);
# 2461 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaBindImageMemory(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VkImage image);
# 2479 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaBindImageMemory2(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VkDeviceSize allocationLocalOffset,
    VkImage image,
    const void* pNext);
# 2520 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaCreateBuffer(
    VmaAllocator allocator,
    const VkBufferCreateInfo* pBufferCreateInfo,
    const VmaAllocationCreateInfo* pAllocationCreateInfo,
    VkBuffer * pBuffer,
    VmaAllocation * pAllocation,
    VmaAllocationInfo* pAllocationInfo);







 VkResult vmaCreateBufferWithAlignment(
    VmaAllocator allocator,
    const VkBufferCreateInfo* pBufferCreateInfo,
    const VmaAllocationCreateInfo* pAllocationCreateInfo,
    VkDeviceSize minAlignment,
    VkBuffer * pBuffer,
    VmaAllocation * pAllocation,
    VmaAllocationInfo* pAllocationInfo);
# 2564 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaCreateAliasingBuffer(
    VmaAllocator allocator,
    VmaAllocation allocation,
    const VkBufferCreateInfo* pBufferCreateInfo,
    VkBuffer * pBuffer);
# 2592 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaCreateAliasingBuffer2(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VkDeviceSize allocationLocalOffset,
    const VkBufferCreateInfo* pBufferCreateInfo,
    VkBuffer * pBuffer);
# 2610 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 void vmaDestroyBuffer(
    VmaAllocator allocator,
    VkBuffer buffer,
    VmaAllocation allocation);


 VkResult vmaCreateImage(
    VmaAllocator allocator,
    const VkImageCreateInfo* pImageCreateInfo,
    const VmaAllocationCreateInfo* pAllocationCreateInfo,
    VkImage * pImage,
    VmaAllocation * pAllocation,
    VmaAllocationInfo* pAllocationInfo);


 VkResult vmaCreateAliasingImage(
    VmaAllocator allocator,
    VmaAllocation allocation,
    const VkImageCreateInfo* pImageCreateInfo,
    VkImage * pImage);


 VkResult vmaCreateAliasingImage2(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VkDeviceSize allocationLocalOffset,
    const VkImageCreateInfo* pImageCreateInfo,
    VkImage * pImage);
# 2650 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 void vmaDestroyImage(
    VmaAllocator allocator,
    VkImage image,
    VmaAllocation allocation);
# 2667 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaCreateVirtualBlock(
    const VmaVirtualBlockCreateInfo* pCreateInfo,
    VmaVirtualBlock * pVirtualBlock);
# 2680 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 void vmaDestroyVirtualBlock(
    VmaVirtualBlock virtualBlock);



 VkBool32 vmaIsVirtualBlockEmpty(
    VmaVirtualBlock virtualBlock);



 void vmaGetVirtualAllocationInfo(
    VmaVirtualBlock virtualBlock,
    VmaVirtualAllocation allocation, VmaVirtualAllocationInfo* pVirtualAllocInfo);
# 2705 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 VkResult vmaVirtualAllocate(
    VmaVirtualBlock virtualBlock,
    const VmaVirtualAllocationCreateInfo* pCreateInfo,
    VmaVirtualAllocation * pAllocation,
    VkDeviceSize* pOffset);





 void vmaVirtualFree(
    VmaVirtualBlock virtualBlock,
    VmaVirtualAllocation allocation);
# 2727 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 void vmaClearVirtualBlock(
    VmaVirtualBlock virtualBlock);



 void vmaSetVirtualAllocationUserData(
    VmaVirtualBlock virtualBlock,
    VmaVirtualAllocation allocation,
    void* pUserData);





 void vmaGetVirtualBlockStatistics(
    VmaVirtualBlock virtualBlock,
    VmaStatistics* pStats);






 void vmaCalculateVirtualBlockStatistics(
    VmaVirtualBlock virtualBlock,
    VmaDetailedStatistics* pStats);
# 2769 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
 void vmaBuildVirtualBlockStatsString(
    VmaVirtualBlock virtualBlock,
    char* * ppStatsString,
    VkBool32 detailedMap);


 void vmaFreeVirtualBlockStatsString(
    VmaVirtualBlock virtualBlock,
    char* pStatsString);






 void vmaBuildStatsString(
    VmaAllocator allocator,
    char* * ppStatsString,
    VkBool32 detailedMap);

 void vmaFreeStatsString(
    VmaAllocator allocator,
    char* pStatsString);
# 2800 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
}
# 2821 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
# 1 "C:/msys64/mingw64/include/c++/15.2.0/cstdint" 1 3
# 40 "C:/msys64/mingw64/include/c++/15.2.0/cstdint" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/c++config.h" 1 3
# 37 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/c++config.h" 3
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wvariadic-macros"

#pragma GCC diagnostic ignored "-Wc++11-extensions"
#pragma GCC diagnostic ignored "-Wc++23-extensions"
# 336 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/c++config.h" 3
namespace std
{
  typedef long long unsigned int size_t;
  typedef long long int ptrdiff_t;


  typedef decltype(nullptr) nullptr_t;


#pragma GCC visibility push(default)


  extern "C++" __attribute__ ((__noreturn__, __always_inline__))
  inline void __terminate() noexcept
  {
    void terminate() noexcept __attribute__ ((__noreturn__,__cold__));
    terminate();
  }
#pragma GCC visibility pop
}
# 369 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/c++config.h" 3
namespace std
{
  inline namespace __cxx11 __attribute__((__abi_tag__ ("cxx11"))) { }
}
namespace __gnu_cxx
{
  inline namespace __cxx11 __attribute__((__abi_tag__ ("cxx11"))) { }
}
# 573 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/c++config.h" 3
namespace std
{
#pragma GCC visibility push(default)




  __attribute__((__always_inline__))
  constexpr inline bool
  __is_constant_evaluated() noexcept
  {





    return __builtin_is_constant_evaluated();



  }
#pragma GCC visibility pop
}
# 617 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/c++config.h" 3
namespace std
{
#pragma GCC visibility push(default)

  extern "C++" __attribute__ ((__noreturn__)) __attribute__((__cold__))
  void
  __glibcxx_assert_fail
    (const char* __file, int __line, const char* __function,
     const char* __condition)
  noexcept;
#pragma GCC visibility pop
}
# 727 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/c++config.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/os_defines.h" 1 3
# 728 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/c++config.h" 2 3


# 1 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/cpu_defines.h" 1 3
# 731 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/c++config.h" 2 3
# 887 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/c++config.h" 3
namespace __gnu_cxx
{
  typedef __decltype(0.0bf16) __bfloat16_t;
}
# 949 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/c++config.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/pstl/pstl_config.h" 1 3
# 950 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/c++config.h" 2 3



#pragma GCC diagnostic pop
# 41 "C:/msys64/mingw64/include/c++/15.2.0/cstdint" 2 3
# 50 "C:/msys64/mingw64/include/c++/15.2.0/cstdint" 3
namespace std
{

  using ::int8_t;
  using ::int16_t;
  using ::int32_t;
  using ::int64_t;

  using ::int_fast8_t;
  using ::int_fast16_t;
  using ::int_fast32_t;
  using ::int_fast64_t;

  using ::int_least8_t;
  using ::int_least16_t;
  using ::int_least32_t;
  using ::int_least64_t;

  using ::intmax_t;
  using ::intptr_t;

  using ::uint8_t;
  using ::uint16_t;
  using ::uint32_t;
  using ::uint64_t;

  using ::uint_fast8_t;
  using ::uint_fast16_t;
  using ::uint_fast32_t;
  using ::uint_fast64_t;

  using ::uint_least8_t;
  using ::uint_least16_t;
  using ::uint_least32_t;
  using ::uint_least64_t;

  using ::uintmax_t;
  using ::uintptr_t;
# 144 "C:/msys64/mingw64/include/c++/15.2.0/cstdint" 3
}
# 2822 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 2
# 1 "C:/msys64/mingw64/include/c++/15.2.0/cstdlib" 1 3
# 80 "C:/msys64/mingw64/include/c++/15.2.0/cstdlib" 3
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wpedantic"

# 1 "C:/msys64/mingw64/include/stdlib.h" 1 3
# 10 "C:/msys64/mingw64/include/stdlib.h" 3
# 1 "C:/msys64/mingw64/include/corecrt_wstdlib.h" 1 3
# 12 "C:/msys64/mingw64/include/corecrt_wstdlib.h" 3
extern "C" {






  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wdupenv_s(wchar_t **_Buffer,size_t *_BufferSizeInWords,const wchar_t *_VarName);




  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _itow_s (int _Val,wchar_t *_DstBuf,size_t _SizeInWords,int _Radix);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _itow_s(int _Val, wchar_t (&_DstBuf)[__size], int _Radix) { return _itow_s(_Val, _DstBuf, __size, _Radix); } }

  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _ltow_s (long _Val,wchar_t *_DstBuf,size_t _SizeInWords,int _Radix);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _ltow_s(long _Val, wchar_t (&_DstBuf)[__size], int _Radix) { return _ltow_s(_Val, _DstBuf, __size, _Radix); } }

  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _ultow_s (unsigned long _Val,wchar_t *_DstBuf,size_t _SizeInWords,int _Radix);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _ultow_s(unsigned long _Val, wchar_t (&_DstBuf)[__size], int _Radix) { return _ultow_s(_Val, _DstBuf, __size, _Radix); } }

  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wgetenv_s(size_t *_ReturnSize,wchar_t *_DstBuf,size_t _DstSizeInWords,const wchar_t *_VarName);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _wgetenv_s(size_t* _ReturnSize, wchar_t (&_DstBuf)[__size], const wchar_t* _VarName) { return _wgetenv_s(_ReturnSize, _DstBuf, __size, _VarName); } }

  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _i64tow_s(long long _Val,wchar_t *_DstBuf,size_t _SizeInWords,int _Radix);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _ui64tow_s(unsigned long long _Val,wchar_t *_DstBuf,size_t _SizeInWords,int _Radix);

  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wmakepath_s(wchar_t *_PathResult,size_t _SizeInWords,const wchar_t *_Drive,const wchar_t *_Dir,const wchar_t *_Filename,const wchar_t *_Ext);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _wmakepath_s(wchar_t (&_PathResult)[__size], const wchar_t* _Drive, const wchar_t* _Dir, const wchar_t* _Filename, const wchar_t* _Ext) { return _wmakepath_s(_PathResult,__size,_Drive,_Dir,_Filename,_Ext); } }

  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wputenv_s(const wchar_t *_Name,const wchar_t *_Value);

  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wsearchenv_s(const wchar_t *_Filename,const wchar_t *_EnvVar,wchar_t *_ResultPath,size_t _SizeInWords);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _wsearchenv_s(const wchar_t* _Filename, const wchar_t* _EnvVar, wchar_t (&_ResultPath)[__size]) { return _wsearchenv_s(_Filename, _EnvVar, _ResultPath, __size); } }

  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wsplitpath_s(const wchar_t *_FullPath,wchar_t *_Drive,size_t _DriveSizeInWords,wchar_t *_Dir,size_t _DirSizeInWords,wchar_t *_Filename,size_t _FilenameSizeInWords,wchar_t *_Ext,size_t _ExtSizeInWords);
  extern "C++" { template <size_t __drive_size, size_t __dir_size, size_t __name_size, size_t __ext_size> inline errno_t __attribute__((__cdecl__)) _wsplitpath_s(const wchar_t *_Dest, wchar_t (&__drive)[__drive_size], wchar_t (&__dir)[__dir_size], wchar_t (&__name)[__name_size], wchar_t (&__ext)[__ext_size]) { return _wsplitpath_s(_Dest, __drive, __drive_size, __dir, __dir_size, __name, __name_size, __ext, __ext_size); } }


}
# 11 "C:/msys64/mingw64/include/stdlib.h" 2 3
# 1 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/limits.h" 1 3 4
# 34 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/limits.h" 3 4
# 1 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/syslimits.h" 1 3 4






#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wpedantic"
# 1 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/limits.h" 1 3 4
# 210 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/limits.h" 3 4
# 1 "C:/msys64/mingw64/include/limits.h" 1 3 4
# 211 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/limits.h" 2 3 4
# 10 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/syslimits.h" 2 3 4
#pragma GCC diagnostic pop
# 35 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/limits.h" 2 3 4
# 12 "C:/msys64/mingw64/include/stdlib.h" 2 3
# 26 "C:/msys64/mingw64/include/stdlib.h" 3
#pragma pack(push,_CRT_PACKING)


extern "C" {
# 50 "C:/msys64/mingw64/include/stdlib.h" 3
  typedef int (__attribute__((__cdecl__)) *_onexit_t)(void);
# 60 "C:/msys64/mingw64/include/stdlib.h" 3
  typedef struct _div_t {
    int quot;
    int rem;
  } div_t;

  typedef struct _ldiv_t {
    long quot;
    long rem;
  } ldiv_t;





#pragma pack(4)
  typedef struct {
    unsigned char ld[10];
  } _LDOUBLE;
#pragma pack()



  typedef struct {
    double x;
  } _CRT_DOUBLE;

  typedef struct {
    float f;
  } _CRT_FLOAT;

       


  typedef struct {
    long double x;
  } _LONGDOUBLE;

       

#pragma pack(4)
  typedef struct {
    unsigned char ld12[12];
  } _LDBL12;
#pragma pack()
# 113 "C:/msys64/mingw64/include/stdlib.h" 3
__attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) ___mb_cur_max_func(void);
# 135 "C:/msys64/mingw64/include/stdlib.h" 3
  typedef void (__attribute__((__cdecl__)) *_purecall_handler)(void);

  __attribute__ ((__dllimport__)) _purecall_handler __attribute__((__cdecl__)) _set_purecall_handler(_purecall_handler _Handler);
  __attribute__ ((__dllimport__)) _purecall_handler __attribute__((__cdecl__)) _get_purecall_handler(void);

  typedef void (__attribute__((__cdecl__)) *_invalid_parameter_handler)(const wchar_t *,const wchar_t *,const wchar_t *,unsigned int,uintptr_t);
  __attribute__ ((__dllimport__)) _invalid_parameter_handler __attribute__((__cdecl__)) _set_invalid_parameter_handler(_invalid_parameter_handler _Handler);
  __attribute__ ((__dllimport__)) _invalid_parameter_handler __attribute__((__cdecl__)) _get_invalid_parameter_handler(void);
# 151 "C:/msys64/mingw64/include/stdlib.h" 3
  __attribute__ ((__dllimport__)) unsigned long *__attribute__((__cdecl__)) __doserrno(void);

  errno_t __attribute__((__cdecl__)) _set_doserrno(unsigned long _Value);
  errno_t __attribute__((__cdecl__)) _get_doserrno(unsigned long *_Value);
  __attribute__ ((__dllimport__)) char **__attribute__((__cdecl__)) __sys_errlist(void);
  __attribute__ ((__dllimport__)) int *__attribute__((__cdecl__)) __sys_nerr(void);



  __attribute__ ((__dllimport__)) char ***__attribute__((__cdecl__)) __p___argv(void);
  __attribute__ ((__dllimport__)) int *__attribute__((__cdecl__)) __p__fmode(void);
  __attribute__ ((__dllimport__)) int *__attribute__((__cdecl__)) __p___argc(void);
  __attribute__ ((__dllimport__)) wchar_t ***__attribute__((__cdecl__)) __p___wargv(void);
  __attribute__ ((__dllimport__)) char **__attribute__((__cdecl__)) __p__pgmptr(void);
  __attribute__ ((__dllimport__)) wchar_t **__attribute__((__cdecl__)) __p__wpgmptr(void);

  errno_t __attribute__((__cdecl__)) _get_pgmptr(char **_Value);
  errno_t __attribute__((__cdecl__)) _get_wpgmptr(wchar_t **_Value);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _set_fmode(int _Mode);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _get_fmode(int *_PMode);
# 221 "C:/msys64/mingw64/include/stdlib.h" 3
  __attribute__ ((__dllimport__)) char ***__attribute__((__cdecl__)) __p__environ(void);
  __attribute__ ((__dllimport__)) wchar_t ***__attribute__((__cdecl__)) __p__wenviron(void);
# 234 "C:/msys64/mingw64/include/stdlib.h" 3
  __attribute__ ((__dllimport__)) unsigned int *__attribute__((__cdecl__)) __p__osplatform(void);
  __attribute__ ((__dllimport__)) unsigned int *__attribute__((__cdecl__)) __p__osver(void);
  __attribute__ ((__dllimport__)) unsigned int *__attribute__((__cdecl__)) __p__winver(void);
  __attribute__ ((__dllimport__)) unsigned int *__attribute__((__cdecl__)) __p__winmajor(void);
  __attribute__ ((__dllimport__)) unsigned int *__attribute__((__cdecl__)) __p__winminor(void);
# 256 "C:/msys64/mingw64/include/stdlib.h" 3
  errno_t __attribute__((__cdecl__)) _get_osplatform(unsigned int *_Value);
  errno_t __attribute__((__cdecl__)) _get_osver(unsigned int *_Value);
  errno_t __attribute__((__cdecl__)) _get_winver(unsigned int *_Value);
  errno_t __attribute__((__cdecl__)) _get_winmajor(unsigned int *_Value);
  errno_t __attribute__((__cdecl__)) _get_winminor(unsigned int *_Value);




  extern "C++" {
    template <typename _CountofType,size_t _SizeOfArray> char (*__countof_helper( _CountofType (&_Array)[_SizeOfArray]))[_SizeOfArray];

  }





  void __attribute__((__cdecl__)) __attribute__ ((__nothrow__)) exit(int _Code) __attribute__ ((__noreturn__));
  void __attribute__((__cdecl__)) __attribute__ ((__nothrow__)) _exit(int _Code) __attribute__ ((__noreturn__));






  void __attribute__((__cdecl__)) _Exit(int) __attribute__ ((__noreturn__));






       

  void __attribute__((__cdecl__)) __attribute__ ((__noreturn__)) abort(void);
       



  __attribute__ ((__dllimport__)) unsigned int __attribute__((__cdecl__)) _set_abort_behavior(unsigned int _Flags,unsigned int _Mask);



  int __attribute__((__cdecl__)) abs(int _X);
  long __attribute__((__cdecl__)) labs(long _X);


  __extension__ long long __attribute__((__cdecl__)) _abs64(long long);

  extern __inline__ __attribute__((__always_inline__,__gnu_inline__)) long long __attribute__((__cdecl__)) _abs64(long long x) {
    return __builtin_llabs(x);
  }


  int __attribute__((__cdecl__)) atexit(void (__attribute__((__cdecl__)) *)(void));





  double __attribute__((__cdecl__)) atof(const char *_String);
  double __attribute__((__cdecl__)) _atof_l(const char *_String,_locale_t _Locale);

  int __attribute__((__cdecl__)) atoi(const char *_Str);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _atoi_l(const char *_Str,_locale_t _Locale);
  long __attribute__((__cdecl__)) atol(const char *_Str);
  __attribute__ ((__dllimport__)) long __attribute__((__cdecl__)) _atol_l(const char *_Str,_locale_t _Locale);


  void *__attribute__((__cdecl__)) bsearch(const void *_Key,const void *_Base,size_t _NumOfElements,size_t _SizeOfElements,int (__attribute__((__cdecl__)) *_PtFuncCompare)(const void *,const void *));
  void __attribute__((__cdecl__)) qsort(void *_Base,size_t _NumOfElements,size_t _SizeOfElements,int (__attribute__((__cdecl__)) *_PtFuncCompare)(const void *,const void *));

  unsigned short __attribute__((__cdecl__)) _byteswap_ushort(unsigned short _Short);
  unsigned long __attribute__((__cdecl__)) _byteswap_ulong (unsigned long _Long);
  __extension__ unsigned long long __attribute__((__cdecl__)) _byteswap_uint64(unsigned long long _Int64);
  div_t __attribute__((__cdecl__)) div(int _Numerator,int _Denominator);
  char *__attribute__((__cdecl__)) getenv(const char *_VarName) ;
  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _itoa(int _Value,char *_Dest,int _Radix);
  __extension__ __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _i64toa(long long _Val,char *_DstBuf,int _Radix) ;
  __extension__ __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _ui64toa(unsigned long long _Val,char *_DstBuf,int _Radix) ;
  __extension__ __attribute__ ((__dllimport__)) long long __attribute__((__cdecl__)) _atoi64(const char *_String);
  __extension__ __attribute__ ((__dllimport__)) long long __attribute__((__cdecl__)) _atoi64_l(const char *_String,_locale_t _Locale);
  __extension__ __attribute__ ((__dllimport__)) long long __attribute__((__cdecl__)) _strtoi64(const char *_String,char **_EndPtr,int _Radix);
  __extension__ __attribute__ ((__dllimport__)) long long __attribute__((__cdecl__)) _strtoi64_l(const char *_String,char **_EndPtr,int _Radix,_locale_t _Locale);
  __extension__ __attribute__ ((__dllimport__)) unsigned long long __attribute__((__cdecl__)) _strtoui64(const char *_String,char **_EndPtr,int _Radix);
  __extension__ __attribute__ ((__dllimport__)) unsigned long long __attribute__((__cdecl__)) _strtoui64_l(const char *_String,char **_EndPtr,int _Radix,_locale_t _Locale);
  ldiv_t __attribute__((__cdecl__)) ldiv(long _Numerator,long _Denominator);
  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _ltoa(long _Value,char *_Dest,int _Radix) ;
  int __attribute__((__cdecl__)) mblen(const char *_Ch,size_t _MaxCount);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _mblen_l(const char *_Ch,size_t _MaxCount,_locale_t _Locale);
  __attribute__ ((__dllimport__)) size_t __attribute__((__cdecl__)) _mbstrlen(const char *_Str);
  __attribute__ ((__dllimport__)) size_t __attribute__((__cdecl__)) _mbstrlen_l(const char *_Str,_locale_t _Locale);
  __attribute__ ((__dllimport__)) size_t __attribute__((__cdecl__)) _mbstrnlen(const char *_Str,size_t _MaxCount);
  __attribute__ ((__dllimport__)) size_t __attribute__((__cdecl__)) _mbstrnlen_l(const char *_Str,size_t _MaxCount,_locale_t _Locale);
  int __attribute__((__cdecl__)) mbtowc(wchar_t * __restrict__ _DstCh,const char * __restrict__ _SrcCh,size_t _SrcSizeInBytes);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _mbtowc_l(wchar_t * __restrict__ _DstCh,const char * __restrict__ _SrcCh,size_t _SrcSizeInBytes,_locale_t _Locale);
  size_t __attribute__((__cdecl__)) mbstowcs(wchar_t * __restrict__ _Dest,const char * __restrict__ _Source,size_t _MaxCount);
  __attribute__ ((__dllimport__)) size_t __attribute__((__cdecl__)) _mbstowcs_l(wchar_t * __restrict__ _Dest,const char * __restrict__ _Source,size_t _MaxCount,_locale_t _Locale);
  int __attribute__((__cdecl__)) mkstemp(char *template_name);
  int __attribute__((__cdecl__)) rand(void);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _set_error_mode(int _Mode);
  void __attribute__((__cdecl__)) srand(unsigned int _Seed);
# 369 "C:/msys64/mingw64/include/stdlib.h" 3
inline __attribute__((__cdecl__))
double __attribute__((__cdecl__)) __attribute__ ((__nothrow__)) strtod(const char * __restrict__ _Str,char ** __restrict__ _EndPtr)
{
  double __attribute__((__cdecl__)) __mingw_strtod (const char * __restrict__, char ** __restrict__);
  return __mingw_strtod( _Str, _EndPtr);
}

inline __attribute__((__cdecl__))
float __attribute__((__cdecl__)) __attribute__ ((__nothrow__)) strtof(const char * __restrict__ _Str,char ** __restrict__ _EndPtr)
{
  float __attribute__((__cdecl__)) __mingw_strtof (const char * __restrict__, char ** __restrict__);
  return __mingw_strtof( _Str, _EndPtr);
}






  long double __attribute__((__cdecl__)) __attribute__ ((__nothrow__)) strtold(const char * __restrict__ , char ** __restrict__ );


  extern double __attribute__((__cdecl__)) __attribute__ ((__nothrow__))
  __strtod (const char * __restrict__ , char ** __restrict__);







  float __attribute__((__cdecl__)) __mingw_strtof (const char * __restrict__, char ** __restrict__);
  double __attribute__((__cdecl__)) __mingw_strtod (const char * __restrict__, char ** __restrict__);
  long double __attribute__((__cdecl__)) __mingw_strtold(const char * __restrict__, char ** __restrict__);

  __attribute__ ((__dllimport__)) float __attribute__((__cdecl__)) _strtof_l(const char * __restrict__ _Str,char ** __restrict__ _EndPtr,_locale_t _Locale);
  __attribute__ ((__dllimport__)) double __attribute__((__cdecl__)) _strtod_l(const char * __restrict__ _Str,char ** __restrict__ _EndPtr,_locale_t _Locale);
  long __attribute__((__cdecl__)) strtol(const char * __restrict__ _Str,char ** __restrict__ _EndPtr,int _Radix);
  __attribute__ ((__dllimport__)) long __attribute__((__cdecl__)) _strtol_l(const char * __restrict__ _Str,char ** __restrict__ _EndPtr,int _Radix,_locale_t _Locale);
  unsigned long __attribute__((__cdecl__)) strtoul(const char * __restrict__ _Str,char ** __restrict__ _EndPtr,int _Radix);
  __attribute__ ((__dllimport__)) unsigned long __attribute__((__cdecl__)) _strtoul_l(const char * __restrict__ _Str,char ** __restrict__ _EndPtr,int _Radix,_locale_t _Locale);


  int __attribute__((__cdecl__)) system(const char *_Command);

  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _ultoa(unsigned long _Value,char *_Dest,int _Radix) ;
  int __attribute__((__cdecl__)) wctomb(char *_MbCh,wchar_t _WCh) ;
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wctomb_l(char *_MbCh,wchar_t _WCh,_locale_t _Locale) ;
  size_t __attribute__((__cdecl__)) wcstombs(char * __restrict__ _Dest,const wchar_t * __restrict__ _Source,size_t _MaxCount) ;
  __attribute__ ((__dllimport__)) size_t __attribute__((__cdecl__)) _wcstombs_l(char * __restrict__ _Dest,const wchar_t * __restrict__ _Source,size_t _MaxCount,_locale_t _Locale) ;
# 452 "C:/msys64/mingw64/include/stdlib.h" 3
  void *__attribute__((__cdecl__)) calloc(size_t _NumOfElements,size_t _SizeOfElements);
  void __attribute__((__cdecl__)) free(void *_Memory);
  void *__attribute__((__cdecl__)) malloc(size_t _Size);
  void *__attribute__((__cdecl__)) realloc(void *_Memory,size_t _NewSize);
  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _aligned_free(void *_Memory);
  __attribute__ ((__dllimport__)) void *__attribute__((__cdecl__)) _aligned_malloc(size_t _Size,size_t _Alignment);
  __attribute__ ((__dllimport__)) void *__attribute__((__cdecl__)) _aligned_offset_malloc(size_t _Size,size_t _Alignment,size_t _Offset);
  __attribute__ ((__dllimport__)) void *__attribute__((__cdecl__)) _aligned_realloc(void *_Memory,size_t _Size,size_t _Alignment);
  __attribute__ ((__dllimport__)) void *__attribute__((__cdecl__)) _aligned_offset_realloc(void *_Memory,size_t _Size,size_t _Alignment,size_t _Offset);
  __attribute__ ((__dllimport__)) void *__attribute__((__cdecl__)) _recalloc(void *_Memory,size_t _Count,size_t _Size);
  __attribute__ ((__dllimport__)) void *__attribute__((__cdecl__)) _aligned_recalloc(void *_Memory,size_t _Count,size_t _Size,size_t _Alignment);
  __attribute__ ((__dllimport__)) void *__attribute__((__cdecl__)) _aligned_offset_recalloc(void *_Memory,size_t _Count,size_t _Size,size_t _Alignment,size_t _Offset);
  __attribute__ ((__dllimport__)) size_t __attribute__((__cdecl__)) _aligned_msize(void *_Memory,size_t _Alignment,size_t _Offset);
# 487 "C:/msys64/mingw64/include/stdlib.h" 3
  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _itow(int _Value,wchar_t *_Dest,int _Radix) ;
  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _ltow(long _Value,wchar_t *_Dest,int _Radix) ;
  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _ultow(unsigned long _Value,wchar_t *_Dest,int _Radix) ;

  double __attribute__((__cdecl__)) __mingw_wcstod(const wchar_t * __restrict__ _Str,wchar_t ** __restrict__ _EndPtr);
  float __attribute__((__cdecl__)) __mingw_wcstof(const wchar_t * __restrict__ nptr, wchar_t ** __restrict__ endptr);
  long double __attribute__((__cdecl__)) __mingw_wcstold(const wchar_t * __restrict__, wchar_t ** __restrict__);


  inline __attribute__((__cdecl__))
  double __attribute__((__cdecl__)) wcstod(const wchar_t * __restrict__ _Str,wchar_t ** __restrict__ _EndPtr){
    return __mingw_wcstod(_Str,_EndPtr);
  }
  inline __attribute__((__cdecl__))
  float __attribute__((__cdecl__)) wcstof(const wchar_t * __restrict__ _Str,wchar_t ** __restrict__ _EndPtr){
    return __mingw_wcstof(_Str,_EndPtr);
  }






  long double __attribute__((__cdecl__)) wcstold(const wchar_t * __restrict__, wchar_t ** __restrict__);

  __attribute__ ((__dllimport__)) double __attribute__((__cdecl__)) _wcstod_l(const wchar_t * __restrict__ _Str,wchar_t ** __restrict__ _EndPtr,_locale_t _Locale);
  __attribute__ ((__dllimport__)) float __attribute__((__cdecl__)) _wcstof_l(const wchar_t * __restrict__ _Str,wchar_t ** __restrict__ _EndPtr,_locale_t _Locale);
  long __attribute__((__cdecl__)) wcstol(const wchar_t * __restrict__ _Str,wchar_t ** __restrict__ _EndPtr,int _Radix);
  __attribute__ ((__dllimport__)) long __attribute__((__cdecl__)) _wcstol_l(const wchar_t * __restrict__ _Str,wchar_t ** __restrict__ _EndPtr,int _Radix,_locale_t _Locale);
  unsigned long __attribute__((__cdecl__)) wcstoul(const wchar_t * __restrict__ _Str,wchar_t ** __restrict__ _EndPtr,int _Radix);
  __attribute__ ((__dllimport__)) unsigned long __attribute__((__cdecl__)) _wcstoul_l(const wchar_t * __restrict__ _Str,wchar_t ** __restrict__ _EndPtr,int _Radix,_locale_t _Locale);
  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _wgetenv(const wchar_t *_VarName) ;


  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wsystem(const wchar_t *_Command);

  __attribute__ ((__dllimport__)) double __attribute__((__cdecl__)) _wtof(const wchar_t *_Str);
  __attribute__ ((__dllimport__)) double __attribute__((__cdecl__)) _wtof_l(const wchar_t *_Str,_locale_t _Locale);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wtoi(const wchar_t *_Str);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wtoi_l(const wchar_t *_Str,_locale_t _Locale);
  __attribute__ ((__dllimport__)) long __attribute__((__cdecl__)) _wtol(const wchar_t *_Str);
  __attribute__ ((__dllimport__)) long __attribute__((__cdecl__)) _wtol_l(const wchar_t *_Str,_locale_t _Locale);

  __extension__ __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _i64tow(long long _Val,wchar_t *_DstBuf,int _Radix) ;
  __extension__ __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _ui64tow(unsigned long long _Val,wchar_t *_DstBuf,int _Radix) ;
  __extension__ __attribute__ ((__dllimport__)) long long __attribute__((__cdecl__)) _wtoi64(const wchar_t *_Str);
  __extension__ __attribute__ ((__dllimport__)) long long __attribute__((__cdecl__)) _wtoi64_l(const wchar_t *_Str,_locale_t _Locale);
  __extension__ __attribute__ ((__dllimport__)) long long __attribute__((__cdecl__)) _wcstoi64(const wchar_t *_Str,wchar_t **_EndPtr,int _Radix);
  __extension__ __attribute__ ((__dllimport__)) long long __attribute__((__cdecl__)) _wcstoi64_l(const wchar_t *_Str,wchar_t **_EndPtr,int _Radix,_locale_t _Locale);
  __extension__ __attribute__ ((__dllimport__)) unsigned long long __attribute__((__cdecl__)) _wcstoui64(const wchar_t *_Str,wchar_t **_EndPtr,int _Radix);
  __extension__ __attribute__ ((__dllimport__)) unsigned long long __attribute__((__cdecl__)) _wcstoui64_l(const wchar_t *_Str ,wchar_t **_EndPtr,int _Radix,_locale_t _Locale);


  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _putenv(const char *_EnvString);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wputenv(const wchar_t *_EnvString);
# 550 "C:/msys64/mingw64/include/stdlib.h" 3
  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _fullpath(char *_FullPath,const char *_Path,size_t _SizeInBytes);




  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _ecvt(double _Val,int _NumOfDigits,int *_PtDec,int *_PtSign) ;
  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _fcvt(double _Val,int _NumOfDec,int *_PtDec,int *_PtSign) ;
  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _gcvt(double _Val,int _NumOfDigits,char *_DstBuf) ;
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _atodbl(_CRT_DOUBLE *_Result,char *_Str);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _atoldbl(_LDOUBLE *_Result,char *_Str);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _atoflt(_CRT_FLOAT *_Result,char *_Str);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _atodbl_l(_CRT_DOUBLE *_Result,char *_Str,_locale_t _Locale);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _atoldbl_l(_LDOUBLE *_Result,char *_Str,_locale_t _Locale);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _atoflt_l(_CRT_FLOAT *_Result,char *_Str,_locale_t _Locale);
# 579 "C:/msys64/mingw64/include/stdlib.h" 3
unsigned long __attribute__((__cdecl__)) _lrotl(unsigned long,int);
unsigned long __attribute__((__cdecl__)) _lrotr(unsigned long,int);





  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _makepath(char *_Path,const char *_Drive,const char *_Dir,const char *_Filename,const char *_Ext);
  _onexit_t __attribute__((__cdecl__)) _onexit(_onexit_t _Func);



  void __attribute__((__cdecl__)) perror(const char *_ErrMsg);

       
       


  __extension__ unsigned long long __attribute__((__cdecl__)) _rotl64(unsigned long long _Val,int _Shift);
  __extension__ unsigned long long __attribute__((__cdecl__)) _rotr64(unsigned long long Value,int Shift);
       
       
       
       


  unsigned int __attribute__((__cdecl__)) _rotr(unsigned int _Val,int _Shift);
  unsigned int __attribute__((__cdecl__)) _rotl(unsigned int _Val,int _Shift);
       
       
  __extension__ unsigned long long __attribute__((__cdecl__)) _rotr64(unsigned long long _Val,int _Shift);
  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _searchenv(const char *_Filename,const char *_EnvVar,char *_ResultPath) ;
  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _splitpath(const char *_FullPath,char *_Drive,char *_Dir,char *_Filename,char *_Ext) ;
  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _swab(char *_Buf1,char *_Buf2,int _SizeInBytes);







  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _wfullpath(wchar_t *_FullPath,const wchar_t *_Path,size_t _SizeInWords);



  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _wmakepath(wchar_t *_ResultPath,const wchar_t *_Drive,const wchar_t *_Dir,const wchar_t *_Filename,const wchar_t *_Ext);


  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _wperror(const wchar_t *_ErrMsg);

  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _wsearchenv(const wchar_t *_Filename,const wchar_t *_EnvVar,wchar_t *_ResultPath) ;
  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _wsplitpath(const wchar_t *_FullPath,wchar_t *_Drive,wchar_t *_Dir,wchar_t *_Filename,wchar_t *_Ext) ;


  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _beep(unsigned _Frequency,unsigned _Duration) __attribute__ ((__deprecated__));

  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _seterrormode(int _Mode) __attribute__ ((__deprecated__));
  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _sleep(unsigned long _Duration) __attribute__ ((__deprecated__));
# 657 "C:/msys64/mingw64/include/stdlib.h" 3
  char *__attribute__((__cdecl__)) ecvt(double _Val,int _NumOfDigits,int *_PtDec,int *_PtSign) ;
  char *__attribute__((__cdecl__)) fcvt(double _Val,int _NumOfDec,int *_PtDec,int *_PtSign) ;
  char *__attribute__((__cdecl__)) gcvt(double _Val,int _NumOfDigits,char *_DstBuf) ;
  char *__attribute__((__cdecl__)) itoa(int _Val,char *_DstBuf,int _Radix) ;
  char *__attribute__((__cdecl__)) ltoa(long _Val,char *_DstBuf,int _Radix) ;
  int __attribute__((__cdecl__)) putenv(const char *_EnvString) ;



  void __attribute__((__cdecl__)) swab(char *_Buf1,char *_Buf2,int _SizeInBytes) ;


  char *__attribute__((__cdecl__)) ultoa(unsigned long _Val,char *_Dstbuf,int _Radix) ;
  _onexit_t __attribute__((__cdecl__)) onexit(_onexit_t _Func);





  typedef struct { __extension__ long long quot, rem; } lldiv_t;

  __extension__ lldiv_t __attribute__((__cdecl__)) lldiv(long long, long long);

  __extension__ long long __attribute__((__cdecl__)) llabs(long long);




  __extension__ long long __attribute__((__cdecl__)) strtoll(const char * __restrict__, char ** __restrict, int);
  __extension__ unsigned long long __attribute__((__cdecl__)) strtoull(const char * __restrict__, char ** __restrict__, int);


  __extension__ long long __attribute__((__cdecl__)) atoll (const char *);


  __extension__ long long __attribute__((__cdecl__)) wtoll (const wchar_t *);
  __extension__ char *__attribute__((__cdecl__)) lltoa (long long, char *, int);
  __extension__ char *__attribute__((__cdecl__)) ulltoa (unsigned long long , char *, int);
  __extension__ wchar_t *__attribute__((__cdecl__)) lltow (long long, wchar_t *, int);
  __extension__ wchar_t *__attribute__((__cdecl__)) ulltow (unsigned long long, wchar_t *, int);
# 711 "C:/msys64/mingw64/include/stdlib.h" 3
}


#pragma pack(pop)

# 1 "C:/msys64/mingw64/include/sec_api/stdlib_s.h" 1 3
# 9 "C:/msys64/mingw64/include/sec_api/stdlib_s.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/stdlib.h" 1 3
# 30 "C:/msys64/mingw64/include/c++/15.2.0/stdlib.h" 3
# 1 "C:/msys64/mingw64/include/stdlib.h" 1 3
# 31 "C:/msys64/mingw64/include/c++/15.2.0/stdlib.h" 2 3
# 10 "C:/msys64/mingw64/include/sec_api/stdlib_s.h" 2 3


extern "C" {






  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _dupenv_s(char **_PBuffer,size_t *_PBufferSizeInBytes,const char *_VarName);




  __attribute__ ((__dllimport__)) void * __attribute__((__cdecl__)) bsearch_s(const void *_Key,const void *_Base,rsize_t _NumOfElements,rsize_t _SizeOfElements,int (__attribute__((__cdecl__)) * _PtFuncCompare)(void *, const void *, const void *), void *_Context);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) getenv_s(size_t *_ReturnSize,char *_DstBuf,rsize_t _DstSize,const char *_VarName);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) getenv_s(size_t * _ReturnSize, char (&_Dest)[__size], const char * _VarName) { return getenv_s(_ReturnSize, _Dest, __size, _VarName); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _itoa_s(int _Value,char *_DstBuf,size_t _Size,int _Radix);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _itoa_s(int _Value, char (&_Dest)[__size], int _Radix) { return _itoa_s(_Value, _Dest, __size, _Radix); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _i64toa_s(long long _Val,char *_DstBuf,size_t _Size,int _Radix);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _ui64toa_s(unsigned long long _Val,char *_DstBuf,size_t _Size,int _Radix);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _ltoa_s(long _Val,char *_DstBuf,size_t _Size,int _Radix);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _ltoa_s(long _Value, char (&_Dest)[__size], int _Radix) { return _ltoa_s(_Value, _Dest, __size, _Radix); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) mbstowcs_s(size_t *_PtNumOfCharConverted,wchar_t *_DstBuf,size_t _SizeInWords,const char *_SrcBuf,size_t _MaxCount);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) mbstowcs_s(size_t * _PtNumOfCharConverted, wchar_t (&_Dest)[__size], const char * _Source, size_t _MaxCount) { return mbstowcs_s(_PtNumOfCharConverted, _Dest, __size, _Source, _MaxCount); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _mbstowcs_s_l(size_t *_PtNumOfCharConverted,wchar_t *_DstBuf,size_t _SizeInWords,const char *_SrcBuf,size_t _MaxCount,_locale_t _Locale);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _mbstowcs_s_l(size_t * _PtNumOfCharConverted, wchar_t (&_Dest)[__size], const char * _Source, size_t _MaxCount, _locale_t _Locale) { return _mbstowcs_s_l(_PtNumOfCharConverted, _Dest, __size, _Source, _MaxCount, _Locale); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _ultoa_s(unsigned long _Val,char *_DstBuf,size_t _Size,int _Radix);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _ultoa_s(unsigned long _Value, char (&_Dest)[__size], int _Radix) { return _ultoa_s(_Value, _Dest, __size, _Radix); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) wctomb_s(int *_SizeConverted,char *_MbCh,rsize_t _SizeInBytes,wchar_t _WCh);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wctomb_s_l(int *_SizeConverted,char *_MbCh,size_t _SizeInBytes,wchar_t _WCh,_locale_t _Locale);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) wcstombs_s(size_t *_PtNumOfCharConverted,char *_Dst,size_t _DstSizeInBytes,const wchar_t *_Src,size_t _MaxCountInBytes);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) wcstombs_s(size_t* _PtNumOfCharConverted, char (&_Dst)[__size], const wchar_t* _Src, size_t _MaxCountInBytes) { return wcstombs_s(_PtNumOfCharConverted, _Dst, __size, _Src, _MaxCountInBytes); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wcstombs_s_l(size_t *_PtNumOfCharConverted,char *_Dst,size_t _DstSizeInBytes,const wchar_t *_Src,size_t _MaxCountInBytes,_locale_t _Locale);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _wcstombs_s_l(size_t* _PtNumOfCharConverted, char (&_Dst)[__size], const wchar_t* _Src, size_t _MaxCountInBytes, _locale_t _Locale) { return _wcstombs_s_l(_PtNumOfCharConverted, _Dst, __size, _Src, _MaxCountInBytes, _Locale); } }


  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _ecvt_s(char *_DstBuf,size_t _Size,double _Val,int _NumOfDights,int *_PtDec,int *_PtSign);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _fcvt_s(char *_DstBuf,size_t _Size,double _Val,int _NumOfDec,int *_PtDec,int *_PtSign);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _gcvt_s(char *_DstBuf,size_t _Size,double _Val,int _NumOfDigits);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _makepath_s(char *_PathResult,size_t _Size,const char *_Drive,const char *_Dir,const char *_Filename,const char *_Ext);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _makepath_s(char (&_PathResult)[__size], const char* _Drive, const char* _Dir, const char* _Filename, const char* _Ext) { return _makepath_s(_PathResult,__size,_Drive,_Dir,_Filename,_Ext); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _putenv_s(const char *_Name,const char *_Value);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _searchenv_s(const char *_Filename,const char *_EnvVar,char *_ResultPath,size_t _SizeInBytes);

  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _splitpath_s(const char *_FullPath,char *_Drive,size_t _DriveSize,char *_Dir,size_t _DirSize,char *_Filename,size_t _FilenameSize,char *_Ext,size_t _ExtSize);
  extern "C++" { template <size_t __drive_size, size_t __dir_size, size_t __name_size, size_t __ext_size> inline errno_t __attribute__((__cdecl__)) _splitpath_s(const char *_Dest, char (&__drive)[__drive_size], char (&__dir)[__dir_size], char (&__name)[__name_size], char (&__ext)[__ext_size]) { return _splitpath_s(_Dest, __drive, __drive_size, __dir, __dir_size, __name, __name_size, __ext, __ext_size); } }



  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) qsort_s(void *_Base,size_t _NumOfElements,size_t _SizeOfElements,int (__attribute__((__cdecl__)) *_PtFuncCompare)(void *,const void *,const void *),void *_Context);





}
# 717 "C:/msys64/mingw64/include/stdlib.h" 2 3
# 1 "C:/msys64/mingw64/include/malloc.h" 1 3
# 11 "C:/msys64/mingw64/include/malloc.h" 3
#pragma pack(push,_CRT_PACKING)


extern "C" {
# 52 "C:/msys64/mingw64/include/malloc.h" 3
  typedef struct _heapinfo {
    int *_pentry;
    size_t _size;
    int _useflag;
  } _HEAPINFO;



  __attribute__ ((__dllimport__)) unsigned int *__attribute__((__cdecl__)) __p__amblksiz(void);
# 129 "C:/msys64/mingw64/include/malloc.h" 3
void * __mingw_aligned_malloc (size_t _Size, size_t _Alignment);
void __mingw_aligned_free (void *_Memory);
void * __mingw_aligned_offset_realloc (void *_Memory, size_t _Size, size_t _Alignment, size_t _Offset);
void * __mingw_aligned_offset_malloc (size_t, size_t, size_t);
void * __mingw_aligned_realloc (void *_Memory, size_t _Size, size_t _Offset);
size_t __mingw_aligned_msize (void *memblock, size_t alignment, size_t offset);



# 1 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/mm_malloc.h" 1 3 4
# 27 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/mm_malloc.h" 3 4
# 1 "C:/msys64/mingw64/include/c++/15.2.0/stdlib.h" 1 3 4
# 28 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/mm_malloc.h" 2 3 4

# 1 "C:/msys64/mingw64/include/errno.h" 1 3 4
# 12 "C:/msys64/mingw64/include/errno.h" 3 4
extern "C" {
# 239 "C:/msys64/mingw64/include/errno.h" 3 4
}
# 30 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/mm_malloc.h" 2 3 4


static __inline__ void *
_mm_malloc (size_t __size, size_t __align)
{
  void * __malloc_ptr;
  void * __aligned_ptr;


  if (__align & (__align - 1))
    {

      (*_errno()) = 22;

      return ((void *) 0);
    }

  if (__size == 0)
    return ((void *) 0);





    if (__align < 2 * sizeof (void *))
      __align = 2 * sizeof (void *);

  __malloc_ptr = malloc (__size + __align);
  if (!__malloc_ptr)
    return ((void *) 0);


  __aligned_ptr = (void *) (((size_t) __malloc_ptr + __align)
       & ~((size_t) (__align) - 1));


  ((void **) __aligned_ptr)[-1] = __malloc_ptr;

  return __aligned_ptr;
}

static __inline__ void
_mm_free (void *__aligned_ptr)
{
  if (__aligned_ptr)
    free (((void **) __aligned_ptr)[-1]);
}
# 139 "C:/msys64/mingw64/include/malloc.h" 2 3





  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _resetstkoflw (void);

  __attribute__ ((__dllimport__)) unsigned long __attribute__((__cdecl__)) _set_malloc_crt_max_wait(unsigned long _NewValue);







  __attribute__ ((__dllimport__)) void *__attribute__((__cdecl__)) _expand(void *_Memory,size_t _NewSize);
  __attribute__ ((__dllimport__)) size_t __attribute__((__cdecl__)) _msize(void *_Memory);
# 167 "C:/msys64/mingw64/include/malloc.h" 3
  __attribute__ ((__dllimport__)) size_t __attribute__((__cdecl__)) _get_sbh_threshold(void);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _set_sbh_threshold(size_t _NewValue);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _set_amblksiz(size_t _Value);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _get_amblksiz(size_t *_Value);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _heapadd(void *_Memory,size_t _Size);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _heapchk(void);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _heapmin(void);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _heapset(unsigned int _Fill);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _heapwalk(_HEAPINFO *_EntryInfo);
  __attribute__ ((__dllimport__)) size_t __attribute__((__cdecl__)) _heapused(size_t *_Used,size_t *_Commit);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _get_heap_handle(void);
# 190 "C:/msys64/mingw64/include/malloc.h" 3
  static __inline void *_MarkAllocaS(void *_Ptr,unsigned int _Marker) {
    if(_Ptr) {
      *((unsigned int*)_Ptr) = _Marker;
      _Ptr = (char*)_Ptr + 16;
    }
    return _Ptr;
  }
# 218 "C:/msys64/mingw64/include/malloc.h" 3
  static __inline void __attribute__((__cdecl__)) _freea(void *_Memory) {
    unsigned int _Marker;
    if(_Memory) {
      _Memory = (char*)_Memory - 16;
      _Marker = *(unsigned int *)_Memory;
      if(_Marker==0xDDDD) {
 free(_Memory);
      }





    }
  }
# 261 "C:/msys64/mingw64/include/malloc.h" 3
}


#pragma pack(pop)
# 718 "C:/msys64/mingw64/include/stdlib.h" 2 3
# 84 "C:/msys64/mingw64/include/c++/15.2.0/cstdlib" 2 3

#pragma GCC diagnostic pop

# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/std_abs.h" 1 3
# 39 "C:/msys64/mingw64/include/c++/15.2.0/bits/std_abs.h" 3
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wpedantic"
#pragma GCC diagnostic ignored "-Wlong-long"
# 52 "C:/msys64/mingw64/include/c++/15.2.0/bits/std_abs.h" 3
extern "C++"
{
namespace std
{


  using ::abs;


  inline long
  abs(long __i) { return __builtin_labs(__i); }



  inline long long
  abs(long long __x) { return __builtin_llabs (__x); }
# 76 "C:/msys64/mingw64/include/c++/15.2.0/bits/std_abs.h" 3
  inline constexpr double
  abs(double __x)
  { return __builtin_fabs(__x); }

  inline constexpr float
  abs(float __x)
  { return __builtin_fabsf(__x); }

  inline constexpr long double
  abs(long double __x)
  { return __builtin_fabsl(__x); }



  __extension__ inline constexpr __int128
  abs(__int128 __x) { return __x >= 0 ? __x : -__x; }
# 141 "C:/msys64/mingw64/include/c++/15.2.0/bits/std_abs.h" 3
  __extension__ inline constexpr
  __float128
  abs(__float128 __x)
  {






    return __builtin_signbit(__x) ? -__x : __x;

  }



}
}

#pragma GCC diagnostic pop
# 88 "C:/msys64/mingw64/include/c++/15.2.0/cstdlib" 2 3
# 131 "C:/msys64/mingw64/include/c++/15.2.0/cstdlib" 3
extern "C++"
{
namespace std
{


  using ::div_t;
  using ::ldiv_t;

  using ::abort;



  using ::atexit;





  using ::atof;
  using ::atoi;
  using ::atol;
  using ::bsearch;
  using ::calloc;
  using ::div;
  using ::exit;
  using ::free;
  using ::getenv;
  using ::labs;
  using ::ldiv;
  using ::malloc;

  using ::mblen;
  using ::mbstowcs;
  using ::mbtowc;

  using ::qsort;





  using ::rand;
  using ::realloc;
  using ::srand;
  using ::strtod;
  using ::strtol;
  using ::strtoul;
  using ::system;

  using ::wcstombs;
  using ::wctomb;



  inline ldiv_t
  div(long __i, long __j) noexcept { return ldiv(__i, __j); }




}
# 205 "C:/msys64/mingw64/include/c++/15.2.0/cstdlib" 3
namespace __gnu_cxx
{



  using ::lldiv_t;





  using ::_Exit;



#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wlong-long"
  using ::llabs;

  inline lldiv_t
  div(long long __n, long long __d)
  { lldiv_t __q; __q.quot = __n / __d; __q.rem = __n % __d; return __q; }

  using ::lldiv;
#pragma GCC diagnostic pop
# 240 "C:/msys64/mingw64/include/c++/15.2.0/cstdlib" 3
  using ::atoll;
  using ::strtoll;
  using ::strtoull;

  using ::strtof;
  using ::strtold;


}

namespace std
{

  using ::__gnu_cxx::lldiv_t;

  using ::__gnu_cxx::_Exit;

  using ::__gnu_cxx::llabs;
  using ::__gnu_cxx::div;
  using ::__gnu_cxx::lldiv;

  using ::__gnu_cxx::atoll;
  using ::__gnu_cxx::strtof;
  using ::__gnu_cxx::strtoll;
  using ::__gnu_cxx::strtoull;
  using ::__gnu_cxx::strtold;
}
# 284 "C:/msys64/mingw64/include/c++/15.2.0/cstdlib" 3
}
# 2823 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 2
# 1 "C:/msys64/mingw64/include/c++/15.2.0/cstring" 1 3
# 47 "C:/msys64/mingw64/include/c++/15.2.0/cstring" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 48 "C:/msys64/mingw64/include/c++/15.2.0/cstring" 2 3
# 1 "C:/msys64/mingw64/include/string.h" 1 3
# 21 "C:/msys64/mingw64/include/string.h" 3
extern "C" {
# 45 "C:/msys64/mingw64/include/string.h" 3
  __attribute__ ((__dllimport__)) void *__attribute__((__cdecl__)) _memccpy(void *_Dst,const void *_Src,int _Val,size_t _MaxCount);
  void *__attribute__((__cdecl__)) memchr(const void *_Buf ,int _Val,size_t _MaxCount);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _memicmp(const void *_Buf1,const void *_Buf2,size_t _Size);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _memicmp_l(const void *_Buf1,const void *_Buf2,size_t _Size,_locale_t _Locale);
  int __attribute__((__cdecl__)) memcmp(const void *_Buf1,const void *_Buf2,size_t _Size);
  void * __attribute__((__cdecl__)) memcpy(void * __restrict__ _Dst,const void * __restrict__ _Src,size_t _Size) ;
  __attribute__((dllimport)) errno_t __attribute__((__cdecl__)) memcpy_s (void *_dest,size_t _numberOfElements,const void *_src,size_t _count);
  void * __attribute__((__cdecl__)) mempcpy (void *_Dst, const void *_Src, size_t _Size);
  void * __attribute__((__cdecl__)) memset(void *_Dst,int _Val,size_t _Size);

  void * __attribute__((__cdecl__)) memccpy(void *_Dst,const void *_Src,int _Val,size_t _Size) ;
  int __attribute__((__cdecl__)) memicmp(const void *_Buf1,const void *_Buf2,size_t _Size) ;


  char * __attribute__((__cdecl__)) _strset(char *_Str,int _Val) ;
  char * __attribute__((__cdecl__)) _strset_l(char *_Str,int _Val,_locale_t _Locale) ;
  char * __attribute__((__cdecl__)) strcpy(char * __restrict__ _Dest,const char * __restrict__ _Source);
  char * __attribute__((__cdecl__)) strcat(char * __restrict__ _Dest,const char * __restrict__ _Source);
  int __attribute__((__cdecl__)) strcmp(const char *_Str1,const char *_Str2);
  size_t __attribute__((__cdecl__)) strlen(const char *_Str);
  size_t __attribute__((__cdecl__)) strnlen(const char *_Str,size_t _MaxCount);
  void *__attribute__((__cdecl__)) memmove(void *_Dst,const void *_Src,size_t _Size) ;




  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _strdup(const char *_Src);



  char *__attribute__((__cdecl__)) strchr(const char *_Str,int _Val);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _stricmp(const char *_Str1,const char *_Str2);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _strcmpi(const char *_Str1,const char *_Str2);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _stricmp_l(const char *_Str1,const char *_Str2,_locale_t _Locale);
  int __attribute__((__cdecl__)) strcoll(const char *_Str1,const char *_Str2);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _strcoll_l(const char *_Str1,const char *_Str2,_locale_t _Locale);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _stricoll(const char *_Str1,const char *_Str2);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _stricoll_l(const char *_Str1,const char *_Str2,_locale_t _Locale);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _strncoll (const char *_Str1,const char *_Str2,size_t _MaxCount);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _strncoll_l(const char *_Str1,const char *_Str2,size_t _MaxCount,_locale_t _Locale);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _strnicoll (const char *_Str1,const char *_Str2,size_t _MaxCount);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _strnicoll_l(const char *_Str1,const char *_Str2,size_t _MaxCount,_locale_t _Locale);
  size_t __attribute__((__cdecl__)) strcspn(const char *_Str,const char *_Control);
  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _strerror(const char *_ErrMsg) ;
  char *__attribute__((__cdecl__)) strerror(int) ;
  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _strlwr(char *_String) ;
  char *strlwr_l(char *_String,_locale_t _Locale) ;
  char *__attribute__((__cdecl__)) strncat(char * __restrict__ _Dest,const char * __restrict__ _Source,size_t _Count) ;
  int __attribute__((__cdecl__)) strncmp(const char *_Str1,const char *_Str2,size_t _MaxCount);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _strnicmp(const char *_Str1,const char *_Str2,size_t _MaxCount);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _strnicmp_l(const char *_Str1,const char *_Str2,size_t _MaxCount,_locale_t _Locale);
  char *strncpy(char * __restrict__ _Dest,const char * __restrict__ _Source,size_t _Count) ;
  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _strnset(char *_Str,int _Val,size_t _MaxCount) ;
  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _strnset_l(char *str,int c,size_t count,_locale_t _Locale) ;
  char *__attribute__((__cdecl__)) strpbrk(const char *_Str,const char *_Control);
  char *__attribute__((__cdecl__)) strrchr(const char *_Str,int _Ch);
  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _strrev(char *_Str);
  size_t __attribute__((__cdecl__)) strspn(const char *_Str,const char *_Control);
  char *__attribute__((__cdecl__)) strstr(const char *_Str,const char *_SubStr);
  char *__attribute__((__cdecl__)) strtok(char * __restrict__ _Str,const char * __restrict__ _Delim) ;
       

  char *strtok_r(char * __restrict__ _Str, const char * __restrict__ _Delim, char ** __restrict__ __last);
       
  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _strupr(char *_String) ;
  __attribute__ ((__dllimport__)) char *_strupr_l(char *_String,_locale_t _Locale) ;
  size_t __attribute__((__cdecl__)) strxfrm(char * __restrict__ _Dst,const char * __restrict__ _Src,size_t _MaxCount);
  __attribute__ ((__dllimport__)) size_t __attribute__((__cdecl__)) _strxfrm_l(char * __restrict__ _Dst,const char * __restrict__ _Src,size_t _MaxCount,_locale_t _Locale);






  char *__attribute__((__cdecl__)) strdup(const char *_Src) ;



  int __attribute__((__cdecl__)) strcmpi(const char *_Str1,const char *_Str2) ;
  int __attribute__((__cdecl__)) stricmp(const char *_Str1,const char *_Str2) ;
  char *__attribute__((__cdecl__)) strlwr(char *_Str) ;
  int __attribute__((__cdecl__)) strnicmp(const char *_Str1,const char *_Str,size_t _MaxCount) ;
  int __attribute__((__cdecl__)) strncasecmp (const char *, const char *, size_t);
  int __attribute__((__cdecl__)) strcasecmp (const char *, const char *);







  char *__attribute__((__cdecl__)) strnset(char *_Str,int _Val,size_t _MaxCount) ;
  char *__attribute__((__cdecl__)) strrev(char *_Str) ;
  char *__attribute__((__cdecl__)) strset(char *_Str,int _Val) ;
  char *__attribute__((__cdecl__)) strupr(char *_Str) ;
# 149 "C:/msys64/mingw64/include/string.h" 3
  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _wcsdup(const wchar_t *_Str);



  wchar_t *__attribute__((__cdecl__)) wcscat(wchar_t * __restrict__ _Dest,const wchar_t * __restrict__ _Source) ;
  wchar_t *__attribute__((__cdecl__)) wcschr(const wchar_t *_Str,wchar_t _Ch);
  int __attribute__((__cdecl__)) wcscmp(const wchar_t *_Str1,const wchar_t *_Str2);
  wchar_t *__attribute__((__cdecl__)) wcscpy(wchar_t * __restrict__ _Dest,const wchar_t * __restrict__ _Source) ;
  size_t __attribute__((__cdecl__)) wcscspn(const wchar_t *_Str,const wchar_t *_Control);
  size_t __attribute__((__cdecl__)) wcslen(const wchar_t *_Str);
  size_t __attribute__((__cdecl__)) wcsnlen(const wchar_t *_Src,size_t _MaxCount);
  wchar_t *wcsncat(wchar_t * __restrict__ _Dest,const wchar_t * __restrict__ _Source,size_t _Count) ;
  int __attribute__((__cdecl__)) wcsncmp(const wchar_t *_Str1,const wchar_t *_Str2,size_t _MaxCount);
  wchar_t *wcsncpy(wchar_t * __restrict__ _Dest,const wchar_t * __restrict__ _Source,size_t _Count) ;
  wchar_t *__attribute__((__cdecl__)) _wcsncpy_l(wchar_t * __restrict__ _Dest,const wchar_t * __restrict__ _Source,size_t _Count,_locale_t _Locale) ;
  wchar_t *__attribute__((__cdecl__)) wcspbrk(const wchar_t *_Str,const wchar_t *_Control);
  wchar_t *__attribute__((__cdecl__)) wcsrchr(const wchar_t *_Str,wchar_t _Ch);
  size_t __attribute__((__cdecl__)) wcsspn(const wchar_t *_Str,const wchar_t *_Control);
  wchar_t *__attribute__((__cdecl__)) wcsstr(const wchar_t *_Str,const wchar_t *_SubStr);
  wchar_t *__attribute__((__cdecl__)) wcstok(wchar_t * __restrict__ _Str,const wchar_t * __restrict__ _Delim,wchar_t ** __restrict__ _Ptr) ;
  wchar_t *__attribute__((__cdecl__)) _wcstok(wchar_t * __restrict__ _Str,const wchar_t * __restrict__ _Delim) ;




  extern "C++" inline wchar_t *__attribute__((__cdecl__)) wcstok(wchar_t * __restrict__ _Str,const wchar_t * __restrict__ _Delim) { return _wcstok(_Str, _Delim); }

  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _wcserror(int _ErrNum) ;
  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) __wcserror(const wchar_t *_Str) ;
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wcsicmp(const wchar_t *_Str1,const wchar_t *_Str2);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wcsicmp_l(const wchar_t *_Str1,const wchar_t *_Str2,_locale_t _Locale);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wcsnicmp(const wchar_t *_Str1,const wchar_t *_Str2,size_t _MaxCount);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wcsnicmp_l(const wchar_t *_Str1,const wchar_t *_Str2,size_t _MaxCount,_locale_t _Locale);
  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _wcsnset(wchar_t *_Str,wchar_t _Val,size_t _MaxCount) ;
  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _wcsrev(wchar_t *_Str);
  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _wcsset(wchar_t *_Str,wchar_t _Val) ;
  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _wcslwr(wchar_t *_String) ;
  __attribute__ ((__dllimport__)) wchar_t *_wcslwr_l(wchar_t *_String,_locale_t _Locale) ;
  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _wcsupr(wchar_t *_String) ;
  __attribute__ ((__dllimport__)) wchar_t *_wcsupr_l(wchar_t *_String,_locale_t _Locale) ;
  size_t __attribute__((__cdecl__)) wcsxfrm(wchar_t * __restrict__ _Dst,const wchar_t * __restrict__ _Src,size_t _MaxCount);
  __attribute__ ((__dllimport__)) size_t __attribute__((__cdecl__)) _wcsxfrm_l(wchar_t * __restrict__ _Dst,const wchar_t * __restrict__ _Src,size_t _MaxCount,_locale_t _Locale);
  int __attribute__((__cdecl__)) wcscoll(const wchar_t *_Str1,const wchar_t *_Str2);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wcscoll_l(const wchar_t *_Str1,const wchar_t *_Str2,_locale_t _Locale);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wcsicoll(const wchar_t *_Str1,const wchar_t *_Str2);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wcsicoll_l(const wchar_t *_Str1,const wchar_t *_Str2,_locale_t _Locale);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wcsncoll(const wchar_t *_Str1,const wchar_t *_Str2,size_t _MaxCount);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wcsncoll_l(const wchar_t *_Str1,const wchar_t *_Str2,size_t _MaxCount,_locale_t _Locale);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wcsnicoll(const wchar_t *_Str1,const wchar_t *_Str2,size_t _MaxCount);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wcsnicoll_l(const wchar_t *_Str1,const wchar_t *_Str2,size_t _MaxCount,_locale_t _Locale);






  wchar_t *__attribute__((__cdecl__)) wcsdup(const wchar_t *_Str) ;




  int __attribute__((__cdecl__)) wcsicmp(const wchar_t *_Str1,const wchar_t *_Str2) ;
  int __attribute__((__cdecl__)) wcsnicmp(const wchar_t *_Str1,const wchar_t *_Str2,size_t _MaxCount) ;
  wchar_t *__attribute__((__cdecl__)) wcsnset(wchar_t *_Str,wchar_t _Val,size_t _MaxCount) ;
  wchar_t *__attribute__((__cdecl__)) wcsrev(wchar_t *_Str) ;
  wchar_t *__attribute__((__cdecl__)) wcsset(wchar_t *_Str,wchar_t _Val) ;
  wchar_t *__attribute__((__cdecl__)) wcslwr(wchar_t *_Str) ;
  wchar_t *__attribute__((__cdecl__)) wcsupr(wchar_t *_Str) ;
  int __attribute__((__cdecl__)) wcsicoll(const wchar_t *_Str1,const wchar_t *_Str2) ;




}


# 1 "C:/msys64/mingw64/include/sec_api/string_s.h" 1 3
# 9 "C:/msys64/mingw64/include/sec_api/string_s.h" 3
# 1 "C:/msys64/mingw64/include/string.h" 1 3
# 10 "C:/msys64/mingw64/include/sec_api/string_s.h" 2 3
# 21 "C:/msys64/mingw64/include/sec_api/string_s.h" 3
extern "C" {


  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _strset_s(char *_Dst,size_t _DstSize,int _Value);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _strset_s(char (&_Dst)[__size], int _Value) { return _strset_s(_Dst,__size,_Value); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _strerror_s(char *_Buf,size_t _SizeInBytes,const char *_ErrMsg);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _strerror_s(char (&_Buf)[__size], const char * _ErrMsg) { return _strerror_s(_Buf,__size,_ErrMsg); } }
  __attribute__((dllimport)) errno_t __attribute__((__cdecl__)) strerror_s(char *_Buf,size_t _SizeInBytes,int _ErrNum);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) strerror_s(char (&_Buf)[__size], int _ErrNum) { return strerror_s(_Buf,__size,_ErrNum); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _strlwr_s(char *_Str,size_t _Size);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _strlwr_s(char (&_Str)[__size]) { return _strlwr_s(_Str,__size); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _strlwr_s_l(char *_Str,size_t _Size,_locale_t _Locale);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _strlwr_s_l(char (&_Str)[__size], _locale_t _Locale) { return _strlwr_s_l(_Str,__size,_Locale); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _strnset_s(char *_Str,size_t _Size,int _Val,size_t _MaxCount);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _strnset_s(char (&_Str)[__size], int _Val, size_t _MaxCount) { return _strnset_s(_Str,__size,_Val,_MaxCount); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _strupr_s(char *_Str,size_t _Size);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _strupr_s(char (&_Str)[__size]) { return _strupr_s(_Str,__size); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _strupr_s_l(char *_Str,size_t _Size,_locale_t _Locale);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _strupr_s_l(char (&_Str)[__size], _locale_t _Locale) { return _strupr_s_l(_Str,__size,_Locale); } }

  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) strncat_s(char *_Dst,size_t _DstSizeInChars,const char *_Src,size_t _MaxCount);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) strncat_s(char (&_Dst)[__size], const char * _Src, size_t _MaxCount) { return strncat_s(_Dst,__size,_Src,_MaxCount); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _strncat_s_l(char *_Dst,size_t _DstSizeInChars,const char *_Src,size_t _MaxCount,_locale_t _Locale);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _strncat_s_l(char (&_Dst)[__size], const char * _Src, size_t _MaxCount, _locale_t _Locale) { return _strncat_s_l(_Dst,__size,_Src,_MaxCount,_Locale); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) strcpy_s(char *_Dst, rsize_t _SizeInBytes, const char *_Src);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) strcpy_s(char (&_Dest)[__size], const char * _Source) { return strcpy_s(_Dest,__size,_Source); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) strncpy_s(char *_Dst, size_t _DstSizeInChars, const char *_Src, size_t _MaxCount);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) strncpy_s(char (&_Dest)[__size], const char * _Source, size_t _MaxCount) { return strncpy_s(_Dest,__size,_Source,_MaxCount); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _strncpy_s_l(char *_Dst, size_t _DstSizeInChars, const char *_Src, size_t _MaxCount, _locale_t _Locale);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _strncpy_s_l(char (&_Dest)[__size], const char * _Source, size_t _MaxCount, _locale_t _Locale) { return _strncpy_s_l(_Dest,__size,_Source,_MaxCount,_Locale); } }
  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) strtok_s(char *_Str,const char *_Delim,char **_Context);
  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _strtok_s_l(char *_Str,const char *_Delim,char **_Context,_locale_t _Locale);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) strcat_s(char *_Dst, rsize_t _SizeInBytes, const char * _Src);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) strcat_s(char (&_Dest)[__size], const char * _Source) { return strcat_s(_Dest,__size,_Source); } }

  inline __attribute__((__always_inline__)) size_t __attribute__((__cdecl__)) strnlen_s(const char * _src, size_t _count) {
    return _src ? strnlen(_src, _count) : 0;
  }

  __attribute__((dllimport)) errno_t __attribute__((__cdecl__)) memmove_s(void *_dest,size_t _numberOfElements,const void *_src,size_t _count);


  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) wcstok_s(wchar_t *_Str,const wchar_t *_Delim,wchar_t **_Context);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wcserror_s(wchar_t *_Buf,size_t _SizeInWords,int _ErrNum);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _wcserror_s(wchar_t (&buffer)[__size], int error) { return _wcserror_s(buffer,__size,error); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) __wcserror_s(wchar_t *_Buffer,size_t _SizeInWords,const wchar_t *_ErrMsg);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wcsnset_s(wchar_t *_Dst,size_t _DstSizeInWords,wchar_t _Val,size_t _MaxCount);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wcsset_s(wchar_t *_Str,size_t _SizeInWords,wchar_t _Val);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wcslwr_s(wchar_t *_Str,size_t _SizeInWords);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _wcslwr_s(wchar_t (&_Str)[__size]) { return _wcslwr_s(_Str,__size); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wcslwr_s_l(wchar_t *_Str,size_t _SizeInWords,_locale_t _Locale);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _wcslwr_s_l(wchar_t (&_Str)[__size], _locale_t _Locale) { return _wcslwr_s_l(_Str,__size,_Locale); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wcsupr_s(wchar_t *_Str,size_t _Size);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _wcsupr_s(wchar_t (&_Str)[__size]) { return _wcsupr_s(_Str,__size); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wcsupr_s_l(wchar_t *_Str,size_t _Size,_locale_t _Locale);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _wcsupr_s_l(wchar_t (&_Str)[__size], _locale_t _Locale) { return _wcsupr_s_l(_Str,__size,_Locale); } }

  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) wcscpy_s(wchar_t *_Dst, rsize_t _SizeInWords, const wchar_t *_Src);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) wcscpy_s(wchar_t (&_Dest)[__size], const wchar_t * _Source) { return wcscpy_s(_Dest,__size,_Source); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) wcscat_s(wchar_t * _Dst, rsize_t _SizeInWords, const wchar_t *_Src);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) wcscat_s(wchar_t (&_Dest)[__size], const wchar_t * _Source) { return wcscat_s(_Dest,__size,_Source); } }

  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) wcsncat_s(wchar_t *_Dst,size_t _DstSizeInChars,const wchar_t *_Src,size_t _MaxCount);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) wcsncat_s(wchar_t (&_Dst)[__size], const wchar_t * _Src, size_t _MaxCount) { return wcsncat_s(_Dst,__size,_Src,_MaxCount); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wcsncat_s_l(wchar_t *_Dst,size_t _DstSizeInChars,const wchar_t *_Src,size_t _MaxCount,_locale_t _Locale);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _wcsncat_s_l(wchar_t (&_Dst)[__size], const wchar_t * _Src, size_t _MaxCount, _locale_t _Locale) { return _wcsncat_s_l(_Dst,__size,_Src,_MaxCount,_Locale); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) wcsncpy_s(wchar_t *_Dst, size_t _DstSizeInChars, const wchar_t *_Src, size_t _MaxCount);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) wcsncpy_s(wchar_t (&_Dest)[__size], const wchar_t * _Source, size_t _MaxCount) { return wcsncpy_s(_Dest,__size,_Source,_MaxCount); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wcsncpy_s_l(wchar_t *_Dst, size_t _DstSizeInChars, const wchar_t *_Src, size_t _MaxCount, _locale_t _Locale);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _wcsncpy_s_l(wchar_t (&_Dest)[__size], const wchar_t * _Source, size_t _MaxCount, _locale_t _Locale) { return _wcsncpy_s_l(_Dest,__size,_Source,_MaxCount,_Locale); } }
  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _wcstok_s_l(wchar_t *_Str,const wchar_t *_Delim,wchar_t **_Context,_locale_t _Locale);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wcsset_s_l(wchar_t *_Str,size_t _SizeInChars,wchar_t _Val,_locale_t _Locale);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _wcsset_s_l(wchar_t (&_Str)[__size], wchar_t _Val, _locale_t _Locale) { return _wcsset_s_l(_Str,__size,_Val,_Locale); } }
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wcsnset_s_l(wchar_t *_Str,size_t _SizeInChars,wchar_t _Val, size_t _Count,_locale_t _Locale);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _wcsnset_s_l(wchar_t (&_Str)[__size], wchar_t _Val, size_t _Count, _locale_t _Locale) { return _wcsnset_s_l(_Str,__size,_Val,_Count,_Locale); } }

  inline __attribute__((__always_inline__)) size_t __attribute__((__cdecl__)) wcsnlen_s(const wchar_t * _src, size_t _count) {
    return _src ? wcsnlen(_src, _count) : 0;
  }



}
# 226 "C:/msys64/mingw64/include/string.h" 2 3
# 49 "C:/msys64/mingw64/include/c++/15.2.0/cstring" 2 3
# 74 "C:/msys64/mingw64/include/c++/15.2.0/cstring" 3
extern "C++"
{
namespace std
{


  using ::memchr;
  using ::memcmp;
  using ::memcpy;
  using ::memmove;
  using ::memset;
  using ::strcat;
  using ::strcmp;
  using ::strcoll;
  using ::strcpy;
  using ::strcspn;
  using ::strerror;
  using ::strlen;
  using ::strncat;
  using ::strncmp;
  using ::strncpy;
  using ::strspn;

  using ::strtok;

  using ::strxfrm;
  using ::strchr;
  using ::strpbrk;
  using ::strrchr;
  using ::strstr;


  inline void*
  memchr(void* __s, int __c, size_t __n)
  { return __builtin_memchr(__s, __c, __n); }

  inline char*
  strchr(char* __s, int __n)
  { return __builtin_strchr(__s, __n); }

  inline char*
  strpbrk(char* __s1, const char* __s2)
  { return __builtin_strpbrk(__s1, __s2); }

  inline char*
  strrchr(char* __s, int __n)
  { return __builtin_strrchr(__s, __n); }

  inline char*
  strstr(char* __s1, const char* __s2)
  { return __builtin_strstr(__s1, __s2); }



}
}
# 2824 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 2
# 1 "C:/msys64/mingw64/include/c++/15.2.0/cinttypes" 1 3
# 48 "C:/msys64/mingw64/include/c++/15.2.0/cinttypes" 3
# 1 "C:/msys64/mingw64/include/inttypes.h" 1 3
# 14 "C:/msys64/mingw64/include/inttypes.h" 3
# 1 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/stddef.h" 1 3 4
# 1 "C:/msys64/mingw64/include/stddef.h" 1 3 4
# 2 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/stddef.h" 2 3 4
# 15 "C:/msys64/mingw64/include/inttypes.h" 2 3


extern "C" {


typedef struct {
 intmax_t quot;
 intmax_t rem;
 } imaxdiv_t;
# 327 "C:/msys64/mingw64/include/inttypes.h" 3
intmax_t __attribute__((__cdecl__)) imaxabs (intmax_t j);




imaxdiv_t __attribute__((__cdecl__)) imaxdiv (intmax_t numer, intmax_t denom);



intmax_t __attribute__((__cdecl__)) strtoimax (const char* __restrict__ nptr,
                            char** __restrict__ endptr, int base);
uintmax_t __attribute__((__cdecl__)) strtoumax (const char* __restrict__ nptr,
        char** __restrict__ endptr, int base);

intmax_t __attribute__((__cdecl__)) wcstoimax (const wchar_t* __restrict__ nptr,
                            wchar_t** __restrict__ endptr, int base);
uintmax_t __attribute__((__cdecl__)) wcstoumax (const wchar_t* __restrict__ nptr,
        wchar_t** __restrict__ endptr, int base);


}
# 49 "C:/msys64/mingw64/include/c++/15.2.0/cinttypes" 2 3
# 57 "C:/msys64/mingw64/include/c++/15.2.0/cinttypes" 3
namespace std
{

  using ::imaxdiv_t;


  using ::imaxabs;
  using ::imaxdiv;





  using ::strtoimax;
  using ::strtoumax;


  using ::wcstoimax;
  using ::wcstoumax;

}
# 2825 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 2
# 1 "C:/msys64/mingw64/include/c++/15.2.0/utility" 1 3
# 70 "C:/msys64/mingw64/include/c++/15.2.0/utility" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_relops.h" 1 3
# 62 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_relops.h" 3
namespace std
{


  namespace rel_ops __attribute__ ((__deprecated__ ("use '" "<=>" "' instead")))
  {
# 86 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_relops.h" 3
    template <class _Tp>
      inline bool
      operator!=(const _Tp& __x, const _Tp& __y)
      { return !(__x == __y); }
# 99 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_relops.h" 3
    template <class _Tp>
      inline bool
      operator>(const _Tp& __x, const _Tp& __y)
      { return __y < __x; }
# 112 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_relops.h" 3
    template <class _Tp>
      inline bool
      operator<=(const _Tp& __x, const _Tp& __y)
      { return !(__y < __x); }
# 125 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_relops.h" 3
    template <class _Tp>
      inline bool
      operator>=(const _Tp& __x, const _Tp& __y)
      { return !(__x < __y); }
  }


}
# 71 "C:/msys64/mingw64/include/c++/15.2.0/utility" 2 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 1 3
# 60 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 1 3
# 66 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 67 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 2 3

extern "C++"
{
namespace std
{


  template<typename _Tp>
    class reference_wrapper;
# 91 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp, _Tp __v>
    struct integral_constant
    {
      static constexpr _Tp value = __v;
      using value_type = _Tp;
      using type = integral_constant<_Tp, __v>;
      constexpr operator value_type() const noexcept { return value; }


      constexpr value_type operator()() const noexcept { return value; }

    };
# 111 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<bool __v>
    using __bool_constant = integral_constant<bool, __v>;



  using true_type = __bool_constant<true>;


  using false_type = __bool_constant<false>;




  template<bool __v>
    using bool_constant = __bool_constant<__v>;






  template<bool, typename _Tp = void>
    struct enable_if
    { };


  template<typename _Tp>
    struct enable_if<true, _Tp>
    { using type = _Tp; };


  template<bool _Cond, typename _Tp = void>
    using __enable_if_t = typename enable_if<_Cond, _Tp>::type;

  template<bool>
    struct __conditional
    {
      template<typename _Tp, typename>
 using type = _Tp;
    };

  template<>
    struct __conditional<false>
    {
      template<typename, typename _Up>
 using type = _Up;
    };


  template<bool _Cond, typename _If, typename _Else>
    using __conditional_t
      = typename __conditional<_Cond>::template type<_If, _Else>;


  template <typename _Type>
    struct __type_identity
    { using type = _Type; };

  template<typename _Tp>
    using __type_identity_t = typename __type_identity<_Tp>::type;

  namespace __detail
  {

    template<typename _Tp, typename...>
      using __first_t = _Tp;


    template<typename... _Bn>
      auto __or_fn(int) -> __first_t<false_type,
         __enable_if_t<!bool(_Bn::value)>...>;

    template<typename... _Bn>
      auto __or_fn(...) -> true_type;

    template<typename... _Bn>
      auto __and_fn(int) -> __first_t<true_type,
          __enable_if_t<bool(_Bn::value)>...>;

    template<typename... _Bn>
      auto __and_fn(...) -> false_type;
  }




  template<typename... _Bn>
    struct __or_
    : decltype(__detail::__or_fn<_Bn...>(0))
    { };

  template<typename... _Bn>
    struct __and_
    : decltype(__detail::__and_fn<_Bn...>(0))
    { };

  template<typename _Pp>
    struct __not_
    : __bool_constant<!bool(_Pp::value)>
    { };





  template<typename... _Bn>
    inline constexpr bool __or_v = __or_<_Bn...>::value;
  template<typename... _Bn>
    inline constexpr bool __and_v = __and_<_Bn...>::value;

  namespace __detail
  {
    template<typename , typename _B1, typename... _Bn>
      struct __disjunction_impl
      { using type = _B1; };

    template<typename _B1, typename _B2, typename... _Bn>
      struct __disjunction_impl<__enable_if_t<!bool(_B1::value)>, _B1, _B2, _Bn...>
      { using type = typename __disjunction_impl<void, _B2, _Bn...>::type; };

    template<typename , typename _B1, typename... _Bn>
      struct __conjunction_impl
      { using type = _B1; };

    template<typename _B1, typename _B2, typename... _Bn>
      struct __conjunction_impl<__enable_if_t<bool(_B1::value)>, _B1, _B2, _Bn...>
      { using type = typename __conjunction_impl<void, _B2, _Bn...>::type; };
  }


  template<typename... _Bn>
    struct conjunction
    : __detail::__conjunction_impl<void, _Bn...>::type
    { };

  template<>
    struct conjunction<>
    : true_type
    { };

  template<typename... _Bn>
    struct disjunction
    : __detail::__disjunction_impl<void, _Bn...>::type
    { };

  template<>
    struct disjunction<>
    : false_type
    { };

  template<typename _Pp>
    struct negation
    : __not_<_Pp>::type
    { };




  template<typename... _Bn>
    inline constexpr bool conjunction_v = conjunction<_Bn...>::value;

  template<typename... _Bn>
    inline constexpr bool disjunction_v = disjunction<_Bn...>::value;

  template<typename _Pp>
    inline constexpr bool negation_v = negation<_Pp>::value;





  template<typename>
    struct is_reference;
  template<typename>
    struct is_function;
  template<typename>
    struct is_void;
  template<typename>
    struct remove_cv;
  template<typename>
    struct is_const;


  template<typename>
    struct __is_array_unknown_bounds;




  template <typename _Tp, size_t = sizeof(_Tp)>
    constexpr true_type __is_complete_or_unbounded(__type_identity<_Tp>)
    { return {}; }

  template <typename _TypeIdentity,
      typename _NestedType = typename _TypeIdentity::type>
    constexpr typename __or_<
      is_reference<_NestedType>,
      is_function<_NestedType>,
      is_void<_NestedType>,
      __is_array_unknown_bounds<_NestedType>
    >::type __is_complete_or_unbounded(_TypeIdentity)
    { return {}; }


  template<typename _Tp>
    using __remove_cv_t = typename remove_cv<_Tp>::type;





  template<typename _Tp>
    struct is_void
    : public false_type { };

  template<>
    struct is_void<void>
    : public true_type { };

  template<>
    struct is_void<const void>
    : public true_type { };

  template<>
    struct is_void<volatile void>
    : public true_type { };

  template<>
    struct is_void<const volatile void>
    : public true_type { };


  template<typename>
    struct __is_integral_helper
    : public false_type { };

  template<>
    struct __is_integral_helper<bool>
    : public true_type { };

  template<>
    struct __is_integral_helper<char>
    : public true_type { };

  template<>
    struct __is_integral_helper<signed char>
    : public true_type { };

  template<>
    struct __is_integral_helper<unsigned char>
    : public true_type { };




  template<>
    struct __is_integral_helper<wchar_t>
    : public true_type { };


  template<>
    struct __is_integral_helper<char8_t>
    : public true_type { };


  template<>
    struct __is_integral_helper<char16_t>
    : public true_type { };

  template<>
    struct __is_integral_helper<char32_t>
    : public true_type { };

  template<>
    struct __is_integral_helper<short>
    : public true_type { };

  template<>
    struct __is_integral_helper<unsigned short>
    : public true_type { };

  template<>
    struct __is_integral_helper<int>
    : public true_type { };

  template<>
    struct __is_integral_helper<unsigned int>
    : public true_type { };

  template<>
    struct __is_integral_helper<long>
    : public true_type { };

  template<>
    struct __is_integral_helper<unsigned long>
    : public true_type { };

  template<>
    struct __is_integral_helper<long long>
    : public true_type { };

  template<>
    struct __is_integral_helper<unsigned long long>
    : public true_type { };




  __extension__
  template<>
    struct __is_integral_helper<__int128>
    : public true_type { };

  __extension__
  template<>
    struct __is_integral_helper<unsigned __int128>
    : public true_type { };
# 465 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct is_integral
    : public __is_integral_helper<__remove_cv_t<_Tp>>::type
    { };


  template<typename>
    struct __is_floating_point_helper
    : public false_type { };

  template<>
    struct __is_floating_point_helper<float>
    : public true_type { };

  template<>
    struct __is_floating_point_helper<double>
    : public true_type { };

  template<>
    struct __is_floating_point_helper<long double>
    : public true_type { };
# 518 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<>
    struct __is_floating_point_helper<__float128>
    : public true_type { };




  template<typename _Tp>
    struct is_floating_point
    : public __is_floating_point_helper<__remove_cv_t<_Tp>>::type
    { };



  template<typename _Tp>
    struct is_array
    : public __bool_constant<__is_array(_Tp)>
    { };
# 552 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct is_pointer
    : public __bool_constant<__is_pointer(_Tp)>
    { };
# 579 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename>
    struct is_lvalue_reference
    : public false_type { };

  template<typename _Tp>
    struct is_lvalue_reference<_Tp&>
    : public true_type { };


  template<typename>
    struct is_rvalue_reference
    : public false_type { };

  template<typename _Tp>
    struct is_rvalue_reference<_Tp&&>
    : public true_type { };



  template<typename _Tp>
    struct is_member_object_pointer
    : public __bool_constant<__is_member_object_pointer(_Tp)>
    { };
# 620 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct is_member_function_pointer
    : public __bool_constant<__is_member_function_pointer(_Tp)>
    { };
# 641 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct is_enum
    : public __bool_constant<__is_enum(_Tp)>
    { };


  template<typename _Tp>
    struct is_union
    : public __bool_constant<__is_union(_Tp)>
    { };


  template<typename _Tp>
    struct is_class
    : public __bool_constant<__is_class(_Tp)>
    { };



  template<typename _Tp>
    struct is_function
    : public __bool_constant<__is_function(_Tp)>
    { };
# 680 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct is_null_pointer
    : public false_type { };

  template<>
    struct is_null_pointer<std::nullptr_t>
    : public true_type { };

  template<>
    struct is_null_pointer<const std::nullptr_t>
    : public true_type { };

  template<>
    struct is_null_pointer<volatile std::nullptr_t>
    : public true_type { };

  template<>
    struct is_null_pointer<const volatile std::nullptr_t>
    : public true_type { };



  template<typename _Tp>
    struct __is_nullptr_t
    : public is_null_pointer<_Tp>
    { } __attribute__ ((__deprecated__ ("use '" "std::is_null_pointer" "' instead")));






  template<typename _Tp>
    struct is_reference
    : public __bool_constant<__is_reference(_Tp)>
    { };
# 734 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct is_arithmetic
    : public __or_<is_integral<_Tp>, is_floating_point<_Tp>>::type
    { };


  template<typename _Tp>
    struct is_fundamental
    : public __or_<is_arithmetic<_Tp>, is_void<_Tp>,
     is_null_pointer<_Tp>>::type
    { };



  template<typename _Tp>
    struct is_object
    : public __bool_constant<__is_object(_Tp)>
    { };
# 760 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename>
    struct is_member_pointer;


  template<typename _Tp>
    struct is_scalar
    : public __or_<is_arithmetic<_Tp>, is_enum<_Tp>, is_pointer<_Tp>,
                   is_member_pointer<_Tp>, is_null_pointer<_Tp>>::type
    { };


  template<typename _Tp>
    struct is_compound
    : public __bool_constant<!is_fundamental<_Tp>::value> { };



  template<typename _Tp>
    struct is_member_pointer
    : public __bool_constant<__is_member_pointer(_Tp)>
    { };
# 798 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename, typename>
    struct is_same;


  template<typename _Tp, typename... _Types>
    using __is_one_of = __or_<is_same<_Tp, _Types>...>;


  __extension__
  template<typename _Tp>
    using __is_signed_integer = __is_one_of<__remove_cv_t<_Tp>,
   signed char, signed short, signed int, signed long,
   signed long long

   , signed __int128
# 823 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
   >;


  __extension__
  template<typename _Tp>
    using __is_unsigned_integer = __is_one_of<__remove_cv_t<_Tp>,
   unsigned char, unsigned short, unsigned int, unsigned long,
   unsigned long long

   , unsigned __int128
# 843 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
   >;


  template<typename _Tp>
    using __is_standard_integer
      = __or_<__is_signed_integer<_Tp>, __is_unsigned_integer<_Tp>>;


  template<typename...> using __void_t = void;






  template<typename _Tp>
    struct is_const
    : public __bool_constant<__is_const(_Tp)>
    { };
# 874 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct is_volatile
    : public __bool_constant<__is_volatile(_Tp)>
    { };
# 895 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct
   
    is_trivial
    : public __bool_constant<__is_trivial(_Tp)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_trivially_copyable
    : public __bool_constant<__is_trivially_copyable(_Tp)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_standard_layout
    : public __bool_constant<__is_standard_layout(_Tp)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };






  template<typename _Tp>
    struct
    __attribute__ ((__deprecated__ ("use '" "is_standard_layout && is_trivial" "' instead")))
    is_pod
    : public __bool_constant<__is_pod(_Tp)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };





  template<typename _Tp>
    struct
    [[__deprecated__]]
    is_literal_type
    : public __bool_constant<__is_literal_type(_Tp)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_empty
    : public __bool_constant<__is_empty(_Tp)>
    { };


  template<typename _Tp>
    struct is_polymorphic
    : public __bool_constant<__is_polymorphic(_Tp)>
    { };




  template<typename _Tp>
    struct is_final
    : public __bool_constant<__is_final(_Tp)>
    { };



  template<typename _Tp>
    struct is_abstract
    : public __bool_constant<__is_abstract(_Tp)>
    { };


  template<typename _Tp,
    bool = is_arithmetic<_Tp>::value>
    struct __is_signed_helper
    : public false_type { };

  template<typename _Tp>
    struct __is_signed_helper<_Tp, true>
    : public __bool_constant<_Tp(-1) < _Tp(0)>
    { };



  template<typename _Tp>
    struct is_signed
    : public __is_signed_helper<_Tp>::type
    { };


  template<typename _Tp>
    struct is_unsigned
    : public __and_<is_arithmetic<_Tp>, __not_<is_signed<_Tp>>>::type
    { };


  template<typename _Tp, typename _Up = _Tp&&>
    _Up
    __declval(int);

  template<typename _Tp>
    _Tp
    __declval(long);


  template<typename _Tp>
    auto declval() noexcept -> decltype(__declval<_Tp>(0));

  template<typename>
    struct remove_all_extents;


  template<typename _Tp>
    struct __is_array_known_bounds
    : public false_type
    { };

  template<typename _Tp, size_t _Size>
    struct __is_array_known_bounds<_Tp[_Size]>
    : public true_type
    { };

  template<typename _Tp>
    struct __is_array_unknown_bounds
    : public false_type
    { };

  template<typename _Tp>
    struct __is_array_unknown_bounds<_Tp[]>
    : public true_type
    { };
# 1047 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  struct __do_is_destructible_impl
  {
    template<typename _Tp, typename = decltype(declval<_Tp&>().~_Tp())>
      static true_type __test(int);

    template<typename>
      static false_type __test(...);
  };

  template<typename _Tp>
    struct __is_destructible_impl
    : public __do_is_destructible_impl
    {
      using type = decltype(__test<_Tp>(0));
    };

  template<typename _Tp,
           bool = __or_<is_void<_Tp>,
                        __is_array_unknown_bounds<_Tp>,
                        is_function<_Tp>>::value,
           bool = __or_<is_reference<_Tp>, is_scalar<_Tp>>::value>
    struct __is_destructible_safe;

  template<typename _Tp>
    struct __is_destructible_safe<_Tp, false, false>
    : public __is_destructible_impl<typename
               remove_all_extents<_Tp>::type>::type
    { };

  template<typename _Tp>
    struct __is_destructible_safe<_Tp, true, false>
    : public false_type { };

  template<typename _Tp>
    struct __is_destructible_safe<_Tp, false, true>
    : public true_type { };



  template<typename _Tp>
    struct is_destructible
    : public __is_destructible_safe<_Tp>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };







  struct __do_is_nt_destructible_impl
  {
    template<typename _Tp>
      static __bool_constant<noexcept(declval<_Tp&>().~_Tp())>
      __test(int);

    template<typename>
      static false_type __test(...);
  };

  template<typename _Tp>
    struct __is_nt_destructible_impl
    : public __do_is_nt_destructible_impl
    {
      using type = decltype(__test<_Tp>(0));
    };

  template<typename _Tp,
           bool = __or_<is_void<_Tp>,
                        __is_array_unknown_bounds<_Tp>,
                        is_function<_Tp>>::value,
           bool = __or_<is_reference<_Tp>, is_scalar<_Tp>>::value>
    struct __is_nt_destructible_safe;

  template<typename _Tp>
    struct __is_nt_destructible_safe<_Tp, false, false>
    : public __is_nt_destructible_impl<typename
               remove_all_extents<_Tp>::type>::type
    { };

  template<typename _Tp>
    struct __is_nt_destructible_safe<_Tp, true, false>
    : public false_type { };

  template<typename _Tp>
    struct __is_nt_destructible_safe<_Tp, false, true>
    : public true_type { };



  template<typename _Tp>
    struct is_nothrow_destructible
    : public __is_nt_destructible_safe<_Tp>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp, typename... _Args>
    using __is_constructible_impl
      = __bool_constant<__is_constructible(_Tp, _Args...)>;



  template<typename _Tp, typename... _Args>
    struct is_constructible
      : public __is_constructible_impl<_Tp, _Args...>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_default_constructible
    : public __is_constructible_impl<_Tp>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };



  template<typename _Tp>
    using __add_lval_ref_t = __add_lvalue_reference(_Tp);
# 1191 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct is_copy_constructible
    : public __is_constructible_impl<_Tp, __add_lval_ref_t<const _Tp>>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };



  template<typename _Tp>
    using __add_rval_ref_t = __add_rvalue_reference(_Tp);
# 1218 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct is_move_constructible
    : public __is_constructible_impl<_Tp, __add_rval_ref_t<_Tp>>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp, typename... _Args>
    using __is_nothrow_constructible_impl
      = __bool_constant<__is_nothrow_constructible(_Tp, _Args...)>;



  template<typename _Tp, typename... _Args>
    struct is_nothrow_constructible
    : public __is_nothrow_constructible_impl<_Tp, _Args...>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_nothrow_default_constructible
    : public __is_nothrow_constructible_impl<_Tp>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_nothrow_copy_constructible
    : public __is_nothrow_constructible_impl<_Tp, __add_lval_ref_t<const _Tp>>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_nothrow_move_constructible
    : public __is_nothrow_constructible_impl<_Tp, __add_rval_ref_t<_Tp>>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp, typename _Up>
    using __is_assignable_impl = __bool_constant<__is_assignable(_Tp, _Up)>;



  template<typename _Tp, typename _Up>
    struct is_assignable
    : public __is_assignable_impl<_Tp, _Up>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_copy_assignable
    : public __is_assignable_impl<__add_lval_ref_t<_Tp>,
      __add_lval_ref_t<const _Tp>>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_move_assignable
    : public __is_assignable_impl<__add_lval_ref_t<_Tp>, __add_rval_ref_t<_Tp>>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp, typename _Up>
    using __is_nothrow_assignable_impl
      = __bool_constant<__is_nothrow_assignable(_Tp, _Up)>;



  template<typename _Tp, typename _Up>
    struct is_nothrow_assignable
    : public __is_nothrow_assignable_impl<_Tp, _Up>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_nothrow_copy_assignable
    : public __is_nothrow_assignable_impl<__add_lval_ref_t<_Tp>,
       __add_lval_ref_t<const _Tp>>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_nothrow_move_assignable
    : public __is_nothrow_assignable_impl<__add_lval_ref_t<_Tp>,
       __add_rval_ref_t<_Tp>>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp, typename... _Args>
    using __is_trivially_constructible_impl
      = __bool_constant<__is_trivially_constructible(_Tp, _Args...)>;



  template<typename _Tp, typename... _Args>
    struct is_trivially_constructible
    : public __is_trivially_constructible_impl<_Tp, _Args...>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_trivially_default_constructible
    : public __is_trivially_constructible_impl<_Tp>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    constexpr bool __is_implicitly_default_constructible_v
      = requires (void(&__f)(_Tp)) { __f({}); };

  template<typename _Tp>
    struct __is_implicitly_default_constructible
    : __bool_constant<__is_implicitly_default_constructible_v<_Tp>>
    { };
# 1402 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct is_trivially_copy_constructible
    : public __is_trivially_constructible_impl<_Tp, __add_lval_ref_t<const _Tp>>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_trivially_move_constructible
    : public __is_trivially_constructible_impl<_Tp, __add_rval_ref_t<_Tp>>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp, typename _Up>
    using __is_trivially_assignable_impl
      = __bool_constant<__is_trivially_assignable(_Tp, _Up)>;



  template<typename _Tp, typename _Up>
    struct is_trivially_assignable
    : public __is_trivially_assignable_impl<_Tp, _Up>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_trivially_copy_assignable
    : public __is_trivially_assignable_impl<__add_lval_ref_t<_Tp>,
         __add_lval_ref_t<const _Tp>>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_trivially_move_assignable
    : public __is_trivially_assignable_impl<__add_lval_ref_t<_Tp>,
         __add_rval_ref_t<_Tp>>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_trivially_destructible
    : public __and_<__is_destructible_safe<_Tp>,
      __bool_constant<__has_trivial_destructor(_Tp)>>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };



  template<typename _Tp>
    struct has_virtual_destructor
    : public __bool_constant<__has_virtual_destructor(_Tp)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };





  template<typename _Tp>
    struct alignment_of
    : public integral_constant<std::size_t, alignof(_Tp)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };




  template<typename _Tp>
    struct rank
    : public integral_constant<std::size_t, __array_rank(_Tp)> { };
# 1507 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename, unsigned _Uint = 0>
    struct extent
    : public integral_constant<size_t, 0> { };

  template<typename _Tp, size_t _Size>
    struct extent<_Tp[_Size], 0>
    : public integral_constant<size_t, _Size> { };

  template<typename _Tp, unsigned _Uint, size_t _Size>
    struct extent<_Tp[_Size], _Uint>
    : public extent<_Tp, _Uint - 1>::type { };

  template<typename _Tp>
    struct extent<_Tp[], 0>
    : public integral_constant<size_t, 0> { };

  template<typename _Tp, unsigned _Uint>
    struct extent<_Tp[], _Uint>
    : public extent<_Tp, _Uint - 1>::type { };






  template<typename _Tp, typename _Up>
    struct is_same
    : public __bool_constant<__is_same(_Tp, _Up)>
    { };
# 1549 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Base, typename _Derived>
    struct is_base_of
    : public __bool_constant<__is_base_of(_Base, _Derived)>
    { };
# 1564 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _From, typename _To>
    struct is_convertible
    : public __bool_constant<__is_convertible(_From, _To)>
    { };
# 1607 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _ToElementType, typename _FromElementType>
    using __is_array_convertible
      = is_convertible<_FromElementType(*)[], _ToElementType(*)[]>;





  template<typename _From, typename _To>
    inline constexpr bool is_nothrow_convertible_v
      = __is_nothrow_convertible(_From, _To);


  template<typename _From, typename _To>
    struct is_nothrow_convertible
    : public bool_constant<is_nothrow_convertible_v<_From, _To>>
    { };
# 1667 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wc++14-extensions"
  template<typename _Tp, typename... _Args>
    struct __is_nothrow_new_constructible_impl
    : __bool_constant<
 noexcept(::new(std::declval<void*>()) _Tp(std::declval<_Args>()...))
      >
    { };

  template<typename _Tp, typename... _Args>
    inline constexpr bool __is_nothrow_new_constructible
      = __and_<is_constructible<_Tp, _Args...>,
        __is_nothrow_new_constructible_impl<_Tp, _Args...>>::value;
#pragma GCC diagnostic pop




  template<typename _Tp>
    struct remove_const
    { using type = _Tp; };

  template<typename _Tp>
    struct remove_const<_Tp const>
    { using type = _Tp; };


  template<typename _Tp>
    struct remove_volatile
    { using type = _Tp; };

  template<typename _Tp>
    struct remove_volatile<_Tp volatile>
    { using type = _Tp; };



  template<typename _Tp>
    struct remove_cv
    { using type = __remove_cv(_Tp); };
# 1726 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct add_const
    { using type = _Tp const; };


  template<typename _Tp>
    struct add_volatile
    { using type = _Tp volatile; };


  template<typename _Tp>
    struct add_cv
    { using type = _Tp const volatile; };



  template<typename _Tp>
    using remove_const_t = typename remove_const<_Tp>::type;


  template<typename _Tp>
    using remove_volatile_t = typename remove_volatile<_Tp>::type;


  template<typename _Tp>
    using remove_cv_t = typename remove_cv<_Tp>::type;


  template<typename _Tp>
    using add_const_t = typename add_const<_Tp>::type;


  template<typename _Tp>
    using add_volatile_t = typename add_volatile<_Tp>::type;


  template<typename _Tp>
    using add_cv_t = typename add_cv<_Tp>::type;






  template<typename _Tp>
    struct remove_reference
    { using type = __remove_reference(_Tp); };
# 1788 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct add_lvalue_reference
    { using type = __add_lval_ref_t<_Tp>; };


  template<typename _Tp>
    struct add_rvalue_reference
    { using type = __add_rval_ref_t<_Tp>; };



  template<typename _Tp>
    using remove_reference_t = typename remove_reference<_Tp>::type;


  template<typename _Tp>
    using add_lvalue_reference_t = typename add_lvalue_reference<_Tp>::type;


  template<typename _Tp>
    using add_rvalue_reference_t = typename add_rvalue_reference<_Tp>::type;







  template<typename _Unqualified, bool _IsConst, bool _IsVol>
    struct __cv_selector;

  template<typename _Unqualified>
    struct __cv_selector<_Unqualified, false, false>
    { using __type = _Unqualified; };

  template<typename _Unqualified>
    struct __cv_selector<_Unqualified, false, true>
    { using __type = volatile _Unqualified; };

  template<typename _Unqualified>
    struct __cv_selector<_Unqualified, true, false>
    { using __type = const _Unqualified; };

  template<typename _Unqualified>
    struct __cv_selector<_Unqualified, true, true>
    { using __type = const volatile _Unqualified; };

  template<typename _Qualified, typename _Unqualified,
    bool _IsConst = is_const<_Qualified>::value,
    bool _IsVol = is_volatile<_Qualified>::value>
    class __match_cv_qualifiers
    {
      using __match = __cv_selector<_Unqualified, _IsConst, _IsVol>;

    public:
      using __type = typename __match::__type;
    };


  template<typename _Tp>
    struct __make_unsigned
    { using __type = _Tp; };

  template<>
    struct __make_unsigned<char>
    { using __type = unsigned char; };

  template<>
    struct __make_unsigned<signed char>
    { using __type = unsigned char; };

  template<>
    struct __make_unsigned<short>
    { using __type = unsigned short; };

  template<>
    struct __make_unsigned<int>
    { using __type = unsigned int; };

  template<>
    struct __make_unsigned<long>
    { using __type = unsigned long; };

  template<>
    struct __make_unsigned<long long>
    { using __type = unsigned long long; };


  __extension__
  template<>
    struct __make_unsigned<__int128>
    { using __type = unsigned __int128; };
# 1901 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp,
    bool _IsInt = is_integral<_Tp>::value,
    bool _IsEnum = __is_enum(_Tp)>
    class __make_unsigned_selector;

  template<typename _Tp>
    class __make_unsigned_selector<_Tp, true, false>
    {
      using __unsigned_type
 = typename __make_unsigned<__remove_cv_t<_Tp>>::__type;

    public:
      using __type
 = typename __match_cv_qualifiers<_Tp, __unsigned_type>::__type;
    };

  class __make_unsigned_selector_base
  {
  protected:
    template<typename...> struct _List { };

    template<typename _Tp, typename... _Up>
      struct _List<_Tp, _Up...> : _List<_Up...>
      { static constexpr size_t __size = sizeof(_Tp); };

    template<size_t _Sz, typename _Tp, bool = (_Sz <= _Tp::__size)>
      struct __select;

    template<size_t _Sz, typename _Uint, typename... _UInts>
      struct __select<_Sz, _List<_Uint, _UInts...>, true>
      { using __type = _Uint; };

    template<size_t _Sz, typename _Uint, typename... _UInts>
      struct __select<_Sz, _List<_Uint, _UInts...>, false>
      : __select<_Sz, _List<_UInts...>>
      { };
  };


  template<typename _Tp>
    class __make_unsigned_selector<_Tp, false, true>
    : __make_unsigned_selector_base
    {

      using _UInts = _List<unsigned char, unsigned short, unsigned int,
      unsigned long, unsigned long long>;

      using __unsigned_type = typename __select<sizeof(_Tp), _UInts>::__type;

    public:
      using __type
 = typename __match_cv_qualifiers<_Tp, __unsigned_type>::__type;
    };





  template<>
    struct __make_unsigned<wchar_t>
    {
      using __type
 = typename __make_unsigned_selector<wchar_t, false, true>::__type;
    };


  template<>
    struct __make_unsigned<char8_t>
    {
      using __type
 = typename __make_unsigned_selector<char8_t, false, true>::__type;
    };


  template<>
    struct __make_unsigned<char16_t>
    {
      using __type
 = typename __make_unsigned_selector<char16_t, false, true>::__type;
    };

  template<>
    struct __make_unsigned<char32_t>
    {
      using __type
 = typename __make_unsigned_selector<char32_t, false, true>::__type;
    };






  template<typename _Tp>
    struct make_unsigned
    { using type = typename __make_unsigned_selector<_Tp>::__type; };


  template<> struct make_unsigned<bool>;
  template<> struct make_unsigned<bool const>;
  template<> struct make_unsigned<bool volatile>;
  template<> struct make_unsigned<bool const volatile>;




  template<typename _Tp>
    struct __make_signed
    { using __type = _Tp; };

  template<>
    struct __make_signed<char>
    { using __type = signed char; };

  template<>
    struct __make_signed<unsigned char>
    { using __type = signed char; };

  template<>
    struct __make_signed<unsigned short>
    { using __type = signed short; };

  template<>
    struct __make_signed<unsigned int>
    { using __type = signed int; };

  template<>
    struct __make_signed<unsigned long>
    { using __type = signed long; };

  template<>
    struct __make_signed<unsigned long long>
    { using __type = signed long long; };


  __extension__
  template<>
    struct __make_signed<unsigned __int128>
    { using __type = __int128; };
# 2061 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp,
    bool _IsInt = is_integral<_Tp>::value,
    bool _IsEnum = __is_enum(_Tp)>
    class __make_signed_selector;

  template<typename _Tp>
    class __make_signed_selector<_Tp, true, false>
    {
      using __signed_type
 = typename __make_signed<__remove_cv_t<_Tp>>::__type;

    public:
      using __type
 = typename __match_cv_qualifiers<_Tp, __signed_type>::__type;
    };


  template<typename _Tp>
    class __make_signed_selector<_Tp, false, true>
    {
      using __unsigned_type = typename __make_unsigned_selector<_Tp>::__type;

    public:
      using __type = typename __make_signed_selector<__unsigned_type>::__type;
    };





  template<>
    struct __make_signed<wchar_t>
    {
      using __type
 = typename __make_signed_selector<wchar_t, false, true>::__type;
    };


  template<>
    struct __make_signed<char8_t>
    {
      using __type
 = typename __make_signed_selector<char8_t, false, true>::__type;
    };


  template<>
    struct __make_signed<char16_t>
    {
      using __type
 = typename __make_signed_selector<char16_t, false, true>::__type;
    };

  template<>
    struct __make_signed<char32_t>
    {
      using __type
 = typename __make_signed_selector<char32_t, false, true>::__type;
    };






  template<typename _Tp>
    struct make_signed
    { using type = typename __make_signed_selector<_Tp>::__type; };


  template<> struct make_signed<bool>;
  template<> struct make_signed<bool const>;
  template<> struct make_signed<bool volatile>;
  template<> struct make_signed<bool const volatile>;



  template<typename _Tp>
    using make_signed_t = typename make_signed<_Tp>::type;


  template<typename _Tp>
    using make_unsigned_t = typename make_unsigned<_Tp>::type;






  template<typename _Tp>
    struct remove_extent
    { using type = __remove_extent(_Tp); };
# 2169 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct remove_all_extents
    { using type = __remove_all_extents(_Tp); };
# 2188 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    using remove_extent_t = typename remove_extent<_Tp>::type;


  template<typename _Tp>
    using remove_all_extents_t = typename remove_all_extents<_Tp>::type;






  template<typename _Tp>
    struct remove_pointer
    { using type = __remove_pointer(_Tp); };
# 2220 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct add_pointer
    { using type = __add_pointer(_Tp); };
# 2248 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    using remove_pointer_t = typename remove_pointer<_Tp>::type;


  template<typename _Tp>
    using add_pointer_t = typename add_pointer<_Tp>::type;





  struct __attribute__((__aligned__)) __aligned_storage_max_align_t
  { };

  constexpr size_t
  __aligned_storage_default_alignment([[__maybe_unused__]] size_t __len)
  {
# 2279 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
    return alignof(__aligned_storage_max_align_t);

  }
# 2315 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<size_t _Len,
    size_t _Align = __aligned_storage_default_alignment(_Len)>
    struct
   
    aligned_storage
    {
      struct type
      {
 alignas(_Align) unsigned char __data[_Len];
      };
    };

  template <typename... _Types>
    struct __strictest_alignment
    {
      static const size_t _S_alignment = 0;
      static const size_t _S_size = 0;
    };

  template <typename _Tp, typename... _Types>
    struct __strictest_alignment<_Tp, _Types...>
    {
      static const size_t _S_alignment =
        alignof(_Tp) > __strictest_alignment<_Types...>::_S_alignment
 ? alignof(_Tp) : __strictest_alignment<_Types...>::_S_alignment;
      static const size_t _S_size =
        sizeof(_Tp) > __strictest_alignment<_Types...>::_S_size
 ? sizeof(_Tp) : __strictest_alignment<_Types...>::_S_size;
    };

#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wdeprecated-declarations"
# 2360 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template <size_t _Len, typename... _Types>
    struct
   
    aligned_union
    {
    private:
      static_assert(sizeof...(_Types) != 0, "At least one type is required");

      using __strictest = __strictest_alignment<_Types...>;
      static const size_t _S_len = _Len > __strictest::_S_size
 ? _Len : __strictest::_S_size;
    public:

      static const size_t alignment_value = __strictest::_S_alignment;

      using type = typename aligned_storage<_S_len, alignment_value>::type;
    };

  template <size_t _Len, typename... _Types>
    const size_t aligned_union<_Len, _Types...>::alignment_value;
#pragma GCC diagnostic pop




  template<typename _Tp>
    struct decay
    { using type = __decay(_Tp); };
# 2425 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct __strip_reference_wrapper
    {
      using __type = _Tp;
    };

  template<typename _Tp>
    struct __strip_reference_wrapper<reference_wrapper<_Tp> >
    {
      using __type = _Tp&;
    };


  template<typename _Tp>
    using __decay_t = typename decay<_Tp>::type;

  template<typename _Tp>
    using __decay_and_strip = __strip_reference_wrapper<__decay_t<_Tp>>;





  template<typename... _Cond>
    using _Require = __enable_if_t<__and_<_Cond...>::value>;


  template<typename _Tp>
    using __remove_cvref_t
     = typename remove_cv<typename remove_reference<_Tp>::type>::type;




  template<bool _Cond, typename _Iftrue, typename _Iffalse>
    struct conditional
    { using type = _Iftrue; };


  template<typename _Iftrue, typename _Iffalse>
    struct conditional<false, _Iftrue, _Iffalse>
    { using type = _Iffalse; };


  template<typename... _Tp>
    struct common_type;
# 2481 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct __success_type
    { using type = _Tp; };

  struct __failure_type
  { };

  struct __do_common_type_impl
  {
    template<typename _Tp, typename _Up>
      using __cond_t
 = decltype(true ? std::declval<_Tp>() : std::declval<_Up>());



    template<typename _Tp, typename _Up>
      static __success_type<__decay_t<__cond_t<_Tp, _Up>>>
      _S_test(int);




    template<typename _Tp, typename _Up>
      static __success_type<__remove_cvref_t<__cond_t<const _Tp&, const _Up&>>>
      _S_test_2(int);


    template<typename, typename>
      static __failure_type
      _S_test_2(...);

    template<typename _Tp, typename _Up>
      static decltype(_S_test_2<_Tp, _Up>(0))
      _S_test(...);
  };


  template<>
    struct common_type<>
    { };


  template<typename _Tp0>
    struct common_type<_Tp0>
    : public common_type<_Tp0, _Tp0>
    { };


  template<typename _Tp1, typename _Tp2,
    typename _Dp1 = __decay_t<_Tp1>, typename _Dp2 = __decay_t<_Tp2>>
    struct __common_type_impl
    {


      using type = common_type<_Dp1, _Dp2>;
    };

  template<typename _Tp1, typename _Tp2>
    struct __common_type_impl<_Tp1, _Tp2, _Tp1, _Tp2>
    : private __do_common_type_impl
    {


      using type = decltype(_S_test<_Tp1, _Tp2>(0));
    };


  template<typename _Tp1, typename _Tp2>
    struct common_type<_Tp1, _Tp2>
    : public __common_type_impl<_Tp1, _Tp2>::type
    { };

  template<typename...>
    struct __common_type_pack
    { };

  template<typename, typename, typename = void>
    struct __common_type_fold;


  template<typename _Tp1, typename _Tp2, typename... _Rp>
    struct common_type<_Tp1, _Tp2, _Rp...>
    : public __common_type_fold<common_type<_Tp1, _Tp2>,
    __common_type_pack<_Rp...>>
    { };




  template<typename _CTp, typename... _Rp>
    struct __common_type_fold<_CTp, __common_type_pack<_Rp...>,
         __void_t<typename _CTp::type>>
    : public common_type<typename _CTp::type, _Rp...>
    { };


  template<typename _CTp, typename _Rp>
    struct __common_type_fold<_CTp, _Rp, void>
    { };

  template<typename _Tp, bool = __is_enum(_Tp)>
    struct __underlying_type_impl
    {
      using type = __underlying_type(_Tp);
    };

  template<typename _Tp>
    struct __underlying_type_impl<_Tp, false>
    { };



  template<typename _Tp>
    struct underlying_type
    : public __underlying_type_impl<_Tp>
    { };


  template<typename _Tp>
    struct __declval_protector
    {
      static const bool __stop = false;
    };






  template<typename _Tp>
    auto declval() noexcept -> decltype(__declval<_Tp>(0))
    {
      static_assert(__declval_protector<_Tp>::__stop,
      "declval() must not be used!");
      return __declval<_Tp>(0);
    }


  template<typename _Signature>
    struct result_of;




  struct __invoke_memfun_ref { };
  struct __invoke_memfun_deref { };
  struct __invoke_memobj_ref { };
  struct __invoke_memobj_deref { };
  struct __invoke_other { };


  template<typename _Tp, typename _Tag>
    struct __result_of_success : __success_type<_Tp>
    { using __invoke_type = _Tag; };


  struct __result_of_memfun_ref_impl
  {
    template<typename _Fp, typename _Tp1, typename... _Args>
      static __result_of_success<decltype(
      (std::declval<_Tp1>().*std::declval<_Fp>())(std::declval<_Args>()...)
      ), __invoke_memfun_ref> _S_test(int);

    template<typename...>
      static __failure_type _S_test(...);
  };

  template<typename _MemPtr, typename _Arg, typename... _Args>
    struct __result_of_memfun_ref
    : private __result_of_memfun_ref_impl
    {
      using type = decltype(_S_test<_MemPtr, _Arg, _Args...>(0));
    };


  struct __result_of_memfun_deref_impl
  {
    template<typename _Fp, typename _Tp1, typename... _Args>
      static __result_of_success<decltype(
      ((*std::declval<_Tp1>()).*std::declval<_Fp>())(std::declval<_Args>()...)
      ), __invoke_memfun_deref> _S_test(int);

    template<typename...>
      static __failure_type _S_test(...);
  };

  template<typename _MemPtr, typename _Arg, typename... _Args>
    struct __result_of_memfun_deref
    : private __result_of_memfun_deref_impl
    {
      using type = decltype(_S_test<_MemPtr, _Arg, _Args...>(0));
    };


  struct __result_of_memobj_ref_impl
  {
    template<typename _Fp, typename _Tp1>
      static __result_of_success<decltype(
      std::declval<_Tp1>().*std::declval<_Fp>()
      ), __invoke_memobj_ref> _S_test(int);

    template<typename, typename>
      static __failure_type _S_test(...);
  };

  template<typename _MemPtr, typename _Arg>
    struct __result_of_memobj_ref
    : private __result_of_memobj_ref_impl
    {
      using type = decltype(_S_test<_MemPtr, _Arg>(0));
    };


  struct __result_of_memobj_deref_impl
  {
    template<typename _Fp, typename _Tp1>
      static __result_of_success<decltype(
      (*std::declval<_Tp1>()).*std::declval<_Fp>()
      ), __invoke_memobj_deref> _S_test(int);

    template<typename, typename>
      static __failure_type _S_test(...);
  };

  template<typename _MemPtr, typename _Arg>
    struct __result_of_memobj_deref
    : private __result_of_memobj_deref_impl
    {
      using type = decltype(_S_test<_MemPtr, _Arg>(0));
    };

  template<typename _MemPtr, typename _Arg>
    struct __result_of_memobj;

  template<typename _Res, typename _Class, typename _Arg>
    struct __result_of_memobj<_Res _Class::*, _Arg>
    {
      using _Argval = __remove_cvref_t<_Arg>;
      using _MemPtr = _Res _Class::*;
      using type = typename __conditional_t<__or_<is_same<_Argval, _Class>,
        is_base_of<_Class, _Argval>>::value,
        __result_of_memobj_ref<_MemPtr, _Arg>,
        __result_of_memobj_deref<_MemPtr, _Arg>
      >::type;
    };

  template<typename _MemPtr, typename _Arg, typename... _Args>
    struct __result_of_memfun;

  template<typename _Res, typename _Class, typename _Arg, typename... _Args>
    struct __result_of_memfun<_Res _Class::*, _Arg, _Args...>
    {
      using _Argval = typename remove_reference<_Arg>::type;
      using _MemPtr = _Res _Class::*;
      using type = typename __conditional_t<is_base_of<_Class, _Argval>::value,
        __result_of_memfun_ref<_MemPtr, _Arg, _Args...>,
        __result_of_memfun_deref<_MemPtr, _Arg, _Args...>
      >::type;
    };






  template<typename _Tp, typename _Up = __remove_cvref_t<_Tp>>
    struct __inv_unwrap
    {
      using type = _Tp;
    };

  template<typename _Tp, typename _Up>
    struct __inv_unwrap<_Tp, reference_wrapper<_Up>>
    {
      using type = _Up&;
    };

  template<bool, bool, typename _Functor, typename... _ArgTypes>
    struct __result_of_impl
    {
      using type = __failure_type;
    };

  template<typename _MemPtr, typename _Arg>
    struct __result_of_impl<true, false, _MemPtr, _Arg>
    : public __result_of_memobj<__decay_t<_MemPtr>,
    typename __inv_unwrap<_Arg>::type>
    { };

  template<typename _MemPtr, typename _Arg, typename... _Args>
    struct __result_of_impl<false, true, _MemPtr, _Arg, _Args...>
    : public __result_of_memfun<__decay_t<_MemPtr>,
    typename __inv_unwrap<_Arg>::type, _Args...>
    { };


  struct __result_of_other_impl
  {
    template<typename _Fn, typename... _Args>
      static __result_of_success<decltype(
      std::declval<_Fn>()(std::declval<_Args>()...)
      ), __invoke_other> _S_test(int);

    template<typename...>
      static __failure_type _S_test(...);
  };

  template<typename _Functor, typename... _ArgTypes>
    struct __result_of_impl<false, false, _Functor, _ArgTypes...>
    : private __result_of_other_impl
    {
      using type = decltype(_S_test<_Functor, _ArgTypes...>(0));
    };


  template<typename _Functor, typename... _ArgTypes>
    struct __invoke_result
    : public __result_of_impl<
        is_member_object_pointer<
          typename remove_reference<_Functor>::type
        >::value,
        is_member_function_pointer<
          typename remove_reference<_Functor>::type
        >::value,
 _Functor, _ArgTypes...
      >::type
    { };


  template<typename _Fn, typename... _Args>
    using __invoke_result_t = typename __invoke_result<_Fn, _Args...>::type;


  template<typename _Functor, typename... _ArgTypes>
    struct result_of<_Functor(_ArgTypes...)>
    : public __invoke_result<_Functor, _ArgTypes...>
    { } __attribute__ ((__deprecated__ ("use '" "std::invoke_result" "' instead")));


#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wdeprecated-declarations"

  template<size_t _Len,
    size_t _Align = __aligned_storage_default_alignment(_Len)>
    using aligned_storage_t = typename aligned_storage<_Len, _Align>::type;

  template <size_t _Len, typename... _Types>
    using aligned_union_t = typename aligned_union<_Len, _Types...>::type;
#pragma GCC diagnostic pop


  template<typename _Tp>
    using decay_t = typename decay<_Tp>::type;


  template<bool _Cond, typename _Tp = void>
    using enable_if_t = typename enable_if<_Cond, _Tp>::type;


  template<bool _Cond, typename _Iftrue, typename _Iffalse>
    using conditional_t = typename conditional<_Cond, _Iftrue, _Iffalse>::type;


  template<typename... _Tp>
    using common_type_t = typename common_type<_Tp...>::type;


  template<typename _Tp>
    using underlying_type_t = typename underlying_type<_Tp>::type;


  template<typename _Tp>
    using result_of_t = typename result_of<_Tp>::type;




  template<typename...> using void_t = void;
# 2868 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Def, template<typename...> class _Op, typename... _Args>
    struct __detected_or
    {
      using type = _Def;
      using __is_detected = false_type;
    };


  template<typename _Def, template<typename...> class _Op, typename... _Args>
    requires requires { typename _Op<_Args...>; }
    struct __detected_or<_Def, _Op, _Args...>
    {
      using type = _Op<_Args...>;
      using __is_detected = true_type;
    };
# 2908 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Default, template<typename...> class _Op,
    typename... _Args>
    using __detected_or_t
      = typename __detected_or<_Default, _Op, _Args...>::type;
# 2927 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template <typename _Tp>
    struct __is_swappable;

  template <typename _Tp>
    struct __is_nothrow_swappable;

  template<typename>
    struct __is_tuple_like_impl : false_type
    { };


  template<typename _Tp>
    struct __is_tuple_like
    : public __is_tuple_like_impl<__remove_cvref_t<_Tp>>::type
    { };


  template<typename _Tp>
    constexpr
    inline
    _Require<__not_<__is_tuple_like<_Tp>>,
      is_move_constructible<_Tp>,
      is_move_assignable<_Tp>>
    swap(_Tp&, _Tp&)
    noexcept(__and_<is_nothrow_move_constructible<_Tp>,
             is_nothrow_move_assignable<_Tp>>::value);

  template<typename _Tp, size_t _Nm>
    constexpr
    inline
    __enable_if_t<__is_swappable<_Tp>::value>
    swap(_Tp (&__a)[_Nm], _Tp (&__b)[_Nm])
    noexcept(__is_nothrow_swappable<_Tp>::value);


  namespace __swappable_details {
    using std::swap;

    struct __do_is_swappable_impl
    {
      template<typename _Tp, typename
               = decltype(swap(std::declval<_Tp&>(), std::declval<_Tp&>()))>
        static true_type __test(int);

      template<typename>
        static false_type __test(...);
    };

    struct __do_is_nothrow_swappable_impl
    {
      template<typename _Tp>
        static __bool_constant<
          noexcept(swap(std::declval<_Tp&>(), std::declval<_Tp&>()))
        > __test(int);

      template<typename>
        static false_type __test(...);
    };

  }

  template<typename _Tp>
    struct __is_swappable_impl
    : public __swappable_details::__do_is_swappable_impl
    {
      using type = decltype(__test<_Tp>(0));
    };

  template<typename _Tp>
    struct __is_nothrow_swappable_impl
    : public __swappable_details::__do_is_nothrow_swappable_impl
    {
      using type = decltype(__test<_Tp>(0));
    };

  template<typename _Tp>
    struct __is_swappable
    : public __is_swappable_impl<_Tp>::type
    { };

  template<typename _Tp>
    struct __is_nothrow_swappable
    : public __is_nothrow_swappable_impl<_Tp>::type
    { };






  template<typename _Tp>
    struct is_swappable
    : public __is_swappable_impl<_Tp>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_nothrow_swappable
    : public __is_nothrow_swappable_impl<_Tp>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };



  template<typename _Tp>
    inline constexpr bool is_swappable_v =
      is_swappable<_Tp>::value;


  template<typename _Tp>
    inline constexpr bool is_nothrow_swappable_v =
      is_nothrow_swappable<_Tp>::value;



  namespace __swappable_with_details {
    using std::swap;

    struct __do_is_swappable_with_impl
    {
      template<typename _Tp, typename _Up, typename
               = decltype(swap(std::declval<_Tp>(), std::declval<_Up>())),
               typename
               = decltype(swap(std::declval<_Up>(), std::declval<_Tp>()))>
        static true_type __test(int);

      template<typename, typename>
        static false_type __test(...);
    };

    struct __do_is_nothrow_swappable_with_impl
    {
      template<typename _Tp, typename _Up>
        static __bool_constant<
          noexcept(swap(std::declval<_Tp>(), std::declval<_Up>()))
          &&
          noexcept(swap(std::declval<_Up>(), std::declval<_Tp>()))
        > __test(int);

      template<typename, typename>
        static false_type __test(...);
    };

  }

  template<typename _Tp, typename _Up>
    struct __is_swappable_with_impl
    : public __swappable_with_details::__do_is_swappable_with_impl
    {
      using type = decltype(__test<_Tp, _Up>(0));
    };


  template<typename _Tp>
    struct __is_swappable_with_impl<_Tp&, _Tp&>
    : public __swappable_details::__do_is_swappable_impl
    {
      using type = decltype(__test<_Tp&>(0));
    };

  template<typename _Tp, typename _Up>
    struct __is_nothrow_swappable_with_impl
    : public __swappable_with_details::__do_is_nothrow_swappable_with_impl
    {
      using type = decltype(__test<_Tp, _Up>(0));
    };


  template<typename _Tp>
    struct __is_nothrow_swappable_with_impl<_Tp&, _Tp&>
    : public __swappable_details::__do_is_nothrow_swappable_impl
    {
      using type = decltype(__test<_Tp&>(0));
    };



  template<typename _Tp, typename _Up>
    struct is_swappable_with
    : public __is_swappable_with_impl<_Tp, _Up>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "first template argument must be a complete class or an unbounded array");
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Up>{}),
 "second template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp, typename _Up>
    struct is_nothrow_swappable_with
    : public __is_nothrow_swappable_with_impl<_Tp, _Up>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "first template argument must be a complete class or an unbounded array");
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Up>{}),
 "second template argument must be a complete class or an unbounded array");
    };



  template<typename _Tp, typename _Up>
    inline constexpr bool is_swappable_with_v =
      is_swappable_with<_Tp, _Up>::value;


  template<typename _Tp, typename _Up>
    inline constexpr bool is_nothrow_swappable_with_v =
      is_nothrow_swappable_with<_Tp, _Up>::value;
# 3149 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Result, typename _Ret,
    bool = is_void<_Ret>::value, typename = void>
    struct __is_invocable_impl
    : false_type
    {
      using __nothrow_conv = false_type;
    };


  template<typename _Result, typename _Ret>
    struct __is_invocable_impl<_Result, _Ret,
                                true,
          __void_t<typename _Result::type>>
    : true_type
    {
      using __nothrow_conv = true_type;
    };

#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wctor-dtor-privacy"

  template<typename _Result, typename _Ret>
    struct __is_invocable_impl<_Result, _Ret,
                                false,
          __void_t<typename _Result::type>>
    {
    private:

      using _Res_t = typename _Result::type;



      static _Res_t _S_get() noexcept;


      template<typename _Tp>
 static void _S_conv(__type_identity_t<_Tp>) noexcept;


      template<typename _Tp,
        bool _Nothrow = noexcept(_S_conv<_Tp>(_S_get())),
        typename = decltype(_S_conv<_Tp>(_S_get())),

        bool _Dangle = __reference_converts_from_temporary(_Tp, _Res_t)



       >
 static __bool_constant<_Nothrow && !_Dangle>
 _S_test(int);

      template<typename _Tp, bool = false>
 static false_type
 _S_test(...);

    public:

      using type = decltype(_S_test<_Ret, true>(1));


      using __nothrow_conv = decltype(_S_test<_Ret>(1));
    };
#pragma GCC diagnostic pop

  template<typename _Fn, typename... _ArgTypes>
    struct __is_invocable
    : __is_invocable_impl<__invoke_result<_Fn, _ArgTypes...>, void>::type
    { };

  template<typename _Fn, typename _Tp, typename... _Args>
    constexpr bool __call_is_nt(__invoke_memfun_ref)
    {
      using _Up = typename __inv_unwrap<_Tp>::type;
      return noexcept((std::declval<_Up>().*std::declval<_Fn>())(
     std::declval<_Args>()...));
    }

  template<typename _Fn, typename _Tp, typename... _Args>
    constexpr bool __call_is_nt(__invoke_memfun_deref)
    {
      return noexcept(((*std::declval<_Tp>()).*std::declval<_Fn>())(
     std::declval<_Args>()...));
    }

  template<typename _Fn, typename _Tp>
    constexpr bool __call_is_nt(__invoke_memobj_ref)
    {
      using _Up = typename __inv_unwrap<_Tp>::type;
      return noexcept(std::declval<_Up>().*std::declval<_Fn>());
    }

  template<typename _Fn, typename _Tp>
    constexpr bool __call_is_nt(__invoke_memobj_deref)
    {
      return noexcept((*std::declval<_Tp>()).*std::declval<_Fn>());
    }

  template<typename _Fn, typename... _Args>
    constexpr bool __call_is_nt(__invoke_other)
    {
      return noexcept(std::declval<_Fn>()(std::declval<_Args>()...));
    }

  template<typename _Result, typename _Fn, typename... _Args>
    struct __call_is_nothrow
    : __bool_constant<
 std::__call_is_nt<_Fn, _Args...>(typename _Result::__invoke_type{})
      >
    { };

  template<typename _Fn, typename... _Args>
    using __call_is_nothrow_
      = __call_is_nothrow<__invoke_result<_Fn, _Args...>, _Fn, _Args...>;


  template<typename _Fn, typename... _Args>
    struct __is_nothrow_invocable
    : __and_<__is_invocable<_Fn, _Args...>,
             __call_is_nothrow_<_Fn, _Args...>>::type
    { };

#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wctor-dtor-privacy"
  struct __nonesuchbase {};
  struct __nonesuch : private __nonesuchbase {
    ~__nonesuch() = delete;
    __nonesuch(__nonesuch const&) = delete;
    void operator=(__nonesuch const&) = delete;
  };
#pragma GCC diagnostic pop




  template<typename _Functor, typename... _ArgTypes>
    struct invoke_result
    : public __invoke_result<_Functor, _ArgTypes...>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Functor>{}),
 "_Functor must be a complete class or an unbounded array");
      static_assert((std::__is_complete_or_unbounded(
 __type_identity<_ArgTypes>{}) && ...),
 "each argument type must be a complete class or an unbounded array");
    };


  template<typename _Fn, typename... _Args>
    using invoke_result_t = typename invoke_result<_Fn, _Args...>::type;


  template<typename _Fn, typename... _ArgTypes>
    struct is_invocable

    : public __bool_constant<__is_invocable(_Fn, _ArgTypes...)>



    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Fn>{}),
 "_Fn must be a complete class or an unbounded array");
      static_assert((std::__is_complete_or_unbounded(
 __type_identity<_ArgTypes>{}) && ...),
 "each argument type must be a complete class or an unbounded array");
    };


  template<typename _Ret, typename _Fn, typename... _ArgTypes>
    struct is_invocable_r
    : __is_invocable_impl<__invoke_result<_Fn, _ArgTypes...>, _Ret>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Fn>{}),
 "_Fn must be a complete class or an unbounded array");
      static_assert((std::__is_complete_or_unbounded(
 __type_identity<_ArgTypes>{}) && ...),
 "each argument type must be a complete class or an unbounded array");
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Ret>{}),
 "_Ret must be a complete class or an unbounded array");
    };


  template<typename _Fn, typename... _ArgTypes>
    struct is_nothrow_invocable

    : public __bool_constant<__is_nothrow_invocable(_Fn, _ArgTypes...)>




    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Fn>{}),
 "_Fn must be a complete class or an unbounded array");
      static_assert((std::__is_complete_or_unbounded(
 __type_identity<_ArgTypes>{}) && ...),
 "each argument type must be a complete class or an unbounded array");
    };





  template<typename _Result, typename _Ret>
    using __is_nt_invocable_impl
      = typename __is_invocable_impl<_Result, _Ret>::__nothrow_conv;



  template<typename _Ret, typename _Fn, typename... _ArgTypes>
    struct is_nothrow_invocable_r
    : __and_<__is_nt_invocable_impl<__invoke_result<_Fn, _ArgTypes...>, _Ret>,
             __call_is_nothrow_<_Fn, _ArgTypes...>>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Fn>{}),
 "_Fn must be a complete class or an unbounded array");
      static_assert((std::__is_complete_or_unbounded(
 __type_identity<_ArgTypes>{}) && ...),
 "each argument type must be a complete class or an unbounded array");
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Ret>{}),
 "_Ret must be a complete class or an unbounded array");
    };
# 3385 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
template <typename _Tp>
  inline constexpr bool is_void_v = is_void<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_null_pointer_v = is_null_pointer<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_integral_v = is_integral<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_floating_point_v = is_floating_point<_Tp>::value;


template <typename _Tp>
  inline constexpr bool is_array_v = __is_array(_Tp);
# 3407 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
template <typename _Tp>
  inline constexpr bool is_pointer_v = __is_pointer(_Tp);
# 3422 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
template <typename _Tp>
  inline constexpr bool is_lvalue_reference_v = false;
template <typename _Tp>
  inline constexpr bool is_lvalue_reference_v<_Tp&> = true;
template <typename _Tp>
  inline constexpr bool is_rvalue_reference_v = false;
template <typename _Tp>
  inline constexpr bool is_rvalue_reference_v<_Tp&&> = true;


template <typename _Tp>
  inline constexpr bool is_member_object_pointer_v =
    __is_member_object_pointer(_Tp);







template <typename _Tp>
  inline constexpr bool is_member_function_pointer_v =
    __is_member_function_pointer(_Tp);






template <typename _Tp>
  inline constexpr bool is_enum_v = __is_enum(_Tp);
template <typename _Tp>
  inline constexpr bool is_union_v = __is_union(_Tp);
template <typename _Tp>
  inline constexpr bool is_class_v = __is_class(_Tp);



template <typename _Tp>
  inline constexpr bool is_reference_v = __is_reference(_Tp);
# 3471 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
template <typename _Tp>
  inline constexpr bool is_arithmetic_v = is_arithmetic<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_fundamental_v = is_fundamental<_Tp>::value;


template <typename _Tp>
  inline constexpr bool is_object_v = __is_object(_Tp);





template <typename _Tp>
  inline constexpr bool is_scalar_v = is_scalar<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_compound_v = !is_fundamental_v<_Tp>;


template <typename _Tp>
  inline constexpr bool is_member_pointer_v = __is_member_pointer(_Tp);






template <typename _Tp>
  inline constexpr bool is_const_v = __is_const(_Tp);
# 3508 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
template <typename _Tp>
  inline constexpr bool is_function_v = __is_function(_Tp);
# 3520 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
template <typename _Tp>
  inline constexpr bool is_volatile_v = __is_volatile(_Tp);







template <typename _Tp>
 
  inline constexpr bool is_trivial_v = __is_trivial(_Tp);
template <typename _Tp>
  inline constexpr bool is_trivially_copyable_v = __is_trivially_copyable(_Tp);
template <typename _Tp>
  inline constexpr bool is_standard_layout_v = __is_standard_layout(_Tp);
template <typename _Tp>
  __attribute__ ((__deprecated__ ("use '" "is_standard_layout_v && is_trivial_v" "' instead")))
  inline constexpr bool is_pod_v = __is_pod(_Tp);
template <typename _Tp>
  [[__deprecated__]]
  inline constexpr bool is_literal_type_v = __is_literal_type(_Tp);
template <typename _Tp>
  inline constexpr bool is_empty_v = __is_empty(_Tp);
template <typename _Tp>
  inline constexpr bool is_polymorphic_v = __is_polymorphic(_Tp);
template <typename _Tp>
  inline constexpr bool is_abstract_v = __is_abstract(_Tp);
template <typename _Tp>
  inline constexpr bool is_final_v = __is_final(_Tp);

template <typename _Tp>
  inline constexpr bool is_signed_v = is_signed<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_unsigned_v = is_unsigned<_Tp>::value;

template <typename _Tp, typename... _Args>
  inline constexpr bool is_constructible_v = __is_constructible(_Tp, _Args...);
template <typename _Tp>
  inline constexpr bool is_default_constructible_v = __is_constructible(_Tp);
template <typename _Tp>
  inline constexpr bool is_copy_constructible_v
    = __is_constructible(_Tp, __add_lval_ref_t<const _Tp>);
template <typename _Tp>
  inline constexpr bool is_move_constructible_v
    = __is_constructible(_Tp, __add_rval_ref_t<_Tp>);

template <typename _Tp, typename _Up>
  inline constexpr bool is_assignable_v = __is_assignable(_Tp, _Up);
template <typename _Tp>
  inline constexpr bool is_copy_assignable_v
    = __is_assignable(__add_lval_ref_t<_Tp>, __add_lval_ref_t<const _Tp>);
template <typename _Tp>
  inline constexpr bool is_move_assignable_v
    = __is_assignable(__add_lval_ref_t<_Tp>, __add_rval_ref_t<_Tp>);

template <typename _Tp>
  inline constexpr bool is_destructible_v = is_destructible<_Tp>::value;

template <typename _Tp, typename... _Args>
  inline constexpr bool is_trivially_constructible_v
    = __is_trivially_constructible(_Tp, _Args...);
template <typename _Tp>
  inline constexpr bool is_trivially_default_constructible_v
    = __is_trivially_constructible(_Tp);
template <typename _Tp>
  inline constexpr bool is_trivially_copy_constructible_v
    = __is_trivially_constructible(_Tp, __add_lval_ref_t<const _Tp>);
template <typename _Tp>
  inline constexpr bool is_trivially_move_constructible_v
    = __is_trivially_constructible(_Tp, __add_rval_ref_t<_Tp>);

template <typename _Tp, typename _Up>
  inline constexpr bool is_trivially_assignable_v
    = __is_trivially_assignable(_Tp, _Up);
template <typename _Tp>
  inline constexpr bool is_trivially_copy_assignable_v
    = __is_trivially_assignable(__add_lval_ref_t<_Tp>,
    __add_lval_ref_t<const _Tp>);
template <typename _Tp>
  inline constexpr bool is_trivially_move_assignable_v
    = __is_trivially_assignable(__add_lval_ref_t<_Tp>,
    __add_rval_ref_t<_Tp>);


template <typename _Tp>
  inline constexpr bool is_trivially_destructible_v = false;

template <typename _Tp>
  requires (!is_reference_v<_Tp>) && requires (_Tp& __t) { __t.~_Tp(); }
  inline constexpr bool is_trivially_destructible_v<_Tp>
    = __has_trivial_destructor(_Tp);
template <typename _Tp>
  inline constexpr bool is_trivially_destructible_v<_Tp&> = true;
template <typename _Tp>
  inline constexpr bool is_trivially_destructible_v<_Tp&&> = true;
template <typename _Tp, size_t _Nm>
  inline constexpr bool is_trivially_destructible_v<_Tp[_Nm]>
    = is_trivially_destructible_v<_Tp>;






template <typename _Tp, typename... _Args>
  inline constexpr bool is_nothrow_constructible_v
    = __is_nothrow_constructible(_Tp, _Args...);
template <typename _Tp>
  inline constexpr bool is_nothrow_default_constructible_v
    = __is_nothrow_constructible(_Tp);
template <typename _Tp>
  inline constexpr bool is_nothrow_copy_constructible_v
    = __is_nothrow_constructible(_Tp, __add_lval_ref_t<const _Tp>);
template <typename _Tp>
  inline constexpr bool is_nothrow_move_constructible_v
    = __is_nothrow_constructible(_Tp, __add_rval_ref_t<_Tp>);

template <typename _Tp, typename _Up>
  inline constexpr bool is_nothrow_assignable_v
    = __is_nothrow_assignable(_Tp, _Up);
template <typename _Tp>
  inline constexpr bool is_nothrow_copy_assignable_v
    = __is_nothrow_assignable(__add_lval_ref_t<_Tp>,
         __add_lval_ref_t<const _Tp>);
template <typename _Tp>
  inline constexpr bool is_nothrow_move_assignable_v
    = __is_nothrow_assignable(__add_lval_ref_t<_Tp>, __add_rval_ref_t<_Tp>);

template <typename _Tp>
  inline constexpr bool is_nothrow_destructible_v =
    is_nothrow_destructible<_Tp>::value;

template <typename _Tp>
  inline constexpr bool has_virtual_destructor_v
    = __has_virtual_destructor(_Tp);

template <typename _Tp>
  inline constexpr size_t alignment_of_v = alignment_of<_Tp>::value;



template <typename _Tp>
  inline constexpr size_t rank_v = __array_rank(_Tp);
# 3673 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
template <typename _Tp, unsigned _Idx = 0>
  inline constexpr size_t extent_v = 0;
template <typename _Tp, size_t _Size>
  inline constexpr size_t extent_v<_Tp[_Size], 0> = _Size;
template <typename _Tp, unsigned _Idx, size_t _Size>
  inline constexpr size_t extent_v<_Tp[_Size], _Idx> = extent_v<_Tp, _Idx - 1>;
template <typename _Tp>
  inline constexpr size_t extent_v<_Tp[], 0> = 0;
template <typename _Tp, unsigned _Idx>
  inline constexpr size_t extent_v<_Tp[], _Idx> = extent_v<_Tp, _Idx - 1>;


template <typename _Tp, typename _Up>
  inline constexpr bool is_same_v = __is_same(_Tp, _Up);






template <typename _Base, typename _Derived>
  inline constexpr bool is_base_of_v = __is_base_of(_Base, _Derived);





template <typename _From, typename _To>
  inline constexpr bool is_convertible_v = __is_convertible(_From, _To);




template<typename _Fn, typename... _Args>
  inline constexpr bool is_invocable_v = is_invocable<_Fn, _Args...>::value;
template<typename _Fn, typename... _Args>
  inline constexpr bool is_nothrow_invocable_v
    = is_nothrow_invocable<_Fn, _Args...>::value;
template<typename _Ret, typename _Fn, typename... _Args>
  inline constexpr bool is_invocable_r_v
    = is_invocable_r<_Ret, _Fn, _Args...>::value;
template<typename _Ret, typename _Fn, typename... _Args>
  inline constexpr bool is_nothrow_invocable_r_v
    = is_nothrow_invocable_r<_Ret, _Fn, _Args...>::value;






  template<typename _Tp>
    struct has_unique_object_representations
    : bool_constant<__has_unique_object_representations(
      remove_cv_t<remove_all_extents_t<_Tp>>
      )>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };



  template<typename _Tp>
    inline constexpr bool has_unique_object_representations_v
      = has_unique_object_representations<_Tp>::value;






  template<typename _Tp>
    struct is_aggregate
    : bool_constant<__is_aggregate(remove_cv_t<_Tp>)>
    { };






  template<typename _Tp>
    inline constexpr bool is_aggregate_v = __is_aggregate(remove_cv_t<_Tp>);
# 3765 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct remove_cvref
    { using type = __remove_cvref(_Tp); };
# 3782 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    using remove_cvref_t = typename remove_cvref<_Tp>::type;
# 3792 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct type_identity { using type = _Tp; };

  template<typename _Tp>
    using type_identity_t = typename type_identity<_Tp>::type;
# 3805 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct unwrap_reference { using type = _Tp; };

  template<typename _Tp>
    struct unwrap_reference<reference_wrapper<_Tp>> { using type = _Tp&; };

  template<typename _Tp>
    using unwrap_reference_t = typename unwrap_reference<_Tp>::type;






  template<typename _Tp>
    struct unwrap_ref_decay { using type = unwrap_reference_t<decay_t<_Tp>>; };

  template<typename _Tp>
    using unwrap_ref_decay_t = typename unwrap_ref_decay<_Tp>::type;
# 3832 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    inline constexpr bool is_bounded_array_v = __is_bounded_array(_Tp);
# 3846 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    inline constexpr bool is_unbounded_array_v = __is_unbounded_array(_Tp);
# 3858 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp>
    struct is_bounded_array
    : public bool_constant<is_bounded_array_v<_Tp>>
    { };



  template<typename _Tp>
    struct is_unbounded_array
    : public bool_constant<is_unbounded_array_v<_Tp>>
    { };





  template<typename _Tp, typename _Up>
    struct is_layout_compatible
    : bool_constant<__is_layout_compatible(_Tp, _Up)>
    { };



  template<typename _Tp, typename _Up>
    constexpr bool is_layout_compatible_v
      = __is_layout_compatible(_Tp, _Up);







  template<typename _S1, typename _S2, typename _M1, typename _M2>
    constexpr bool
    is_corresponding_member(_M1 _S1::*__m1, _M2 _S2::*__m2) noexcept
    { return __builtin_is_corresponding_member(__m1, __m2); }







  template<typename _Base, typename _Derived>
    struct is_pointer_interconvertible_base_of
    : bool_constant<__is_pointer_interconvertible_base_of(_Base, _Derived)>
    { };



  template<typename _Base, typename _Derived>
    constexpr bool is_pointer_interconvertible_base_of_v
      = __is_pointer_interconvertible_base_of(_Base, _Derived);
# 3921 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  template<typename _Tp, typename _Mem>
    constexpr bool
    is_pointer_interconvertible_with_class(_Mem _Tp::*__mp) noexcept
    { return __builtin_is_pointer_interconvertible_with_class(__mp); }
# 4005 "C:/msys64/mingw64/include/c++/15.2.0/type_traits" 3
  constexpr inline bool
  is_constant_evaluated() noexcept
  {



    return __builtin_is_constant_evaluated();

  }




  template<typename _From, typename _To>
    using __copy_cv = typename __match_cv_qualifiers<_From, _To>::__type;

  template<typename _Xp, typename _Yp>
    using __cond_res
      = decltype(false ? declval<_Xp(&)()>()() : declval<_Yp(&)()>()());

  template<typename _Ap, typename _Bp, typename = void>
    struct __common_ref_impl
    { };


  template<typename _Ap, typename _Bp>
    using __common_ref = typename __common_ref_impl<_Ap, _Bp>::type;


  template<typename _Xp, typename _Yp>
    using __condres_cvref
      = __cond_res<__copy_cv<_Xp, _Yp>&, __copy_cv<_Yp, _Xp>&>;


  template<typename _Xp, typename _Yp>
    struct __common_ref_impl<_Xp&, _Yp&, __void_t<__condres_cvref<_Xp, _Yp>>>
    : enable_if<is_reference_v<__condres_cvref<_Xp, _Yp>>,
  __condres_cvref<_Xp, _Yp>>
    { };


  template<typename _Xp, typename _Yp>
    using __common_ref_C = remove_reference_t<__common_ref<_Xp&, _Yp&>>&&;


  template<typename _Xp, typename _Yp>
    struct __common_ref_impl<_Xp&&, _Yp&&,
      _Require<is_convertible<_Xp&&, __common_ref_C<_Xp, _Yp>>,
        is_convertible<_Yp&&, __common_ref_C<_Xp, _Yp>>>>
    { using type = __common_ref_C<_Xp, _Yp>; };


  template<typename _Xp, typename _Yp>
    using __common_ref_D = __common_ref<const _Xp&, _Yp&>;


  template<typename _Xp, typename _Yp>
    struct __common_ref_impl<_Xp&&, _Yp&,
      _Require<is_convertible<_Xp&&, __common_ref_D<_Xp, _Yp>>>>
    { using type = __common_ref_D<_Xp, _Yp>; };


  template<typename _Xp, typename _Yp>
    struct __common_ref_impl<_Xp&, _Yp&&>
    : __common_ref_impl<_Yp&&, _Xp&>
    { };


  template<typename _Tp, typename _Up,
    template<typename> class _TQual, template<typename> class _UQual>
    struct basic_common_reference
    { };


  template<typename _Tp>
    struct __xref
    { template<typename _Up> using __type = __copy_cv<_Tp, _Up>; };

  template<typename _Tp>
    struct __xref<_Tp&>
    { template<typename _Up> using __type = __copy_cv<_Tp, _Up>&; };

  template<typename _Tp>
    struct __xref<_Tp&&>
    { template<typename _Up> using __type = __copy_cv<_Tp, _Up>&&; };

  template<typename _Tp1, typename _Tp2>
    using __basic_common_ref
      = typename basic_common_reference<remove_cvref_t<_Tp1>,
     remove_cvref_t<_Tp2>,
     __xref<_Tp1>::template __type,
     __xref<_Tp2>::template __type>::type;


  template<typename... _Tp>
    struct common_reference;

  template<typename... _Tp>
    using common_reference_t = typename common_reference<_Tp...>::type;


  template<>
    struct common_reference<>
    { };


  template<typename _Tp0>
    struct common_reference<_Tp0>
    { using type = _Tp0; };


  template<typename _Tp1, typename _Tp2, int _Bullet = 1, typename = void>
    struct __common_reference_impl
    : __common_reference_impl<_Tp1, _Tp2, _Bullet + 1>
    { };


  template<typename _Tp1, typename _Tp2>
    struct common_reference<_Tp1, _Tp2>
    : __common_reference_impl<_Tp1, _Tp2>
    { };


  template<typename _Tp1, typename _Tp2>
    struct __common_reference_impl<_Tp1&, _Tp2&, 1,
       void_t<__common_ref<_Tp1&, _Tp2&>>>
    { using type = __common_ref<_Tp1&, _Tp2&>; };

  template<typename _Tp1, typename _Tp2>
    struct __common_reference_impl<_Tp1&&, _Tp2&&, 1,
       void_t<__common_ref<_Tp1&&, _Tp2&&>>>
    { using type = __common_ref<_Tp1&&, _Tp2&&>; };

  template<typename _Tp1, typename _Tp2>
    struct __common_reference_impl<_Tp1&, _Tp2&&, 1,
       void_t<__common_ref<_Tp1&, _Tp2&&>>>
    { using type = __common_ref<_Tp1&, _Tp2&&>; };

  template<typename _Tp1, typename _Tp2>
    struct __common_reference_impl<_Tp1&&, _Tp2&, 1,
       void_t<__common_ref<_Tp1&&, _Tp2&>>>
    { using type = __common_ref<_Tp1&&, _Tp2&>; };


  template<typename _Tp1, typename _Tp2>
    struct __common_reference_impl<_Tp1, _Tp2, 2,
       void_t<__basic_common_ref<_Tp1, _Tp2>>>
    { using type = __basic_common_ref<_Tp1, _Tp2>; };


  template<typename _Tp1, typename _Tp2>
    struct __common_reference_impl<_Tp1, _Tp2, 3,
       void_t<__cond_res<_Tp1, _Tp2>>>
    { using type = __cond_res<_Tp1, _Tp2>; };


  template<typename _Tp1, typename _Tp2>
    struct __common_reference_impl<_Tp1, _Tp2, 4,
       void_t<common_type_t<_Tp1, _Tp2>>>
    { using type = common_type_t<_Tp1, _Tp2>; };


  template<typename _Tp1, typename _Tp2>
    struct __common_reference_impl<_Tp1, _Tp2, 5, void>
    { };


  template<typename _Tp1, typename _Tp2, typename... _Rest>
    struct common_reference<_Tp1, _Tp2, _Rest...>
    : __common_type_fold<common_reference<_Tp1, _Tp2>,
    __common_type_pack<_Rest...>>
    { };


  template<typename _Tp1, typename _Tp2, typename... _Rest>
    struct __common_type_fold<common_reference<_Tp1, _Tp2>,
         __common_type_pack<_Rest...>,
         void_t<common_reference_t<_Tp1, _Tp2>>>
    : public common_reference<common_reference_t<_Tp1, _Tp2>, _Rest...>
    { };







}
}
# 61 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 2 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/move.h" 1 3
# 40 "C:/msys64/mingw64/include/c++/15.2.0/bits/move.h" 3
namespace std
{







  template<typename _Tp>
    __attribute__((__always_inline__))
    inline constexpr _Tp*
    __addressof(_Tp& __r) noexcept
    { return __builtin_addressof(__r); }
# 69 "C:/msys64/mingw64/include/c++/15.2.0/bits/move.h" 3
  template<typename _Tp>
    [[__nodiscard__,__gnu__::__always_inline__]]
    constexpr _Tp&&
    forward(typename std::remove_reference<_Tp>::type& __t) noexcept
    { return static_cast<_Tp&&>(__t); }
# 82 "C:/msys64/mingw64/include/c++/15.2.0/bits/move.h" 3
  template<typename _Tp>
    [[__nodiscard__,__gnu__::__always_inline__]]
    constexpr _Tp&&
    forward(typename std::remove_reference<_Tp>::type&& __t) noexcept
    {
      static_assert(!std::is_lvalue_reference<_Tp>::value,
   "std::forward must not be used to convert an rvalue to an lvalue");
      return static_cast<_Tp&&>(__t);
    }
# 135 "C:/msys64/mingw64/include/c++/15.2.0/bits/move.h" 3
  template<typename _Tp>
    [[__nodiscard__,__gnu__::__always_inline__]]
    constexpr typename std::remove_reference<_Tp>::type&&
    move(_Tp&& __t) noexcept
    { return static_cast<typename std::remove_reference<_Tp>::type&&>(__t); }


  template<typename _Tp>
    struct __move_if_noexcept_cond
    : public __and_<__not_<is_nothrow_move_constructible<_Tp>>,
                    is_copy_constructible<_Tp>>::type { };
# 156 "C:/msys64/mingw64/include/c++/15.2.0/bits/move.h" 3
  template<typename _Tp>
    [[__nodiscard__,__gnu__::__always_inline__]]
    constexpr
    __conditional_t<__move_if_noexcept_cond<_Tp>::value, const _Tp&, _Tp&&>
    move_if_noexcept(_Tp& __x) noexcept
    { return std::move(__x); }
# 173 "C:/msys64/mingw64/include/c++/15.2.0/bits/move.h" 3
  template<typename _Tp>
    [[__nodiscard__,__gnu__::__always_inline__]]
    inline constexpr _Tp*
    addressof(_Tp& __r) noexcept
    { return std::__addressof(__r); }



  template<typename _Tp>
    const _Tp* addressof(const _Tp&&) = delete;


  template <typename _Tp, typename _Up = _Tp>
    constexpr
    inline _Tp
    __exchange(_Tp& __obj, _Up&& __new_val)
    {
      _Tp __old_val = std::move(__obj);
      __obj = std::forward<_Up>(__new_val);
      return __old_val;
    }
# 217 "C:/msys64/mingw64/include/c++/15.2.0/bits/move.h" 3
  template<typename _Tp>
    constexpr
    inline

    typename enable_if<__and_<__not_<__is_tuple_like<_Tp>>,
         is_move_constructible<_Tp>,
         is_move_assignable<_Tp>>::value>::type



    swap(_Tp& __a, _Tp& __b)
    noexcept(__and_<is_nothrow_move_constructible<_Tp>, is_nothrow_move_assignable<_Tp>>::value)

    {




      _Tp __tmp = std::move(__a);
      __a = std::move(__b);
      __b = std::move(__tmp);
    }




  template<typename _Tp, size_t _Nm>
    constexpr
    inline

    typename enable_if<__is_swappable<_Tp>::value>::type



    swap(_Tp (&__a)[_Nm], _Tp (&__b)[_Nm])
    noexcept(__is_nothrow_swappable<_Tp>::value)
    {
      for (size_t __n = 0; __n < _Nm; ++__n)
 swap(__a[__n], __b[__n]);
    }



}
# 62 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 2 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/utility.h" 1 3
# 45 "C:/msys64/mingw64/include/c++/15.2.0/bits/utility.h" 3
namespace std
{



  template<typename _Tp>
    struct tuple_size;





  template<typename _Tp,
    typename _Up = typename remove_cv<_Tp>::type,
    typename = typename enable_if<is_same<_Tp, _Up>::value>::type,
    size_t = tuple_size<_Tp>::value>
    using __enable_if_has_tuple_size = _Tp;

  template<typename _Tp>
    struct tuple_size<const __enable_if_has_tuple_size<_Tp>>
    : public tuple_size<_Tp> { };

  template<typename _Tp>
    struct tuple_size<volatile __enable_if_has_tuple_size<_Tp>>
    : public tuple_size<_Tp> { };

  template<typename _Tp>
    struct tuple_size<const volatile __enable_if_has_tuple_size<_Tp>>
    : public tuple_size<_Tp> { };


  template<typename _Tp>
    inline constexpr size_t tuple_size_v = tuple_size<_Tp>::value;



  template<size_t __i, typename _Tp>
    struct tuple_element;


  template<size_t __i, typename _Tp>
    using __tuple_element_t = typename tuple_element<__i, _Tp>::type;

  template<size_t __i, typename _Tp>
    struct tuple_element<__i, const _Tp>
    {
      using type = const __tuple_element_t<__i, _Tp>;
    };

  template<size_t __i, typename _Tp>
    struct tuple_element<__i, volatile _Tp>
    {
      using type = volatile __tuple_element_t<__i, _Tp>;
    };

  template<size_t __i, typename _Tp>
    struct tuple_element<__i, const volatile _Tp>
    {
      using type = const volatile __tuple_element_t<__i, _Tp>;
    };





  template<typename _Tp, typename... _Types>
    constexpr size_t
    __find_uniq_type_in_pack()
    {
      constexpr size_t __sz = sizeof...(_Types);
      constexpr bool __found[__sz] = { __is_same(_Tp, _Types) ... };
      size_t __n = __sz;
      for (size_t __i = 0; __i < __sz; ++__i)
 {
   if (__found[__i])
     {
       if (__n < __sz)
  return __sz;
       __n = __i;
     }
 }
      return __n;
    }
# 136 "C:/msys64/mingw64/include/c++/15.2.0/bits/utility.h" 3
  template<size_t __i, typename _Tp>
    using tuple_element_t = typename tuple_element<__i, _Tp>::type;




  template<size_t... _Indexes> struct _Index_tuple { };


  template<size_t _Num>
    struct _Build_index_tuple
    {
# 156 "C:/msys64/mingw64/include/c++/15.2.0/bits/utility.h" 3
      using __type = _Index_tuple<__integer_pack(_Num)...>;

    };




  template<typename _Tp, _Tp... _Idx>
    struct integer_sequence
    {

      static_assert(is_integral_v<_Tp>);

      typedef _Tp value_type;
      static constexpr size_t size() noexcept { return sizeof...(_Idx); }
    };


  template<typename _Tp, _Tp _Num>
    using make_integer_sequence



      = integer_sequence<_Tp, __integer_pack(_Num)...>;



  template<size_t... _Idx>
    using index_sequence = integer_sequence<size_t, _Idx...>;


  template<size_t _Num>
    using make_index_sequence = make_integer_sequence<size_t, _Num>;


  template<typename... _Types>
    using index_sequence_for = make_index_sequence<sizeof...(_Types)>;




  struct in_place_t {
    explicit in_place_t() = default;
  };

  inline constexpr in_place_t in_place{};

  template<typename _Tp> struct in_place_type_t
  {
    explicit in_place_type_t() = default;
  };

  template<typename _Tp>
    inline constexpr in_place_type_t<_Tp> in_place_type{};

  template<size_t _Idx> struct in_place_index_t
  {
    explicit in_place_index_t() = default;
  };

  template<size_t _Idx>
    inline constexpr in_place_index_t<_Idx> in_place_index{};

  template<typename>
    inline constexpr bool __is_in_place_type_v = false;

  template<typename _Tp>
    inline constexpr bool __is_in_place_type_v<in_place_type_t<_Tp>> = true;

  template<typename>
    inline constexpr bool __is_in_place_index_v = false;

  template<size_t _Nm>
    inline constexpr bool __is_in_place_index_v<in_place_index_t<_Nm>> = true;




  template<size_t _Np, typename... _Types>
    struct _Nth_type
    { using type = __type_pack_element<_Np, _Types...>; };
# 275 "C:/msys64/mingw64/include/c++/15.2.0/bits/utility.h" 3
  namespace ranges::__detail
  {
    template<typename _Range>
      inline constexpr bool __is_subrange = false;
  }




  struct _Swallow_assign
  {
    template<class _Tp>
      constexpr const _Swallow_assign&
      operator=(const _Tp&) const noexcept
      { return *this; }
  };
# 309 "C:/msys64/mingw64/include/c++/15.2.0/bits/utility.h" 3
  inline constexpr _Swallow_assign ignore{};
# 319 "C:/msys64/mingw64/include/c++/15.2.0/bits/utility.h" 3

}
# 63 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 2 3


# 1 "C:/msys64/mingw64/include/c++/15.2.0/compare" 1 3
# 38 "C:/msys64/mingw64/include/c++/15.2.0/compare" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 39 "C:/msys64/mingw64/include/c++/15.2.0/compare" 2 3



# 1 "C:/msys64/mingw64/include/c++/15.2.0/concepts" 1 3
# 38 "C:/msys64/mingw64/include/c++/15.2.0/concepts" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 39 "C:/msys64/mingw64/include/c++/15.2.0/concepts" 2 3
# 50 "C:/msys64/mingw64/include/c++/15.2.0/concepts" 3
namespace std
{




  namespace __detail
  {
    template<typename _Tp, typename _Up>
      concept __same_as = std::is_same_v<_Tp, _Up>;
  }


  template<typename _Tp, typename _Up>
    concept same_as
      = __detail::__same_as<_Tp, _Up> && __detail::__same_as<_Up, _Tp>;

  namespace __detail
  {
    template<typename _Tp, typename _Up>
      concept __different_from
 = !same_as<remove_cvref_t<_Tp>, remove_cvref_t<_Up>>;
  }


  template<typename _Derived, typename _Base>
    concept derived_from = __is_base_of(_Base, _Derived)
      && is_convertible_v<const volatile _Derived*, const volatile _Base*>;


  template<typename _From, typename _To>
    concept convertible_to = is_convertible_v<_From, _To>
      && requires { static_cast<_To>(std::declval<_From>()); };


  template<typename _Tp, typename _Up>
    concept common_reference_with
      = same_as<common_reference_t<_Tp, _Up>, common_reference_t<_Up, _Tp>>
      && convertible_to<_Tp, common_reference_t<_Tp, _Up>>
      && convertible_to<_Up, common_reference_t<_Tp, _Up>>;


  template<typename _Tp, typename _Up>
    concept common_with
      = same_as<common_type_t<_Tp, _Up>, common_type_t<_Up, _Tp>>
      && requires {
 static_cast<common_type_t<_Tp, _Up>>(std::declval<_Tp>());
 static_cast<common_type_t<_Tp, _Up>>(std::declval<_Up>());
      }
      && common_reference_with<add_lvalue_reference_t<const _Tp>,
          add_lvalue_reference_t<const _Up>>
      && common_reference_with<add_lvalue_reference_t<common_type_t<_Tp, _Up>>,
          common_reference_t<
     add_lvalue_reference_t<const _Tp>,
     add_lvalue_reference_t<const _Up>>>;



  template<typename _Tp>
    concept integral = is_integral_v<_Tp>;

  template<typename _Tp>
    concept signed_integral = integral<_Tp> && is_signed_v<_Tp>;

  template<typename _Tp>
    concept unsigned_integral = integral<_Tp> && !signed_integral<_Tp>;

  template<typename _Tp>
    concept floating_point = is_floating_point_v<_Tp>;

  namespace __detail
  {
    template<typename _Tp>
      using __cref = const remove_reference_t<_Tp>&;

    template<typename _Tp>
      concept __class_or_enum
 = is_class_v<_Tp> || is_union_v<_Tp> || is_enum_v<_Tp>;

    template<typename _Tp>
      constexpr bool __destructible_impl = false;
    template<typename _Tp>
      requires requires(_Tp& __t) { { __t.~_Tp() } noexcept; }
      constexpr bool __destructible_impl<_Tp> = true;

    template<typename _Tp>
      constexpr bool __destructible = __destructible_impl<_Tp>;
    template<typename _Tp>
      constexpr bool __destructible<_Tp&> = true;
    template<typename _Tp>
      constexpr bool __destructible<_Tp&&> = true;
    template<typename _Tp, size_t _Nm>
      constexpr bool __destructible<_Tp[_Nm]> = __destructible<_Tp>;

  }


  template<typename _Lhs, typename _Rhs>
    concept assignable_from
      = is_lvalue_reference_v<_Lhs>
      && common_reference_with<__detail::__cref<_Lhs>, __detail::__cref<_Rhs>>
      && requires(_Lhs __lhs, _Rhs&& __rhs) {
 { __lhs = static_cast<_Rhs&&>(__rhs) } -> same_as<_Lhs>;
      };


  template<typename _Tp>
    concept destructible = __detail::__destructible<_Tp>;


  template<typename _Tp, typename... _Args>
    concept constructible_from
      = destructible<_Tp> && is_constructible_v<_Tp, _Args...>;


  template<typename _Tp>
    concept default_initializable = constructible_from<_Tp>
      && requires
      {
 _Tp{};
 (void) ::new _Tp;
      };


  template<typename _Tp>
    concept move_constructible
    = constructible_from<_Tp, _Tp> && convertible_to<_Tp, _Tp>;


  template<typename _Tp>
    concept copy_constructible
      = move_constructible<_Tp>
      && constructible_from<_Tp, _Tp&> && convertible_to<_Tp&, _Tp>
      && constructible_from<_Tp, const _Tp&> && convertible_to<const _Tp&, _Tp>
      && constructible_from<_Tp, const _Tp> && convertible_to<const _Tp, _Tp>;



  namespace ranges
  {

    namespace __swap
    {
      template<typename _Tp> void swap(_Tp&, _Tp&) = delete;

      template<typename _Tp, typename _Up>
 concept __adl_swap
   = (std::__detail::__class_or_enum<remove_reference_t<_Tp>>
     || std::__detail::__class_or_enum<remove_reference_t<_Up>>)
   && requires(_Tp&& __t, _Up&& __u) {
     swap(static_cast<_Tp&&>(__t), static_cast<_Up&&>(__u));
   };

      struct _Swap
      {
      private:
 template<typename _Tp, typename _Up>
   static constexpr bool
   _S_noexcept()
   {
     if constexpr (__adl_swap<_Tp, _Up>)
       return noexcept(swap(std::declval<_Tp>(), std::declval<_Up>()));
     else
       return is_nothrow_move_constructible_v<remove_reference_t<_Tp>>
     && is_nothrow_move_assignable_v<remove_reference_t<_Tp>>;
   }

      public:
 template<typename _Tp, typename _Up>
   requires __adl_swap<_Tp, _Up>
   || (same_as<_Tp, _Up> && is_lvalue_reference_v<_Tp>
       && move_constructible<remove_reference_t<_Tp>>
       && assignable_from<_Tp, remove_reference_t<_Tp>>)
   constexpr void
   operator()(_Tp&& __t, _Up&& __u) const
   noexcept(_S_noexcept<_Tp, _Up>())
   {
     if constexpr (__adl_swap<_Tp, _Up>)
       swap(static_cast<_Tp&&>(__t), static_cast<_Up&&>(__u));
     else
       {
  auto __tmp = static_cast<remove_reference_t<_Tp>&&>(__t);
  __t = static_cast<remove_reference_t<_Tp>&&>(__u);
  __u = static_cast<remove_reference_t<_Tp>&&>(__tmp);
       }
   }

 template<typename _Tp, typename _Up, size_t _Num>
   requires requires(const _Swap& __swap, _Tp& __e1, _Up& __e2) {
     __swap(__e1, __e2);
   }
   constexpr void
   operator()(_Tp (&__e1)[_Num], _Up (&__e2)[_Num]) const
   noexcept(noexcept(std::declval<const _Swap&>()(*__e1, *__e2)))
   {
     for (size_t __n = 0; __n < _Num; ++__n)
       (*this)(__e1[__n], __e2[__n]);
   }
      };
    }


    inline namespace _Cpo {
      inline constexpr __swap::_Swap swap{};
    }
  }

  template<typename _Tp>
    concept swappable
      = requires(_Tp& __a, _Tp& __b) { ranges::swap(__a, __b); };

  template<typename _Tp, typename _Up>
    concept swappable_with = common_reference_with<_Tp, _Up>
      && requires(_Tp&& __t, _Up&& __u) {
 ranges::swap(static_cast<_Tp&&>(__t), static_cast<_Tp&&>(__t));
 ranges::swap(static_cast<_Up&&>(__u), static_cast<_Up&&>(__u));
 ranges::swap(static_cast<_Tp&&>(__t), static_cast<_Up&&>(__u));
 ranges::swap(static_cast<_Up&&>(__u), static_cast<_Tp&&>(__t));
      };



  template<typename _Tp>
    concept movable = is_object_v<_Tp> && move_constructible<_Tp>
      && assignable_from<_Tp&, _Tp> && swappable<_Tp>;

  template<typename _Tp>
    concept copyable = copy_constructible<_Tp> && movable<_Tp>
      && assignable_from<_Tp&, _Tp&> && assignable_from<_Tp&, const _Tp&>
      && assignable_from<_Tp&, const _Tp>;

  template<typename _Tp>
    concept semiregular = copyable<_Tp> && default_initializable<_Tp>;




  namespace __detail
  {
    template<typename _Tp>
      concept __boolean_testable_impl = convertible_to<_Tp, bool>;

    template<typename _Tp>
      concept __boolean_testable
 = __boolean_testable_impl<_Tp>
   && requires(_Tp&& __t)
   { { !static_cast<_Tp&&>(__t) } -> __boolean_testable_impl; };
  }



  namespace __detail
  {
    template<typename _Tp, typename _Up>
      concept __weakly_eq_cmp_with
 = requires(__detail::__cref<_Tp> __t, __detail::__cref<_Up> __u) {
   { __t == __u } -> __boolean_testable;
   { __t != __u } -> __boolean_testable;
   { __u == __t } -> __boolean_testable;
   { __u != __t } -> __boolean_testable;
 };
  }

  template<typename _Tp>
    concept equality_comparable = __detail::__weakly_eq_cmp_with<_Tp, _Tp>;

  template<typename _Tp, typename _Up>
    concept equality_comparable_with
      = equality_comparable<_Tp> && equality_comparable<_Up>
      && common_reference_with<__detail::__cref<_Tp>, __detail::__cref<_Up>>
      && equality_comparable<common_reference_t<__detail::__cref<_Tp>,
      __detail::__cref<_Up>>>
      && __detail::__weakly_eq_cmp_with<_Tp, _Up>;

  namespace __detail
  {
    template<typename _Tp, typename _Up>
      concept __partially_ordered_with
 = requires(const remove_reference_t<_Tp>& __t,
     const remove_reference_t<_Up>& __u) {
   { __t < __u } -> __boolean_testable;
   { __t > __u } -> __boolean_testable;
   { __t <= __u } -> __boolean_testable;
   { __t >= __u } -> __boolean_testable;
   { __u < __t } -> __boolean_testable;
   { __u > __t } -> __boolean_testable;
   { __u <= __t } -> __boolean_testable;
   { __u >= __t } -> __boolean_testable;
 };
  }


  template<typename _Tp>
    concept totally_ordered
      = equality_comparable<_Tp>
      && __detail::__partially_ordered_with<_Tp, _Tp>;

  template<typename _Tp, typename _Up>
    concept totally_ordered_with
      = totally_ordered<_Tp> && totally_ordered<_Up>
      && equality_comparable_with<_Tp, _Up>
      && totally_ordered<common_reference_t<__detail::__cref<_Tp>,
         __detail::__cref<_Up>>>
      && __detail::__partially_ordered_with<_Tp, _Up>;

  template<typename _Tp>
    concept regular = semiregular<_Tp> && equality_comparable<_Tp>;




  template<typename _Fn, typename... _Args>
    concept invocable = is_invocable_v<_Fn, _Args...>;


  template<typename _Fn, typename... _Args>
    concept regular_invocable = invocable<_Fn, _Args...>;


  template<typename _Fn, typename... _Args>
    concept predicate = regular_invocable<_Fn, _Args...>
      && __detail::__boolean_testable<invoke_result_t<_Fn, _Args...>>;


  template<typename _Rel, typename _Tp, typename _Up>
    concept relation
      = predicate<_Rel, _Tp, _Tp> && predicate<_Rel, _Up, _Up>
      && predicate<_Rel, _Tp, _Up> && predicate<_Rel, _Up, _Tp>;


  template<typename _Rel, typename _Tp, typename _Up>
    concept equivalence_relation = relation<_Rel, _Tp, _Up>;


  template<typename _Rel, typename _Tp, typename _Up>
    concept strict_weak_order = relation<_Rel, _Tp, _Up>;


}
# 43 "C:/msys64/mingw64/include/c++/15.2.0/compare" 2 3

#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wpedantic"
#pragma GCC diagnostic ignored "-Wzero-as-null-pointer-constant"

namespace std
{


  namespace __cmp_cat
  {
    using type = signed char;

    enum class _Ord : type { equivalent = 0, less = -1, greater = 1 };

    enum class _Ncmp : type { _Unordered = 2 };

    struct __unspec
    {
      consteval __unspec(__unspec*) noexcept { }
    };
  }

  class partial_ordering
  {

    __cmp_cat::type _M_value;

    constexpr explicit
    partial_ordering(__cmp_cat::_Ord __v) noexcept
    : _M_value(__cmp_cat::type(__v))
    { }

    constexpr explicit
    partial_ordering(__cmp_cat::_Ncmp __v) noexcept
    : _M_value(__cmp_cat::type(__v))
    { }

    friend class weak_ordering;
    friend class strong_ordering;

  public:

    static const partial_ordering less;
    static const partial_ordering equivalent;
    static const partial_ordering greater;
    static const partial_ordering unordered;


    [[nodiscard]]
    friend constexpr bool
    operator==(partial_ordering __v, __cmp_cat::__unspec) noexcept
    { return __v._M_value == 0; }

    [[nodiscard]]
    friend constexpr bool
    operator==(partial_ordering, partial_ordering) noexcept = default;

    [[nodiscard]]
    friend constexpr bool
    operator< (partial_ordering __v, __cmp_cat::__unspec) noexcept
    { return __v._M_value == -1; }

    [[nodiscard]]
    friend constexpr bool
    operator> (partial_ordering __v, __cmp_cat::__unspec) noexcept
    { return __v._M_value == 1; }

    [[nodiscard]]
    friend constexpr bool
    operator<=(partial_ordering __v, __cmp_cat::__unspec) noexcept
    { return __v._M_value <= 0; }

    [[nodiscard]]
    friend constexpr bool
    operator>=(partial_ordering __v, __cmp_cat::__unspec) noexcept
    { return __cmp_cat::type(__v._M_value & 1) == __v._M_value; }

    [[nodiscard]]
    friend constexpr bool
    operator< (__cmp_cat::__unspec, partial_ordering __v) noexcept
    { return __v._M_value == 1; }

    [[nodiscard]]
    friend constexpr bool
    operator> (__cmp_cat::__unspec, partial_ordering __v) noexcept
    { return __v._M_value == -1; }

    [[nodiscard]]
    friend constexpr bool
    operator<=(__cmp_cat::__unspec, partial_ordering __v) noexcept
    { return __cmp_cat::type(__v._M_value & 1) == __v._M_value; }

    [[nodiscard]]
    friend constexpr bool
    operator>=(__cmp_cat::__unspec, partial_ordering __v) noexcept
    { return 0 >= __v._M_value; }

    [[nodiscard]]
    friend constexpr partial_ordering
    operator<=>(partial_ordering __v, __cmp_cat::__unspec) noexcept
    { return __v; }

    [[nodiscard]]
    friend constexpr partial_ordering
    operator<=>(__cmp_cat::__unspec, partial_ordering __v) noexcept
    {
      if (__v._M_value & 1)
 return partial_ordering(__cmp_cat::_Ord(-__v._M_value));
      else
 return __v;
    }
  };


  inline constexpr partial_ordering
  partial_ordering::less(__cmp_cat::_Ord::less);

  inline constexpr partial_ordering
  partial_ordering::equivalent(__cmp_cat::_Ord::equivalent);

  inline constexpr partial_ordering
  partial_ordering::greater(__cmp_cat::_Ord::greater);

  inline constexpr partial_ordering
  partial_ordering::unordered(__cmp_cat::_Ncmp::_Unordered);

  class weak_ordering
  {
    __cmp_cat::type _M_value;

    constexpr explicit
    weak_ordering(__cmp_cat::_Ord __v) noexcept : _M_value(__cmp_cat::type(__v))
    { }

    friend class strong_ordering;

  public:

    static const weak_ordering less;
    static const weak_ordering equivalent;
    static const weak_ordering greater;

    [[nodiscard]]
    constexpr operator partial_ordering() const noexcept
    { return partial_ordering(__cmp_cat::_Ord(_M_value)); }


    [[nodiscard]]
    friend constexpr bool
    operator==(weak_ordering __v, __cmp_cat::__unspec) noexcept
    { return __v._M_value == 0; }

    [[nodiscard]]
    friend constexpr bool
    operator==(weak_ordering, weak_ordering) noexcept = default;

    [[nodiscard]]
    friend constexpr bool
    operator< (weak_ordering __v, __cmp_cat::__unspec) noexcept
    { return __v._M_value < 0; }

    [[nodiscard]]
    friend constexpr bool
    operator> (weak_ordering __v, __cmp_cat::__unspec) noexcept
    { return __v._M_value > 0; }

    [[nodiscard]]
    friend constexpr bool
    operator<=(weak_ordering __v, __cmp_cat::__unspec) noexcept
    { return __v._M_value <= 0; }

    [[nodiscard]]
    friend constexpr bool
    operator>=(weak_ordering __v, __cmp_cat::__unspec) noexcept
    { return __v._M_value >= 0; }

    [[nodiscard]]
    friend constexpr bool
    operator< (__cmp_cat::__unspec, weak_ordering __v) noexcept
    { return 0 < __v._M_value; }

    [[nodiscard]]
    friend constexpr bool
    operator> (__cmp_cat::__unspec, weak_ordering __v) noexcept
    { return 0 > __v._M_value; }

    [[nodiscard]]
    friend constexpr bool
    operator<=(__cmp_cat::__unspec, weak_ordering __v) noexcept
    { return 0 <= __v._M_value; }

    [[nodiscard]]
    friend constexpr bool
    operator>=(__cmp_cat::__unspec, weak_ordering __v) noexcept
    { return 0 >= __v._M_value; }

    [[nodiscard]]
    friend constexpr weak_ordering
    operator<=>(weak_ordering __v, __cmp_cat::__unspec) noexcept
    { return __v; }

    [[nodiscard]]
    friend constexpr weak_ordering
    operator<=>(__cmp_cat::__unspec, weak_ordering __v) noexcept
    { return weak_ordering(__cmp_cat::_Ord(-__v._M_value)); }
  };


  inline constexpr weak_ordering
  weak_ordering::less(__cmp_cat::_Ord::less);

  inline constexpr weak_ordering
  weak_ordering::equivalent(__cmp_cat::_Ord::equivalent);

  inline constexpr weak_ordering
  weak_ordering::greater(__cmp_cat::_Ord::greater);

  class strong_ordering
  {
    __cmp_cat::type _M_value;

    constexpr explicit
    strong_ordering(__cmp_cat::_Ord __v) noexcept
    : _M_value(__cmp_cat::type(__v))
    { }

  public:

    static const strong_ordering less;
    static const strong_ordering equal;
    static const strong_ordering equivalent;
    static const strong_ordering greater;

    [[nodiscard]]
    constexpr operator partial_ordering() const noexcept
    { return partial_ordering(__cmp_cat::_Ord(_M_value)); }

    [[nodiscard]]
    constexpr operator weak_ordering() const noexcept
    { return weak_ordering(__cmp_cat::_Ord(_M_value)); }


    [[nodiscard]]
    friend constexpr bool
    operator==(strong_ordering __v, __cmp_cat::__unspec) noexcept
    { return __v._M_value == 0; }

    [[nodiscard]]
    friend constexpr bool
    operator==(strong_ordering, strong_ordering) noexcept = default;

    [[nodiscard]]
    friend constexpr bool
    operator< (strong_ordering __v, __cmp_cat::__unspec) noexcept
    { return __v._M_value < 0; }

    [[nodiscard]]
    friend constexpr bool
    operator> (strong_ordering __v, __cmp_cat::__unspec) noexcept
    { return __v._M_value > 0; }

    [[nodiscard]]
    friend constexpr bool
    operator<=(strong_ordering __v, __cmp_cat::__unspec) noexcept
    { return __v._M_value <= 0; }

    [[nodiscard]]
    friend constexpr bool
    operator>=(strong_ordering __v, __cmp_cat::__unspec) noexcept
    { return __v._M_value >= 0; }

    [[nodiscard]]
    friend constexpr bool
    operator< (__cmp_cat::__unspec, strong_ordering __v) noexcept
    { return 0 < __v._M_value; }

    [[nodiscard]]
    friend constexpr bool
    operator> (__cmp_cat::__unspec, strong_ordering __v) noexcept
    { return 0 > __v._M_value; }

    [[nodiscard]]
    friend constexpr bool
    operator<=(__cmp_cat::__unspec, strong_ordering __v) noexcept
    { return 0 <= __v._M_value; }

    [[nodiscard]]
    friend constexpr bool
    operator>=(__cmp_cat::__unspec, strong_ordering __v) noexcept
    { return 0 >= __v._M_value; }

    [[nodiscard]]
    friend constexpr strong_ordering
    operator<=>(strong_ordering __v, __cmp_cat::__unspec) noexcept
    { return __v; }

    [[nodiscard]]
    friend constexpr strong_ordering
    operator<=>(__cmp_cat::__unspec, strong_ordering __v) noexcept
    { return strong_ordering(__cmp_cat::_Ord(-__v._M_value)); }
  };


  inline constexpr strong_ordering
  strong_ordering::less(__cmp_cat::_Ord::less);

  inline constexpr strong_ordering
  strong_ordering::equal(__cmp_cat::_Ord::equivalent);

  inline constexpr strong_ordering
  strong_ordering::equivalent(__cmp_cat::_Ord::equivalent);

  inline constexpr strong_ordering
  strong_ordering::greater(__cmp_cat::_Ord::greater);



  [[nodiscard]]
  constexpr bool
  is_eq(partial_ordering __cmp) noexcept
  { return __cmp == 0; }

  [[nodiscard]]
  constexpr bool
  is_neq(partial_ordering __cmp) noexcept
  { return __cmp != 0; }

  [[nodiscard]]
  constexpr bool
  is_lt (partial_ordering __cmp) noexcept
  { return __cmp < 0; }

  [[nodiscard]]
  constexpr bool
  is_lteq(partial_ordering __cmp) noexcept
  { return __cmp <= 0; }

  [[nodiscard]]
  constexpr bool
  is_gt (partial_ordering __cmp) noexcept
  { return __cmp > 0; }

  [[nodiscard]]
  constexpr bool
  is_gteq(partial_ordering __cmp) noexcept
  { return __cmp >= 0; }

  namespace __detail
  {
    template<typename _Tp>
      inline constexpr unsigned __cmp_cat_id = 1;
    template<>
      inline constexpr unsigned __cmp_cat_id<partial_ordering> = 2;
    template<>
      inline constexpr unsigned __cmp_cat_id<weak_ordering> = 4;
    template<>
      inline constexpr unsigned __cmp_cat_id<strong_ordering> = 8;

    template<typename... _Ts>
      constexpr auto __common_cmp_cat()
      {
 constexpr unsigned __cats = (__cmp_cat_id<_Ts> | ...);

 if constexpr (__cats & 1)
   return;


 else if constexpr (bool(__cats & __cmp_cat_id<partial_ordering>))
   return partial_ordering::equivalent;


 else if constexpr (bool(__cats & __cmp_cat_id<weak_ordering>))
   return weak_ordering::equivalent;

 else
   return strong_ordering::equivalent;
      }
  }


  template<typename... _Ts>
    struct common_comparison_category
    {
      using type = decltype(__detail::__common_cmp_cat<_Ts...>());
    };



  template<typename _Tp>
    struct common_comparison_category<_Tp>
    { using type = void; };

  template<>
    struct common_comparison_category<partial_ordering>
    { using type = partial_ordering; };

  template<>
    struct common_comparison_category<weak_ordering>
    { using type = weak_ordering; };

  template<>
    struct common_comparison_category<strong_ordering>
    { using type = strong_ordering; };

  template<>
    struct common_comparison_category<>
    { using type = strong_ordering; };

  template<typename... _Ts>
    using common_comparison_category_t
      = typename common_comparison_category<_Ts...>::type;



  namespace __detail
  {
    template<typename _Tp, typename _Cat>
      concept __compares_as
 = same_as<common_comparison_category_t<_Tp, _Cat>, _Cat>;
  }


  template<typename _Tp, typename _Cat = partial_ordering>
    concept three_way_comparable
      = __detail::__weakly_eq_cmp_with<_Tp, _Tp>
      && __detail::__partially_ordered_with<_Tp, _Tp>
      && requires(const remove_reference_t<_Tp>& __a,
    const remove_reference_t<_Tp>& __b)
      {
 { __a <=> __b } -> __detail::__compares_as<_Cat>;
      };

  template<typename _Tp, typename _Up, typename _Cat = partial_ordering>
    concept three_way_comparable_with
      = three_way_comparable<_Tp, _Cat>
      && three_way_comparable<_Up, _Cat>
      && common_reference_with<const remove_reference_t<_Tp>&,
          const remove_reference_t<_Up>&>
      && three_way_comparable<
   common_reference_t<const remove_reference_t<_Tp>&,
        const remove_reference_t<_Up>&>, _Cat>
      && __detail::__weakly_eq_cmp_with<_Tp, _Up>
      && __detail::__partially_ordered_with<_Tp, _Up>
      && requires(const remove_reference_t<_Tp>& __t,
    const remove_reference_t<_Up>& __u)
      {
 { __t <=> __u } -> __detail::__compares_as<_Cat>;
 { __u <=> __t } -> __detail::__compares_as<_Cat>;
      };

  namespace __detail
  {
    template<typename _Tp, typename _Up>
      using __cmp3way_res_t
 = decltype(std::declval<_Tp>() <=> std::declval<_Up>());






    template<typename _Tp, typename _Up>
      struct __cmp3way_res_impl
      { };

    template<typename _Tp, typename _Up>
      requires requires { typename __cmp3way_res_t<__cref<_Tp>, __cref<_Up>>; }
      struct __cmp3way_res_impl<_Tp, _Up>
      {
 using type = __cmp3way_res_t<__cref<_Tp>, __cref<_Up>>;
      };
  }


  template<typename _Tp, typename _Up = _Tp>
    struct compare_three_way_result
    : __detail::__cmp3way_res_impl<_Tp, _Up>
    { };


  template<typename _Tp, typename _Up = _Tp>
    using compare_three_way_result_t
      = typename __detail::__cmp3way_res_impl<_Tp, _Up>::type;

  namespace __detail
  {




    template<typename _Tp, typename _Up>
      concept __3way_builtin_ptr_cmp
 = requires(_Tp&& __t, _Up&& __u)
   { static_cast<_Tp&&>(__t) <=> static_cast<_Up&&>(__u); }
   && convertible_to<_Tp, const volatile void*>
   && convertible_to<_Up, const volatile void*>
   && ! requires(_Tp&& __t, _Up&& __u)
   { operator<=>(static_cast<_Tp&&>(__t), static_cast<_Up&&>(__u)); }
   && ! requires(_Tp&& __t, _Up&& __u)
   { static_cast<_Tp&&>(__t).operator<=>(static_cast<_Up&&>(__u)); };
  }





  struct compare_three_way
  {
    template<typename _Tp, typename _Up>
      requires three_way_comparable_with<_Tp, _Up>
      constexpr auto
      operator() [[nodiscard]] (_Tp&& __t, _Up&& __u) const
      noexcept(noexcept(std::declval<_Tp>() <=> std::declval<_Up>()))
      {
 if constexpr (__detail::__3way_builtin_ptr_cmp<_Tp, _Up>)
   {
     auto __pt = static_cast<const volatile void*>(__t);
     auto __pu = static_cast<const volatile void*>(__u);
     if (std::__is_constant_evaluated())
       return __pt <=> __pu;
     auto __it = reinterpret_cast<long long unsigned int>(__pt);
     auto __iu = reinterpret_cast<long long unsigned int>(__pu);
     return __it <=> __iu;
   }
 else
   return static_cast<_Tp&&>(__t) <=> static_cast<_Up&&>(__u);
      }

    using is_transparent = void;
  };



  namespace __compare
  {
    template<floating_point _Tp>
      constexpr weak_ordering
      __fp_weak_ordering(_Tp __e, _Tp __f)
      {


 auto __cat = [](_Tp __fp) -> int {
   const int __sign = __builtin_signbit(__fp) ? -1 : 1;
   if (__builtin_isnormal(__fp))
     return (__fp == 0 ? 1 : 3) * __sign;
   if (__builtin_isnan(__fp))
     return 5 * __sign;
   if (int __inf = __builtin_isinf_sign(__fp))
     return 4 * __inf;
   return 2 * __sign;
 };

 auto __po = __e <=> __f;
 if (is_lt(__po))
   return weak_ordering::less;
 else if (is_gt(__po))
   return weak_ordering::greater;
 else if (__po == partial_ordering::equivalent)
   return weak_ordering::equivalent;
 else
   {

     auto __isnan_sign = [](_Tp __fp) -> int {
       return __builtin_isnan(__fp)
  ? __builtin_signbit(__fp) ? -1 : 1
  : 0;
     };
     auto __ord = __isnan_sign(__e) <=> __isnan_sign(__f);
     if (is_eq(__ord))
       return weak_ordering::equivalent;
     else if (is_lt(__ord))
       return weak_ordering::less;
     else
       return weak_ordering::greater;
   }
      }

    void strong_order() = delete;

    template<typename _Tp, typename _Up>
      concept __adl_strong = requires(_Tp&& __t, _Up&& __u)
 {
   strong_ordering(strong_order(static_cast<_Tp&&>(__t),
           static_cast<_Up&&>(__u)));
 };

    void weak_order() = delete;

    template<typename _Tp, typename _Up>
      concept __adl_weak = requires(_Tp&& __t, _Up&& __u)
 {
   weak_ordering(weak_order(static_cast<_Tp&&>(__t),
       static_cast<_Up&&>(__u)));
 };

    void partial_order() = delete;

    template<typename _Tp, typename _Up>
      concept __adl_partial = requires(_Tp&& __t, _Up&& __u)
 {
   partial_ordering(partial_order(static_cast<_Tp&&>(__t),
      static_cast<_Up&&>(__u)));
 };

    template<typename _Ord, typename _Tp, typename _Up>
      concept __cmp3way = requires(_Tp&& __t, _Up&& __u, compare_three_way __c)
 {
   _Ord(__c(static_cast<_Tp&&>(__t), static_cast<_Up&&>(__u)));
 };

    template<typename _Tp, typename _Up>
      concept __strongly_ordered
 = __adl_strong<_Tp, _Up>
   || floating_point<remove_reference_t<_Tp>>
   || __cmp3way<strong_ordering, _Tp, _Up>;

    template<typename _Tp, typename _Up>
      concept __decayed_same_as = same_as<decay_t<_Tp>, decay_t<_Up>>;

    class _Strong_order
    {
      template<typename _Tp, typename _Up>
 static constexpr bool
 _S_noexcept()
 {
   if constexpr (floating_point<decay_t<_Tp>>)
     return true;
   else if constexpr (__adl_strong<_Tp, _Up>)
     return noexcept(strong_ordering(strong_order(std::declval<_Tp>(),
        std::declval<_Up>())));
   else if constexpr (__cmp3way<strong_ordering, _Tp, _Up>)
     return noexcept(compare_three_way()(std::declval<_Tp>(),
      std::declval<_Up>()));
 }

      friend class _Weak_order;
      friend class _Strong_fallback;


      enum class _Fp_fmt
      {
 _Binary16, _Binary32, _Binary64, _Binary128,
 _X86_80bit,
 _M68k_80bit,
 _Dbldbl,
 _Bfloat16,
      };
# 705 "C:/msys64/mingw64/include/c++/15.2.0/compare" 3
      template<typename _Tp>
 static consteval _Fp_fmt
 _S_fp_fmt() noexcept
 {

   using enum _Fp_fmt;
# 725 "C:/msys64/mingw64/include/c++/15.2.0/compare" 3
   if constexpr (__is_same(_Tp, long double))
     return (-16381) == -16381 ? _X86_80bit : _M68k_80bit;


   if constexpr (__is_same(_Tp, __float80))
     return _X86_80bit;






   constexpr int __width = sizeof(_Tp) * 8;

   if constexpr (__width == 16)
     return _Binary16;
   else if constexpr (__width == 32)
     return _Binary32;
   else if constexpr (__width == 64)
     return _Binary64;
   else if constexpr (__width == 128)
     return _Binary128;
 }


      using int64_t = long long int;
      using int32_t = int;
      using int16_t = short int;
      using uint64_t = long long unsigned int;
      using uint16_t = short unsigned int;


      template<typename _Tp>
 struct _Int
 {

   uint64_t _M_lo;
   _Tp _M_hi;





   constexpr explicit
   _Int(_Tp __hi, uint64_t __lo) noexcept : _M_hi(__hi)
   { _M_lo = __lo; }

   constexpr explicit
   _Int(uint64_t __lo) noexcept : _M_hi(0)
   { _M_lo = __lo; }

   constexpr bool operator==(const _Int&) const = default;
# 787 "C:/msys64/mingw64/include/c++/15.2.0/compare" 3
   constexpr _Int&
   operator^=(const _Int& __rhs) noexcept
   {
     _M_hi ^= __rhs._M_hi;
     _M_lo ^= __rhs._M_lo;
     return *this;
   }

   constexpr strong_ordering
   operator<=>(const _Int& __rhs) const noexcept
   {
     strong_ordering __cmp = _M_hi <=> __rhs._M_hi;
     if (__cmp != strong_ordering::equal)
       return __cmp;
     return _M_lo <=> __rhs._M_lo;
   }
 };

      template<typename _Tp>
 static constexpr _Tp
 _S_compl(_Tp __t) noexcept
 {
   constexpr int __width = sizeof(_Tp) * 8;

   make_unsigned_t<_Tp> __sign = __t >> (__width - 1);


   return __t ^ (__sign >> 1);
 }


      template<typename _Tp>
 static constexpr _Int<_Tp>
 _S_compl(_Int<_Tp> __t) noexcept
 {
   constexpr int __width = sizeof(_Tp) * 8;
   make_unsigned_t<_Tp> __sign = __t._M_hi >> (__width - 1);
   __t._M_hi ^= (__sign >> 1 );
   uint64_t __sign64 = (_Tp)__sign;
   __t._M_lo ^= __sign64;
   return __t;
 }


      template<typename _Tp>
 constexpr static auto
 _S_fp_bits(_Tp __val) noexcept
 {
   if constexpr (sizeof(_Tp) == sizeof(int64_t))
     return __builtin_bit_cast(int64_t, __val);
   else if constexpr (sizeof(_Tp) == sizeof(int32_t))
     return __builtin_bit_cast(int32_t, __val);
   else if constexpr (sizeof(_Tp) == sizeof(int16_t))
     return __builtin_bit_cast(int16_t, __val);
   else
     {

       using enum _Fp_fmt;

       constexpr auto __fmt = _S_fp_fmt<_Tp>();
       if constexpr (__fmt == _X86_80bit)
  {
    if constexpr (sizeof(_Tp) == 3 * sizeof(int32_t))
      {
        auto __ival = __builtin_bit_cast(_Int<int32_t>, __val);
        return _Int<int16_t>(__ival._M_hi, __ival._M_lo);
      }
    else
      {
        auto __ival = __builtin_bit_cast(_Int<int64_t>, __val);
        return _Int<int16_t>(__ival._M_hi, __ival._M_lo);
      }
  }
       else if constexpr (__fmt == _M68k_80bit)
  {
    auto __ival = __builtin_bit_cast(_Int<int32_t>, __val);
    return _Int<int16_t>(__ival._M_hi >> 16, __ival._M_lo);
  }
       else if constexpr (sizeof(_Tp) == 2 * sizeof(int64_t))
  {

    return __builtin_bit_cast(__int128, __val);



  }
       else
  static_assert(sizeof(_Tp) == sizeof(int64_t),
         "unsupported floating-point type");
     }
 }

      template<typename _Tp>
 static constexpr strong_ordering
 _S_fp_cmp(_Tp __x, _Tp __y) noexcept
 {
# 896 "C:/msys64/mingw64/include/c++/15.2.0/compare" 3
   auto __ix = _S_fp_bits(__x);
   auto __iy = _S_fp_bits(__y);

   if (__ix == __iy)
     return strong_ordering::equal;


   using enum _Fp_fmt;

   constexpr auto __fmt = _S_fp_fmt<_Tp>();

   if constexpr (__fmt == _Dbldbl)
     {


       struct _Unpacked { double _M_hi; int64_t _M_lo; };
       auto __x2 = __builtin_bit_cast(_Unpacked, __x);
       auto __y2 = __builtin_bit_cast(_Unpacked, __y);


       auto __cmp = _S_fp_cmp(__x2._M_hi, __y2._M_hi);
       if (__cmp != strong_ordering::equal)
  return __cmp;



       if (__builtin_isnan(__x2._M_hi))
  return strong_ordering::equal;


       if (((__x2._M_lo | __y2._M_lo) & 0x7fffffffffffffffULL) == 0)
  return strong_ordering::equal;


       return _S_compl(__x2._M_lo) <=> _S_compl(__y2._M_lo);
     }
   else
     {
       if constexpr (__fmt == _M68k_80bit)
  {



    constexpr uint16_t __maxexp = 0x7fff;
    if ((__ix._M_hi & __maxexp) == __maxexp)
      __ix._M_lo |= 1ull << 63;
    if ((__iy._M_hi & __maxexp) == __maxexp)
      __iy._M_lo |= 1ull << 63;
  }
       else
  {
# 963 "C:/msys64/mingw64/include/c++/15.2.0/compare" 3
  }
       return _S_compl(__ix) <=> _S_compl(__iy);
     }
 }

    public:
      template<typename _Tp, __decayed_same_as<_Tp> _Up>
 requires __strongly_ordered<_Tp, _Up>
 constexpr strong_ordering
 operator() [[nodiscard]] (_Tp&& __e, _Up&& __f) const
 noexcept(_S_noexcept<_Tp, _Up>())
 {
   if constexpr (floating_point<decay_t<_Tp>>)
     return _S_fp_cmp(__e, __f);
   else if constexpr (__adl_strong<_Tp, _Up>)
     return strong_ordering(strong_order(static_cast<_Tp&&>(__e),
      static_cast<_Up&&>(__f)));
   else if constexpr (__cmp3way<strong_ordering, _Tp, _Up>)
     return compare_three_way()(static_cast<_Tp&&>(__e),
           static_cast<_Up&&>(__f));
 }
    };

    template<typename _Tp, typename _Up>
      concept __weakly_ordered
 = floating_point<remove_reference_t<_Tp>>
   || __adl_weak<_Tp, _Up>
   || __cmp3way<weak_ordering, _Tp, _Up>
   || __strongly_ordered<_Tp, _Up>;

    class _Weak_order
    {
      template<typename _Tp, typename _Up>
 static constexpr bool
 _S_noexcept()
 {
   if constexpr (floating_point<decay_t<_Tp>>)
     return true;
   else if constexpr (__adl_weak<_Tp, _Up>)
     return noexcept(weak_ordering(weak_order(std::declval<_Tp>(),
           std::declval<_Up>())));
   else if constexpr (__cmp3way<weak_ordering, _Tp, _Up>)
     return noexcept(compare_three_way()(std::declval<_Tp>(),
      std::declval<_Up>()));
   else if constexpr (__strongly_ordered<_Tp, _Up>)
     return _Strong_order::_S_noexcept<_Tp, _Up>();
 }

      friend class _Partial_order;
      friend class _Weak_fallback;

    public:
      template<typename _Tp, __decayed_same_as<_Tp> _Up>
 requires __weakly_ordered<_Tp, _Up>
 constexpr weak_ordering
 operator() [[nodiscard]] (_Tp&& __e, _Up&& __f) const
 noexcept(_S_noexcept<_Tp, _Up>())
 {
   if constexpr (floating_point<decay_t<_Tp>>)
     return __compare::__fp_weak_ordering(__e, __f);
   else if constexpr (__adl_weak<_Tp, _Up>)
     return weak_ordering(weak_order(static_cast<_Tp&&>(__e),
         static_cast<_Up&&>(__f)));
   else if constexpr (__cmp3way<weak_ordering, _Tp, _Up>)
     return compare_three_way()(static_cast<_Tp&&>(__e),
           static_cast<_Up&&>(__f));
   else if constexpr (__strongly_ordered<_Tp, _Up>)
     return _Strong_order{}(static_cast<_Tp&&>(__e),
       static_cast<_Up&&>(__f));
 }
    };

    template<typename _Tp, typename _Up>
      concept __partially_ordered
 = __adl_partial<_Tp, _Up>
 || __cmp3way<partial_ordering, _Tp, _Up>
 || __weakly_ordered<_Tp, _Up>;

    class _Partial_order
    {
      template<typename _Tp, typename _Up>
 static constexpr bool
 _S_noexcept()
 {
   if constexpr (__adl_partial<_Tp, _Up>)
     return noexcept(partial_ordering(partial_order(std::declval<_Tp>(),
        std::declval<_Up>())));
   else if constexpr (__cmp3way<partial_ordering, _Tp, _Up>)
     return noexcept(compare_three_way()(std::declval<_Tp>(),
      std::declval<_Up>()));
   else if constexpr (__weakly_ordered<_Tp, _Up>)
     return _Weak_order::_S_noexcept<_Tp, _Up>();
 }

      friend class _Partial_fallback;

    public:
      template<typename _Tp, __decayed_same_as<_Tp> _Up>
 requires __partially_ordered<_Tp, _Up>
 constexpr partial_ordering
 operator() [[nodiscard]] (_Tp&& __e, _Up&& __f) const
 noexcept(_S_noexcept<_Tp, _Up>())
 {
   if constexpr (__adl_partial<_Tp, _Up>)
     return partial_ordering(partial_order(static_cast<_Tp&&>(__e),
        static_cast<_Up&&>(__f)));
   else if constexpr (__cmp3way<partial_ordering, _Tp, _Up>)
     return compare_three_way()(static_cast<_Tp&&>(__e),
           static_cast<_Up&&>(__f));
   else if constexpr (__weakly_ordered<_Tp, _Up>)
     return _Weak_order{}(static_cast<_Tp&&>(__e),
     static_cast<_Up&&>(__f));
 }
    };

    template<typename _Tp, typename _Up>
      concept __op_eq_lt = requires(_Tp&& __t, _Up&& __u)
 {
   { static_cast<_Tp&&>(__t) == static_cast<_Up&&>(__u) }
     -> convertible_to<bool>;
   { static_cast<_Tp&&>(__t) < static_cast<_Up&&>(__u) }
     -> convertible_to<bool>;
 };

    class _Strong_fallback
    {
      template<typename _Tp, typename _Up>
 static constexpr bool
 _S_noexcept()
 {
   if constexpr (__strongly_ordered<_Tp, _Up>)
     return _Strong_order::_S_noexcept<_Tp, _Up>();
   else
     return noexcept(bool(std::declval<_Tp>() == std::declval<_Up>()))
       && noexcept(bool(std::declval<_Tp>() < std::declval<_Up>()));
 }

    public:
      template<typename _Tp, __decayed_same_as<_Tp> _Up>
 requires __strongly_ordered<_Tp, _Up> || __op_eq_lt<_Tp, _Up>
 constexpr strong_ordering
 operator() [[nodiscard]] (_Tp&& __e, _Up&& __f) const
 noexcept(_S_noexcept<_Tp, _Up>())
 {
   if constexpr (__strongly_ordered<_Tp, _Up>)
     return _Strong_order{}(static_cast<_Tp&&>(__e),
       static_cast<_Up&&>(__f));
   else
     return static_cast<_Tp&&>(__e) == static_cast<_Up&&>(__f)
       ? strong_ordering::equal
       : static_cast<_Tp&&>(__e) < static_cast<_Up&&>(__f)
       ? strong_ordering::less
       : strong_ordering::greater;
 }
    };

    class _Weak_fallback
    {
      template<typename _Tp, typename _Up>
 static constexpr bool
 _S_noexcept()
 {
   if constexpr (__weakly_ordered<_Tp, _Up>)
     return _Weak_order::_S_noexcept<_Tp, _Up>();
   else
     return noexcept(bool(std::declval<_Tp>() == std::declval<_Up>()))
       && noexcept(bool(std::declval<_Tp>() < std::declval<_Up>()));
 }

    public:
      template<typename _Tp, __decayed_same_as<_Tp> _Up>
 requires __weakly_ordered<_Tp, _Up> || __op_eq_lt<_Tp, _Up>
 constexpr weak_ordering
 operator() [[nodiscard]] (_Tp&& __e, _Up&& __f) const
 noexcept(_S_noexcept<_Tp, _Up>())
 {
   if constexpr (__weakly_ordered<_Tp, _Up>)
     return _Weak_order{}(static_cast<_Tp&&>(__e),
     static_cast<_Up&&>(__f));
   else
     return static_cast<_Tp&&>(__e) == static_cast<_Up&&>(__f)
       ? weak_ordering::equivalent
       : static_cast<_Tp&&>(__e) < static_cast<_Up&&>(__f)
       ? weak_ordering::less
       : weak_ordering::greater;
 }
    };



    template<typename _Tp, typename _Up>
      concept __op_eq_lt_lt = __op_eq_lt<_Tp, _Up>
 && requires(_Tp&& __t, _Up&& __u)
 {
   { static_cast<_Up&&>(__u) < static_cast<_Tp&&>(__t) }
     -> convertible_to<bool>;
 };

    class _Partial_fallback
    {
      template<typename _Tp, typename _Up>
 static constexpr bool
 _S_noexcept()
 {
   if constexpr (__partially_ordered<_Tp, _Up>)
     return _Partial_order::_S_noexcept<_Tp, _Up>();
   else
     return noexcept(bool(std::declval<_Tp>() == std::declval<_Up>()))
       && noexcept(bool(std::declval<_Tp>() < std::declval<_Up>()));
 }

    public:
      template<typename _Tp, __decayed_same_as<_Tp> _Up>
 requires __partially_ordered<_Tp, _Up> || __op_eq_lt_lt<_Tp, _Up>
 constexpr partial_ordering
 operator() [[nodiscard]] (_Tp&& __e, _Up&& __f) const
 noexcept(_S_noexcept<_Tp, _Up>())
 {
   if constexpr (__partially_ordered<_Tp, _Up>)
     return _Partial_order{}(static_cast<_Tp&&>(__e),
        static_cast<_Up&&>(__f));
   else
     return static_cast<_Tp&&>(__e) == static_cast<_Up&&>(__f)
       ? partial_ordering::equivalent
       : static_cast<_Tp&&>(__e) < static_cast<_Up&&>(__f)
       ? partial_ordering::less
       : static_cast<_Up&&>(__f) < static_cast<_Tp&&>(__e)
       ? partial_ordering::greater
       : partial_ordering::unordered;
 }
    };
  }



  inline namespace _Cpo
  {
    inline constexpr __compare::_Strong_order strong_order{};

    inline constexpr __compare::_Weak_order weak_order{};

    inline constexpr __compare::_Partial_order partial_order{};

    inline constexpr __compare::_Strong_fallback
      compare_strong_order_fallback{};

    inline constexpr __compare::_Weak_fallback
      compare_weak_order_fallback{};

    inline constexpr __compare::_Partial_fallback
      compare_partial_order_fallback{};
  }


  namespace __detail
  {

    inline constexpr struct _Synth3way
    {
      template<typename _Tp, typename _Up>
 static constexpr bool
 _S_noexcept(const _Tp* __t = nullptr, const _Up* __u = nullptr)
 {
   if constexpr (three_way_comparable_with<_Tp, _Up>)
     return noexcept(*__t <=> *__u);
   else
     return noexcept(*__t < *__u) && noexcept(*__u < *__t);
 }

      template<typename _Tp, typename _Up>
 [[nodiscard]]
 constexpr auto
 operator()(const _Tp& __t, const _Up& __u) const
 noexcept(_S_noexcept<_Tp, _Up>())
 requires requires
 {
   { __t < __u } -> __boolean_testable;
   { __u < __t } -> __boolean_testable;
 }
 {
   if constexpr (three_way_comparable_with<_Tp, _Up>)
     return __t <=> __u;
   else
     {
       if (__t < __u)
  return weak_ordering::less;
       else if (__u < __t)
  return weak_ordering::greater;
       else
  return weak_ordering::equivalent;
     }
 }
    } __synth3way = {};


    template<typename _Tp, typename _Up = _Tp>
      using __synth3way_t
 = decltype(__detail::__synth3way(std::declval<_Tp&>(),
      std::declval<_Up&>()));
  }


}

#pragma GCC diagnostic pop
# 66 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 2 3


namespace std
{

# 79 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 3
  struct piecewise_construct_t { explicit piecewise_construct_t() = default; };


  inline constexpr piecewise_construct_t piecewise_construct =
    piecewise_construct_t();




  template<typename _T1, typename _T2>
    struct pair;

  template<typename...>
    class tuple;





  template<typename _Tp, size_t _Nm>
    struct array;

  template<size_t...>
    struct _Index_tuple;

  template<typename _Tp>
    class complex;

  template<size_t _Int, class _Tp1, class _Tp2>
    constexpr typename tuple_element<_Int, pair<_Tp1, _Tp2>>::type&
    get(pair<_Tp1, _Tp2>& __in) noexcept;

  template<size_t _Int, class _Tp1, class _Tp2>
    constexpr typename tuple_element<_Int, pair<_Tp1, _Tp2>>::type&&
    get(pair<_Tp1, _Tp2>&& __in) noexcept;

  template<size_t _Int, class _Tp1, class _Tp2>
    constexpr const typename tuple_element<_Int, pair<_Tp1, _Tp2>>::type&
    get(const pair<_Tp1, _Tp2>& __in) noexcept;

  template<size_t _Int, class _Tp1, class _Tp2>
    constexpr const typename tuple_element<_Int, pair<_Tp1, _Tp2>>::type&&
    get(const pair<_Tp1, _Tp2>&& __in) noexcept;

  template<size_t __i, typename... _Elements>
    constexpr __tuple_element_t<__i, tuple<_Elements...>>&
    get(tuple<_Elements...>& __t) noexcept;

  template<size_t __i, typename... _Elements>
    constexpr const __tuple_element_t<__i, tuple<_Elements...>>&
    get(const tuple<_Elements...>& __t) noexcept;

  template<size_t __i, typename... _Elements>
    constexpr __tuple_element_t<__i, tuple<_Elements...>>&&
    get(tuple<_Elements...>&& __t) noexcept;

  template<size_t __i, typename... _Elements>
    constexpr const __tuple_element_t<__i, tuple<_Elements...>>&&
    get(const tuple<_Elements...>&& __t) noexcept;

  template<size_t _Int, typename _Tp, size_t _Nm>
    constexpr _Tp&
    get(array<_Tp, _Nm>&) noexcept;

  template<size_t _Int, typename _Tp, size_t _Nm>
    constexpr _Tp&&
    get(array<_Tp, _Nm>&&) noexcept;

  template<size_t _Int, typename _Tp, size_t _Nm>
    constexpr const _Tp&
    get(const array<_Tp, _Nm>&) noexcept;

  template<size_t _Int, typename _Tp, size_t _Nm>
    constexpr const _Tp&&
    get(const array<_Tp, _Nm>&&) noexcept;
# 278 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 3
  template<typename _U1, typename _U2> class __pair_base
  {







  };
# 301 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 3
  template<typename _T1, typename _T2>
    struct pair
    : public __pair_base<_T1, _T2>
    {
      typedef _T1 first_type;
      typedef _T2 second_type;

      _T1 first;
      _T2 second;


      constexpr pair(const pair&) = default;
      constexpr pair(pair&&) = default;

      template<typename... _Args1, typename... _Args2>
 constexpr
 pair(piecewise_construct_t, tuple<_Args1...>, tuple<_Args2...>);


      constexpr void
      swap(pair& __p)
      noexcept(__and_<__is_nothrow_swappable<_T1>,
        __is_nothrow_swappable<_T2>>::value)
      {
 using std::swap;
 swap(first, __p.first);
 swap(second, __p.second);
      }
# 349 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 3
    private:
      template<typename... _Args1, size_t... _Indexes1,
        typename... _Args2, size_t... _Indexes2>
 constexpr
 pair(tuple<_Args1...>&, tuple<_Args2...>&,
      _Index_tuple<_Indexes1...>, _Index_tuple<_Indexes2...>);
    public:





      constexpr
      explicit(__not_<__and_<__is_implicitly_default_constructible<_T1>,
        __is_implicitly_default_constructible<_T2>>>())
      pair()
      noexcept(is_nothrow_default_constructible_v<_T1>
  && is_nothrow_default_constructible_v<_T2>)
      requires is_default_constructible_v<_T1>
        && is_default_constructible_v<_T2>
      : first(), second()
      { }

    private:


      template<typename _U1, typename _U2>
 static constexpr bool
 _S_constructible()
 {
   if constexpr (is_constructible_v<_T1, _U1>)
     return is_constructible_v<_T2, _U2>;
   return false;
 }

      template<typename _U1, typename _U2>
 static constexpr bool
 _S_nothrow_constructible()
 {
   if constexpr (is_nothrow_constructible_v<_T1, _U1>)
     return is_nothrow_constructible_v<_T2, _U2>;
   return false;
 }

      template<typename _U1, typename _U2>
 static constexpr bool
 _S_convertible()
 {
   if constexpr (is_convertible_v<_U1, _T1>)
     return is_convertible_v<_U2, _T2>;
   return false;
 }


      template<typename _U1, typename _U2>
 static constexpr bool
 _S_dangles()
 {

   if constexpr (__reference_constructs_from_temporary(_T1, _U1&&))
     return true;
   else
     return __reference_constructs_from_temporary(_T2, _U2&&);



 }
# 444 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 3
    public:


      constexpr explicit(!_S_convertible<const _T1&, const _T2&>())
      pair(const _T1& __x, const _T2& __y)
      noexcept(_S_nothrow_constructible<const _T1&, const _T2&>())
      requires (_S_constructible<const _T1&, const _T2&>())
      : first(__x), second(__y)
      { }





      template<typename _U1, typename _U2>

 requires (_S_constructible<_U1, _U2>()) && (!_S_dangles<_U1, _U2>())
 constexpr explicit(!_S_convertible<_U1, _U2>())
 pair(_U1&& __x, _U2&& __y)
 noexcept(_S_nothrow_constructible<_U1, _U2>())
 : first(std::forward<_U1>(__x)), second(std::forward<_U2>(__y))
 { }




      template<typename _U1, typename _U2>

 requires (_S_constructible<_U1, _U2>()) && (_S_dangles<_U1, _U2>())
 constexpr explicit(!_S_convertible<_U1, _U2>())
 pair(_U1&&, _U2&&) = delete;


      template<typename _U1, typename _U2>
 requires (_S_constructible<const _U1&, const _U2&>())
   && (!_S_dangles<_U1, _U2>())
 constexpr explicit(!_S_convertible<const _U1&, const _U2&>())
 pair(const pair<_U1, _U2>& __p)
 noexcept(_S_nothrow_constructible<const _U1&, const _U2&>())
 : first(__p.first), second(__p.second)
 { }

      template<typename _U1, typename _U2>
 requires (_S_constructible<const _U1&, const _U2&>())
       && (_S_dangles<const _U1&, const _U2&>())
 constexpr explicit(!_S_convertible<const _U1&, const _U2&>())
 pair(const pair<_U1, _U2>&) = delete;


      template<typename _U1, typename _U2>
 requires (_S_constructible<_U1, _U2>()) && (!_S_dangles<_U1, _U2>())
 constexpr explicit(!_S_convertible<_U1, _U2>())
 pair(pair<_U1, _U2>&& __p)
 noexcept(_S_nothrow_constructible<_U1, _U2>())
 : first(std::forward<_U1>(__p.first)),
   second(std::forward<_U2>(__p.second))
 { }

      template<typename _U1, typename _U2>
 requires (_S_constructible<_U1, _U2>()) && (_S_dangles<_U1, _U2>())
 constexpr explicit(!_S_convertible<_U1, _U2>())
 pair(pair<_U1, _U2>&&) = delete;
# 557 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 3
  private:

      template<typename _U1, typename _U2>
 static constexpr bool
 _S_assignable()
 {
   if constexpr (is_assignable_v<_T1&, _U1>)
     return is_assignable_v<_T2&, _U2>;
   return false;
 }

      template<typename _U1, typename _U2>
 static constexpr bool
 _S_const_assignable()
 {
   if constexpr (is_assignable_v<const _T1&, _U1>)
     return is_assignable_v<const _T2&, _U2>;
   return false;
 }

      template<typename _U1, typename _U2>
 static constexpr bool
 _S_nothrow_assignable()
 {
   if constexpr (is_nothrow_assignable_v<_T1&, _U1>)
     return is_nothrow_assignable_v<_T2&, _U2>;
   return false;
 }
# 605 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 3
  public:

      pair& operator=(const pair&) = delete;


      constexpr pair&
      operator=(const pair& __p)
      noexcept(_S_nothrow_assignable<const _T1&, const _T2&>())
      requires (_S_assignable<const _T1&, const _T2&>())
      {
 first = __p.first;
 second = __p.second;
 return *this;
      }


      constexpr pair&
      operator=(pair&& __p)
      noexcept(_S_nothrow_assignable<_T1, _T2>())
      requires (_S_assignable<_T1, _T2>())
      {
 first = std::forward<first_type>(__p.first);
 second = std::forward<second_type>(__p.second);
 return *this;
      }


      template<typename _U1, typename _U2>
 constexpr pair&
 operator=(const pair<_U1, _U2>& __p)
 noexcept(_S_nothrow_assignable<const _U1&, const _U2&>())
 requires (_S_assignable<const _U1&, const _U2&>())
 {
   first = __p.first;
   second = __p.second;
   return *this;
 }


      template<typename _U1, typename _U2>
 constexpr pair&
 operator=(pair<_U1, _U2>&& __p)
 noexcept(_S_nothrow_assignable<_U1, _U2>())
 requires (_S_assignable<_U1, _U2>())
 {
   first = std::forward<_U1>(__p.first);
   second = std::forward<_U2>(__p.second);
   return *this;
 }
# 1015 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 3
    };




  template<typename _T1, typename _T2> pair(_T1, _T2) -> pair<_T1, _T2>;







  template<typename _T1, typename _T2, typename _U1, typename _U2>
    [[nodiscard]]
    constexpr bool
    operator==(const pair<_T1, _T2>& __x, const pair<_U1, _U2>& __y)
    requires requires {
      { __x.first == __y.first } -> __detail::__boolean_testable;
      { __x.second == __y.second } -> __detail::__boolean_testable;
    }
    { return __x.first == __y.first && __x.second == __y.second; }
# 1045 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 3
  template<typename _T1, typename _T2, typename _U1, typename _U2>
    [[nodiscard]]
    constexpr common_comparison_category_t<__detail::__synth3way_t<_T1, _U1>,
        __detail::__synth3way_t<_T2, _U2>>
    operator<=>(const pair<_T1, _T2>& __x, const pair<_U1, _U2>& __y)
    {
      if (auto __c = __detail::__synth3way(__x.first, __y.first); __c != 0)
 return __c;
      return __detail::__synth3way(__x.second, __y.second);
    }
# 1112 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 3
  template<typename _T1, typename _T2>
    constexpr inline


    typename enable_if<__and_<__is_swappable<_T1>,
                              __is_swappable<_T2>>::value>::type



    swap(pair<_T1, _T2>& __x, pair<_T1, _T2>& __y)
    noexcept(noexcept(__x.swap(__y)))
    { __x.swap(__y); }
# 1135 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 3
  template<typename _T1, typename _T2>
    typename enable_if<!__and_<__is_swappable<_T1>,
          __is_swappable<_T2>>::value>::type
    swap(pair<_T1, _T2>&, pair<_T1, _T2>&) = delete;
# 1161 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 3
  template<typename _T1, typename _T2>
    constexpr pair<typename __decay_and_strip<_T1>::__type,
                   typename __decay_and_strip<_T2>::__type>
    make_pair(_T1&& __x, _T2&& __y)
    {
      typedef typename __decay_and_strip<_T1>::__type __ds_type1;
      typedef typename __decay_and_strip<_T2>::__type __ds_type2;
      typedef pair<__ds_type1, __ds_type2> __pair_type;
      return __pair_type(std::forward<_T1>(__x), std::forward<_T2>(__y));
    }
# 1184 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 3
  template<typename _T1, typename _T2>
    struct __is_tuple_like_impl<pair<_T1, _T2>> : true_type
    { };



  template<class _Tp1, class _Tp2>
    struct tuple_size<pair<_Tp1, _Tp2>>
    : public integral_constant<size_t, 2> { };


  template<class _Tp1, class _Tp2>
    struct tuple_element<0, pair<_Tp1, _Tp2>>
    { typedef _Tp1 type; };


  template<class _Tp1, class _Tp2>
    struct tuple_element<1, pair<_Tp1, _Tp2>>
    { typedef _Tp2 type; };


  template<typename _Tp1, typename _Tp2>
    inline constexpr size_t tuple_size_v<pair<_Tp1, _Tp2>> = 2;

  template<typename _Tp1, typename _Tp2>
    inline constexpr size_t tuple_size_v<const pair<_Tp1, _Tp2>> = 2;



#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wc++14-extensions"
#pragma GCC diagnostic ignored "-Wc++17-extensions"
  template<typename _Tp>
    inline constexpr bool __is_pair = false;

  template<typename _Tp, typename _Up>
    inline constexpr bool __is_pair<pair<_Tp, _Up>> = true;
#pragma GCC diagnostic pop



  template<size_t _Int>
    struct __pair_get;

  template<>
    struct __pair_get<0>
    {
      template<typename _Tp1, typename _Tp2>
 static constexpr _Tp1&
 __get(pair<_Tp1, _Tp2>& __pair) noexcept
 { return __pair.first; }

      template<typename _Tp1, typename _Tp2>
 static constexpr _Tp1&&
 __move_get(pair<_Tp1, _Tp2>&& __pair) noexcept
 { return std::forward<_Tp1>(__pair.first); }

      template<typename _Tp1, typename _Tp2>
 static constexpr const _Tp1&
 __const_get(const pair<_Tp1, _Tp2>& __pair) noexcept
 { return __pair.first; }

      template<typename _Tp1, typename _Tp2>
 static constexpr const _Tp1&&
 __const_move_get(const pair<_Tp1, _Tp2>&& __pair) noexcept
 { return std::forward<const _Tp1>(__pair.first); }
    };

  template<>
    struct __pair_get<1>
    {
      template<typename _Tp1, typename _Tp2>
 static constexpr _Tp2&
 __get(pair<_Tp1, _Tp2>& __pair) noexcept
 { return __pair.second; }

      template<typename _Tp1, typename _Tp2>
 static constexpr _Tp2&&
 __move_get(pair<_Tp1, _Tp2>&& __pair) noexcept
 { return std::forward<_Tp2>(__pair.second); }

      template<typename _Tp1, typename _Tp2>
 static constexpr const _Tp2&
 __const_get(const pair<_Tp1, _Tp2>& __pair) noexcept
 { return __pair.second; }

      template<typename _Tp1, typename _Tp2>
 static constexpr const _Tp2&&
 __const_move_get(const pair<_Tp1, _Tp2>&& __pair) noexcept
 { return std::forward<const _Tp2>(__pair.second); }
    };






  template<size_t _Int, class _Tp1, class _Tp2>
    constexpr typename tuple_element<_Int, pair<_Tp1, _Tp2>>::type&
    get(pair<_Tp1, _Tp2>& __in) noexcept
    { return __pair_get<_Int>::__get(__in); }

  template<size_t _Int, class _Tp1, class _Tp2>
    constexpr typename tuple_element<_Int, pair<_Tp1, _Tp2>>::type&&
    get(pair<_Tp1, _Tp2>&& __in) noexcept
    { return __pair_get<_Int>::__move_get(std::move(__in)); }

  template<size_t _Int, class _Tp1, class _Tp2>
    constexpr const typename tuple_element<_Int, pair<_Tp1, _Tp2>>::type&
    get(const pair<_Tp1, _Tp2>& __in) noexcept
    { return __pair_get<_Int>::__const_get(__in); }

  template<size_t _Int, class _Tp1, class _Tp2>
    constexpr const typename tuple_element<_Int, pair<_Tp1, _Tp2>>::type&&
    get(const pair<_Tp1, _Tp2>&& __in) noexcept
    { return __pair_get<_Int>::__const_move_get(std::move(__in)); }



  template <typename _Tp, typename _Up>
    constexpr _Tp&
    get(pair<_Tp, _Up>& __p) noexcept
    { return __p.first; }

  template <typename _Tp, typename _Up>
    constexpr const _Tp&
    get(const pair<_Tp, _Up>& __p) noexcept
    { return __p.first; }

  template <typename _Tp, typename _Up>
    constexpr _Tp&&
    get(pair<_Tp, _Up>&& __p) noexcept
    { return std::move(__p.first); }

  template <typename _Tp, typename _Up>
    constexpr const _Tp&&
    get(const pair<_Tp, _Up>&& __p) noexcept
    { return std::move(__p.first); }

  template <typename _Tp, typename _Up>
    constexpr _Tp&
    get(pair<_Up, _Tp>& __p) noexcept
    { return __p.second; }

  template <typename _Tp, typename _Up>
    constexpr const _Tp&
    get(const pair<_Up, _Tp>& __p) noexcept
    { return __p.second; }

  template <typename _Tp, typename _Up>
    constexpr _Tp&&
    get(pair<_Up, _Tp>&& __p) noexcept
    { return std::move(__p.second); }

  template <typename _Tp, typename _Up>
    constexpr const _Tp&&
    get(const pair<_Up, _Tp>&& __p) noexcept
    { return std::move(__p.second); }
# 1365 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_pair.h" 3

}
# 72 "C:/msys64/mingw64/include/c++/15.2.0/utility" 2 3



# 1 "C:/msys64/mingw64/include/c++/15.2.0/initializer_list" 1 3
# 43 "C:/msys64/mingw64/include/c++/15.2.0/initializer_list" 3
namespace std
{

  template<class _E>
    class initializer_list
    {
    public:
      typedef _E value_type;
      typedef const _E& reference;
      typedef const _E& const_reference;
      typedef size_t size_type;
      typedef const _E* iterator;
      typedef const _E* const_iterator;

    private:
      iterator _M_array;
      size_type _M_len;


      constexpr initializer_list(const_iterator __a, size_type __l)
      : _M_array(__a), _M_len(__l) { }

    public:
      constexpr initializer_list() noexcept
      : _M_array(0), _M_len(0) { }


      constexpr size_type
      size() const noexcept { return _M_len; }


      constexpr const_iterator
      begin() const noexcept { return _M_array; }


      constexpr const_iterator
      end() const noexcept { return begin() + size(); }
    };







  template<class _Tp>
    constexpr const _Tp*
    begin(initializer_list<_Tp> __ils) noexcept
    { return __ils.begin(); }







  template<class _Tp>
    constexpr const _Tp*
    end(initializer_list<_Tp> __ils) noexcept
    { return __ils.end(); }
}
# 76 "C:/msys64/mingw64/include/c++/15.2.0/utility" 2 3





# 1 "C:/msys64/mingw64/include/c++/15.2.0/ext/numeric_traits.h" 1 3
# 36 "C:/msys64/mingw64/include/c++/15.2.0/ext/numeric_traits.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/cpp_type_traits.h" 1 3
# 40 "C:/msys64/mingw64/include/c++/15.2.0/bits/cpp_type_traits.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 41 "C:/msys64/mingw64/include/c++/15.2.0/bits/cpp_type_traits.h" 2 3




#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wlong-long"
# 76 "C:/msys64/mingw64/include/c++/15.2.0/bits/cpp_type_traits.h" 3
extern "C++" {

namespace std
{


  struct __true_type { };
  struct __false_type { };

  template<bool>
    struct __truth_type
    { typedef __false_type __type; };

  template<>
    struct __truth_type<true>
    { typedef __true_type __type; };



  template<class _Sp, class _Tp>
    struct __traitor
    {
      enum { __value = bool(_Sp::__value) || bool(_Tp::__value) };
      typedef typename __truth_type<__value>::__type __type;
    };


  template<typename, typename>
    struct __are_same
    {
      enum { __value = 0 };
      typedef __false_type __type;
    };

  template<typename _Tp>
    struct __are_same<_Tp, _Tp>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };




  template<typename _Tp>
    struct __is_integer
    {
      enum { __value = 0 };
      typedef __false_type __type;
    };



  template<>
    struct __is_integer<bool>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<char>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<signed char>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<unsigned char>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };


  template<>
    struct __is_integer<wchar_t>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };



  template<>
    struct __is_integer<char8_t>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };



  template<>
    struct __is_integer<char16_t>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<char32_t>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };


  template<>
    struct __is_integer<short>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<unsigned short>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<int>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<unsigned int>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<long>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<unsigned long>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<long long>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<unsigned long long>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };
# 264 "C:/msys64/mingw64/include/c++/15.2.0/bits/cpp_type_traits.h" 3
__extension__ template<> struct __is_integer<__int128> { enum { __value = 1 }; typedef __true_type __type; }; __extension__ template<> struct __is_integer<unsigned __int128> { enum { __value = 1 }; typedef __true_type __type; };
# 281 "C:/msys64/mingw64/include/c++/15.2.0/bits/cpp_type_traits.h" 3
  template<typename _Tp>
    struct __is_floating
    {
      enum { __value = 0 };
      typedef __false_type __type;
    };


  template<>
    struct __is_floating<float>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_floating<double>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_floating<long double>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };
# 358 "C:/msys64/mingw64/include/c++/15.2.0/bits/cpp_type_traits.h" 3
  template<typename _Tp>
    struct __is_arithmetic
    : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >
    { };




  template<typename _Tp>
    struct __is_char
    {
      enum { __value = 0 };
      typedef __false_type __type;
    };

  template<>
    struct __is_char<char>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };


  template<>
    struct __is_char<wchar_t>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };


  template<typename _Tp>
    struct __is_byte
    {
      enum { __value = 0 };
      typedef __false_type __type;
    };

  template<>
    struct __is_byte<char>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_byte<signed char>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_byte<unsigned char>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };


  enum class byte : unsigned char;

  template<>
    struct __is_byte<byte>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };



  template<>
    struct __is_byte<char8_t>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };



  template<typename _Tp>
    struct __is_nonvolatile_trivially_copyable
    {
      enum { __value = __is_trivially_copyable(_Tp) };
    };




  template<typename _Tp>
    struct __is_nonvolatile_trivially_copyable<volatile _Tp>
    {
      enum { __value = 0 };
    };


  template<typename _OutputIter, typename _InputIter>
    struct __memcpyable
    {
      enum { __value = 0 };
    };


  template<typename _Tp>
    struct __memcpyable<_Tp*, _Tp*>
    : __is_nonvolatile_trivially_copyable<_Tp>
    { };


  template<typename _Tp>
    struct __memcpyable<_Tp*, const _Tp*>
    : __is_nonvolatile_trivially_copyable<_Tp>
    { };

  template<typename _Tp> struct __memcpyable_integer;




  template<typename _Tp, typename _Up>
    struct __memcpyable<_Tp*, _Up*>
    {
      enum {
 __value = __memcpyable_integer<_Tp>::__width != 0
      && ((int)__memcpyable_integer<_Tp>::__width
     == (int)__memcpyable_integer<_Up>::__width)
      };
    };


  template<typename _Tp, typename _Up>
    struct __memcpyable<_Tp*, const _Up*>
    : __memcpyable<_Tp*, _Up*>
    { };

  template<typename _Tp>
    struct __memcpyable_integer
    {
      enum {
 __width = __is_integer<_Tp>::__value ? (sizeof(_Tp) * 8) : 0
      };
    };


  template<typename _Tp>
    struct __memcpyable_integer<volatile _Tp>
    { enum { __width = 0 }; };
# 592 "C:/msys64/mingw64/include/c++/15.2.0/bits/cpp_type_traits.h" 3
  template<typename _Iter1, typename _Iter2>
    struct __memcmpable
    {
      enum { __value = 0 };
    };


  template<typename _Tp>
    struct __memcmpable<_Tp*, _Tp*>
    : __is_nonvolatile_trivially_copyable<_Tp>
    { };

  template<typename _Tp>
    struct __memcmpable<const _Tp*, _Tp*>
    : __is_nonvolatile_trivially_copyable<_Tp>
    { };

  template<typename _Tp>
    struct __memcmpable<_Tp*, const _Tp*>
    : __is_nonvolatile_trivially_copyable<_Tp>
    { };







  template<typename _Tp, bool _TreatAsBytes =



 __is_byte<_Tp>::__value

    >
    struct __is_memcmp_ordered
    {
      static const bool __value = _Tp(-1) > _Tp(1);
    };

  template<typename _Tp>
    struct __is_memcmp_ordered<_Tp, false>
    {
      static const bool __value = false;
    };


  template<typename _Tp, typename _Up, bool = sizeof(_Tp) == sizeof(_Up)>
    struct __is_memcmp_ordered_with
    {
      static const bool __value = __is_memcmp_ordered<_Tp>::__value
 && __is_memcmp_ordered<_Up>::__value;
    };

  template<typename _Tp, typename _Up>
    struct __is_memcmp_ordered_with<_Tp, _Up, false>
    {
      static const bool __value = false;
    };
# 661 "C:/msys64/mingw64/include/c++/15.2.0/bits/cpp_type_traits.h" 3
  template<>
    struct __is_memcmp_ordered_with<std::byte, std::byte, true>
    { static constexpr bool __value = true; };

  template<typename _Tp, bool _SameSize>
    struct __is_memcmp_ordered_with<_Tp, std::byte, _SameSize>
    { static constexpr bool __value = false; };

  template<typename _Up, bool _SameSize>
    struct __is_memcmp_ordered_with<std::byte, _Up, _SameSize>
    { static constexpr bool __value = false; };



  template<typename _ValT, typename _Tp>
    constexpr bool __can_use_memchr_for_find

      = __is_byte<_ValT>::__value

   && (is_same_v<_Tp, _ValT> || is_integral_v<_Tp>);





  template<typename _Tp>
    struct __is_move_iterator
    {
      enum { __value = 0 };
      typedef __false_type __type;
    };



  template<typename _Iterator>
    constexpr
    inline _Iterator
    __miter_base(_Iterator __it)
    { return __it; }


}
}

#pragma GCC diagnostic pop
# 37 "C:/msys64/mingw64/include/c++/15.2.0/ext/numeric_traits.h" 2 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/ext/type_traits.h" 1 3
# 39 "C:/msys64/mingw64/include/c++/15.2.0/ext/type_traits.h" 3
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wlong-long"

extern "C++" {

namespace __gnu_cxx
{



  template<bool, typename>
    struct __enable_if
    { };

  template<typename _Tp>
    struct __enable_if<true, _Tp>
    { typedef _Tp __type; };



  template<bool _Cond, typename _Iftrue, typename _Iffalse>
    struct __conditional_type
    { typedef _Iftrue __type; };

  template<typename _Iftrue, typename _Iffalse>
    struct __conditional_type<false, _Iftrue, _Iffalse>
    { typedef _Iffalse __type; };



  template<typename _Tp>
    struct __add_unsigned
    {
    private:
      typedef __enable_if<std::__is_integer<_Tp>::__value, _Tp> __if_type;

    public:
      typedef typename __if_type::__type __type;
    };

  template<>
    struct __add_unsigned<char>
    { typedef unsigned char __type; };

  template<>
    struct __add_unsigned<signed char>
    { typedef unsigned char __type; };

  template<>
    struct __add_unsigned<short>
    { typedef unsigned short __type; };

  template<>
    struct __add_unsigned<int>
    { typedef unsigned int __type; };

  template<>
    struct __add_unsigned<long>
    { typedef unsigned long __type; };

  template<>
    struct __add_unsigned<long long>
    { typedef unsigned long long __type; };


  template<>
    struct __add_unsigned<bool>;

  template<>
    struct __add_unsigned<wchar_t>;



  template<typename _Tp>
    struct __remove_unsigned
    {
    private:
      typedef __enable_if<std::__is_integer<_Tp>::__value, _Tp> __if_type;

    public:
      typedef typename __if_type::__type __type;
    };

  template<>
    struct __remove_unsigned<char>
    { typedef signed char __type; };

  template<>
    struct __remove_unsigned<unsigned char>
    { typedef signed char __type; };

  template<>
    struct __remove_unsigned<unsigned short>
    { typedef short __type; };

  template<>
    struct __remove_unsigned<unsigned int>
    { typedef int __type; };

  template<>
    struct __remove_unsigned<unsigned long>
    { typedef long __type; };

  template<>
    struct __remove_unsigned<unsigned long long>
    { typedef long long __type; };


  template<>
    struct __remove_unsigned<bool>;

  template<>
    struct __remove_unsigned<wchar_t>;



  template<typename _Type>
    constexpr
    inline bool
    __is_null_pointer(_Type* __ptr)
    { return __ptr == 0; }

  template<typename _Type>
    constexpr
    inline bool
    __is_null_pointer(_Type)
    { return false; }


  constexpr bool
  __is_null_pointer(std::nullptr_t)
  { return true; }




  template<typename _Tp, bool = std::__is_integer<_Tp>::__value>
    struct __promote
    { typedef double __type; };




  template<typename _Tp>
    struct __promote<_Tp, false>
    { };

  template<>
    struct __promote<long double>
    { typedef long double __type; };

  template<>
    struct __promote<double>
    { typedef double __type; };

  template<>
    struct __promote<float>
    { typedef float __type; };
# 230 "C:/msys64/mingw64/include/c++/15.2.0/ext/type_traits.h" 3
  template<typename... _Tp>
    using __promoted_t = decltype((typename __promote<_Tp>::__type(0) + ...));



  template<typename _Tp, typename _Up>
    using __promote_2 = __promote<__promoted_t<_Tp, _Up>>;

  template<typename _Tp, typename _Up, typename _Vp>
    using __promote_3 = __promote<__promoted_t<_Tp, _Up, _Vp>>;

  template<typename _Tp, typename _Up, typename _Vp, typename _Wp>
    using __promote_4 = __promote<__promoted_t<_Tp, _Up, _Vp, _Wp>>;
# 274 "C:/msys64/mingw64/include/c++/15.2.0/ext/type_traits.h" 3

}
}

#pragma GCC diagnostic pop
# 38 "C:/msys64/mingw64/include/c++/15.2.0/ext/numeric_traits.h" 2 3

namespace __gnu_cxx
{

# 52 "C:/msys64/mingw64/include/c++/15.2.0/ext/numeric_traits.h" 3
  template<typename _Tp>
    struct __is_integer_nonstrict
    : public std::__is_integer<_Tp>
    {
      using std::__is_integer<_Tp>::__value;


      enum { __width = __value ? sizeof(_Tp) * 8 : 0 };
    };

  template<typename _Value>
    struct __numeric_traits_integer
    {

      static_assert(__is_integer_nonstrict<_Value>::__value,
      "invalid specialization");




      static const bool __is_signed = (_Value)(-1) < 0;
      static const int __digits
 = __is_integer_nonstrict<_Value>::__width - __is_signed;


      static const _Value __max = __is_signed
 ? (((((_Value)1 << (__digits - 1)) - 1) << 1) + 1)
 : ~(_Value)0;
      static const _Value __min = __is_signed ? -__max - 1 : (_Value)0;
    };

  template<typename _Value>
    const _Value __numeric_traits_integer<_Value>::__min;

  template<typename _Value>
    const _Value __numeric_traits_integer<_Value>::__max;

  template<typename _Value>
    const bool __numeric_traits_integer<_Value>::__is_signed;

  template<typename _Value>
    const int __numeric_traits_integer<_Value>::__digits;
# 139 "C:/msys64/mingw64/include/c++/15.2.0/ext/numeric_traits.h" 3
  template<typename _Tp>
    using __int_traits = __numeric_traits_integer<_Tp>;
# 159 "C:/msys64/mingw64/include/c++/15.2.0/ext/numeric_traits.h" 3
  template<typename _Value>
    struct __numeric_traits_floating
    {

      static const int __max_digits10 = (2 + (std::__are_same<_Value, float>::__value ? 24 : std::__are_same<_Value, double>::__value ? 53 : 64) * 643L / 2136);


      static const bool __is_signed = true;
      static const int __digits10 = (std::__are_same<_Value, float>::__value ? 6 : std::__are_same<_Value, double>::__value ? 15 : 18);
      static const int __max_exponent10 = (std::__are_same<_Value, float>::__value ? 38 : std::__are_same<_Value, double>::__value ? 308 : 4932);
    };

  template<typename _Value>
    const int __numeric_traits_floating<_Value>::__max_digits10;

  template<typename _Value>
    const bool __numeric_traits_floating<_Value>::__is_signed;

  template<typename _Value>
    const int __numeric_traits_floating<_Value>::__digits10;

  template<typename _Value>
    const int __numeric_traits_floating<_Value>::__max_exponent10;






  template<typename _Value>
    struct __numeric_traits
    : public __numeric_traits_integer<_Value>
    { };

  template<>
    struct __numeric_traits<float>
    : public __numeric_traits_floating<float>
    { };

  template<>
    struct __numeric_traits<double>
    : public __numeric_traits_floating<double>
    { };

  template<>
    struct __numeric_traits<long double>
    : public __numeric_traits_floating<long double>
    { };
# 240 "C:/msys64/mingw64/include/c++/15.2.0/ext/numeric_traits.h" 3

}
# 82 "C:/msys64/mingw64/include/c++/15.2.0/utility" 2 3
# 103 "C:/msys64/mingw64/include/c++/15.2.0/utility" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 104 "C:/msys64/mingw64/include/c++/15.2.0/utility" 2 3

namespace std
{




  template <typename _Tp, typename _Up = _Tp>
    constexpr
    inline _Tp
    exchange(_Tp& __obj, _Up&& __new_val)
    noexcept(__and_<is_nothrow_move_constructible<_Tp>,
      is_nothrow_assignable<_Tp&, _Up>>::value)
    { return std::__exchange(__obj, std::forward<_Up>(__new_val)); }



  template<typename _Tp>
    [[nodiscard]]
    constexpr add_const_t<_Tp>&
    as_const(_Tp& __t) noexcept
    { return __t; }

  template<typename _Tp>
    void as_const(const _Tp&&) = delete;



  template<typename _Tp, typename _Up>
    constexpr bool
    cmp_equal(_Tp __t, _Up __u) noexcept
    {
      static_assert(__is_standard_integer<_Tp>::value);
      static_assert(__is_standard_integer<_Up>::value);

      if constexpr (is_signed_v<_Tp> == is_signed_v<_Up>)
 return __t == __u;
      else if constexpr (is_signed_v<_Tp>)
 return __t >= 0 && make_unsigned_t<_Tp>(__t) == __u;
      else
 return __u >= 0 && __t == make_unsigned_t<_Up>(__u);
    }

  template<typename _Tp, typename _Up>
    constexpr bool
    cmp_not_equal(_Tp __t, _Up __u) noexcept
    { return !std::cmp_equal(__t, __u); }

  template<typename _Tp, typename _Up>
    constexpr bool
    cmp_less(_Tp __t, _Up __u) noexcept
    {
      static_assert(__is_standard_integer<_Tp>::value);
      static_assert(__is_standard_integer<_Up>::value);

      if constexpr (is_signed_v<_Tp> == is_signed_v<_Up>)
 return __t < __u;
      else if constexpr (is_signed_v<_Tp>)
 return __t < 0 || make_unsigned_t<_Tp>(__t) < __u;
      else
 return __u >= 0 && __t < make_unsigned_t<_Up>(__u);
    }

  template<typename _Tp, typename _Up>
    constexpr bool
    cmp_greater(_Tp __t, _Up __u) noexcept
    { return std::cmp_less(__u, __t); }

  template<typename _Tp, typename _Up>
    constexpr bool
    cmp_less_equal(_Tp __t, _Up __u) noexcept
    { return !std::cmp_less(__u, __t); }

  template<typename _Tp, typename _Up>
    constexpr bool
    cmp_greater_equal(_Tp __t, _Up __u) noexcept
    { return !std::cmp_less(__t, __u); }

  template<typename _Res, typename _Tp>
    constexpr bool
    in_range(_Tp __t) noexcept
    {
      static_assert(__is_standard_integer<_Res>::value);
      static_assert(__is_standard_integer<_Tp>::value);
      using __gnu_cxx::__int_traits;

      if constexpr (is_signed_v<_Tp> == is_signed_v<_Res>)
 return __int_traits<_Res>::__min <= __t
   && __t <= __int_traits<_Res>::__max;
      else if constexpr (is_signed_v<_Tp>)
 return __t >= 0
   && make_unsigned_t<_Tp>(__t) <= __int_traits<_Res>::__max;
      else
 return __t <= make_unsigned_t<_Res>(__int_traits<_Res>::__max);
    }
# 237 "C:/msys64/mingw64/include/c++/15.2.0/utility" 3

}
# 2826 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 2
# 2840 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bit" 1 3
# 63 "C:/msys64/mingw64/include/c++/15.2.0/bit" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 64 "C:/msys64/mingw64/include/c++/15.2.0/bit" 2 3

namespace std
{

# 87 "C:/msys64/mingw64/include/c++/15.2.0/bit" 3
  template<typename _To, typename _From>
    [[nodiscard]]
    constexpr _To
    bit_cast(const _From& __from) noexcept

    requires (sizeof(_To) == sizeof(_From))
      && is_trivially_copyable_v<_To> && is_trivially_copyable_v<_From>

    {
      return __builtin_bit_cast(_To, __from);
    }
# 157 "C:/msys64/mingw64/include/c++/15.2.0/bit" 3
  template<typename _Tp>
    constexpr _Tp
    __rotl(_Tp __x, int __s) noexcept
    {
      constexpr auto _Nd = __gnu_cxx::__int_traits<_Tp>::__digits;
      if constexpr ((_Nd & (_Nd - 1)) == 0)
 {


   constexpr unsigned __uNd = _Nd;
   const unsigned __r = __s;
   return (__x << (__r % __uNd)) | (__x >> ((-__r) % __uNd));
 }
      const int __r = __s % _Nd;
      if (__r == 0)
 return __x;
      else if (__r > 0)
 return (__x << __r) | (__x >> ((_Nd - __r) % _Nd));
      else
 return (__x >> -__r) | (__x << ((_Nd + __r) % _Nd));
    }

  template<typename _Tp>
    constexpr _Tp
    __rotr(_Tp __x, int __s) noexcept
    {
      constexpr auto _Nd = __gnu_cxx::__int_traits<_Tp>::__digits;
      if constexpr ((_Nd & (_Nd - 1)) == 0)
 {


   constexpr unsigned __uNd = _Nd;
   const unsigned __r = __s;
   return (__x >> (__r % __uNd)) | (__x << ((-__r) % __uNd));
 }
      const int __r = __s % _Nd;
      if (__r == 0)
 return __x;
      else if (__r > 0)
 return (__x >> __r) | (__x << ((_Nd - __r) % _Nd));
      else
 return (__x << -__r) | (__x >> ((_Nd + __r) % _Nd));
    }

  template<typename _Tp>
    constexpr int
    __countl_zero(_Tp __x) noexcept
    {
      using __gnu_cxx::__int_traits;
      constexpr auto _Nd = __int_traits<_Tp>::__digits;


      return __builtin_clzg(__x, _Nd);
# 249 "C:/msys64/mingw64/include/c++/15.2.0/bit" 3
    }

  template<typename _Tp>
    constexpr int
    __countl_one(_Tp __x) noexcept
    {
      return std::__countl_zero<_Tp>((_Tp)~__x);
    }

  template<typename _Tp>
    constexpr int
    __countr_zero(_Tp __x) noexcept
    {
      using __gnu_cxx::__int_traits;
      constexpr auto _Nd = __int_traits<_Tp>::__digits;


      return __builtin_ctzg(__x, _Nd);
# 294 "C:/msys64/mingw64/include/c++/15.2.0/bit" 3
    }

  template<typename _Tp>
    constexpr int
    __countr_one(_Tp __x) noexcept
    {
      return std::__countr_zero((_Tp)~__x);
    }

  template<typename _Tp>
    constexpr int
    __popcount(_Tp __x) noexcept
    {

      return __builtin_popcountg(__x);
# 334 "C:/msys64/mingw64/include/c++/15.2.0/bit" 3
    }

  template<typename _Tp>
    constexpr bool
    __has_single_bit(_Tp __x) noexcept
    { return std::__popcount(__x) == 1; }

  template<typename _Tp>
    constexpr _Tp
    __bit_ceil(_Tp __x) noexcept
    {
      using __gnu_cxx::__int_traits;
      constexpr auto _Nd = __int_traits<_Tp>::__digits;
      if (__x == 0 || __x == 1)
        return 1;
      auto __shift_exponent = _Nd - std::__countl_zero((_Tp)(__x - 1u));




      if (!std::__is_constant_evaluated())
 {
   do { if (__builtin_expect(!bool(__shift_exponent != __int_traits<_Tp>::__digits), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bit", 356, __PRETTY_FUNCTION__, "__shift_exponent != __int_traits<_Tp>::__digits"); } while (false);
 }

      using __promoted_type = decltype(__x << 1);
      if constexpr (!is_same<__promoted_type, _Tp>::value)
 {





   const int __extra_exp = sizeof(__promoted_type) / sizeof(_Tp) / 2;
   __shift_exponent |= (__shift_exponent & _Nd) << __extra_exp;
 }
      return (_Tp)1u << __shift_exponent;
    }

  template<typename _Tp>
    constexpr _Tp
    __bit_floor(_Tp __x) noexcept
    {
      constexpr auto _Nd = __gnu_cxx::__int_traits<_Tp>::__digits;
      if (__x == 0)
        return 0;
      return (_Tp)1u << (_Nd - std::__countl_zero((_Tp)(__x >> 1)));
    }

  template<typename _Tp>
    constexpr int
    __bit_width(_Tp __x) noexcept
    {
      constexpr auto _Nd = __gnu_cxx::__int_traits<_Tp>::__digits;
      return _Nd - std::__countl_zero(__x);
    }






  template<typename _Tp>
    concept __unsigned_integer = __is_unsigned_integer<_Tp>::value;





  template<__unsigned_integer _Tp>
    [[nodiscard]] constexpr _Tp
    rotl(_Tp __x, int __s) noexcept
    { return std::__rotl(__x, __s); }


  template<__unsigned_integer _Tp>
    [[nodiscard]] constexpr _Tp
    rotr(_Tp __x, int __s) noexcept
    { return std::__rotr(__x, __s); }




  template<__unsigned_integer _Tp>
    constexpr int
    countl_zero(_Tp __x) noexcept
    { return std::__countl_zero(__x); }


  template<__unsigned_integer _Tp>
    constexpr int
    countl_one(_Tp __x) noexcept
    { return std::__countl_one(__x); }


  template<__unsigned_integer _Tp>
    constexpr int
    countr_zero(_Tp __x) noexcept
    { return std::__countr_zero(__x); }


  template<__unsigned_integer _Tp>
    constexpr int
    countr_one(_Tp __x) noexcept
    { return std::__countr_one(__x); }


  template<__unsigned_integer _Tp>
    constexpr int
    popcount(_Tp __x) noexcept
    { return std::__popcount(__x); }






  template<__unsigned_integer _Tp>
    constexpr bool
    has_single_bit(_Tp __x) noexcept
    { return std::__has_single_bit(__x); }


  template<__unsigned_integer _Tp>
    constexpr _Tp
    bit_ceil(_Tp __x) noexcept
    { return std::__bit_ceil(__x); }


  template<__unsigned_integer _Tp>
    constexpr _Tp
    bit_floor(_Tp __x) noexcept
    { return std::__bit_floor(__x); }




  template<__unsigned_integer _Tp>
    constexpr int
    bit_width(_Tp __x) noexcept
    { return std::__bit_width(__x); }
# 486 "C:/msys64/mingw64/include/c++/15.2.0/bit" 3
  enum class endian
  {
    little = 1234,
    big = 4321,
    native = 1234
  };





}
# 2841 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 2



# 1 "C:/msys64/mingw64/include/c++/15.2.0/cstdio" 1 3
# 47 "C:/msys64/mingw64/include/c++/15.2.0/cstdio" 3
# 1 "C:/msys64/mingw64/include/stdio.h" 1 3
# 9 "C:/msys64/mingw64/include/stdio.h" 3
# 1 "C:/msys64/mingw64/include/corecrt_stdio_config.h" 1 3
# 13 "C:/msys64/mingw64/include/corecrt_stdio_config.h" 3
extern "C" {


unsigned long long* __attribute__((__cdecl__)) __local_stdio_printf_options(void);
unsigned long long* __attribute__((__cdecl__)) __local_stdio_scanf_options(void);
# 39 "C:/msys64/mingw64/include/corecrt_stdio_config.h" 3
}
# 10 "C:/msys64/mingw64/include/stdio.h" 2 3

#pragma pack(push,_CRT_PACKING)

       

       

       

       



extern "C" {
# 33 "C:/msys64/mingw64/include/stdio.h" 3
  struct _iobuf {



    char *_ptr;
    int _cnt;
    char *_base;
    int _flag;
    int _file;
    int _charbuf;
    int _bufsiz;
    char *_tmpfname;

  };
  typedef struct _iobuf FILE;
# 99 "C:/msys64/mingw64/include/stdio.h" 3
# 1 "C:/msys64/mingw64/include/_mingw_off_t.h" 1 3




  typedef long _off_t;

  typedef long off32_t;





  __extension__ typedef long long _off64_t;

  __extension__ typedef long long off64_t;
# 26 "C:/msys64/mingw64/include/_mingw_off_t.h" 3
typedef off32_t off_t;
# 100 "C:/msys64/mingw64/include/stdio.h" 2 3

__attribute__ ((__dllimport__)) FILE *__attribute__((__cdecl__)) __acrt_iob_func(unsigned index);

  __attribute__ ((__dllimport__)) FILE *__attribute__((__cdecl__)) __iob_func(void);
# 112 "C:/msys64/mingw64/include/stdio.h" 3
  __extension__ typedef long long fpos_t;
# 156 "C:/msys64/mingw64/include/stdio.h" 3
extern
  __attribute__((__format__(__gnu_scanf__, 2,3))) __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __mingw_sscanf(const char * __restrict__ _Src,const char * __restrict__ _Format,...);
extern
  __attribute__((__format__(__gnu_scanf__, 2,0))) __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __mingw_vsscanf (const char * __restrict__ _Str,const char * __restrict__ Format,va_list argp);
extern
  __attribute__((__format__(__gnu_scanf__, 1,2))) __attribute__ ((__nonnull__ (1)))
  int __attribute__((__cdecl__)) __mingw_scanf(const char * __restrict__ _Format,...);
extern
  __attribute__((__format__(__gnu_scanf__, 1,0))) __attribute__ ((__nonnull__ (1)))
  int __attribute__((__cdecl__)) __mingw_vscanf(const char * __restrict__ Format, va_list argp);
extern
  __attribute__((__format__(__gnu_scanf__, 2,3))) __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __mingw_fscanf(FILE * __restrict__ _File,const char * __restrict__ _Format,...);
extern
  __attribute__((__format__(__gnu_scanf__, 2,0))) __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __mingw_vfscanf (FILE * __restrict__ fp, const char * __restrict__ Format,va_list argp);

extern
  __attribute__((__format__(__gnu_printf__,3,0))) __attribute__ ((__nonnull__ (3)))
  int __attribute__((__cdecl__)) __mingw_vsnprintf(char * __restrict__ _DstBuf,size_t _MaxCount,const char * __restrict__ _Format,
                               va_list _ArgList);
extern
  __attribute__((__format__(__gnu_printf__,3,4))) __attribute__ ((__nonnull__ (3)))
  int __attribute__((__cdecl__)) __mingw_snprintf(char * __restrict__ s, size_t n, const char * __restrict__ format, ...);
extern
  __attribute__((__format__(__gnu_printf__,1,2))) __attribute__ ((__nonnull__ (1)))
  int __attribute__((__cdecl__)) __mingw_printf(const char * __restrict__ , ... ) __attribute__ ((__nothrow__));
extern
  __attribute__((__format__(__gnu_printf__,1,0))) __attribute__ ((__nonnull__ (1)))
  int __attribute__((__cdecl__)) __mingw_vprintf (const char * __restrict__ , va_list) __attribute__ ((__nothrow__));
extern
  __attribute__((__format__(__gnu_printf__,2,3))) __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __mingw_fprintf (FILE * __restrict__ , const char * __restrict__ , ...) __attribute__ ((__nothrow__));
extern
  __attribute__((__format__(__gnu_printf__,2,0))) __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __mingw_vfprintf (FILE * __restrict__ , const char * __restrict__ , va_list) __attribute__ ((__nothrow__));
extern
  __attribute__((__format__(__gnu_printf__,2,3))) __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __mingw_sprintf (char * __restrict__ , const char * __restrict__ , ...) __attribute__ ((__nothrow__));
extern
  __attribute__((__format__(__gnu_printf__,2,0))) __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __mingw_vsprintf (char * __restrict__ , const char * __restrict__ , va_list) __attribute__ ((__nothrow__));
extern
  __attribute__((__format__(__gnu_printf__,2,3))) __attribute__((nonnull (1,2)))
  int __attribute__((__cdecl__)) __mingw_asprintf(char ** __restrict__ , const char * __restrict__ , ...) __attribute__ ((__nothrow__));
extern
  __attribute__((__format__(__gnu_printf__,2,0))) __attribute__((nonnull (1,2)))
  int __attribute__((__cdecl__)) __mingw_vasprintf(char ** __restrict__ , const char * __restrict__ , va_list) __attribute__ ((__nothrow__));

extern
  __attribute__((__format__(__ms_scanf__, 2,3))) __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __ms_sscanf(const char * __restrict__ _Src,const char * __restrict__ _Format,...)
  ;
extern
  __attribute__((__format__(__ms_scanf__, 2,0))) __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __ms_vsscanf(const char * __restrict__ _Str,const char * __restrict__ _Format,va_list argp)
  __asm__("vsscanf");
extern
  __attribute__((__format__(__ms_scanf__, 1,2))) __attribute__ ((__nonnull__ (1)))
  int __attribute__((__cdecl__)) __ms_scanf(const char * __restrict__ _Format,...)
  ;
extern
  __attribute__((__format__(__ms_scanf__, 1,0))) __attribute__ ((__nonnull__ (1)))
  int __attribute__((__cdecl__)) __ms_vscanf(const char * __restrict__ _Format,va_list argp)
  __asm__("vscanf");
extern
  __attribute__((__format__(__ms_scanf__, 2,3))) __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __ms_fscanf(FILE * __restrict__ _File,const char * __restrict__ _Format,...)
  ;
extern
  __attribute__((__format__(__ms_scanf__, 2,0))) __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __ms_vfscanf(FILE * __restrict__ _File,const char * __restrict__ _Format,va_list argp)
  __asm__("vfscanf");

extern
  __attribute__((__format__(__ms_printf__, 1,2))) __attribute__ ((__nonnull__ (1)))
  int __attribute__((__cdecl__)) __ms_printf(const char * __restrict__ , ... )
  __attribute__ ((__nothrow__));
extern
  __attribute__((__format__(__ms_printf__, 1,0))) __attribute__ ((__nonnull__ (1)))
  int __attribute__((__cdecl__)) __ms_vprintf (const char * __restrict__ , va_list)
  __attribute__ ((__nothrow__));
extern
  __attribute__((__format__(__ms_printf__, 2,3))) __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __ms_fprintf (FILE * __restrict__ , const char * __restrict__ , ...)
  __attribute__ ((__nothrow__));
extern
  __attribute__((__format__(__ms_printf__, 2,0))) __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __ms_vfprintf (FILE * __restrict__ , const char * __restrict__ , va_list)
  __attribute__ ((__nothrow__))
;
extern
  __attribute__((__format__(__ms_printf__, 2,3))) __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __ms_sprintf (char * __restrict__ , const char * __restrict__ , ...)
  __attribute__ ((__nothrow__));
extern
  __attribute__((__format__(__ms_printf__, 2,0))) __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __ms_vsprintf (char * __restrict__ , const char * __restrict__ , va_list)
  __attribute__ ((__nothrow__));
extern
  __attribute__((__format__(__ms_printf__, 3,4))) __attribute__ ((__nonnull__ (3)))
  int __attribute__((__cdecl__)) __ms_snprintf (char * __restrict__ , size_t , const char * __restrict__ , ...)
  __attribute__ ((__nothrow__));
extern
  __attribute__((__format__(__ms_printf__, 3,0))) __attribute__ ((__nonnull__ (3)))
  int __attribute__((__cdecl__)) __ms_vsnprintf (char * __restrict__ , size_t , const char * __restrict__ , va_list)
  __attribute__ ((__nothrow__));
# 305 "C:/msys64/mingw64/include/stdio.h" 3
extern "C++" {


__attribute__((__format__(__gnu_scanf__, 2,3))) __attribute__ ((__nonnull__ (2)))
int sscanf(const char *__source, const char *__format, ...)
__asm__("__mingw_sscanf");

__attribute__((__format__(__gnu_scanf__, 1,2))) __attribute__ ((__nonnull__ (1)))
int scanf(const char *__format, ...)
__asm__("__mingw_scanf");

__attribute__((__format__(__gnu_scanf__, 2,3))) __attribute__ ((__nonnull__ (2)))
int fscanf(FILE *__stream, const char *__format, ...)
__asm__("__mingw_fscanf");



#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wshadow"


__attribute__((__format__(__gnu_scanf__, 2,0))) __attribute__ ((__nonnull__ (2)))
int vsscanf (const char *__source, const char *__format, __builtin_va_list __local_argv)
__asm__("__mingw_vsscanf");

__attribute__((__format__(__gnu_scanf__, 1,0))) __attribute__ ((__nonnull__ (1)))
int vscanf(const char *__format, __builtin_va_list __local_argv)
__asm__("__mingw_vscanf");

__attribute__((__format__(__gnu_scanf__, 2,0))) __attribute__ ((__nonnull__ (2)))
int vfscanf (FILE *__stream, const char *__format, __builtin_va_list __local_argv)
__asm__("__mingw_vfscanf");


#pragma GCC diagnostic pop





__attribute__((__format__(__gnu_printf__,2,3))) __attribute__ ((__nonnull__ (2)))
int fprintf (FILE *__stream, const char *__format, ...)
__asm__("__mingw_fprintf");

__attribute__((__format__(__gnu_printf__,1,2))) __attribute__ ((__nonnull__ (1)))
int printf (const char *__format, ...)
__asm__("__mingw_printf");

__attribute__((__format__(__gnu_printf__,2,3))) __attribute__ ((__nonnull__ (2)))
int sprintf (char *__stream, const char *__format, ...)
__asm__("__mingw_sprintf");
# 374 "C:/msys64/mingw64/include/stdio.h" 3
__attribute__((__format__(__gnu_printf__,2,0))) __attribute__ ((__nonnull__ (2)))
int vfprintf (FILE *__stream, const char *__format, __builtin_va_list __local_argv)
__asm__("__mingw_vfprintf");

__attribute__((__format__(__gnu_printf__,1,0))) __attribute__ ((__nonnull__ (1)))
int vprintf (const char *__format, __builtin_va_list __local_argv)
__asm__("__mingw_vprintf");

inline __attribute__((__cdecl__))
__attribute__((__format__(__gnu_printf__,2,0))) __attribute__ ((__nonnull__ (2)))
int vsprintf (char *__stream, const char *__format, __builtin_va_list __local_argv)
{
# 394 "C:/msys64/mingw64/include/stdio.h" 3
  return __mingw_vsprintf( __stream, __format, __local_argv );
}


__attribute__((__format__(__gnu_printf__,3,4))) __attribute__ ((__nonnull__ (3)))
int snprintf (char *__stream, size_t __n, const char *__format, ...)
__asm__("__mingw_snprintf");
# 414 "C:/msys64/mingw64/include/stdio.h" 3
inline __attribute__((__cdecl__))
__attribute__((__format__(__gnu_printf__,3,0))) __attribute__ ((__nonnull__ (3)))
int vsnprintf (char *__stream, size_t __n, const char *__format, __builtin_va_list __local_argv)
{



  return __mingw_vsnprintf( __stream, __n, __format, __local_argv );
}
# 431 "C:/msys64/mingw64/include/stdio.h" 3
}
# 535 "C:/msys64/mingw64/include/stdio.h" 3
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _filbuf(FILE *_File);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _flsbuf(int _Ch,FILE *_File);



  __attribute__ ((__dllimport__)) FILE *__attribute__((__cdecl__)) _fsopen(const char *_Filename,const char *_Mode,int _ShFlag);

  void __attribute__((__cdecl__)) clearerr(FILE *_File);
  int __attribute__((__cdecl__)) fclose(FILE *_File);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _fcloseall(void);



  __attribute__ ((__dllimport__)) FILE *__attribute__((__cdecl__)) _fdopen(int _FileHandle,const char *_Mode);

  int __attribute__((__cdecl__)) feof(FILE *_File);
  int __attribute__((__cdecl__)) ferror(FILE *_File);
  int __attribute__((__cdecl__)) fflush(FILE *_File);
  int __attribute__((__cdecl__)) fgetc(FILE *_File);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _fgetchar(void);
  int __attribute__((__cdecl__)) fgetpos(FILE * __restrict__ _File ,fpos_t * __restrict__ _Pos);
  int __attribute__((__cdecl__)) fgetpos64(FILE * __restrict__ _File ,fpos_t * __restrict__ _Pos);
  char *__attribute__((__cdecl__)) fgets(char * __restrict__ _Buf,int _MaxCount,FILE * __restrict__ _File);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _fileno(FILE *_File);







  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _tempnam(const char *_DirName,const char *_FilePrefix);



  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _flushall(void);
  FILE *__attribute__((__cdecl__)) fopen(const char * __restrict__ _Filename,const char * __restrict__ _Mode) ;
  FILE *__attribute__((__cdecl__)) fopen64(const char * __restrict__ filename,const char * __restrict__ mode);
  int __attribute__((__cdecl__)) fputc(int _Ch,FILE *_File);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _fputchar(int _Ch);
  int __attribute__((__cdecl__)) fputs(const char * __restrict__ _Str,FILE * __restrict__ _File);
  size_t __attribute__((__cdecl__)) fread(void * __restrict__ _DstBuf,size_t _ElementSize,size_t _Count,FILE * __restrict__ _File);
  FILE *__attribute__((__cdecl__)) freopen(const char * __restrict__ _Filename,const char * __restrict__ _Mode,FILE * __restrict__ _File) ;
  FILE *__attribute__((__cdecl__)) freopen64(const char * __restrict__ _Filename,const char * __restrict__ _Mode,FILE * __restrict__ _File);
  int __attribute__((__cdecl__)) fsetpos(FILE *_File,const fpos_t *_Pos);
  int __attribute__((__cdecl__)) fsetpos64(FILE *_File,const fpos_t *_Pos);
  int __attribute__((__cdecl__)) fseek(FILE *_File,long _Offset,int _Origin);
  long __attribute__((__cdecl__)) ftell(FILE *_File);

  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _fseeki64(FILE *_File,long long _Offset,int _Origin);
  __attribute__ ((__dllimport__)) long long __attribute__((__cdecl__)) _ftelli64(FILE *_File);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) fseeko(FILE *_File, _off_t _Offset, int _Origin);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) fseeko64(FILE *_File, _off64_t _Offset, int _Origin);
  __attribute__ ((__dllimport__)) _off_t __attribute__((__cdecl__)) ftello(FILE *_File);
  __attribute__ ((__dllimport__)) _off64_t __attribute__((__cdecl__)) ftello64(FILE *_File);
# 605 "C:/msys64/mingw64/include/stdio.h" 3
  size_t __attribute__((__cdecl__)) fwrite(const void * __restrict__ _Str,size_t _Size,size_t _Count,FILE * __restrict__ _File);
  int __attribute__((__cdecl__)) getc(FILE *_File);
  int __attribute__((__cdecl__)) getchar(void);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _getmaxstdio(void);
  char *__attribute__((__cdecl__)) gets(char *_Buffer)
    __attribute__((__warning__("Using gets() is always unsafe - use fgets() instead")));
  int __attribute__((__cdecl__)) _getw(FILE *_File);





  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _pclose(FILE *_File);
  __attribute__ ((__dllimport__)) FILE *__attribute__((__cdecl__)) _popen(const char *_Command,const char *_Mode);





  int __attribute__((__cdecl__)) putc(int _Ch,FILE *_File);
  int __attribute__((__cdecl__)) putchar(int _Ch);
  int __attribute__((__cdecl__)) puts(const char *_Str);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _putw(int _Word,FILE *_File);


  int __attribute__((__cdecl__)) remove(const char *_Filename);
  int __attribute__((__cdecl__)) rename(const char *_OldFilename,const char *_NewFilename);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _unlink(const char *_Filename);

  int __attribute__((__cdecl__)) unlink(const char *_Filename) ;


  void __attribute__((__cdecl__)) rewind(FILE *_File);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _rmtmp(void);
  void __attribute__((__cdecl__)) setbuf(FILE * __restrict__ _File,char * __restrict__ _Buffer) ;
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _setmaxstdio(int _Max);
  __attribute__ ((__dllimport__)) unsigned int __attribute__((__cdecl__)) _set_output_format(unsigned int _Format);
  __attribute__ ((__dllimport__)) unsigned int __attribute__((__cdecl__)) _get_output_format(void);
  int __attribute__((__cdecl__)) setvbuf(FILE * __restrict__ _File,char * __restrict__ _Buf,int _Mode,size_t _Size);







  __attribute__ ((__pure__))
  __attribute__((__format__(__ms_printf__, 1,2))) __attribute__ ((__nonnull__ (1)))
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _scprintf(const char * __restrict__ _Format,...);
  __attribute__((__format__(__ms_scanf__, 3,4))) __attribute__ ((__nonnull__ (3)))
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _snscanf(const char * __restrict__ _Src,size_t _MaxCount,const char * __restrict__ _Format,...) ;

  __attribute__ ((__pure__))
  __attribute__((__format__(__ms_printf__, 1,0))) __attribute__ ((__nonnull__ (1)))
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vscprintf(const char * __restrict__ _Format,va_list _ArgList);
  FILE *__attribute__((__cdecl__)) tmpfile(void) ;
  FILE *__attribute__((__cdecl__)) tmpfile64(void);
  char *__attribute__((__cdecl__)) tmpnam(char *_Buffer);
  int __attribute__((__cdecl__)) ungetc(int _Ch,FILE *_File);







  __attribute__((__format__(__ms_printf__, 3,4))) __attribute__ ((__nonnull__ (3)))
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _snprintf(char * __restrict__ _Dest,size_t _Count,const char * __restrict__ _Format,...) ;
  __attribute__((__format__(__ms_printf__, 3,0))) __attribute__ ((__nonnull__ (3)))
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vsnprintf(char * __restrict__ _Dest,size_t _Count,const char * __restrict__ _Format,va_list _Args) ;
# 889 "C:/msys64/mingw64/include/stdio.h" 3
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _set_printf_count_output(int _Value);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _get_printf_count_output(void);




                                                     __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __mingw_swscanf(const wchar_t * __restrict__ _Src,const wchar_t * __restrict__ _Format,...);
                                                     __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __mingw_vswscanf (const wchar_t * __restrict__ _Str,const wchar_t * __restrict__ Format,va_list argp);
                                                     __attribute__ ((__nonnull__ (1)))
  int __attribute__((__cdecl__)) __mingw_wscanf(const wchar_t * __restrict__ _Format,...);
                                                     __attribute__ ((__nonnull__ (1)))
  int __attribute__((__cdecl__)) __mingw_vwscanf(const wchar_t * __restrict__ Format, va_list argp);
                                                     __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __mingw_fwscanf(FILE * __restrict__ _File,const wchar_t * __restrict__ _Format,...);
                                                     __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __mingw_vfwscanf (FILE * __restrict__ fp, const wchar_t * __restrict__ Format,va_list argp);

                                                      __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __mingw_fwprintf(FILE * __restrict__ _File,const wchar_t * __restrict__ _Format,...);
                                                      __attribute__ ((__nonnull__ (1)))
  int __attribute__((__cdecl__)) __mingw_wprintf(const wchar_t * __restrict__ _Format,...);
                                                     __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __mingw_vfwprintf(FILE * __restrict__ _File,const wchar_t * __restrict__ _Format,va_list _ArgList);
                                                     __attribute__ ((__nonnull__ (1)))
  int __attribute__((__cdecl__)) __mingw_vwprintf(const wchar_t * __restrict__ _Format,va_list _ArgList);
                                                      __attribute__ ((__nonnull__ (3)))
  int __attribute__((__cdecl__)) __mingw_snwprintf (wchar_t * __restrict__ s, size_t n, const wchar_t * __restrict__ format, ...);
                                                      __attribute__ ((__nonnull__ (3)))
  int __attribute__((__cdecl__)) __mingw_vsnwprintf (wchar_t * __restrict__ , size_t, const wchar_t * __restrict__ , va_list);
                                                      __attribute__ ((__nonnull__ (3)))
  int __attribute__((__cdecl__)) __mingw_swprintf(wchar_t * __restrict__ , size_t, const wchar_t * __restrict__ , ...);
                                                      __attribute__ ((__nonnull__ (3)))
  int __attribute__((__cdecl__)) __mingw_vswprintf(wchar_t * __restrict__ , size_t, const wchar_t * __restrict__ ,va_list);

                                                    __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __ms_swscanf(const wchar_t * __restrict__ _Src,const wchar_t * __restrict__ _Format,...)
  ;
                                                    __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __ms_vswscanf(const wchar_t * __restrict__ _Src,const wchar_t * __restrict__ _Format,va_list)
  __asm__("vswscanf");
                                                    __attribute__ ((__nonnull__ (1)))
  int __attribute__((__cdecl__)) __ms_wscanf(const wchar_t * __restrict__ _Format,...)
  ;
                                                    __attribute__ ((__nonnull__ (1)))
  int __attribute__((__cdecl__)) __ms_vwscanf(const wchar_t * __restrict__ _Format, va_list)
  __asm__("vwscanf");
                                                    __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __ms_fwscanf(FILE * __restrict__ _File,const wchar_t * __restrict__ _Format,...)
  ;
                                                    __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __ms_vfwscanf(FILE * __restrict__ _File,const wchar_t * __restrict__ _Format,va_list)
  __asm__("vfwscanf");

                                                     __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __ms_fwprintf(FILE * __restrict__ _File,const wchar_t * __restrict__ _Format,...);


                                                     __attribute__ ((__nonnull__ (1)))
  int __attribute__((__cdecl__)) __ms_wprintf(const wchar_t * __restrict__ _Format,...)
  ;
                                                    __attribute__ ((__nonnull__ (2)))
  int __attribute__((__cdecl__)) __ms_vfwprintf(FILE * __restrict__ _File,const wchar_t * __restrict__ _Format,va_list _ArgList)
  ;
                                                    __attribute__ ((__nonnull__ (1)))
  int __attribute__((__cdecl__)) __ms_vwprintf(const wchar_t * __restrict__ _Format,va_list _ArgList)
  ;
                                                     __attribute__ ((__nonnull__ (3)))
  int __attribute__((__cdecl__)) __ms_swprintf(wchar_t * __restrict__ , size_t, const wchar_t * __restrict__ , ...)
  ;
                                                     __attribute__ ((__nonnull__ (3)))
  int __attribute__((__cdecl__)) __ms_vswprintf(wchar_t * __restrict__ , size_t, const wchar_t * __restrict__ ,va_list)
  ;
                                                     __attribute__ ((__nonnull__ (3)))
  int __attribute__((__cdecl__)) __ms_snwprintf(wchar_t * __restrict__ , size_t, const wchar_t * __restrict__ , ...)
  ;
                                                     __attribute__ ((__nonnull__ (3)))
  int __attribute__((__cdecl__)) __ms_vsnwprintf(wchar_t * __restrict__ , size_t, const wchar_t * __restrict__ , va_list)
  ;
# 982 "C:/msys64/mingw64/include/stdio.h" 3
                                                     __attribute__ ((__nonnull__ (2)))
int swscanf(const wchar_t *__source, const wchar_t *__format, ...)
__asm__("__mingw_swscanf");

                                                     __attribute__ ((__nonnull__ (1)))
int wscanf(const wchar_t *__format, ...)
__asm__("__mingw_wscanf");

                                                     __attribute__ ((__nonnull__ (2)))
int fwscanf(FILE *__stream, const wchar_t *__format, ...)
__asm__("__mingw_fwscanf");


                                                     __attribute__ ((__nonnull__ (2)))
int vswscanf (const wchar_t * __restrict__ __source, const wchar_t * __restrict__ __format, __builtin_va_list __local_argv)
__asm__("__mingw_vswscanf");

                                                     __attribute__ ((__nonnull__ (1)))
int vwscanf(const wchar_t *__format, __builtin_va_list __local_argv)
__asm__("__mingw_vwscanf");

                                                     __attribute__ ((__nonnull__ (2)))
int vfwscanf (FILE *__stream, const wchar_t *__format, __builtin_va_list __local_argv)
__asm__("__mingw_vfwscanf");




                                                      __attribute__ ((__nonnull__ (2)))
int fwprintf (FILE *__stream, const wchar_t *__format, ...)
__asm__("__mingw_fwprintf");

                                                      __attribute__ ((__nonnull__ (1)))
int wprintf (const wchar_t *__format, ...)
__asm__("__mingw_wprintf");

                                                      __attribute__ ((__nonnull__ (2)))
int vfwprintf (FILE *__stream, const wchar_t *__format, __builtin_va_list __local_argv)
__asm__("__mingw_vfwprintf");

                                                      __attribute__ ((__nonnull__ (1)))
int vwprintf (const wchar_t *__format, __builtin_va_list __local_argv)
__asm__("__mingw_vwprintf");

                                                      __attribute__ ((__nonnull__ (3)))
int swprintf (wchar_t *__stream, size_t __n, const wchar_t *__format, ...)
__asm__("__mingw_swprintf");
# 1042 "C:/msys64/mingw64/include/stdio.h" 3
inline __attribute__((__cdecl__))
                                                      __attribute__ ((__nonnull__ (3)))
int vswprintf (wchar_t *__stream, size_t __n, const wchar_t *__format, __builtin_va_list __local_argv)
{



  return __mingw_vswprintf( __stream, __n, __format, __local_argv );
}



                                                      __attribute__ ((__nonnull__ (3)))
int snwprintf (wchar_t *__stream, size_t __n, const wchar_t *__format, ...)
__asm__("__mingw_snwprintf");
# 1070 "C:/msys64/mingw64/include/stdio.h" 3
inline __attribute__((__cdecl__))
                                                      __attribute__ ((__nonnull__ (3)))
int vsnwprintf (wchar_t *__stream, size_t __n, const wchar_t *__format, __builtin_va_list __local_argv)
{



  return __mingw_vsnwprintf( __stream, __n, __format, __local_argv );
}
# 1119 "C:/msys64/mingw64/include/stdio.h" 3
  __attribute__ ((__dllimport__)) FILE *__attribute__((__cdecl__)) _wfsopen(const wchar_t *_Filename,const wchar_t *_Mode,int _ShFlag);


  wint_t __attribute__((__cdecl__)) fgetwc(FILE *_File);
  __attribute__ ((__dllimport__)) wint_t __attribute__((__cdecl__)) _fgetwchar(void);
  wint_t __attribute__((__cdecl__)) fputwc(wchar_t _Ch,FILE *_File);
  __attribute__ ((__dllimport__)) wint_t __attribute__((__cdecl__)) _fputwchar(wchar_t _Ch);
  wint_t __attribute__((__cdecl__)) getwc(FILE *_File);
  wint_t __attribute__((__cdecl__)) getwchar(void);
  wint_t __attribute__((__cdecl__)) putwc(wchar_t _Ch,FILE *_File);
  wint_t __attribute__((__cdecl__)) putwchar(wchar_t _Ch);
  wint_t __attribute__((__cdecl__)) ungetwc(wint_t _Ch,FILE *_File);
  wchar_t *__attribute__((__cdecl__)) fgetws(wchar_t * __restrict__ _Dst,int _SizeInWords,FILE * __restrict__ _File);
  int __attribute__((__cdecl__)) fputws(const wchar_t * __restrict__ _Str,FILE * __restrict__ _File);
  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _getws(wchar_t *_String) ;
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _putws(const wchar_t *_Str);

  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _scwprintf(const wchar_t * __restrict__ _Format,...);

  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _swprintf_c(wchar_t * __restrict__ _DstBuf,size_t _SizeInWords,const wchar_t * __restrict__ _Format,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vswprintf_c(wchar_t * __restrict__ _DstBuf,size_t _SizeInWords,const wchar_t * __restrict__ _Format,va_list _ArgList);

  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _snwprintf(wchar_t * __restrict__ _Dest,size_t _Count,const wchar_t * __restrict__ _Format,...) ;
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vsnwprintf(wchar_t * __restrict__ _Dest,size_t _Count,const wchar_t * __restrict__ _Format,va_list _Args) ;
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vscwprintf(const wchar_t * __restrict__ _Format,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _swprintf(wchar_t * __restrict__ _Dest,const wchar_t * __restrict__ _Format,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vswprintf(wchar_t * __restrict__ _Dest,const wchar_t * __restrict__ _Format,va_list _Args);


# 1 "C:/msys64/mingw64/include/swprintf.inl" 1 3
# 12 "C:/msys64/mingw64/include/swprintf.inl" 3
extern "C++" {

                                                      __attribute__ ((__nonnull__ (2)))
int vswprintf (wchar_t *__stream, const wchar_t *__format, __builtin_va_list __local_argv) __asm__("_vswprintf");

                                                      __attribute__ ((__nonnull__ (2)))
int swprintf (wchar_t *__stream, const wchar_t *__format, ...) __asm__("_swprintf");

}
# 1149 "C:/msys64/mingw64/include/stdio.h" 2 3
# 1162 "C:/msys64/mingw64/include/stdio.h" 3
  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _wtempnam(const wchar_t *_Directory,const wchar_t *_FilePrefix);



  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _snwscanf(const wchar_t * __restrict__ _Src,size_t _MaxCount,const wchar_t * __restrict__ _Format,...);
  __attribute__ ((__dllimport__)) FILE *__attribute__((__cdecl__)) _wfdopen(int _FileHandle ,const wchar_t *_Mode);
  __attribute__ ((__dllimport__)) FILE *__attribute__((__cdecl__)) _wfopen(const wchar_t * __restrict__ _Filename,const wchar_t *__restrict__ _Mode) ;
  __attribute__ ((__dllimport__)) FILE *__attribute__((__cdecl__)) _wfreopen(const wchar_t * __restrict__ _Filename,const wchar_t * __restrict__ _Mode,FILE * __restrict__ _OldFile) ;





  __attribute__ ((__dllimport__)) FILE *__attribute__((__cdecl__)) _wpopen(const wchar_t *_Command,const wchar_t *_Mode);




  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wremove(const wchar_t *_Filename);
  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _wtmpnam(wchar_t *_Buffer);
# 1225 "C:/msys64/mingw64/include/stdio.h" 3
  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _lock_file(FILE *_File);
  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _unlock_file(FILE *_File);
# 1247 "C:/msys64/mingw64/include/stdio.h" 3
  char *__attribute__((__cdecl__)) tempnam(const char *_Directory,const char *_FilePrefix) ;



  int __attribute__((__cdecl__)) fcloseall(void) ;
  FILE *__attribute__((__cdecl__)) fdopen(int _FileHandle,const char *_Format) ;
  int __attribute__((__cdecl__)) fgetchar(void) ;
  int __attribute__((__cdecl__)) fileno(FILE *_File) ;
  int __attribute__((__cdecl__)) flushall(void) ;
  int __attribute__((__cdecl__)) fputchar(int _Ch) ;
  int __attribute__((__cdecl__)) getw(FILE *_File) ;
  int __attribute__((__cdecl__)) putw(int _Ch,FILE *_File) ;
  int __attribute__((__cdecl__)) rmtmp(void) ;
# 1276 "C:/msys64/mingw64/include/stdio.h" 3
int __attribute__((__cdecl__)) __mingw_str_wide_utf8 (const wchar_t * const wptr, char **mbptr, size_t * buflen);
# 1290 "C:/msys64/mingw64/include/stdio.h" 3
int __attribute__((__cdecl__)) __mingw_str_utf8_wide (const char *const mbptr, wchar_t ** wptr, size_t * buflen);
# 1299 "C:/msys64/mingw64/include/stdio.h" 3
void __attribute__((__cdecl__)) __mingw_str_free(void *ptr);






  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _wspawnl(int _Mode,const wchar_t *_Filename,const wchar_t *_ArgList,...);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _wspawnle(int _Mode,const wchar_t *_Filename,const wchar_t *_ArgList,...);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _wspawnlp(int _Mode,const wchar_t *_Filename,const wchar_t *_ArgList,...);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _wspawnlpe(int _Mode,const wchar_t *_Filename,const wchar_t *_ArgList,...);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _wspawnv(int _Mode,const wchar_t *_Filename,const wchar_t *const *_ArgList);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _wspawnve(int _Mode,const wchar_t *_Filename,const wchar_t *const *_ArgList,const wchar_t *const *_Env);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _wspawnvp(int _Mode,const wchar_t *_Filename,const wchar_t *const *_ArgList);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _wspawnvpe(int _Mode,const wchar_t *_Filename,const wchar_t *const *_ArgList,const wchar_t *const *_Env);
# 1330 "C:/msys64/mingw64/include/stdio.h" 3
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _spawnv(int _Mode,const char *_Filename,const char *const *_ArgList);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _spawnve(int _Mode,const char *_Filename,const char *const *_ArgList,const char *const *_Env);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _spawnvp(int _Mode,const char *_Filename,const char *const *_ArgList);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _spawnvpe(int _Mode,const char *_Filename,const char *const *_ArgList,const char *const *_Env);




}


       
       
       
       

#pragma pack(pop)

# 1 "C:/msys64/mingw64/include/sec_api/stdio_s.h" 1 3
# 9 "C:/msys64/mingw64/include/sec_api/stdio_s.h" 3
# 1 "C:/msys64/mingw64/include/stdio.h" 1 3
# 10 "C:/msys64/mingw64/include/sec_api/stdio_s.h" 2 3
# 21 "C:/msys64/mingw64/include/sec_api/stdio_s.h" 3
extern "C" {







  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) clearerr_s(FILE *_File);

  size_t __attribute__((__cdecl__)) fread_s(void *_DstBuf,size_t _DstSize,size_t _ElementSize,size_t _Count,FILE *_File);
# 515 "C:/msys64/mingw64/include/sec_api/stdio_s.h" 3
  int __attribute__((__cdecl__)) fprintf_s(FILE *_File,const char *_Format,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _fscanf_s_l(FILE *_File,const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) fscanf_s(FILE *_File, const char *_Format, ...);
  int __attribute__((__cdecl__)) printf_s(const char *_Format,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _scanf_l(const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _scanf_s_l(const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) scanf_s(const char *_Format, ...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _snprintf_c(char *_DstBuf,size_t _MaxCount,const char *_Format,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vsnprintf_c(char *_DstBuf,size_t _MaxCount,const char *_Format,va_list _ArgList);

  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _fscanf_l(FILE *_File,const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _sscanf_l(const char *_Src,const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _sscanf_s_l(const char *_Src,const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) sscanf_s(const char *_Src,const char *_Format,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _snscanf_s(const char *_Src,size_t _MaxCount,const char *_Format,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _snscanf_l(const char *_Src,size_t _MaxCount,const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _snscanf_s_l(const char *_Src,size_t _MaxCount,const char *_Format,_locale_t _Locale,...);
  int __attribute__((__cdecl__)) vfprintf_s(FILE *_File,const char *_Format,va_list _ArgList);
  int __attribute__((__cdecl__)) vprintf_s(const char *_Format,va_list _ArgList);

  int __attribute__((__cdecl__)) vsnprintf_s(char *_DstBuf,size_t _DstSize,size_t _MaxCount,const char *_Format,va_list _ArgList);

  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vsnprintf_s(char *_DstBuf,size_t _DstSize,size_t _MaxCount,const char *_Format,va_list _ArgList);

  __attribute__((dllimport)) int __attribute__((__cdecl__)) vsprintf_s(char *_DstBuf,size_t _Size,const char *_Format,va_list _ArgList);

  __attribute__((dllimport)) int __attribute__((__cdecl__)) sprintf_s(char *_DstBuf,size_t _DstSize,const char *_Format,...);

  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _snprintf_s(char *_DstBuf,size_t _DstSize,size_t _MaxCount,const char *_Format,...);

  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _fprintf_p(FILE *_File,const char *_Format,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _printf_p(const char *_Format,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _sprintf_p(char *_Dst,size_t _MaxCount,const char *_Format,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vfprintf_p(FILE *_File,const char *_Format,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vprintf_p(const char *_Format,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vsprintf_p(char *_Dst,size_t _MaxCount,const char *_Format,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _scprintf_p(const char *_Format,...);
  __attribute__((dllimport)) int __attribute__((__cdecl__)) _vscprintf_p(const char *_Format,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _printf_l(const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _printf_p_l(const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vprintf_l(const char *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vprintf_p_l(const char *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _fprintf_l(FILE *_File,const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _fprintf_p_l(FILE *_File,const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vfprintf_l(FILE *_File,const char *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vfprintf_p_l(FILE *_File,const char *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _sprintf_l(char *_DstBuf,const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _sprintf_p_l(char *_DstBuf,size_t _MaxCount,const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vsprintf_l(char *_DstBuf,const char *_Format,_locale_t,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vsprintf_p_l(char *_DstBuf,size_t _MaxCount,const char *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _scprintf_l(const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _scprintf_p_l(const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vscprintf_l(const char *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vscprintf_p_l(const char *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _printf_s_l(const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vprintf_s_l(const char *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _fprintf_s_l(FILE *_File,const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vfprintf_s_l(FILE *_File,const char *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _sprintf_s_l(char *_DstBuf,size_t _DstSize,const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vsprintf_s_l(char *_DstBuf,size_t _DstSize,const char *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _snprintf_s_l(char *_DstBuf,size_t _DstSize,size_t _MaxCount,const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vsnprintf_s_l(char *_DstBuf,size_t _DstSize,size_t _MaxCount,const char *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _snprintf_l(char *_DstBuf,size_t _MaxCount,const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _snprintf_c_l(char *_DstBuf,size_t _MaxCount,const char *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vsnprintf_l(char *_DstBuf,size_t _MaxCount,const char *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vsnprintf_c_l(char *_DstBuf,size_t _MaxCount,const char *,_locale_t _Locale,va_list _ArgList);


  extern "C++" { template <size_t __size> inline int __attribute__((__cdecl__)) vsnprintf_s(char (&_DstBuf)[__size], size_t _MaxCount, const char* _Format, va_list _ArgList) { return vsnprintf_s(_DstBuf,__size,_MaxCount,_Format,_ArgList); } }
  extern "C++" { template <size_t __size> inline int __attribute__((__cdecl__)) _vsnprintf_s(char (&_DstBuf)[__size], size_t _MaxCount, const char* _Format, va_list _ArgList) { return _vsnprintf_s(_DstBuf,__size,_MaxCount,_Format,_ArgList); } }
  extern "C++" { template <size_t __size> inline int __attribute__((__cdecl__)) vsprintf_s(char (&_DstBuf)[__size], const char* _Format, va_list _ArgList) { return vsprintf_s(_DstBuf,__size,_Format,_ArgList); } }
  extern "C++" { template <size_t __size> inline int __attribute__((__cdecl__)) sprintf_s(char (&_DstBuf)[__size], const char* _Format, ...) { va_list __vaargs; __builtin_va_start(__vaargs,_Format); int __retval = vsprintf_s(_DstBuf,__size,_Format,__vaargs); __builtin_va_end(__vaargs); return __retval; } }
  extern "C++" { template <size_t __size> inline int __attribute__((__cdecl__)) _snprintf_s(char (&_DstBuf)[__size], size_t _MaxCount, const char* _Format, ...) { va_list __vaargs; __builtin_va_start(__vaargs,_Format); int __retval = _vsnprintf_s(_DstBuf,__size,_MaxCount,_Format,__vaargs); __builtin_va_end(__vaargs); return __retval; } }

  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) fopen_s(FILE **_File,const char *_Filename,const char *_Mode);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) freopen_s(FILE** _File, const char *_Filename, const char *_Mode, FILE *_Stream);

  __attribute__ ((__dllimport__)) char* __attribute__((__cdecl__)) gets_s(char*,rsize_t);
  extern "C++" { template <size_t __size> inline char* __attribute__((__cdecl__)) get_s(char (&_DstBuf)[__size]) { return get_s(_DstBuf,__size); } }

  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) tmpfile_s(FILE **_File);

  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) tmpnam_s(char*,rsize_t);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) tmpnam_s(char (&_DstBuf)[__size]) { return tmpnam_s(_DstBuf,__size); } }




  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _getws_s(wchar_t *_Str,size_t _SizeInWords);
  extern "C++" { template <size_t __size> inline wchar_t* __attribute__((__cdecl__)) _getws_s(wchar_t (&_DstBuf)[__size]) { return _getws_s(_DstBuf,__size); } }
# 830 "C:/msys64/mingw64/include/sec_api/stdio_s.h" 3
  int __attribute__((__cdecl__)) fwprintf_s(FILE *_File,const wchar_t *_Format,...);
  int __attribute__((__cdecl__)) wprintf_s(const wchar_t *_Format,...);
  int __attribute__((__cdecl__)) vfwprintf_s(FILE *_File,const wchar_t *_Format,va_list _ArgList);
  int __attribute__((__cdecl__)) vwprintf_s(const wchar_t *_Format,va_list _ArgList);

  int __attribute__((__cdecl__)) vswprintf_s(wchar_t *_Dst,size_t _SizeInWords,const wchar_t *_Format,va_list _ArgList);

  int __attribute__((__cdecl__)) swprintf_s(wchar_t *_Dst,size_t _SizeInWords,const wchar_t *_Format,...);

  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vsnwprintf_s(wchar_t *_DstBuf,size_t _DstSizeInWords,size_t _MaxCount,const wchar_t *_Format,va_list _ArgList);

  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _snwprintf_s(wchar_t *_DstBuf,size_t _DstSizeInWords,size_t _MaxCount,const wchar_t *_Format,...);


  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wprintf_s_l(const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vwprintf_s_l(const wchar_t *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _fwprintf_s_l(FILE *_File,const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vfwprintf_s_l(FILE *_File,const wchar_t *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _swprintf_s_l(wchar_t *_DstBuf,size_t _DstSize,const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vswprintf_s_l(wchar_t *_DstBuf,size_t _DstSize,const wchar_t *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _snwprintf_s_l(wchar_t *_DstBuf,size_t _DstSize,size_t _MaxCount,const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vsnwprintf_s_l(wchar_t *_DstBuf,size_t _DstSize,size_t _MaxCount,const wchar_t *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _fwscanf_s_l(FILE *_File,const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) fwscanf_s(FILE *_File, const wchar_t *_Format, ...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _swscanf_s_l(const wchar_t *_Src,const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) swscanf_s(const wchar_t *_Src,const wchar_t *_Format,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _snwscanf_s(const wchar_t *_Src,size_t _MaxCount,const wchar_t *_Format,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _snwscanf_s_l(const wchar_t *_Src,size_t _MaxCount,const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wscanf_s_l(const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) wscanf_s(const wchar_t *_Format, ...);


  extern "C++" { template <size_t __size> inline int __attribute__((__cdecl__)) vswprintf_s(wchar_t (&_Dst)[__size], const wchar_t* _Format, va_list _ArgList) { return vswprintf_s(_Dst,__size,_Format,_ArgList); } }
  extern "C++" { template <size_t __size> inline int __attribute__((__cdecl__)) swprintf_s(wchar_t (&_Dst)[__size], const wchar_t* _Format, ...) { va_list __vaargs; __builtin_va_start(__vaargs,_Format); int __retval = vswprintf_s(_Dst,__size,_Format,__vaargs); __builtin_va_end(__vaargs); return __retval; } }
  extern "C++" { template <size_t __size> inline int __attribute__((__cdecl__)) _vsnwprintf_s(wchar_t (&_DstBuf)[__size], size_t _MaxCount, const wchar_t* _Format, va_list _ArgList) { return _vsnwprintf_s(_DstBuf,__size,_MaxCount,_Format,_ArgList); } }
  extern "C++" { template <size_t __size> inline int __attribute__((__cdecl__)) _snwprintf_s(wchar_t (&_DstBuf)[__size], size_t _MaxCount, const wchar_t* _Format, ...) { va_list __vaargs; __builtin_va_start(__vaargs,_Format); int __retval = _vsnwprintf_s(_DstBuf,__size,_MaxCount,_Format,__vaargs); __builtin_va_end(__vaargs); return __retval; } }

  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wfopen_s(FILE **_File,const wchar_t *_Filename,const wchar_t *_Mode);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wfreopen_s(FILE **_File,const wchar_t *_Filename,const wchar_t *_Mode,FILE *_OldFile);

  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _wtmpnam_s(wchar_t *_DstBuf,size_t _SizeInWords);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _wtmpnam_s(wchar_t (&_DstBuf)[__size]) { return _wtmpnam_s(_DstBuf,__size); } }


  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _fwprintf_p(FILE *_File,const wchar_t *_Format,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wprintf_p(const wchar_t *_Format,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vfwprintf_p(FILE *_File,const wchar_t *_Format,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vwprintf_p(const wchar_t *_Format,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _swprintf_p(wchar_t *_DstBuf,size_t _MaxCount,const wchar_t *_Format,...);
  __attribute__((dllimport)) int __attribute__((__cdecl__)) _vswprintf_p(wchar_t *_DstBuf,size_t _MaxCount,const wchar_t *_Format,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _scwprintf_p(const wchar_t *_Format,...);
  __attribute__((dllimport)) int __attribute__((__cdecl__)) _vscwprintf_p(const wchar_t *_Format,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wprintf_l(const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wprintf_p_l(const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vwprintf_l(const wchar_t *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vwprintf_p_l(const wchar_t *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _fwprintf_l(FILE *_File,const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _fwprintf_p_l(FILE *_File,const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vfwprintf_l(FILE *_File,const wchar_t *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vfwprintf_p_l(FILE *_File,const wchar_t *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _swprintf_c_l(wchar_t *_DstBuf,size_t _MaxCount,const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _swprintf_p_l(wchar_t *_DstBuf,size_t _MaxCount,const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vswprintf_c_l(wchar_t *_DstBuf,size_t _MaxCount,const wchar_t *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vswprintf_p_l(wchar_t *_DstBuf,size_t _MaxCount,const wchar_t *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _scwprintf_l(const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _scwprintf_p_l(const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vscwprintf_p_l(const wchar_t *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _snwprintf_l(wchar_t *_DstBuf,size_t _MaxCount,const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vsnwprintf_l(wchar_t *_DstBuf,size_t _MaxCount,const wchar_t *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) __swprintf_l(wchar_t *_Dest,const wchar_t *_Format,_locale_t _Plocinfo,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) __vswprintf_l(wchar_t *_Dest,const wchar_t *_Format,_locale_t _Plocinfo,va_list _Args);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _vscwprintf_l(const wchar_t *_Format,_locale_t _Locale,va_list _ArgList);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _fwscanf_l(FILE *_File,const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _swscanf_l(const wchar_t *_Src,const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _snwscanf_l(const wchar_t *_Src,size_t _MaxCount,const wchar_t *_Format,_locale_t _Locale,...);
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _wscanf_l(const wchar_t *_Format,_locale_t _Locale,...);
# 916 "C:/msys64/mingw64/include/sec_api/stdio_s.h" 3
}
# 1349 "C:/msys64/mingw64/include/stdio.h" 2 3
# 48 "C:/msys64/mingw64/include/c++/15.2.0/cstdio" 2 3
# 98 "C:/msys64/mingw64/include/c++/15.2.0/cstdio" 3
namespace std
{
  using ::FILE;
  using ::fpos_t;

  using ::clearerr;
  using ::fclose;
  using ::feof;
  using ::ferror;
  using ::fflush;
  using ::fgetc;
  using ::fgetpos;
  using ::fgets;
  using ::fopen;
  using ::fprintf;
  using ::fputc;
  using ::fputs;
  using ::fread;
  using ::freopen;
  using ::fscanf;
  using ::fseek;
  using ::fsetpos;
  using ::ftell;
  using ::fwrite;
  using ::getc;
  using ::getchar;




  using ::perror;
  using ::printf;
  using ::putc;
  using ::putchar;
  using ::puts;
  using ::remove;
  using ::rename;
  using ::rewind;
  using ::scanf;
  using ::setbuf;
  using ::setvbuf;
  using ::sprintf;
  using ::sscanf;
  using ::tmpfile;

  using ::tmpnam;

  using ::ungetc;
  using ::vfprintf;
  using ::vprintf;
  using ::vsprintf;
}
# 159 "C:/msys64/mingw64/include/c++/15.2.0/cstdio" 3
namespace __gnu_cxx
{
# 177 "C:/msys64/mingw64/include/c++/15.2.0/cstdio" 3
  using ::snprintf;
  using ::vfscanf;
  using ::vscanf;
  using ::vsnprintf;
  using ::vsscanf;

}

namespace std
{
  using ::__gnu_cxx::snprintf;
  using ::__gnu_cxx::vfscanf;
  using ::__gnu_cxx::vscanf;
  using ::__gnu_cxx::vsnprintf;
  using ::__gnu_cxx::vsscanf;
}
# 2845 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 2
# 2913 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
# 1 "C:/msys64/mingw64/include/c++/15.2.0/cassert" 1 3
# 46 "C:/msys64/mingw64/include/c++/15.2.0/cassert" 3
# 1 "C:/msys64/mingw64/include/assert.h" 1 3
# 17 "C:/msys64/mingw64/include/assert.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/stdlib.h" 1 3
# 38 "C:/msys64/mingw64/include/c++/15.2.0/stdlib.h" 3
using std::abort;
using std::atexit;
using std::exit;
# 49 "C:/msys64/mingw64/include/c++/15.2.0/stdlib.h" 3
  using std::_Exit;




using std::div_t;
using std::ldiv_t;

using std::abs;
using std::atof;
using std::atoi;
using std::atol;
using std::bsearch;
using std::calloc;
using std::div;
using std::free;
using std::getenv;
using std::labs;
using std::ldiv;
using std::malloc;

using std::mblen;
using std::mbstowcs;
using std::mbtowc;

using std::qsort;
using std::rand;
using std::realloc;
using std::srand;
using std::strtod;
using std::strtol;
using std::strtoul;
using std::system;

using std::wcstombs;
using std::wctomb;
# 18 "C:/msys64/mingw64/include/assert.h" 2 3



extern "C" {


__attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) __attribute__ ((__noreturn__)) _wassert(const wchar_t *_Message,const wchar_t *_File,unsigned _Line);
__attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) __attribute__ ((__noreturn__)) _assert (const char *_Message, const char *_File, unsigned _Line);


}
# 47 "C:/msys64/mingw64/include/c++/15.2.0/cassert" 2 3
# 2914 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 2
# 1 "C:/msys64/mingw64/include/c++/15.2.0/algorithm" 1 3
# 62 "C:/msys64/mingw64/include/c++/15.2.0/algorithm" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 1 3
# 60 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/functexcept.h" 1 3
# 40 "C:/msys64/mingw64/include/c++/15.2.0/bits/functexcept.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/exception_defines.h" 1 3
# 41 "C:/msys64/mingw64/include/c++/15.2.0/bits/functexcept.h" 2 3

namespace std
{




  void
  __throw_bad_exception(void) __attribute__((__noreturn__));


  void
  __throw_bad_alloc(void) __attribute__((__noreturn__));

  void
  __throw_bad_array_new_length(void) __attribute__((__noreturn__));


  void
  __throw_bad_cast(void) __attribute__((__noreturn__,__cold__));

  void
  __throw_bad_typeid(void) __attribute__((__noreturn__,__cold__));


  void
  __throw_logic_error(const char*) __attribute__((__noreturn__,__cold__));

  void
  __throw_domain_error(const char*) __attribute__((__noreturn__,__cold__));

  void
  __throw_invalid_argument(const char*) __attribute__((__noreturn__,__cold__));

  void
  __throw_length_error(const char*) __attribute__((__noreturn__,__cold__));

  void
  __throw_out_of_range(const char*) __attribute__((__noreturn__,__cold__));

  void
  __throw_out_of_range_fmt(const char*, ...) __attribute__((__noreturn__,__cold__))
    __attribute__((__format__(__gnu_printf__, 1, 2)));

  void
  __throw_runtime_error(const char*) __attribute__((__noreturn__,__cold__));

  void
  __throw_range_error(const char*) __attribute__((__noreturn__,__cold__));

  void
  __throw_overflow_error(const char*) __attribute__((__noreturn__,__cold__));

  void
  __throw_underflow_error(const char*) __attribute__((__noreturn__,__cold__));


  void
  __throw_ios_failure(const char*) __attribute__((__noreturn__,__cold__));

  void
  __throw_ios_failure(const char*, int) __attribute__((__noreturn__,__cold__));


  void
  __throw_system_error(int) __attribute__((__noreturn__,__cold__));


  void
  __throw_future_error(int) __attribute__((__noreturn__,__cold__));


  void
  __throw_bad_function_call() __attribute__((__noreturn__,__cold__));
# 140 "C:/msys64/mingw64/include/c++/15.2.0/bits/functexcept.h" 3

}
# 61 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 2 3




# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator_base_types.h" 1 3
# 73 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator_base_types.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/iterator_concepts.h" 1 3
# 39 "C:/msys64/mingw64/include/c++/15.2.0/bits/iterator_concepts.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/ptr_traits.h" 1 3
# 39 "C:/msys64/mingw64/include/c++/15.2.0/bits/ptr_traits.h" 3
namespace __gnu_debug { struct _Safe_iterator_base; }


namespace std
{




  class __undefined;



  template<typename _Tp>
    struct __get_first_arg
    { using type = __undefined; };

  template<template<typename, typename...> class _SomeTemplate, typename _Tp,
           typename... _Types>
    struct __get_first_arg<_SomeTemplate<_Tp, _Types...>>
    { using type = _Tp; };



  template<typename _Tp, typename _Up>
    struct __replace_first_arg
    { };

  template<template<typename, typename...> class _SomeTemplate, typename _Up,
           typename _Tp, typename... _Types>
    struct __replace_first_arg<_SomeTemplate<_Tp, _Types...>, _Up>
    { using type = _SomeTemplate<_Up, _Types...>; };


  template<typename _Ptr, typename = void>
    struct __ptr_traits_elem : __get_first_arg<_Ptr>
    { };



  template<typename _Ptr> requires requires { typename _Ptr::element_type; }
    struct __ptr_traits_elem<_Ptr, void>
    { using type = typename _Ptr::element_type; };






  template<typename _Ptr>
    using __ptr_traits_elem_t = typename __ptr_traits_elem<_Ptr>::type;




  template<typename _Ptr, typename _Elt, bool = is_void<_Elt>::value>
    struct __ptr_traits_ptr_to
    {
      using pointer = _Ptr;
      using element_type = _Elt;







      static pointer
      pointer_to(element_type& __r)

      requires requires {
 { pointer::pointer_to(__r) } -> convertible_to<pointer>;
      }

      { return pointer::pointer_to(__r); }
    };


  template<typename _Ptr, typename _Elt>
    struct __ptr_traits_ptr_to<_Ptr, _Elt, true>
    { };


  template<typename _Tp>
    struct __ptr_traits_ptr_to<_Tp*, _Tp, false>
    {
      using pointer = _Tp*;
      using element_type = _Tp;






      static constexpr pointer
      pointer_to(element_type& __r) noexcept
      { return std::addressof(__r); }
    };

  template<typename _Ptr, typename _Elt>
    struct __ptr_traits_impl : __ptr_traits_ptr_to<_Ptr, _Elt>
    {
    private:
      template<typename _Tp>
 using __diff_t = typename _Tp::difference_type;

      template<typename _Tp, typename _Up>
 using __rebind = __type_identity<typename _Tp::template rebind<_Up>>;

    public:

      using pointer = _Ptr;


      using element_type = _Elt;


      using difference_type = __detected_or_t<ptrdiff_t, __diff_t, _Ptr>;


      template<typename _Up>
 using rebind = typename __detected_or_t<__replace_first_arg<_Ptr, _Up>,
      __rebind, _Ptr, _Up>::type;
    };



  template<typename _Ptr>
    struct __ptr_traits_impl<_Ptr, __undefined>
    { };







  template<typename _Ptr>
    struct pointer_traits : __ptr_traits_impl<_Ptr, __ptr_traits_elem_t<_Ptr>>
    { };







  template<typename _Tp>
    struct pointer_traits<_Tp*> : __ptr_traits_ptr_to<_Tp*, _Tp>
    {

      typedef _Tp* pointer;

      typedef _Tp element_type;

      typedef ptrdiff_t difference_type;

      template<typename _Up> using rebind = _Up*;
    };


  template<typename _Ptr, typename _Tp>
    using __ptr_rebind = typename pointer_traits<_Ptr>::template rebind<_Tp>;
# 229 "C:/msys64/mingw64/include/c++/15.2.0/bits/ptr_traits.h" 3
  template<typename _Tp>
    [[__gnu__::__always_inline__]]
    constexpr _Tp*
    to_address(_Tp* __ptr) noexcept
    {
      static_assert(!is_function_v<_Tp>, "std::to_address argument "
      "must not be a function pointer");
      return __ptr;
    }
# 246 "C:/msys64/mingw64/include/c++/15.2.0/bits/ptr_traits.h" 3
  template<typename _Ptr>
    constexpr auto
    to_address(const _Ptr& __ptr) noexcept
    {
      if constexpr (requires { pointer_traits<_Ptr>::to_address(__ptr); })
 return pointer_traits<_Ptr>::to_address(__ptr);
      else if constexpr (is_base_of_v<__gnu_debug::_Safe_iterator_base, _Ptr>)
 return std::to_address(__ptr.base().operator->());
      else
 return std::to_address(__ptr.operator->());
    }



  template<typename _Ptr>
    [[__gnu__::__always_inline__]]
    constexpr auto
    __to_address(const _Ptr& __ptr) noexcept
    { return std::to_address(__ptr); }




}
# 40 "C:/msys64/mingw64/include/c++/15.2.0/bits/iterator_concepts.h" 2 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_cmp.h" 1 3
# 37 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_cmp.h" 3
namespace std
{


  struct __is_transparent;





  struct identity
  {
    template<typename _Tp>
      [[nodiscard]]
      constexpr _Tp&&
      operator()(_Tp&& __t) const noexcept
      { return std::forward<_Tp>(__t); }

    using is_transparent = __is_transparent;
  };


namespace ranges
{
  namespace __detail
  {



    template<typename _Tp, typename _Up>
      concept __less_builtin_ptr_cmp
 = requires (_Tp&& __t, _Up&& __u) { { __t < __u } -> same_as<bool>; }
   && convertible_to<_Tp, const volatile void*>
   && convertible_to<_Up, const volatile void*>
   && (! requires(_Tp&& __t, _Up&& __u)
       { operator<(std::forward<_Tp>(__t), std::forward<_Up>(__u)); }
       && ! requires(_Tp&& __t, _Up&& __u)
       { std::forward<_Tp>(__t).operator<(std::forward<_Up>(__u)); });
  }







  struct equal_to
  {
    template<typename _Tp, typename _Up>
      requires equality_comparable_with<_Tp, _Up>
      constexpr bool
      operator()(_Tp&& __t, _Up&& __u) const
      noexcept(noexcept(std::declval<_Tp>() == std::declval<_Up>()))
      { return std::forward<_Tp>(__t) == std::forward<_Up>(__u); }

    using is_transparent = __is_transparent;
  };


  struct not_equal_to
  {
    template<typename _Tp, typename _Up>
      requires equality_comparable_with<_Tp, _Up>
      constexpr bool
      operator()(_Tp&& __t, _Up&& __u) const
      noexcept(noexcept(std::declval<_Tp>() == std::declval<_Up>()))
      { return !equal_to{}(std::forward<_Tp>(__t), std::forward<_Up>(__u)); }

    using is_transparent = __is_transparent;
  };


  struct less
  {
    template<typename _Tp, typename _Up>
      requires totally_ordered_with<_Tp, _Up>
      constexpr bool
      operator()(_Tp&& __t, _Up&& __u) const
      noexcept(noexcept(std::declval<_Tp>() < std::declval<_Up>()))
      {
 if constexpr (__detail::__less_builtin_ptr_cmp<_Tp, _Up>)
   {
     if (std::__is_constant_evaluated())
       return __t < __u;

     auto __x = reinterpret_cast<long long unsigned int>(
       static_cast<const volatile void*>(std::forward<_Tp>(__t)));
     auto __y = reinterpret_cast<long long unsigned int>(
       static_cast<const volatile void*>(std::forward<_Up>(__u)));
     return __x < __y;
   }
 else
   return std::forward<_Tp>(__t) < std::forward<_Up>(__u);
      }

    using is_transparent = __is_transparent;
  };


  struct greater
  {
    template<typename _Tp, typename _Up>
      requires totally_ordered_with<_Tp, _Up>
      constexpr bool
      operator()(_Tp&& __t, _Up&& __u) const
      noexcept(noexcept(std::declval<_Up>() < std::declval<_Tp>()))
      { return less{}(std::forward<_Up>(__u), std::forward<_Tp>(__t)); }

    using is_transparent = __is_transparent;
  };


  struct greater_equal
  {
    template<typename _Tp, typename _Up>
      requires totally_ordered_with<_Tp, _Up>
      constexpr bool
      operator()(_Tp&& __t, _Up&& __u) const
      noexcept(noexcept(std::declval<_Tp>() < std::declval<_Up>()))
      { return !less{}(std::forward<_Tp>(__t), std::forward<_Up>(__u)); }

    using is_transparent = __is_transparent;
  };


  struct less_equal
  {
    template<typename _Tp, typename _Up>
      requires totally_ordered_with<_Tp, _Up>
      constexpr bool
      operator()(_Tp&& __t, _Up&& __u) const
      noexcept(noexcept(std::declval<_Up>() < std::declval<_Tp>()))
      { return !less{}(std::forward<_Up>(__u), std::forward<_Tp>(__t)); }

    using is_transparent = __is_transparent;
  };

}


}
# 41 "C:/msys64/mingw64/include/c++/15.2.0/bits/iterator_concepts.h" 2 3

#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wpedantic"

namespace std
{

# 63 "C:/msys64/mingw64/include/c++/15.2.0/bits/iterator_concepts.h" 3
  struct default_sentinel_t { };


  inline constexpr default_sentinel_t default_sentinel{};


  struct input_iterator_tag;
  struct output_iterator_tag;
  struct forward_iterator_tag;
  struct bidirectional_iterator_tag;
  struct random_access_iterator_tag;
  struct contiguous_iterator_tag;

  template<typename _Iterator>
    struct iterator_traits;

  template<typename _Tp> requires is_object_v<_Tp>
    struct iterator_traits<_Tp*>;

  template<typename _Iterator, typename>
    struct __iterator_traits;

  namespace __detail
  {
    template<typename _Tp>
      using __with_ref = _Tp&;

    template<typename _Tp>
      concept __can_reference = requires { typename __with_ref<_Tp>; };

    template<typename _Tp>
      concept __dereferenceable = requires(_Tp& __t)
 {
   { *__t } -> __can_reference;
 };
  }

  template<__detail::__dereferenceable _Tp>
    using iter_reference_t = decltype(*std::declval<_Tp&>());

  namespace ranges
  {


    namespace __imove
    {
      void iter_move() = delete;



      template<typename _Tp>
 concept __adl_imove
   = (std::__detail::__class_or_enum<remove_reference_t<_Tp>>)
       && requires(_Tp&& __t) { iter_move(static_cast<_Tp&&>(__t)); };

      struct _IterMove
      {
      private:


 template<typename _Tp>
   using __iter_ref_t = decltype(*std::declval<_Tp>());

 template<typename _Tp>
   struct __result
   { using type = __iter_ref_t<_Tp>; };


 template<typename _Tp>
   requires __adl_imove<_Tp>
   struct __result<_Tp>
   { using type = decltype(iter_move(std::declval<_Tp>())); };


 template<typename _Tp>
   requires (!__adl_imove<_Tp>)
     && is_lvalue_reference_v<__iter_ref_t<_Tp>>
   struct __result<_Tp>
   {




     using type
       = decltype(std::declval<remove_reference_t<__iter_ref_t<_Tp>>>());
   };

 template<typename _Tp>
   static constexpr bool
   _S_noexcept()
   {
     if constexpr (__adl_imove<_Tp>)
       return noexcept(iter_move(std::declval<_Tp>()));
     else
       return noexcept(*std::declval<_Tp>());
   }

      public:

 template<typename _Tp>
   using __type = typename __result<_Tp>::type;

 template<typename _Tp>
   requires __adl_imove<_Tp> || requires { typename __iter_ref_t<_Tp>; }
   [[nodiscard]]
   constexpr __type<_Tp>
   operator()(_Tp&& __e) const
   noexcept(_S_noexcept<_Tp>())
   {
     if constexpr (__adl_imove<_Tp>)
       return iter_move(static_cast<_Tp&&>(__e));
     else if constexpr (is_lvalue_reference_v<__iter_ref_t<_Tp>>)
       return std::move(*static_cast<_Tp&&>(__e));
     else
       return *static_cast<_Tp&&>(__e);
   }
      };
    }


    inline namespace _Cpo {
      inline constexpr __imove::_IterMove iter_move{};
    }
  }


  template<__detail::__dereferenceable _Tp>
    requires __detail::__can_reference<ranges::__imove::_IterMove::__type<_Tp&>>
    using iter_rvalue_reference_t = ranges::__imove::_IterMove::__type<_Tp&>;

  template<typename> struct incrementable_traits { };

  template<typename _Tp> requires is_object_v<_Tp>
    struct incrementable_traits<_Tp*>
    { using difference_type = ptrdiff_t; };

  template<typename _Iter>
    struct incrementable_traits<const _Iter>
    : incrementable_traits<_Iter> { };

  template<typename _Tp> requires requires { typename _Tp::difference_type; }
    struct incrementable_traits<_Tp>
    { using difference_type = typename _Tp::difference_type; };

  template<typename _Tp>
    requires (!requires { typename _Tp::difference_type; }
       && requires(const _Tp& __a, const _Tp& __b)
       { { __a - __b } -> integral; })
    struct incrementable_traits<_Tp>
    {
      using difference_type
 = make_signed_t<decltype(std::declval<_Tp>() - std::declval<_Tp>())>;
    };
# 228 "C:/msys64/mingw64/include/c++/15.2.0/bits/iterator_concepts.h" 3
  namespace __detail
  {


    template<typename _Iter>
      concept __primary_traits_iter
 = __is_base_of(__iterator_traits<_Iter, void>, iterator_traits<_Iter>);

    template<typename _Iter, typename _Tp>
      struct __iter_traits_impl
      { using type = iterator_traits<_Iter>; };

    template<typename _Iter, typename _Tp>
      requires __primary_traits_iter<_Iter>
      struct __iter_traits_impl<_Iter, _Tp>
      { using type = _Tp; };


    template<typename _Iter, typename _Tp = _Iter>
      using __iter_traits = typename __iter_traits_impl<_Iter, _Tp>::type;

    template<typename _Tp>
      using __iter_diff_t = typename
 __iter_traits<_Tp, incrementable_traits<_Tp>>::difference_type;
  }

  template<typename _Tp>
    using iter_difference_t = __detail::__iter_diff_t<remove_cvref_t<_Tp>>;

  namespace __detail
  {
    template<typename> struct __cond_value_type { };

    template<typename _Tp> requires is_object_v<_Tp>
      struct __cond_value_type<_Tp>
      { using value_type = remove_cv_t<_Tp>; };

    template<typename _Tp>
      concept __has_member_value_type
 = requires { typename _Tp::value_type; };

    template<typename _Tp>
      concept __has_member_element_type
 = requires { typename _Tp::element_type; };

  }

  template<typename> struct indirectly_readable_traits { };

  template<typename _Tp>
    struct indirectly_readable_traits<_Tp*>
    : __detail::__cond_value_type<_Tp>
    { };

  template<typename _Iter> requires is_array_v<_Iter>
    struct indirectly_readable_traits<_Iter>
    { using value_type = remove_cv_t<remove_extent_t<_Iter>>; };

  template<typename _Iter>
    struct indirectly_readable_traits<const _Iter>
    : indirectly_readable_traits<_Iter>
    { };

  template<__detail::__has_member_value_type _Tp>
    struct indirectly_readable_traits<_Tp>
    : __detail::__cond_value_type<typename _Tp::value_type>
    { };

  template<__detail::__has_member_element_type _Tp>
    struct indirectly_readable_traits<_Tp>
    : __detail::__cond_value_type<typename _Tp::element_type>
    { };



  template<__detail::__has_member_value_type _Tp>
    requires __detail::__has_member_element_type<_Tp>
    && same_as<remove_cv_t<typename _Tp::element_type>,
        remove_cv_t<typename _Tp::value_type>>
    struct indirectly_readable_traits<_Tp>
    : __detail::__cond_value_type<typename _Tp::value_type>
    { };



  template<__detail::__has_member_value_type _Tp>
    requires __detail::__has_member_element_type<_Tp>
    struct indirectly_readable_traits<_Tp>
    { };

  namespace __detail
  {
    template<typename _Tp>
      using __iter_value_t = typename
 __iter_traits<_Tp, indirectly_readable_traits<_Tp>>::value_type;
  }

  template<typename _Tp>
    using iter_value_t = __detail::__iter_value_t<remove_cvref_t<_Tp>>;

  namespace __detail
  {


    template<typename _Iter>
      concept __cpp17_iterator = requires(_Iter __it)
 {
   { *__it } -> __can_reference;
   { ++__it } -> same_as<_Iter&>;
   { *__it++ } -> __can_reference;
 } && copyable<_Iter>;

    template<typename _Iter>
      concept __cpp17_input_iterator = __cpp17_iterator<_Iter>
 && equality_comparable<_Iter>
 && requires(_Iter __it)
 {
   typename incrementable_traits<_Iter>::difference_type;
   typename indirectly_readable_traits<_Iter>::value_type;
   typename common_reference_t<iter_reference_t<_Iter>&&,
     typename indirectly_readable_traits<_Iter>::value_type&>;
   typename common_reference_t<decltype(*__it++)&&,
     typename indirectly_readable_traits<_Iter>::value_type&>;
   requires signed_integral<
     typename incrementable_traits<_Iter>::difference_type>;
 };



    template<typename _Iter>
      concept __cpp17_fwd_iterator = __cpp17_input_iterator<_Iter>
 && constructible_from<_Iter>
 && is_reference_v<iter_reference_t<_Iter>>
 && same_as<remove_cvref_t<iter_reference_t<_Iter>>,
     typename indirectly_readable_traits<_Iter>::value_type>
 && requires(_Iter __it)
 {
   { __it++ } -> convertible_to<const _Iter&>;
   { *__it++ } -> same_as<iter_reference_t<_Iter>>;
 };

    template<typename _Iter>
      concept __cpp17_bidi_iterator = __cpp17_fwd_iterator<_Iter>
 && requires(_Iter __it)
 {
   { --__it } -> same_as<_Iter&>;
   { __it-- } -> convertible_to<const _Iter&>;
   { *__it-- } -> same_as<iter_reference_t<_Iter>>;
 };

    template<typename _Iter>
      concept __cpp17_randacc_iterator = __cpp17_bidi_iterator<_Iter>
 && totally_ordered<_Iter>
 && requires(_Iter __it,
      typename incrementable_traits<_Iter>::difference_type __n)
 {
   { __it += __n } -> same_as<_Iter&>;
   { __it -= __n } -> same_as<_Iter&>;
   { __it + __n } -> same_as<_Iter>;
   { __n + __it } -> same_as<_Iter>;
   { __it - __n } -> same_as<_Iter>;
   { __it - __it } -> same_as<decltype(__n)>;
   { __it[__n] } -> convertible_to<iter_reference_t<_Iter>>;
 };

    template<typename _Iter>
      concept __iter_with_nested_types = requires {
 typename _Iter::iterator_category;
 typename _Iter::value_type;
 typename _Iter::difference_type;
 typename _Iter::reference;
      };

    template<typename _Iter>
      concept __iter_without_nested_types = !__iter_with_nested_types<_Iter>;

    template<typename _Iter>
      concept __iter_without_category
 = !requires { typename _Iter::iterator_category; };

  }

  template<typename _Iterator>
    requires __detail::__iter_with_nested_types<_Iterator>
    struct __iterator_traits<_Iterator, void>
    {
    private:
      template<typename _Iter>
 struct __ptr
 { using type = void; };

      template<typename _Iter> requires requires { typename _Iter::pointer; }
 struct __ptr<_Iter>
 { using type = typename _Iter::pointer; };

    public:
      using iterator_category = typename _Iterator::iterator_category;
      using value_type = typename _Iterator::value_type;
      using difference_type = typename _Iterator::difference_type;
      using pointer = typename __ptr<_Iterator>::type;
      using reference = typename _Iterator::reference;
    };

  template<typename _Iterator>
    requires __detail::__iter_without_nested_types<_Iterator>
       && __detail::__cpp17_input_iterator<_Iterator>
    struct __iterator_traits<_Iterator, void>
    {
    private:
      template<typename _Iter>
 struct __cat
 { using type = input_iterator_tag; };

      template<typename _Iter>
 requires requires { typename _Iter::iterator_category; }
 struct __cat<_Iter>
 { using type = typename _Iter::iterator_category; };

      template<typename _Iter>
 requires __detail::__iter_without_category<_Iter>
    && __detail::__cpp17_randacc_iterator<_Iter>
 struct __cat<_Iter>
 { using type = random_access_iterator_tag; };

      template<typename _Iter>
 requires __detail::__iter_without_category<_Iter>
    && __detail::__cpp17_bidi_iterator<_Iter>
 struct __cat<_Iter>
 { using type = bidirectional_iterator_tag; };

      template<typename _Iter>
 requires __detail::__iter_without_category<_Iter>
    && __detail::__cpp17_fwd_iterator<_Iter>
 struct __cat<_Iter>
 { using type = forward_iterator_tag; };

      template<typename _Iter>
 struct __ptr
 { using type = void; };

      template<typename _Iter> requires requires { typename _Iter::pointer; }
 struct __ptr<_Iter>
 { using type = typename _Iter::pointer; };

      template<typename _Iter>
 requires (!requires { typename _Iter::pointer; }
     && requires(_Iter& __it) { __it.operator->(); })
 struct __ptr<_Iter>
 { using type = decltype(std::declval<_Iter&>().operator->()); };

      template<typename _Iter>
 struct __ref
 { using type = iter_reference_t<_Iter>; };

      template<typename _Iter> requires requires { typename _Iter::reference; }
 struct __ref<_Iter>
 { using type = typename _Iter::reference; };

    public:
      using iterator_category = typename __cat<_Iterator>::type;
      using value_type
 = typename indirectly_readable_traits<_Iterator>::value_type;
      using difference_type
 = typename incrementable_traits<_Iterator>::difference_type;
      using pointer = typename __ptr<_Iterator>::type;
      using reference = typename __ref<_Iterator>::type;
    };

  template<typename _Iterator>
    requires __detail::__iter_without_nested_types<_Iterator>
       && __detail::__cpp17_iterator<_Iterator>
    struct __iterator_traits<_Iterator, void>
    {
    private:
      template<typename _Iter>
 struct __diff
 { using type = void; };

      template<typename _Iter>
 requires requires
 { typename incrementable_traits<_Iter>::difference_type; }
 struct __diff<_Iter>
 {
   using type = typename incrementable_traits<_Iter>::difference_type;
 };

    public:
      using iterator_category = output_iterator_tag;
      using value_type = void;
      using difference_type = typename __diff<_Iterator>::type;
      using pointer = void;
      using reference = void;
    };

  namespace __detail
  {
    template<typename _Iter>
      struct __iter_concept_impl;


    template<typename _Iter>
      requires requires { typename __iter_traits<_Iter>::iterator_concept; }
      struct __iter_concept_impl<_Iter>
      { using type = typename __iter_traits<_Iter>::iterator_concept; };


    template<typename _Iter>
      requires (!requires { typename __iter_traits<_Iter>::iterator_concept; }
   && requires { typename __iter_traits<_Iter>::iterator_category; })
      struct __iter_concept_impl<_Iter>
      { using type = typename __iter_traits<_Iter>::iterator_category; };


    template<typename _Iter>
      requires (!requires { typename __iter_traits<_Iter>::iterator_concept; }
   && !requires { typename __iter_traits<_Iter>::iterator_category; }
   && __primary_traits_iter<_Iter>)
      struct __iter_concept_impl<_Iter>
      { using type = random_access_iterator_tag; };


    template<typename _Iter>
      struct __iter_concept_impl
      { };


    template<typename _Iter>
      using __iter_concept = typename __iter_concept_impl<_Iter>::type;

  template<typename _In>
    concept __indirectly_readable_impl = requires
      {
 typename iter_value_t<_In>;
 typename iter_reference_t<_In>;
 typename iter_rvalue_reference_t<_In>;
 requires same_as<iter_reference_t<const _In>,
    iter_reference_t<_In>>;
 requires same_as<iter_rvalue_reference_t<const _In>,
    iter_rvalue_reference_t<_In>>;
      }
      && common_reference_with<iter_reference_t<_In>&&, iter_value_t<_In>&>
      && common_reference_with<iter_reference_t<_In>&&,
         iter_rvalue_reference_t<_In>&&>
      && common_reference_with<iter_rvalue_reference_t<_In>&&,
          const iter_value_t<_In>&>;

  }


  template<typename _In>
    concept indirectly_readable
      = __detail::__indirectly_readable_impl<remove_cvref_t<_In>>;

  namespace __detail
  {
    template<typename _Tp>
      struct __indirect_value
      { using type = iter_value_t<_Tp>&; };


  }

  template<typename _Tp>
    using __indirect_value_t = typename __detail::__indirect_value<_Tp>::type;

  template<indirectly_readable _Tp>
    using iter_common_reference_t
      = common_reference_t<iter_reference_t<_Tp>, __indirect_value_t<_Tp>>;


  template<typename _Out, typename _Tp>
    concept indirectly_writable = requires(_Out&& __o, _Tp&& __t)
      {
 *__o = std::forward<_Tp>(__t);
 *std::forward<_Out>(__o) = std::forward<_Tp>(__t);
 const_cast<const iter_reference_t<_Out>&&>(*__o)
   = std::forward<_Tp>(__t);
 const_cast<const iter_reference_t<_Out>&&>(*std::forward<_Out>(__o))
   = std::forward<_Tp>(__t);
      };

  namespace ranges::__detail
  {
    class __max_diff_type;
    class __max_size_type;

    __extension__
    template<typename _Tp>
      concept __is_signed_int128

 = same_as<_Tp, __int128>;




    __extension__
    template<typename _Tp>
      concept __is_unsigned_int128

 = same_as<_Tp, unsigned __int128>;




    template<typename _Tp>
      concept __cv_bool = same_as<const volatile _Tp, const volatile bool>;

    template<typename _Tp>
      concept __integral_nonbool = integral<_Tp> && !__cv_bool<_Tp>;

    template<typename _Tp>
      concept __is_int128 = __is_signed_int128<_Tp> || __is_unsigned_int128<_Tp>;

    template<typename _Tp>
      concept __is_integer_like = __integral_nonbool<_Tp>
 || __is_int128<_Tp>
 || same_as<_Tp, __max_diff_type> || same_as<_Tp, __max_size_type>;

    template<typename _Tp>
      concept __is_signed_integer_like = signed_integral<_Tp>
 || __is_signed_int128<_Tp>
 || same_as<_Tp, __max_diff_type>;

  }

  namespace __detail { using ranges::__detail::__is_signed_integer_like; }


  template<typename _Iter>
    concept weakly_incrementable = movable<_Iter>
      && requires(_Iter __i)
      {
 typename iter_difference_t<_Iter>;
 requires __detail::__is_signed_integer_like<iter_difference_t<_Iter>>;
 { ++__i } -> same_as<_Iter&>;
 __i++;
      };

  template<typename _Iter>
    concept incrementable = regular<_Iter> && weakly_incrementable<_Iter>
      && requires(_Iter __i) { { __i++ } -> same_as<_Iter>; };

  template<typename _Iter>
    concept input_or_output_iterator
      = requires(_Iter __i) { { *__i } -> __detail::__can_reference; }
 && weakly_incrementable<_Iter>;

  template<typename _Sent, typename _Iter>
    concept sentinel_for = semiregular<_Sent>
      && input_or_output_iterator<_Iter>
      && __detail::__weakly_eq_cmp_with<_Sent, _Iter>;

  template<typename _Sent, typename _Iter>
    inline constexpr bool disable_sized_sentinel_for = false;

  template<typename _Sent, typename _Iter>
    concept sized_sentinel_for = sentinel_for<_Sent, _Iter>
    && !disable_sized_sentinel_for<remove_cv_t<_Sent>, remove_cv_t<_Iter>>
    && requires(const _Iter& __i, const _Sent& __s)
    {
      { __s - __i } -> same_as<iter_difference_t<_Iter>>;
      { __i - __s } -> same_as<iter_difference_t<_Iter>>;
    };

  template<typename _Iter>
    concept input_iterator = input_or_output_iterator<_Iter>
      && indirectly_readable<_Iter>
      && requires { typename __detail::__iter_concept<_Iter>; }
      && derived_from<__detail::__iter_concept<_Iter>, input_iterator_tag>;

  template<typename _Iter, typename _Tp>
    concept output_iterator = input_or_output_iterator<_Iter>
      && indirectly_writable<_Iter, _Tp>
      && requires(_Iter __i, _Tp&& __t) { *__i++ = std::forward<_Tp>(__t); };

  template<typename _Iter>
    concept forward_iterator = input_iterator<_Iter>
      && derived_from<__detail::__iter_concept<_Iter>, forward_iterator_tag>
      && incrementable<_Iter> && sentinel_for<_Iter, _Iter>;

  template<typename _Iter>
    concept bidirectional_iterator = forward_iterator<_Iter>
      && derived_from<__detail::__iter_concept<_Iter>,
        bidirectional_iterator_tag>
      && requires(_Iter __i)
      {
 { --__i } -> same_as<_Iter&>;
 { __i-- } -> same_as<_Iter>;
      };

  template<typename _Iter>
    concept random_access_iterator = bidirectional_iterator<_Iter>
      && derived_from<__detail::__iter_concept<_Iter>,
        random_access_iterator_tag>
      && totally_ordered<_Iter> && sized_sentinel_for<_Iter, _Iter>
      && requires(_Iter __i, const _Iter __j,
    const iter_difference_t<_Iter> __n)
      {
 { __i += __n } -> same_as<_Iter&>;
 { __j + __n } -> same_as<_Iter>;
 { __n + __j } -> same_as<_Iter>;
 { __i -= __n } -> same_as<_Iter&>;
 { __j - __n } -> same_as<_Iter>;
 { __j[__n] } -> same_as<iter_reference_t<_Iter>>;
      };

  template<typename _Iter>
    concept contiguous_iterator = random_access_iterator<_Iter>
      && derived_from<__detail::__iter_concept<_Iter>, contiguous_iterator_tag>
      && is_lvalue_reference_v<iter_reference_t<_Iter>>
      && same_as<iter_value_t<_Iter>, remove_cvref_t<iter_reference_t<_Iter>>>
      && requires(const _Iter& __i)
      {
 { std::to_address(__i) }
   -> same_as<add_pointer_t<iter_reference_t<_Iter>>>;
      };





  template<typename _Fn, typename _Iter>
    concept indirectly_unary_invocable = indirectly_readable<_Iter>
      && copy_constructible<_Fn> && invocable<_Fn&, __indirect_value_t<_Iter>>
      && invocable<_Fn&, iter_reference_t<_Iter>>
      && common_reference_with<invoke_result_t<_Fn&, __indirect_value_t<_Iter>>,
          invoke_result_t<_Fn&, iter_reference_t<_Iter>>>;

  template<typename _Fn, typename _Iter>
    concept indirectly_regular_unary_invocable = indirectly_readable<_Iter>
      && copy_constructible<_Fn>
      && regular_invocable<_Fn&, __indirect_value_t<_Iter>>
      && regular_invocable<_Fn&, iter_reference_t<_Iter>>
      && common_reference_with<invoke_result_t<_Fn&, __indirect_value_t<_Iter>>,
          invoke_result_t<_Fn&, iter_reference_t<_Iter>>>;

  template<typename _Fn, typename _Iter>
    concept indirect_unary_predicate = indirectly_readable<_Iter>
      && copy_constructible<_Fn> && predicate<_Fn&, __indirect_value_t<_Iter>>
      && predicate<_Fn&, iter_reference_t<_Iter>>;

  template<typename _Fn, typename _I1, typename _I2>
    concept indirect_binary_predicate
      = indirectly_readable<_I1> && indirectly_readable<_I2>
      && copy_constructible<_Fn>
      && predicate<_Fn&, __indirect_value_t<_I1>, __indirect_value_t<_I2>>
      && predicate<_Fn&, __indirect_value_t<_I1>, iter_reference_t<_I2>>
      && predicate<_Fn&, iter_reference_t<_I1>, __indirect_value_t<_I2>>
      && predicate<_Fn&, iter_reference_t<_I1>, iter_reference_t<_I2>>;

  template<typename _Fn, typename _I1, typename _I2 = _I1>
    concept indirect_equivalence_relation
      = indirectly_readable<_I1> && indirectly_readable<_I2>
      && copy_constructible<_Fn>
      && equivalence_relation<_Fn&, __indirect_value_t<_I1>, __indirect_value_t<_I2>>
      && equivalence_relation<_Fn&, __indirect_value_t<_I1>, iter_reference_t<_I2>>
      && equivalence_relation<_Fn&, iter_reference_t<_I1>, __indirect_value_t<_I2>>
      && equivalence_relation<_Fn&, iter_reference_t<_I1>,
         iter_reference_t<_I2>>;

  template<typename _Fn, typename _I1, typename _I2 = _I1>
    concept indirect_strict_weak_order
      = indirectly_readable<_I1> && indirectly_readable<_I2>
      && copy_constructible<_Fn>
      && strict_weak_order<_Fn&, __indirect_value_t<_I1>, __indirect_value_t<_I2>>
      && strict_weak_order<_Fn&, __indirect_value_t<_I1>, iter_reference_t<_I2>>
      && strict_weak_order<_Fn&, iter_reference_t<_I1>, __indirect_value_t<_I2>>
      && strict_weak_order<_Fn&, iter_reference_t<_I1>, iter_reference_t<_I2>>;

  template<typename _Fn, typename... _Is>
    requires (indirectly_readable<_Is> && ...)
      && invocable<_Fn, iter_reference_t<_Is>...>
    using indirect_result_t = invoke_result_t<_Fn, iter_reference_t<_Is>...>;

  namespace __detail
  {
    template<typename _Iter, typename _Proj>
      struct __projected
      {
 struct __type
 {
   using value_type = remove_cvref_t<indirect_result_t<_Proj&, _Iter>>;
   indirect_result_t<_Proj&, _Iter> operator*() const;



   using __projected_Iter = _Iter;
   using __projected_Proj = _Proj;
 };
      };

    template<weakly_incrementable _Iter, typename _Proj>
      struct __projected<_Iter, _Proj>
      {
 struct __type
 {
   using value_type = remove_cvref_t<indirect_result_t<_Proj&, _Iter>>;
   using difference_type = iter_difference_t<_Iter>;
   indirect_result_t<_Proj&, _Iter> operator*() const;

   using __projected_Iter = _Iter;
   using __projected_Proj = _Proj;
 };
      };
  }


  template<indirectly_readable _Iter,
    indirectly_regular_unary_invocable<_Iter> _Proj>
    using projected = typename __detail::__projected<_Iter, _Proj>::__type;


  template<typename _Tp>
    requires same_as<_Tp, projected<typename _Tp::__projected_Iter,
        typename _Tp::__projected_Proj>>
    struct __detail::__indirect_value<_Tp>
    {
      using _Iter = typename _Tp::__projected_Iter;
      using _Proj = typename _Tp::__projected_Proj;
      using type = invoke_result_t<_Proj&, __indirect_value_t<_Iter>>;
    };
# 861 "C:/msys64/mingw64/include/c++/15.2.0/bits/iterator_concepts.h" 3
  template<typename _In, typename _Out>
    concept indirectly_movable = indirectly_readable<_In>
      && indirectly_writable<_Out, iter_rvalue_reference_t<_In>>;

  template<typename _In, typename _Out>
    concept indirectly_movable_storable = indirectly_movable<_In, _Out>
      && indirectly_writable<_Out, iter_value_t<_In>>
      && movable<iter_value_t<_In>>
      && constructible_from<iter_value_t<_In>, iter_rvalue_reference_t<_In>>
      && assignable_from<iter_value_t<_In>&, iter_rvalue_reference_t<_In>>;


  template<typename _In, typename _Out>
    concept indirectly_copyable = indirectly_readable<_In>
      && indirectly_writable<_Out, iter_reference_t<_In>>;

  template<typename _In, typename _Out>
    concept indirectly_copyable_storable = indirectly_copyable<_In, _Out>
      && indirectly_writable<_Out, iter_value_t<_In>&>
      && indirectly_writable<_Out, const iter_value_t<_In>&>
      && indirectly_writable<_Out, iter_value_t<_In>&&>
      && indirectly_writable<_Out, const iter_value_t<_In>&&>
      && copyable<iter_value_t<_In>>
      && constructible_from<iter_value_t<_In>, iter_reference_t<_In>>
      && assignable_from<iter_value_t<_In>&, iter_reference_t<_In>>;

namespace ranges
{


  namespace __iswap
  {
    template<typename _It1, typename _It2>
      void iter_swap(_It1, _It2) = delete;



    template<typename _Tp, typename _Up>
      concept __adl_iswap
 = (std::__detail::__class_or_enum<remove_reference_t<_Tp>>
   || std::__detail::__class_or_enum<remove_reference_t<_Up>>)
 && requires(_Tp&& __t, _Up&& __u) {
   iter_swap(static_cast<_Tp&&>(__t), static_cast<_Up&&>(__u));
 };

    template<typename _Xp, typename _Yp>
      constexpr iter_value_t<_Xp>
      __iter_exchange_move(_Xp&& __x, _Yp&& __y)
      noexcept(noexcept(iter_value_t<_Xp>(iter_move(__x)))
        && noexcept(*__x = iter_move(__y)))
      {
 iter_value_t<_Xp> __old_value(iter_move(__x));
 *__x = iter_move(__y);
 return __old_value;
      }

    struct _IterSwap
    {
    private:
      template<typename _Tp, typename _Up>
 static constexpr bool
 _S_noexcept()
 {
   if constexpr (__adl_iswap<_Tp, _Up>)
     return noexcept(iter_swap(std::declval<_Tp>(),
          std::declval<_Up>()));
   else if constexpr (indirectly_readable<_Tp>
       && indirectly_readable<_Up>
       && swappable_with<iter_reference_t<_Tp>, iter_reference_t<_Up>>)
     return noexcept(ranges::swap(*std::declval<_Tp>(),
      *std::declval<_Up>()));
   else
     return noexcept(*std::declval<_Tp>()
  = __iswap::__iter_exchange_move(std::declval<_Up>(),
          std::declval<_Tp>()));
 }

    public:
      template<typename _Tp, typename _Up>
 requires __adl_iswap<_Tp, _Up>
 || (indirectly_readable<remove_reference_t<_Tp>>
     && indirectly_readable<remove_reference_t<_Up>>
     && swappable_with<iter_reference_t<_Tp>, iter_reference_t<_Up>>)
 || (indirectly_movable_storable<_Tp, _Up>
     && indirectly_movable_storable<_Up, _Tp>)
 constexpr void
 operator()(_Tp&& __e1, _Up&& __e2) const
 noexcept(_S_noexcept<_Tp, _Up>())
 {
   if constexpr (__adl_iswap<_Tp, _Up>)
     iter_swap(static_cast<_Tp&&>(__e1), static_cast<_Up&&>(__e2));
   else if constexpr (indirectly_readable<_Tp>
       && indirectly_readable<_Up>
       && swappable_with<iter_reference_t<_Tp>, iter_reference_t<_Up>>)
     ranges::swap(*__e1, *__e2);
   else
     *__e1 = __iswap::__iter_exchange_move(__e2, __e1);
 }
    };
  }


  inline namespace _Cpo {
    inline constexpr __iswap::_IterSwap iter_swap{};
  }

}


  template<typename _I1, typename _I2 = _I1>
    concept indirectly_swappable
      = indirectly_readable<_I1> && indirectly_readable<_I2>
      && requires(const _I1 __i1, const _I2 __i2)
      {
 ranges::iter_swap(__i1, __i1);
 ranges::iter_swap(__i2, __i2);
 ranges::iter_swap(__i1, __i2);
 ranges::iter_swap(__i2, __i1);
      };


  template<typename _I1, typename _I2, typename _Rel, typename _P1 = identity,
    typename _P2 = identity>
    concept indirectly_comparable
      = indirect_binary_predicate<_Rel, projected<_I1, _P1>,
      projected<_I2, _P2>>;


  template<typename _Iter>
    concept permutable = forward_iterator<_Iter>
      && indirectly_movable_storable<_Iter, _Iter>
      && indirectly_swappable<_Iter, _Iter>;


  template<typename _I1, typename _I2, typename _Out,
    typename _Rel = ranges::less, typename _P1 = identity,
    typename _P2 = identity>
    concept mergeable = input_iterator<_I1> && input_iterator<_I2>
      && weakly_incrementable<_Out> && indirectly_copyable<_I1, _Out>
      && indirectly_copyable<_I2, _Out>
      && indirect_strict_weak_order<_Rel, projected<_I1, _P1>,
        projected<_I2, _P2>>;


  template<typename _Iter, typename _Rel = ranges::less,
    typename _Proj = identity>
    concept sortable = permutable<_Iter>
      && indirect_strict_weak_order<_Rel, projected<_Iter, _Proj>>;

  struct unreachable_sentinel_t
  {
    template<weakly_incrementable _It>
      friend constexpr bool
      operator==(unreachable_sentinel_t, const _It&) noexcept
      { return false; }
  };

  inline constexpr unreachable_sentinel_t unreachable_sentinel{};


  namespace ranges::__access
  {
    using std::__detail::__class_or_enum;

    struct _Decay_copy final
    {
      template<typename _Tp>
 constexpr decay_t<_Tp>
 operator()(_Tp&& __t) const
 noexcept(is_nothrow_convertible_v<_Tp, decay_t<_Tp>>)
 { return std::forward<_Tp>(__t); }
    } inline constexpr __decay_copy{};

    template<typename _Tp>
      concept __member_begin = requires(_Tp& __t)
 {
   { __decay_copy(__t.begin()) } -> input_or_output_iterator;
 };


    void begin() = delete;

    template<typename _Tp>
      concept __adl_begin = __class_or_enum<remove_reference_t<_Tp>>
 && requires(_Tp& __t)
 {
   { __decay_copy(begin(__t)) } -> input_or_output_iterator;
 };



    template<typename _Tp>
      requires is_array_v<_Tp> || __member_begin<_Tp&> || __adl_begin<_Tp&>
      auto
      __begin(_Tp& __t)
      {
 if constexpr (is_array_v<_Tp>)
   return __t + 0;
 else if constexpr (__member_begin<_Tp&>)
   return __t.begin();
 else
   return begin(__t);
      }
  }

  namespace __detail
  {

    template<typename _Tp>
      using __range_iter_t
 = decltype(ranges::__access::__begin(std::declval<_Tp&>()));

  }



}
#pragma GCC diagnostic pop
# 74 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator_base_types.h" 2 3


namespace std
{

# 95 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator_base_types.h" 3
  struct input_iterator_tag { };


  struct output_iterator_tag { };


  struct forward_iterator_tag : public input_iterator_tag { };



  struct bidirectional_iterator_tag : public forward_iterator_tag { };



  struct random_access_iterator_tag : public bidirectional_iterator_tag { };



  struct contiguous_iterator_tag : public random_access_iterator_tag { };
# 127 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator_base_types.h" 3
  template<typename _Category, typename _Tp, typename _Distance = ptrdiff_t,
           typename _Pointer = _Tp*, typename _Reference = _Tp&>
    struct [[__deprecated__]] iterator
    {

      typedef _Category iterator_category;

      typedef _Tp value_type;

      typedef _Distance difference_type;

      typedef _Pointer pointer;

      typedef _Reference reference;
    };
# 151 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator_base_types.h" 3
  template<typename _Iterator>
    struct iterator_traits;




  template<typename _Iterator, typename = __void_t<>>
    struct __iterator_traits { };
# 178 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator_base_types.h" 3
  template<typename _Iterator>
    struct iterator_traits
    : public __iterator_traits<_Iterator> { };
# 196 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator_base_types.h" 3
  template<typename _Tp>

    requires is_object_v<_Tp>

    struct iterator_traits<_Tp*>
    {
      using iterator_concept = contiguous_iterator_tag;
      using iterator_category = random_access_iterator_tag;
      using value_type = remove_cv_t<_Tp>;
      using difference_type = ptrdiff_t;
      using pointer = _Tp*;
      using reference = _Tp&;
    };
# 237 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator_base_types.h" 3
  template<typename _Iter>
    __attribute__((__always_inline__))
    inline constexpr
    typename iterator_traits<_Iter>::iterator_category
    __iterator_category(const _Iter&)
    { return typename iterator_traits<_Iter>::iterator_category(); }




  template<typename _Iter>
    using __iter_category_t
      = typename iterator_traits<_Iter>::iterator_category;

  template<typename _InIter>
    using _RequireInputIter =
      __enable_if_t<is_convertible<__iter_category_t<_InIter>,
       input_iterator_tag>::value>;


  template<typename _InIter>
    concept __has_input_iter_cat
      = is_convertible_v<__iter_category_t<_InIter>, input_iterator_tag>;


  template<typename _It,
    typename _Cat = __iter_category_t<_It>>
    struct __is_random_access_iter
      : is_base_of<random_access_iterator_tag, _Cat>
    {
      typedef is_base_of<random_access_iterator_tag, _Cat> _Base;
      enum { __value = _Base::value };
    };








}
# 66 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 2 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator_base_funcs.h" 1 3
# 66 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator_base_funcs.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/concept_check.h" 1 3
# 39 "C:/msys64/mingw64/include/c++/15.2.0/bits/concept_check.h" 3
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wvariadic-macros"
# 86 "C:/msys64/mingw64/include/c++/15.2.0/bits/concept_check.h" 3
#pragma GCC diagnostic pop
# 67 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator_base_funcs.h" 2 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/debug/assertions.h" 1 3
# 68 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator_base_funcs.h" 2 3


namespace std
{




  template <typename> struct _List_iterator;
  template <typename> struct _List_const_iterator;


  template<typename _InputIterator>
    inline constexpr
    typename iterator_traits<_InputIterator>::difference_type
    __distance(_InputIterator __first, _InputIterator __last,
               input_iterator_tag)
    {

     

      typename iterator_traits<_InputIterator>::difference_type __n = 0;
      while (__first != __last)
 {
   ++__first;
   ++__n;
 }
      return __n;
    }

  template<typename _RandomAccessIterator>
    __attribute__((__always_inline__))
    inline constexpr
    typename iterator_traits<_RandomAccessIterator>::difference_type
    __distance(_RandomAccessIterator __first, _RandomAccessIterator __last,
               random_access_iterator_tag)
    {

     

      return __last - __first;
    }



  template<typename _Tp>
    ptrdiff_t
    __distance(std::_List_iterator<_Tp>,
        std::_List_iterator<_Tp>,
        input_iterator_tag);

  template<typename _Tp>
    ptrdiff_t
    __distance(std::_List_const_iterator<_Tp>,
        std::_List_const_iterator<_Tp>,
        input_iterator_tag);




  template<typename _OutputIterator>
    void
    __distance(_OutputIterator, _OutputIterator, output_iterator_tag) = delete;
# 146 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator_base_funcs.h" 3
  template<typename _InputIterator>
    [[__nodiscard__]] __attribute__((__always_inline__))
    inline constexpr
    typename iterator_traits<_InputIterator>::difference_type
    distance(_InputIterator __first, _InputIterator __last)
    {

      return std::__distance(__first, __last,
        std::__iterator_category(__first));
    }

  template<typename _InputIterator, typename _Distance>
    inline constexpr void
    __advance(_InputIterator& __i, _Distance __n, input_iterator_tag)
    {

     
      do { if (__builtin_expect(!bool(__n >= 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator_base_funcs.h", 163, __PRETTY_FUNCTION__, "__n >= 0"); } while (false);
      while (__n--)
 ++__i;
    }

  template<typename _BidirectionalIterator, typename _Distance>
    inline constexpr void
    __advance(_BidirectionalIterator& __i, _Distance __n,
       bidirectional_iterator_tag)
    {

     

      if (__n > 0)
        while (__n--)
   ++__i;
      else
        while (__n++)
   --__i;
    }

  template<typename _RandomAccessIterator, typename _Distance>
    inline constexpr void
    __advance(_RandomAccessIterator& __i, _Distance __n,
              random_access_iterator_tag)
    {

     

      if (__builtin_constant_p(__n) && __n == 1)
 ++__i;
      else if (__builtin_constant_p(__n) && __n == -1)
 --__i;
      else
 __i += __n;
    }



  template<typename _OutputIterator, typename _Distance>
    void
    __advance(_OutputIterator&, _Distance, output_iterator_tag) = delete;
# 219 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator_base_funcs.h" 3
  template<typename _InputIterator, typename _Distance>
    __attribute__((__always_inline__))
    inline constexpr void
    advance(_InputIterator& __i, _Distance __n)
    {

      typename iterator_traits<_InputIterator>::difference_type __d = __n;
      std::__advance(__i, __d, std::__iterator_category(__i));
    }



  template<typename _InputIterator>
    [[__nodiscard__]] [[__gnu__::__always_inline__]]
    inline constexpr _InputIterator
    next(_InputIterator __x, typename
  iterator_traits<_InputIterator>::difference_type __n = 1)
    {

     
      std::advance(__x, __n);
      return __x;
    }

  template<typename _BidirectionalIterator>
    [[__nodiscard__]] [[__gnu__::__always_inline__]]
    inline constexpr _BidirectionalIterator
    prev(_BidirectionalIterator __x, typename
  iterator_traits<_BidirectionalIterator>::difference_type __n = 1)
    {

     

      std::advance(__x, -__n);
      return __x;
    }




}
# 67 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 2 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 1 3
# 75 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/new" 1 3
# 43 "C:/msys64/mingw64/include/c++/15.2.0/new" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/exception.h" 1 3
# 40 "C:/msys64/mingw64/include/c++/15.2.0/bits/exception.h" 3
extern "C++" {

namespace std
{
# 61 "C:/msys64/mingw64/include/c++/15.2.0/bits/exception.h" 3
  class exception
  {
  public:
    exception() noexcept { }
    virtual ~exception() noexcept;

    exception(const exception&) = default;
    exception& operator=(const exception&) = default;
    exception(exception&&) = default;
    exception& operator=(exception&&) = default;




    virtual const char*
    what() const noexcept;
  };



}

}
# 44 "C:/msys64/mingw64/include/c++/15.2.0/new" 2 3





# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 50 "C:/msys64/mingw64/include/c++/15.2.0/new" 2 3

#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wc++11-extensions"

#pragma GCC visibility push(default)

extern "C++" {

namespace std
{






  class bad_alloc : public exception
  {
  public:
    bad_alloc() throw() { }


    bad_alloc(const bad_alloc&) = default;
    bad_alloc& operator=(const bad_alloc&) = default;




    virtual ~bad_alloc() throw();


    virtual const char* what() const throw();
  };


  class bad_array_new_length : public bad_alloc
  {
  public:
    bad_array_new_length() throw() { }



    virtual ~bad_array_new_length() throw();


    virtual const char* what() const throw();
  };



  enum class align_val_t: size_t {};


  struct nothrow_t
  {

    explicit nothrow_t() = default;

  };

  extern const nothrow_t nothrow;



  typedef void (*new_handler)();



  new_handler set_new_handler(new_handler) throw();



  new_handler get_new_handler() noexcept;

}
# 137 "C:/msys64/mingw64/include/c++/15.2.0/new" 3
[[__nodiscard__]] void* operator new(std::size_t)
 
  __attribute__((__externally_visible__, __malloc__));
[[__nodiscard__]] void* operator new[](std::size_t)
 
  __attribute__((__externally_visible__, __malloc__));
void operator delete(void*) noexcept
  __attribute__((__externally_visible__));
void operator delete[](void*) noexcept
  __attribute__((__externally_visible__));

void operator delete(void*, std::size_t)
  noexcept
  __attribute__((__externally_visible__));
void operator delete[](void*, std::size_t)
  noexcept
  __attribute__((__externally_visible__));

[[__nodiscard__]] void* operator new(std::size_t, const std::nothrow_t&)
  noexcept
  __attribute__((__externally_visible__, __alloc_size__ (1), __malloc__));
[[__nodiscard__]] void* operator new[](std::size_t, const std::nothrow_t&)
  noexcept
  __attribute__((__externally_visible__, __alloc_size__ (1), __malloc__));
void operator delete(void*, const std::nothrow_t&)
  noexcept
  __attribute__((__externally_visible__));
void operator delete[](void*, const std::nothrow_t&)
  noexcept
  __attribute__((__externally_visible__));

[[__nodiscard__]] void* operator new(std::size_t, std::align_val_t)
 
  __attribute__((__externally_visible__, __alloc_size__ (1), __alloc_align__ (2), __malloc__));
[[__nodiscard__]] void* operator new(std::size_t, std::align_val_t, const std::nothrow_t&)
  noexcept
  __attribute__((__externally_visible__, __alloc_size__ (1), __alloc_align__ (2), __malloc__));
void operator delete(void*, std::align_val_t)
  noexcept __attribute__((__externally_visible__));
void operator delete(void*, std::align_val_t, const std::nothrow_t&)
 
  noexcept __attribute__((__externally_visible__));
[[__nodiscard__]] void* operator new[](std::size_t, std::align_val_t)
 
  __attribute__((__externally_visible__, __alloc_size__ (1), __alloc_align__ (2), __malloc__));
[[__nodiscard__]] void* operator new[](std::size_t, std::align_val_t, const std::nothrow_t&)
  noexcept
  __attribute__((__externally_visible__, __alloc_size__ (1), __alloc_align__ (2), __malloc__));
void operator delete[](void*, std::align_val_t)
  noexcept __attribute__((__externally_visible__));
void operator delete[](void*, std::align_val_t, const std::nothrow_t&)
 
  noexcept __attribute__((__externally_visible__));

void operator delete(void*, std::size_t, std::align_val_t)
  noexcept __attribute__((__externally_visible__));
void operator delete[](void*, std::size_t, std::align_val_t)
  noexcept __attribute__((__externally_visible__));
# 205 "C:/msys64/mingw64/include/c++/15.2.0/new" 3
[[__nodiscard__]] inline
void* operator new(std::size_t, void* __p)
  noexcept
{ return __p; }
[[__nodiscard__]] inline
void* operator new[](std::size_t, void* __p)
  noexcept
{ return __p; }




inline void operator delete (void*, void*)
  noexcept
{ }
inline void operator delete[](void*, void*)
  noexcept
{ }

}

namespace std
{


  template<typename _Tp>
    [[nodiscard]] constexpr _Tp*
    launder(_Tp* __p) noexcept
    {
      if constexpr (__is_same(const volatile _Tp, const volatile void))
 static_assert(!__is_same(const volatile _Tp, const volatile void),
        "std::launder argument must not be a void pointer");

      else if constexpr (__is_function(_Tp))
 static_assert(!__is_function(_Tp),
        "std::launder argument must not be a function pointer");

      else
 return __builtin_launder(__p);
      return nullptr;
    }



  inline constexpr size_t hardware_destructive_interference_size = 64;
  inline constexpr size_t hardware_constructive_interference_size = 64;






  struct destroying_delete_t
  {
    explicit destroying_delete_t() = default;
  };

  inline constexpr destroying_delete_t destroying_delete{};

}

#pragma GCC visibility pop
#pragma GCC diagnostic pop
# 76 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 2 3


# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_construct.h" 1 3
# 73 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_construct.h" 3
namespace std
{



  template <typename _Tp>
    constexpr inline void
    destroy_at(_Tp* __location)
    {
      if constexpr (202002L > 201703L && is_array_v<_Tp>)
 {
   for (auto& __x : *__location)
     std::destroy_at(std::__addressof(__x));
 }
      else
 __location->~_Tp();
    }


  template<typename _Tp, typename... _Args>
    requires (!is_unbounded_array_v<_Tp>)
      && requires { ::new((void*)0) _Tp(std::declval<_Args>()...); }
    constexpr _Tp*
    construct_at(_Tp* __location, _Args&&... __args)
    noexcept(noexcept(::new((void*)0) _Tp(std::declval<_Args>()...)))
    {
      void* __loc = __location;


      if constexpr (is_array_v<_Tp>)
 {
   static_assert(sizeof...(_Args) == 0, "std::construct_at for array "
         "types must not use any arguments to initialize the "
         "array");
   return ::new(__loc) _Tp[1]();
 }
      else
 return ::new(__loc) _Tp(std::forward<_Args>(__args)...);
    }
# 120 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_construct.h" 3
  template<typename _Tp, typename... _Args>
    constexpr
    inline void
    _Construct(_Tp* __p, _Args&&... __args)
    {

      if (std::__is_constant_evaluated())
 {

   std::construct_at(__p, std::forward<_Args>(__args)...);
   return;
 }

      ::new(static_cast<void*>(__p)) _Tp(std::forward<_Args>(__args)...);
    }
# 146 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_construct.h" 3
  template<typename _T1>
   
    inline void
    _Construct_novalue(_T1* __p)
    { ::new(static_cast<void*>(__p)) _T1; }

  template<typename _ForwardIterator>
    constexpr void
    _Destroy(_ForwardIterator __first, _ForwardIterator __last);




  template<typename _Tp>
    constexpr inline void
    _Destroy(_Tp* __pointer)
    {

      std::destroy_at(__pointer);



    }

#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wc++17-extensions"
# 200 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_construct.h" 3
  template<typename _ForwardIterator>
    constexpr inline void
    _Destroy(_ForwardIterator __first, _ForwardIterator __last)
    {
      typedef typename iterator_traits<_ForwardIterator>::value_type
                       _Value_type;


      static_assert(is_destructible<_Value_type>::value,
      "value type is destructible");
      if constexpr (!__has_trivial_destructor(_Value_type))
 for (; __first != __last; ++__first)
   std::_Destroy(std::__addressof(*__first));

      else if (std::__is_constant_evaluated())
 for (; __first != __last; ++__first)
   std::destroy_at(std::__addressof(*__first));





    }
# 256 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_construct.h" 3
  template<typename _ForwardIterator, typename _Size>
    constexpr inline _ForwardIterator
    _Destroy_n(_ForwardIterator __first, _Size __count)
    {
      typedef typename iterator_traits<_ForwardIterator>::value_type
                       _Value_type;


      static_assert(is_destructible<_Value_type>::value,
      "value type is destructible");
      if constexpr (!__has_trivial_destructor(_Value_type))
 for (; __count > 0; (void)++__first, --__count)
   std::_Destroy(std::__addressof(*__first));

      else if (std::__is_constant_evaluated())
 for (; __count > 0; (void)++__first, --__count)
   std::destroy_at(std::__addressof(*__first));

      else
 std::advance(__first, __count);
      return __first;




    }
#pragma GCC diagnostic pop


  template <typename _ForwardIterator>
    constexpr inline void
    destroy(_ForwardIterator __first, _ForwardIterator __last)
    {
      std::_Destroy(__first, __last);
    }

  template <typename _ForwardIterator, typename _Size>
    constexpr inline _ForwardIterator
    destroy_n(_ForwardIterator __first, _Size __count)
    {
      return std::_Destroy_n(__first, __count);
    }



}
# 79 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 2 3






namespace std
{

# 96 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  namespace __detail
  {


    template<typename _Cat, typename _Limit, typename _Otherwise = _Cat>
      using __clamp_iter_cat
 = __conditional_t<derived_from<_Cat, _Limit>, _Limit, _Otherwise>;
  }




#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wdeprecated-declarations"
# 130 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  template<typename _Iterator>
    class reverse_iterator
    : public iterator<typename iterator_traits<_Iterator>::iterator_category,
        typename iterator_traits<_Iterator>::value_type,
        typename iterator_traits<_Iterator>::difference_type,
        typename iterator_traits<_Iterator>::pointer,
                      typename iterator_traits<_Iterator>::reference>
    {
      template<typename _Iter>
 friend class reverse_iterator;




      template<typename _Iter>
 static constexpr bool __convertible = !is_same_v<_Iter, _Iterator>
     && convertible_to<const _Iter&, _Iterator>;


    protected:
      _Iterator current;

      typedef iterator_traits<_Iterator> __traits_type;

    public:
      typedef _Iterator iterator_type;
      typedef typename __traits_type::pointer pointer;




      using iterator_concept
 = __conditional_t<random_access_iterator<_Iterator>,
     random_access_iterator_tag,
     bidirectional_iterator_tag>;
      using iterator_category
 = __detail::__clamp_iter_cat<typename __traits_type::iterator_category,
         random_access_iterator_tag>;
      using value_type = iter_value_t<_Iterator>;
      using difference_type = iter_difference_t<_Iterator>;
      using reference = iter_reference_t<_Iterator>;
# 180 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
      constexpr
      reverse_iterator()
      noexcept(noexcept(_Iterator()))
      : current()
      { }




      explicit constexpr
      reverse_iterator(iterator_type __x)
      noexcept(noexcept(_Iterator(__x)))
      : current(__x)
      { }




      constexpr
      reverse_iterator(const reverse_iterator& __x)
      noexcept(noexcept(_Iterator(__x.current)))
      : current(__x.current)
      { }


      reverse_iterator& operator=(const reverse_iterator&) = default;






      template<typename _Iter>

 requires __convertible<_Iter>

 constexpr
        reverse_iterator(const reverse_iterator<_Iter>& __x)
 noexcept(noexcept(_Iterator(__x.current)))
 : current(__x.current)
 { }


      template<typename _Iter>

 requires __convertible<_Iter>
   && assignable_from<_Iterator&, const _Iter&>

 constexpr
 reverse_iterator&
 operator=(const reverse_iterator<_Iter>& __x)
 noexcept(noexcept(current = __x.current))
 {
   current = __x.current;
   return *this;
 }





      [[__nodiscard__]]
      constexpr iterator_type
      base() const
      noexcept(noexcept(_Iterator(current)))
      { return current; }
# 257 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
      [[__nodiscard__]]
      constexpr reference
      operator*() const
      {
 _Iterator __tmp = current;
 return *--__tmp;
      }






      [[__nodiscard__]]
      constexpr pointer
      operator->() const

      requires is_pointer_v<_Iterator>
 || requires(const _Iterator __i) { __i.operator->(); }

      {


 _Iterator __tmp = current;
 --__tmp;
 return _S_to_pointer(__tmp);
      }






      constexpr reverse_iterator&
      operator++()
      {
 --current;
 return *this;
      }






      constexpr reverse_iterator
      operator++(int)
      {
 reverse_iterator __tmp = *this;
 --current;
 return __tmp;
      }






      constexpr reverse_iterator&
      operator--()
      {
 ++current;
 return *this;
      }






      constexpr reverse_iterator
      operator--(int)
      {
 reverse_iterator __tmp = *this;
 ++current;
 return __tmp;
      }






      [[__nodiscard__]]
      constexpr reverse_iterator
      operator+(difference_type __n) const
      { return reverse_iterator(current - __n); }







      constexpr reverse_iterator&
      operator+=(difference_type __n)
      {
 current -= __n;
 return *this;
      }






      [[__nodiscard__]]
      constexpr reverse_iterator
      operator-(difference_type __n) const
      { return reverse_iterator(current + __n); }







      constexpr reverse_iterator&
      operator-=(difference_type __n)
      {
 current += __n;
 return *this;
      }






      [[__nodiscard__]]
      constexpr reference
      operator[](difference_type __n) const
      { return *(*this + __n); }


      [[nodiscard]]
      friend constexpr iter_rvalue_reference_t<_Iterator>
      iter_move(const reverse_iterator& __i)
      noexcept(is_nothrow_copy_constructible_v<_Iterator>
        && noexcept(ranges::iter_move(--std::declval<_Iterator&>())))
      {
 auto __tmp = __i.base();
 return ranges::iter_move(--__tmp);
      }

      template<indirectly_swappable<_Iterator> _Iter2>
 friend constexpr void
 iter_swap(const reverse_iterator& __x,
    const reverse_iterator<_Iter2>& __y)
 noexcept(is_nothrow_copy_constructible_v<_Iterator>
   && is_nothrow_copy_constructible_v<_Iter2>
   && noexcept(ranges::iter_swap(--std::declval<_Iterator&>(),
            --std::declval<_Iter2&>())))
 {
   auto __xtmp = __x.base();
   auto __ytmp = __y.base();
   ranges::iter_swap(--__xtmp, --__ytmp);
 }


    private:
      template<typename _Tp>
 static constexpr _Tp*
 _S_to_pointer(_Tp* __p)
        { return __p; }

      template<typename _Tp>
 static constexpr pointer
 _S_to_pointer(_Tp __t)
        { return __t.operator->(); }
    };
# 526 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  template<typename _IteratorL, typename _IteratorR>
    [[nodiscard]]
    constexpr bool
    operator==(const reverse_iterator<_IteratorL>& __x,
        const reverse_iterator<_IteratorR>& __y)
    requires requires { { __x.base() == __y.base() } -> convertible_to<bool>; }
    { return __x.base() == __y.base(); }

  template<typename _IteratorL, typename _IteratorR>
    [[nodiscard]]
    constexpr bool
    operator!=(const reverse_iterator<_IteratorL>& __x,
        const reverse_iterator<_IteratorR>& __y)
    requires requires { { __x.base() != __y.base() } -> convertible_to<bool>; }
    { return __x.base() != __y.base(); }

  template<typename _IteratorL, typename _IteratorR>
    [[nodiscard]]
    constexpr bool
    operator<(const reverse_iterator<_IteratorL>& __x,
       const reverse_iterator<_IteratorR>& __y)
    requires requires { { __x.base() > __y.base() } -> convertible_to<bool>; }
    { return __x.base() > __y.base(); }

  template<typename _IteratorL, typename _IteratorR>
    [[nodiscard]]
    constexpr bool
    operator>(const reverse_iterator<_IteratorL>& __x,
       const reverse_iterator<_IteratorR>& __y)
    requires requires { { __x.base() < __y.base() } -> convertible_to<bool>; }
    { return __x.base() < __y.base(); }

  template<typename _IteratorL, typename _IteratorR>
    [[nodiscard]]
    constexpr bool
    operator<=(const reverse_iterator<_IteratorL>& __x,
        const reverse_iterator<_IteratorR>& __y)
    requires requires { { __x.base() >= __y.base() } -> convertible_to<bool>; }
    { return __x.base() >= __y.base(); }

  template<typename _IteratorL, typename _IteratorR>
    [[nodiscard]]
    constexpr bool
    operator>=(const reverse_iterator<_IteratorL>& __x,
        const reverse_iterator<_IteratorR>& __y)
    requires requires { { __x.base() <= __y.base() } -> convertible_to<bool>; }
    { return __x.base() <= __y.base(); }

  template<typename _IteratorL,
    three_way_comparable_with<_IteratorL> _IteratorR>
    [[nodiscard]]
    constexpr compare_three_way_result_t<_IteratorL, _IteratorR>
    operator<=>(const reverse_iterator<_IteratorL>& __x,
  const reverse_iterator<_IteratorR>& __y)
    { return __y.base() <=> __x.base(); }




  template<typename _Iterator>
    [[nodiscard]]
    constexpr bool
    operator==(const reverse_iterator<_Iterator>& __x,
        const reverse_iterator<_Iterator>& __y)
    requires requires { { __x.base() == __y.base() } -> convertible_to<bool>; }
    { return __x.base() == __y.base(); }

  template<three_way_comparable _Iterator>
    [[nodiscard]]
    constexpr compare_three_way_result_t<_Iterator, _Iterator>
    operator<=>(const reverse_iterator<_Iterator>& __x,
  const reverse_iterator<_Iterator>& __y)
    { return __y.base() <=> __x.base(); }
# 617 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr auto
    operator-(const reverse_iterator<_IteratorL>& __x,
       const reverse_iterator<_IteratorR>& __y)
    -> decltype(__y.base() - __x.base())
    { return __y.base() - __x.base(); }


  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr reverse_iterator<_Iterator>
    operator+(typename reverse_iterator<_Iterator>::difference_type __n,
       const reverse_iterator<_Iterator>& __x)
    { return reverse_iterator<_Iterator>(__x.base() - __n); }



  template<typename _Iterator>
    inline constexpr reverse_iterator<_Iterator>
    __make_reverse_iterator(_Iterator __i)
    { return reverse_iterator<_Iterator>(__i); }





  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr reverse_iterator<_Iterator>
    make_reverse_iterator(_Iterator __i)
    { return reverse_iterator<_Iterator>(__i); }


  template<typename _Iterator1, typename _Iterator2>
    requires (!sized_sentinel_for<_Iterator1, _Iterator2>)
    inline constexpr bool
    disable_sized_sentinel_for<reverse_iterator<_Iterator1>,
          reverse_iterator<_Iterator2>> = true;



  template<typename _Iterator>
    struct __is_move_iterator<reverse_iterator<_Iterator> >
      : __is_move_iterator<_Iterator>
    { };
# 676 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  template<typename _Container>
    class back_insert_iterator
    : public iterator<output_iterator_tag, void, void, void, void>
    {
    protected:
      _Container* container;

    public:

      typedef _Container container_type;

      using difference_type = ptrdiff_t;



      explicit constexpr
      back_insert_iterator(_Container& __x)
      : container(std::__addressof(__x)) { }
# 714 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
      constexpr
      back_insert_iterator&
      operator=(const typename _Container::value_type& __value)
      {
 container->push_back(__value);
 return *this;
      }

      constexpr
      back_insert_iterator&
      operator=(typename _Container::value_type&& __value)
      {
 container->push_back(std::move(__value));
 return *this;
      }



      [[__nodiscard__]] constexpr
      back_insert_iterator&
      operator*()
      { return *this; }


      constexpr
      back_insert_iterator&
      operator++()
      { return *this; }


      constexpr
      back_insert_iterator
      operator++(int)
      { return *this; }
    };
# 761 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  template<typename _Container>
    [[__nodiscard__]] constexpr
    inline back_insert_iterator<_Container>
    back_inserter(_Container& __x)
    { return back_insert_iterator<_Container>(__x); }
# 777 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  template<typename _Container>
    class front_insert_iterator
    : public iterator<output_iterator_tag, void, void, void, void>
    {
    protected:
      _Container* container;

    public:

      typedef _Container container_type;

      using difference_type = ptrdiff_t;



      explicit constexpr
      front_insert_iterator(_Container& __x)
      : container(std::__addressof(__x)) { }
# 815 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
      constexpr
      front_insert_iterator&
      operator=(const typename _Container::value_type& __value)
      {
 container->push_front(__value);
 return *this;
      }

      constexpr
      front_insert_iterator&
      operator=(typename _Container::value_type&& __value)
      {
 container->push_front(std::move(__value));
 return *this;
      }



      [[__nodiscard__]] constexpr
      front_insert_iterator&
      operator*()
      { return *this; }


      constexpr
      front_insert_iterator&
      operator++()
      { return *this; }


      constexpr
      front_insert_iterator
      operator++(int)
      { return *this; }
    };
# 862 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  template<typename _Container>
    [[__nodiscard__]] constexpr
    inline front_insert_iterator<_Container>
    front_inserter(_Container& __x)
    { return front_insert_iterator<_Container>(__x); }
# 882 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  template<typename _Container>
    class insert_iterator
    : public iterator<output_iterator_tag, void, void, void, void>
    {

      using _Iter = std::__detail::__range_iter_t<_Container>;



    protected:
      _Container* container;
      _Iter iter;

    public:

      typedef _Container container_type;


      using difference_type = ptrdiff_t;






      constexpr
      insert_iterator(_Container& __x, _Iter __i)
      : container(std::__addressof(__x)), iter(__i) {}
# 943 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
      constexpr
      insert_iterator&
      operator=(const typename _Container::value_type& __value)
      {
 iter = container->insert(iter, __value);
 ++iter;
 return *this;
      }

      constexpr
      insert_iterator&
      operator=(typename _Container::value_type&& __value)
      {
 iter = container->insert(iter, std::move(__value));
 ++iter;
 return *this;
      }



      [[__nodiscard__]] constexpr
      insert_iterator&
      operator*()
      { return *this; }


      constexpr
      insert_iterator&
      operator++()
      { return *this; }


      constexpr
      insert_iterator&
      operator++(int)
      { return *this; }
    };

#pragma GCC diagnostic pop
# 996 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  template<typename _Container>
    [[nodiscard]]
    constexpr insert_iterator<_Container>
    inserter(_Container& __x, std::__detail::__range_iter_t<_Container> __i)
    { return insert_iterator<_Container>(__x, __i); }
# 1011 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3

}

namespace __gnu_cxx
{

# 1025 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  template<typename _Iterator, typename _Container>
    class __normal_iterator
    {
    protected:
      _Iterator _M_current;

      typedef std::iterator_traits<_Iterator> __traits_type;







    public:
      typedef _Iterator iterator_type;
      typedef typename __traits_type::iterator_category iterator_category;
      typedef typename __traits_type::value_type value_type;
      typedef typename __traits_type::difference_type difference_type;
      typedef typename __traits_type::reference reference;
      typedef typename __traits_type::pointer pointer;


      using iterator_concept = std::__detail::__iter_concept<_Iterator>;


      __attribute__((__always_inline__))
      constexpr
      __normal_iterator() noexcept
      : _M_current() { }

      __attribute__((__always_inline__))
      explicit constexpr
      __normal_iterator(const _Iterator& __i) noexcept
      : _M_current(__i) { }




      template<typename _Iter> requires std::is_convertible_v<_Iter, _Iterator>



 [[__gnu__::__always_inline__]]
 constexpr
 __normal_iterator(const __normal_iterator<_Iter, _Container>& __i)
 noexcept
# 1082 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
        : _M_current(__i.base()) { }



      [[__nodiscard__]] __attribute__((__always_inline__))
      constexpr
      reference
      operator*() const noexcept
      { return *_M_current; }

      [[__nodiscard__]] __attribute__((__always_inline__))
      constexpr
      pointer
      operator->() const noexcept
      { return _M_current; }

      __attribute__((__always_inline__))
      constexpr
      __normal_iterator&
      operator++() noexcept
      {
 ++_M_current;
 return *this;
      }

      __attribute__((__always_inline__))
      constexpr
      __normal_iterator
      operator++(int) noexcept
      { return __normal_iterator(_M_current++); }



      __attribute__((__always_inline__))
      constexpr
      __normal_iterator&
      operator--() noexcept
      {
 --_M_current;
 return *this;
      }

      __attribute__((__always_inline__))
      constexpr
      __normal_iterator
      operator--(int) noexcept
      { return __normal_iterator(_M_current--); }



      [[__nodiscard__]] __attribute__((__always_inline__))
      constexpr
      reference
      operator[](difference_type __n) const noexcept
      { return _M_current[__n]; }

      __attribute__((__always_inline__))
      constexpr
      __normal_iterator&
      operator+=(difference_type __n) noexcept
      { _M_current += __n; return *this; }

      [[__nodiscard__]] __attribute__((__always_inline__))
      constexpr
      __normal_iterator
      operator+(difference_type __n) const noexcept
      { return __normal_iterator(_M_current + __n); }

      __attribute__((__always_inline__))
      constexpr
      __normal_iterator&
      operator-=(difference_type __n) noexcept
      { _M_current -= __n; return *this; }

      [[__nodiscard__]] __attribute__((__always_inline__))
      constexpr
      __normal_iterator
      operator-(difference_type __n) const noexcept
      { return __normal_iterator(_M_current - __n); }

      [[__nodiscard__]] __attribute__((__always_inline__))
      constexpr
      const _Iterator&
      base() const noexcept
      { return _M_current; }
    };
# 1178 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  template<typename _IteratorL, typename _IteratorR, typename _Container>
    [[nodiscard, __gnu__::__always_inline__]]
    constexpr bool
    operator==(const __normal_iterator<_IteratorL, _Container>& __lhs,
        const __normal_iterator<_IteratorR, _Container>& __rhs)
    noexcept(noexcept(__lhs.base() == __rhs.base()))
    requires requires {
      { __lhs.base() == __rhs.base() } -> std::convertible_to<bool>;
    }
    { return __lhs.base() == __rhs.base(); }

  template<typename _IteratorL, typename _IteratorR, typename _Container>
    [[nodiscard, __gnu__::__always_inline__]]
    constexpr std::__detail::__synth3way_t<_IteratorR, _IteratorL>
    operator<=>(const __normal_iterator<_IteratorL, _Container>& __lhs,
  const __normal_iterator<_IteratorR, _Container>& __rhs)
    noexcept(noexcept(std::__detail::__synth3way(__lhs.base(), __rhs.base())))
    { return std::__detail::__synth3way(__lhs.base(), __rhs.base()); }

  template<typename _Iterator, typename _Container>
    [[nodiscard, __gnu__::__always_inline__]]
    constexpr bool
    operator==(const __normal_iterator<_Iterator, _Container>& __lhs,
        const __normal_iterator<_Iterator, _Container>& __rhs)
    noexcept(noexcept(__lhs.base() == __rhs.base()))
    requires requires {
      { __lhs.base() == __rhs.base() } -> std::convertible_to<bool>;
    }
    { return __lhs.base() == __rhs.base(); }

  template<typename _Iterator, typename _Container>
    [[nodiscard, __gnu__::__always_inline__]]
    constexpr std::__detail::__synth3way_t<_Iterator>
    operator<=>(const __normal_iterator<_Iterator, _Container>& __lhs,
  const __normal_iterator<_Iterator, _Container>& __rhs)
    noexcept(noexcept(std::__detail::__synth3way(__lhs.base(), __rhs.base())))
    { return std::__detail::__synth3way(__lhs.base(), __rhs.base()); }
# 1319 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  template<typename _IteratorL, typename _IteratorR, typename _Container>


    [[__nodiscard__, __gnu__::__always_inline__]]
    constexpr auto
    operator-(const __normal_iterator<_IteratorL, _Container>& __lhs,
       const __normal_iterator<_IteratorR, _Container>& __rhs) noexcept
    -> decltype(__lhs.base() - __rhs.base())





    { return __lhs.base() - __rhs.base(); }

  template<typename _Iterator, typename _Container>
    [[__nodiscard__]] __attribute__((__always_inline__)) constexpr
    inline typename __normal_iterator<_Iterator, _Container>::difference_type
    operator-(const __normal_iterator<_Iterator, _Container>& __lhs,
       const __normal_iterator<_Iterator, _Container>& __rhs)
    noexcept
    { return __lhs.base() - __rhs.base(); }

  template<typename _Iterator, typename _Container>
    [[__nodiscard__]] __attribute__((__always_inline__)) constexpr
    inline __normal_iterator<_Iterator, _Container>
    operator+(typename __normal_iterator<_Iterator, _Container>::difference_type
       __n, const __normal_iterator<_Iterator, _Container>& __i)
    noexcept
    { return __normal_iterator<_Iterator, _Container>(__i.base() + __n); }


}

namespace std
{

# 1365 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  template<semiregular _Sent>
    class move_sentinel
    {
    public:
      constexpr
      move_sentinel()
      noexcept(is_nothrow_default_constructible_v<_Sent>)
      : _M_last() { }

      constexpr explicit
      move_sentinel(_Sent __s)
      noexcept(is_nothrow_move_constructible_v<_Sent>)
      : _M_last(std::move(__s)) { }

      template<typename _S2> requires convertible_to<const _S2&, _Sent>
 constexpr
 move_sentinel(const move_sentinel<_S2>& __s)
 noexcept(is_nothrow_constructible_v<_Sent, const _S2&>)
 : _M_last(__s.base())
 { }

      template<typename _S2> requires assignable_from<_Sent&, const _S2&>
 constexpr move_sentinel&
 operator=(const move_sentinel<_S2>& __s)
 noexcept(is_nothrow_assignable_v<_Sent, const _S2&>)
 {
   _M_last = __s.base();
   return *this;
 }

      [[nodiscard]]
      constexpr _Sent
      base() const
      noexcept(is_nothrow_copy_constructible_v<_Sent>)
      { return _M_last; }

    private:
      _Sent _M_last;
    };


  namespace __detail
  {
    template<typename _Iterator>
      struct __move_iter_cat
      { };

    template<typename _Iterator>
      requires requires { typename __iter_category_t<_Iterator>; }
      struct __move_iter_cat<_Iterator>
      {
 using iterator_category
   = __clamp_iter_cat<__iter_category_t<_Iterator>,
        random_access_iterator_tag>;
      };
  }
# 1434 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  template<typename _Iterator>
    class move_iterator

      : public __detail::__move_iter_cat<_Iterator>

    {
      _Iterator _M_current;

      using __traits_type = iterator_traits<_Iterator>;




      template<typename _Iter2>
 friend class move_iterator;




      template<typename _Iter2>
 static constexpr bool __convertible = !is_same_v<_Iter2, _Iterator>
     && convertible_to<const _Iter2&, _Iterator>;



      static auto
      _S_iter_concept()
      {
 if constexpr (random_access_iterator<_Iterator>)
   return random_access_iterator_tag{};
 else if constexpr (bidirectional_iterator<_Iterator>)
   return bidirectional_iterator_tag{};
 else if constexpr (forward_iterator<_Iterator>)
   return forward_iterator_tag{};
 else
   return input_iterator_tag{};
      }


    public:
      using iterator_type = _Iterator;


      using iterator_concept = decltype(_S_iter_concept());


      using value_type = iter_value_t<_Iterator>;
      using difference_type = iter_difference_t<_Iterator>;
      using pointer = _Iterator;
      using reference = iter_rvalue_reference_t<_Iterator>;
# 1498 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
      constexpr
      move_iterator()
      : _M_current() { }

      explicit constexpr
      move_iterator(iterator_type __i)
      : _M_current(std::move(__i)) { }

      template<typename _Iter>

 requires __convertible<_Iter>

 constexpr
 move_iterator(const move_iterator<_Iter>& __i)
 : _M_current(__i._M_current) { }

      template<typename _Iter>

 requires __convertible<_Iter>
   && assignable_from<_Iterator&, const _Iter&>

 constexpr
 move_iterator& operator=(const move_iterator<_Iter>& __i)
 {
   _M_current = __i._M_current;
   return *this;
 }







      [[nodiscard]]
      constexpr const iterator_type&
      base() const & noexcept
      { return _M_current; }

      [[nodiscard]]
      constexpr iterator_type
      base() &&
      { return std::move(_M_current); }


      [[__nodiscard__]]
      constexpr reference
      operator*() const

      { return ranges::iter_move(_M_current); }




      [[__nodiscard__]]
      constexpr pointer
      operator->() const
      { return _M_current; }

      constexpr move_iterator&
      operator++()
      {
 ++_M_current;
 return *this;
      }

      constexpr move_iterator
      operator++(int)
      {
 move_iterator __tmp = *this;
 ++_M_current;
 return __tmp;
      }


      constexpr void
      operator++(int) requires (!forward_iterator<_Iterator>)
      { ++_M_current; }


      constexpr move_iterator&
      operator--()
      {
 --_M_current;
 return *this;
      }

      constexpr move_iterator
      operator--(int)
      {
 move_iterator __tmp = *this;
 --_M_current;
 return __tmp;
      }

      [[__nodiscard__]]
      constexpr move_iterator
      operator+(difference_type __n) const
      { return move_iterator(_M_current + __n); }

      constexpr move_iterator&
      operator+=(difference_type __n)
      {
 _M_current += __n;
 return *this;
      }

      [[__nodiscard__]]
      constexpr move_iterator
      operator-(difference_type __n) const
      { return move_iterator(_M_current - __n); }

      constexpr move_iterator&
      operator-=(difference_type __n)
      {
 _M_current -= __n;
 return *this;
      }

      [[__nodiscard__]]
      constexpr reference
      operator[](difference_type __n) const

      { return ranges::iter_move(_M_current + __n); }





      template<sentinel_for<_Iterator> _Sent>
 [[nodiscard]]
 friend constexpr bool
 operator==(const move_iterator& __x, const move_sentinel<_Sent>& __y)
 { return __x.base() == __y.base(); }

      template<sized_sentinel_for<_Iterator> _Sent>
 [[nodiscard]]
 friend constexpr iter_difference_t<_Iterator>
 operator-(const move_sentinel<_Sent>& __x, const move_iterator& __y)
 { return __x.base() - __y.base(); }

      template<sized_sentinel_for<_Iterator> _Sent>
 [[nodiscard]]
 friend constexpr iter_difference_t<_Iterator>
 operator-(const move_iterator& __x, const move_sentinel<_Sent>& __y)
 { return __x.base() - __y.base(); }

      [[nodiscard]]
      friend constexpr iter_rvalue_reference_t<_Iterator>
      iter_move(const move_iterator& __i)
      noexcept(noexcept(ranges::iter_move(__i._M_current)))
      { return ranges::iter_move(__i._M_current); }

      template<indirectly_swappable<_Iterator> _Iter2>
 friend constexpr void
 iter_swap(const move_iterator& __x, const move_iterator<_Iter2>& __y)
 noexcept(noexcept(ranges::iter_swap(__x._M_current, __y._M_current)))
 { return ranges::iter_swap(__x._M_current, __y._M_current); }

    };

  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr bool
    operator==(const move_iterator<_IteratorL>& __x,
        const move_iterator<_IteratorR>& __y)

    requires requires { { __x.base() == __y.base() } -> convertible_to<bool>; }

    { return __x.base() == __y.base(); }


  template<typename _IteratorL,
    three_way_comparable_with<_IteratorL> _IteratorR>
    [[__nodiscard__]]
    constexpr compare_three_way_result_t<_IteratorL, _IteratorR>
    operator<=>(const move_iterator<_IteratorL>& __x,
  const move_iterator<_IteratorR>& __y)
    { return __x.base() <=> __y.base(); }
# 1686 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr bool
    operator<(const move_iterator<_IteratorL>& __x,
       const move_iterator<_IteratorR>& __y)

    requires requires { { __x.base() < __y.base() } -> convertible_to<bool>; }

    { return __x.base() < __y.base(); }

  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr bool
    operator<=(const move_iterator<_IteratorL>& __x,
        const move_iterator<_IteratorR>& __y)

    requires requires { { __y.base() < __x.base() } -> convertible_to<bool>; }

    { return !(__y < __x); }

  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr bool
    operator>(const move_iterator<_IteratorL>& __x,
       const move_iterator<_IteratorR>& __y)

    requires requires { { __y.base() < __x.base() } -> convertible_to<bool>; }

    { return __y < __x; }

  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr bool
    operator>=(const move_iterator<_IteratorL>& __x,
        const move_iterator<_IteratorR>& __y)

    requires requires { { __x.base() < __y.base() } -> convertible_to<bool>; }

    { return !(__x < __y); }




  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr bool
    operator==(const move_iterator<_Iterator>& __x,
        const move_iterator<_Iterator>& __y)

    { return __x.base() == __y.base(); }


  template<three_way_comparable _Iterator>
    [[__nodiscard__]]
    constexpr compare_three_way_result_t<_Iterator>
    operator<=>(const move_iterator<_Iterator>& __x,
  const move_iterator<_Iterator>& __y)
    { return __x.base() <=> __y.base(); }
# 1782 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr auto
    operator-(const move_iterator<_IteratorL>& __x,
       const move_iterator<_IteratorR>& __y)
    -> decltype(__x.base() - __y.base())
    { return __x.base() - __y.base(); }

  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr move_iterator<_Iterator>
    operator+(typename move_iterator<_Iterator>::difference_type __n,
       const move_iterator<_Iterator>& __x)

    requires requires { { __x.base() + __n } -> same_as<_Iterator>; }

    { return __x + __n; }

  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr move_iterator<_Iterator>
    make_move_iterator(_Iterator __i)
    { return move_iterator<_Iterator>(std::move(__i)); }

  template<typename _Iterator, typename _ReturnType
    = __conditional_t<__move_if_noexcept_cond
      <typename iterator_traits<_Iterator>::value_type>::value,
  _Iterator, move_iterator<_Iterator>>>
    [[__nodiscard__]]
    constexpr _ReturnType
    __make_move_if_noexcept_iterator(_Iterator __i)
    { return _ReturnType(__i); }



  template<typename _Tp, typename _ReturnType
    = __conditional_t<__move_if_noexcept_cond<_Tp>::value,
        const _Tp*, move_iterator<_Tp*>>>
    [[__nodiscard__]]
    constexpr _ReturnType
    __make_move_if_noexcept_iterator(_Tp* __i)
    { return _ReturnType(__i); }

  template<typename _Iterator>
    struct __is_move_iterator<move_iterator<_Iterator> >
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };
# 1843 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  template<typename _Iterator1, typename _Iterator2>
    requires (!sized_sentinel_for<_Iterator1, _Iterator2>)
    inline constexpr bool
    disable_sized_sentinel_for<move_iterator<_Iterator1>,
          move_iterator<_Iterator2>> = true;




  namespace __detail
  {
    template<typename _It>
      concept __common_iter_has_arrow = indirectly_readable<const _It>
 && (requires(const _It& __it) { __it.operator->(); }
     || is_reference_v<iter_reference_t<_It>>
     || constructible_from<iter_value_t<_It>, iter_reference_t<_It>>);

    template<typename _It>
      concept __common_iter_use_postfix_proxy
 = (!requires (_It& __i) { { *__i++ } -> __can_reference; })
   && constructible_from<iter_value_t<_It>, iter_reference_t<_It>>
   && move_constructible<iter_value_t<_It>>;
  }



  template<input_or_output_iterator _It, sentinel_for<_It> _Sent>
    requires (!same_as<_It, _Sent>) && copyable<_It>
  class common_iterator
  {
    template<typename _Tp, typename _Up>
      static constexpr bool
      _S_noexcept1()
      {
 if constexpr (is_trivially_default_constructible_v<_Tp>)
   return is_nothrow_assignable_v<_Tp&, _Up>;
 else
   return is_nothrow_constructible_v<_Tp, _Up>;
      }

    template<typename _It2, typename _Sent2>
      static constexpr bool
      _S_noexcept()
      { return _S_noexcept1<_It, _It2>() && _S_noexcept1<_Sent, _Sent2>(); }

    class __arrow_proxy
    {
      iter_value_t<_It> _M_keep;

      constexpr
      __arrow_proxy(iter_reference_t<_It>&& __x)
      : _M_keep(std::move(__x)) { }

      friend class common_iterator;

    public:
      constexpr const iter_value_t<_It>*
      operator->() const noexcept
      { return std::__addressof(_M_keep); }
    };

    class __postfix_proxy
    {
      iter_value_t<_It> _M_keep;

      constexpr
      __postfix_proxy(iter_reference_t<_It>&& __x)
      : _M_keep(std::forward<iter_reference_t<_It>>(__x)) { }

      friend class common_iterator;

    public:
      constexpr const iter_value_t<_It>&
      operator*() const noexcept
      { return _M_keep; }
    };

  public:
    constexpr
    common_iterator()
    noexcept(is_nothrow_default_constructible_v<_It>)
    requires default_initializable<_It>
    : _M_it(), _M_index(0)
    { }

    constexpr
    common_iterator(_It __i)
    noexcept(is_nothrow_move_constructible_v<_It>)
    : _M_it(std::move(__i)), _M_index(0)
    { }

    constexpr
    common_iterator(_Sent __s)
    noexcept(is_nothrow_move_constructible_v<_Sent>)
    : _M_sent(std::move(__s)), _M_index(1)
    { }

    template<typename _It2, typename _Sent2>
      requires convertible_to<const _It2&, _It>
 && convertible_to<const _Sent2&, _Sent>
      constexpr
      common_iterator(const common_iterator<_It2, _Sent2>& __x)
      noexcept(_S_noexcept<const _It2&, const _Sent2&>())
      : _M_valueless(), _M_index(__x._M_index)
      {
 do { if (__builtin_expect(!bool(__x._M_has_value()), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 1948, __PRETTY_FUNCTION__, "__x._M_has_value()"); } while (false);
 if (_M_index == 0)
   {
     if constexpr (is_trivially_default_constructible_v<_It>)
       _M_it = std::move(__x._M_it);
     else
       std::construct_at(std::__addressof(_M_it), __x._M_it);
   }
 else if (_M_index == 1)
   {
     if constexpr (is_trivially_default_constructible_v<_Sent>)
       _M_sent = std::move(__x._M_sent);
     else
       std::construct_at(std::__addressof(_M_sent), __x._M_sent);
   }
      }

    common_iterator(const common_iterator&) = default;

    constexpr
    common_iterator(const common_iterator& __x)
    noexcept(_S_noexcept<const _It&, const _Sent&>())
    requires (!is_trivially_copyable_v<_It> || !is_trivially_copyable_v<_Sent>)
    : _M_valueless(), _M_index(__x._M_index)
    {
      if (_M_index == 0)
 {
   if constexpr (is_trivially_default_constructible_v<_It>)
     _M_it = __x._M_it;
   else
     std::construct_at(std::__addressof(_M_it), __x._M_it);
 }
      else if (_M_index == 1)
 {
   if constexpr (is_trivially_default_constructible_v<_Sent>)
     _M_sent = __x._M_sent;
   else
     std::construct_at(std::__addressof(_M_sent), __x._M_sent);
 }
    }

    common_iterator(common_iterator&&) = default;

    constexpr
    common_iterator(common_iterator&& __x)
    noexcept(_S_noexcept<_It, _Sent>())
    requires (!is_trivially_copyable_v<_It> || !is_trivially_copyable_v<_Sent>)
    : _M_valueless(), _M_index(__x._M_index)
    {
      if (_M_index == 0)
 {
   if constexpr (is_trivially_default_constructible_v<_It>)
     _M_it = std::move(__x._M_it);
   else
     std::construct_at(std::__addressof(_M_it), std::move(__x._M_it));
 }
      else if (_M_index == 1)
 {
   if constexpr (is_trivially_default_constructible_v<_Sent>)
     _M_sent = std::move(__x._M_sent);
   else
     std::construct_at(std::__addressof(_M_sent),
         std::move(__x._M_sent));
 }
    }

    constexpr common_iterator&
    operator=(const common_iterator&) = default;

    constexpr common_iterator&
    operator=(const common_iterator& __x)
    noexcept(is_nothrow_copy_assignable_v<_It>
      && is_nothrow_copy_assignable_v<_Sent>
      && is_nothrow_copy_constructible_v<_It>
      && is_nothrow_copy_constructible_v<_Sent>)
    requires (!is_trivially_copy_assignable_v<_It>
  || !is_trivially_copy_assignable_v<_Sent>)
    {
      _M_assign(__x);
      return *this;
    }

    constexpr common_iterator&
    operator=(common_iterator&&) = default;

    constexpr common_iterator&
    operator=(common_iterator&& __x)
    noexcept(is_nothrow_move_assignable_v<_It>
      && is_nothrow_move_assignable_v<_Sent>
      && is_nothrow_move_constructible_v<_It>
      && is_nothrow_move_constructible_v<_Sent>)
    requires (!is_trivially_move_assignable_v<_It>
  || !is_trivially_move_assignable_v<_Sent>)
    {
      _M_assign(std::move(__x));
      return *this;
    }

    template<typename _It2, typename _Sent2>
      requires convertible_to<const _It2&, _It>
 && convertible_to<const _Sent2&, _Sent>
 && assignable_from<_It&, const _It2&>
 && assignable_from<_Sent&, const _Sent2&>
      constexpr common_iterator&
      operator=(const common_iterator<_It2, _Sent2>& __x)
      noexcept(is_nothrow_constructible_v<_It, const _It2&>
        && is_nothrow_constructible_v<_Sent, const _Sent2&>
        && is_nothrow_assignable_v<_It&, const _It2&>
        && is_nothrow_assignable_v<_Sent&, const _Sent2&>)
      {
 do { if (__builtin_expect(!bool(__x._M_has_value()), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2058, __PRETTY_FUNCTION__, "__x._M_has_value()"); } while (false);
 _M_assign(__x);
 return *this;
      }


    ~common_iterator() = default;

    constexpr
    ~common_iterator()
      requires (!is_trivially_destructible_v<_It>
    || !is_trivially_destructible_v<_Sent>)




    {
      if (_M_index == 0)
 _M_it.~_It();
      else if (_M_index == 1)
 _M_sent.~_Sent();
    }

    [[nodiscard]]
    constexpr decltype(auto)
    operator*()
    {
      do { if (__builtin_expect(!bool(_M_index == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2085, __PRETTY_FUNCTION__, "_M_index == 0"); } while (false);
      return *_M_it;
    }

    [[nodiscard]]
    constexpr decltype(auto)
    operator*() const requires __detail::__dereferenceable<const _It>
    {
      do { if (__builtin_expect(!bool(_M_index == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2093, __PRETTY_FUNCTION__, "_M_index == 0"); } while (false);
      return *_M_it;
    }

    [[nodiscard]]
    constexpr auto
    operator->() const requires __detail::__common_iter_has_arrow<_It>
    {
      do { if (__builtin_expect(!bool(_M_index == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2101, __PRETTY_FUNCTION__, "_M_index == 0"); } while (false);
      if constexpr (is_pointer_v<_It> || requires { _M_it.operator->(); })
 return _M_it;
      else if constexpr (is_reference_v<iter_reference_t<_It>>)
 {
   auto&& __tmp = *_M_it;
   return std::__addressof(__tmp);
 }
      else
 return __arrow_proxy{*_M_it};
    }

    constexpr common_iterator&
    operator++()
    {
      do { if (__builtin_expect(!bool(_M_index == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2116, __PRETTY_FUNCTION__, "_M_index == 0"); } while (false);
      ++_M_it;
      return *this;
    }

    constexpr decltype(auto)
    operator++(int)
    {
      do { if (__builtin_expect(!bool(_M_index == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2124, __PRETTY_FUNCTION__, "_M_index == 0"); } while (false);
      if constexpr (forward_iterator<_It>)
 {
   common_iterator __tmp = *this;
   ++*this;
   return __tmp;
 }
      else if constexpr (!__detail::__common_iter_use_postfix_proxy<_It>)
 return _M_it++;
      else
 {
   __postfix_proxy __p(**this);
   ++*this;
   return __p;
 }
    }

    template<typename _It2, sentinel_for<_It> _Sent2>
      requires sentinel_for<_Sent, _It2>
      friend constexpr bool
      operator== [[nodiscard]] (const common_iterator& __x,
    const common_iterator<_It2, _Sent2>& __y)
      {
 switch(__x._M_index << 2 | __y._M_index)
   {
   case 0b0000:
   case 0b0101:
     return true;
   case 0b0001:
     return __x._M_it == __y._M_sent;
   case 0b0100:
     return __x._M_sent == __y._M_it;
   default:
     do { if (__builtin_expect(!bool(__x._M_has_value()), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2157, __PRETTY_FUNCTION__, "__x._M_has_value()"); } while (false);
     do { if (__builtin_expect(!bool(__y._M_has_value()), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2158, __PRETTY_FUNCTION__, "__y._M_has_value()"); } while (false);
     __builtin_unreachable();
   }
      }

    template<typename _It2, sentinel_for<_It> _Sent2>
      requires sentinel_for<_Sent, _It2> && equality_comparable_with<_It, _It2>
      friend constexpr bool
      operator== [[nodiscard]] (const common_iterator& __x,
    const common_iterator<_It2, _Sent2>& __y)
      {
 switch(__x._M_index << 2 | __y._M_index)
   {
   case 0b0101:
     return true;
   case 0b0000:
     return __x._M_it == __y._M_it;
   case 0b0001:
     return __x._M_it == __y._M_sent;
   case 0b0100:
     return __x._M_sent == __y._M_it;
   default:
     do { if (__builtin_expect(!bool(__x._M_has_value()), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2180, __PRETTY_FUNCTION__, "__x._M_has_value()"); } while (false);
     do { if (__builtin_expect(!bool(__y._M_has_value()), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2181, __PRETTY_FUNCTION__, "__y._M_has_value()"); } while (false);
     __builtin_unreachable();
   }
      }

    template<sized_sentinel_for<_It> _It2, sized_sentinel_for<_It> _Sent2>
      requires sized_sentinel_for<_Sent, _It2>
      friend constexpr iter_difference_t<_It2>
      operator- [[nodiscard]] (const common_iterator& __x,
          const common_iterator<_It2, _Sent2>& __y)
      {
 switch(__x._M_index << 2 | __y._M_index)
   {
   case 0b0101:
     return 0;
   case 0b0000:
     return __x._M_it - __y._M_it;
   case 0b0001:
     return __x._M_it - __y._M_sent;
   case 0b0100:
     return __x._M_sent - __y._M_it;
   default:
     do { if (__builtin_expect(!bool(__x._M_has_value()), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2203, __PRETTY_FUNCTION__, "__x._M_has_value()"); } while (false);
     do { if (__builtin_expect(!bool(__y._M_has_value()), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2204, __PRETTY_FUNCTION__, "__y._M_has_value()"); } while (false);
     __builtin_unreachable();
   }
      }

    [[nodiscard]]
    friend constexpr iter_rvalue_reference_t<_It>
    iter_move(const common_iterator& __i)
    noexcept(noexcept(ranges::iter_move(std::declval<const _It&>())))
    requires input_iterator<_It>
    {
      do { if (__builtin_expect(!bool(__i._M_index == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2215, __PRETTY_FUNCTION__, "__i._M_index == 0"); } while (false);
      return ranges::iter_move(__i._M_it);
    }

    template<indirectly_swappable<_It> _It2, typename _Sent2>
      friend constexpr void
      iter_swap(const common_iterator& __x,
  const common_iterator<_It2, _Sent2>& __y)
      noexcept(noexcept(ranges::iter_swap(std::declval<const _It&>(),
       std::declval<const _It2&>())))
      {
 do { if (__builtin_expect(!bool(__x._M_index == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2226, __PRETTY_FUNCTION__, "__x._M_index == 0"); } while (false);
 do { if (__builtin_expect(!bool(__y._M_index == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2227, __PRETTY_FUNCTION__, "__y._M_index == 0"); } while (false);
 return ranges::iter_swap(__x._M_it, __y._M_it);
      }

  private:
    template<input_or_output_iterator _It2, sentinel_for<_It2> _Sent2>
      requires (!same_as<_It2, _Sent2>) && copyable<_It2>
      friend class common_iterator;

    constexpr bool
    _M_has_value() const noexcept { return _M_index != _S_valueless; }

    template<typename _CIt>
      constexpr void
      _M_assign(_CIt&& __x)
      {
 if (_M_index == __x._M_index)
   {
     if (_M_index == 0)
       _M_it = std::forward<_CIt>(__x)._M_it;
     else if (_M_index == 1)
       _M_sent = std::forward<_CIt>(__x)._M_sent;
   }
 else
   {
     if (_M_index == 0)
       _M_it.~_It();
     else if (_M_index == 1)
       _M_sent.~_Sent();
     _M_index = _S_valueless;

     if (__x._M_index == 0)
       std::construct_at(std::__addressof(_M_it),
    std::forward<_CIt>(__x)._M_it);
     else if (__x._M_index == 1)
       std::construct_at(std::__addressof(_M_sent),
    std::forward<_CIt>(__x)._M_sent);
     _M_index = __x._M_index;
   }
      }

    union
    {
      _It _M_it;
      _Sent _M_sent;
      unsigned char _M_valueless;
    };
    unsigned char _M_index;

    static constexpr unsigned char _S_valueless{2};
  };

  template<typename _It, typename _Sent>
    struct incrementable_traits<common_iterator<_It, _Sent>>
    {
      using difference_type = iter_difference_t<_It>;
    };

  template<input_iterator _It, typename _Sent>
    struct iterator_traits<common_iterator<_It, _Sent>>
    {
    private:
      template<typename _Iter>
 struct __ptr
 {
   using type = void;
 };

      template<typename _Iter>
 requires __detail::__common_iter_has_arrow<_Iter>
 struct __ptr<_Iter>
 {
   using _CIter = common_iterator<_Iter, _Sent>;
   using type = decltype(std::declval<const _CIter&>().operator->());
 };

      static auto
      _S_iter_cat()
      {
 if constexpr (requires { requires derived_from<__iter_category_t<_It>,
             forward_iterator_tag>; })
   return forward_iterator_tag{};
 else
   return input_iterator_tag{};
      }

    public:
      using iterator_concept = __conditional_t<forward_iterator<_It>,
            forward_iterator_tag,
            input_iterator_tag>;
      using iterator_category = decltype(_S_iter_cat());
      using value_type = iter_value_t<_It>;
      using difference_type = iter_difference_t<_It>;
      using pointer = typename __ptr<_It>::type;
      using reference = iter_reference_t<_It>;
    };




  namespace __detail
  {
    template<typename _It>
      struct __counted_iter_value_type
      { };

    template<indirectly_readable _It>
      struct __counted_iter_value_type<_It>
      { using value_type = iter_value_t<_It>; };

    template<typename _It>
      struct __counted_iter_concept
      { };

    template<typename _It>
      requires requires { typename _It::iterator_concept; }
      struct __counted_iter_concept<_It>
      { using iterator_concept = typename _It::iterator_concept; };

    template<typename _It>
      struct __counted_iter_cat
      { };

    template<typename _It>
      requires requires { typename _It::iterator_category; }
      struct __counted_iter_cat<_It>
      { using iterator_category = typename _It::iterator_category; };
  }



  template<input_or_output_iterator _It>
    class counted_iterator
      : public __detail::__counted_iter_value_type<_It>,
 public __detail::__counted_iter_concept<_It>,
 public __detail::__counted_iter_cat<_It>
    {
    public:
      using iterator_type = _It;

      using difference_type = iter_difference_t<_It>;



      constexpr counted_iterator() requires default_initializable<_It> = default;

      constexpr
      counted_iterator(_It __i, iter_difference_t<_It> __n)
      : _M_current(std::move(__i)), _M_length(__n)
      { do { if (__builtin_expect(!bool(__n >= 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2376, __PRETTY_FUNCTION__, "__n >= 0"); } while (false); }

      template<typename _It2>
 requires convertible_to<const _It2&, _It>
 constexpr
 counted_iterator(const counted_iterator<_It2>& __x)
 : _M_current(__x._M_current), _M_length(__x._M_length)
 { }

      template<typename _It2>
 requires assignable_from<_It&, const _It2&>
 constexpr counted_iterator&
 operator=(const counted_iterator<_It2>& __x)
 {
   _M_current = __x._M_current;
   _M_length = __x._M_length;
   return *this;
 }

      [[nodiscard]]
      constexpr const _It&
      base() const & noexcept
      { return _M_current; }

      [[nodiscard]]
      constexpr _It
      base() &&
      noexcept(is_nothrow_move_constructible_v<_It>)
      { return std::move(_M_current); }

      [[nodiscard]]
      constexpr iter_difference_t<_It>
      count() const noexcept { return _M_length; }

      [[nodiscard]]
      constexpr decltype(auto)
      operator*()
      noexcept(noexcept(*_M_current))
      {
 do { if (__builtin_expect(!bool(_M_length > 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2415, __PRETTY_FUNCTION__, "_M_length > 0"); } while (false);
 return *_M_current;
      }

      [[nodiscard]]
      constexpr decltype(auto)
      operator*() const
      noexcept(noexcept(*_M_current))
      requires __detail::__dereferenceable<const _It>
      {
 do { if (__builtin_expect(!bool(_M_length > 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2425, __PRETTY_FUNCTION__, "_M_length > 0"); } while (false);
 return *_M_current;
      }

      [[nodiscard]]
      constexpr auto
      operator->() const noexcept
      requires contiguous_iterator<_It>
      { return std::to_address(_M_current); }

      constexpr counted_iterator&
      operator++()
      {
 do { if (__builtin_expect(!bool(_M_length > 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2438, __PRETTY_FUNCTION__, "_M_length > 0"); } while (false);
 ++_M_current;
 --_M_length;
 return *this;
      }

      constexpr decltype(auto)
      operator++(int)
      {
 do { if (__builtin_expect(!bool(_M_length > 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2447, __PRETTY_FUNCTION__, "_M_length > 0"); } while (false);
 --_M_length;
 try
   {
     return _M_current++;
   } catch(...) {
     ++_M_length;
     throw;
   }
      }

      constexpr counted_iterator
      operator++(int) requires forward_iterator<_It>
      {
 auto __tmp = *this;
 ++*this;
 return __tmp;
      }

      constexpr counted_iterator&
      operator--() requires bidirectional_iterator<_It>
      {
 --_M_current;
 ++_M_length;
 return *this;
      }

      constexpr counted_iterator
      operator--(int) requires bidirectional_iterator<_It>
      {
 auto __tmp = *this;
 --*this;
 return __tmp;
      }

      [[nodiscard]]
      constexpr counted_iterator
      operator+(iter_difference_t<_It> __n) const
 requires random_access_iterator<_It>
      { return counted_iterator(_M_current + __n, _M_length - __n); }

      [[nodiscard]]
      friend constexpr counted_iterator
      operator+(iter_difference_t<_It> __n, const counted_iterator& __x)
      requires random_access_iterator<_It>
      { return __x + __n; }

      constexpr counted_iterator&
      operator+=(iter_difference_t<_It> __n)
      requires random_access_iterator<_It>
      {
 do { if (__builtin_expect(!bool(__n <= _M_length), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2498, __PRETTY_FUNCTION__, "__n <= _M_length"); } while (false);
 _M_current += __n;
 _M_length -= __n;
 return *this;
      }

      [[nodiscard]]
      constexpr counted_iterator
      operator-(iter_difference_t<_It> __n) const
      requires random_access_iterator<_It>
      { return counted_iterator(_M_current - __n, _M_length + __n); }

      template<common_with<_It> _It2>
 [[nodiscard]]
 friend constexpr iter_difference_t<_It2>
 operator-(const counted_iterator& __x,
    const counted_iterator<_It2>& __y)
 { return __y._M_length - __x._M_length; }

      [[nodiscard]]
      friend constexpr iter_difference_t<_It>
      operator-(const counted_iterator& __x, default_sentinel_t)
      { return -__x._M_length; }

      [[nodiscard]]
      friend constexpr iter_difference_t<_It>
      operator-(default_sentinel_t, const counted_iterator& __y)
      { return __y._M_length; }

      constexpr counted_iterator&
      operator-=(iter_difference_t<_It> __n)
      requires random_access_iterator<_It>
      {
 do { if (__builtin_expect(!bool(-__n <= _M_length), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2531, __PRETTY_FUNCTION__, "-__n <= _M_length"); } while (false);
 _M_current -= __n;
 _M_length += __n;
 return *this;
      }

      [[nodiscard]]
      constexpr decltype(auto)
      operator[](iter_difference_t<_It> __n) const
      noexcept(noexcept(_M_current[__n]))
      requires random_access_iterator<_It>
      {
 do { if (__builtin_expect(!bool(__n < _M_length), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2543, __PRETTY_FUNCTION__, "__n < _M_length"); } while (false);
 return _M_current[__n];
      }

      template<common_with<_It> _It2>
 [[nodiscard]]
 friend constexpr bool
 operator==(const counted_iterator& __x,
     const counted_iterator<_It2>& __y)
 { return __x._M_length == __y._M_length; }

      [[nodiscard]]
      friend constexpr bool
      operator==(const counted_iterator& __x, default_sentinel_t)
      { return __x._M_length == 0; }

      template<common_with<_It> _It2>
 [[nodiscard]]
 friend constexpr strong_ordering
 operator<=>(const counted_iterator& __x,
      const counted_iterator<_It2>& __y)
 { return __y._M_length <=> __x._M_length; }

      [[nodiscard]]
      friend constexpr iter_rvalue_reference_t<_It>
      iter_move(const counted_iterator& __i)
      noexcept(noexcept(ranges::iter_move(__i._M_current)))
      requires input_iterator<_It>
      {
 do { if (__builtin_expect(!bool(__i._M_length > 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2572, __PRETTY_FUNCTION__, "__i._M_length > 0"); } while (false);
 return ranges::iter_move(__i._M_current);
      }

      template<indirectly_swappable<_It> _It2>
 friend constexpr void
 iter_swap(const counted_iterator& __x,
    const counted_iterator<_It2>& __y)
 noexcept(noexcept(ranges::iter_swap(__x._M_current, __y._M_current)))
 {
   do { if (__builtin_expect(!bool(__x._M_length > 0 && __y._M_length > 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h", 2582, __PRETTY_FUNCTION__, "__x._M_length > 0 && __y._M_length > 0"); } while (false);
   ranges::iter_swap(__x._M_current, __y._M_current);
 }

    private:
      template<input_or_output_iterator _It2> friend class counted_iterator;

      _It _M_current = _It();
      iter_difference_t<_It> _M_length = 0;
    };

  template<input_iterator _It>
    requires same_as<__detail::__iter_traits<_It>, iterator_traits<_It>>
    struct iterator_traits<counted_iterator<_It>> : iterator_traits<_It>
    {
      using pointer = __conditional_t<contiguous_iterator<_It>,
          add_pointer_t<iter_reference_t<_It>>,
          void>;
    };
# 2980 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3

}

namespace __gnu_debug
{
  template<typename _Iterator, typename _Sequence, typename _Category>
    class _Safe_iterator;
}

namespace std
{





  template<typename _Iterator, typename _Container>
    [[__nodiscard__]] __attribute__((__always_inline__))
    constexpr
    inline _Iterator
    __niter_base(__gnu_cxx::__normal_iterator<_Iterator, _Container> __it)
    noexcept(std::is_nothrow_copy_constructible<_Iterator>::value)
    { return __it.base(); }


  template<typename _Iterator>
    [[__nodiscard__]] __attribute__((__always_inline__))
    constexpr
    inline _Iterator
    __niter_base(_Iterator __it)
    noexcept(std::is_nothrow_copy_constructible<_Iterator>::value)
    { return __it; }
# 3027 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_iterator.h" 3
  template<typename _Ite, typename _Seq>
    constexpr
    decltype(std::__niter_base(std::declval<_Ite>()))
    __niter_base(const ::__gnu_debug::_Safe_iterator<_Ite, _Seq,
   std::random_access_iterator_tag>&)
    noexcept(std::is_nothrow_copy_constructible<_Ite>::value);



  template<typename _Iterator>
    constexpr
    inline auto
    __niter_base(reverse_iterator<_Iterator> __it)
    -> decltype(__make_reverse_iterator(__niter_base(__it.base())))
    { return __make_reverse_iterator(__niter_base(__it.base())); }

  template<typename _Iterator>
    constexpr
    inline auto
    __niter_base(move_iterator<_Iterator> __it)
    -> decltype(make_move_iterator(__niter_base(__it.base())))
    { return make_move_iterator(__niter_base(__it.base())); }

  template<typename _Iterator>
    constexpr
    inline auto
    __miter_base(reverse_iterator<_Iterator> __it)
    -> decltype(__make_reverse_iterator(__miter_base(__it.base())))
    { return __make_reverse_iterator(__miter_base(__it.base())); }

  template<typename _Iterator>
    constexpr
    inline auto
    __miter_base(move_iterator<_Iterator> __it)
    -> decltype(__miter_base(__it.base()))
    { return __miter_base(__it.base()); }






  template<typename _From, typename _To>
    [[__nodiscard__]]
    constexpr
    inline _From
    __niter_wrap(_From __from, _To __res)
    { return __from + (std::__niter_base(__res) - std::__niter_base(__from)); }


  template<typename _Iterator>
    [[__nodiscard__]] __attribute__((__always_inline__))
    constexpr
    inline _Iterator
    __niter_wrap(const _Iterator&, _Iterator __res)
    { return __res; }






  template<typename _InputIterator>
    using __iter_key_t = remove_const_t<



      typename iterator_traits<_InputIterator>::value_type::first_type>;


  template<typename _InputIterator>
    using __iter_val_t



      = typename iterator_traits<_InputIterator>::value_type::second_type;


  template<typename _T1, typename _T2>
    struct pair;

  template<typename _InputIterator>
    using __iter_to_alloc_t
      = pair<const __iter_key_t<_InputIterator>, __iter_val_t<_InputIterator>>;



}
# 68 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 2 3

# 1 "C:/msys64/mingw64/include/c++/15.2.0/debug/debug.h" 1 3
# 48 "C:/msys64/mingw64/include/c++/15.2.0/debug/debug.h" 3
namespace std
{
  namespace __debug { }
}




namespace __gnu_debug
{
  using namespace std::__debug;

  template<typename _Ite, typename _Seq, typename _Cat>
    struct _Safe_iterator;
}
# 70 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 2 3

# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/predefined_ops.h" 1 3
# 35 "C:/msys64/mingw64/include/c++/15.2.0/bits/predefined_ops.h" 3
namespace __gnu_cxx
{
namespace __ops
{
  struct _Iter_less_iter
  {
    template<typename _Iterator1, typename _Iterator2>
      constexpr
      bool
      operator()(_Iterator1 __it1, _Iterator2 __it2) const
      { return *__it1 < *__it2; }
  };

  constexpr
  inline _Iter_less_iter
  __iter_less_iter()
  { return _Iter_less_iter(); }

  struct _Iter_less_val
  {

    constexpr _Iter_less_val() = default;




    constexpr
    explicit
    _Iter_less_val(_Iter_less_iter) { }

    template<typename _Iterator, typename _Value>
      constexpr
      bool
      operator()(_Iterator __it, _Value& __val) const
      { return *__it < __val; }
  };

  constexpr
  inline _Iter_less_val
  __iter_less_val()
  { return _Iter_less_val(); }

  constexpr
  inline _Iter_less_val
  __iter_comp_val(_Iter_less_iter)
  { return _Iter_less_val(); }

  struct _Val_less_iter
  {

    constexpr _Val_less_iter() = default;




    constexpr
    explicit
    _Val_less_iter(_Iter_less_iter) { }

    template<typename _Value, typename _Iterator>
      constexpr
      bool
      operator()(_Value& __val, _Iterator __it) const
      { return __val < *__it; }
  };

  constexpr
  inline _Val_less_iter
  __val_less_iter()
  { return _Val_less_iter(); }

  constexpr
  inline _Val_less_iter
  __val_comp_iter(_Iter_less_iter)
  { return _Val_less_iter(); }

  struct _Iter_equal_to_iter
  {
    template<typename _Iterator1, typename _Iterator2>
      constexpr
      bool
      operator()(_Iterator1 __it1, _Iterator2 __it2) const
      { return *__it1 == *__it2; }
  };

  constexpr
  inline _Iter_equal_to_iter
  __iter_equal_to_iter()
  { return _Iter_equal_to_iter(); }

  struct _Iter_equal_to_val
  {
    template<typename _Iterator, typename _Value>
      constexpr
      bool
      operator()(_Iterator __it, _Value& __val) const
      { return *__it == __val; }
  };

  constexpr
  inline _Iter_equal_to_val
  __iter_equal_to_val()
  { return _Iter_equal_to_val(); }

  constexpr
  inline _Iter_equal_to_val
  __iter_comp_val(_Iter_equal_to_iter)
  { return _Iter_equal_to_val(); }

  template<typename _Compare>
    struct _Iter_comp_iter
    {
      _Compare _M_comp;

      explicit constexpr
      _Iter_comp_iter(_Compare __comp)
 : _M_comp(std::move(__comp))
      { }

      template<typename _Iterator1, typename _Iterator2>
        constexpr
        bool
        operator()(_Iterator1 __it1, _Iterator2 __it2)
        { return bool(_M_comp(*__it1, *__it2)); }
    };

  template<typename _Compare>
    constexpr
    inline _Iter_comp_iter<_Compare>
    __iter_comp_iter(_Compare __comp)
    { return _Iter_comp_iter<_Compare>(std::move(__comp)); }

  template<typename _Compare>
    struct _Iter_comp_val
    {
      _Compare _M_comp;

      constexpr
      explicit
      _Iter_comp_val(_Compare __comp)
 : _M_comp(std::move(__comp))
      { }

      constexpr
      explicit
      _Iter_comp_val(const _Iter_comp_iter<_Compare>& __comp)
 : _M_comp(__comp._M_comp)
      { }


      constexpr
      explicit
      _Iter_comp_val(_Iter_comp_iter<_Compare>&& __comp)
 : _M_comp(std::move(__comp._M_comp))
      { }


      template<typename _Iterator, typename _Value>
 constexpr
 bool
 operator()(_Iterator __it, _Value& __val)
 { return bool(_M_comp(*__it, __val)); }
    };

  template<typename _Compare>
    constexpr
    inline _Iter_comp_val<_Compare>
    __iter_comp_val(_Compare __comp)
    { return _Iter_comp_val<_Compare>(std::move(__comp)); }

  template<typename _Compare>
    constexpr
    inline _Iter_comp_val<_Compare>
    __iter_comp_val(_Iter_comp_iter<_Compare> __comp)
    { return _Iter_comp_val<_Compare>(std::move(__comp)); }

  template<typename _Compare>
    struct _Val_comp_iter
    {
      _Compare _M_comp;

      constexpr
      explicit
      _Val_comp_iter(_Compare __comp)
 : _M_comp(std::move(__comp))
      { }

      constexpr
      explicit
      _Val_comp_iter(const _Iter_comp_iter<_Compare>& __comp)
 : _M_comp(__comp._M_comp)
      { }


      constexpr
      explicit
      _Val_comp_iter(_Iter_comp_iter<_Compare>&& __comp)
 : _M_comp(std::move(__comp._M_comp))
      { }


      template<typename _Value, typename _Iterator>
 constexpr
 bool
 operator()(_Value& __val, _Iterator __it)
 { return bool(_M_comp(__val, *__it)); }
    };

  template<typename _Compare>
    constexpr
    inline _Val_comp_iter<_Compare>
    __val_comp_iter(_Compare __comp)
    { return _Val_comp_iter<_Compare>(std::move(__comp)); }

  template<typename _Compare>
    constexpr
    inline _Val_comp_iter<_Compare>
    __val_comp_iter(_Iter_comp_iter<_Compare> __comp)
    { return _Val_comp_iter<_Compare>(std::move(__comp)); }

  template<typename _Value>
    struct _Iter_equals_val
    {
      _Value& _M_value;

      constexpr
      explicit
      _Iter_equals_val(_Value& __value)
 : _M_value(__value)
      { }

      template<typename _Iterator>
 constexpr
 bool
 operator()(_Iterator __it)
 { return *__it == _M_value; }
    };

  template<typename _Value>
    constexpr
    inline _Iter_equals_val<_Value>
    __iter_equals_val(_Value& __val)
    { return _Iter_equals_val<_Value>(__val); }

  template<typename _Iterator1>
    struct _Iter_equals_iter
    {
      _Iterator1 _M_it1;

      constexpr
      explicit
      _Iter_equals_iter(_Iterator1 __it1)
 : _M_it1(__it1)
      { }

      template<typename _Iterator2>
 constexpr
 bool
 operator()(_Iterator2 __it2)
 { return *__it2 == *_M_it1; }
    };

  template<typename _Iterator>
    constexpr
    inline _Iter_equals_iter<_Iterator>
    __iter_comp_iter(_Iter_equal_to_iter, _Iterator __it)
    { return _Iter_equals_iter<_Iterator>(__it); }

  template<typename _Predicate>
    struct _Iter_pred
    {
      _Predicate _M_pred;

      constexpr
      explicit
      _Iter_pred(_Predicate __pred)
 : _M_pred(std::move(__pred))
      { }

      template<typename _Iterator>
 constexpr
 bool
 operator()(_Iterator __it)
 { return bool(_M_pred(*__it)); }
    };

  template<typename _Predicate>
    constexpr
    inline _Iter_pred<_Predicate>
    __pred_iter(_Predicate __pred)
    { return _Iter_pred<_Predicate>(std::move(__pred)); }

  template<typename _Compare, typename _Value>
    struct _Iter_comp_to_val
    {
      _Compare _M_comp;
      _Value& _M_value;

      constexpr
      _Iter_comp_to_val(_Compare __comp, _Value& __value)
 : _M_comp(std::move(__comp)), _M_value(__value)
      { }

      template<typename _Iterator>
 constexpr
 bool
 operator()(_Iterator __it)
 { return bool(_M_comp(*__it, _M_value)); }
    };

  template<typename _Compare, typename _Value>
    _Iter_comp_to_val<_Compare, _Value>
    constexpr
    __iter_comp_val(_Compare __comp, _Value &__val)
    {
      return _Iter_comp_to_val<_Compare, _Value>(std::move(__comp), __val);
    }

  template<typename _Compare, typename _Iterator1>
    struct _Iter_comp_to_iter
    {
      _Compare _M_comp;
      _Iterator1 _M_it1;

      constexpr
      _Iter_comp_to_iter(_Compare __comp, _Iterator1 __it1)
 : _M_comp(std::move(__comp)), _M_it1(__it1)
      { }

      template<typename _Iterator2>
 constexpr
 bool
 operator()(_Iterator2 __it2)
 { return bool(_M_comp(*__it2, *_M_it1)); }
    };

  template<typename _Compare, typename _Iterator>
    constexpr
    inline _Iter_comp_to_iter<_Compare, _Iterator>
    __iter_comp_iter(_Iter_comp_iter<_Compare> __comp, _Iterator __it)
    {
      return _Iter_comp_to_iter<_Compare, _Iterator>(
   std::move(__comp._M_comp), __it);
    }

  template<typename _Predicate>
    struct _Iter_negate
    {
      _Predicate _M_pred;

      constexpr
      explicit
      _Iter_negate(_Predicate __pred)
 : _M_pred(std::move(__pred))
      { }

      template<typename _Iterator>
 constexpr
 bool
 operator()(_Iterator __it)
 { return !bool(_M_pred(*__it)); }
    };

  template<typename _Predicate>
    constexpr
    inline _Iter_negate<_Predicate>
    __negate(_Iter_pred<_Predicate> __pred)
    { return _Iter_negate<_Predicate>(std::move(__pred._M_pred)); }

}
}
# 72 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 2 3
# 83 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
namespace std
{






  template<typename _Tp, typename _Up>
    constexpr
    inline int
    __memcmp(const _Tp* __first1, const _Up* __first2, size_t __num)
    {

      static_assert(sizeof(_Tp) == sizeof(_Up), "can be compared with memcmp");


      if (std::is_constant_evaluated())
 {
   for(; __num > 0; ++__first1, ++__first2, --__num)
     if (*__first1 != *__first2)
       return *__first1 < *__first2 ? -1 : 1;
   return 0;
 }
      else

 return __builtin_memcmp(__first1, __first2, sizeof(_Tp) * __num);
    }
# 153 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _ForwardIterator1, typename _ForwardIterator2>
    constexpr
    inline void
    iter_swap(_ForwardIterator1 __a, _ForwardIterator2 __b)
    {

     

     
# 186 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
      swap(*__a, *__b);

    }
# 202 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _ForwardIterator1, typename _ForwardIterator2>
    constexpr
    _ForwardIterator2
    swap_ranges(_ForwardIterator1 __first1, _ForwardIterator1 __last1,
  _ForwardIterator2 __first2)
    {

     

     

      ;

      for (; __first1 != __last1; ++__first1, (void)++__first2)
 std::iter_swap(__first1, __first2);
      return __first2;
    }
# 231 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _Tp>
    [[__nodiscard__]] constexpr
    inline const _Tp&
    min(const _Tp& __a, const _Tp& __b)
    {

     

      if (__b < __a)
 return __b;
      return __a;
    }
# 255 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _Tp>
    [[__nodiscard__]] constexpr
    inline const _Tp&
    max(const _Tp& __a, const _Tp& __b)
    {

     

      if (__a < __b)
 return __b;
      return __a;
    }
# 279 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _Tp, typename _Compare>
    [[__nodiscard__]] constexpr
    inline const _Tp&
    min(const _Tp& __a, const _Tp& __b, _Compare __comp)
    {

      if (__comp(__b, __a))
 return __b;
      return __a;
    }
# 301 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _Tp, typename _Compare>
    [[__nodiscard__]] constexpr
    inline const _Tp&
    max(const _Tp& __a, const _Tp& __b, _Compare __comp)
    {

      if (__comp(__a, __b))
 return __b;
      return __a;
    }



  template<typename _Tp, typename _Ref, typename _Ptr>
    struct _Deque_iterator;

  struct _Bit_iterator;






  template<typename _CharT>
    struct char_traits;

  template<typename _CharT, typename _Traits>
    class istreambuf_iterator;

  template<typename _CharT, typename _Traits>
    class ostreambuf_iterator;

  template<bool _IsMove, typename _CharT>
    typename __gnu_cxx::__enable_if<__is_char<_CharT>::__value,
      ostreambuf_iterator<_CharT, char_traits<_CharT> > >::__type
    __copy_move_a2(_CharT*, _CharT*,
     ostreambuf_iterator<_CharT, char_traits<_CharT> >);

  template<bool _IsMove, typename _CharT>
    typename __gnu_cxx::__enable_if<__is_char<_CharT>::__value,
      ostreambuf_iterator<_CharT, char_traits<_CharT> > >::__type
    __copy_move_a2(const _CharT*, const _CharT*,
     ostreambuf_iterator<_CharT, char_traits<_CharT> >);

  template<bool _IsMove, typename _CharT>
    typename __gnu_cxx::__enable_if<__is_char<_CharT>::__value,
        _CharT*>::__type
    __copy_move_a2(istreambuf_iterator<_CharT, char_traits<_CharT> >,
     istreambuf_iterator<_CharT, char_traits<_CharT> >, _CharT*);

  template<bool _IsMove, typename _CharT>
    typename __gnu_cxx::__enable_if<
      __is_char<_CharT>::__value,
      std::_Deque_iterator<_CharT, _CharT&, _CharT*> >::__type
    __copy_move_a2(
 istreambuf_iterator<_CharT, char_traits<_CharT> >,
 istreambuf_iterator<_CharT, char_traits<_CharT> >,
 std::_Deque_iterator<_CharT, _CharT&, _CharT*>);



  template<typename _OutIter, typename _InIter, typename _Sent = _InIter>
    concept __memcpyable_iterators
      = contiguous_iterator<_OutIter> && contiguous_iterator<_InIter>
   && sized_sentinel_for<_Sent, _InIter>
   && requires (_OutIter __o, _InIter __i) {
     requires !!__memcpyable<decltype(std::to_address(__o)),
        decltype(std::to_address(__i))>::__value;
   };
# 395 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wc++17-extensions"
  template<bool _IsMove, typename _OutIter, typename _InIter>
    __attribute__((__always_inline__)) constexpr
    inline void
    __assign_one(_OutIter& __out, _InIter& __in)
    {

      if constexpr (_IsMove)
 *__out = std::move(*__in);
      else

 *__out = *__in;
    }

  template<bool _IsMove, typename _InIter, typename _Sent, typename _OutIter>
    constexpr
    inline _OutIter
    __copy_move_a2(_InIter __first, _Sent __last, _OutIter __result)
    {
      typedef __decltype(*__first) _InRef;
      typedef __decltype(*__result) _OutRef;
      if constexpr (!__is_trivially_assignable(_OutRef, _InRef))
 { }
      else if (std::__is_constant_evaluated())
 { }
      else if constexpr (__memcpyable<_OutIter, _InIter>::__value)
 {
   ptrdiff_t __n = std::distance(__first, __last);
   if (__builtin_expect(__n > 1, true))
     {
       __builtin_memmove(__result,
    __first,
    __n * sizeof(*__first));
       __result += __n;
     }
   else if (__n == 1)
     {
       std::__assign_one<_IsMove>(__result, __first);
       ++__result;
     }
   return __result;
 }

      else if constexpr (__memcpyable_iterators<_OutIter, _InIter, _Sent>)
 {
   if (auto __n = __last - __first; __n > 1) [[likely]]
     {
       void* __dest = std::to_address(__result);
       const void* __src = std::to_address(__first);
       size_t __nbytes = __n * sizeof(iter_value_t<_InIter>);


       (void) std::to_address(__result += __n);
       (void) std::to_address(__first += __n);
       __builtin_memmove(__dest, __src, __nbytes);
     }
   else if (__n == 1)
     {
       std::__assign_one<_IsMove>(__result, __first);
       ++__result;
     }
   return __result;
 }


      for (; __first != __last; ++__result, (void)++__first)
 std::__assign_one<_IsMove>(__result, __first);
      return __result;
    }
#pragma GCC diagnostic pop

  template<bool _IsMove,
    typename _Tp, typename _Ref, typename _Ptr, typename _OI>
    _OI
    __copy_move_a1(std::_Deque_iterator<_Tp, _Ref, _Ptr>,
     std::_Deque_iterator<_Tp, _Ref, _Ptr>,
     _OI);

  template<bool _IsMove,
    typename _ITp, typename _IRef, typename _IPtr, typename _OTp>
    std::_Deque_iterator<_OTp, _OTp&, _OTp*>
    __copy_move_a1(std::_Deque_iterator<_ITp, _IRef, _IPtr>,
     std::_Deque_iterator<_ITp, _IRef, _IPtr>,
     std::_Deque_iterator<_OTp, _OTp&, _OTp*>);

  template<bool _IsMove, typename _II, typename _Tp>
    typename __gnu_cxx::__enable_if<
      __is_random_access_iter<_II>::__value,
      std::_Deque_iterator<_Tp, _Tp&, _Tp*> >::__type
    __copy_move_a1(_II, _II, std::_Deque_iterator<_Tp, _Tp&, _Tp*>);

  template<bool _IsMove, typename _II, typename _OI>
    __attribute__((__always_inline__))
    constexpr
    inline _OI
    __copy_move_a1(_II __first, _II __last, _OI __result)
    { return std::__copy_move_a2<_IsMove>(__first, __last, __result); }

  template<bool _IsMove, typename _II, typename _OI>
    __attribute__((__always_inline__))
    constexpr
    inline _OI
    __copy_move_a(_II __first, _II __last, _OI __result)
    {
      return std::__niter_wrap(__result,
  std::__copy_move_a1<_IsMove>(std::__niter_base(__first),
          std::__niter_base(__last),
          std::__niter_base(__result)));
    }

  template<bool _IsMove,
    typename _Ite, typename _Seq, typename _Cat, typename _OI>
    constexpr
    _OI
    __copy_move_a(const ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>&,
    const ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>&,
    _OI);

  template<bool _IsMove,
    typename _II, typename _Ite, typename _Seq, typename _Cat>
    constexpr
    __gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>
    __copy_move_a(_II, _II,
    const ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>&);

  template<bool _IsMove,
    typename _IIte, typename _ISeq, typename _ICat,
    typename _OIte, typename _OSeq, typename _OCat>
    constexpr
    ::__gnu_debug::_Safe_iterator<_OIte, _OSeq, _OCat>
    __copy_move_a(const ::__gnu_debug::_Safe_iterator<_IIte, _ISeq, _ICat>&,
    const ::__gnu_debug::_Safe_iterator<_IIte, _ISeq, _ICat>&,
    const ::__gnu_debug::_Safe_iterator<_OIte, _OSeq, _OCat>&);

#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wc++17-extensions"
  template<typename _InputIterator, typename _Size, typename _OutputIterator>
    constexpr
    _OutputIterator
    __copy_n_a(_InputIterator __first, _Size __n, _OutputIterator __result,
        bool)
    {
      typedef __decltype(*__first) _InRef;
      typedef __decltype(*__result) _OutRef;
      if constexpr (!__is_trivially_assignable(_OutRef, _InRef))
 { }

      else if (std::is_constant_evaluated())
 { }

      else if constexpr (__memcpyable<_OutputIterator,
            _InputIterator>::__value)
 {
   if (__builtin_expect(__n > 1, true))
     {
       __builtin_memmove(__result,
    __first,
    __n * sizeof(*__first));
       __result += __n;
     }
   else if (__n == 1)
     *__result++ = *__first;
   return __result;
 }

      else if constexpr (__memcpyable_iterators<_OutputIterator,
      _InputIterator>)
 {
   if (__n > 1) [[likely]]
     {
       void* __dest = std::to_address(__result);
       const void* __src = std::to_address(__first);
       size_t __nbytes = __n * sizeof(iter_value_t<_InputIterator>);


       (void) std::to_address(__result += __n);
       (void) std::to_address(__first += __n);
       __builtin_memmove(__dest, __src, __nbytes);
     }
   else if (__n == 1)
     *__result++ = *__first;
   return __result;
 }


      if (__n > 0)
 {
   while (true)
     {
       *__result = *__first;
       ++__result;
       if (--__n > 0)
  ++__first;
       else
  break;
     }
 }
      return __result;
    }
#pragma GCC diagnostic pop


  template<typename _CharT, typename _Size>
    typename __gnu_cxx::__enable_if<
      __is_char<_CharT>::__value, _CharT*>::__type
    __copy_n_a(istreambuf_iterator<_CharT, char_traits<_CharT> >,
        _Size, _CharT*, bool);

  template<typename _CharT, typename _Size>
    typename __gnu_cxx::__enable_if<
      __is_char<_CharT>::__value,
      std::_Deque_iterator<_CharT, _CharT&, _CharT*> >::__type
    __copy_n_a(istreambuf_iterator<_CharT, char_traits<_CharT> >, _Size,
        std::_Deque_iterator<_CharT, _CharT&, _CharT*>,
        bool);
# 630 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _II, typename _OI>
    constexpr
    inline _OI
    copy(_II __first, _II __last, _OI __result)
    {

     
     

      ;

      return std::__copy_move_a<__is_move_iterator<_II>::__value>
      (std::__miter_base(__first), std::__miter_base(__last), __result);
    }
# 663 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _II, typename _OI>
    constexpr
    inline _OI
    move(_II __first, _II __last, _OI __result)
    {

     
     

      ;

      return std::__copy_move_a<true>(std::__miter_base(__first),
          std::__miter_base(__last), __result);
    }






#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wc++17-extensions"
  template<bool _IsMove, typename _BI1, typename _BI2>
    constexpr
    inline _BI2
    __copy_move_backward_a2(_BI1 __first, _BI1 __last, _BI2 __result)
    {
      typedef __decltype(*__first) _InRef;
      typedef __decltype(*__result) _OutRef;
      if constexpr (!__is_trivially_assignable(_OutRef, _InRef))
       { }

      else if (std::is_constant_evaluated())
       { }

      else if constexpr (__memcpyable<_BI2, _BI1>::__value)
 {
   ptrdiff_t __n = std::distance(__first, __last);
   std::advance(__result, -__n);
   if (__builtin_expect(__n > 1, true))
     {
       __builtin_memmove(__result,
    __first,
    __n * sizeof(*__first));
     }
   else if (__n == 1)
     std::__assign_one<_IsMove>(__result, __first);
   return __result;
 }

      else if constexpr (__memcpyable_iterators<_BI2, _BI1>)
 {
   if (auto __n = __last - __first; __n > 1) [[likely]]
     {
       const void* __src = std::to_address(__first);


       (void) std::to_address(__result -= __n);
       (void) std::to_address(__first += __n);
       void* __dest = std::to_address(__result);
       size_t __nbytes = __n * sizeof(iter_value_t<_BI1>);
       __builtin_memmove(__dest, __src, __nbytes);
     }
   else if (__n == 1)
     {
       --__result;
       std::__assign_one<_IsMove>(__result, __first);
     }
   return __result;
 }


      while (__first != __last)
 {
   --__last;
   --__result;
   std::__assign_one<_IsMove>(__result, __last);
 }
      return __result;
    }
#pragma GCC diagnostic pop




  template<bool _IsMove, typename _BI1, typename _BI2>
    __attribute__((__always_inline__))
    constexpr
    inline _BI2
    __copy_move_backward_a1(_BI1 __first, _BI1 __last, _BI2 __result)
    { return std::__copy_move_backward_a2<_IsMove>(__first, __last, __result); }

  template<bool _IsMove,
    typename _Tp, typename _Ref, typename _Ptr, typename _OI>
    _OI
    __copy_move_backward_a1(std::_Deque_iterator<_Tp, _Ref, _Ptr>,
       std::_Deque_iterator<_Tp, _Ref, _Ptr>,
       _OI);

  template<bool _IsMove,
    typename _ITp, typename _IRef, typename _IPtr, typename _OTp>
    std::_Deque_iterator<_OTp, _OTp&, _OTp*>
    __copy_move_backward_a1(
   std::_Deque_iterator<_ITp, _IRef, _IPtr>,
   std::_Deque_iterator<_ITp, _IRef, _IPtr>,
   std::_Deque_iterator<_OTp, _OTp&, _OTp*>);

  template<bool _IsMove, typename _II, typename _Tp>
    typename __gnu_cxx::__enable_if<
      __is_random_access_iter<_II>::__value,
      std::_Deque_iterator<_Tp, _Tp&, _Tp*> >::__type
    __copy_move_backward_a1(_II, _II,
       std::_Deque_iterator<_Tp, _Tp&, _Tp*>);

  template<bool _IsMove, typename _II, typename _OI>
    __attribute__((__always_inline__))
    constexpr
    inline _OI
    __copy_move_backward_a(_II __first, _II __last, _OI __result)
    {
      return std::__niter_wrap(__result,
  std::__copy_move_backward_a1<_IsMove>
    (std::__niter_base(__first), std::__niter_base(__last),
     std::__niter_base(__result)));
    }

  template<bool _IsMove,
    typename _Ite, typename _Seq, typename _Cat, typename _OI>
    constexpr
    _OI
    __copy_move_backward_a(
  const ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>&,
  const ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>&,
  _OI);

  template<bool _IsMove,
    typename _II, typename _Ite, typename _Seq, typename _Cat>
    constexpr
    __gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>
    __copy_move_backward_a(_II, _II,
  const ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>&);

  template<bool _IsMove,
    typename _IIte, typename _ISeq, typename _ICat,
    typename _OIte, typename _OSeq, typename _OCat>
    constexpr
    ::__gnu_debug::_Safe_iterator<_OIte, _OSeq, _OCat>
    __copy_move_backward_a(
  const ::__gnu_debug::_Safe_iterator<_IIte, _ISeq, _ICat>&,
  const ::__gnu_debug::_Safe_iterator<_IIte, _ISeq, _ICat>&,
  const ::__gnu_debug::_Safe_iterator<_OIte, _OSeq, _OCat>&);
# 833 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _BI1, typename _BI2>
    __attribute__((__always_inline__))
    constexpr
    inline _BI2
    copy_backward(_BI1 __first, _BI1 __last, _BI2 __result)
    {

     
     
     

      ;

      return std::__copy_move_backward_a<__is_move_iterator<_BI1>::__value>
      (std::__miter_base(__first), std::__miter_base(__last), __result);
    }
# 869 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _BI1, typename _BI2>
    __attribute__((__always_inline__))
    constexpr
    inline _BI2
    move_backward(_BI1 __first, _BI1 __last, _BI2 __result)
    {

     
     
     

      ;

      return std::__copy_move_backward_a<true>(std::__miter_base(__first),
            std::__miter_base(__last),
            __result);
    }






#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wc++17-extensions"
  template<typename _ForwardIterator, typename _Tp>
    constexpr
    inline void
    __fill_a1(_ForwardIterator __first, _ForwardIterator __last,
       const _Tp& __value)
    {
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wlong-long"




      const bool __load_outside_loop =


     __is_trivially_constructible(_Tp, const _Tp&)
     && __is_trivially_assignable(__decltype(*__first), const _Tp&)




     && sizeof(_Tp) <= sizeof(long long);
#pragma GCC diagnostic pop



      typedef typename __gnu_cxx::__conditional_type<__load_outside_loop,
           const _Tp,
           const _Tp&>::__type _Up;
      _Up __val(__value);
      for (; __first != __last; ++__first)
 *__first = __val;
    }
#pragma GCC diagnostic pop


  template<typename _Up, typename _Tp>
    constexpr
    inline typename
    __gnu_cxx::__enable_if<__is_byte<_Up>::__value
        && (__are_same<_Up, _Tp>::__value
       || __memcpyable_integer<_Tp>::__width),
      void>::__type
    __fill_a1(_Up* __first, _Up* __last, const _Tp& __x)
    {


      const _Up __val = __x;

      if (std::is_constant_evaluated())
 {
   for (; __first != __last; ++__first)
     *__first = __val;
   return;
 }

      if (const size_t __len = __last - __first)
 __builtin_memset(__first, static_cast<unsigned char>(__val), __len);
    }

  template<typename _Ite, typename _Cont, typename _Tp>
    __attribute__((__always_inline__))
    constexpr
    inline void
    __fill_a1(::__gnu_cxx::__normal_iterator<_Ite, _Cont> __first,
       ::__gnu_cxx::__normal_iterator<_Ite, _Cont> __last,
       const _Tp& __value)
    { std::__fill_a1(__first.base(), __last.base(), __value); }

  template<typename _Tp, typename _VTp>
    void
    __fill_a1(const std::_Deque_iterator<_Tp, _Tp&, _Tp*>&,
       const std::_Deque_iterator<_Tp, _Tp&, _Tp*>&,
       const _VTp&);

  constexpr
  void
  __fill_a1(std::_Bit_iterator, std::_Bit_iterator,
     const bool&);

  template<typename _FIte, typename _Tp>
    __attribute__((__always_inline__))
    constexpr
    inline void
    __fill_a(_FIte __first, _FIte __last, const _Tp& __value)
    { std::__fill_a1(__first, __last, __value); }

  template<typename _Ite, typename _Seq, typename _Cat, typename _Tp>
    constexpr
    void
    __fill_a(const ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>&,
      const ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>&,
      const _Tp&);
# 1000 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _ForwardIterator, typename _Tp>
    __attribute__((__always_inline__))
    constexpr
    inline void
    fill(_ForwardIterator __first, _ForwardIterator __last, const _Tp& __value)
    {

     

      ;

      std::__fill_a(__first, __last, __value);
    }

#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wlong-long"

  inline constexpr int
  __size_to_integer(int __n) { return __n; }
  inline constexpr unsigned
  __size_to_integer(unsigned __n) { return __n; }
  inline constexpr long
  __size_to_integer(long __n) { return __n; }
  inline constexpr unsigned long
  __size_to_integer(unsigned long __n) { return __n; }
  inline constexpr long long
  __size_to_integer(long long __n) { return __n; }
  inline constexpr unsigned long long
  __size_to_integer(unsigned long long __n) { return __n; }


  __extension__ inline constexpr __int128
  __size_to_integer(__int128 __n) { return __n; }
  __extension__ inline constexpr unsigned __int128
  __size_to_integer(unsigned __int128 __n) { return __n; }
# 1055 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  inline constexpr long long
  __size_to_integer(float __n) { return (long long)__n; }
  inline constexpr long long
  __size_to_integer(double __n) { return (long long)__n; }
  inline constexpr long long
  __size_to_integer(long double __n) { return (long long)__n; }

  __extension__ inline constexpr long long
  __size_to_integer(__float128 __n) { return (long long)__n; }

#pragma GCC diagnostic pop

#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wc++17-extensions"
#pragma GCC diagnostic ignored "-Wlong-long"
  template<typename _OutputIterator, typename _Size, typename _Tp>
    constexpr
    inline _OutputIterator
    __fill_n_a1(_OutputIterator __first, _Size __n, const _Tp& __value)
    {

      const bool __load_outside_loop =


     __is_trivially_constructible(_Tp, const _Tp&)
     && __is_trivially_assignable(__decltype(*__first), const _Tp&)




     && sizeof(_Tp) <= sizeof(long long);



      typedef typename __gnu_cxx::__conditional_type<__load_outside_loop,
           const _Tp,
           const _Tp&>::__type _Up;
      _Up __val(__value);
      for (; __n > 0; --__n, (void) ++__first)
 *__first = __val;
      return __first;
    }
#pragma GCC diagnostic pop

  template<typename _Ite, typename _Seq, typename _Cat, typename _Size,
    typename _Tp>
    constexpr
    ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>
    __fill_n_a(const ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>& __first,
        _Size __n, const _Tp& __value,
        std::input_iterator_tag);

  template<typename _OutputIterator, typename _Size, typename _Tp>
    __attribute__((__always_inline__))
    constexpr
    inline _OutputIterator
    __fill_n_a(_OutputIterator __first, _Size __n, const _Tp& __value,
        std::output_iterator_tag)
    {

      static_assert(is_integral<_Size>{}, "fill_n must pass integral size");

      return __fill_n_a1(__first, __n, __value);
    }

  template<typename _OutputIterator, typename _Size, typename _Tp>
    __attribute__((__always_inline__))
    constexpr
    inline _OutputIterator
    __fill_n_a(_OutputIterator __first, _Size __n, const _Tp& __value,
        std::input_iterator_tag)
    {

      static_assert(is_integral<_Size>{}, "fill_n must pass integral size");

      return __fill_n_a1(__first, __n, __value);
    }

  template<typename _OutputIterator, typename _Size, typename _Tp>
    __attribute__((__always_inline__))
    constexpr
    inline _OutputIterator
    __fill_n_a(_OutputIterator __first, _Size __n, const _Tp& __value,
        std::random_access_iterator_tag)
    {

      static_assert(is_integral<_Size>{}, "fill_n must pass integral size");

      if (__n <= 0)
 return __first;

      ;

      std::__fill_a(__first, __first + __n, __value);
      return __first + __n;
    }
# 1169 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _OI, typename _Size, typename _Tp>
    __attribute__((__always_inline__))
    constexpr
    inline _OI
    fill_n(_OI __first, _Size __n, const _Tp& __value)
    {

     

      return std::__fill_n_a(__first, std::__size_to_integer(__n), __value,
          std::__iterator_category(__first));
    }

  template<bool _BoolType>
    struct __equal
    {
      template<typename _II1, typename _II2>
 constexpr
 static bool
 equal(_II1 __first1, _II1 __last1, _II2 __first2)
 {
   for (; __first1 != __last1; ++__first1, (void) ++__first2)
     if (!(*__first1 == *__first2))
       return false;
   return true;
 }
    };

  template<>
    struct __equal<true>
    {
      template<typename _Tp>
 constexpr
 static bool
 equal(const _Tp* __first1, const _Tp* __last1, const _Tp* __first2)
 {
   if (const size_t __len = (__last1 - __first1))
     return !std::__memcmp(__first1, __first2, __len);
   return true;
 }
    };

  template<typename _Tp, typename _Ref, typename _Ptr, typename _II>
    typename __gnu_cxx::__enable_if<
      __is_random_access_iter<_II>::__value, bool>::__type
    __equal_aux1(std::_Deque_iterator<_Tp, _Ref, _Ptr>,
   std::_Deque_iterator<_Tp, _Ref, _Ptr>,
   _II);

  template<typename _Tp1, typename _Ref1, typename _Ptr1,
    typename _Tp2, typename _Ref2, typename _Ptr2>
    bool
    __equal_aux1(std::_Deque_iterator<_Tp1, _Ref1, _Ptr1>,
   std::_Deque_iterator<_Tp1, _Ref1, _Ptr1>,
   std::_Deque_iterator<_Tp2, _Ref2, _Ptr2>);

  template<typename _II, typename _Tp, typename _Ref, typename _Ptr>
    typename __gnu_cxx::__enable_if<
      __is_random_access_iter<_II>::__value, bool>::__type
    __equal_aux1(_II, _II,
  std::_Deque_iterator<_Tp, _Ref, _Ptr>);

  template<typename _II1, typename _II2>
    constexpr
    inline bool
    __equal_aux1(_II1 __first1, _II1 __last1, _II2 __first2)
    {
      typedef typename iterator_traits<_II1>::value_type _ValueType1;
      const bool __simple = ((__is_integer<_ValueType1>::__value

    || __is_pointer(_ValueType1)



    || is_same_v<_ValueType1, byte>

        ) && __memcmpable<_II1, _II2>::__value);
      return std::__equal<__simple>::equal(__first1, __last1, __first2);
    }

  template<typename _II1, typename _II2>
    __attribute__((__always_inline__))
    constexpr
    inline bool
    __equal_aux(_II1 __first1, _II1 __last1, _II2 __first2)
    {
      return std::__equal_aux1(std::__niter_base(__first1),
          std::__niter_base(__last1),
          std::__niter_base(__first2));
    }

  template<typename _II1, typename _Seq1, typename _Cat1, typename _II2>
    constexpr
    bool
    __equal_aux(const ::__gnu_debug::_Safe_iterator<_II1, _Seq1, _Cat1>&,
  const ::__gnu_debug::_Safe_iterator<_II1, _Seq1, _Cat1>&,
  _II2);

  template<typename _II1, typename _II2, typename _Seq2, typename _Cat2>
    constexpr
    bool
    __equal_aux(_II1, _II1,
  const ::__gnu_debug::_Safe_iterator<_II2, _Seq2, _Cat2>&);

  template<typename _II1, typename _Seq1, typename _Cat1,
    typename _II2, typename _Seq2, typename _Cat2>
    constexpr
    bool
    __equal_aux(const ::__gnu_debug::_Safe_iterator<_II1, _Seq1, _Cat1>&,
  const ::__gnu_debug::_Safe_iterator<_II1, _Seq1, _Cat1>&,
  const ::__gnu_debug::_Safe_iterator<_II2, _Seq2, _Cat2>&);

  template<typename, typename>
    struct __lc_rai
    {
      template<typename _II1, typename _II2>
 constexpr
 static _II1
 __newlast1(_II1, _II1 __last1, _II2, _II2)
 { return __last1; }

      template<typename _II>
 constexpr
 static bool
 __cnd2(_II __first, _II __last)
 { return __first != __last; }
    };

  template<>
    struct __lc_rai<random_access_iterator_tag, random_access_iterator_tag>
    {
      template<typename _RAI1, typename _RAI2>
 constexpr
 static _RAI1
 __newlast1(_RAI1 __first1, _RAI1 __last1,
     _RAI2 __first2, _RAI2 __last2)
 {
   const typename iterator_traits<_RAI1>::difference_type
     __diff1 = __last1 - __first1;
   const typename iterator_traits<_RAI2>::difference_type
     __diff2 = __last2 - __first2;
   return __diff2 < __diff1 ? __first1 + __diff2 : __last1;
 }

      template<typename _RAI>
 static constexpr bool
 __cnd2(_RAI, _RAI)
 { return true; }
    };

  template<typename _II1, typename _II2, typename _Compare>
    constexpr
    bool
    __lexicographical_compare_impl(_II1 __first1, _II1 __last1,
       _II2 __first2, _II2 __last2,
       _Compare __comp)
    {
      typedef typename iterator_traits<_II1>::iterator_category _Category1;
      typedef typename iterator_traits<_II2>::iterator_category _Category2;
      typedef std::__lc_rai<_Category1, _Category2> __rai_type;

      __last1 = __rai_type::__newlast1(__first1, __last1, __first2, __last2);
      for (; __first1 != __last1 && __rai_type::__cnd2(__first2, __last2);
    ++__first1, (void)++__first2)
 {
   if (__comp(__first1, __first2))
     return true;
   if (__comp(__first2, __first1))
     return false;
 }
      return __first1 == __last1 && __first2 != __last2;
    }

  template<bool _BoolType>
    struct __lexicographical_compare
    {
      template<typename _II1, typename _II2>
 constexpr
 static bool
 __lc(_II1 __first1, _II1 __last1, _II2 __first2, _II2 __last2)
 {
   using __gnu_cxx::__ops::__iter_less_iter;
   return std::__lexicographical_compare_impl(__first1, __last1,
           __first2, __last2,
           __iter_less_iter());
 }

      template<typename _II1, typename _II2>
 constexpr
 static int
 __3way(_II1 __first1, _II1 __last1, _II2 __first2, _II2 __last2)
 {
   while (__first1 != __last1)
     {
       if (__first2 == __last2)
  return +1;
       if (*__first1 < *__first2)
  return -1;
       if (*__first2 < *__first1)
  return +1;
       ++__first1;
       ++__first2;
     }
   return int(__first2 == __last2) - 1;
 }
    };

  template<>
    struct __lexicographical_compare<true>
    {
      template<typename _Tp, typename _Up>
 constexpr
 static bool
 __lc(const _Tp* __first1, const _Tp* __last1,
      const _Up* __first2, const _Up* __last2)
 { return __3way(__first1, __last1, __first2, __last2) < 0; }

      template<typename _Tp, typename _Up>
 constexpr
 static ptrdiff_t
 __3way(const _Tp* __first1, const _Tp* __last1,
        const _Up* __first2, const _Up* __last2)
 {
   const size_t __len1 = __last1 - __first1;
   const size_t __len2 = __last2 - __first2;
   if (const size_t __len = std::min(__len1, __len2))
     if (int __result = std::__memcmp(__first1, __first2, __len))
       return __result;
   return ptrdiff_t(__len1 - __len2);
 }
    };

  template<typename _II1, typename _II2>
    constexpr
    inline bool
    __lexicographical_compare_aux1(_II1 __first1, _II1 __last1,
       _II2 __first2, _II2 __last2)
    {
      typedef typename iterator_traits<_II1>::value_type _ValueType1;
      typedef typename iterator_traits<_II2>::value_type _ValueType2;

      const bool __simple =
 (__is_memcmp_ordered_with<_ValueType1, _ValueType2>::__value
  && __is_pointer(_II1) && __is_pointer(_II2)




  && !is_volatile_v<remove_reference_t<iter_reference_t<_II1>>>
  && !is_volatile_v<remove_reference_t<iter_reference_t<_II2>>>

  );




      return std::__lexicographical_compare<__simple>::__lc(__first1, __last1,
           __first2, __last2);
    }

  template<typename _Tp1, typename _Ref1, typename _Ptr1,
    typename _Tp2>
    bool
    __lexicographical_compare_aux1(
 std::_Deque_iterator<_Tp1, _Ref1, _Ptr1>,
 std::_Deque_iterator<_Tp1, _Ref1, _Ptr1>,
 _Tp2*, _Tp2*);

  template<typename _Tp1,
    typename _Tp2, typename _Ref2, typename _Ptr2>
    bool
    __lexicographical_compare_aux1(_Tp1*, _Tp1*,
 std::_Deque_iterator<_Tp2, _Ref2, _Ptr2>,
 std::_Deque_iterator<_Tp2, _Ref2, _Ptr2>);

  template<typename _Tp1, typename _Ref1, typename _Ptr1,
    typename _Tp2, typename _Ref2, typename _Ptr2>
    bool
    __lexicographical_compare_aux1(
 std::_Deque_iterator<_Tp1, _Ref1, _Ptr1>,
 std::_Deque_iterator<_Tp1, _Ref1, _Ptr1>,
 std::_Deque_iterator<_Tp2, _Ref2, _Ptr2>,
 std::_Deque_iterator<_Tp2, _Ref2, _Ptr2>);

  template<typename _II1, typename _II2>
    constexpr
    inline bool
    __lexicographical_compare_aux(_II1 __first1, _II1 __last1,
      _II2 __first2, _II2 __last2)
    {
      return std::__lexicographical_compare_aux1(std::__niter_base(__first1),
       std::__niter_base(__last1),
       std::__niter_base(__first2),
       std::__niter_base(__last2));
    }

  template<typename _Iter1, typename _Seq1, typename _Cat1,
    typename _II2>
    constexpr
    bool
    __lexicographical_compare_aux(
  const ::__gnu_debug::_Safe_iterator<_Iter1, _Seq1, _Cat1>&,
  const ::__gnu_debug::_Safe_iterator<_Iter1, _Seq1, _Cat1>&,
  _II2, _II2);

  template<typename _II1,
    typename _Iter2, typename _Seq2, typename _Cat2>
    constexpr
    bool
    __lexicographical_compare_aux(
  _II1, _II1,
  const ::__gnu_debug::_Safe_iterator<_Iter2, _Seq2, _Cat2>&,
  const ::__gnu_debug::_Safe_iterator<_Iter2, _Seq2, _Cat2>&);

  template<typename _Iter1, typename _Seq1, typename _Cat1,
    typename _Iter2, typename _Seq2, typename _Cat2>
    constexpr
    bool
    __lexicographical_compare_aux(
  const ::__gnu_debug::_Safe_iterator<_Iter1, _Seq1, _Cat1>&,
  const ::__gnu_debug::_Safe_iterator<_Iter1, _Seq1, _Cat1>&,
  const ::__gnu_debug::_Safe_iterator<_Iter2, _Seq2, _Cat2>&,
  const ::__gnu_debug::_Safe_iterator<_Iter2, _Seq2, _Cat2>&);

  template<typename _ForwardIterator, typename _Tp, typename _Compare>
    constexpr
    _ForwardIterator
    __lower_bound(_ForwardIterator __first, _ForwardIterator __last,
    const _Tp& __val, _Compare __comp)
    {
      typedef typename iterator_traits<_ForwardIterator>::difference_type
 _DistanceType;

      _DistanceType __len = std::distance(__first, __last);

      while (__len > 0)
 {
   _DistanceType __half = __len >> 1;
   _ForwardIterator __middle = __first;
   std::advance(__middle, __half);
   if (__comp(__middle, __val))
     {
       __first = __middle;
       ++__first;
       __len = __len - __half - 1;
     }
   else
     __len = __half;
 }
      return __first;
    }
# 1532 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _ForwardIterator, typename _Tp>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator
    lower_bound(_ForwardIterator __first, _ForwardIterator __last,
  const _Tp& __val)
    {

     
     

      ;

      return std::__lower_bound(__first, __last, __val,
    __gnu_cxx::__ops::__iter_less_val());
    }



  template<typename _Tp>
    inline constexpr _Tp
    __lg(_Tp __n)
    {

      return std::__bit_width(make_unsigned_t<_Tp>(__n)) - 1;
# 1568 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
    }


# 1584 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _II1, typename _II2>
    [[__nodiscard__]] constexpr
    inline bool
    equal(_II1 __first1, _II1 __last1, _II2 __first2)
    {

     
     
     


      ;

      return std::__equal_aux(__first1, __last1, __first2);
    }
# 1615 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _IIter1, typename _IIter2, typename _BinaryPredicate>
    [[__nodiscard__]] constexpr
    inline bool
    equal(_IIter1 __first1, _IIter1 __last1,
   _IIter2 __first2, _BinaryPredicate __binary_pred)
    {

     
     
      ;

      for (; __first1 != __last1; ++__first1, (void)++__first2)
 if (!bool(__binary_pred(*__first1, *__first2)))
   return false;
      return true;
    }


#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wc++17-extensions"


  template<typename _II1, typename _II2>
    constexpr
    inline bool
    __equal4(_II1 __first1, _II1 __last1, _II2 __first2, _II2 __last2)
    {
      using _RATag = random_access_iterator_tag;
      using _Cat1 = typename iterator_traits<_II1>::iterator_category;
      using _Cat2 = typename iterator_traits<_II2>::iterator_category;
      using _RAIters = __and_<is_same<_Cat1, _RATag>, is_same<_Cat2, _RATag>>;
      if constexpr (_RAIters::value)
 {
   if ((__last1 - __first1) != (__last2 - __first2))
     return false;
   return std::equal(__first1, __last1, __first2);
 }
      else
 {
   for (; __first1 != __last1 && __first2 != __last2;
        ++__first1, (void)++__first2)
     if (!(*__first1 == *__first2))
       return false;
   return __first1 == __last1 && __first2 == __last2;
 }
    }


  template<typename _II1, typename _II2, typename _BinaryPredicate>
    constexpr
    inline bool
    __equal4(_II1 __first1, _II1 __last1, _II2 __first2, _II2 __last2,
      _BinaryPredicate __binary_pred)
    {
      using _RATag = random_access_iterator_tag;
      using _Cat1 = typename iterator_traits<_II1>::iterator_category;
      using _Cat2 = typename iterator_traits<_II2>::iterator_category;
      using _RAIters = __and_<is_same<_Cat1, _RATag>, is_same<_Cat2, _RATag>>;
      if constexpr (_RAIters::value)
 {
   if ((__last1 - __first1) != (__last2 - __first2))
     return false;
   return std::equal(__first1, __last1, __first2,
           __binary_pred);
 }
      else
 {
   for (; __first1 != __last1 && __first2 != __last2;
        ++__first1, (void)++__first2)
     if (!bool(__binary_pred(*__first1, *__first2)))
       return false;
   return __first1 == __last1 && __first2 == __last2;
 }
    }
#pragma GCC diagnostic pop
# 1706 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _II1, typename _II2>
    [[__nodiscard__]] constexpr
    inline bool
    equal(_II1 __first1, _II1 __last1, _II2 __first2, _II2 __last2)
    {

     
     
     


      ;
      ;

      return std::__equal4(__first1, __last1, __first2, __last2);
    }
# 1739 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _IIter1, typename _IIter2, typename _BinaryPredicate>
    [[__nodiscard__]] constexpr
    inline bool
    equal(_IIter1 __first1, _IIter1 __last1,
   _IIter2 __first2, _IIter2 __last2, _BinaryPredicate __binary_pred)
    {

     
     
      ;
      ;

      return std::__equal4(__first1, __last1, __first2, __last2,
          __binary_pred);
    }
# 1771 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _II1, typename _II2>
    [[__nodiscard__]] constexpr
    inline bool
    lexicographical_compare(_II1 __first1, _II1 __last1,
       _II2 __first2, _II2 __last2)
    {





     
     
     
     
      ;
      ;

      return std::__lexicographical_compare_aux(__first1, __last1,
      __first2, __last2);
    }
# 1806 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _II1, typename _II2, typename _Compare>
    [[__nodiscard__]] constexpr
    inline bool
    lexicographical_compare(_II1 __first1, _II1 __last1,
       _II2 __first2, _II2 __last2, _Compare __comp)
    {

     
     
      ;
      ;

      return std::__lexicographical_compare_impl
 (__first1, __last1, __first2, __last2,
  __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }





  template<typename _Iter1, typename _Iter2>
    concept __memcmp_ordered_with
      = (__is_memcmp_ordered_with<iter_value_t<_Iter1>,
      iter_value_t<_Iter2>>::__value)
   && contiguous_iterator<_Iter1> && contiguous_iterator<_Iter2>;



  template<typename _Tp>
    constexpr auto
    __min_cmp(_Tp __x, _Tp __y)
    {
      struct _Res {
 _Tp _M_min;
 decltype(__x <=> __y) _M_cmp;
      };
      auto __c = __x <=> __y;
      if (__c > 0)
 return _Res{__y, __c};
      return _Res{__x, __c};
    }
# 1860 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _InputIter1, typename _InputIter2, typename _Comp>
    [[nodiscard]] constexpr auto
    lexicographical_compare_three_way(_InputIter1 __first1,
          _InputIter1 __last1,
          _InputIter2 __first2,
          _InputIter2 __last2,
          _Comp __comp)
    -> decltype(__comp(*__first1, *__first2))
    {

     
     
      ;
      ;

      using _Cat = decltype(__comp(*__first1, *__first2));
      static_assert(same_as<common_comparison_category_t<_Cat>, _Cat>);

      if (!std::__is_constant_evaluated())
 if constexpr (same_as<_Comp, __detail::_Synth3way>
        || same_as<_Comp, compare_three_way>)
   if constexpr (__memcmp_ordered_with<_InputIter1, _InputIter2>)
     {
       const auto [__len, __lencmp] = std::
  __min_cmp(__last1 - __first1, __last2 - __first2);
       if (__len)
  {
    const auto __blen = __len * sizeof(*__first1);
    const auto __c
      = __builtin_memcmp(&*__first1, &*__first2, __blen) <=> 0;
    if (__c != 0)
      return __c;
  }
       return __lencmp;
     }

      while (__first1 != __last1)
 {
   if (__first2 == __last2)
     return strong_ordering::greater;
   if (auto __cmp = __comp(*__first1, *__first2); __cmp != 0)
     return __cmp;
   ++__first1;
   ++__first2;
 }
      return (__first2 == __last2) <=> true;
    }

  template<typename _InputIter1, typename _InputIter2>
    constexpr auto
    lexicographical_compare_three_way(_InputIter1 __first1,
          _InputIter1 __last1,
          _InputIter2 __first2,
          _InputIter2 __last2)
    {
      return std::
 lexicographical_compare_three_way(__first1, __last1, __first2, __last2,
       compare_three_way{});
    }


  template<typename _InputIterator1, typename _InputIterator2,
    typename _BinaryPredicate>
    constexpr
    pair<_InputIterator1, _InputIterator2>
    __mismatch(_InputIterator1 __first1, _InputIterator1 __last1,
        _InputIterator2 __first2, _BinaryPredicate __binary_pred)
    {
      while (__first1 != __last1 && __binary_pred(__first1, __first2))
 {
   ++__first1;
   ++__first2;
 }
      return pair<_InputIterator1, _InputIterator2>(__first1, __first2);
    }
# 1949 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _InputIterator1, typename _InputIterator2>
    [[__nodiscard__]] constexpr
    inline pair<_InputIterator1, _InputIterator2>
    mismatch(_InputIterator1 __first1, _InputIterator1 __last1,
      _InputIterator2 __first2)
    {

     
     
     


      ;

      return std::__mismatch(__first1, __last1, __first2,
        __gnu_cxx::__ops::__iter_equal_to_iter());
    }
# 1983 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _InputIterator1, typename _InputIterator2,
    typename _BinaryPredicate>
    [[__nodiscard__]] constexpr
    inline pair<_InputIterator1, _InputIterator2>
    mismatch(_InputIterator1 __first1, _InputIterator1 __last1,
      _InputIterator2 __first2, _BinaryPredicate __binary_pred)
    {

     
     
      ;

      return std::__mismatch(__first1, __last1, __first2,
 __gnu_cxx::__ops::__iter_comp_iter(__binary_pred));
    }


  template<typename _InputIterator1, typename _InputIterator2,
    typename _BinaryPredicate>
    constexpr
    pair<_InputIterator1, _InputIterator2>
    __mismatch(_InputIterator1 __first1, _InputIterator1 __last1,
        _InputIterator2 __first2, _InputIterator2 __last2,
        _BinaryPredicate __binary_pred)
    {
      while (__first1 != __last1 && __first2 != __last2
      && __binary_pred(__first1, __first2))
 {
   ++__first1;
   ++__first2;
 }
      return pair<_InputIterator1, _InputIterator2>(__first1, __first2);
    }
# 2031 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _InputIterator1, typename _InputIterator2>
    [[__nodiscard__]] constexpr
    inline pair<_InputIterator1, _InputIterator2>
    mismatch(_InputIterator1 __first1, _InputIterator1 __last1,
      _InputIterator2 __first2, _InputIterator2 __last2)
    {

     
     
     


      ;
      ;

      return std::__mismatch(__first1, __last1, __first2, __last2,
        __gnu_cxx::__ops::__iter_equal_to_iter());
    }
# 2067 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _InputIterator1, typename _InputIterator2,
    typename _BinaryPredicate>
    [[__nodiscard__]] constexpr
    inline pair<_InputIterator1, _InputIterator2>
    mismatch(_InputIterator1 __first1, _InputIterator1 __last1,
      _InputIterator2 __first2, _InputIterator2 __last2,
      _BinaryPredicate __binary_pred)
    {

     
     
      ;
      ;

      return std::__mismatch(__first1, __last1, __first2, __last2,
        __gnu_cxx::__ops::__iter_comp_iter(__binary_pred));
    }





  template<typename _Iterator, typename _Predicate>
    constexpr
    inline _Iterator
    __find_if(_Iterator __first, _Iterator __last, _Predicate __pred)
    {
#pragma GCC unroll 4
      while (__first != __last && !__pred(__first))
 ++__first;
      return __first;
    }

  template<typename _InputIterator, typename _Predicate>
    constexpr
    typename iterator_traits<_InputIterator>::difference_type
    __count_if(_InputIterator __first, _InputIterator __last, _Predicate __pred)
    {
      typename iterator_traits<_InputIterator>::difference_type __n = 0;
      for (; __first != __last; ++__first)
 if (__pred(__first))
   ++__n;
      return __n;
    }

  template<typename _ForwardIterator, typename _Predicate>
    constexpr
    _ForwardIterator
    __remove_if(_ForwardIterator __first, _ForwardIterator __last,
  _Predicate __pred)
    {
      __first = std::__find_if(__first, __last, __pred);
      if (__first == __last)
 return __first;
      _ForwardIterator __result = __first;
      ++__first;
      for (; __first != __last; ++__first)
 if (!__pred(__first))
   {
     *__result = std::move(*__first);
     ++__result;
   }
      return __result;
    }

  template<typename _ForwardIterator1, typename _ForwardIterator2,
    typename _BinaryPredicate>
    constexpr
    _ForwardIterator1
    __search(_ForwardIterator1 __first1, _ForwardIterator1 __last1,
      _ForwardIterator2 __first2, _ForwardIterator2 __last2,
      _BinaryPredicate __predicate)
    {

      if (__first1 == __last1 || __first2 == __last2)
 return __first1;


      _ForwardIterator2 __p1(__first2);
      if (++__p1 == __last2)
 return std::__find_if(__first1, __last1,
  __gnu_cxx::__ops::__iter_comp_iter(__predicate, __first2));


      _ForwardIterator1 __current = __first1;

      for (;;)
 {
   __first1 =
     std::__find_if(__first1, __last1,
  __gnu_cxx::__ops::__iter_comp_iter(__predicate, __first2));

   if (__first1 == __last1)
     return __last1;

   _ForwardIterator2 __p = __p1;
   __current = __first1;
   if (++__current == __last1)
     return __last1;

   while (__predicate(__current, __p))
     {
       if (++__p == __last2)
  return __first1;
       if (++__current == __last1)
  return __last1;
     }
   ++__first1;
 }
      return __first1;
    }


  template<typename _ForwardIterator1, typename _ForwardIterator2,
    typename _BinaryPredicate>
    constexpr
    bool
    __is_permutation(_ForwardIterator1 __first1, _ForwardIterator1 __last1,
       _ForwardIterator2 __first2, _BinaryPredicate __pred)
    {


      for (; __first1 != __last1; ++__first1, (void)++__first2)
 if (!__pred(__first1, __first2))
   break;

      if (__first1 == __last1)
 return true;



      _ForwardIterator2 __last2 = __first2;
      std::advance(__last2, std::distance(__first1, __last1));
      for (_ForwardIterator1 __scan = __first1; __scan != __last1; ++__scan)
 {
   if (__scan != std::__find_if(__first1, __scan,
     __gnu_cxx::__ops::__iter_comp_iter(__pred, __scan)))
     continue;

   auto __matches
     = std::__count_if(__first2, __last2,
   __gnu_cxx::__ops::__iter_comp_iter(__pred, __scan));
   if (0 == __matches ||
       std::__count_if(__scan, __last1,
   __gnu_cxx::__ops::__iter_comp_iter(__pred, __scan))
       != __matches)
     return false;
 }
      return true;
    }
# 2230 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _ForwardIterator1, typename _ForwardIterator2>
    constexpr
    inline bool
    is_permutation(_ForwardIterator1 __first1, _ForwardIterator1 __last1,
     _ForwardIterator2 __first2)
    {

     
     
     


      ;

      return std::__is_permutation(__first1, __last1, __first2,
       __gnu_cxx::__ops::__iter_equal_to_iter());
    }



# 2272 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algobase.h" 3
  template<typename _ForwardIterator1, typename _ForwardIterator2,
    typename _BinaryPredicate>
    constexpr
    inline _ForwardIterator1
    search(_ForwardIterator1 __first1, _ForwardIterator1 __last1,
    _ForwardIterator2 __first2, _ForwardIterator2 __last2,
    _BinaryPredicate __predicate)
    {

     
     
     


      ;
      ;

      return std::__search(__first1, __last1, __first2, __last2,
      __gnu_cxx::__ops::__iter_comp_iter(__predicate));
    }



}
# 63 "C:/msys64/mingw64/include/c++/15.2.0/algorithm" 2 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 1 3
# 59 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/algorithmfwd.h" 1 3
# 44 "C:/msys64/mingw64/include/c++/15.2.0/bits/algorithmfwd.h" 3
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wc++11-extensions"

namespace std
{

# 200 "C:/msys64/mingw64/include/c++/15.2.0/bits/algorithmfwd.h" 3
  template<typename _IIter, typename _Predicate>
    constexpr
    bool
    all_of(_IIter, _IIter, _Predicate);

  template<typename _IIter, typename _Predicate>
    constexpr
    bool
    any_of(_IIter, _IIter, _Predicate);


  template<typename _FIter, typename _Tp >
    constexpr
    bool
    binary_search(_FIter, _FIter, const _Tp&);

  template<typename _FIter, typename _Tp ,
    typename _Compare>
    constexpr
    bool
    binary_search(_FIter, _FIter, const _Tp&, _Compare);


  template<typename _Tp>
    constexpr
    const _Tp&
    clamp(const _Tp&, const _Tp&, const _Tp&);

  template<typename _Tp, typename _Compare>
    constexpr
    const _Tp&
    clamp(const _Tp&, const _Tp&, const _Tp&, _Compare);


  template<typename _IIter, typename _OIter>
    constexpr
    _OIter
    copy(_IIter, _IIter, _OIter);

  template<typename _BIter1, typename _BIter2>
    constexpr
    _BIter2
    copy_backward(_BIter1, _BIter1, _BIter2);


  template<typename _IIter, typename _OIter, typename _Predicate>
    constexpr
    _OIter
    copy_if(_IIter, _IIter, _OIter, _Predicate);

  template<typename _IIter, typename _Size, typename _OIter>
    constexpr
    _OIter
    copy_n(_IIter, _Size, _OIter);





  template<typename _FIter, typename _Tp >
    constexpr
    pair<_FIter, _FIter>
    equal_range(_FIter, _FIter, const _Tp&);

  template<typename _FIter, typename _Tp ,
    typename _Compare>
    constexpr
    pair<_FIter, _FIter>
    equal_range(_FIter, _FIter, const _Tp&, _Compare);

  template<typename _FIter, typename _Tp >
    constexpr
    void
    fill(_FIter, _FIter, const _Tp&);

  template<typename _OIter, typename _Size,
    typename _Tp >
    constexpr
    _OIter
    fill_n(_OIter, _Size, const _Tp&);



  template<typename _FIter1, typename _FIter2>
    constexpr
    _FIter1
    find_end(_FIter1, _FIter1, _FIter2, _FIter2);

  template<typename _FIter1, typename _FIter2, typename _BinaryPredicate>
    constexpr
    _FIter1
    find_end(_FIter1, _FIter1, _FIter2, _FIter2, _BinaryPredicate);





  template<typename _IIter, typename _Predicate>
    constexpr
    _IIter
    find_if_not(_IIter, _IIter, _Predicate);






  template<typename _IIter1, typename _IIter2>
    constexpr
    bool
    includes(_IIter1, _IIter1, _IIter2, _IIter2);

  template<typename _IIter1, typename _IIter2, typename _Compare>
    constexpr
    bool
    includes(_IIter1, _IIter1, _IIter2, _IIter2, _Compare);

  template<typename _BIter>
   
    void
    inplace_merge(_BIter, _BIter, _BIter);

  template<typename _BIter, typename _Compare>
   
    void
    inplace_merge(_BIter, _BIter, _BIter, _Compare);


  template<typename _RAIter>
    constexpr
    bool
    is_heap(_RAIter, _RAIter);

  template<typename _RAIter, typename _Compare>
    constexpr
    bool
    is_heap(_RAIter, _RAIter, _Compare);

  template<typename _RAIter>
    constexpr
    _RAIter
    is_heap_until(_RAIter, _RAIter);

  template<typename _RAIter, typename _Compare>
    constexpr
    _RAIter
    is_heap_until(_RAIter, _RAIter, _Compare);

  template<typename _IIter, typename _Predicate>
    constexpr
    bool
    is_partitioned(_IIter, _IIter, _Predicate);

  template<typename _FIter1, typename _FIter2>
    constexpr
    bool
    is_permutation(_FIter1, _FIter1, _FIter2);

  template<typename _FIter1, typename _FIter2,
    typename _BinaryPredicate>
    constexpr
    bool
    is_permutation(_FIter1, _FIter1, _FIter2, _BinaryPredicate);

  template<typename _FIter>
    constexpr
    bool
    is_sorted(_FIter, _FIter);

  template<typename _FIter, typename _Compare>
    constexpr
    bool
    is_sorted(_FIter, _FIter, _Compare);

  template<typename _FIter>
    constexpr
    _FIter
    is_sorted_until(_FIter, _FIter);

  template<typename _FIter, typename _Compare>
    constexpr
    _FIter
    is_sorted_until(_FIter, _FIter, _Compare);


  template<typename _FIter1, typename _FIter2>
    constexpr
    void
    iter_swap(_FIter1, _FIter2);

  template<typename _FIter, typename _Tp >
    constexpr
    _FIter
    lower_bound(_FIter, _FIter, const _Tp&);

  template<typename _FIter, typename _Tp ,
    typename _Compare>
    constexpr
    _FIter
    lower_bound(_FIter, _FIter, const _Tp&, _Compare);

  template<typename _RAIter>
    constexpr
    void
    make_heap(_RAIter, _RAIter);

  template<typename _RAIter, typename _Compare>
    constexpr
    void
    make_heap(_RAIter, _RAIter, _Compare);

  template<typename _Tp>
    constexpr
    const _Tp&
    max(const _Tp&, const _Tp&);

  template<typename _Tp, typename _Compare>
    constexpr
    const _Tp&
    max(const _Tp&, const _Tp&, _Compare);




  template<typename _Tp>
    constexpr
    const _Tp&
    min(const _Tp&, const _Tp&);

  template<typename _Tp, typename _Compare>
    constexpr
    const _Tp&
    min(const _Tp&, const _Tp&, _Compare);




  template<typename _Tp>
    constexpr
    pair<const _Tp&, const _Tp&>
    minmax(const _Tp&, const _Tp&);

  template<typename _Tp, typename _Compare>
    constexpr
    pair<const _Tp&, const _Tp&>
    minmax(const _Tp&, const _Tp&, _Compare);

  template<typename _FIter>
    constexpr
    pair<_FIter, _FIter>
    minmax_element(_FIter, _FIter);

  template<typename _FIter, typename _Compare>
    constexpr
    pair<_FIter, _FIter>
    minmax_element(_FIter, _FIter, _Compare);

  template<typename _Tp>
    constexpr
    _Tp
    min(initializer_list<_Tp>);

  template<typename _Tp, typename _Compare>
    constexpr
    _Tp
    min(initializer_list<_Tp>, _Compare);

  template<typename _Tp>
    constexpr
    _Tp
    max(initializer_list<_Tp>);

  template<typename _Tp, typename _Compare>
    constexpr
    _Tp
    max(initializer_list<_Tp>, _Compare);

  template<typename _Tp>
    constexpr
    pair<_Tp, _Tp>
    minmax(initializer_list<_Tp>);

  template<typename _Tp, typename _Compare>
    constexpr
    pair<_Tp, _Tp>
    minmax(initializer_list<_Tp>, _Compare);




  template<typename _BIter>
    constexpr
    bool
    next_permutation(_BIter, _BIter);

  template<typename _BIter, typename _Compare>
    constexpr
    bool
    next_permutation(_BIter, _BIter, _Compare);


  template<typename _IIter, typename _Predicate>
    constexpr
    bool
    none_of(_IIter, _IIter, _Predicate);





  template<typename _IIter, typename _RAIter>
    constexpr
    _RAIter
    partial_sort_copy(_IIter, _IIter, _RAIter, _RAIter);

  template<typename _IIter, typename _RAIter, typename _Compare>
    constexpr
    _RAIter
    partial_sort_copy(_IIter, _IIter, _RAIter, _RAIter, _Compare);




  template<typename _IIter, typename _OIter1,
    typename _OIter2, typename _Predicate>
    constexpr
    pair<_OIter1, _OIter2>
    partition_copy(_IIter, _IIter, _OIter1, _OIter2, _Predicate);

  template<typename _FIter, typename _Predicate>
    constexpr
    _FIter
    partition_point(_FIter, _FIter, _Predicate);


  template<typename _RAIter>
    constexpr
    void
    pop_heap(_RAIter, _RAIter);

  template<typename _RAIter, typename _Compare>
    constexpr
    void
    pop_heap(_RAIter, _RAIter, _Compare);

  template<typename _BIter>
    constexpr
    bool
    prev_permutation(_BIter, _BIter);

  template<typename _BIter, typename _Compare>
    constexpr
    bool
    prev_permutation(_BIter, _BIter, _Compare);

  template<typename _RAIter>
    constexpr
    void
    push_heap(_RAIter, _RAIter);

  template<typename _RAIter, typename _Compare>
    constexpr
    void
    push_heap(_RAIter, _RAIter, _Compare);



  template<typename _FIter, typename _Tp >
    constexpr
    _FIter
    remove(_FIter, _FIter, const _Tp&);

  template<typename _FIter, typename _Predicate>
    constexpr
    _FIter
    remove_if(_FIter, _FIter, _Predicate);

  template<typename _IIter, typename _OIter,
    typename _Tp >
    constexpr
    _OIter
    remove_copy(_IIter, _IIter, _OIter, const _Tp&);

  template<typename _IIter, typename _OIter, typename _Predicate>
    constexpr
    _OIter
    remove_copy_if(_IIter, _IIter, _OIter, _Predicate);



  template<typename _IIter, typename _OIter, typename _Tp>
    constexpr
    _OIter
    replace_copy(_IIter, _IIter, _OIter, const _Tp&, const _Tp&);

  template<typename _Iter, typename _OIter, typename _Predicate,
    typename _Tp >
    constexpr
    _OIter
    replace_copy_if(_Iter, _Iter, _OIter, _Predicate, const _Tp&);



  template<typename _BIter>
    constexpr
    void
    reverse(_BIter, _BIter);

  template<typename _BIter, typename _OIter>
    constexpr
    _OIter
    reverse_copy(_BIter, _BIter, _OIter);

inline namespace _V2 {

  template<typename _FIter>
    constexpr
    _FIter
    rotate(_FIter, _FIter, _FIter);

}

  template<typename _FIter, typename _OIter>
    constexpr
    _OIter
    rotate_copy(_FIter, _FIter, _FIter, _OIter);
# 635 "C:/msys64/mingw64/include/c++/15.2.0/bits/algorithmfwd.h" 3
  template<typename _RAIter, typename _UGenerator>
    void
    shuffle(_RAIter, _RAIter, _UGenerator&&);


  template<typename _RAIter>
    constexpr
    void
    sort_heap(_RAIter, _RAIter);

  template<typename _RAIter, typename _Compare>
    constexpr
    void
    sort_heap(_RAIter, _RAIter, _Compare);


  template<typename _BIter, typename _Predicate>
   
    _BIter
    stable_partition(_BIter, _BIter, _Predicate);
# 671 "C:/msys64/mingw64/include/c++/15.2.0/bits/algorithmfwd.h" 3
  template<typename _FIter1, typename _FIter2>
    constexpr
    _FIter2
    swap_ranges(_FIter1, _FIter1, _FIter2);



  template<typename _FIter>
    constexpr
    _FIter
    unique(_FIter, _FIter);

  template<typename _FIter, typename _BinaryPredicate>
    constexpr
    _FIter
    unique(_FIter, _FIter, _BinaryPredicate);



  template<typename _FIter, typename _Tp >
    constexpr
    _FIter
    upper_bound(_FIter, _FIter, const _Tp&);

  template<typename _FIter, typename _Tp ,
    typename _Compare>
    constexpr
    _FIter
    upper_bound(_FIter, _FIter, const _Tp&, _Compare);



  template<typename _FIter>
    constexpr
    _FIter
    adjacent_find(_FIter, _FIter);

  template<typename _FIter, typename _BinaryPredicate>
    constexpr
    _FIter
    adjacent_find(_FIter, _FIter, _BinaryPredicate);

  template<typename _IIter, typename _Tp >
    constexpr
    typename iterator_traits<_IIter>::difference_type
    count(_IIter, _IIter, const _Tp&);

  template<typename _IIter, typename _Predicate>
    constexpr
    typename iterator_traits<_IIter>::difference_type
    count_if(_IIter, _IIter, _Predicate);

  template<typename _IIter1, typename _IIter2>
    constexpr
    bool
    equal(_IIter1, _IIter1, _IIter2);

  template<typename _IIter1, typename _IIter2, typename _BinaryPredicate>
    constexpr
    bool
    equal(_IIter1, _IIter1, _IIter2, _BinaryPredicate);

  template<typename _IIter, typename _Tp >
    constexpr
    _IIter
    find(_IIter, _IIter, const _Tp&);

  template<typename _FIter1, typename _FIter2>
    constexpr
    _FIter1
    find_first_of(_FIter1, _FIter1, _FIter2, _FIter2);

  template<typename _FIter1, typename _FIter2, typename _BinaryPredicate>
    constexpr
    _FIter1
    find_first_of(_FIter1, _FIter1, _FIter2, _FIter2, _BinaryPredicate);

  template<typename _IIter, typename _Predicate>
    constexpr
    _IIter
    find_if(_IIter, _IIter, _Predicate);

  template<typename _IIter, typename _Funct>
    constexpr
    _Funct
    for_each(_IIter, _IIter, _Funct);

  template<typename _FIter, typename _Generator>
    constexpr
    void
    generate(_FIter, _FIter, _Generator);

  template<typename _OIter, typename _Size, typename _Generator>
    constexpr
    _OIter
    generate_n(_OIter, _Size, _Generator);

  template<typename _IIter1, typename _IIter2>
    constexpr
    bool
    lexicographical_compare(_IIter1, _IIter1, _IIter2, _IIter2);

  template<typename _IIter1, typename _IIter2, typename _Compare>
    constexpr
    bool
    lexicographical_compare(_IIter1, _IIter1, _IIter2, _IIter2, _Compare);

  template<typename _FIter>
    constexpr
    _FIter
    max_element(_FIter, _FIter);

  template<typename _FIter, typename _Compare>
    constexpr
    _FIter
    max_element(_FIter, _FIter, _Compare);

  template<typename _IIter1, typename _IIter2, typename _OIter>
    constexpr
    _OIter
    merge(_IIter1, _IIter1, _IIter2, _IIter2, _OIter);

  template<typename _IIter1, typename _IIter2, typename _OIter,
    typename _Compare>
    constexpr
    _OIter
    merge(_IIter1, _IIter1, _IIter2, _IIter2, _OIter, _Compare);

  template<typename _FIter>
    constexpr
    _FIter
    min_element(_FIter, _FIter);

  template<typename _FIter, typename _Compare>
    constexpr
    _FIter
    min_element(_FIter, _FIter, _Compare);

  template<typename _IIter1, typename _IIter2>
    constexpr
    pair<_IIter1, _IIter2>
    mismatch(_IIter1, _IIter1, _IIter2);

  template<typename _IIter1, typename _IIter2, typename _BinaryPredicate>
    constexpr
    pair<_IIter1, _IIter2>
    mismatch(_IIter1, _IIter1, _IIter2, _BinaryPredicate);

  template<typename _RAIter>
    constexpr
    void
    nth_element(_RAIter, _RAIter, _RAIter);

  template<typename _RAIter, typename _Compare>
    constexpr
    void
    nth_element(_RAIter, _RAIter, _RAIter, _Compare);

  template<typename _RAIter>
    constexpr
    void
    partial_sort(_RAIter, _RAIter, _RAIter);

  template<typename _RAIter, typename _Compare>
    constexpr
    void
    partial_sort(_RAIter, _RAIter, _RAIter, _Compare);

  template<typename _BIter, typename _Predicate>
    constexpr
    _BIter
    partition(_BIter, _BIter, _Predicate);


  template<typename _RAIter>
    __attribute__ ((__deprecated__ ("use '" "std::shuffle" "' instead")))
    void
    random_shuffle(_RAIter, _RAIter);

  template<typename _RAIter, typename _Generator>
    __attribute__ ((__deprecated__ ("use '" "std::shuffle" "' instead")))
    void
    random_shuffle(_RAIter, _RAIter,

     _Generator&&);





  template<typename _FIter, typename _Tp >
    constexpr
    void
    replace(_FIter, _FIter, const _Tp&, const _Tp&);

  template<typename _FIter, typename _Predicate,
    typename _Tp >
    constexpr
    void
    replace_if(_FIter, _FIter, _Predicate, const _Tp&);

  template<typename _FIter1, typename _FIter2>
    constexpr
    _FIter1
    search(_FIter1, _FIter1, _FIter2, _FIter2);

  template<typename _FIter1, typename _FIter2, typename _BinaryPredicate>
    constexpr
    _FIter1
    search(_FIter1, _FIter1, _FIter2, _FIter2, _BinaryPredicate);

  template<typename _FIter, typename _Size,
    typename _Tp >
    constexpr
    _FIter
    search_n(_FIter, _FIter, _Size, const _Tp&);

  template<typename _FIter, typename _Size,
    typename _Tp ,
    typename _BinaryPredicate>
    constexpr
    _FIter
    search_n(_FIter, _FIter, _Size, const _Tp&, _BinaryPredicate);

  template<typename _IIter1, typename _IIter2, typename _OIter>
    constexpr
    _OIter
    set_difference(_IIter1, _IIter1, _IIter2, _IIter2, _OIter);

  template<typename _IIter1, typename _IIter2, typename _OIter,
    typename _Compare>
    constexpr
    _OIter
    set_difference(_IIter1, _IIter1, _IIter2, _IIter2, _OIter, _Compare);

  template<typename _IIter1, typename _IIter2, typename _OIter>
    constexpr
    _OIter
    set_intersection(_IIter1, _IIter1, _IIter2, _IIter2, _OIter);

  template<typename _IIter1, typename _IIter2, typename _OIter,
    typename _Compare>
    constexpr
    _OIter
    set_intersection(_IIter1, _IIter1, _IIter2, _IIter2, _OIter, _Compare);

  template<typename _IIter1, typename _IIter2, typename _OIter>
    constexpr
    _OIter
    set_symmetric_difference(_IIter1, _IIter1, _IIter2, _IIter2, _OIter);

  template<typename _IIter1, typename _IIter2, typename _OIter,
    typename _Compare>
    constexpr
    _OIter
    set_symmetric_difference(_IIter1, _IIter1, _IIter2, _IIter2,
        _OIter, _Compare);

  template<typename _IIter1, typename _IIter2, typename _OIter>
    constexpr
    _OIter
    set_union(_IIter1, _IIter1, _IIter2, _IIter2, _OIter);

  template<typename _IIter1, typename _IIter2, typename _OIter,
    typename _Compare>
    constexpr
    _OIter
    set_union(_IIter1, _IIter1, _IIter2, _IIter2, _OIter, _Compare);

  template<typename _RAIter>
    constexpr
    void
    sort(_RAIter, _RAIter);

  template<typename _RAIter, typename _Compare>
    constexpr
    void
    sort(_RAIter, _RAIter, _Compare);

  template<typename _RAIter>
   
    void
    stable_sort(_RAIter, _RAIter);

  template<typename _RAIter, typename _Compare>
   
    void
    stable_sort(_RAIter, _RAIter, _Compare);

  template<typename _IIter, typename _OIter, typename _UnaryOperation>
    constexpr
    _OIter
    transform(_IIter, _IIter, _OIter, _UnaryOperation);

  template<typename _IIter1, typename _IIter2, typename _OIter,
    typename _BinaryOperation>
    constexpr
    _OIter
    transform(_IIter1, _IIter1, _IIter2, _OIter, _BinaryOperation);

  template<typename _IIter, typename _OIter>
    constexpr
    _OIter
    unique_copy(_IIter, _IIter, _OIter);

  template<typename _IIter, typename _OIter, typename _BinaryPredicate>
    constexpr
    _OIter
    unique_copy(_IIter, _IIter, _OIter, _BinaryPredicate);



}

#pragma GCC diagnostic pop
# 60 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 2 3

# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_heap.h" 1 3
# 63 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_heap.h" 3
namespace std
{







  template<typename _RandomAccessIterator, typename _Distance,
    typename _Compare>
    constexpr
    _Distance
    __is_heap_until(_RandomAccessIterator __first, _Distance __n,
      _Compare& __comp)
    {
      _Distance __parent = 0;
      for (_Distance __child = 1; __child < __n; ++__child)
 {
   if (__comp(__first + __parent, __first + __child))
     return __child;
   if ((__child & 1) == 0)
     ++__parent;
 }
      return __n;
    }



  template<typename _RandomAccessIterator, typename _Distance>
    constexpr
    inline bool
    __is_heap(_RandomAccessIterator __first, _Distance __n)
    {
      __gnu_cxx::__ops::_Iter_less_iter __comp;
      return std::__is_heap_until(__first, __n, __comp) == __n;
    }

  template<typename _RandomAccessIterator, typename _Compare,
    typename _Distance>
    constexpr
    inline bool
    __is_heap(_RandomAccessIterator __first, _Compare __comp, _Distance __n)
    {
      typedef __decltype(__comp) _Cmp;
      __gnu_cxx::__ops::_Iter_comp_iter<_Cmp> __cmp(std::move(__comp));
      return std::__is_heap_until(__first, __n, __cmp) == __n;
    }

  template<typename _RandomAccessIterator>
    constexpr
    inline bool
    __is_heap(_RandomAccessIterator __first, _RandomAccessIterator __last)
    { return std::__is_heap(__first, std::distance(__first, __last)); }

  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    inline bool
    __is_heap(_RandomAccessIterator __first, _RandomAccessIterator __last,
       _Compare __comp)
    {
      return std::__is_heap(__first, std::move(__comp),
       std::distance(__first, __last));
    }




  template<typename _RandomAccessIterator, typename _Distance, typename _Tp,
    typename _Compare>
    constexpr
    void
    __push_heap(_RandomAccessIterator __first,
  _Distance __holeIndex, _Distance __topIndex, _Tp __value,
  _Compare& __comp)
    {
      _Distance __parent = (__holeIndex - 1) / 2;
      while (__holeIndex > __topIndex && __comp(__first + __parent, __value))
 {
   *(__first + __holeIndex) = std::move(*(__first + __parent));
   __holeIndex = __parent;
   __parent = (__holeIndex - 1) / 2;
 }
      *(__first + __holeIndex) = std::move(__value);
    }
# 159 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_heap.h" 3
  template<typename _RandomAccessIterator>
    constexpr
    inline void
    push_heap(_RandomAccessIterator __first, _RandomAccessIterator __last)
    {
      typedef typename iterator_traits<_RandomAccessIterator>::value_type
   _ValueType;
      typedef typename iterator_traits<_RandomAccessIterator>::difference_type
   _DistanceType;


     

     
      ;
      ;
      ;

      __gnu_cxx::__ops::_Iter_less_val __comp;
      _ValueType __value = std::move(*(__last - 1));
      std::__push_heap(__first, _DistanceType((__last - __first) - 1),
         _DistanceType(0), std::move(__value), __comp);
    }
# 195 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_heap.h" 3
  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    inline void
    push_heap(_RandomAccessIterator __first, _RandomAccessIterator __last,
       _Compare __comp)
    {
      typedef typename iterator_traits<_RandomAccessIterator>::value_type
   _ValueType;
      typedef typename iterator_traits<_RandomAccessIterator>::difference_type
   _DistanceType;


     

      ;
      ;
      ;

      __decltype(__gnu_cxx::__ops::__iter_comp_val(std::move(__comp)))
 __cmp(std::move(__comp));
      _ValueType __value = std::move(*(__last - 1));
      std::__push_heap(__first, _DistanceType((__last - __first) - 1),
         _DistanceType(0), std::move(__value), __cmp);
    }

  template<typename _RandomAccessIterator, typename _Distance,
    typename _Tp, typename _Compare>
    constexpr
    void
    __adjust_heap(_RandomAccessIterator __first, _Distance __holeIndex,
    _Distance __len, _Tp __value, _Compare __comp)
    {
      const _Distance __topIndex = __holeIndex;
      _Distance __secondChild = __holeIndex;
      while (__secondChild < (__len - 1) / 2)
 {
   __secondChild = 2 * (__secondChild + 1);
   if (__comp(__first + __secondChild,
       __first + (__secondChild - 1)))
     __secondChild--;
   *(__first + __holeIndex) = std::move(*(__first + __secondChild));
   __holeIndex = __secondChild;
 }
      if ((__len & 1) == 0 && __secondChild == (__len - 2) / 2)
 {
   __secondChild = 2 * (__secondChild + 1);
   *(__first + __holeIndex) = std::move(*(__first + (__secondChild - 1)))
                                  ;
   __holeIndex = __secondChild - 1;
 }
      __decltype(__gnu_cxx::__ops::__iter_comp_val(std::move(__comp)))
 __cmp(std::move(__comp));
      std::__push_heap(__first, __holeIndex, __topIndex,
         std::move(__value), __cmp);
    }

  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    inline void
    __pop_heap(_RandomAccessIterator __first, _RandomAccessIterator __last,
        _RandomAccessIterator __result, _Compare& __comp)
    {
      typedef typename iterator_traits<_RandomAccessIterator>::value_type
 _ValueType;
      typedef typename iterator_traits<_RandomAccessIterator>::difference_type
 _DistanceType;

      _ValueType __value = std::move(*__result);
      *__result = std::move(*__first);
      std::__adjust_heap(__first, _DistanceType(0),
    _DistanceType(__last - __first),
    std::move(__value), __comp);
    }
# 280 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_heap.h" 3
  template<typename _RandomAccessIterator>
    constexpr
    inline void
    pop_heap(_RandomAccessIterator __first, _RandomAccessIterator __last)
    {

     

     

      do { if (__builtin_expect(!bool(__first != __last), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_heap.h", 290, __PRETTY_FUNCTION__, "__first != __last"); } while (false);
      ;
      ;
      ;

      if (__last - __first > 1)
 {
   --__last;
   __gnu_cxx::__ops::_Iter_less_iter __comp;
   std::__pop_heap(__first, __last, __last, __comp);
 }
    }
# 314 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_heap.h" 3
  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    inline void
    pop_heap(_RandomAccessIterator __first,
      _RandomAccessIterator __last, _Compare __comp)
    {

     

      ;
      ;
      do { if (__builtin_expect(!bool(__first != __last), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_heap.h", 325, __PRETTY_FUNCTION__, "__first != __last"); } while (false);
      ;

      if (__last - __first > 1)
 {
   typedef __decltype(__comp) _Cmp;
   __gnu_cxx::__ops::_Iter_comp_iter<_Cmp> __cmp(std::move(__comp));
   --__last;
   std::__pop_heap(__first, __last, __last, __cmp);
 }
    }

  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    void
    __make_heap(_RandomAccessIterator __first, _RandomAccessIterator __last,
  _Compare& __comp)
    {
      typedef typename iterator_traits<_RandomAccessIterator>::value_type
   _ValueType;
      typedef typename iterator_traits<_RandomAccessIterator>::difference_type
   _DistanceType;

      if (__last - __first < 2)
 return;

      const _DistanceType __len = __last - __first;
      _DistanceType __parent = (__len - 2) / 2;
      while (true)
 {
   _ValueType __value = std::move(*(__first + __parent));
   std::__adjust_heap(__first, __parent, __len, std::move(__value),
        __comp);
   if (__parent == 0)
     return;
   __parent--;
 }
    }
# 372 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_heap.h" 3
  template<typename _RandomAccessIterator>
    constexpr
    inline void
    make_heap(_RandomAccessIterator __first, _RandomAccessIterator __last)
    {

     

     

      ;
      ;

      __gnu_cxx::__ops::_Iter_less_iter __comp;
      std::__make_heap(__first, __last, __comp);
    }
# 399 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_heap.h" 3
  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    inline void
    make_heap(_RandomAccessIterator __first, _RandomAccessIterator __last,
       _Compare __comp)
    {

     

      ;
      ;

      typedef __decltype(__comp) _Cmp;
      __gnu_cxx::__ops::_Iter_comp_iter<_Cmp> __cmp(std::move(__comp));
      std::__make_heap(__first, __last, __cmp);
    }

  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    void
    __sort_heap(_RandomAccessIterator __first, _RandomAccessIterator __last,
  _Compare& __comp)
    {
      while (__last - __first > 1)
 {
   --__last;
   std::__pop_heap(__first, __last, __last, __comp);
 }
    }
# 437 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_heap.h" 3
  template<typename _RandomAccessIterator>
    constexpr
    inline void
    sort_heap(_RandomAccessIterator __first, _RandomAccessIterator __last)
    {

     

     

      ;
      ;
      ;

      __gnu_cxx::__ops::_Iter_less_iter __comp;
      std::__sort_heap(__first, __last, __comp);
    }
# 465 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_heap.h" 3
  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    inline void
    sort_heap(_RandomAccessIterator __first, _RandomAccessIterator __last,
       _Compare __comp)
    {

     

      ;
      ;
      ;

      typedef __decltype(__comp) _Cmp;
      __gnu_cxx::__ops::_Iter_comp_iter<_Cmp> __cmp(std::move(__comp));
      std::__sort_heap(__first, __last, __cmp);
    }
# 494 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_heap.h" 3
  template<typename _RandomAccessIterator>
    [[__nodiscard__]] constexpr
    inline _RandomAccessIterator
    is_heap_until(_RandomAccessIterator __first, _RandomAccessIterator __last)
    {

     

     

      ;
      ;

      __gnu_cxx::__ops::_Iter_less_iter __comp;
      return __first +
 std::__is_heap_until(__first, std::distance(__first, __last), __comp);
    }
# 523 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_heap.h" 3
  template<typename _RandomAccessIterator, typename _Compare>
    [[__nodiscard__]] constexpr
    inline _RandomAccessIterator
    is_heap_until(_RandomAccessIterator __first, _RandomAccessIterator __last,
    _Compare __comp)
    {

     

      ;
      ;

      typedef __decltype(__comp) _Cmp;
      __gnu_cxx::__ops::_Iter_comp_iter<_Cmp> __cmp(std::move(__comp));
      return __first
 + std::__is_heap_until(__first, std::distance(__first, __last), __cmp);
    }
# 548 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_heap.h" 3
  template<typename _RandomAccessIterator>
    [[__nodiscard__]] constexpr
    inline bool
    is_heap(_RandomAccessIterator __first, _RandomAccessIterator __last)
    { return std::is_heap_until(__first, __last) == __last; }
# 562 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_heap.h" 3
  template<typename _RandomAccessIterator, typename _Compare>
    [[__nodiscard__]] constexpr
    inline bool
    is_heap(_RandomAccessIterator __first, _RandomAccessIterator __last,
     _Compare __comp)
    {

     

      ;
      ;

      const auto __dist = std::distance(__first, __last);
      typedef __decltype(__comp) _Cmp;
      __gnu_cxx::__ops::_Iter_comp_iter<_Cmp> __cmp(std::move(__comp));
      return std::__is_heap_until(__first, __dist, __cmp) == __dist;
    }



}
# 62 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 2 3



# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/uniform_int_dist.h" 1 3
# 41 "C:/msys64/mingw64/include/c++/15.2.0/bits/uniform_int_dist.h" 3
namespace std
{

# 52 "C:/msys64/mingw64/include/c++/15.2.0/bits/uniform_int_dist.h" 3
  template<typename _Gen>
    concept uniform_random_bit_generator
      = invocable<_Gen&> && unsigned_integral<invoke_result_t<_Gen&>>
      && requires
      {
 { _Gen::min() } -> same_as<invoke_result_t<_Gen&>>;
 { _Gen::max() } -> same_as<invoke_result_t<_Gen&>>;
 requires bool_constant<(_Gen::min() < _Gen::max())>::value;
      };



  namespace __detail
  {



    template<typename _Tp>
      constexpr bool
      _Power_of_2(_Tp __x)
      {
 return ((__x - 1) & __x) == 0;
      }
  }
# 87 "C:/msys64/mingw64/include/c++/15.2.0/bits/uniform_int_dist.h" 3
  template<typename _IntType = int>
    class uniform_int_distribution
    {
      static_assert(std::is_integral<_IntType>::value,
      "template argument must be an integral type");

    public:

      typedef _IntType result_type;

      struct param_type
      {
 typedef uniform_int_distribution<_IntType> distribution_type;

 param_type() : param_type(0) { }

 explicit
 param_type(_IntType __a,
     _IntType __b = __gnu_cxx::__int_traits<_IntType>::__max)
 : _M_a(__a), _M_b(__b)
 {
   do { if (__builtin_expect(!bool(_M_a <= _M_b), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/uniform_int_dist.h", 108, __PRETTY_FUNCTION__, "_M_a <= _M_b"); } while (false);
 }

 result_type
 a() const
 { return _M_a; }

 result_type
 b() const
 { return _M_b; }

 friend bool
 operator==(const param_type& __p1, const param_type& __p2)
 { return __p1._M_a == __p2._M_a && __p1._M_b == __p2._M_b; }

 friend bool
 operator!=(const param_type& __p1, const param_type& __p2)
 { return !(__p1 == __p2); }

      private:
 _IntType _M_a;
 _IntType _M_b;
      };

    public:



      uniform_int_distribution() : uniform_int_distribution(0) { }




      explicit
      uniform_int_distribution(_IntType __a,
          _IntType __b
     = __gnu_cxx::__int_traits<_IntType>::__max)
      : _M_param(__a, __b)
      { }

      explicit
      uniform_int_distribution(const param_type& __p)
      : _M_param(__p)
      { }






      void
      reset() { }

      result_type
      a() const
      { return _M_param.a(); }

      result_type
      b() const
      { return _M_param.b(); }




      param_type
      param() const
      { return _M_param; }





      void
      param(const param_type& __param)
      { _M_param = __param; }




      result_type
      min() const
      { return this->a(); }




      result_type
      max() const
      { return this->b(); }




      template<typename _UniformRandomBitGenerator>
 result_type
 operator()(_UniformRandomBitGenerator& __urng)
        { return this->operator()(__urng, _M_param); }

      template<typename _UniformRandomBitGenerator>
 result_type
 operator()(_UniformRandomBitGenerator& __urng,
     const param_type& __p);

      template<typename _ForwardIterator,
        typename _UniformRandomBitGenerator>
 void
 __generate(_ForwardIterator __f, _ForwardIterator __t,
     _UniformRandomBitGenerator& __urng)
 { this->__generate(__f, __t, __urng, _M_param); }

      template<typename _ForwardIterator,
        typename _UniformRandomBitGenerator>
 void
 __generate(_ForwardIterator __f, _ForwardIterator __t,
     _UniformRandomBitGenerator& __urng,
     const param_type& __p)
 { this->__generate_impl(__f, __t, __urng, __p); }

      template<typename _UniformRandomBitGenerator>
 void
 __generate(result_type* __f, result_type* __t,
     _UniformRandomBitGenerator& __urng,
     const param_type& __p)
 { this->__generate_impl(__f, __t, __urng, __p); }





      friend bool
      operator==(const uniform_int_distribution& __d1,
   const uniform_int_distribution& __d2)
      { return __d1._M_param == __d2._M_param; }

    private:
      template<typename _ForwardIterator,
        typename _UniformRandomBitGenerator>
 void
 __generate_impl(_ForwardIterator __f, _ForwardIterator __t,
   _UniformRandomBitGenerator& __urng,
   const param_type& __p);

      param_type _M_param;




      template<typename _Wp, typename _Urbg, typename _Up>
 static _Up
 _S_nd(_Urbg& __g, _Up __range)
 {
   using _Up_traits = __gnu_cxx::__int_traits<_Up>;
   using _Wp_traits = __gnu_cxx::__int_traits<_Wp>;
   static_assert(!_Up_traits::__is_signed, "U must be unsigned");
   static_assert(!_Wp_traits::__is_signed, "W must be unsigned");
   static_assert(_Wp_traits::__digits == (2 * _Up_traits::__digits),
   "W must be twice as wide as U");




   _Wp __product = _Wp(__g()) * _Wp(__range);
   _Up __low = _Up(__product);
   if (__low < __range)
     {
       _Up __threshold = -__range % __range;
       while (__low < __threshold)
  {
    __product = _Wp(__g()) * _Wp(__range);
    __low = _Up(__product);
  }
     }
   return __product >> _Up_traits::__digits;
 }
    };

  template<typename _IntType>
    template<typename _UniformRandomBitGenerator>
      typename uniform_int_distribution<_IntType>::result_type
      uniform_int_distribution<_IntType>::
      operator()(_UniformRandomBitGenerator& __urng,
   const param_type& __param)
      {
 typedef typename _UniformRandomBitGenerator::result_type _Gresult_type;
 typedef typename make_unsigned<result_type>::type __utype;
 typedef typename common_type<_Gresult_type, __utype>::type __uctype;

 constexpr __uctype __urngmin = _UniformRandomBitGenerator::min();
 constexpr __uctype __urngmax = _UniformRandomBitGenerator::max();
 static_assert( __urngmin < __urngmax,
     "Uniform random bit generator must define min() < max()");
 constexpr __uctype __urngrange = __urngmax - __urngmin;

 const __uctype __urange
   = __uctype(__param.b()) - __uctype(__param.a());

 __uctype __ret;
 if (__urngrange > __urange)
   {


     const __uctype __uerange = __urange + 1;



     if constexpr (__urngrange == 0xffffffffffffffffULL)
       {


  long long unsigned int __u64erange = __uerange;
  __ret = __extension__ _S_nd<unsigned __int128>(__urng,
              __u64erange);
       }
     else

     if constexpr (__urngrange == 0xffffffffU)
       {


  unsigned int __u32erange = __uerange;
  __ret = _S_nd<long long unsigned int>(__urng, __u32erange);
       }
     else

       {

  const __uctype __scaling = __urngrange / __uerange;
  const __uctype __past = __uerange * __scaling;
  do
    __ret = __uctype(__urng()) - __urngmin;
  while (__ret >= __past);
  __ret /= __scaling;
       }
   }
 else if (__urngrange < __urange)
   {
# 359 "C:/msys64/mingw64/include/c++/15.2.0/bits/uniform_int_dist.h" 3
     __uctype __tmp;
     do
       {
  const __uctype __uerngrange = __urngrange + 1;
  __tmp = (__uerngrange * operator()
    (__urng, param_type(0, __urange / __uerngrange)));
  __ret = __tmp + (__uctype(__urng()) - __urngmin);
       }
     while (__ret > __urange || __ret < __tmp);
   }
 else
   __ret = __uctype(__urng()) - __urngmin;

 return __ret + __param.a();
      }


  template<typename _IntType>
    template<typename _ForwardIterator,
      typename _UniformRandomBitGenerator>
      void
      uniform_int_distribution<_IntType>::
      __generate_impl(_ForwardIterator __f, _ForwardIterator __t,
        _UniformRandomBitGenerator& __urng,
        const param_type& __param)
      {

 typedef typename _UniformRandomBitGenerator::result_type _Gresult_type;
 typedef typename make_unsigned<result_type>::type __utype;
 typedef typename common_type<_Gresult_type, __utype>::type __uctype;

 static_assert( __urng.min() < __urng.max(),
     "Uniform random bit generator must define min() < max()");

 constexpr __uctype __urngmin = __urng.min();
 constexpr __uctype __urngmax = __urng.max();
 constexpr __uctype __urngrange = __urngmax - __urngmin;
 const __uctype __urange
   = __uctype(__param.b()) - __uctype(__param.a());

 __uctype __ret;

 if (__urngrange > __urange)
   {
     if (__detail::_Power_of_2(__urngrange + 1)
  && __detail::_Power_of_2(__urange + 1))
       {
  while (__f != __t)
    {
      __ret = __uctype(__urng()) - __urngmin;
      *__f++ = (__ret & __urange) + __param.a();
    }
       }
     else
       {

  const __uctype __uerange = __urange + 1;
  const __uctype __scaling = __urngrange / __uerange;
  const __uctype __past = __uerange * __scaling;
  while (__f != __t)
    {
      do
        __ret = __uctype(__urng()) - __urngmin;
      while (__ret >= __past);
      *__f++ = __ret / __scaling + __param.a();
    }
       }
   }
 else if (__urngrange < __urange)
   {
# 444 "C:/msys64/mingw64/include/c++/15.2.0/bits/uniform_int_dist.h" 3
     __uctype __tmp;
     while (__f != __t)
       {
  do
    {
      constexpr __uctype __uerngrange = __urngrange + 1;
      __tmp = (__uerngrange * operator()
        (__urng, param_type(0, __urange / __uerngrange)));
      __ret = __tmp + (__uctype(__urng()) - __urngmin);
    }
  while (__ret > __urange || __ret < __tmp);
  *__f++ = __ret;
       }
   }
 else
   while (__f != __t)
     *__f++ = __uctype(__urng()) - __urngmin + __param.a();
      }




}
# 66 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 2 3



# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_tempbuf.h" 1 3
# 65 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_tempbuf.h" 3
namespace std
{

# 77 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_tempbuf.h" 3
  namespace __detail
  {


    template<typename _Tp>
      inline _Tp*
      __get_temporary_buffer(ptrdiff_t __len) noexcept
      {
 if (__builtin_expect(size_t(__len) > (size_t(-1) / sizeof(_Tp)), 0))
   return 0;


 if (alignof(_Tp) > 16)
   return (_Tp*) __builtin_operator_new(__len * sizeof(_Tp),
           align_val_t(alignof(_Tp)),
           nothrow_t());

 return (_Tp*) __builtin_operator_new(__len * sizeof(_Tp), nothrow_t());
      }



    template<typename _Tp>
      inline void
      __return_temporary_buffer(_Tp* __p,
    size_t __len __attribute__((__unused__)))
      {







 if (alignof(_Tp) > 16)
   {
     __builtin_operator_delete((__p), (__len) * sizeof(_Tp),
         align_val_t(alignof(_Tp)));
     return;
   }

 __builtin_operator_delete((__p), (__len) * sizeof(_Tp));
      }

  }
# 140 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_tempbuf.h" 3
  template<typename _Tp>
    [[__deprecated__]]
    pair<_Tp*, ptrdiff_t>
    get_temporary_buffer(ptrdiff_t __len) noexcept
    {
      const ptrdiff_t __max =
 __gnu_cxx::__numeric_traits<ptrdiff_t>::__max / sizeof(_Tp);
      if (__len > __max)
 __len = __max;

      while (__len > 0)
 {
   if (_Tp* __tmp = __detail::__get_temporary_buffer<_Tp>(__len))
     return pair<_Tp*, ptrdiff_t>(__tmp, __len);
   __len = __len == 1 ? 0 : ((__len + 1) / 2);
 }
      return pair<_Tp*, ptrdiff_t>();
    }
# 166 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_tempbuf.h" 3
  template<typename _Tp>
    [[__deprecated__]]
    inline void
    return_temporary_buffer(_Tp* __p)
    {

      if (alignof(_Tp) > 16)
 __builtin_operator_delete(__p, align_val_t(alignof(_Tp)));
      else

      __builtin_operator_delete(__p);
    }
# 187 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_tempbuf.h" 3
  template<typename _ForwardIterator, typename _Tp>
    class _Temporary_buffer
    {

     

    public:
      typedef _Tp value_type;
      typedef value_type* pointer;
      typedef pointer iterator;
      typedef ptrdiff_t size_type;

    protected:
      size_type _M_original_len;
      struct _Impl
      {
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wdeprecated-declarations"
 explicit
 _Impl(ptrdiff_t __original_len)
 {
   pair<pointer, size_type> __p(
     std::get_temporary_buffer<value_type>(__original_len));
   _M_len = __p.second;
   _M_buffer = __p.first;
 }
#pragma GCC diagnostic pop

 ~_Impl()
 { std::__detail::__return_temporary_buffer(_M_buffer, _M_len); }

 size_type _M_len;
 pointer _M_buffer;
      } _M_impl;

    public:

      size_type
      size() const
      { return _M_impl._M_len; }


      size_type
      requested_size() const
      { return _M_original_len; }


      iterator
      begin()
      { return _M_impl._M_buffer; }


      iterator
      end()
      { return _M_impl._M_buffer + _M_impl._M_len; }





      _Temporary_buffer(_ForwardIterator __seed, size_type __original_len);

      ~_Temporary_buffer()
      { std::_Destroy(_M_impl._M_buffer, _M_impl._M_buffer + _M_impl._M_len); }

    private:

      _Temporary_buffer(const _Temporary_buffer&);

      void
      operator=(const _Temporary_buffer&);
    };


  template<bool>
    struct __uninitialized_construct_buf_dispatch
    {
      template<typename _Pointer, typename _ForwardIterator>
        static void
        __ucr(_Pointer __first, _Pointer __last,
       _ForwardIterator __seed)
        {
   if (__builtin_expect(__first == __last, 0))
     return;

   _Pointer __cur = __first;
   try
     {
       std::_Construct(std::__addressof(*__first),
         std::move(*__seed));
       _Pointer __prev = __cur;
       ++__cur;
       for(; __cur != __last; ++__cur, ++__prev)
  std::_Construct(std::__addressof(*__cur),
    std::move(*__prev));
       *__seed = std::move(*__prev);
     }
   catch(...)
     {
       std::_Destroy(__first, __cur);
       throw;
     }
 }
    };

  template<>
    struct __uninitialized_construct_buf_dispatch<true>
    {
      template<typename _Pointer, typename _ForwardIterator>
        static void
        __ucr(_Pointer, _Pointer, _ForwardIterator) { }
    };
# 311 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_tempbuf.h" 3
  template<typename _Tp, typename _ForwardIterator>
    inline void
    __uninitialized_construct_buf(_Tp* __first, _Tp* __last,
      _ForwardIterator __seed)
    {
      std::__uninitialized_construct_buf_dispatch<
 __has_trivial_constructor(_Tp)>::
   __ucr(__first, __last, __seed);
    }

  template<typename _ForwardIterator, typename _Tp>
    _Temporary_buffer<_ForwardIterator, _Tp>::
    _Temporary_buffer(_ForwardIterator __seed, size_type __original_len)
    : _M_original_len(__original_len), _M_impl(__original_len)
    {
      std::__uninitialized_construct_buf(begin(), end(), __seed);
    }


}
# 70 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 2 3





#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wc++11-extensions"



namespace std
{



  template<typename _Iterator, typename _Compare>
    constexpr
    void
    __move_median_to_first(_Iterator __result,_Iterator __a, _Iterator __b,
      _Iterator __c, _Compare __comp)
    {
      if (__comp(__a, __b))
 {
   if (__comp(__b, __c))
     std::iter_swap(__result, __b);
   else if (__comp(__a, __c))
     std::iter_swap(__result, __c);
   else
     std::iter_swap(__result, __a);
 }
      else if (__comp(__a, __c))
 std::iter_swap(__result, __a);
      else if (__comp(__b, __c))
 std::iter_swap(__result, __c);
      else
 std::iter_swap(__result, __b);
    }


  template<typename _InputIterator, typename _Predicate>
    constexpr
    inline _InputIterator
    __find_if_not(_InputIterator __first, _InputIterator __last,
    _Predicate __pred)
    {
      return std::__find_if(__first, __last,
       __gnu_cxx::__ops::__negate(__pred));
    }




  template<typename _InputIterator, typename _Predicate, typename _Distance>
    constexpr
    _InputIterator
    __find_if_not_n(_InputIterator __first, _Distance& __len, _Predicate __pred)
    {
      for (; __len; --__len, (void) ++__first)
 if (!__pred(__first))
   break;
      return __first;
    }
# 150 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Integer,
    typename _UnaryPredicate>
    constexpr
    _ForwardIterator
    __search_n_aux(_ForwardIterator __first, _ForwardIterator __last,
     _Integer __count, _UnaryPredicate __unary_pred,
     std::forward_iterator_tag)
    {
      __first = std::__find_if(__first, __last, __unary_pred);
      while (__first != __last)
 {
   typename iterator_traits<_ForwardIterator>::difference_type
     __n = __count;
   _ForwardIterator __i = __first;
   ++__i;
   while (__i != __last && __n != 1 && __unary_pred(__i))
     {
       ++__i;
       --__n;
     }
   if (__n == 1)
     return __first;
   if (__i == __last)
     return __last;
   __first = std::__find_if(++__i, __last, __unary_pred);
 }
      return __last;
    }





  template<typename _RandomAccessIter, typename _Integer,
    typename _UnaryPredicate>
    constexpr
    _RandomAccessIter
    __search_n_aux(_RandomAccessIter __first, _RandomAccessIter __last,
     _Integer __count, _UnaryPredicate __unary_pred,
     std::random_access_iterator_tag)
    {
      typedef typename std::iterator_traits<_RandomAccessIter>::difference_type
 _DistanceType;

      _DistanceType __tailSize = __last - __first;
      _DistanceType __remainder = __count;

      while (__remainder <= __tailSize)
 {
   __first += __remainder;
   __tailSize -= __remainder;


   _RandomAccessIter __backTrack = __first;
   while (__unary_pred(--__backTrack))
     {
       if (--__remainder == 0)
  return (__first - __count);
     }
   __remainder = __count + 1 - (__first - __backTrack);
 }
      return __last;
    }

  template<typename _ForwardIterator, typename _Integer,
    typename _UnaryPredicate>
    constexpr
    _ForwardIterator
    __search_n(_ForwardIterator __first, _ForwardIterator __last,
        _Integer __count,
        _UnaryPredicate __unary_pred)
    {
      if (__count <= 0)
 return __first;

      if (__count == 1)
 return std::__find_if(__first, __last, __unary_pred);

      return std::__search_n_aux(__first, __last, __count, __unary_pred,
     std::__iterator_category(__first));
    }


  template<typename _ForwardIterator1, typename _ForwardIterator2,
    typename _BinaryPredicate>
    constexpr
    _ForwardIterator1
    __find_end(_ForwardIterator1 __first1, _ForwardIterator1 __last1,
        _ForwardIterator2 __first2, _ForwardIterator2 __last2,
        forward_iterator_tag, forward_iterator_tag,
        _BinaryPredicate __comp)
    {
      if (__first2 == __last2)
 return __last1;

      _ForwardIterator1 __result = __last1;
      while (1)
 {
   _ForwardIterator1 __new_result
     = std::__search(__first1, __last1, __first2, __last2, __comp);
   if (__new_result == __last1)
     return __result;
   else
     {
       __result = __new_result;
       __first1 = __new_result;
       ++__first1;
     }
 }
    }


  template<typename _BidirectionalIterator1, typename _BidirectionalIterator2,
    typename _BinaryPredicate>
    constexpr
    _BidirectionalIterator1
    __find_end(_BidirectionalIterator1 __first1,
        _BidirectionalIterator1 __last1,
        _BidirectionalIterator2 __first2,
        _BidirectionalIterator2 __last2,
        bidirectional_iterator_tag, bidirectional_iterator_tag,
        _BinaryPredicate __comp)
    {

     

     


      typedef reverse_iterator<_BidirectionalIterator1> _RevIterator1;
      typedef reverse_iterator<_BidirectionalIterator2> _RevIterator2;

      _RevIterator1 __rlast1(__first1);
      _RevIterator2 __rlast2(__first2);
      _RevIterator1 __rresult = std::__search(_RevIterator1(__last1), __rlast1,
           _RevIterator2(__last2), __rlast2,
           __comp);

      if (__rresult == __rlast1)
 return __last1;
      else
 {
   _BidirectionalIterator1 __result = __rresult.base();
   std::advance(__result, -std::distance(__first2, __last2));
   return __result;
 }
    }
# 324 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator1, typename _ForwardIterator2>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator1
    find_end(_ForwardIterator1 __first1, _ForwardIterator1 __last1,
      _ForwardIterator2 __first2, _ForwardIterator2 __last2)
    {

     
     
     


      ;
      ;

      return std::__find_end(__first1, __last1, __first2, __last2,
        std::__iterator_category(__first1),
        std::__iterator_category(__first2),
        __gnu_cxx::__ops::__iter_equal_to_iter());
    }
# 373 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator1, typename _ForwardIterator2,
    typename _BinaryPredicate>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator1
    find_end(_ForwardIterator1 __first1, _ForwardIterator1 __last1,
      _ForwardIterator2 __first2, _ForwardIterator2 __last2,
      _BinaryPredicate __comp)
    {

     
     
     


      ;
      ;

      return std::__find_end(__first1, __last1, __first2, __last2,
        std::__iterator_category(__first1),
        std::__iterator_category(__first2),
        __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }
# 409 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _Predicate>
    [[__nodiscard__]] constexpr
    inline bool
    all_of(_InputIterator __first, _InputIterator __last, _Predicate __pred)
    { return __last == std::find_if_not(__first, __last, __pred); }
# 427 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _Predicate>
    [[__nodiscard__]] constexpr
    inline bool
    none_of(_InputIterator __first, _InputIterator __last, _Predicate __pred)
    { return __last == std::find_if(__first, __last, __pred); }
# 446 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _Predicate>
    [[__nodiscard__]] constexpr
    inline bool
    any_of(_InputIterator __first, _InputIterator __last, _Predicate __pred)
    { return !std::none_of(__first, __last, __pred); }
# 462 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _Predicate>
    [[__nodiscard__]] constexpr
    inline _InputIterator
    find_if_not(_InputIterator __first, _InputIterator __last,
  _Predicate __pred)
    {

     
     

      ;
      return std::__find_if_not(__first, __last,
    __gnu_cxx::__ops::__pred_iter(__pred));
    }
# 487 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _Predicate>
    [[__nodiscard__]] constexpr
    inline bool
    is_partitioned(_InputIterator __first, _InputIterator __last,
     _Predicate __pred)
    {
      __first = std::find_if_not(__first, __last, __pred);
      if (__first == __last)
 return true;
      ++__first;
      return std::none_of(__first, __last, __pred);
    }
# 509 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Predicate>
    [[__nodiscard__]] constexpr
    _ForwardIterator
    partition_point(_ForwardIterator __first, _ForwardIterator __last,
      _Predicate __pred)
    {

     
     



      ;

      typedef typename iterator_traits<_ForwardIterator>::difference_type
 _DistanceType;

      _DistanceType __len = std::distance(__first, __last);

      while (__len > 0)
 {
   _DistanceType __half = __len >> 1;
   _ForwardIterator __middle = __first;
   std::advance(__middle, __half);
   if (__pred(*__middle))
     {
       __first = __middle;
       ++__first;
       __len = __len - __half - 1;
     }
   else
     __len = __half;
 }
      return __first;
    }


  template<typename _InputIterator, typename _OutputIterator,
    typename _Predicate>
    constexpr
    _OutputIterator
    __remove_copy_if(_InputIterator __first, _InputIterator __last,
       _OutputIterator __result, _Predicate __pred)
    {
      for (; __first != __last; ++__first)
 if (!__pred(__first))
   {
     *__result = *__first;
     ++__result;
   }
      return __result;
    }
# 576 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _OutputIterator, typename _Tp>
    constexpr
    inline _OutputIterator
    remove_copy(_InputIterator __first, _InputIterator __last,
  _OutputIterator __result, const _Tp& __value)
    {

     
     

     

      ;

      return std::__remove_copy_if(__first, __last, __result,
 __gnu_cxx::__ops::__iter_equals_val(__value));
    }
# 609 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _OutputIterator,
    typename _Predicate>
    constexpr
    inline _OutputIterator
    remove_copy_if(_InputIterator __first, _InputIterator __last,
     _OutputIterator __result, _Predicate __pred)
    {

     
     

     

      ;

      return std::__remove_copy_if(__first, __last, __result,
       __gnu_cxx::__ops::__pred_iter(__pred));
    }
# 644 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _OutputIterator,
    typename _Predicate>
    constexpr
    _OutputIterator
    copy_if(_InputIterator __first, _InputIterator __last,
     _OutputIterator __result, _Predicate __pred)
    {

     
     

     

      ;

      for (; __first != __last; ++__first)
 if (__pred(*__first))
   {
     *__result = *__first;
     ++__result;
   }
      return __result;
    }
# 681 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _Size, typename _OutputIterator>
    constexpr
    inline _OutputIterator
    copy_n(_InputIterator __first, _Size __n, _OutputIterator __result)
    {

     
     


      const auto __n2 = std::__size_to_integer(__n);
      if (__n2 <= 0)
 return __result;

      ;
      ;

      auto __res = std::__copy_n_a(std::__niter_base(__first), __n2,
       std::__niter_base(__result), true);
      return std::__niter_wrap(__result, std::move(__res));
    }
# 718 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _OutputIterator1,
    typename _OutputIterator2, typename _Predicate>
    constexpr
    pair<_OutputIterator1, _OutputIterator2>
    partition_copy(_InputIterator __first, _InputIterator __last,
     _OutputIterator1 __out_true, _OutputIterator2 __out_false,
     _Predicate __pred)
    {

     
     

     

     

      ;

      for (; __first != __last; ++__first)
 if (__pred(*__first))
   {
     *__out_true = *__first;
     ++__out_true;
   }
 else
   {
     *__out_false = *__first;
     ++__out_false;
   }

      return pair<_OutputIterator1, _OutputIterator2>(__out_true, __out_false);
    }
# 769 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Tp>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator
    remove(_ForwardIterator __first, _ForwardIterator __last,
    const _Tp& __value)
    {

     

     

      ;

      return std::__remove_if(__first, __last,
  __gnu_cxx::__ops::__iter_equals_val(__value));
    }
# 803 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Predicate>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator
    remove_if(_ForwardIterator __first, _ForwardIterator __last,
       _Predicate __pred)
    {

     

     

      ;

      return std::__remove_if(__first, __last,
         __gnu_cxx::__ops::__pred_iter(__pred));
    }

  template<typename _ForwardIterator, typename _BinaryPredicate>
    constexpr
    _ForwardIterator
    __adjacent_find(_ForwardIterator __first, _ForwardIterator __last,
      _BinaryPredicate __binary_pred)
    {
      if (__first == __last)
 return __last;
      _ForwardIterator __next = __first;
      while (++__next != __last)
 {
   if (__binary_pred(__first, __next))
     return __first;
   __first = __next;
 }
      return __last;
    }

  template<typename _ForwardIterator, typename _BinaryPredicate>
    constexpr
    _ForwardIterator
    __unique(_ForwardIterator __first, _ForwardIterator __last,
      _BinaryPredicate __binary_pred)
    {

      __first = std::__adjacent_find(__first, __last, __binary_pred);
      if (__first == __last)
 return __last;


      _ForwardIterator __dest = __first;
      ++__first;
      while (++__first != __last)
 if (!__binary_pred(__dest, __first))
   *++__dest = std::move(*__first);
      return ++__dest;
    }
# 872 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator
    unique(_ForwardIterator __first, _ForwardIterator __last)
    {

     

     

      ;

      return std::__unique(__first, __last,
      __gnu_cxx::__ops::__iter_equal_to_iter());
    }
# 903 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _BinaryPredicate>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator
    unique(_ForwardIterator __first, _ForwardIterator __last,
    _BinaryPredicate __binary_pred)
    {

     

     


      ;

      return std::__unique(__first, __last,
      __gnu_cxx::__ops::__iter_comp_iter(__binary_pred));
    }







  template<typename _ForwardIterator, typename _OutputIterator,
    typename _BinaryPredicate>
    constexpr
    _OutputIterator
    __unique_copy(_ForwardIterator __first, _ForwardIterator __last,
    _OutputIterator __result, _BinaryPredicate __binary_pred,
    forward_iterator_tag, output_iterator_tag)
    {

     



      _ForwardIterator __next = __first;
      *__result = *__first;
      while (++__next != __last)
 if (!__binary_pred(__first, __next))
   {
     __first = __next;
     *++__result = *__first;
   }
      return ++__result;
    }







  template<typename _InputIterator, typename _OutputIterator,
    typename _BinaryPredicate>
    constexpr
    _OutputIterator
    __unique_copy(_InputIterator __first, _InputIterator __last,
    _OutputIterator __result, _BinaryPredicate __binary_pred,
    input_iterator_tag, output_iterator_tag)
    {

     



      typename iterator_traits<_InputIterator>::value_type __value = *__first;
      __decltype(__gnu_cxx::__ops::__iter_comp_val(__binary_pred))
 __rebound_pred
 = __gnu_cxx::__ops::__iter_comp_val(__binary_pred);
      *__result = __value;
      while (++__first != __last)
 if (!__rebound_pred(__first, __value))
   {
     __value = *__first;
     *++__result = __value;
   }
      return ++__result;
    }







  template<typename _InputIterator, typename _ForwardIterator,
    typename _BinaryPredicate>
    constexpr
    _ForwardIterator
    __unique_copy(_InputIterator __first, _InputIterator __last,
    _ForwardIterator __result, _BinaryPredicate __binary_pred,
    input_iterator_tag, forward_iterator_tag)
    {

     


      *__result = *__first;
      while (++__first != __last)
 if (!__binary_pred(__result, __first))
   *++__result = *__first;
      return ++__result;
    }






  template<typename _BidirectionalIterator>
    constexpr
    void
    __reverse(_BidirectionalIterator __first, _BidirectionalIterator __last,
       bidirectional_iterator_tag)
    {
      while (true)
 if (__first == __last || __first == --__last)
   return;
 else
   {
     std::iter_swap(__first, __last);
     ++__first;
   }
    }






  template<typename _RandomAccessIterator>
    constexpr
    void
    __reverse(_RandomAccessIterator __first, _RandomAccessIterator __last,
       random_access_iterator_tag)
    {
      if (__first == __last)
 return;
      --__last;
      while (__first < __last)
 {
   std::iter_swap(__first, __last);
   ++__first;
   --__last;
 }
    }
# 1064 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _BidirectionalIterator>
    constexpr
    inline void
    reverse(_BidirectionalIterator __first, _BidirectionalIterator __last)
    {

     

      ;
      std::__reverse(__first, __last, std::__iterator_category(__first));
    }
# 1092 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _BidirectionalIterator, typename _OutputIterator>
    constexpr
    _OutputIterator
    reverse_copy(_BidirectionalIterator __first, _BidirectionalIterator __last,
   _OutputIterator __result)
    {

     

     

      ;

      while (__first != __last)
 {
   --__last;
   *__result = *__last;
   ++__result;
 }
      return __result;
    }





  template<typename _EuclideanRingElement>
    constexpr
    _EuclideanRingElement
    __gcd(_EuclideanRingElement __m, _EuclideanRingElement __n)
    {
      while (__n != 0)
 {
   _EuclideanRingElement __t = __m % __n;
   __m = __n;
   __n = __t;
 }
      return __m;
    }

inline namespace _V2 {


  template<typename _ForwardIterator>
    constexpr
    _ForwardIterator
    __rotate(_ForwardIterator __first,
      _ForwardIterator __middle,
      _ForwardIterator __last,
      forward_iterator_tag)
    {
      if (__first == __middle)
 return __last;
      else if (__last == __middle)
 return __first;

      _ForwardIterator __first2 = __middle;
      do
 {
   std::iter_swap(__first, __first2);
   ++__first;
   ++__first2;
   if (__first == __middle)
     __middle = __first2;
 }
      while (__first2 != __last);

      _ForwardIterator __ret = __first;

      __first2 = __middle;

      while (__first2 != __last)
 {
   std::iter_swap(__first, __first2);
   ++__first;
   ++__first2;
   if (__first == __middle)
     __middle = __first2;
   else if (__first2 == __last)
     __first2 = __middle;
 }
      return __ret;
    }


  template<typename _BidirectionalIterator>
    constexpr
    _BidirectionalIterator
    __rotate(_BidirectionalIterator __first,
      _BidirectionalIterator __middle,
      _BidirectionalIterator __last,
       bidirectional_iterator_tag)
    {

     


      if (__first == __middle)
 return __last;
      else if (__last == __middle)
 return __first;

      std::__reverse(__first, __middle, bidirectional_iterator_tag());
      std::__reverse(__middle, __last, bidirectional_iterator_tag());

      while (__first != __middle && __middle != __last)
 {
   std::iter_swap(__first, --__last);
   ++__first;
 }

      if (__first == __middle)
 {
   std::__reverse(__middle, __last, bidirectional_iterator_tag());
   return __last;
 }
      else
 {
   std::__reverse(__first, __middle, bidirectional_iterator_tag());
   return __first;
 }
    }


  template<typename _RandomAccessIterator>
    constexpr
    _RandomAccessIterator
    __rotate(_RandomAccessIterator __first,
      _RandomAccessIterator __middle,
      _RandomAccessIterator __last,
      random_access_iterator_tag)
    {

     


      if (__first == __middle)
 return __last;
      else if (__last == __middle)
 return __first;

      typedef typename iterator_traits<_RandomAccessIterator>::difference_type
 _Distance;
      typedef typename iterator_traits<_RandomAccessIterator>::value_type
 _ValueType;


      typedef typename make_unsigned<_Distance>::type _UDistance;




      _Distance __n = __last - __first;
      _Distance __k = __middle - __first;

      if (__k == __n - __k)
 {
   std::swap_ranges(__first, __middle, __middle);
   return __middle;
 }

      _RandomAccessIterator __p = __first;
      _RandomAccessIterator __ret = __first + (__last - __middle);

      for (;;)
 {
   if (__k < __n - __k)
     {
       if (__is_pod(_ValueType) && __k == 1)
  {
    _ValueType __t = std::move(*__p);
    std::move(__p + 1, __p + __n, __p);
    *(__p + __n - 1) = std::move(__t);
    return __ret;
  }
       _RandomAccessIterator __q = __p + __k;
       for (_Distance __i = 0; __i < __n - __k; ++ __i)
  {
    std::iter_swap(__p, __q);
    ++__p;
    ++__q;
  }
       __n = static_cast<_UDistance>(__n) % static_cast<_UDistance>(__k);
       if (__n == 0)
  return __ret;
       std::swap(__n, __k);
       __k = __n - __k;
     }
   else
     {
       __k = __n - __k;
       if (__is_pod(_ValueType) && __k == 1)
  {
    _ValueType __t = std::move(*(__p + __n - 1));
    std::move_backward(__p, __p + __n - 1, __p + __n);
    *__p = std::move(__t);
    return __ret;
  }
       _RandomAccessIterator __q = __p + __n;
       __p = __q - __k;
       for (_Distance __i = 0; __i < __n - __k; ++ __i)
  {
    --__p;
    --__q;
    std::iter_swap(__p, __q);
  }
       __n = static_cast<_UDistance>(__n) % static_cast<_UDistance>(__k);
       if (__n == 0)
  return __ret;
       std::swap(__n, __k);
     }
 }
    }
# 1329 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator>
    constexpr
    inline _ForwardIterator
    rotate(_ForwardIterator __first, _ForwardIterator __middle,
    _ForwardIterator __last)
    {

     

      ;
      ;

      return std::__rotate(__first, __middle, __last,
      std::__iterator_category(__first));
    }

}
# 1367 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _OutputIterator>
    constexpr
    inline _OutputIterator
    rotate_copy(_ForwardIterator __first, _ForwardIterator __middle,
  _ForwardIterator __last, _OutputIterator __result)
    {

     
     

      ;
      ;

      return std::copy(__first, __middle,
         std::copy(__middle, __last, __result));
    }


  template<typename _ForwardIterator, typename _Predicate>
    constexpr
    _ForwardIterator
    __partition(_ForwardIterator __first, _ForwardIterator __last,
  _Predicate __pred, forward_iterator_tag)
    {
      if (__first == __last)
 return __first;

      while (__pred(*__first))
 if (++__first == __last)
   return __first;

      _ForwardIterator __next = __first;

      while (++__next != __last)
 if (__pred(*__next))
   {
     std::iter_swap(__first, __next);
     ++__first;
   }

      return __first;
    }


  template<typename _BidirectionalIterator, typename _Predicate>
    constexpr
    _BidirectionalIterator
    __partition(_BidirectionalIterator __first, _BidirectionalIterator __last,
  _Predicate __pred, bidirectional_iterator_tag)
    {
      while (true)
 {
   while (true)
     if (__first == __last)
       return __first;
     else if (__pred(*__first))
       ++__first;
     else
       break;
   --__last;
   while (true)
     if (__first == __last)
       return __first;
     else if (!bool(__pred(*__last)))
       --__last;
     else
       break;
   std::iter_swap(__first, __last);
   ++__first;
 }
    }
# 1448 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Pointer, typename _Predicate,
    typename _Distance>
   
    _ForwardIterator
    __stable_partition_adaptive(_ForwardIterator __first,
    _ForwardIterator __last,
    _Predicate __pred, _Distance __len,
    _Pointer __buffer,
    _Distance __buffer_size)
    {
      if (__len == 1)
 return __first;

      if (__len <= __buffer_size)
 {
   _ForwardIterator __result1 = __first;
   _Pointer __result2 = __buffer;




   *__result2 = std::move(*__first);
   ++__result2;
   ++__first;
   for (; __first != __last; ++__first)
     if (__pred(__first))
       {
  *__result1 = std::move(*__first);
  ++__result1;
       }
     else
       {
  *__result2 = std::move(*__first);
  ++__result2;
       }

   std::move(__buffer, __result2, __result1);
   return __result1;
 }

      _ForwardIterator __middle = __first;
      std::advance(__middle, __len / 2);
      _ForwardIterator __left_split =
 std::__stable_partition_adaptive(__first, __middle, __pred,
      __len / 2, __buffer,
      __buffer_size);



      _Distance __right_len = __len - __len / 2;
      _ForwardIterator __right_split =
 std::__find_if_not_n(__middle, __right_len, __pred);

      if (__right_len)
 __right_split =
   std::__stable_partition_adaptive(__right_split, __last, __pred,
        __right_len,
        __buffer, __buffer_size);

      return std::rotate(__left_split, __middle, __right_split);
    }

  template<typename _ForwardIterator, typename _Predicate>
   
    _ForwardIterator
    __stable_partition(_ForwardIterator __first, _ForwardIterator __last,
         _Predicate __pred)
    {
      __first = std::__find_if_not(__first, __last, __pred);

      if (__first == __last)
 return __first;

      typedef typename iterator_traits<_ForwardIterator>::value_type
 _ValueType;
      typedef typename iterator_traits<_ForwardIterator>::difference_type
 _DistanceType;

      const _DistanceType __len = std::distance(__first, __last);
# 1540 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
      _Temporary_buffer<_ForwardIterator, _ValueType>
 __buf(__first, __len);
      return
 std::__stable_partition_adaptive(__first, __last, __pred,
      __len,
      __buf.begin(),
      _DistanceType(__buf.size()));
    }
# 1566 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Predicate>
   
    inline _ForwardIterator
    stable_partition(_ForwardIterator __first, _ForwardIterator __last,
       _Predicate __pred)
    {

     

     

      ;

      return std::__stable_partition(__first, __last,
         __gnu_cxx::__ops::__pred_iter(__pred));
    }





  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    void
    __heap_select(_RandomAccessIterator __first,
    _RandomAccessIterator __middle,
    _RandomAccessIterator __last, _Compare __comp)
    {
      std::__make_heap(__first, __middle, __comp);
      for (_RandomAccessIterator __i = __middle; __i < __last; ++__i)
 if (__comp(__i, __first))
   std::__pop_heap(__first, __middle, __i, __comp);
    }



  template<typename _InputIterator, typename _RandomAccessIterator,
    typename _Compare>
    constexpr
    _RandomAccessIterator
    __partial_sort_copy(_InputIterator __first, _InputIterator __last,
   _RandomAccessIterator __result_first,
   _RandomAccessIterator __result_last,
   _Compare __comp)
    {
      typedef typename iterator_traits<_InputIterator>::value_type
 _InputValueType;
      typedef iterator_traits<_RandomAccessIterator> _RItTraits;
      typedef typename _RItTraits::difference_type _DistanceType;

      if (__result_first == __result_last)
 return __result_last;
      _RandomAccessIterator __result_real_last = __result_first;
      while (__first != __last && __result_real_last != __result_last)
 {
   *__result_real_last = *__first;
   ++__result_real_last;
   ++__first;
 }

      std::__make_heap(__result_first, __result_real_last, __comp);
      while (__first != __last)
 {
   if (__comp(__first, __result_first))
     std::__adjust_heap(__result_first, _DistanceType(0),
          _DistanceType(__result_real_last
          - __result_first),
          _InputValueType(*__first), __comp);
   ++__first;
 }
      std::__sort_heap(__result_first, __result_real_last, __comp);
      return __result_real_last;
    }
# 1660 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _RandomAccessIterator>
    constexpr
    inline _RandomAccessIterator
    partial_sort_copy(_InputIterator __first, _InputIterator __last,
        _RandomAccessIterator __result_first,
        _RandomAccessIterator __result_last)
    {
# 1675 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
     
     

     

     
      ;
      ;
      ;

      return std::__partial_sort_copy(__first, __last,
          __result_first, __result_last,
          __gnu_cxx::__ops::__iter_less_iter());
    }
# 1710 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _RandomAccessIterator,
    typename _Compare>
    constexpr
    inline _RandomAccessIterator
    partial_sort_copy(_InputIterator __first, _InputIterator __last,
        _RandomAccessIterator __result_first,
        _RandomAccessIterator __result_last,
        _Compare __comp)
    {
# 1727 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
     
     

     

     

     

      ;
      ;
      ;

      return std::__partial_sort_copy(__first, __last,
          __result_first, __result_last,
    __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }




  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    void
    __unguarded_linear_insert(_RandomAccessIterator __last,
         _Compare __comp)
    {
      typename iterator_traits<_RandomAccessIterator>::value_type
 __val = std::move(*__last);
      _RandomAccessIterator __next = __last;
      --__next;
      while (__comp(__val, __next))
 {
   *__last = std::move(*__next);
   __last = __next;
   --__next;
 }
      *__last = std::move(__val);
    }


  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    void
    __insertion_sort(_RandomAccessIterator __first,
       _RandomAccessIterator __last, _Compare __comp)
    {
      if (__first == __last) return;

      for (_RandomAccessIterator __i = __first + 1; __i != __last; ++__i)
 {
   if (__comp(__i, __first))
     {
       typename iterator_traits<_RandomAccessIterator>::value_type
  __val = std::move(*__i);
       std::move_backward(__first, __i, __i + 1);
       *__first = std::move(__val);
     }
   else
     std::__unguarded_linear_insert(__i,
    __gnu_cxx::__ops::__val_comp_iter(__comp));
 }
    }


  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    inline void
    __unguarded_insertion_sort(_RandomAccessIterator __first,
          _RandomAccessIterator __last, _Compare __comp)
    {
      for (_RandomAccessIterator __i = __first; __i != __last; ++__i)
 std::__unguarded_linear_insert(__i,
    __gnu_cxx::__ops::__val_comp_iter(__comp));
    }





  enum { _S_threshold = 16 };


  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    void
    __final_insertion_sort(_RandomAccessIterator __first,
      _RandomAccessIterator __last, _Compare __comp)
    {
      if (__last - __first > int(_S_threshold))
 {
   std::__insertion_sort(__first, __first + int(_S_threshold), __comp);
   std::__unguarded_insertion_sort(__first + int(_S_threshold), __last,
       __comp);
 }
      else
 std::__insertion_sort(__first, __last, __comp);
    }


  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    _RandomAccessIterator
    __unguarded_partition(_RandomAccessIterator __first,
     _RandomAccessIterator __last,
     _RandomAccessIterator __pivot, _Compare __comp)
    {
      while (true)
 {
   while (__comp(__first, __pivot))
     ++__first;
   --__last;
   while (__comp(__pivot, __last))
     --__last;
   if (!(__first < __last))
     return __first;
   std::iter_swap(__first, __last);
   ++__first;
 }
    }


  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    inline _RandomAccessIterator
    __unguarded_partition_pivot(_RandomAccessIterator __first,
    _RandomAccessIterator __last, _Compare __comp)
    {
      _RandomAccessIterator __mid = __first + (__last - __first) / 2;
      std::__move_median_to_first(__first, __first + 1, __mid, __last - 1,
      __comp);
      return std::__unguarded_partition(__first + 1, __last, __first, __comp);
    }

  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    inline void
    __partial_sort(_RandomAccessIterator __first,
     _RandomAccessIterator __middle,
     _RandomAccessIterator __last,
     _Compare __comp)
    {
      std::__heap_select(__first, __middle, __last, __comp);
      std::__sort_heap(__first, __middle, __comp);
    }


  template<typename _RandomAccessIterator, typename _Size, typename _Compare>
    constexpr
    void
    __introsort_loop(_RandomAccessIterator __first,
       _RandomAccessIterator __last,
       _Size __depth_limit, _Compare __comp)
    {
      while (__last - __first > int(_S_threshold))
 {
   if (__depth_limit == 0)
     {
       std::__partial_sort(__first, __last, __last, __comp);
       return;
     }
   --__depth_limit;
   _RandomAccessIterator __cut =
     std::__unguarded_partition_pivot(__first, __last, __comp);
   std::__introsort_loop(__cut, __last, __depth_limit, __comp);
   __last = __cut;
 }
    }



  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    inline void
    __sort(_RandomAccessIterator __first, _RandomAccessIterator __last,
    _Compare __comp)
    {
      if (__first != __last)
 {
   std::__introsort_loop(__first, __last,
    std::__lg(__last - __first) * 2,
    __comp);
   std::__final_insertion_sort(__first, __last, __comp);
 }
    }

  template<typename _RandomAccessIterator, typename _Size, typename _Compare>
    constexpr
    void
    __introselect(_RandomAccessIterator __first, _RandomAccessIterator __nth,
    _RandomAccessIterator __last, _Size __depth_limit,
    _Compare __comp)
    {
      while (__last - __first > 3)
 {
   if (__depth_limit == 0)
     {
       std::__heap_select(__first, __nth + 1, __last, __comp);

       std::iter_swap(__first, __nth);
       return;
     }
   --__depth_limit;
   _RandomAccessIterator __cut =
     std::__unguarded_partition_pivot(__first, __last, __comp);
   if (__cut <= __nth)
     __first = __cut;
   else
     __last = __cut;
 }
      std::__insertion_sort(__first, __last, __comp);
    }
# 1961 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Tp, typename _Compare>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator
    lower_bound(_ForwardIterator __first, _ForwardIterator __last,
  const _Tp& __val, _Compare __comp)
    {

     
     

     
                    ;

      return std::__lower_bound(__first, __last, __val,
    __gnu_cxx::__ops::__iter_comp_val(__comp));
    }

  template<typename _ForwardIterator, typename _Tp, typename _Compare>
    constexpr
    _ForwardIterator
    __upper_bound(_ForwardIterator __first, _ForwardIterator __last,
    const _Tp& __val, _Compare __comp)
    {
      typedef typename iterator_traits<_ForwardIterator>::difference_type
 _DistanceType;

      _DistanceType __len = std::distance(__first, __last);

      while (__len > 0)
 {
   _DistanceType __half = __len >> 1;
   _ForwardIterator __middle = __first;
   std::advance(__middle, __half);
   if (__comp(__val, __middle))
     __len = __half;
   else
     {
       __first = __middle;
       ++__first;
       __len = __len - __half - 1;
     }
 }
      return __first;
    }
# 2017 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Tp>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator
    upper_bound(_ForwardIterator __first, _ForwardIterator __last,
  const _Tp& __val)
    {

     
     

      ;

      return std::__upper_bound(__first, __last, __val,
    __gnu_cxx::__ops::__val_less_iter());
    }
# 2048 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Tp, typename _Compare>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator
    upper_bound(_ForwardIterator __first, _ForwardIterator __last,
  const _Tp& __val, _Compare __comp)
    {

     
     

     
                    ;

      return std::__upper_bound(__first, __last, __val,
    __gnu_cxx::__ops::__val_comp_iter(__comp));
    }

  template<typename _ForwardIterator, typename _Tp,
    typename _CompareItTp, typename _CompareTpIt>
    constexpr
    pair<_ForwardIterator, _ForwardIterator>
    __equal_range(_ForwardIterator __first, _ForwardIterator __last,
    const _Tp& __val,
    _CompareItTp __comp_it_val, _CompareTpIt __comp_val_it)
    {
      typedef typename iterator_traits<_ForwardIterator>::difference_type
 _DistanceType;

      _DistanceType __len = std::distance(__first, __last);

      while (__len > 0)
 {
   _DistanceType __half = __len >> 1;
   _ForwardIterator __middle = __first;
   std::advance(__middle, __half);
   if (__comp_it_val(__middle, __val))
     {
       __first = __middle;
       ++__first;
       __len = __len - __half - 1;
     }
   else if (__comp_val_it(__val, __middle))
     __len = __half;
   else
     {
       _ForwardIterator __left
  = std::__lower_bound(__first, __middle, __val, __comp_it_val);
       std::advance(__first, __len);
       _ForwardIterator __right
  = std::__upper_bound(++__middle, __first, __val, __comp_val_it);
       return pair<_ForwardIterator, _ForwardIterator>(__left, __right);
     }
 }
      return pair<_ForwardIterator, _ForwardIterator>(__first, __first);
    }
# 2121 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Tp>
    [[__nodiscard__]] constexpr
    inline pair<_ForwardIterator, _ForwardIterator>
    equal_range(_ForwardIterator __first, _ForwardIterator __last,
  const _Tp& __val)
    {

     
     

     

      ;
      ;

      return std::__equal_range(__first, __last, __val,
    __gnu_cxx::__ops::__iter_less_val(),
    __gnu_cxx::__ops::__val_less_iter());
    }
# 2158 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Tp, typename _Compare>
    [[__nodiscard__]] constexpr
    inline pair<_ForwardIterator, _ForwardIterator>
    equal_range(_ForwardIterator __first, _ForwardIterator __last,
  const _Tp& __val, _Compare __comp)
    {

     
     

     

     
                    ;
     
                    ;

      return std::__equal_range(__first, __last, __val,
    __gnu_cxx::__ops::__iter_comp_val(__comp),
    __gnu_cxx::__ops::__val_comp_iter(__comp));
    }
# 2192 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Tp>
    [[__nodiscard__]] constexpr
    bool
    binary_search(_ForwardIterator __first, _ForwardIterator __last,
    const _Tp& __val)
    {

     
     

      ;
      ;

      _ForwardIterator __i
 = std::__lower_bound(__first, __last, __val,
        __gnu_cxx::__ops::__iter_less_val());
      return __i != __last && !(__val < *__i);
    }
# 2226 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Tp, typename _Compare>
    [[__nodiscard__]] constexpr
    bool
    binary_search(_ForwardIterator __first, _ForwardIterator __last,
    const _Tp& __val, _Compare __comp)
    {

     
     

     
                    ;
     
                    ;

      _ForwardIterator __i
 = std::__lower_bound(__first, __last, __val,
        __gnu_cxx::__ops::__iter_comp_val(__comp));
      return __i != __last && !bool(__comp(__val, *__i));
    }




  template<typename _InputIterator1, typename _InputIterator2,
    typename _OutputIterator, typename _Compare>
    void
    __move_merge_adaptive(_InputIterator1 __first1, _InputIterator1 __last1,
     _InputIterator2 __first2, _InputIterator2 __last2,
     _OutputIterator __result, _Compare __comp)
    {
      while (__first1 != __last1 && __first2 != __last2)
 {
   if (__comp(__first2, __first1))
     {
       *__result = std::move(*__first2);
       ++__first2;
     }
   else
     {
       *__result = std::move(*__first1);
       ++__first1;
     }
   ++__result;
 }
      if (__first1 != __last1)
 std::move(__first1, __last1, __result);
    }


  template<typename _BidirectionalIterator1, typename _BidirectionalIterator2,
    typename _BidirectionalIterator3, typename _Compare>
    void
    __move_merge_adaptive_backward(_BidirectionalIterator1 __first1,
       _BidirectionalIterator1 __last1,
       _BidirectionalIterator2 __first2,
       _BidirectionalIterator2 __last2,
       _BidirectionalIterator3 __result,
       _Compare __comp)
    {
      if (__first1 == __last1)
 {
   std::move_backward(__first2, __last2, __result);
   return;
 }
      else if (__first2 == __last2)
 return;

      --__last1;
      --__last2;
      while (true)
 {
   if (__comp(__last2, __last1))
     {
       *--__result = std::move(*__last1);
       if (__first1 == __last1)
  {
    std::move_backward(__first2, ++__last2, __result);
    return;
  }
       --__last1;
     }
   else
     {
       *--__result = std::move(*__last2);
       if (__first2 == __last2)
  return;
       --__last2;
     }
 }
    }


  template<typename _BidirectionalIterator1, typename _BidirectionalIterator2,
    typename _Distance>
    _BidirectionalIterator1
    __rotate_adaptive(_BidirectionalIterator1 __first,
        _BidirectionalIterator1 __middle,
        _BidirectionalIterator1 __last,
        _Distance __len1, _Distance __len2,
        _BidirectionalIterator2 __buffer,
        _Distance __buffer_size)
    {
      _BidirectionalIterator2 __buffer_end;
      if (__len1 > __len2 && __len2 <= __buffer_size)
 {
   if (__len2)
     {
       __buffer_end = std::move(__middle, __last, __buffer);
       std::move_backward(__first, __middle, __last);
       return std::move(__buffer, __buffer_end, __first);
     }
   else
     return __first;
 }
      else if (__len1 <= __buffer_size)
 {
   if (__len1)
     {
       __buffer_end = std::move(__first, __middle, __buffer);
       std::move(__middle, __last, __first);
       return std::move_backward(__buffer, __buffer_end, __last);
     }
   else
     return __last;
 }
      else
 return std::rotate(__first, __middle, __last);
    }


  template<typename _BidirectionalIterator, typename _Distance,
    typename _Pointer, typename _Compare>
    void
    __merge_adaptive(_BidirectionalIterator __first,
       _BidirectionalIterator __middle,
       _BidirectionalIterator __last,
       _Distance __len1, _Distance __len2,
       _Pointer __buffer, _Compare __comp)
    {
      if (__len1 <= __len2)
 {
   _Pointer __buffer_end = std::move(__first, __middle, __buffer);
   std::__move_merge_adaptive(__buffer, __buffer_end, __middle, __last,
         __first, __comp);
 }
      else
 {
   _Pointer __buffer_end = std::move(__middle, __last, __buffer);
   std::__move_merge_adaptive_backward(__first, __middle, __buffer,
           __buffer_end, __last, __comp);
 }
    }

  template<typename _BidirectionalIterator, typename _Distance,
    typename _Pointer, typename _Compare>
    void
    __merge_adaptive_resize(_BidirectionalIterator __first,
       _BidirectionalIterator __middle,
       _BidirectionalIterator __last,
       _Distance __len1, _Distance __len2,
       _Pointer __buffer, _Distance __buffer_size,
       _Compare __comp)
    {
      if (__len1 <= __buffer_size || __len2 <= __buffer_size)
 std::__merge_adaptive(__first, __middle, __last,
         __len1, __len2, __buffer, __comp);
      else
 {
   _BidirectionalIterator __first_cut = __first;
   _BidirectionalIterator __second_cut = __middle;
   _Distance __len11 = 0;
   _Distance __len22 = 0;
   if (__len1 > __len2)
     {
       __len11 = __len1 / 2;
       std::advance(__first_cut, __len11);
       __second_cut
  = std::__lower_bound(__middle, __last, *__first_cut,
         __gnu_cxx::__ops::__iter_comp_val(__comp));
       __len22 = std::distance(__middle, __second_cut);
     }
   else
     {
       __len22 = __len2 / 2;
       std::advance(__second_cut, __len22);
       __first_cut
  = std::__upper_bound(__first, __middle, *__second_cut,
         __gnu_cxx::__ops::__val_comp_iter(__comp));
       __len11 = std::distance(__first, __first_cut);
     }

   _BidirectionalIterator __new_middle
     = std::__rotate_adaptive(__first_cut, __middle, __second_cut,
         _Distance(__len1 - __len11), __len22,
         __buffer, __buffer_size);
   std::__merge_adaptive_resize(__first, __first_cut, __new_middle,
           __len11, __len22,
           __buffer, __buffer_size, __comp);
   std::__merge_adaptive_resize(__new_middle, __second_cut, __last,
           _Distance(__len1 - __len11),
           _Distance(__len2 - __len22),
           __buffer, __buffer_size, __comp);
 }
    }


  template<typename _BidirectionalIterator, typename _Distance,
    typename _Compare>
   
    void
    __merge_without_buffer(_BidirectionalIterator __first,
      _BidirectionalIterator __middle,
      _BidirectionalIterator __last,
      _Distance __len1, _Distance __len2,
      _Compare __comp)
    {
      if (__len1 == 0 || __len2 == 0)
 return;

      if (__len1 + __len2 == 2)
 {
   if (__comp(__middle, __first))
     std::iter_swap(__first, __middle);
   return;
 }

      _BidirectionalIterator __first_cut = __first;
      _BidirectionalIterator __second_cut = __middle;
      _Distance __len11 = 0;
      _Distance __len22 = 0;
      if (__len1 > __len2)
 {
   __len11 = __len1 / 2;
   std::advance(__first_cut, __len11);
   __second_cut
     = std::__lower_bound(__middle, __last, *__first_cut,
     __gnu_cxx::__ops::__iter_comp_val(__comp));
   __len22 = std::distance(__middle, __second_cut);
 }
      else
 {
   __len22 = __len2 / 2;
   std::advance(__second_cut, __len22);
   __first_cut
     = std::__upper_bound(__first, __middle, *__second_cut,
     __gnu_cxx::__ops::__val_comp_iter(__comp));
   __len11 = std::distance(__first, __first_cut);
 }

      _BidirectionalIterator __new_middle
 = std::rotate(__first_cut, __middle, __second_cut);
      std::__merge_without_buffer(__first, __first_cut, __new_middle,
      __len11, __len22, __comp);
      std::__merge_without_buffer(__new_middle, __second_cut, __last,
      __len1 - __len11, __len2 - __len22, __comp);
    }

  template<typename _BidirectionalIterator, typename _Compare>
   
    void
    __inplace_merge(_BidirectionalIterator __first,
      _BidirectionalIterator __middle,
      _BidirectionalIterator __last,
      _Compare __comp)
    {
      typedef typename iterator_traits<_BidirectionalIterator>::value_type
   _ValueType;
      typedef typename iterator_traits<_BidirectionalIterator>::difference_type
   _DistanceType;

      if (__first == __middle || __middle == __last)
 return;

      const _DistanceType __len1 = std::distance(__first, __middle);
      const _DistanceType __len2 = std::distance(__middle, __last);
# 2510 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
      typedef _Temporary_buffer<_BidirectionalIterator, _ValueType> _TmpBuf;


      _TmpBuf __buf(__first, std::min(__len1, __len2));

      if (__builtin_expect(__buf.size() == __buf.requested_size(), true))
 std::__merge_adaptive
   (__first, __middle, __last, __len1, __len2, __buf.begin(), __comp);
      else if (__builtin_expect(__buf.begin() == 0, false))
 std::__merge_without_buffer
   (__first, __middle, __last, __len1, __len2, __comp);
      else
 std::__merge_adaptive_resize
   (__first, __middle, __last, __len1, __len2, __buf.begin(),
    _DistanceType(__buf.size()), __comp);




    }
# 2549 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _BidirectionalIterator>
   
    inline void
    inplace_merge(_BidirectionalIterator __first,
    _BidirectionalIterator __middle,
    _BidirectionalIterator __last)
    {

     

     

      ;
      ;
      ;

      std::__inplace_merge(__first, __middle, __last,
      __gnu_cxx::__ops::__iter_less_iter());
    }
# 2591 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _BidirectionalIterator, typename _Compare>
   
    inline void
    inplace_merge(_BidirectionalIterator __first,
    _BidirectionalIterator __middle,
    _BidirectionalIterator __last,
    _Compare __comp)
    {

     

     


      ;
      ;
      ;

      std::__inplace_merge(__first, __middle, __last,
      __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }



  template<typename _InputIterator, typename _OutputIterator,
    typename _Compare>
    _OutputIterator
    __move_merge(_InputIterator __first1, _InputIterator __last1,
   _InputIterator __first2, _InputIterator __last2,
   _OutputIterator __result, _Compare __comp)
    {
      while (__first1 != __last1 && __first2 != __last2)
 {
   if (__comp(__first2, __first1))
     {
       *__result = std::move(*__first2);
       ++__first2;
     }
   else
     {
       *__result = std::move(*__first1);
       ++__first1;
     }
   ++__result;
 }
      return std::move(__first2, __last2, std::move(__first1, __last1, __result))

                  ;
    }

  template<typename _RandomAccessIterator1, typename _RandomAccessIterator2,
    typename _Distance, typename _Compare>
    void
    __merge_sort_loop(_RandomAccessIterator1 __first,
        _RandomAccessIterator1 __last,
        _RandomAccessIterator2 __result, _Distance __step_size,
        _Compare __comp)
    {
      const _Distance __two_step = 2 * __step_size;

      while (__last - __first >= __two_step)
 {
   __result = std::__move_merge(__first, __first + __step_size,
           __first + __step_size,
           __first + __two_step,
           __result, __comp);
   __first += __two_step;
 }
      __step_size = std::min(_Distance(__last - __first), __step_size);

      std::__move_merge(__first, __first + __step_size,
   __first + __step_size, __last, __result, __comp);
    }

  template<typename _RandomAccessIterator, typename _Distance,
    typename _Compare>
    constexpr
    void
    __chunk_insertion_sort(_RandomAccessIterator __first,
      _RandomAccessIterator __last,
      _Distance __chunk_size, _Compare __comp)
    {
      while (__last - __first >= __chunk_size)
 {
   std::__insertion_sort(__first, __first + __chunk_size, __comp);
   __first += __chunk_size;
 }
      std::__insertion_sort(__first, __last, __comp);
    }

  enum { _S_chunk_size = 7 };

  template<typename _RandomAccessIterator, typename _Pointer, typename _Compare>
    void
    __merge_sort_with_buffer(_RandomAccessIterator __first,
        _RandomAccessIterator __last,
        _Pointer __buffer, _Compare __comp)
    {
      typedef typename iterator_traits<_RandomAccessIterator>::difference_type
 _Distance;

      const _Distance __len = __last - __first;
      const _Pointer __buffer_last = __buffer + __len;

      _Distance __step_size = _S_chunk_size;
      std::__chunk_insertion_sort(__first, __last, __step_size, __comp);

      while (__step_size < __len)
 {
   std::__merge_sort_loop(__first, __last, __buffer,
     __step_size, __comp);
   __step_size *= 2;
   std::__merge_sort_loop(__buffer, __buffer_last, __first,
     __step_size, __comp);
   __step_size *= 2;
 }
    }

  template<typename _RandomAccessIterator, typename _Pointer, typename _Compare>
    void
    __stable_sort_adaptive(_RandomAccessIterator __first,
      _RandomAccessIterator __middle,
      _RandomAccessIterator __last,
      _Pointer __buffer, _Compare __comp)
    {
      std::__merge_sort_with_buffer(__first, __middle, __buffer, __comp);
      std::__merge_sort_with_buffer(__middle, __last, __buffer, __comp);

      std::__merge_adaptive(__first, __middle, __last,
       __middle - __first, __last - __middle,
       __buffer, __comp);
    }

  template<typename _RandomAccessIterator, typename _Pointer,
    typename _Distance, typename _Compare>
    void
    __stable_sort_adaptive_resize(_RandomAccessIterator __first,
      _RandomAccessIterator __last,
      _Pointer __buffer, _Distance __buffer_size,
      _Compare __comp)
    {
      const _Distance __len = (__last - __first + 1) / 2;
      const _RandomAccessIterator __middle = __first + __len;
      if (__len > __buffer_size)
 {
   std::__stable_sort_adaptive_resize(__first, __middle, __buffer,
          __buffer_size, __comp);
   std::__stable_sort_adaptive_resize(__middle, __last, __buffer,
          __buffer_size, __comp);
   std::__merge_adaptive_resize(__first, __middle, __last,
           _Distance(__middle - __first),
           _Distance(__last - __middle),
           __buffer, __buffer_size,
           __comp);
 }
      else
 std::__stable_sort_adaptive(__first, __middle, __last,
        __buffer, __comp);
    }


  template<typename _RandomAccessIterator, typename _Compare>
   
    void
    __inplace_stable_sort(_RandomAccessIterator __first,
     _RandomAccessIterator __last, _Compare __comp)
    {
      if (__last - __first < 15)
 {
   std::__insertion_sort(__first, __last, __comp);
   return;
 }
      _RandomAccessIterator __middle = __first + (__last - __first) / 2;
      std::__inplace_stable_sort(__first, __middle, __comp);
      std::__inplace_stable_sort(__middle, __last, __comp);
      std::__merge_without_buffer(__first, __middle, __last,
      __middle - __first,
      __last - __middle,
      __comp);
    }
# 2779 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator1, typename _InputIterator2,
    typename _Compare>
    constexpr
    bool
    __includes(_InputIterator1 __first1, _InputIterator1 __last1,
        _InputIterator2 __first2, _InputIterator2 __last2,
        _Compare __comp)
    {
      while (__first1 != __last1 && __first2 != __last2)
 {
   if (__comp(__first2, __first1))
     return false;
   if (!__comp(__first1, __first2))
     ++__first2;
   ++__first1;
 }

      return __first2 == __last2;
    }
# 2817 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator1, typename _InputIterator2>
    [[__nodiscard__]] constexpr
    inline bool
    includes(_InputIterator1 __first1, _InputIterator1 __last1,
      _InputIterator2 __first2, _InputIterator2 __last2)
    {

     
     
     


     


      ;
      ;
      ;
      ;

      return std::__includes(__first1, __last1, __first2, __last2,
        __gnu_cxx::__ops::__iter_less_iter());
    }
# 2862 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator1, typename _InputIterator2,
    typename _Compare>
    [[__nodiscard__]] constexpr
    inline bool
    includes(_InputIterator1 __first1, _InputIterator1 __last1,
      _InputIterator2 __first2, _InputIterator2 __last2,
      _Compare __comp)
    {

     
     
     


     


      ;
      ;
      ;
      ;

      return std::__includes(__first1, __last1, __first2, __last2,
        __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }
# 2898 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _BidirectionalIterator, typename _Compare>
    constexpr
    bool
    __next_permutation(_BidirectionalIterator __first,
         _BidirectionalIterator __last, _Compare __comp)
    {
      if (__first == __last)
 return false;
      _BidirectionalIterator __i = __first;
      ++__i;
      if (__i == __last)
 return false;
      __i = __last;
      --__i;

      for(;;)
 {
   _BidirectionalIterator __ii = __i;
   --__i;
   if (__comp(__i, __ii))
     {
       _BidirectionalIterator __j = __last;
       while (!__comp(__i, --__j))
  {}
       std::iter_swap(__i, __j);
       std::__reverse(__ii, __last,
        std::__iterator_category(__first));
       return true;
     }
   if (__i == __first)
     {
       std::__reverse(__first, __last,
        std::__iterator_category(__first));
       return false;
     }
 }
    }
# 2948 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _BidirectionalIterator>
    constexpr
    inline bool
    next_permutation(_BidirectionalIterator __first,
       _BidirectionalIterator __last)
    {

     

     

      ;
      ;

      return std::__next_permutation
 (__first, __last, __gnu_cxx::__ops::__iter_less_iter());
    }
# 2981 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _BidirectionalIterator, typename _Compare>
    constexpr
    inline bool
    next_permutation(_BidirectionalIterator __first,
       _BidirectionalIterator __last, _Compare __comp)
    {

     

     


      ;
      ;

      return std::__next_permutation
 (__first, __last, __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }

  template<typename _BidirectionalIterator, typename _Compare>
    constexpr
    bool
    __prev_permutation(_BidirectionalIterator __first,
         _BidirectionalIterator __last, _Compare __comp)
    {
      if (__first == __last)
 return false;
      _BidirectionalIterator __i = __first;
      ++__i;
      if (__i == __last)
 return false;
      __i = __last;
      --__i;

      for(;;)
 {
   _BidirectionalIterator __ii = __i;
   --__i;
   if (__comp(__ii, __i))
     {
       _BidirectionalIterator __j = __last;
       while (!__comp(--__j, __i))
  {}
       std::iter_swap(__i, __j);
       std::__reverse(__ii, __last,
        std::__iterator_category(__first));
       return true;
     }
   if (__i == __first)
     {
       std::__reverse(__first, __last,
        std::__iterator_category(__first));
       return false;
     }
 }
    }
# 3051 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _BidirectionalIterator>
    constexpr
    inline bool
    prev_permutation(_BidirectionalIterator __first,
       _BidirectionalIterator __last)
    {

     

     

      ;
      ;

      return std::__prev_permutation(__first, __last,
         __gnu_cxx::__ops::__iter_less_iter());
    }
# 3084 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _BidirectionalIterator, typename _Compare>
    constexpr
    inline bool
    prev_permutation(_BidirectionalIterator __first,
       _BidirectionalIterator __last, _Compare __comp)
    {

     

     


      ;
      ;

      return std::__prev_permutation(__first, __last,
    __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }




  template<typename _InputIterator, typename _OutputIterator,
    typename _Predicate, typename _Tp>
    constexpr
    _OutputIterator
    __replace_copy_if(_InputIterator __first, _InputIterator __last,
        _OutputIterator __result,
        _Predicate __pred, const _Tp& __new_value)
    {
      for (; __first != __last; ++__first, (void)++__result)
 if (__pred(__first))
   *__result = __new_value;
 else
   *__result = *__first;
      return __result;
    }
# 3136 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _OutputIterator, typename _Tp>
    constexpr
    inline _OutputIterator
    replace_copy(_InputIterator __first, _InputIterator __last,
   _OutputIterator __result,
   const _Tp& __old_value, const _Tp& __new_value)
    {

     
     

     

      ;

      return std::__replace_copy_if(__first, __last, __result,
   __gnu_cxx::__ops::__iter_equals_val(__old_value),
           __new_value);
    }
# 3171 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _OutputIterator,
    typename _Predicate, typename _Tp>
    constexpr
    inline _OutputIterator
    replace_copy_if(_InputIterator __first, _InputIterator __last,
      _OutputIterator __result,
      _Predicate __pred, const _Tp& __new_value)
    {

     
     

     

      ;

      return std::__replace_copy_if(__first, __last, __result,
    __gnu_cxx::__ops::__pred_iter(__pred),
           __new_value);
    }
# 3200 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator>
    [[__nodiscard__]] constexpr
    inline bool
    is_sorted(_ForwardIterator __first, _ForwardIterator __last)
    { return std::is_sorted_until(__first, __last) == __last; }
# 3215 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Compare>
    [[__nodiscard__]] constexpr
    inline bool
    is_sorted(_ForwardIterator __first, _ForwardIterator __last,
       _Compare __comp)
    { return std::is_sorted_until(__first, __last, __comp) == __last; }

  template<typename _ForwardIterator, typename _Compare>
    constexpr
    _ForwardIterator
    __is_sorted_until(_ForwardIterator __first, _ForwardIterator __last,
        _Compare __comp)
    {
      if (__first == __last)
 return __last;

      _ForwardIterator __next = __first;
      for (++__next; __next != __last; __first = __next, (void)++__next)
 if (__comp(__next, __first))
   return __next;
      return __next;
    }
# 3246 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator
    is_sorted_until(_ForwardIterator __first, _ForwardIterator __last)
    {

     
     

      ;
      ;

      return std::__is_sorted_until(__first, __last,
        __gnu_cxx::__ops::__iter_less_iter());
    }
# 3271 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Compare>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator
    is_sorted_until(_ForwardIterator __first, _ForwardIterator __last,
      _Compare __comp)
    {

     
     


      ;
      ;

      return std::__is_sorted_until(__first, __last,
        __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }
# 3297 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _Tp>
    [[__nodiscard__]] constexpr
    inline pair<const _Tp&, const _Tp&>
    minmax(const _Tp& __a, const _Tp& __b)
    {

     

      return __b < __a ? pair<const _Tp&, const _Tp&>(__b, __a)
         : pair<const _Tp&, const _Tp&>(__a, __b);
    }
# 3318 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _Tp, typename _Compare>
    [[__nodiscard__]] constexpr
    inline pair<const _Tp&, const _Tp&>
    minmax(const _Tp& __a, const _Tp& __b, _Compare __comp)
    {
      return __comp(__b, __a) ? pair<const _Tp&, const _Tp&>(__b, __a)
         : pair<const _Tp&, const _Tp&>(__a, __b);
    }

  template<typename _ForwardIterator, typename _Compare>
    constexpr
    pair<_ForwardIterator, _ForwardIterator>
    __minmax_element(_ForwardIterator __first, _ForwardIterator __last,
       _Compare __comp)
    {
      _ForwardIterator __next = __first;
      if (__first == __last
   || ++__next == __last)
 return std::make_pair(__first, __first);

      _ForwardIterator __min{}, __max{};
      if (__comp(__next, __first))
 {
   __min = __next;
   __max = __first;
 }
      else
 {
   __min = __first;
   __max = __next;
 }

      __first = __next;
      ++__first;

      while (__first != __last)
 {
   __next = __first;
   if (++__next == __last)
     {
       if (__comp(__first, __min))
  __min = __first;
       else if (!__comp(__first, __max))
  __max = __first;
       break;
     }

   if (__comp(__next, __first))
     {
       if (__comp(__next, __min))
  __min = __next;
       if (!__comp(__first, __max))
  __max = __first;
     }
   else
     {
       if (__comp(__first, __min))
  __min = __first;
       if (!__comp(__next, __max))
  __max = __next;
     }

   __first = __next;
   ++__first;
 }

      return std::make_pair(__min, __max);
    }
# 3398 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator>
    [[__nodiscard__]] constexpr
    inline pair<_ForwardIterator, _ForwardIterator>
    minmax_element(_ForwardIterator __first, _ForwardIterator __last)
    {

     
     

      ;
      ;

      return std::__minmax_element(__first, __last,
       __gnu_cxx::__ops::__iter_less_iter());
    }
# 3426 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Compare>
    [[__nodiscard__]] constexpr
    inline pair<_ForwardIterator, _ForwardIterator>
    minmax_element(_ForwardIterator __first, _ForwardIterator __last,
     _Compare __comp)
    {

     
     


      ;
      ;

      return std::__minmax_element(__first, __last,
       __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }

  template<typename _Tp>
    [[__nodiscard__]] constexpr
    inline pair<_Tp, _Tp>
    minmax(initializer_list<_Tp> __l)
    {
      ;
      pair<const _Tp*, const _Tp*> __p =
 std::__minmax_element(__l.begin(), __l.end(),
         __gnu_cxx::__ops::__iter_less_iter());
      return std::make_pair(*__p.first, *__p.second);
    }

  template<typename _Tp, typename _Compare>
    [[__nodiscard__]] constexpr
    inline pair<_Tp, _Tp>
    minmax(initializer_list<_Tp> __l, _Compare __comp)
    {
      ;
      pair<const _Tp*, const _Tp*> __p =
 std::__minmax_element(__l.begin(), __l.end(),
         __gnu_cxx::__ops::__iter_comp_iter(__comp));
      return std::make_pair(*__p.first, *__p.second);
    }
# 3482 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator1, typename _ForwardIterator2,
    typename _BinaryPredicate>
    [[__nodiscard__]] constexpr
    inline bool
    is_permutation(_ForwardIterator1 __first1, _ForwardIterator1 __last1,
     _ForwardIterator2 __first2, _BinaryPredicate __pred)
    {

     
     
     


      ;

      return std::__is_permutation(__first1, __last1, __first2,
       __gnu_cxx::__ops::__iter_comp_iter(__pred));
    }


#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wc++17-extensions"
  template<typename _ForwardIterator1, typename _ForwardIterator2,
    typename _BinaryPredicate>
    constexpr
    bool
    __is_permutation(_ForwardIterator1 __first1, _ForwardIterator1 __last1,
       _ForwardIterator2 __first2, _ForwardIterator2 __last2,
       _BinaryPredicate __pred)
    {
      using _Cat1
 = typename iterator_traits<_ForwardIterator1>::iterator_category;
      using _Cat2
 = typename iterator_traits<_ForwardIterator2>::iterator_category;
      using _It1_is_RA = is_same<_Cat1, random_access_iterator_tag>;
      using _It2_is_RA = is_same<_Cat2, random_access_iterator_tag>;
      constexpr bool __ra_iters = __and_<_It1_is_RA, _It2_is_RA>::value;
      if constexpr (__ra_iters)
 {
   if ((__last1 - __first1) != (__last2 - __first2))
     return false;
 }



      for (; __first1 != __last1 && __first2 != __last2;
   ++__first1, (void)++__first2)
 if (!__pred(__first1, __first2))
   break;

      if constexpr (__ra_iters)
 {
   if (__first1 == __last1)
     return true;
 }
      else
 {
   auto __d1 = std::distance(__first1, __last1);
   auto __d2 = std::distance(__first2, __last2);
   if (__d1 == 0 && __d2 == 0)
     return true;
   if (__d1 != __d2)
     return false;
 }

      for (_ForwardIterator1 __scan = __first1; __scan != __last1; ++__scan)
 {
   if (__scan != std::__find_if(__first1, __scan,
   __gnu_cxx::__ops::__iter_comp_iter(__pred, __scan)))
     continue;

   auto __matches = std::__count_if(__first2, __last2,
  __gnu_cxx::__ops::__iter_comp_iter(__pred, __scan));
   if (0 == __matches
       || std::__count_if(__scan, __last1,
   __gnu_cxx::__ops::__iter_comp_iter(__pred, __scan))
       != __matches)
     return false;
 }
      return true;
    }
#pragma GCC diagnostic pop
# 3578 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator1, typename _ForwardIterator2>
    [[__nodiscard__]] constexpr
    inline bool
    is_permutation(_ForwardIterator1 __first1, _ForwardIterator1 __last1,
     _ForwardIterator2 __first2, _ForwardIterator2 __last2)
    {
      ;
      ;

      return
 std::__is_permutation(__first1, __last1, __first2, __last2,
         __gnu_cxx::__ops::__iter_equal_to_iter());
    }
# 3606 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator1, typename _ForwardIterator2,
    typename _BinaryPredicate>
    [[__nodiscard__]] constexpr
    inline bool
    is_permutation(_ForwardIterator1 __first1, _ForwardIterator1 __last1,
     _ForwardIterator2 __first2, _ForwardIterator2 __last2,
     _BinaryPredicate __pred)
    {
      ;
      ;

      return std::__is_permutation(__first1, __last1, __first2, __last2,
       __gnu_cxx::__ops::__iter_comp_iter(__pred));
    }
# 3634 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _Tp>
    [[nodiscard]] constexpr const _Tp&
    clamp(const _Tp& __val, const _Tp& __lo, const _Tp& __hi)
    {
      do { if (__builtin_expect(!bool(!(__hi < __lo)), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h", 3638, __PRETTY_FUNCTION__, "!(__hi < __lo)"); } while (false);
      return std::min(std::max(__val, __lo), __hi);
    }
# 3654 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _Tp, typename _Compare>
    [[nodiscard]] constexpr const _Tp&
    clamp(const _Tp& __val, const _Tp& __lo, const _Tp& __hi, _Compare __comp)
    {
      do { if (__builtin_expect(!bool(!__comp(__hi, __lo)), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h", 3658, __PRETTY_FUNCTION__, "!__comp(__hi, __lo)"); } while (false);
      return std::min(std::max(__val, __lo, __comp), __hi, __comp);
    }
# 3684 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _IntType, typename _UniformRandomBitGenerator>
    pair<_IntType, _IntType>
    __gen_two_uniform_ints(_IntType __b0, _IntType __b1,
      _UniformRandomBitGenerator&& __g)
    {
      _IntType __x
 = uniform_int_distribution<_IntType>{0, (__b0 * __b1) - 1}(__g);
      return std::make_pair(__x / __b1, __x % __b1);
    }
# 3706 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _RandomAccessIterator,
    typename _UniformRandomNumberGenerator>
    void
    shuffle(_RandomAccessIterator __first, _RandomAccessIterator __last,
     _UniformRandomNumberGenerator&& __g)
    {

     

      ;

      if (__first == __last)
 return;

      typedef typename iterator_traits<_RandomAccessIterator>::difference_type
 _DistanceType;

      typedef typename std::make_unsigned<_DistanceType>::type __ud_type;
      typedef typename std::uniform_int_distribution<__ud_type> __distr_type;
      typedef typename __distr_type::param_type __p_type;

      typedef typename remove_reference<_UniformRandomNumberGenerator>::type
 _Gen;
      typedef typename common_type<typename _Gen::result_type, __ud_type>::type
 __uc_type;

      const __uc_type __urngrange = __g.max() - __g.min();
      const __uc_type __urange = __uc_type(__last - __first);

      if (__urngrange / __urange >= __urange)

      {
 _RandomAccessIterator __i = __first + 1;





 if ((__urange % 2) == 0)
 {
   __distr_type __d{0, 1};
   std::iter_swap(__i++, __first + __d(__g));
 }





 while (__i != __last)
 {
   const __uc_type __swap_range = __uc_type(__i - __first) + 1;

   const pair<__uc_type, __uc_type> __pospos =
     __gen_two_uniform_ints(__swap_range, __swap_range + 1, __g);

   std::iter_swap(__i++, __first + __pospos.first);
   std::iter_swap(__i++, __first + __pospos.second);
 }

 return;
      }

      __distr_type __d;

      for (_RandomAccessIterator __i = __first + 1; __i != __last; ++__i)
 std::iter_swap(__i, __first + __d(__g, __p_type(0, __i - __first)));
    }



# 3789 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _Function>
    constexpr
    _Function
    for_each(_InputIterator __first, _InputIterator __last, _Function __f)
    {

     
      ;
      for (; __first != __last; ++__first)
 __f(*__first);
      return __f;
    }
# 3815 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _Size, typename _Function>
    constexpr
    _InputIterator
    for_each_n(_InputIterator __first, _Size __n, _Function __f)
    {
      auto __n2 = std::__size_to_integer(__n);
      using _Cat = typename iterator_traits<_InputIterator>::iterator_category;
      if constexpr (is_base_of_v<random_access_iterator_tag, _Cat>)
 {
   if (__n2 <= 0)
     return __first;
   auto __last = __first + __n2;
   std::for_each(__first, __last, std::move(__f));
   return __last;
 }
      else
 {
   while (__n2-->0)
     {
       __f(*__first);
       ++__first;
     }
   return __first;
 }
    }
# 3851 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _Tp>
    [[__nodiscard__]] constexpr
    inline _InputIterator
    find(_InputIterator __first, _InputIterator __last, const _Tp& __val)
    {

     
     

      ;


      using _ValT = typename iterator_traits<_InputIterator>::value_type;
      if constexpr (__can_use_memchr_for_find<_ValT, _Tp>)
 if constexpr (is_pointer_v<decltype(std::__niter_base(__first))>

   || contiguous_iterator<_InputIterator>

       )
   {




     if (!(static_cast<_ValT>(__val) == __val))
       return __last;
     else if (!__is_constant_evaluated())
       {
  const int __ival = static_cast<int>(__val);
  if (auto __n = __last - __first; __n > 0)
    {

      const void* __p0 = std::to_address(__first);



      if (auto __p1 = __builtin_memchr(__p0, __ival, __n))
        return __first + ((const char*)__p1 - (const char*)__p0);
    }
  return __last;
       }
   }


      return std::__find_if(__first, __last,
       __gnu_cxx::__ops::__iter_equals_val(__val));
    }
# 3909 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _Predicate>
    [[__nodiscard__]] constexpr
    inline _InputIterator
    find_if(_InputIterator __first, _InputIterator __last,
     _Predicate __pred)
    {

     
     

      ;

      return std::__find_if(__first, __last,
       __gnu_cxx::__ops::__pred_iter(__pred));
    }
# 3941 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _ForwardIterator>
    [[__nodiscard__]] constexpr
    _InputIterator
    find_first_of(_InputIterator __first1, _InputIterator __last1,
    _ForwardIterator __first2, _ForwardIterator __last2)
    {

     
     
     


      ;
      ;

      for (; __first1 != __last1; ++__first1)
 for (_ForwardIterator __iter = __first2; __iter != __last2; ++__iter)
   if (*__first1 == *__iter)
     return __first1;
      return __last1;
    }
# 3982 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _ForwardIterator,
    typename _BinaryPredicate>
    [[__nodiscard__]] constexpr
    _InputIterator
    find_first_of(_InputIterator __first1, _InputIterator __last1,
    _ForwardIterator __first2, _ForwardIterator __last2,
    _BinaryPredicate __comp)
    {

     
     
     


      ;
      ;

      for (; __first1 != __last1; ++__first1)
 for (_ForwardIterator __iter = __first2; __iter != __last2; ++__iter)
   if (__comp(*__first1, *__iter))
     return __first1;
      return __last1;
    }
# 4015 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator
    adjacent_find(_ForwardIterator __first, _ForwardIterator __last)
    {

     
     

      ;

      return std::__adjacent_find(__first, __last,
      __gnu_cxx::__ops::__iter_equal_to_iter());
    }
# 4041 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _BinaryPredicate>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator
    adjacent_find(_ForwardIterator __first, _ForwardIterator __last,
    _BinaryPredicate __binary_pred)
    {

     
     


      ;

      return std::__adjacent_find(__first, __last,
   __gnu_cxx::__ops::__iter_comp_iter(__binary_pred));
    }
# 4067 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _Tp>
    [[__nodiscard__]] constexpr
    inline typename iterator_traits<_InputIterator>::difference_type
    count(_InputIterator __first, _InputIterator __last, const _Tp& __value)
    {

     
     

      ;

      return std::__count_if(__first, __last,
        __gnu_cxx::__ops::__iter_equals_val(__value));
    }
# 4091 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _Predicate>
    [[__nodiscard__]] constexpr
    inline typename iterator_traits<_InputIterator>::difference_type
    count_if(_InputIterator __first, _InputIterator __last, _Predicate __pred)
    {

     
     

      ;

      return std::__count_if(__first, __last,
        __gnu_cxx::__ops::__pred_iter(__pred));
    }
# 4132 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator1, typename _ForwardIterator2>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator1
    search(_ForwardIterator1 __first1, _ForwardIterator1 __last1,
    _ForwardIterator2 __first2, _ForwardIterator2 __last2)
    {

     
     
     


      ;
      ;

      return std::__search(__first1, __last1, __first2, __last2,
      __gnu_cxx::__ops::__iter_equal_to_iter());
    }
# 4166 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Integer, typename _Tp>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator
    search_n(_ForwardIterator __first, _ForwardIterator __last,
      _Integer __count, const _Tp& __val)
    {

     
     

      ;

      return std::__search_n(__first, __last, __count,
        __gnu_cxx::__ops::__iter_equals_val(__val));
    }
# 4200 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Integer, typename _Tp,
    typename _BinaryPredicate>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator
    search_n(_ForwardIterator __first, _ForwardIterator __last,
      _Integer __count, const _Tp& __val,
      _BinaryPredicate __binary_pred)
    {

     
     

      ;

      return std::__search_n(__first, __last, __count,
  __gnu_cxx::__ops::__iter_comp_val(__binary_pred, __val));
    }
# 4226 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Searcher>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator
    search(_ForwardIterator __first, _ForwardIterator __last,
    const _Searcher& __searcher)
    { return __searcher(__first, __last).first; }
# 4250 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _OutputIterator,
    typename _UnaryOperation>
    constexpr
    _OutputIterator
    transform(_InputIterator __first, _InputIterator __last,
       _OutputIterator __result, _UnaryOperation __unary_op)
    {

     
     


      ;

      for (; __first != __last; ++__first, (void)++__result)
 *__result = __unary_op(*__first);
      return __result;
    }
# 4288 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator1, typename _InputIterator2,
    typename _OutputIterator, typename _BinaryOperation>
    constexpr
    _OutputIterator
    transform(_InputIterator1 __first1, _InputIterator1 __last1,
       _InputIterator2 __first2, _OutputIterator __result,
       _BinaryOperation __binary_op)
    {

     
     
     


      ;

      for (; __first1 != __last1; ++__first1, (void)++__first2, ++__result)
 *__result = __binary_op(*__first1, *__first2);
      return __result;
    }
# 4322 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Tp>
    constexpr
    void
    replace(_ForwardIterator __first, _ForwardIterator __last,
     const _Tp& __old_value, const _Tp& __new_value)
    {

     

     

     

      ;

      for (; __first != __last; ++__first)
 if (*__first == __old_value)
   *__first = __new_value;
    }
# 4355 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Predicate, typename _Tp>
    constexpr
    void
    replace_if(_ForwardIterator __first, _ForwardIterator __last,
        _Predicate __pred, const _Tp& __new_value)
    {

     

     

     

      ;

      for (; __first != __last; ++__first)
 if (__pred(*__first))
   *__first = __new_value;
    }
# 4387 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Generator>
    constexpr
    void
    generate(_ForwardIterator __first, _ForwardIterator __last,
      _Generator __gen)
    {

     
     

      ;

      for (; __first != __last; ++__first)
 *__first = __gen();
    }
# 4420 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _OutputIterator, typename _Size, typename _Generator>
    constexpr
    _OutputIterator
    generate_n(_OutputIterator __first, _Size __n, _Generator __gen)
    {

     



      typedef __decltype(std::__size_to_integer(__n)) _IntSize;
      for (_IntSize __niter = std::__size_to_integer(__n);
    __niter > 0; --__niter, (void) ++__first)
 *__first = __gen();
      return __first;
    }
# 4455 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _OutputIterator>
    constexpr
    inline _OutputIterator
    unique_copy(_InputIterator __first, _InputIterator __last,
  _OutputIterator __result)
    {

     
     

     

      ;

      if (__first == __last)
 return __result;
      return std::__unique_copy(__first, __last, __result,
    __gnu_cxx::__ops::__iter_equal_to_iter(),
    std::__iterator_category(__first),
    std::__iterator_category(__result));
    }
# 4495 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator, typename _OutputIterator,
    typename _BinaryPredicate>
    constexpr
    inline _OutputIterator
    unique_copy(_InputIterator __first, _InputIterator __last,
  _OutputIterator __result,
  _BinaryPredicate __binary_pred)
    {

     
     

      ;

      if (__first == __last)
 return __result;
      return std::__unique_copy(__first, __last, __result,
   __gnu_cxx::__ops::__iter_comp_iter(__binary_pred),
    std::__iterator_category(__first),
    std::__iterator_category(__result));
    }
# 4534 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _RandomAccessIterator>
    __attribute__ ((__deprecated__ ("use '" "std::shuffle" "' instead")))
    inline void
    random_shuffle(_RandomAccessIterator __first, _RandomAccessIterator __last)
    {

     

      ;

      if (__first == __last)
 return;


      if (__builtin_expect((__last - __first) >= 0x7fff / 4, 0))
 {


   unsigned __xss
     = (unsigned)std::rand() ^ ((unsigned)std::rand() << 15);
   for (_RandomAccessIterator __i = __first + 1; __i != __last; ++__i)
     {
       __xss += !__xss;
       __xss ^= __xss << 13;
       __xss ^= __xss >> 17;
       __xss ^= __xss << 5;
       _RandomAccessIterator __j = __first
         + (__xss % ((__i - __first) + 1));
       if (__i != __j)
  std::iter_swap(__i, __j);
     }
   return;
 }


      for (_RandomAccessIterator __i = __first + 1; __i != __last; ++__i)
 {

   _RandomAccessIterator __j = __first
     + (std::rand() % ((__i - __first) + 1));
   if (__i != __j)
     std::iter_swap(__i, __j);
 }
    }
# 4597 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _RandomAccessIterator, typename _RandomNumberGenerator>
    __attribute__ ((__deprecated__ ("use '" "std::shuffle" "' instead")))
    void
    random_shuffle(_RandomAccessIterator __first, _RandomAccessIterator __last,

     _RandomNumberGenerator&& __rand)



    {

     

      ;

      if (__first == __last)
 return;
      for (_RandomAccessIterator __i = __first + 1; __i != __last; ++__i)
 {
   _RandomAccessIterator __j = __first + __rand((__i - __first) + 1);
   if (__i != __j)
     std::iter_swap(__i, __j);
 }
    }
# 4639 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Predicate>
    constexpr
    inline _ForwardIterator
    partition(_ForwardIterator __first, _ForwardIterator __last,
       _Predicate __pred)
    {

     

     

      ;

      return std::__partition(__first, __last, __pred,
         std::__iterator_category(__first));
    }
# 4674 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _RandomAccessIterator>
    constexpr
    inline void
    partial_sort(_RandomAccessIterator __first,
   _RandomAccessIterator __middle,
   _RandomAccessIterator __last)
    {

     

     

      ;
      ;
      ;

      std::__partial_sort(__first, __middle, __last,
     __gnu_cxx::__ops::__iter_less_iter());
    }
# 4713 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    inline void
    partial_sort(_RandomAccessIterator __first,
   _RandomAccessIterator __middle,
   _RandomAccessIterator __last,
   _Compare __comp)
    {

     

     


      ;
      ;
      ;

      std::__partial_sort(__first, __middle, __last,
     __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }
# 4750 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _RandomAccessIterator>
    constexpr
    inline void
    nth_element(_RandomAccessIterator __first, _RandomAccessIterator __nth,
  _RandomAccessIterator __last)
    {

     

     

      ;
      ;
      ;

      if (__first == __last || __nth == __last)
 return;

      std::__introselect(__first, __nth, __last,
    std::__lg(__last - __first) * 2,
    __gnu_cxx::__ops::__iter_less_iter());
    }
# 4790 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    inline void
    nth_element(_RandomAccessIterator __first, _RandomAccessIterator __nth,
  _RandomAccessIterator __last, _Compare __comp)
    {

     

     


      ;
      ;
      ;

      if (__first == __last || __nth == __last)
 return;

      std::__introselect(__first, __nth, __last,
    std::__lg(__last - __first) * 2,
    __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }
# 4828 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _RandomAccessIterator>
    constexpr
    inline void
    sort(_RandomAccessIterator __first, _RandomAccessIterator __last)
    {

     

     

      ;
      ;

      std::__sort(__first, __last, __gnu_cxx::__ops::__iter_less_iter());
    }
# 4859 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _RandomAccessIterator, typename _Compare>
    constexpr
    inline void
    sort(_RandomAccessIterator __first, _RandomAccessIterator __last,
  _Compare __comp)
    {

     

     


      ;
      ;

      std::__sort(__first, __last, __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }

  template<typename _InputIterator1, typename _InputIterator2,
    typename _OutputIterator, typename _Compare>
    constexpr
    _OutputIterator
    __merge(_InputIterator1 __first1, _InputIterator1 __last1,
     _InputIterator2 __first2, _InputIterator2 __last2,
     _OutputIterator __result, _Compare __comp)
    {
      while (__first1 != __last1 && __first2 != __last2)
 {
   if (__comp(__first2, __first1))
     {
       *__result = *__first2;
       ++__first2;
     }
   else
     {
       *__result = *__first1;
       ++__first1;
     }
   ++__result;
 }
      return std::copy(__first2, __last2,
         std::copy(__first1, __last1, __result));
    }
# 4922 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator1, typename _InputIterator2,
    typename _OutputIterator>
    constexpr
    inline _OutputIterator
    merge(_InputIterator1 __first1, _InputIterator1 __last1,
   _InputIterator2 __first2, _InputIterator2 __last2,
   _OutputIterator __result)
    {

     
     
     

     

     


      ;
      ;
      ;
      ;

      return std::__merge(__first1, __last1,
         __first2, __last2, __result,
         __gnu_cxx::__ops::__iter_less_iter());
    }
# 4973 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator1, typename _InputIterator2,
    typename _OutputIterator, typename _Compare>
    constexpr
    inline _OutputIterator
    merge(_InputIterator1 __first1, _InputIterator1 __last1,
   _InputIterator2 __first2, _InputIterator2 __last2,
   _OutputIterator __result, _Compare __comp)
    {

     
     
     

     

     


      ;
      ;
      ;
      ;

      return std::__merge(__first1, __last1,
    __first2, __last2, __result,
    __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }

  template<typename _RandomAccessIterator, typename _Compare>
   
    inline void
    __stable_sort(_RandomAccessIterator __first, _RandomAccessIterator __last,
    _Compare __comp)
    {
      typedef typename iterator_traits<_RandomAccessIterator>::value_type
 _ValueType;
      typedef typename iterator_traits<_RandomAccessIterator>::difference_type
 _DistanceType;

      if (__first == __last)
 return;
# 5022 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
      typedef _Temporary_buffer<_RandomAccessIterator, _ValueType> _TmpBuf;


      _TmpBuf __buf(__first, (__last - __first + 1) / 2);

      if (__builtin_expect(__buf.requested_size() == __buf.size(), true))
 std::__stable_sort_adaptive(__first,
        __first + _DistanceType(__buf.size()),
        __last, __buf.begin(), __comp);
      else if (__builtin_expect(__buf.begin() == 0, false))
 std::__inplace_stable_sort(__first, __last, __comp);
      else
 std::__stable_sort_adaptive_resize(__first, __last, __buf.begin(),
        _DistanceType(__buf.size()), __comp);



    }
# 5058 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _RandomAccessIterator>
   
    inline void
    stable_sort(_RandomAccessIterator __first, _RandomAccessIterator __last)
    {

     

     

      ;
      ;

      std::__stable_sort(__first, __last,
        __gnu_cxx::__ops::__iter_less_iter());
    }
# 5093 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _RandomAccessIterator, typename _Compare>
   
    inline void
    stable_sort(_RandomAccessIterator __first, _RandomAccessIterator __last,
  _Compare __comp)
    {

     

     


      ;
      ;

      std::__stable_sort(__first, __last,
        __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }

  template<typename _InputIterator1, typename _InputIterator2,
    typename _OutputIterator,
    typename _Compare>
    constexpr
    _OutputIterator
    __set_union(_InputIterator1 __first1, _InputIterator1 __last1,
  _InputIterator2 __first2, _InputIterator2 __last2,
  _OutputIterator __result, _Compare __comp)
    {
      while (__first1 != __last1 && __first2 != __last2)
 {
   if (__comp(__first1, __first2))
     {
       *__result = *__first1;
       ++__first1;
     }
   else if (__comp(__first2, __first1))
     {
       *__result = *__first2;
       ++__first2;
     }
   else
     {
       *__result = *__first1;
       ++__first1;
       ++__first2;
     }
   ++__result;
 }
      return std::copy(__first2, __last2,
         std::copy(__first1, __last1, __result));
    }
# 5164 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator1, typename _InputIterator2,
    typename _OutputIterator>
    constexpr
    inline _OutputIterator
    set_union(_InputIterator1 __first1, _InputIterator1 __last1,
       _InputIterator2 __first2, _InputIterator2 __last2,
       _OutputIterator __result)
    {

     
     
     

     

     


     


      ;
      ;
      ;
      ;

      return std::__set_union(__first1, __last1,
    __first2, __last2, __result,
    __gnu_cxx::__ops::__iter_less_iter());
    }
# 5215 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator1, typename _InputIterator2,
    typename _OutputIterator, typename _Compare>
    constexpr
    inline _OutputIterator
    set_union(_InputIterator1 __first1, _InputIterator1 __last1,
       _InputIterator2 __first2, _InputIterator2 __last2,
       _OutputIterator __result, _Compare __comp)
    {

     
     
     

     

     


     


      ;
      ;
      ;
      ;

      return std::__set_union(__first1, __last1,
    __first2, __last2, __result,
    __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }

  template<typename _InputIterator1, typename _InputIterator2,
    typename _OutputIterator,
    typename _Compare>
    constexpr
    _OutputIterator
    __set_intersection(_InputIterator1 __first1, _InputIterator1 __last1,
         _InputIterator2 __first2, _InputIterator2 __last2,
         _OutputIterator __result, _Compare __comp)
    {
      while (__first1 != __last1 && __first2 != __last2)
 if (__comp(__first1, __first2))
   ++__first1;
 else if (__comp(__first2, __first1))
   ++__first2;
 else
   {
     *__result = *__first1;
     ++__first1;
     ++__first2;
     ++__result;
   }
      return __result;
    }
# 5288 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator1, typename _InputIterator2,
    typename _OutputIterator>
    constexpr
    inline _OutputIterator
    set_intersection(_InputIterator1 __first1, _InputIterator1 __last1,
       _InputIterator2 __first2, _InputIterator2 __last2,
       _OutputIterator __result)
    {

     
     
     

     


     


      ;
      ;
      ;
      ;

      return std::__set_intersection(__first1, __last1,
         __first2, __last2, __result,
         __gnu_cxx::__ops::__iter_less_iter());
    }
# 5338 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator1, typename _InputIterator2,
    typename _OutputIterator, typename _Compare>
    constexpr
    inline _OutputIterator
    set_intersection(_InputIterator1 __first1, _InputIterator1 __last1,
       _InputIterator2 __first2, _InputIterator2 __last2,
       _OutputIterator __result, _Compare __comp)
    {

     
     
     

     


     


      ;
      ;
      ;
      ;

      return std::__set_intersection(__first1, __last1,
    __first2, __last2, __result,
    __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }

  template<typename _InputIterator1, typename _InputIterator2,
    typename _OutputIterator,
    typename _Compare>
    constexpr
    _OutputIterator
    __set_difference(_InputIterator1 __first1, _InputIterator1 __last1,
       _InputIterator2 __first2, _InputIterator2 __last2,
       _OutputIterator __result, _Compare __comp)
    {
      while (__first1 != __last1 && __first2 != __last2)
 if (__comp(__first1, __first2))
   {
     *__result = *__first1;
     ++__first1;
     ++__result;
   }
 else if (__comp(__first2, __first1))
   ++__first2;
 else
   {
     ++__first1;
     ++__first2;
   }
      return std::copy(__first1, __last1, __result);
    }
# 5413 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator1, typename _InputIterator2,
    typename _OutputIterator>
    constexpr
    inline _OutputIterator
    set_difference(_InputIterator1 __first1, _InputIterator1 __last1,
     _InputIterator2 __first2, _InputIterator2 __last2,
     _OutputIterator __result)
    {

     
     
     

     


     


      ;
      ;
      ;
      ;

      return std::__set_difference(__first1, __last1,
       __first2, __last2, __result,
       __gnu_cxx::__ops::__iter_less_iter());
    }
# 5465 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator1, typename _InputIterator2,
    typename _OutputIterator, typename _Compare>
    constexpr
    inline _OutputIterator
    set_difference(_InputIterator1 __first1, _InputIterator1 __last1,
     _InputIterator2 __first2, _InputIterator2 __last2,
     _OutputIterator __result, _Compare __comp)
    {

     
     
     

     


     


      ;
      ;
      ;
      ;

      return std::__set_difference(__first1, __last1,
       __first2, __last2, __result,
       __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }

  template<typename _InputIterator1, typename _InputIterator2,
    typename _OutputIterator,
    typename _Compare>
    constexpr
    _OutputIterator
    __set_symmetric_difference(_InputIterator1 __first1,
          _InputIterator1 __last1,
          _InputIterator2 __first2,
          _InputIterator2 __last2,
          _OutputIterator __result,
          _Compare __comp)
    {
      while (__first1 != __last1 && __first2 != __last2)
 if (__comp(__first1, __first2))
   {
     *__result = *__first1;
     ++__first1;
     ++__result;
   }
 else if (__comp(__first2, __first1))
   {
     *__result = *__first2;
     ++__first2;
     ++__result;
   }
 else
   {
     ++__first1;
     ++__first2;
   }
      return std::copy(__first2, __last2,
         std::copy(__first1, __last1, __result));
    }
# 5546 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator1, typename _InputIterator2,
    typename _OutputIterator>
    constexpr
    inline _OutputIterator
    set_symmetric_difference(_InputIterator1 __first1, _InputIterator1 __last1,
        _InputIterator2 __first2, _InputIterator2 __last2,
        _OutputIterator __result)
    {

     
     
     

     

     


     


      ;
      ;
      ;
      ;

      return std::__set_symmetric_difference(__first1, __last1,
     __first2, __last2, __result,
     __gnu_cxx::__ops::__iter_less_iter());
    }
# 5598 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _InputIterator1, typename _InputIterator2,
    typename _OutputIterator, typename _Compare>
    constexpr
    inline _OutputIterator
    set_symmetric_difference(_InputIterator1 __first1, _InputIterator1 __last1,
        _InputIterator2 __first2, _InputIterator2 __last2,
        _OutputIterator __result,
        _Compare __comp)
    {

     
     
     

     

     


     


      ;
      ;
      ;
      ;

      return std::__set_symmetric_difference(__first1, __last1,
    __first2, __last2, __result,
    __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }

  template<typename _ForwardIterator, typename _Compare>
    constexpr
    _ForwardIterator
    __min_element(_ForwardIterator __first, _ForwardIterator __last,
    _Compare __comp)
    {
      if (__first == __last)
 return __first;
      _ForwardIterator __result = __first;
      while (++__first != __last)
 if (__comp(__first, __result))
   __result = __first;
      return __result;
    }
# 5652 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator>
    [[__nodiscard__]] constexpr
    _ForwardIterator
    inline min_element(_ForwardIterator __first, _ForwardIterator __last)
    {

     
     

      ;
      ;

      return std::__min_element(__first, __last,
    __gnu_cxx::__ops::__iter_less_iter());
    }
# 5677 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Compare>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator
    min_element(_ForwardIterator __first, _ForwardIterator __last,
  _Compare __comp)
    {

     
     


      ;
      ;

      return std::__min_element(__first, __last,
    __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }

  template<typename _ForwardIterator, typename _Compare>
    constexpr
    _ForwardIterator
    __max_element(_ForwardIterator __first, _ForwardIterator __last,
    _Compare __comp)
    {
      if (__first == __last) return __first;
      _ForwardIterator __result = __first;
      while (++__first != __last)
 if (__comp(__result, __first))
   __result = __first;
      return __result;
    }
# 5716 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator
    max_element(_ForwardIterator __first, _ForwardIterator __last)
    {

     
     

      ;
      ;

      return std::__max_element(__first, __last,
    __gnu_cxx::__ops::__iter_less_iter());
    }
# 5741 "C:/msys64/mingw64/include/c++/15.2.0/bits/stl_algo.h" 3
  template<typename _ForwardIterator, typename _Compare>
    [[__nodiscard__]] constexpr
    inline _ForwardIterator
    max_element(_ForwardIterator __first, _ForwardIterator __last,
  _Compare __comp)
    {

     
     


      ;
      ;

      return std::__max_element(__first, __last,
    __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }



  template<typename _Tp>
    constexpr
    inline _Tp
    min(initializer_list<_Tp> __l)
    {
      ;
      return *std::__min_element(__l.begin(), __l.end(),
   __gnu_cxx::__ops::__iter_less_iter());
    }

  template<typename _Tp, typename _Compare>
    constexpr
    inline _Tp
    min(initializer_list<_Tp> __l, _Compare __comp)
    {
      ;
      return *std::__min_element(__l.begin(), __l.end(),
   __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }

  template<typename _Tp>
    constexpr
    inline _Tp
    max(initializer_list<_Tp> __l)
    {
      ;
      return *std::__max_element(__l.begin(), __l.end(),
   __gnu_cxx::__ops::__iter_less_iter());
    }

  template<typename _Tp, typename _Compare>
    constexpr
    inline _Tp
    max(initializer_list<_Tp> __l, _Compare __comp)
    {
      ;
      return *std::__max_element(__l.begin(), __l.end(),
   __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }




  template<typename _InputIterator, typename _RandomAccessIterator,
           typename _Size, typename _UniformRandomBitGenerator>
    _RandomAccessIterator
    __sample(_InputIterator __first, _InputIterator __last, input_iterator_tag,
      _RandomAccessIterator __out, random_access_iterator_tag,
      _Size __n, _UniformRandomBitGenerator&& __g)
    {
      using __distrib_type = uniform_int_distribution<_Size>;
      using __param_type = typename __distrib_type::param_type;
      __distrib_type __d{};
      _Size __sample_sz = 0;
      while (__first != __last && __sample_sz != __n)
 {
   __out[__sample_sz++] = *__first;
   ++__first;
 }
      for (auto __pop_sz = __sample_sz; __first != __last;
   ++__first, (void) ++__pop_sz)
 {
   const auto __k = __d(__g, __param_type{0, __pop_sz});
   if (__k < __n)
     __out[__k] = *__first;
 }
      return __out + __sample_sz;
    }


  template<typename _ForwardIterator, typename _OutputIterator, typename _Cat,
           typename _Size, typename _UniformRandomBitGenerator>
    _OutputIterator
    __sample(_ForwardIterator __first, _ForwardIterator __last,
      forward_iterator_tag,
      _OutputIterator __out, _Cat,
      _Size __n, _UniformRandomBitGenerator&& __g)
    {
      using __distrib_type = uniform_int_distribution<_Size>;
      using __param_type = typename __distrib_type::param_type;
      using _USize = make_unsigned_t<_Size>;
      using _Gen = remove_reference_t<_UniformRandomBitGenerator>;
      using __uc_type = common_type_t<typename _Gen::result_type, _USize>;

      if (__first == __last)
 return __out;

      __distrib_type __d{};
      _Size __unsampled_sz = std::distance(__first, __last);
      __n = std::min(__n, __unsampled_sz);




      const __uc_type __urngrange = __g.max() - __g.min();
      if (__urngrange / __uc_type(__unsampled_sz) >= __uc_type(__unsampled_sz))


        {
   while (__n != 0 && __unsampled_sz >= 2)
     {
       const pair<_Size, _Size> __p =
  __gen_two_uniform_ints(__unsampled_sz, __unsampled_sz - 1, __g);

       --__unsampled_sz;
       if (__p.first < __n)
  {
    *__out++ = *__first;
    --__n;
  }

       ++__first;

       if (__n == 0) break;

       --__unsampled_sz;
       if (__p.second < __n)
  {
    *__out++ = *__first;
    --__n;
  }

       ++__first;
     }
        }



      for (; __n != 0; ++__first)
 if (__d(__g, __param_type{0, --__unsampled_sz}) < __n)
   {
     *__out++ = *__first;
     --__n;
   }
      return __out;
    }




  template<typename _PopulationIterator, typename _SampleIterator,
           typename _Distance, typename _UniformRandomBitGenerator>
    _SampleIterator
    sample(_PopulationIterator __first, _PopulationIterator __last,
    _SampleIterator __out, _Distance __n,
    _UniformRandomBitGenerator&& __g)
    {
      using __pop_cat = typename
 std::iterator_traits<_PopulationIterator>::iterator_category;
      using __samp_cat = typename
 std::iterator_traits<_SampleIterator>::iterator_category;

      static_assert(
   __or_<is_convertible<__pop_cat, forward_iterator_tag>,
  is_convertible<__samp_cat, random_access_iterator_tag>>::value,
   "output range must use a RandomAccessIterator when input range"
   " does not meet the ForwardIterator requirements");

      static_assert(is_integral<_Distance>::value,
      "sample size must be an integer type");

      typename iterator_traits<_PopulationIterator>::difference_type __d = __n;
      return std::
 __sample(__first, __last, __pop_cat{}, __out, __samp_cat{}, __d,
   std::forward<_UniformRandomBitGenerator>(__g));
    }




}

#pragma GCC diagnostic pop
# 64 "C:/msys64/mingw64/include/c++/15.2.0/algorithm" 2 3

# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_algo.h" 1 3
# 38 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_algo.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_algobase.h" 1 3
# 38 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_algobase.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_base.h" 1 3
# 41 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_base.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/max_size_type.h" 1 3
# 39 "C:/msys64/mingw64/include/c++/15.2.0/bits/max_size_type.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/numbers" 1 3
# 37 "C:/msys64/mingw64/include/c++/15.2.0/numbers" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 38 "C:/msys64/mingw64/include/c++/15.2.0/numbers" 2 3





#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wpedantic"

namespace std
{








namespace numbers
{


  template<typename _Tp>
    using _Enable_if_floating = enable_if_t<is_floating_point_v<_Tp>, _Tp>;



  template<typename _Tp>
    inline constexpr _Tp e_v
      = _Enable_if_floating<_Tp>(2.718281828459045235360287471352662498L);


  template<typename _Tp>
    inline constexpr _Tp log2e_v
      = _Enable_if_floating<_Tp>(1.442695040888963407359924681001892137L);


  template<typename _Tp>
    inline constexpr _Tp log10e_v
      = _Enable_if_floating<_Tp>(0.434294481903251827651128918916605082L);


  template<typename _Tp>
    inline constexpr _Tp pi_v
      = _Enable_if_floating<_Tp>(3.141592653589793238462643383279502884L);


  template<typename _Tp>
    inline constexpr _Tp inv_pi_v
      = _Enable_if_floating<_Tp>(0.318309886183790671537767526745028724L);


  template<typename _Tp>
    inline constexpr _Tp inv_sqrtpi_v
      = _Enable_if_floating<_Tp>(0.564189583547756286948079451560772586L);


  template<typename _Tp>
    inline constexpr _Tp ln2_v
      = _Enable_if_floating<_Tp>(0.693147180559945309417232121458176568L);


  template<typename _Tp>
    inline constexpr _Tp ln10_v
      = _Enable_if_floating<_Tp>(2.302585092994045684017991454684364208L);


  template<typename _Tp>
    inline constexpr _Tp sqrt2_v
      = _Enable_if_floating<_Tp>(1.414213562373095048801688724209698079L);


  template<typename _Tp>
    inline constexpr _Tp sqrt3_v
      = _Enable_if_floating<_Tp>(1.732050807568877293527446341505872367L);


  template<typename _Tp>
    inline constexpr _Tp inv_sqrt3_v
      = _Enable_if_floating<_Tp>(0.577350269189625764509148780501957456L);


  template<typename _Tp>
    inline constexpr _Tp egamma_v
      = _Enable_if_floating<_Tp>(0.577215664901532860606512090082402431L);


  template<typename _Tp>
    inline constexpr _Tp phi_v
      = _Enable_if_floating<_Tp>(1.618033988749894848204586834365638118L);

  inline constexpr double e = e_v<double>;
  inline constexpr double log2e = log2e_v<double>;
  inline constexpr double log10e = log10e_v<double>;
  inline constexpr double pi = pi_v<double>;
  inline constexpr double inv_pi = inv_pi_v<double>;
  inline constexpr double inv_sqrtpi = inv_sqrtpi_v<double>;
  inline constexpr double ln2 = ln2_v<double>;
  inline constexpr double ln10 = ln10_v<double>;
  inline constexpr double sqrt2 = sqrt2_v<double>;
  inline constexpr double sqrt3 = sqrt3_v<double>;
  inline constexpr double inv_sqrt3 = inv_sqrt3_v<double>;
  inline constexpr double egamma = egamma_v<double>;
  inline constexpr double phi = phi_v<double>;
# 230 "C:/msys64/mingw64/include/c++/15.2.0/numbers" 3
template<> inline constexpr __float128 e_v<__float128> = 2.718281828459045235360287471352662498Q; template<> inline constexpr __float128 log2e_v<__float128> = 1.442695040888963407359924681001892137Q; template<> inline constexpr __float128 log10e_v<__float128> = 0.434294481903251827651128918916605082Q; template<> inline constexpr __float128 pi_v<__float128> = 3.141592653589793238462643383279502884Q; template<> inline constexpr __float128 inv_pi_v<__float128> = 0.318309886183790671537767526745028724Q; template<> inline constexpr __float128 inv_sqrtpi_v<__float128> = 0.564189583547756286948079451560772586Q; template<> inline constexpr __float128 ln2_v<__float128> = 0.693147180559945309417232121458176568Q; template<> inline constexpr __float128 ln10_v<__float128> = 2.302585092994045684017991454684364208Q; template<> inline constexpr __float128 sqrt2_v<__float128> = 1.414213562373095048801688724209698079Q; template<> inline constexpr __float128 sqrt3_v<__float128> = 1.732050807568877293527446341505872367Q; template<> inline constexpr __float128 inv_sqrt3_v<__float128> = 0.577350269189625764509148780501957456Q; template<> inline constexpr __float128 egamma_v<__float128> = 0.577215664901532860606512090082402431Q; template<> inline constexpr __float128 phi_v<__float128> = 1.618033988749894848204586834365638118Q;




}


}

#pragma GCC diagnostic pop
# 40 "C:/msys64/mingw64/include/c++/15.2.0/bits/max_size_type.h" 2 3
# 50 "C:/msys64/mingw64/include/c++/15.2.0/bits/max_size_type.h" 3
namespace std
{


template<typename _Tp>
  struct numeric_limits;

namespace ranges
{
  namespace __detail
  {
    class __max_size_type
    {
    public:
      __max_size_type() = default;

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 constexpr
 __max_size_type(_Tp __i) noexcept
   : _M_val(__i), _M_msb(__i < 0)
 { }

      constexpr explicit
      __max_size_type(const __max_diff_type& __d) noexcept;

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 constexpr explicit
 operator _Tp() const noexcept
 { return _M_val; }

      constexpr explicit
      operator bool() const noexcept
      { return _M_val != 0 || _M_msb != 0; }

      constexpr __max_size_type
      operator+() const noexcept
      { return *this; }

      constexpr __max_size_type
      operator~() const noexcept
      { return __max_size_type{~_M_val, !_M_msb}; }

      constexpr __max_size_type
      operator-() const noexcept
      { return operator~() + 1; }

      constexpr __max_size_type&
      operator++() noexcept
      { return *this += 1; }

      constexpr __max_size_type
      operator++(int) noexcept
      {
 auto __tmp = *this;
 ++*this;
 return __tmp;
      }

      constexpr __max_size_type&
      operator--() noexcept
      { return *this -= 1; }

      constexpr __max_size_type
      operator--(int) noexcept
      {
 auto __tmp = *this;
 --*this;
 return __tmp;
      }

      constexpr __max_size_type&
      operator+=(const __max_size_type& __r) noexcept
      {
 const auto __sum = _M_val + __r._M_val;
 const bool __overflow = (__sum < _M_val);
 _M_msb = _M_msb ^ __r._M_msb ^ __overflow;
 _M_val = __sum;
 return *this;
      }

      constexpr __max_size_type&
      operator-=(const __max_size_type& __r) noexcept
      { return *this += -__r; }

      constexpr __max_size_type&
      operator*=(__max_size_type __r) noexcept
      {
 constexpr __max_size_type __threshold
   = __rep(1) << (_S_rep_bits / 2 - 1);
 if (_M_val < __threshold && __r < __threshold)


   _M_val = _M_val * __r._M_val;
 else
   {



     const bool __lsb = _M_val & 1;
     const bool __rlsb = __r._M_val & 1;
     *this >>= 1;
     __r >>= 1;
     _M_val = (2 * _M_val * __r._M_val
        + _M_val * __rlsb + __r._M_val * __lsb);
     *this <<= 1;
     *this += __rlsb * __lsb;
   }

 return *this;
      }

      constexpr __max_size_type&
      operator/=(const __max_size_type& __r) noexcept
      {
 do { if (__builtin_expect(!bool(__r != 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/max_size_type.h", 164, __PRETTY_FUNCTION__, "__r != 0"); } while (false);

 if (!_M_msb && !__r._M_msb) [[likely]]
   _M_val /= __r._M_val;
 else if (_M_msb && __r._M_msb)
   {
     _M_val = (_M_val >= __r._M_val);
     _M_msb = 0;
   }
 else if (!_M_msb && __r._M_msb)
   _M_val = 0;
 else if (_M_msb && !__r._M_msb)
   {




     const auto __orig = *this;
     *this >>= 1;
     _M_val /= __r._M_val;
     *this <<= 1;
     if (__orig - *this * __r >= __r)
       ++_M_val;
   }
 return *this;
      }

      constexpr __max_size_type&
      operator%=(const __max_size_type& __r) noexcept
      {
 if (!_M_msb && !__r._M_msb) [[likely]]
   _M_val %= __r._M_val;
 else
   *this -= (*this / __r) * __r;
 return *this;
      }

      constexpr __max_size_type&
      operator<<=(const __max_size_type& __r) noexcept
      {
 do { if (__builtin_expect(!bool(__r <= _S_rep_bits), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/max_size_type.h", 204, __PRETTY_FUNCTION__, "__r <= _S_rep_bits"); } while (false);
 if (__r != 0)
   {
     _M_msb = (_M_val >> (_S_rep_bits - __r._M_val)) & 1;

     if (__r._M_val == _S_rep_bits) [[unlikely]]
       _M_val = 0;
     else
       _M_val <<= __r._M_val;
   }
 return *this;
      }

      constexpr __max_size_type&
      operator>>=(const __max_size_type& __r) noexcept
      {
 do { if (__builtin_expect(!bool(__r <= _S_rep_bits), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/max_size_type.h", 220, __PRETTY_FUNCTION__, "__r <= _S_rep_bits"); } while (false);
 if (__r != 0)
   {
     if (__r._M_val == _S_rep_bits) [[unlikely]]
       _M_val = 0;
     else
       _M_val >>= __r._M_val;

     if (_M_msb) [[unlikely]]
       {
  _M_val |= __rep(1) << (_S_rep_bits - __r._M_val);
  _M_msb = 0;
       }
   }
 return *this;
      }

      constexpr __max_size_type&
      operator&=(const __max_size_type& __r) noexcept
      {
 _M_val &= __r._M_val;
 _M_msb &= __r._M_msb;
 return *this;
      }

      constexpr __max_size_type&
      operator|=(const __max_size_type& __r) noexcept
      {
 _M_val |= __r._M_val;
 _M_msb |= __r._M_msb;
 return *this;
      }

      constexpr __max_size_type&
      operator^=(const __max_size_type& __r) noexcept
      {
 _M_val ^= __r._M_val;
 _M_msb ^= __r._M_msb;
 return *this;
      }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator+=(_Tp& __a, const __max_size_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a + __b)); }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator-=(_Tp& __a, const __max_size_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a - __b)); }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator*=(_Tp& __a, const __max_size_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a * __b)); }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator/=(_Tp& __a, const __max_size_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a / __b)); }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator%=(_Tp& __a, const __max_size_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a % __b)); }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator&=(_Tp& __a, const __max_size_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a & __b)); }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator|=(_Tp& __a, const __max_size_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a | __b)); }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator^=(_Tp& __a, const __max_size_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a ^ __b)); }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator<<=(_Tp& __a, const __max_size_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a << __b)); }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator>>=(_Tp& __a, const __max_size_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a >> __b)); }

      friend constexpr __max_size_type
      operator+(__max_size_type __l, const __max_size_type& __r) noexcept
      {
 __l += __r;
 return __l;
      }

      friend constexpr __max_size_type
      operator-(__max_size_type __l, const __max_size_type& __r) noexcept
      {
 __l -= __r;
 return __l;
      }

      friend constexpr __max_size_type
      operator*(__max_size_type __l, const __max_size_type& __r) noexcept
      {
 __l *= __r;
 return __l;
      }

      friend constexpr __max_size_type
      operator/(__max_size_type __l, const __max_size_type& __r) noexcept
      {
 __l /= __r;
 return __l;
      }

      friend constexpr __max_size_type
      operator%(__max_size_type __l, const __max_size_type& __r) noexcept
      {
 __l %= __r;
 return __l;
      }

      friend constexpr __max_size_type
      operator<<(__max_size_type __l, const __max_size_type& __r) noexcept
      {
 __l <<= __r;
 return __l;
      }

      friend constexpr __max_size_type
      operator>>(__max_size_type __l, const __max_size_type& __r) noexcept
      {
 __l >>= __r;
 return __l;
      }

      friend constexpr __max_size_type
      operator&(__max_size_type __l, const __max_size_type& __r) noexcept
      {
 __l &= __r;
 return __l;
      }

      friend constexpr __max_size_type
      operator|(__max_size_type __l, const __max_size_type& __r) noexcept
      {
 __l |= __r;
 return __l;
      }

      friend constexpr __max_size_type
      operator^(__max_size_type __l, const __max_size_type& __r) noexcept
      {
 __l ^= __r;
 return __l;
      }

      friend constexpr bool
      operator==(const __max_size_type& __l, const __max_size_type& __r) noexcept
      { return __l._M_val == __r._M_val && __l._M_msb == __r._M_msb; }


      friend constexpr strong_ordering
      operator<=>(const __max_size_type& __l, const __max_size_type& __r) noexcept
      {
 if (__l._M_msb ^ __r._M_msb)
   return __l._M_msb ? strong_ordering::greater : strong_ordering::less;
 else
   return __l._M_val <=> __r._M_val;
      }
# 422 "C:/msys64/mingw64/include/c++/15.2.0/bits/max_size_type.h" 3
      __extension__
      using __rep = unsigned __int128;



      static constexpr size_t _S_rep_bits = sizeof(__rep) * 8;
    private:
      __rep _M_val = 0;
      unsigned _M_msb:1 = 0;

      constexpr explicit
      __max_size_type(__rep __val, int __msb) noexcept
 : _M_val(__val), _M_msb(__msb)
      { }

      friend __max_diff_type;
      friend std::numeric_limits<__max_size_type>;
      friend std::numeric_limits<__max_diff_type>;
    };

    class __max_diff_type
    {
    public:
      __max_diff_type() = default;

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 constexpr
 __max_diff_type(_Tp __i) noexcept
   : _M_rep(__i)
 { }

      constexpr explicit
      __max_diff_type(const __max_size_type& __d) noexcept
 : _M_rep(__d)
      { }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 constexpr explicit
 operator _Tp() const noexcept
 { return static_cast<_Tp>(_M_rep); }

      constexpr explicit
      operator bool() const noexcept
      { return _M_rep != 0; }

      constexpr __max_diff_type
      operator+() const noexcept
      { return *this; }

      constexpr __max_diff_type
      operator-() const noexcept
      { return __max_diff_type(-_M_rep); }

      constexpr __max_diff_type
      operator~() const noexcept
      { return __max_diff_type(~_M_rep); }

      constexpr __max_diff_type&
      operator++() noexcept
      { return *this += 1; }

      constexpr __max_diff_type
      operator++(int) noexcept
      {
 auto __tmp = *this;
 ++*this;
 return __tmp;
      }

      constexpr __max_diff_type&
      operator--() noexcept
      { return *this -= 1; }

      constexpr __max_diff_type
      operator--(int) noexcept
      {
 auto __tmp = *this;
 --*this;
 return __tmp;
      }

      constexpr __max_diff_type&
      operator+=(const __max_diff_type& __r) noexcept
      {
 _M_rep += __r._M_rep;
 return *this;
      }

      constexpr __max_diff_type&
      operator-=(const __max_diff_type& __r) noexcept
      {
 _M_rep -= __r._M_rep;
 return *this;
      }

      constexpr __max_diff_type&
      operator*=(const __max_diff_type& __r) noexcept
      {
 _M_rep *= __r._M_rep;
 return *this;
      }

      constexpr __max_diff_type&
      operator/=(const __max_diff_type& __r) noexcept
      {
 do { if (__builtin_expect(!bool(__r != 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/max_size_type.h", 527, __PRETTY_FUNCTION__, "__r != 0"); } while (false);
 const bool __neg = *this < 0;
 const bool __rneg = __r < 0;
 if (!__neg && !__rneg)
   _M_rep = _M_rep / __r._M_rep;
 else if (__neg && __rneg)
   _M_rep = -_M_rep / -__r._M_rep;
 else if (__neg && !__rneg)
   _M_rep = -(-_M_rep / __r._M_rep);
 else
   _M_rep = -(_M_rep / -__r._M_rep);
 return *this ;
      }

      constexpr __max_diff_type&
      operator%=(const __max_diff_type& __r) noexcept
      {
 do { if (__builtin_expect(!bool(__r != 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/max_size_type.h", 544, __PRETTY_FUNCTION__, "__r != 0"); } while (false);
 if (*this >= 0 && __r > 0)
   _M_rep %= __r._M_rep;
 else
   *this -= (*this / __r) * __r;
 return *this;
      }

      constexpr __max_diff_type&
      operator<<=(const __max_diff_type& __r) noexcept
      {
 _M_rep.operator<<=(__r._M_rep);
 return *this;
      }

      constexpr __max_diff_type&
      operator>>=(const __max_diff_type& __r) noexcept
      {

 const auto __msb = _M_rep._M_msb;
 _M_rep >>= __r._M_rep;
 if (__msb)
   _M_rep |= ~(__max_size_type(-1) >> __r._M_rep);
 return *this;
      }

      constexpr __max_diff_type&
      operator&=(const __max_diff_type& __r) noexcept
      {
 _M_rep &= __r._M_rep;
 return *this;
      }

      constexpr __max_diff_type&
      operator|=(const __max_diff_type& __r) noexcept
      {
 _M_rep |= __r._M_rep;
 return *this;
      }

      constexpr __max_diff_type&
      operator^=(const __max_diff_type& __r) noexcept
      {
 _M_rep ^= __r._M_rep;
 return *this;
      }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator+=(_Tp& __a, const __max_diff_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a + __b)); }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator-=(_Tp& __a, const __max_diff_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a - __b)); }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator*=(_Tp& __a, const __max_diff_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a * __b)); }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator/=(_Tp& __a, const __max_diff_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a / __b)); }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator%=(_Tp& __a, const __max_diff_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a % __b)); }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator&=(_Tp& __a, const __max_diff_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a & __b)); }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator|=(_Tp& __a, const __max_diff_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a | __b)); }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator^=(_Tp& __a, const __max_diff_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a ^ __b)); }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator<<=(_Tp& __a, const __max_diff_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a << __b)); }

      template<typename _Tp> requires integral<_Tp> || __is_int128<_Tp>
 friend constexpr _Tp&
 operator>>=(_Tp& __a, const __max_diff_type& __b) noexcept
 { return (__a = static_cast<_Tp>(__a >> __b)); }

      friend constexpr __max_diff_type
      operator+(__max_diff_type __l, const __max_diff_type& __r) noexcept
      {
 __l += __r;
 return __l;
      }

      friend constexpr __max_diff_type
      operator-(__max_diff_type __l, const __max_diff_type& __r) noexcept
      {
 __l -= __r;
 return __l;
      }

      friend constexpr __max_diff_type
      operator*(__max_diff_type __l, const __max_diff_type& __r) noexcept
      {
 __l *= __r;
 return __l;
      }

      friend constexpr __max_diff_type
      operator/(__max_diff_type __l, const __max_diff_type& __r) noexcept
      {
 __l /= __r;
 return __l;
      }

      friend constexpr __max_diff_type
      operator%(__max_diff_type __l, const __max_diff_type& __r) noexcept
      {
 __l %= __r;
 return __l;
      }

      friend constexpr __max_diff_type
      operator<<(__max_diff_type __l, const __max_diff_type& __r) noexcept
      {
 __l <<= __r;
 return __l;
      }

      friend constexpr __max_diff_type
      operator>>(__max_diff_type __l, const __max_diff_type& __r) noexcept
      {
 __l >>= __r;
 return __l;
      }

      friend constexpr __max_diff_type
      operator&(__max_diff_type __l, const __max_diff_type& __r) noexcept
      {
 __l &= __r;
 return __l;
      }

      friend constexpr __max_diff_type
      operator|(__max_diff_type __l, const __max_diff_type& __r) noexcept
      {
 __l |= __r;
 return __l;
      }

      friend constexpr __max_diff_type
      operator^(__max_diff_type __l, const __max_diff_type& __r) noexcept
      {
 __l ^= __r;
 return __l;
      }

      friend constexpr bool
      operator==(const __max_diff_type& __l, const __max_diff_type& __r) noexcept
      { return __l._M_rep == __r._M_rep; }


      constexpr strong_ordering
      operator<=>(const __max_diff_type& __r) const noexcept
      {
 const auto __lsign = _M_rep._M_msb;
 const auto __rsign = __r._M_rep._M_msb;
 if (__lsign ^ __rsign)
   return __lsign ? strong_ordering::less : strong_ordering::greater;
 else
   return _M_rep <=> __r._M_rep;
      }
# 755 "C:/msys64/mingw64/include/c++/15.2.0/bits/max_size_type.h" 3
    private:
      __max_size_type _M_rep = 0;

      friend class __max_size_type;
    };

    constexpr
    __max_size_type::__max_size_type(const __max_diff_type& __d) noexcept
      : __max_size_type(__d._M_rep)
    { }

  }
}

  template<>
    struct numeric_limits<ranges::__detail::__max_size_type>
    {
      using _Sp = ranges::__detail::__max_size_type;
      static constexpr bool is_specialized = true;
      static constexpr bool is_signed = false;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int digits
 = __gnu_cxx::__int_traits<_Sp::__rep>::__digits + 1;
      static constexpr int digits10
 = static_cast<int>(digits * numbers::ln2 / numbers::ln10);

      static constexpr _Sp
      min() noexcept
      { return 0; }

      static constexpr _Sp
      max() noexcept
      { return _Sp(static_cast<_Sp::__rep>(-1), 1); }

      static constexpr _Sp
      lowest() noexcept
      { return min(); }
    };

  template<>
    struct numeric_limits<ranges::__detail::__max_diff_type>
    {
      using _Dp = ranges::__detail::__max_diff_type;
      using _Sp = ranges::__detail::__max_size_type;
      static constexpr bool is_specialized = true;
      static constexpr bool is_signed = true;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int digits = numeric_limits<_Sp>::digits - 1;
      static constexpr int digits10
 = static_cast<int>(digits * numbers::ln2 / numbers::ln10);

      static constexpr _Dp
      min() noexcept
      { return _Dp(_Sp(0, 1)); }

      static constexpr _Dp
      max() noexcept
      { return _Dp(_Sp(static_cast<_Sp::__rep>(-1), 0)); }

      static constexpr _Dp
      lowest() noexcept
      { return min(); }
    };


}
# 42 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_base.h" 2 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 43 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_base.h" 2 3





#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wpedantic"
# 58 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_base.h" 3
namespace std
{

namespace ranges
{
  template<typename>
    inline constexpr bool disable_sized_range = false;

  template<typename _Tp>
    inline constexpr bool enable_borrowed_range = false;

  namespace __detail
  {
    constexpr __max_size_type
    __to_unsigned_like(__max_size_type __t) noexcept
    { return __t; }

    constexpr __max_size_type
    __to_unsigned_like(__max_diff_type __t) noexcept
    { return __max_size_type(__t); }

    template<integral _Tp>
      constexpr auto
      __to_unsigned_like(_Tp __t) noexcept
      { return static_cast<make_unsigned_t<_Tp>>(__t); }
# 94 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_base.h" 3
    template<typename _Tp>
      using __make_unsigned_like_t
 = decltype(__detail::__to_unsigned_like(std::declval<_Tp>()));


    template<typename _Tp>
      concept __maybe_borrowed_range
 = is_lvalue_reference_v<_Tp>
   || enable_borrowed_range<remove_cvref_t<_Tp>>;

  }


  namespace __access
  {
    using std::ranges::__detail::__maybe_borrowed_range;
    using std::__detail::__range_iter_t;

    struct _Begin
    {
    private:
      template<typename _Tp>
 static constexpr bool
 _S_noexcept()
 {
   if constexpr (is_array_v<remove_reference_t<_Tp>>)
     return true;
   else if constexpr (__member_begin<_Tp>)
     return noexcept(__decay_copy(std::declval<_Tp&>().begin()));
   else
     return noexcept(__decay_copy(begin(std::declval<_Tp&>())));
 }

    public:
      template<__maybe_borrowed_range _Tp>
 requires is_array_v<remove_reference_t<_Tp>> || __member_begin<_Tp>
   || __adl_begin<_Tp>
 constexpr auto
 operator()[[nodiscard]](_Tp&& __t) const noexcept(_S_noexcept<_Tp&>())
 {
   if constexpr (is_array_v<remove_reference_t<_Tp>>)
     {
       static_assert(is_lvalue_reference_v<_Tp>);
       return __t + 0;
     }
   else if constexpr (__member_begin<_Tp>)
     return __t.begin();
   else
     return begin(__t);
 }
    };

    template<typename _Tp>
      concept __member_end = requires(_Tp& __t)
 {
   { __decay_copy(__t.end()) } -> sentinel_for<__range_iter_t<_Tp>>;
 };


    void end() = delete;

    template<typename _Tp>
      concept __adl_end = __class_or_enum<remove_reference_t<_Tp>>
 && requires(_Tp& __t)
 {
   { __decay_copy(end(__t)) } -> sentinel_for<__range_iter_t<_Tp>>;
 };

    struct _End
    {
    private:
      template<typename _Tp>
 static constexpr bool
 _S_noexcept()
 {
   if constexpr (is_bounded_array_v<remove_reference_t<_Tp>>)
     return true;
   else if constexpr (__member_end<_Tp>)
     return noexcept(__decay_copy(std::declval<_Tp&>().end()));
   else
     return noexcept(__decay_copy(end(std::declval<_Tp&>())));
 }

    public:
      template<__maybe_borrowed_range _Tp>
 requires is_bounded_array_v<remove_reference_t<_Tp>>
   || __member_end<_Tp> || __adl_end<_Tp>
 constexpr auto
 operator()[[nodiscard]](_Tp&& __t) const noexcept(_S_noexcept<_Tp&>())
 {
   if constexpr (is_bounded_array_v<remove_reference_t<_Tp>>)
     {
       static_assert(is_lvalue_reference_v<_Tp>);
       return __t + extent_v<remove_reference_t<_Tp>>;
     }
   else if constexpr (__member_end<_Tp>)
     return __t.end();
   else
     return end(__t);
 }
    };

    template<typename _Tp>
      concept __member_rbegin = requires(_Tp& __t)
 {
   { __decay_copy(__t.rbegin()) } -> input_or_output_iterator;
 };

    void rbegin() = delete;

    template<typename _Tp>
      concept __adl_rbegin = __class_or_enum<remove_reference_t<_Tp>>
 && requires(_Tp& __t)
 {
   { __decay_copy(rbegin(__t)) } -> input_or_output_iterator;
 };

    template<typename _Tp>
      concept __reversable = requires(_Tp& __t)
 {
   { _Begin{}(__t) } -> bidirectional_iterator;
   { _End{}(__t) } -> same_as<decltype(_Begin{}(__t))>;
 };

    struct _RBegin
    {
    private:
      template<typename _Tp>
 static constexpr bool
 _S_noexcept()
 {
   if constexpr (__member_rbegin<_Tp>)
     return noexcept(__decay_copy(std::declval<_Tp&>().rbegin()));
   else if constexpr (__adl_rbegin<_Tp>)
     return noexcept(__decay_copy(rbegin(std::declval<_Tp&>())));
   else
     {
       if constexpr (noexcept(_End{}(std::declval<_Tp&>())))
  {
    using _It = decltype(_End{}(std::declval<_Tp&>()));

    return is_nothrow_copy_constructible_v<_It>;
  }
       else
  return false;
     }
 }

    public:
      template<__maybe_borrowed_range _Tp>
 requires __member_rbegin<_Tp> || __adl_rbegin<_Tp> || __reversable<_Tp>
 constexpr auto
 operator()[[nodiscard]](_Tp&& __t) const
 noexcept(_S_noexcept<_Tp&>())
 {
   if constexpr (__member_rbegin<_Tp>)
     return __t.rbegin();
   else if constexpr (__adl_rbegin<_Tp>)
     return rbegin(__t);
   else
     return std::make_reverse_iterator(_End{}(__t));
 }
    };

    template<typename _Tp>
      concept __member_rend = requires(_Tp& __t)
 {
   { __decay_copy(__t.rend()) }
     -> sentinel_for<decltype(_RBegin{}(std::forward<_Tp>(__t)))>;
 };

    void rend() = delete;

    template<typename _Tp>
      concept __adl_rend = __class_or_enum<remove_reference_t<_Tp>>
 && requires(_Tp& __t)
 {
   { __decay_copy(rend(__t)) }
     -> sentinel_for<decltype(_RBegin{}(std::forward<_Tp>(__t)))>;
 };

    struct _REnd
    {
    private:
      template<typename _Tp>
 static constexpr bool
 _S_noexcept()
 {
   if constexpr (__member_rend<_Tp>)
     return noexcept(__decay_copy(std::declval<_Tp&>().rend()));
   else if constexpr (__adl_rend<_Tp>)
     return noexcept(__decay_copy(rend(std::declval<_Tp&>())));
   else
     {
       if constexpr (noexcept(_Begin{}(std::declval<_Tp&>())))
  {
    using _It = decltype(_Begin{}(std::declval<_Tp&>()));

    return is_nothrow_copy_constructible_v<_It>;
  }
       else
  return false;
     }
 }

    public:
      template<__maybe_borrowed_range _Tp>
 requires __member_rend<_Tp> || __adl_rend<_Tp> || __reversable<_Tp>
 constexpr auto
 operator()[[nodiscard]](_Tp&& __t) const
 noexcept(_S_noexcept<_Tp&>())
 {
   if constexpr (__member_rend<_Tp>)
     return __t.rend();
   else if constexpr (__adl_rend<_Tp>)
     return rend(__t);
   else
     return std::make_reverse_iterator(_Begin{}(__t));
 }
    };

    template<typename _Tp>
      concept __member_size = !disable_sized_range<remove_cvref_t<_Tp>>
 && requires(_Tp& __t)
 {
   { __decay_copy(__t.size()) } -> __detail::__is_integer_like;
 };

    void size() = delete;

    template<typename _Tp>
      concept __adl_size = __class_or_enum<remove_reference_t<_Tp>>
 && !disable_sized_range<remove_cvref_t<_Tp>>
 && requires(_Tp& __t)
 {
   { __decay_copy(size(__t)) } -> __detail::__is_integer_like;
 };

    template<typename _Tp>
      concept __sentinel_size = requires(_Tp& __t)
 {
   requires (!is_unbounded_array_v<remove_reference_t<_Tp>>);

   { _Begin{}(__t) } -> forward_iterator;

   { _End{}(__t) } -> sized_sentinel_for<decltype(_Begin{}(__t))>;

   __detail::__to_unsigned_like(_End{}(__t) - _Begin{}(__t));
 };

    struct _Size
    {
    private:
      template<typename _Tp>
 static constexpr bool
 _S_noexcept()
 {
   if constexpr (is_bounded_array_v<remove_reference_t<_Tp>>)
     return true;
   else if constexpr (__member_size<_Tp>)
     return noexcept(__decay_copy(std::declval<_Tp&>().size()));
   else if constexpr (__adl_size<_Tp>)
     return noexcept(__decay_copy(size(std::declval<_Tp&>())));
   else if constexpr (__sentinel_size<_Tp>)
     return noexcept(_End{}(std::declval<_Tp&>())
       - _Begin{}(std::declval<_Tp&>()));
 }

    public:
      template<typename _Tp>
 requires is_bounded_array_v<remove_reference_t<_Tp>>
   || __member_size<_Tp> || __adl_size<_Tp> || __sentinel_size<_Tp>
 constexpr auto
 operator()[[nodiscard]](_Tp&& __t) const noexcept(_S_noexcept<_Tp&>())
 {
   if constexpr (is_bounded_array_v<remove_reference_t<_Tp>>)
     return extent_v<remove_reference_t<_Tp>>;
   else if constexpr (__member_size<_Tp>)
     return __t.size();
   else if constexpr (__adl_size<_Tp>)
     return size(__t);
   else if constexpr (__sentinel_size<_Tp>)
     return __detail::__to_unsigned_like(_End{}(__t) - _Begin{}(__t));
 }
    };

    struct _SSize
    {


      template<typename _Tp>
 requires requires (_Tp& __t) { _Size{}(__t); }
 constexpr auto
 operator()[[nodiscard]](_Tp&& __t) const noexcept(noexcept(_Size{}(__t)))
 {
   auto __size = _Size{}(__t);
   using __size_type = decltype(__size);

   if constexpr (integral<__size_type>)
     {
       using __gnu_cxx::__int_traits;
       if constexpr (__int_traits<__size_type>::__digits
       < __int_traits<ptrdiff_t>::__digits)
  return static_cast<ptrdiff_t>(__size);
       else
  return static_cast<make_signed_t<__size_type>>(__size);
     }





   else
     return __detail::__max_diff_type(__size);
 }
    };

    template<typename _Tp>
      concept __member_empty = requires(_Tp& __t) { bool(__t.empty()); };

    template<typename _Tp>
      concept __size0_empty = requires(_Tp& __t) { _Size{}(__t) == 0; };

    template<typename _Tp>
      concept __eq_iter_empty = requires(_Tp& __t)
 {
   requires (!is_unbounded_array_v<remove_reference_t<_Tp>>);

   { _Begin{}(__t) } -> forward_iterator;

   bool(_Begin{}(__t) == _End{}(__t));
 };

    struct _Empty
    {
    private:
      template<typename _Tp>
 static constexpr bool
 _S_noexcept()
 {
   if constexpr (__member_empty<_Tp>)
     return noexcept(bool(std::declval<_Tp&>().empty()));
   else if constexpr (__size0_empty<_Tp>)
     return noexcept(_Size{}(std::declval<_Tp&>()) == 0);
   else
     return noexcept(bool(_Begin{}(std::declval<_Tp&>())
  == _End{}(std::declval<_Tp&>())));
 }

    public:
      template<typename _Tp>
 requires __member_empty<_Tp> || __size0_empty<_Tp>
   || __eq_iter_empty<_Tp>
 constexpr bool
 operator()[[nodiscard]](_Tp&& __t) const noexcept(_S_noexcept<_Tp&>())
 {
   if constexpr (__member_empty<_Tp>)
     return bool(__t.empty());
   else if constexpr (__size0_empty<_Tp>)
     return _Size{}(__t) == 0;
   else
     return bool(_Begin{}(__t) == _End{}(__t));
 }
    };

    template<typename _Tp>
      concept __pointer_to_object = is_pointer_v<_Tp>
        && is_object_v<remove_pointer_t<_Tp>>;

    template<typename _Tp>
      concept __member_data = requires(_Tp& __t)
 {
   { __decay_copy(__t.data()) } -> __pointer_to_object;
 };

    template<typename _Tp>
      concept __begin_data = contiguous_iterator<__range_iter_t<_Tp>>;

    struct _Data
    {
    private:
      template<typename _Tp>
 static constexpr bool
 _S_noexcept()
 {
   if constexpr (__member_data<_Tp>)
     return noexcept(__decay_copy(std::declval<_Tp&>().data()));
   else
     return noexcept(_Begin{}(std::declval<_Tp&>()));
 }

    public:
      template<__maybe_borrowed_range _Tp>
 requires __member_data<_Tp> || __begin_data<_Tp>
 constexpr auto
 operator()[[nodiscard]](_Tp&& __t) const noexcept(_S_noexcept<_Tp>())
 {
   if constexpr (__member_data<_Tp>)
     return __t.data();
   else
     return std::to_address(_Begin{}(__t));
 }
    };

  }

  inline namespace _Cpo
  {
    inline constexpr ranges::__access::_Begin begin{};
    inline constexpr ranges::__access::_End end{};
    inline constexpr ranges::__access::_RBegin rbegin{};
    inline constexpr ranges::__access::_REnd rend{};
    inline constexpr ranges::__access::_Size size{};
    inline constexpr ranges::__access::_SSize ssize{};
    inline constexpr ranges::__access::_Empty empty{};
    inline constexpr ranges::__access::_Data data{};
  }


  template<typename _Tp>
    concept range = requires(_Tp& __t)
      {
 ranges::begin(__t);
 ranges::end(__t);
      };


  template<typename _Tp>
    concept borrowed_range
      = range<_Tp> && __detail::__maybe_borrowed_range<_Tp>;

  template<typename _Tp>
    using iterator_t = std::__detail::__range_iter_t<_Tp>;

  template<range _Range>
    using sentinel_t = decltype(ranges::end(std::declval<_Range&>()));
# 542 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_base.h" 3
  template<range _Range>
    using range_difference_t = iter_difference_t<iterator_t<_Range>>;

  template<range _Range>
    using range_value_t = iter_value_t<iterator_t<_Range>>;

  template<range _Range>
    using range_reference_t = iter_reference_t<iterator_t<_Range>>;

  template<range _Range>
    using range_rvalue_reference_t
      = iter_rvalue_reference_t<iterator_t<_Range>>;



  template<range _Range>
    using range_common_reference_t
      = iter_common_reference_t<iterator_t<_Range>>;


  template<typename _Tp>
    concept sized_range = range<_Tp>
      && requires(_Tp& __t) { ranges::size(__t); };

  template<sized_range _Range>
    using range_size_t = decltype(ranges::size(std::declval<_Range&>()));

  template<typename _Derived>
    requires is_class_v<_Derived> && same_as<_Derived, remove_cv_t<_Derived>>
    class view_interface;

  namespace __detail
  {
    template<typename _Tp, typename _Up>
      requires (!same_as<_Tp, view_interface<_Up>>)
      void __is_derived_from_view_interface_fn(const _Tp&,
            const view_interface<_Up>&);



    template<typename _Tp>
      concept __is_derived_from_view_interface
 = requires (_Tp __t) { __is_derived_from_view_interface_fn(__t, __t); };
  }


  struct view_base { };


  template<typename _Tp>
    inline constexpr bool enable_view = derived_from<_Tp, view_base>
      || __detail::__is_derived_from_view_interface<_Tp>;


  template<typename _Tp>
    concept view
      = range<_Tp> && movable<_Tp> && enable_view<_Tp>;




  template<typename _Range, typename _Tp>
    concept output_range
      = range<_Range> && output_iterator<iterator_t<_Range>, _Tp>;


  template<typename _Tp>
    concept input_range = range<_Tp> && input_iterator<iterator_t<_Tp>>;


  template<typename _Tp>
    concept forward_range
      = input_range<_Tp> && forward_iterator<iterator_t<_Tp>>;


  template<typename _Tp>
    concept bidirectional_range
      = forward_range<_Tp> && bidirectional_iterator<iterator_t<_Tp>>;


  template<typename _Tp>
    concept random_access_range
      = bidirectional_range<_Tp> && random_access_iterator<iterator_t<_Tp>>;


  template<typename _Tp>
    concept contiguous_range
      = random_access_range<_Tp> && contiguous_iterator<iterator_t<_Tp>>
      && requires(_Tp& __t)
      {
 { ranges::data(__t) } -> same_as<add_pointer_t<range_reference_t<_Tp>>>;
      };


  template<typename _Tp>
    concept common_range
      = range<_Tp> && same_as<iterator_t<_Tp>, sentinel_t<_Tp>>;







  namespace __access
  {
# 662 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_base.h" 3
    template<typename _To, typename _Tp>
      constexpr decltype(auto)
      __as_const(_Tp& __t) noexcept
      {
 static_assert(std::is_same_v<_To&, _Tp&>);

 if constexpr (is_lvalue_reference_v<_To>)
   return const_cast<const _Tp&>(__t);
 else
   return static_cast<const _Tp&&>(__t);
      }


    struct _CBegin
    {
# 691 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_base.h" 3
      template<typename _Tp>
 [[nodiscard]]
 constexpr auto
 operator()(_Tp&& __e) const
 noexcept(noexcept(_Begin{}(__access::__as_const<_Tp>(__e))))
 requires requires { _Begin{}(__access::__as_const<_Tp>(__e)); }
 {
   return _Begin{}(__access::__as_const<_Tp>(__e));
 }

    };

    struct _CEnd final
    {
# 719 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_base.h" 3
      template<typename _Tp>
 [[nodiscard]]
 constexpr auto
 operator()(_Tp&& __e) const
 noexcept(noexcept(_End{}(__access::__as_const<_Tp>(__e))))
 requires requires { _End{}(__access::__as_const<_Tp>(__e)); }
 {
   return _End{}(__access::__as_const<_Tp>(__e));
 }

    };

    struct _CRBegin
    {
# 747 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_base.h" 3
      template<typename _Tp>
 [[nodiscard]]
 constexpr auto
 operator()(_Tp&& __e) const
 noexcept(noexcept(_RBegin{}(__access::__as_const<_Tp>(__e))))
 requires requires { _RBegin{}(__access::__as_const<_Tp>(__e)); }
 {
   return _RBegin{}(__access::__as_const<_Tp>(__e));
 }

    };

    struct _CREnd
    {
# 775 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_base.h" 3
      template<typename _Tp>
 [[nodiscard]]
 constexpr auto
 operator()(_Tp&& __e) const
 noexcept(noexcept(_REnd{}(__access::__as_const<_Tp>(__e))))
 requires requires { _REnd{}(__access::__as_const<_Tp>(__e)); }
 {
   return _REnd{}(__access::__as_const<_Tp>(__e));
 }

    };

    struct _CData
    {
# 798 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_base.h" 3
      template<typename _Tp>
 [[nodiscard]]
 constexpr auto
 operator()(_Tp&& __e) const
 noexcept(noexcept(_Data{}(__access::__as_const<_Tp>(__e))))
 requires requires { _Data{}(__access::__as_const<_Tp>(__e)); }
 {
   return _Data{}(__access::__as_const<_Tp>(__e));
 }

    };
  }

  inline namespace _Cpo
  {
    inline constexpr ranges::__access::_CBegin cbegin{};
    inline constexpr ranges::__access::_CEnd cend{};
    inline constexpr ranges::__access::_CRBegin crbegin{};
    inline constexpr ranges::__access::_CREnd crend{};
    inline constexpr ranges::__access::_CData cdata{};
  }

  namespace __detail
  {
    template<typename _Tp>
      inline constexpr bool __is_initializer_list = false;

    template<typename _Tp>
      inline constexpr bool __is_initializer_list<initializer_list<_Tp>> = true;
  }


  template<typename _Tp>
    concept viewable_range = range<_Tp>
      && ((view<remove_cvref_t<_Tp>> && constructible_from<remove_cvref_t<_Tp>, _Tp>)
   || (!view<remove_cvref_t<_Tp>>
       && (is_lvalue_reference_v<_Tp>
    || (movable<remove_reference_t<_Tp>>
        && !__detail::__is_initializer_list<remove_cvref_t<_Tp>>))));



  struct __advance_fn final
  {
    template<input_or_output_iterator _It>
      constexpr void
      operator()(_It& __it, iter_difference_t<_It> __n) const
      {
 if constexpr (random_access_iterator<_It>)
   __it += __n;
 else if constexpr (bidirectional_iterator<_It>)
   {
     if (__n > 0)
       {
  do
    {
      ++__it;
    }
  while (--__n);
       }
     else if (__n < 0)
       {
  do
    {
      --__it;
    }
  while (++__n);
       }
   }
 else
   {

     do { if (__builtin_expect(!bool(__n >= 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_base.h", 870, __PRETTY_FUNCTION__, "__n >= 0"); } while (false);
     while (__n-- > 0)
       ++__it;
   }
      }

    template<input_or_output_iterator _It, sentinel_for<_It> _Sent>
      constexpr void
      operator()(_It& __it, _Sent __bound) const
      {
 if constexpr (assignable_from<_It&, _Sent>)
   __it = std::move(__bound);
 else if constexpr (sized_sentinel_for<_Sent, _It>)
   (*this)(__it, __bound - __it);
 else
   {
     while (__it != __bound)
       ++__it;
   }
      }

    template<input_or_output_iterator _It, sentinel_for<_It> _Sent>
      constexpr iter_difference_t<_It>
      operator()(_It& __it, iter_difference_t<_It> __n, _Sent __bound) const
      {
 if constexpr (sized_sentinel_for<_Sent, _It>)
   {
     const auto __diff = __bound - __it;

     if (__diff == 0)
       return __n;
     else if (__diff > 0 ? __n >= __diff : __n <= __diff)
       {
  (*this)(__it, __bound);
  return __n - __diff;
       }
     else if (__n != 0) [[likely]]
       {

  do { if (__builtin_expect(!bool((__n < 0) == (__diff < 0)), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_base.h", 909, __PRETTY_FUNCTION__, "(__n < 0) == (__diff < 0)"); } while (false);

  (*this)(__it, __n);
  return 0;
       }
     else
       return 0;
   }
 else if (__it == __bound || __n == 0)
   return __n;
 else if (__n > 0)
   {
     iter_difference_t<_It> __m = 0;
     do
       {
  ++__it;
  ++__m;
       }
     while (__m != __n && __it != __bound);
     return __n - __m;
   }
 else if constexpr (bidirectional_iterator<_It> && same_as<_It, _Sent>)
   {
     iter_difference_t<_It> __m = 0;
     do
       {
  --__it;
  --__m;
       }
     while (__m != __n && __it != __bound);
     return __n - __m;
   }
 else
   {

     do { if (__builtin_expect(!bool(__n >= 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_base.h", 944, __PRETTY_FUNCTION__, "__n >= 0"); } while (false);
     return __n;
   }
      }

    void operator&() const = delete;
  };

  inline constexpr __advance_fn advance{};

  struct __distance_fn final
  {


    template<typename _It, sentinel_for<_It> _Sent>
      requires (!sized_sentinel_for<_Sent, _It>)
      constexpr iter_difference_t<_It>
      operator()[[nodiscard]](_It __first, _Sent __last) const
      {
 iter_difference_t<_It> __n = 0;
 while (__first != __last)
   {
     ++__first;
     ++__n;
   }
 return __n;
      }

    template<typename _It, sized_sentinel_for<decay_t<_It>> _Sent>
      [[nodiscard]]
      constexpr iter_difference_t<decay_t<_It>>
      operator()(_It&& __first, _Sent __last) const
      { return __last - static_cast<const decay_t<_It>&>(__first); }

    template<range _Range>
      [[nodiscard]]
      constexpr range_difference_t<_Range>
      operator()(_Range&& __r) const
      {
 if constexpr (sized_range<_Range>)
   return static_cast<range_difference_t<_Range>>(ranges::size(__r));
 else
   return (*this)(ranges::begin(__r), ranges::end(__r));
      }

    void operator&() const = delete;
  };

  inline constexpr __distance_fn distance{};

  struct __next_fn final
  {
    template<input_or_output_iterator _It>
      [[nodiscard]]
      constexpr _It
      operator()(_It __x) const
      {
 ++__x;
 return __x;
      }

    template<input_or_output_iterator _It>
      [[nodiscard]]
      constexpr _It
      operator()(_It __x, iter_difference_t<_It> __n) const
      {
 ranges::advance(__x, __n);
 return __x;
      }

    template<input_or_output_iterator _It, sentinel_for<_It> _Sent>
      [[nodiscard]]
      constexpr _It
      operator()(_It __x, _Sent __bound) const
      {
 ranges::advance(__x, __bound);
 return __x;
      }

    template<input_or_output_iterator _It, sentinel_for<_It> _Sent>
      [[nodiscard]]
      constexpr _It
      operator()(_It __x, iter_difference_t<_It> __n, _Sent __bound) const
      {
 ranges::advance(__x, __n, __bound);
 return __x;
      }

    void operator&() const = delete;
  };

  inline constexpr __next_fn next{};

  struct __prev_fn final
  {
    template<bidirectional_iterator _It>
      [[nodiscard]]
      constexpr _It
      operator()(_It __x) const
      {
 --__x;
 return __x;
      }

    template<bidirectional_iterator _It>
      [[nodiscard]]
      constexpr _It
      operator()(_It __x, iter_difference_t<_It> __n) const
      {
 ranges::advance(__x, -__n);
 return __x;
      }

    template<bidirectional_iterator _It>
      [[nodiscard]]
      constexpr _It
      operator()(_It __x, iter_difference_t<_It> __n, _It __bound) const
      {
 ranges::advance(__x, -__n, __bound);
 return __x;
      }

    void operator&() const = delete;
  };

  inline constexpr __prev_fn prev{};


  struct dangling
  {
    constexpr dangling() noexcept = default;
    template<typename... _Args>
      constexpr dangling(_Args&&...) noexcept { }
  };

  template<range _Range>
    using borrowed_iterator_t = __conditional_t<borrowed_range<_Range>,
      iterator_t<_Range>,
      dangling>;
}
# 1120 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_base.h" 3

}

#pragma GCC diagnostic pop
# 39 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_algobase.h" 2 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/invoke.h" 1 3
# 44 "C:/msys64/mingw64/include/c++/15.2.0/bits/invoke.h" 3
namespace std
{

# 55 "C:/msys64/mingw64/include/c++/15.2.0/bits/invoke.h" 3
  template<typename _Tp, typename _Up = typename __inv_unwrap<_Tp>::type>
    constexpr _Up&&
    __invfwd(typename remove_reference<_Tp>::type& __t) noexcept
    { return static_cast<_Up&&>(__t); }

  template<typename _Res, typename _Fn, typename... _Args>
    constexpr _Res
    __invoke_impl(__invoke_other, _Fn&& __f, _Args&&... __args)
    { return std::forward<_Fn>(__f)(std::forward<_Args>(__args)...); }

  template<typename _Res, typename _MemFun, typename _Tp, typename... _Args>
    constexpr _Res
    __invoke_impl(__invoke_memfun_ref, _MemFun&& __f, _Tp&& __t,
    _Args&&... __args)
    { return (__invfwd<_Tp>(__t).*__f)(std::forward<_Args>(__args)...); }

  template<typename _Res, typename _MemFun, typename _Tp, typename... _Args>
    constexpr _Res
    __invoke_impl(__invoke_memfun_deref, _MemFun&& __f, _Tp&& __t,
    _Args&&... __args)
    {
      return ((*std::forward<_Tp>(__t)).*__f)(std::forward<_Args>(__args)...);
    }

  template<typename _Res, typename _MemPtr, typename _Tp>
    constexpr _Res
    __invoke_impl(__invoke_memobj_ref, _MemPtr&& __f, _Tp&& __t)
    { return __invfwd<_Tp>(__t).*__f; }

  template<typename _Res, typename _MemPtr, typename _Tp>
    constexpr _Res
    __invoke_impl(__invoke_memobj_deref, _MemPtr&& __f, _Tp&& __t)
    { return (*std::forward<_Tp>(__t)).*__f; }


  template<typename _Callable, typename... _Args>
    constexpr typename __invoke_result<_Callable, _Args...>::type
    __invoke(_Callable&& __fn, _Args&&... __args)
    noexcept(__is_nothrow_invocable<_Callable, _Args...>::value)
    {
      using __result = __invoke_result<_Callable, _Args...>;
      using __type = typename __result::type;
      using __tag = typename __result::__invoke_type;
      return std::__invoke_impl<__type>(__tag{}, std::forward<_Callable>(__fn),
     std::forward<_Args>(__args)...);
    }



  template<typename _Res, typename _Callable, typename... _Args>
    constexpr enable_if_t<is_invocable_r_v<_Res, _Callable, _Args...>, _Res>
    __invoke_r(_Callable&& __fn, _Args&&... __args)
    noexcept(is_nothrow_invocable_r_v<_Res, _Callable, _Args...>)
    {
      using __result = __invoke_result<_Callable, _Args...>;
      using __type = typename __result::type;
      using __tag = typename __result::__invoke_type;
      if constexpr (is_void_v<_Res>)
 std::__invoke_impl<__type>(__tag{}, std::forward<_Callable>(__fn),
     std::forward<_Args>(__args)...);
      else
 return std::__invoke_impl<__type>(__tag{},
       std::forward<_Callable>(__fn),
       std::forward<_Args>(__args)...);
    }
# 157 "C:/msys64/mingw64/include/c++/15.2.0/bits/invoke.h" 3

}
# 40 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_algobase.h" 2 3




namespace std
{

namespace ranges
{
  namespace __detail
  {
    template<typename _Tp>
      constexpr inline bool __is_normal_iterator = false;

    template<typename _Iterator, typename _Container>
      constexpr inline bool
 __is_normal_iterator<__gnu_cxx::__normal_iterator<_Iterator,
         _Container>> = true;

    template<typename _Tp>
      constexpr inline bool __is_reverse_iterator = false;

    template<typename _Iterator>
      constexpr inline bool
 __is_reverse_iterator<reverse_iterator<_Iterator>> = true;

    template<typename _Tp>
      constexpr inline bool __is_move_iterator = false;

    template<typename _Iterator>
      constexpr inline bool
 __is_move_iterator<move_iterator<_Iterator>> = true;
  }
# 97 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_algobase.h" 3
  struct __equal_fn
  {
    template<input_iterator _Iter1, sentinel_for<_Iter1> _Sent1,
      input_iterator _Iter2, sentinel_for<_Iter2> _Sent2,
      typename _Pred = ranges::equal_to,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires indirectly_comparable<_Iter1, _Iter2, _Pred, _Proj1, _Proj2>
      constexpr bool
      operator()(_Iter1 __first1, _Sent1 __last1,
   _Iter2 __first2, _Sent2 __last2, _Pred __pred = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {


 if constexpr (__detail::__is_normal_iterator<_Iter1>
        && same_as<_Iter1, _Sent1>)
   return (*this)(__first1.base(), __last1.base(),
    std::move(__first2), std::move(__last2),
    std::move(__pred),
    std::move(__proj1), std::move(__proj2));
 else if constexpr (__detail::__is_normal_iterator<_Iter2>
      && same_as<_Iter2, _Sent2>)
   return (*this)(std::move(__first1), std::move(__last1),
    __first2.base(), __last2.base(),
    std::move(__pred),
    std::move(__proj1), std::move(__proj2));
 else if constexpr (sized_sentinel_for<_Sent1, _Iter1>
      && sized_sentinel_for<_Sent2, _Iter2>)
   {
     auto __d1 = ranges::distance(__first1, __last1);
     auto __d2 = ranges::distance(__first2, __last2);
     if (__d1 != __d2)
       return false;

     using _ValueType1 = iter_value_t<_Iter1>;
     constexpr bool __use_memcmp
       = ((is_integral_v<_ValueType1> || is_pointer_v<_ValueType1>)
   && __memcmpable<_Iter1, _Iter2>::__value
   && is_same_v<_Pred, ranges::equal_to>
   && is_same_v<_Proj1, identity>
   && is_same_v<_Proj2, identity>);
     if constexpr (__use_memcmp)
       {
  if (const size_t __len = (__last1 - __first1))
    return !std::__memcmp(__first1, __first2, __len);
  return true;
       }
     else
       {
  for (; __first1 != __last1; ++__first1, (void)++__first2)
    if (!(bool)std::__invoke(__pred,
        std::__invoke(__proj1, *__first1),
        std::__invoke(__proj2, *__first2)))
      return false;
  return true;
       }
   }
 else
   {
     for (; __first1 != __last1 && __first2 != __last2;
   ++__first1, (void)++__first2)
       if (!(bool)std::__invoke(__pred,
           std::__invoke(__proj1, *__first1),
           std::__invoke(__proj2, *__first2)))
  return false;
     return __first1 == __last1 && __first2 == __last2;
   }
      }

    template<input_range _Range1, input_range _Range2,
      typename _Pred = ranges::equal_to,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires indirectly_comparable<iterator_t<_Range1>, iterator_t<_Range2>,
         _Pred, _Proj1, _Proj2>
      constexpr bool
      operator()(_Range1&& __r1, _Range2&& __r2, _Pred __pred = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {


 if constexpr (sized_range<_Range1>)
   if constexpr (sized_range<_Range2>)
     if (ranges::distance(__r1) != ranges::distance(__r2))
       return false;

 return (*this)(ranges::begin(__r1), ranges::end(__r1),
         ranges::begin(__r2), ranges::end(__r2),
         std::move(__pred),
         std::move(__proj1), std::move(__proj2));
      }
  };

  inline constexpr __equal_fn equal{};

namespace __detail
{
  template<bool _IsMove, typename _OutIter, typename _InIter>
    [[__gnu__::__always_inline__]]
    constexpr void
    __assign_one(_OutIter& __out, _InIter& __in)
    {
      if constexpr (_IsMove)
 *__out = ranges::iter_move(__in);
      else
 *__out = *__in;
    }
}

  template<typename _Iter, typename _Out>
    struct in_out_result
    {
      [[no_unique_address]] _Iter in;
      [[no_unique_address]] _Out out;

      template<typename _Iter2, typename _Out2>
 requires convertible_to<const _Iter&, _Iter2>
   && convertible_to<const _Out&, _Out2>
 constexpr
 operator in_out_result<_Iter2, _Out2>() const &
 { return {in, out}; }

      template<typename _Iter2, typename _Out2>
 requires convertible_to<_Iter, _Iter2>
   && convertible_to<_Out, _Out2>
 constexpr
 operator in_out_result<_Iter2, _Out2>() &&
 { return {std::move(in), std::move(out)}; }
    };

  template<typename _Iter, typename _Out>
    using copy_result = in_out_result<_Iter, _Out>;

  template<typename _Iter, typename _Out>
    using move_result = in_out_result<_Iter, _Out>;

  template<typename _Iter1, typename _Iter2>
    using move_backward_result = in_out_result<_Iter1, _Iter2>;

  template<typename _Iter1, typename _Iter2>
    using copy_backward_result = in_out_result<_Iter1, _Iter2>;

  template<bool _IsMove,
    bidirectional_iterator _Iter, sentinel_for<_Iter> _Sent,
    bidirectional_iterator _Out>
    requires (_IsMove
       ? indirectly_movable<_Iter, _Out>
       : indirectly_copyable<_Iter, _Out>)
    constexpr __conditional_t<_IsMove,
         move_backward_result<_Iter, _Out>,
         copy_backward_result<_Iter, _Out>>
    __copy_or_move_backward(_Iter __first, _Sent __last, _Out __result);

  template<bool _IsMove,
    input_iterator _Iter, sentinel_for<_Iter> _Sent,
    weakly_incrementable _Out>
    requires (_IsMove
       ? indirectly_movable<_Iter, _Out>
       : indirectly_copyable<_Iter, _Out>)
    constexpr __conditional_t<_IsMove,
         move_result<_Iter, _Out>,
         copy_result<_Iter, _Out>>
    __copy_or_move(_Iter __first, _Sent __last, _Out __result)
    {


      using __detail::__is_move_iterator;
      using __detail::__is_reverse_iterator;
      using __detail::__is_normal_iterator;
      if constexpr (__is_move_iterator<_Iter> && same_as<_Iter, _Sent>)
 {
   auto [__in, __out]
     = ranges::__copy_or_move<true>(std::move(__first).base(),
        std::move(__last).base(),
        std::move(__result));
   return {move_iterator{std::move(__in)}, std::move(__out)};
 }
      else if constexpr (__is_reverse_iterator<_Iter> && same_as<_Iter, _Sent>
    && __is_reverse_iterator<_Out>)
 {
   auto [__in,__out]
     = ranges::__copy_or_move_backward<_IsMove>(std::move(__last).base(),
             std::move(__first).base(),
             std::move(__result).base());
   return {reverse_iterator{std::move(__in)},
    reverse_iterator{std::move(__out)}};
 }
      else if constexpr (__is_normal_iterator<_Iter> && same_as<_Iter, _Sent>)
 {
   auto [__in,__out]
     = ranges::__copy_or_move<_IsMove>(__first.base(), __last.base(),
           std::move(__result));
   return {decltype(__first){__in}, std::move(__out)};
 }
      else if constexpr (__is_normal_iterator<_Out>)
 {
   auto [__in,__out]
     = ranges::__copy_or_move<_IsMove>(std::move(__first), __last, __result.base());
   return {std::move(__in), decltype(__result){__out}};
 }
      else if constexpr (sized_sentinel_for<_Sent, _Iter>)
 {
   if (!std::__is_constant_evaluated())
     {
       if constexpr (__memcpyable<_Out, _Iter>::__value)
  {
    using _ValueTypeI = iter_value_t<_Iter>;
    auto __num = __last - __first;
    if (__num > 1) [[likely]]
      __builtin_memmove(__result, __first,
          sizeof(_ValueTypeI) * __num);
    else if (__num == 1)
      __detail::__assign_one<_IsMove>(__result, __first);
    return {__first + __num, __result + __num};
  }
     }

   for (auto __n = __last - __first; __n > 0; --__n)
     {
       __detail::__assign_one<_IsMove>(__result, __first);
       ++__first;
       ++__result;
     }
   return {std::move(__first), std::move(__result)};
 }
      else
 {
   while (__first != __last)
     {
       __detail::__assign_one<_IsMove>(__result, __first);
       ++__first;
       ++__result;
     }
   return {std::move(__first), std::move(__result)};
 }
    }

  struct __copy_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      weakly_incrementable _Out>
      requires indirectly_copyable<_Iter, _Out>
      constexpr copy_result<_Iter, _Out>
      operator()(_Iter __first, _Sent __last, _Out __result) const
      {
 return ranges::__copy_or_move<false>(std::move(__first),
          std::move(__last),
          std::move(__result));
      }

    template<input_range _Range, weakly_incrementable _Out>
      requires indirectly_copyable<iterator_t<_Range>, _Out>
      constexpr copy_result<borrowed_iterator_t<_Range>, _Out>
      operator()(_Range&& __r, _Out __result) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__result));
      }
  };

  inline constexpr __copy_fn copy{};

  struct __move_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      weakly_incrementable _Out>
      requires indirectly_movable<_Iter, _Out>
      constexpr move_result<_Iter, _Out>
      operator()(_Iter __first, _Sent __last, _Out __result) const
      {
 return ranges::__copy_or_move<true>(std::move(__first),
         std::move(__last),
         std::move(__result));
      }

    template<input_range _Range, weakly_incrementable _Out>
      requires indirectly_movable<iterator_t<_Range>, _Out>
      constexpr move_result<borrowed_iterator_t<_Range>, _Out>
      operator()(_Range&& __r, _Out __result) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__result));
      }
  };

  inline constexpr __move_fn move{};

  template<bool _IsMove,
    bidirectional_iterator _Iter, sentinel_for<_Iter> _Sent,
    bidirectional_iterator _Out>
    requires (_IsMove
       ? indirectly_movable<_Iter, _Out>
       : indirectly_copyable<_Iter, _Out>)
    constexpr __conditional_t<_IsMove,
         move_backward_result<_Iter, _Out>,
         copy_backward_result<_Iter, _Out>>
    __copy_or_move_backward(_Iter __first, _Sent __last, _Out __result)
    {


      using __detail::__is_reverse_iterator;
      using __detail::__is_normal_iterator;
      if constexpr (__is_reverse_iterator<_Iter> && same_as<_Iter, _Sent>
      && __is_reverse_iterator<_Out>)
 {
   auto [__in,__out]
     = ranges::__copy_or_move<_IsMove>(std::move(__last).base(),
           std::move(__first).base(),
           std::move(__result).base());
   return {reverse_iterator{std::move(__in)},
    reverse_iterator{std::move(__out)}};
 }
      else if constexpr (__is_normal_iterator<_Iter> && same_as<_Iter, _Sent>)
 {
   auto [__in,__out]
     = ranges::__copy_or_move_backward<_IsMove>(__first.base(),
             __last.base(),
             std::move(__result));
   return {decltype(__first){__in}, std::move(__out)};
 }
      else if constexpr (__is_normal_iterator<_Out>)
 {
   auto [__in,__out]
     = ranges::__copy_or_move_backward<_IsMove>(std::move(__first),
             std::move(__last),
             __result.base());
   return {std::move(__in), decltype(__result){__out}};
 }
      else if constexpr (sized_sentinel_for<_Sent, _Iter>)
 {
   if (!std::__is_constant_evaluated())
     {
       if constexpr (__memcpyable<_Out, _Iter>::__value)
  {
    using _ValueTypeI = iter_value_t<_Iter>;
    auto __num = __last - __first;
    __result -= __num;
    if (__num > 1) [[likely]]
      __builtin_memmove(__result, __first,
          sizeof(_ValueTypeI) * __num);
    else if (__num == 1)
      __detail::__assign_one<_IsMove>(__result, __first);
    return {__first + __num, __result};
  }
     }

   auto __lasti = ranges::next(__first, __last);
   auto __tail = __lasti;

   for (auto __n = __last - __first; __n > 0; --__n)
     {
       --__tail;
       --__result;
       __detail::__assign_one<_IsMove>(__result, __tail);
     }
   return {std::move(__lasti), std::move(__result)};
 }
      else
 {
   auto __lasti = ranges::next(__first, __last);
   auto __tail = __lasti;

   while (__first != __tail)
     {
       --__tail;
       --__result;
       __detail::__assign_one<_IsMove>(__result, __tail);
     }
   return {std::move(__lasti), std::move(__result)};
 }
    }

  struct __copy_backward_fn
  {
    template<bidirectional_iterator _Iter1, sentinel_for<_Iter1> _Sent1,
      bidirectional_iterator _Iter2>
      requires indirectly_copyable<_Iter1, _Iter2>
      constexpr copy_backward_result<_Iter1, _Iter2>
      operator()(_Iter1 __first, _Sent1 __last, _Iter2 __result) const
      {
 return ranges::__copy_or_move_backward<false>(std::move(__first),
            std::move(__last),
            std::move(__result));
      }

    template<bidirectional_range _Range, bidirectional_iterator _Iter>
      requires indirectly_copyable<iterator_t<_Range>, _Iter>
      constexpr copy_backward_result<borrowed_iterator_t<_Range>, _Iter>
      operator()(_Range&& __r, _Iter __result) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__result));
      }
  };

  inline constexpr __copy_backward_fn copy_backward{};

  struct __move_backward_fn
  {
    template<bidirectional_iterator _Iter1, sentinel_for<_Iter1> _Sent1,
      bidirectional_iterator _Iter2>
      requires indirectly_movable<_Iter1, _Iter2>
      constexpr move_backward_result<_Iter1, _Iter2>
      operator()(_Iter1 __first, _Sent1 __last, _Iter2 __result) const
      {
 return ranges::__copy_or_move_backward<true>(std::move(__first),
           std::move(__last),
           std::move(__result));
      }

    template<bidirectional_range _Range, bidirectional_iterator _Iter>
      requires indirectly_movable<iterator_t<_Range>, _Iter>
      constexpr move_backward_result<borrowed_iterator_t<_Range>, _Iter>
      operator()(_Range&& __r, _Iter __result) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__result));
      }
  };

  inline constexpr __move_backward_fn move_backward{};

  template<typename _Iter, typename _Out>
    using copy_n_result = in_out_result<_Iter, _Out>;

  struct __copy_n_fn
  {
    template<input_iterator _Iter, weakly_incrementable _Out>
      requires indirectly_copyable<_Iter, _Out>
      constexpr copy_n_result<_Iter, _Out>
      operator()(_Iter __first, iter_difference_t<_Iter> __n,
   _Out __result) const
      {
 if constexpr (random_access_iterator<_Iter>)
   {
     if (__n > 0)
       return ranges::copy(__first, __first + __n, std::move(__result));
   }
 else
   {
     for (; __n > 0; --__n, (void)++__result, (void)++__first)
       *__result = *__first;
   }
 return {std::move(__first), std::move(__result)};
      }
  };

  inline constexpr __copy_n_fn copy_n{};

  struct __fill_n_fn
  {
    template<typename _Out,
      typename _Tp >
      requires output_iterator<_Out, const _Tp&>
      constexpr _Out
      operator()(_Out __first, iter_difference_t<_Out> __n,
   const _Tp& __value) const
      {


 if (__n <= 0)
   return __first;

 if constexpr (is_scalar_v<_Tp>)
   {

     if constexpr (is_pointer_v<_Out>

     && __is_byte<remove_pointer_t<_Out>>::__value
     && integral<_Tp>)
       {
  if (!std::__is_constant_evaluated())
    {
      __builtin_memset(__first,
         static_cast<unsigned char>(__value),
         __n);
      return __first + __n;
    }
       }

     const auto __tmp = __value;
     for (; __n > 0; --__n, (void)++__first)
       *__first = __tmp;
     return __first;
   }
 else
   {
     for (; __n > 0; --__n, (void)++__first)
       *__first = __value;
     return __first;
   }
      }
  };

  inline constexpr __fill_n_fn fill_n{};

  struct __fill_fn
  {
    template<typename _Out,
      sentinel_for<_Out> _Sent,
      typename _Tp >
      requires output_iterator<_Out, const _Tp&>
      constexpr _Out
      operator()(_Out __first, _Sent __last, const _Tp& __value) const
      {


 if constexpr (sized_sentinel_for<_Sent, _Out>)
   {
     const auto __len = __last - __first;
     return ranges::fill_n(std::move(__first), __len, __value);
   }
 else if constexpr (is_scalar_v<_Tp>)
   {
     const auto __tmp = __value;
     for (; __first != __last; ++__first)
       *__first = __tmp;
     return __first;
   }
 else
   {
     for (; __first != __last; ++__first)
       *__first = __value;
     return __first;
   }
      }

    template<typename _Range,
      typename _Tp >
      requires output_range<_Range, const _Tp&>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r, const _Tp& __value) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r), __value);
      }
  };

  inline constexpr __fill_fn fill{};
}

}
# 39 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_algo.h" 2 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_util.h" 1 3
# 43 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_util.h" 3
namespace std
{

namespace ranges
{


  namespace __detail
  {
    template<typename _Range>
      concept __simple_view = view<_Range> && range<const _Range>
 && same_as<iterator_t<_Range>, iterator_t<const _Range>>
 && same_as<sentinel_t<_Range>, sentinel_t<const _Range>>;



    template<typename _It>
      concept __has_arrow = input_iterator<_It>
 && (is_pointer_v<_It>
       || requires(const _It __it) { __it.operator->(); });

    using std::__detail::__different_from;
  }


  template<typename _Derived>
    requires is_class_v<_Derived> && same_as<_Derived, remove_cv_t<_Derived>>
    class view_interface
    {
    private:
      constexpr _Derived& _M_derived() noexcept
      {
 static_assert(derived_from<_Derived, view_interface<_Derived>>);
 static_assert(view<_Derived>);
 return static_cast<_Derived&>(*this);
      }

      constexpr const _Derived& _M_derived() const noexcept
      {
 static_assert(derived_from<_Derived, view_interface<_Derived>>);
 static_assert(view<_Derived>);
 return static_cast<const _Derived&>(*this);
      }

      static constexpr bool
      _S_bool(bool) noexcept;

      template<typename _Tp>
 static constexpr bool
 _S_empty(_Tp& __t)
 noexcept(noexcept(_S_bool(ranges::begin(__t) == ranges::end(__t))))
 { return ranges::begin(__t) == ranges::end(__t); }

      template<typename _Tp>
 static constexpr auto
 _S_size(_Tp& __t)
 noexcept(noexcept(ranges::end(__t) - ranges::begin(__t)))
 { return ranges::end(__t) - ranges::begin(__t); }

    public:
      constexpr bool
      empty()
      noexcept(noexcept(_S_empty(_M_derived())))
      requires forward_range<_Derived> && (!sized_range<_Derived>)
      { return _S_empty(_M_derived()); }

      constexpr bool
      empty()
      noexcept(noexcept(ranges::size(_M_derived()) == 0))
      requires sized_range<_Derived>
      { return ranges::size(_M_derived()) == 0; }

      constexpr bool
      empty() const
      noexcept(noexcept(_S_empty(_M_derived())))
      requires forward_range<const _Derived> && (!sized_range<const _Derived>)
      { return _S_empty(_M_derived()); }

      constexpr bool
      empty() const
      noexcept(noexcept(ranges::size(_M_derived()) == 0))
      requires sized_range<const _Derived>
      { return ranges::size(_M_derived()) == 0; }

      constexpr explicit
      operator bool() noexcept(noexcept(ranges::empty(_M_derived())))
      requires requires { ranges::empty(_M_derived()); }
      { return !ranges::empty(_M_derived()); }

      constexpr explicit
      operator bool() const noexcept(noexcept(ranges::empty(_M_derived())))
      requires requires { ranges::empty(_M_derived()); }
      { return !ranges::empty(_M_derived()); }

      constexpr auto
      data() noexcept(noexcept(ranges::begin(_M_derived())))
      requires contiguous_iterator<iterator_t<_Derived>>
      { return std::to_address(ranges::begin(_M_derived())); }

      constexpr auto
      data() const noexcept(noexcept(ranges::begin(_M_derived())))
      requires range<const _Derived>
 && contiguous_iterator<iterator_t<const _Derived>>
      { return std::to_address(ranges::begin(_M_derived())); }

      constexpr auto
      size() noexcept(noexcept(_S_size(_M_derived())))
      requires forward_range<_Derived>
 && sized_sentinel_for<sentinel_t<_Derived>, iterator_t<_Derived>>
      { return _S_size(_M_derived()); }

      constexpr auto
      size() const noexcept(noexcept(_S_size(_M_derived())))
      requires forward_range<const _Derived>
 && sized_sentinel_for<sentinel_t<const _Derived>,
         iterator_t<const _Derived>>
      { return _S_size(_M_derived()); }

      constexpr decltype(auto)
      front() requires forward_range<_Derived>
      {
 do { if (__builtin_expect(!bool(!empty()), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_util.h", 164, __PRETTY_FUNCTION__, "!empty()"); } while (false);
 return *ranges::begin(_M_derived());
      }

      constexpr decltype(auto)
      front() const requires forward_range<const _Derived>
      {
 do { if (__builtin_expect(!bool(!empty()), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_util.h", 171, __PRETTY_FUNCTION__, "!empty()"); } while (false);
 return *ranges::begin(_M_derived());
      }

      constexpr decltype(auto)
      back()
      requires bidirectional_range<_Derived> && common_range<_Derived>
      {
 do { if (__builtin_expect(!bool(!empty()), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_util.h", 179, __PRETTY_FUNCTION__, "!empty()"); } while (false);
 return *ranges::prev(ranges::end(_M_derived()));
      }

      constexpr decltype(auto)
      back() const
      requires bidirectional_range<const _Derived>
 && common_range<const _Derived>
      {
 do { if (__builtin_expect(!bool(!empty()), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_util.h", 188, __PRETTY_FUNCTION__, "!empty()"); } while (false);
 return *ranges::prev(ranges::end(_M_derived()));
      }

      template<random_access_range _Range = _Derived>
 constexpr decltype(auto)
 operator[](range_difference_t<_Range> __n)
 { return ranges::begin(_M_derived())[__n]; }

      template<random_access_range _Range = const _Derived>
 constexpr decltype(auto)
 operator[](range_difference_t<_Range> __n) const
 { return ranges::begin(_M_derived())[__n]; }
# 219 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_util.h" 3
    };

  namespace __detail
  {
    template<typename _From, typename _To>
      concept __uses_nonqualification_pointer_conversion
 = is_pointer_v<_From> && is_pointer_v<_To>
   && !convertible_to<remove_pointer_t<_From>(*)[],
        remove_pointer_t<_To>(*)[]>;

    template<typename _From, typename _To>
      concept __convertible_to_non_slicing = convertible_to<_From, _To>
 && !__uses_nonqualification_pointer_conversion<decay_t<_From>,
             decay_t<_To>>;





    template<typename _Tp>
      concept __pair_like
 = !is_reference_v<_Tp> && requires(_Tp __t)
 {
   typename tuple_size<_Tp>::type;
   requires derived_from<tuple_size<_Tp>, integral_constant<size_t, 2>>;
   typename tuple_element_t<0, remove_const_t<_Tp>>;
   typename tuple_element_t<1, remove_const_t<_Tp>>;
   { get<0>(__t) } -> convertible_to<const tuple_element_t<0, _Tp>&>;
   { get<1>(__t) } -> convertible_to<const tuple_element_t<1, _Tp>&>;
 };


    template<typename _Tp, typename _Up, typename _Vp>
      concept __pair_like_convertible_from
 = !range<_Tp> && !is_reference_v<_Tp> && __pair_like<_Tp>
 && constructible_from<_Tp, _Up, _Vp>
 && __convertible_to_non_slicing<_Up, tuple_element_t<0, _Tp>>
 && convertible_to<_Vp, tuple_element_t<1, _Tp>>;

  }

  namespace views { struct _Drop; }

  enum class subrange_kind : bool { unsized, sized };


  template<input_or_output_iterator _It, sentinel_for<_It> _Sent = _It,
    subrange_kind _Kind = sized_sentinel_for<_Sent, _It>
      ? subrange_kind::sized : subrange_kind::unsized>
    requires (_Kind == subrange_kind::sized || !sized_sentinel_for<_Sent, _It>)
    class subrange : public view_interface<subrange<_It, _Sent, _Kind>>
    {
    private:
      static constexpr bool _S_store_size
 = _Kind == subrange_kind::sized && !sized_sentinel_for<_Sent, _It>;

      friend struct views::_Drop;

      _It _M_begin = _It();
      [[no_unique_address]] _Sent _M_end = _Sent();

      using __size_type
 = __detail::__make_unsigned_like_t<iter_difference_t<_It>>;

      template<typename _Tp, bool = _S_store_size>
 struct _Size
 {
   [[__gnu__::__always_inline__]]
   constexpr _Size(_Tp = {}) { }
 };

      template<typename _Tp>
 struct _Size<_Tp, true>
 {
   [[__gnu__::__always_inline__]]
   constexpr _Size(_Tp __s = {}) : _M_size(__s) { }

   _Tp _M_size;
 };

      [[no_unique_address]] _Size<__size_type> _M_size = {};

    public:
      subrange() requires default_initializable<_It> = default;

      constexpr
      subrange(__detail::__convertible_to_non_slicing<_It> auto __i, _Sent __s)
      noexcept(is_nothrow_constructible_v<_It, decltype(__i)>
        && is_nothrow_constructible_v<_Sent, _Sent&>)
 requires (!_S_store_size)
      : _M_begin(std::move(__i)), _M_end(__s)
      { }

      constexpr
      subrange(__detail::__convertible_to_non_slicing<_It> auto __i, _Sent __s,
        __size_type __n)
      noexcept(is_nothrow_constructible_v<_It, decltype(__i)>
        && is_nothrow_constructible_v<_Sent, _Sent&>)
 requires (_Kind == subrange_kind::sized)
      : _M_begin(std::move(__i)), _M_end(__s), _M_size(__n)
      { }

      template<__detail::__different_from<subrange> _Rng>
 requires borrowed_range<_Rng>
   && __detail::__convertible_to_non_slicing<iterator_t<_Rng>, _It>
   && convertible_to<sentinel_t<_Rng>, _Sent>
 constexpr
 subrange(_Rng&& __r)
 noexcept(noexcept(subrange(__r, ranges::size(__r))))
 requires _S_store_size && sized_range<_Rng>
 : subrange(__r, ranges::size(__r))
 { }

      template<__detail::__different_from<subrange> _Rng>
 requires borrowed_range<_Rng>
   && __detail::__convertible_to_non_slicing<iterator_t<_Rng>, _It>
   && convertible_to<sentinel_t<_Rng>, _Sent>
 constexpr
 subrange(_Rng&& __r)
 noexcept(noexcept(subrange(ranges::begin(__r), ranges::end(__r))))
 requires (!_S_store_size)
 : subrange(ranges::begin(__r), ranges::end(__r))
 { }

      template<borrowed_range _Rng>
 requires __detail::__convertible_to_non_slicing<iterator_t<_Rng>, _It>
   && convertible_to<sentinel_t<_Rng>, _Sent>
 constexpr
 subrange(_Rng&& __r, __size_type __n)
 noexcept(noexcept(subrange(ranges::begin(__r), ranges::end(__r), __n)))
 requires (_Kind == subrange_kind::sized)
 : subrange{ranges::begin(__r), ranges::end(__r), __n}
 { }

      template<__detail::__different_from<subrange> _PairLike>
 requires __detail::__pair_like_convertible_from<_PairLike, const _It&,
       const _Sent&>
 constexpr
 operator _PairLike() const
 { return _PairLike(_M_begin, _M_end); }

      constexpr _It
      begin() const requires copyable<_It>
      { return _M_begin; }

      [[nodiscard]] constexpr _It
      begin() requires (!copyable<_It>)
      { return std::move(_M_begin); }

      constexpr _Sent end() const { return _M_end; }

      constexpr bool empty() const { return _M_begin == _M_end; }

      constexpr __size_type
      size() const requires (_Kind == subrange_kind::sized)
      {
 if constexpr (_S_store_size)
   return _M_size._M_size;
 else
   return __detail::__to_unsigned_like(_M_end - _M_begin);
      }

      [[nodiscard]] constexpr subrange
      next(iter_difference_t<_It> __n = 1) const &
 requires forward_iterator<_It>
      {
 auto __tmp = *this;
 __tmp.advance(__n);
 return __tmp;
      }

      [[nodiscard]] constexpr subrange
      next(iter_difference_t<_It> __n = 1) &&
      {
 advance(__n);
 return std::move(*this);
      }

      [[nodiscard]] constexpr subrange
      prev(iter_difference_t<_It> __n = 1) const
 requires bidirectional_iterator<_It>
      {
 auto __tmp = *this;
 __tmp.advance(-__n);
 return __tmp;
      }

      constexpr subrange&
      advance(iter_difference_t<_It> __n)
      {


 if constexpr (bidirectional_iterator<_It>)
   if (__n < 0)
     {
       ranges::advance(_M_begin, __n);
       if constexpr (_S_store_size)
  _M_size._M_size += __detail::__to_unsigned_like(-__n);
       return *this;
     }

 do { if (__builtin_expect(!bool(__n >= 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_util.h", 420, __PRETTY_FUNCTION__, "__n >= 0"); } while (false);
 auto __d = __n - ranges::advance(_M_begin, __n, _M_end);
 if constexpr (_S_store_size)
   _M_size._M_size -= __detail::__to_unsigned_like(__d);
 return *this;
      }
    };

  template<input_or_output_iterator _It, sentinel_for<_It> _Sent>
    subrange(_It, _Sent) -> subrange<_It, _Sent>;

  template<input_or_output_iterator _It, sentinel_for<_It> _Sent>
    subrange(_It, _Sent,
      __detail::__make_unsigned_like_t<iter_difference_t<_It>>)
      -> subrange<_It, _Sent, subrange_kind::sized>;

  template<borrowed_range _Rng>
    subrange(_Rng&&)
      -> subrange<iterator_t<_Rng>, sentinel_t<_Rng>,
   (sized_range<_Rng>
    || sized_sentinel_for<sentinel_t<_Rng>, iterator_t<_Rng>>)
   ? subrange_kind::sized : subrange_kind::unsized>;

  template<borrowed_range _Rng>
    subrange(_Rng&&,
      __detail::__make_unsigned_like_t<range_difference_t<_Rng>>)
      -> subrange<iterator_t<_Rng>, sentinel_t<_Rng>, subrange_kind::sized>;




  template<size_t _Num, class _It, class _Sent, subrange_kind _Kind>
    requires ((_Num == 0 && copyable<_It>) || _Num == 1)
    constexpr auto
    get(const subrange<_It, _Sent, _Kind>& __r)
    {
      if constexpr (_Num == 0)
 return __r.begin();
      else
 return __r.end();
    }

  template<size_t _Num, class _It, class _Sent, subrange_kind _Kind>
    requires (_Num < 2)
    constexpr auto
    get(subrange<_It, _Sent, _Kind>&& __r)
    {
      if constexpr (_Num == 0)
 return __r.begin();
      else
 return __r.end();
    }

  template<typename _It, typename _Sent, subrange_kind _Kind>
    inline constexpr bool
      enable_borrowed_range<subrange<_It, _Sent, _Kind>> = true;

  template<range _Range>
    using borrowed_subrange_t = __conditional_t<borrowed_range<_Range>,
      subrange<iterator_t<_Range>>,
      dangling>;


  template<typename _Iter, typename _Sent, subrange_kind _Kind>
    inline constexpr bool __detail::__is_subrange<subrange<_Iter, _Sent, _Kind>> = true;
}
# 495 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_util.h" 3
namespace ranges
{
  struct __find_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      typename _Tp >
      requires indirect_binary_predicate<ranges::equal_to,
      projected<_Iter, _Proj>, const _Tp*>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last,
   const _Tp& __value, _Proj __proj = {}) const
      {
 if constexpr (is_same_v<_Proj, identity>)
   if constexpr(__can_use_memchr_for_find<iter_value_t<_Iter>, _Tp>)
     if constexpr (sized_sentinel_for<_Sent, _Iter>)
       if constexpr (contiguous_iterator<_Iter>)
  if (!is_constant_evaluated())
    {
      using _Vt = iter_value_t<_Iter>;
      auto __n = __last - __first;
      if (static_cast<_Vt>(__value) == __value) [[likely]]
        if (__n > 0)
   {
     const size_t __nu = static_cast<size_t>(__n);
     const int __ival = static_cast<int>(__value);
     const void* __p0 = std::to_address(__first);
     if (auto __p1 = __builtin_memchr(__p0, __ival, __nu))
       __n = (const char*)__p1 - (const char*)__p0;
   }
      return __first + __n;
    }

 while (__first != __last
     && !(std::__invoke(__proj, *__first) == __value))
   ++__first;
 return __first;
      }

    template<input_range _Range, typename _Proj = identity,
      typename _Tp
      >
      requires indirect_binary_predicate<ranges::equal_to,
      projected<iterator_t<_Range>, _Proj>,
      const _Tp*>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r, const _Tp& __value, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         __value, std::move(__proj));
      }
  };

  inline constexpr __find_fn find{};

  struct __find_if_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_unary_predicate<projected<_Iter, _Proj>> _Pred>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last,
   _Pred __pred, _Proj __proj = {}) const
      {
 while (__first != __last
     && !(bool)std::__invoke(__pred, std::__invoke(__proj, *__first)))
   ++__first;
 return __first;
      }

    template<input_range _Range, typename _Proj = identity,
      indirect_unary_predicate<projected<iterator_t<_Range>, _Proj>>
        _Pred>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r, _Pred __pred, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__pred), std::move(__proj));
      }
  };

  inline constexpr __find_if_fn find_if{};

  struct __find_if_not_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_unary_predicate<projected<_Iter, _Proj>> _Pred>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last,
   _Pred __pred, _Proj __proj = {}) const
      {
 while (__first != __last
     && (bool)std::__invoke(__pred, std::__invoke(__proj, *__first)))
   ++__first;
 return __first;
      }

    template<input_range _Range, typename _Proj = identity,
      indirect_unary_predicate<projected<iterator_t<_Range>, _Proj>>
        _Pred>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r, _Pred __pred, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__pred), std::move(__proj));
      }
  };

  inline constexpr __find_if_not_fn find_if_not{};

  template<typename _Iter1, typename _Iter2>
    struct in_in_result
    {
      [[no_unique_address]] _Iter1 in1;
      [[no_unique_address]] _Iter2 in2;

      template<typename _IIter1, typename _IIter2>
 requires convertible_to<const _Iter1&, _IIter1>
   && convertible_to<const _Iter2&, _IIter2>
 constexpr
 operator in_in_result<_IIter1, _IIter2>() const &
 { return {in1, in2}; }

      template<typename _IIter1, typename _IIter2>
 requires convertible_to<_Iter1, _IIter1>
   && convertible_to<_Iter2, _IIter2>
 constexpr
 operator in_in_result<_IIter1, _IIter2>() &&
 { return {std::move(in1), std::move(in2)}; }
    };

  template<typename _Iter1, typename _Iter2>
    using mismatch_result = in_in_result<_Iter1, _Iter2>;

  struct __mismatch_fn
  {
    template<input_iterator _Iter1, sentinel_for<_Iter1> _Sent1,
      input_iterator _Iter2, sentinel_for<_Iter2> _Sent2,
      typename _Pred = ranges::equal_to,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires indirectly_comparable<_Iter1, _Iter2, _Pred, _Proj1, _Proj2>
      constexpr mismatch_result<_Iter1, _Iter2>
      operator()(_Iter1 __first1, _Sent1 __last1,
   _Iter2 __first2, _Sent2 __last2, _Pred __pred = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 while (__first1 != __last1 && __first2 != __last2
        && (bool)std::__invoke(__pred,
          std::__invoke(__proj1, *__first1),
          std::__invoke(__proj2, *__first2)))
 {
   ++__first1;
   ++__first2;
 }
 return { std::move(__first1), std::move(__first2) };
      }

    template<input_range _Range1, input_range _Range2,
      typename _Pred = ranges::equal_to,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires indirectly_comparable<iterator_t<_Range1>, iterator_t<_Range2>,
         _Pred, _Proj1, _Proj2>
      constexpr mismatch_result<iterator_t<_Range1>, iterator_t<_Range2>>
      operator()(_Range1&& __r1, _Range2&& __r2, _Pred __pred = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 return (*this)(ranges::begin(__r1), ranges::end(__r1),
         ranges::begin(__r2), ranges::end(__r2),
         std::move(__pred),
         std::move(__proj1), std::move(__proj2));
      }
  };

  inline constexpr __mismatch_fn mismatch{};

  struct __search_fn
  {
    template<forward_iterator _Iter1, sentinel_for<_Iter1> _Sent1,
      forward_iterator _Iter2, sentinel_for<_Iter2> _Sent2,
      typename _Pred = ranges::equal_to,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires indirectly_comparable<_Iter1, _Iter2, _Pred, _Proj1, _Proj2>
      constexpr subrange<_Iter1>
      operator()(_Iter1 __first1, _Sent1 __last1,
   _Iter2 __first2, _Sent2 __last2, _Pred __pred = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 if (__first1 == __last1 || __first2 == __last2)
   return {__first1, __first1};

 for (;;)
   {
     for (;;)
       {
  if (__first1 == __last1)
    return {__first1, __first1};
  if (std::__invoke(__pred,
      std::__invoke(__proj1, *__first1),
      std::__invoke(__proj2, *__first2)))
    break;
  ++__first1;
       }
     auto __cur1 = __first1;
     auto __cur2 = __first2;
     for (;;)
       {
  if (++__cur2 == __last2)
    return {__first1, ++__cur1};
  if (++__cur1 == __last1)
    return {__cur1, __cur1};
  if (!(bool)std::__invoke(__pred,
      std::__invoke(__proj1, *__cur1),
      std::__invoke(__proj2, *__cur2)))
    {
      ++__first1;
      break;
    }
       }
   }
      }

    template<forward_range _Range1, forward_range _Range2,
      typename _Pred = ranges::equal_to,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires indirectly_comparable<iterator_t<_Range1>, iterator_t<_Range2>,
         _Pred, _Proj1, _Proj2>
      constexpr borrowed_subrange_t<_Range1>
      operator()(_Range1&& __r1, _Range2&& __r2, _Pred __pred = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 return (*this)(ranges::begin(__r1), ranges::end(__r1),
         ranges::begin(__r2), ranges::end(__r2),
         std::move(__pred),
         std::move(__proj1), std::move(__proj2));
      }
  };

  inline constexpr __search_fn search{};

  struct __min_fn
  {
    template<typename _Tp, typename _Proj = identity,
      indirect_strict_weak_order<projected<const _Tp*, _Proj>>
        _Comp = ranges::less>
      constexpr const _Tp&
      operator()(const _Tp& __a, const _Tp& __b,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 if (std::__invoke(__comp,
     std::__invoke(__proj, __b),
     std::__invoke(__proj, __a)))
   return __b;
 else
   return __a;
      }

    template<input_range _Range, typename _Proj = identity,
      indirect_strict_weak_order<projected<iterator_t<_Range>, _Proj>>
        _Comp = ranges::less>
      requires indirectly_copyable_storable<iterator_t<_Range>,
         range_value_t<_Range>*>
      constexpr range_value_t<_Range>
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 auto __first = ranges::begin(__r);
 auto __last = ranges::end(__r);
 do { if (__builtin_expect(!bool(__first != __last), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_util.h", 762, __PRETTY_FUNCTION__, "__first != __last"); } while (false);
 auto __result = *__first;
 while (++__first != __last)
   {
     auto&& __tmp = *__first;
     if (std::__invoke(__comp,
         std::__invoke(__proj, __tmp),
         std::__invoke(__proj, __result)))
       __result = std::forward<decltype(__tmp)>(__tmp);
   }
 return __result;
      }

    template<copyable _Tp, typename _Proj = identity,
      indirect_strict_weak_order<projected<const _Tp*, _Proj>>
        _Comp = ranges::less>
      constexpr _Tp
      operator()(initializer_list<_Tp> __r,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::subrange(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __min_fn min{};

  struct __adjacent_find_fn
  {
    template<forward_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_binary_predicate<projected<_Iter, _Proj>,
           projected<_Iter, _Proj>> _Pred
        = ranges::equal_to>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last,
   _Pred __pred = {}, _Proj __proj = {}) const
      {
 if (__first == __last)
   return __first;
 auto __next = __first;
 for (; ++__next != __last; __first = __next)
   {
     if (std::__invoke(__pred,
         std::__invoke(__proj, *__first),
         std::__invoke(__proj, *__next)))
       return __first;
   }
 return __next;
      }

    template<forward_range _Range, typename _Proj = identity,
      indirect_binary_predicate<
        projected<iterator_t<_Range>, _Proj>,
        projected<iterator_t<_Range>, _Proj>> _Pred = ranges::equal_to>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r, _Pred __pred = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__pred), std::move(__proj));
      }
  };

  inline constexpr __adjacent_find_fn adjacent_find{};

}

  using ranges::get;

  template<typename _Iter, typename _Sent, ranges::subrange_kind _Kind>
    struct tuple_size<ranges::subrange<_Iter, _Sent, _Kind>>
    : integral_constant<size_t, 2>
    { };

  template<typename _Iter, typename _Sent, ranges::subrange_kind _Kind>
    struct tuple_element<0, ranges::subrange<_Iter, _Sent, _Kind>>
    { using type = _Iter; };

  template<typename _Iter, typename _Sent, ranges::subrange_kind _Kind>
    struct tuple_element<1, ranges::subrange<_Iter, _Sent, _Kind>>
    { using type = _Sent; };

  template<typename _Iter, typename _Sent, ranges::subrange_kind _Kind>
    struct tuple_element<0, const ranges::subrange<_Iter, _Sent, _Kind>>
    { using type = _Iter; };

  template<typename _Iter, typename _Sent, ranges::subrange_kind _Kind>
    struct tuple_element<1, const ranges::subrange<_Iter, _Sent, _Kind>>
    { using type = _Sent; };


}
# 40 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_algo.h" 2 3



namespace std
{

namespace ranges
{
  namespace __detail
  {
    template<typename _Comp, typename _Proj>
      constexpr auto
      __make_comp_proj(_Comp& __comp, _Proj& __proj)
      {
 return [&] (auto&& __lhs, auto&& __rhs) -> bool {
   using _TL = decltype(__lhs);
   using _TR = decltype(__rhs);
   return std::__invoke(__comp,
          std::__invoke(__proj, std::forward<_TL>(__lhs)),
          std::__invoke(__proj, std::forward<_TR>(__rhs)));
 };
      }

    template<typename _Pred, typename _Proj>
      constexpr auto
      __make_pred_proj(_Pred& __pred, _Proj& __proj)
      {
 return [&] <typename _Tp> (_Tp&& __arg) -> bool {
   return std::__invoke(__pred,
          std::__invoke(__proj, std::forward<_Tp>(__arg)));
 };
      }
  }

  struct __all_of_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_unary_predicate<projected<_Iter, _Proj>> _Pred>
      constexpr bool
      operator()(_Iter __first, _Sent __last,
   _Pred __pred, _Proj __proj = {}) const
      {
 for (; __first != __last; ++__first)
   if (!(bool)std::__invoke(__pred, std::__invoke(__proj, *__first)))
     return false;
 return true;
      }

    template<input_range _Range, typename _Proj = identity,
      indirect_unary_predicate<projected<iterator_t<_Range>, _Proj>>
        _Pred>
      constexpr bool
      operator()(_Range&& __r, _Pred __pred, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__pred), std::move(__proj));
      }
  };

  inline constexpr __all_of_fn all_of{};

  struct __any_of_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_unary_predicate<projected<_Iter, _Proj>> _Pred>
      constexpr bool
      operator()(_Iter __first, _Sent __last,
   _Pred __pred, _Proj __proj = {}) const
      {
 for (; __first != __last; ++__first)
   if (std::__invoke(__pred, std::__invoke(__proj, *__first)))
     return true;
 return false;
      }

    template<input_range _Range, typename _Proj = identity,
      indirect_unary_predicate<projected<iterator_t<_Range>, _Proj>>
        _Pred>
      constexpr bool
      operator()(_Range&& __r, _Pred __pred, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__pred), std::move(__proj));
      }
  };

  inline constexpr __any_of_fn any_of{};

  struct __none_of_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_unary_predicate<projected<_Iter, _Proj>> _Pred>
      constexpr bool
      operator()(_Iter __first, _Sent __last,
   _Pred __pred, _Proj __proj = {}) const
      {
 for (; __first != __last; ++__first)
   if (std::__invoke(__pred, std::__invoke(__proj, *__first)))
     return false;
 return true;
      }

    template<input_range _Range, typename _Proj = identity,
      indirect_unary_predicate<projected<iterator_t<_Range>, _Proj>>
        _Pred>
      constexpr bool
      operator()(_Range&& __r, _Pred __pred, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__pred), std::move(__proj));
      }
  };

  inline constexpr __none_of_fn none_of{};

  template<typename _Iter, typename _Fp>
    struct in_fun_result
    {
      [[no_unique_address]] _Iter in;
      [[no_unique_address]] _Fp fun;

      template<typename _Iter2, typename _F2p>
 requires convertible_to<const _Iter&, _Iter2>
   && convertible_to<const _Fp&, _F2p>
 constexpr
 operator in_fun_result<_Iter2, _F2p>() const &
 { return {in, fun}; }

      template<typename _Iter2, typename _F2p>
 requires convertible_to<_Iter, _Iter2> && convertible_to<_Fp, _F2p>
 constexpr
 operator in_fun_result<_Iter2, _F2p>() &&
 { return {std::move(in), std::move(fun)}; }
    };

  template<typename _Iter, typename _Fp>
    using for_each_result = in_fun_result<_Iter, _Fp>;

  struct __for_each_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirectly_unary_invocable<projected<_Iter, _Proj>> _Fun>
      constexpr for_each_result<_Iter, _Fun>
      operator()(_Iter __first, _Sent __last, _Fun __f, _Proj __proj = {}) const
      {
 for (; __first != __last; ++__first)
   std::__invoke(__f, std::__invoke(__proj, *__first));
 return { std::move(__first), std::move(__f) };
      }

    template<input_range _Range, typename _Proj = identity,
      indirectly_unary_invocable<projected<iterator_t<_Range>, _Proj>>
        _Fun>
      constexpr for_each_result<borrowed_iterator_t<_Range>, _Fun>
      operator()(_Range&& __r, _Fun __f, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__f), std::move(__proj));
      }
  };

  inline constexpr __for_each_fn for_each{};

  template<typename _Iter, typename _Fp>
    using for_each_n_result = in_fun_result<_Iter, _Fp>;

  struct __for_each_n_fn
  {
    template<input_iterator _Iter, typename _Proj = identity,
      indirectly_unary_invocable<projected<_Iter, _Proj>> _Fun>
      constexpr for_each_n_result<_Iter, _Fun>
      operator()(_Iter __first, iter_difference_t<_Iter> __n,
   _Fun __f, _Proj __proj = {}) const
      {
 if constexpr (random_access_iterator<_Iter>)
   {
     if (__n <= 0)
       return {std::move(__first), std::move(__f)};
     auto __last = __first + __n;
     return ranges::for_each(std::move(__first), std::move(__last),
        std::move(__f), std::move(__proj));
   }
 else
   {
     while (__n-- > 0)
       {
  std::__invoke(__f, std::__invoke(__proj, *__first));
  ++__first;
       }
     return {std::move(__first), std::move(__f)};
   }
      }
  };

  inline constexpr __for_each_n_fn for_each_n{};



  struct __find_first_of_fn
  {
    template<input_iterator _Iter1, sentinel_for<_Iter1> _Sent1,
      forward_iterator _Iter2, sentinel_for<_Iter2> _Sent2,
      typename _Pred = ranges::equal_to,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires indirectly_comparable<_Iter1, _Iter2, _Pred, _Proj1, _Proj2>
      constexpr _Iter1
      operator()(_Iter1 __first1, _Sent1 __last1,
   _Iter2 __first2, _Sent2 __last2, _Pred __pred = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 for (; __first1 != __last1; ++__first1)
   for (auto __iter = __first2; __iter != __last2; ++__iter)
     if (std::__invoke(__pred,
         std::__invoke(__proj1, *__first1),
         std::__invoke(__proj2, *__iter)))
       return __first1;
 return __first1;
      }

    template<input_range _Range1, forward_range _Range2,
      typename _Pred = ranges::equal_to,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires indirectly_comparable<iterator_t<_Range1>, iterator_t<_Range2>,
         _Pred, _Proj1, _Proj2>
      constexpr borrowed_iterator_t<_Range1>
      operator()(_Range1&& __r1, _Range2&& __r2, _Pred __pred = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 return (*this)(ranges::begin(__r1), ranges::end(__r1),
         ranges::begin(__r2), ranges::end(__r2),
         std::move(__pred),
         std::move(__proj1), std::move(__proj2));
      }
  };

  inline constexpr __find_first_of_fn find_first_of{};

  struct __count_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      typename _Tp >
      requires indirect_binary_predicate<ranges::equal_to,
      projected<_Iter, _Proj>,
      const _Tp*>
      constexpr iter_difference_t<_Iter>
      operator()(_Iter __first, _Sent __last,
   const _Tp& __value, _Proj __proj = {}) const
      {
 iter_difference_t<_Iter> __n = 0;
 for (; __first != __last; ++__first)
   if (std::__invoke(__proj, *__first) == __value)
     ++__n;
 return __n;
      }

    template<input_range _Range, typename _Proj = identity,
      typename _Tp
        >
      requires indirect_binary_predicate<ranges::equal_to,
      projected<iterator_t<_Range>, _Proj>,
      const _Tp*>
      constexpr range_difference_t<_Range>
      operator()(_Range&& __r, const _Tp& __value, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         __value, std::move(__proj));
      }
  };

  inline constexpr __count_fn count{};

  struct __count_if_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_unary_predicate<projected<_Iter, _Proj>> _Pred>
      constexpr iter_difference_t<_Iter>
      operator()(_Iter __first, _Sent __last,
   _Pred __pred, _Proj __proj = {}) const
      {
 iter_difference_t<_Iter> __n = 0;
 for (; __first != __last; ++__first)
   if (std::__invoke(__pred, std::__invoke(__proj, *__first)))
     ++__n;
 return __n;
      }

    template<input_range _Range,
      typename _Proj = identity,
      indirect_unary_predicate<projected<iterator_t<_Range>, _Proj>>
        _Pred>
      constexpr range_difference_t<_Range>
      operator()(_Range&& __r, _Pred __pred, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__pred), std::move(__proj));
      }
  };

  inline constexpr __count_if_fn count_if{};



  struct __search_n_fn
  {
    template<forward_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Pred = ranges::equal_to, typename _Proj = identity,
      typename _Tp >
      requires indirectly_comparable<_Iter, const _Tp*, _Pred, _Proj>
      constexpr subrange<_Iter>
      operator()(_Iter __first, _Sent __last, iter_difference_t<_Iter> __count,
   const _Tp& __value, _Pred __pred = {}, _Proj __proj = {}) const
      {
 if (__count <= 0)
   return {__first, __first};

 auto __value_comp = [&] <typename _Rp> (_Rp&& __arg) -> bool {
     return std::__invoke(__pred, std::forward<_Rp>(__arg), __value);
 };
 if (__count == 1)
   {
     __first = ranges::find_if(std::move(__first), __last,
          std::move(__value_comp),
          std::move(__proj));
     if (__first == __last)
       return {__first, __first};
     else
       {
  auto __end = __first;
  return {__first, ++__end};
       }
   }

 if constexpr (sized_sentinel_for<_Sent, _Iter>
        && random_access_iterator<_Iter>)
   {
     auto __tail_size = __last - __first;
     auto __remainder = __count;

     while (__remainder <= __tail_size)
       {
  __first += __remainder;
  __tail_size -= __remainder;
  auto __backtrack = __first;
  while (__value_comp(std::__invoke(__proj, *--__backtrack)))
    {
      if (--__remainder == 0)
        return {__first - __count, __first};
    }
  __remainder = __count + 1 - (__first - __backtrack);
       }
     auto __i = __first + __tail_size;
     return {__i, __i};
   }
 else
   {
     __first = ranges::find_if(__first, __last, __value_comp, __proj);
     while (__first != __last)
       {
  auto __n = __count;
  auto __i = __first;
  ++__i;
  while (__i != __last && __n != 1
         && __value_comp(std::__invoke(__proj, *__i)))
    {
      ++__i;
      --__n;
    }
  if (__n == 1)
    return {__first, __i};
  if (__i == __last)
    return {__i, __i};
  __first = ranges::find_if(++__i, __last, __value_comp, __proj);
       }
     return {__first, __first};
   }
      }

    template<forward_range _Range,
      typename _Pred = ranges::equal_to, typename _Proj = identity,
      typename _Tp
        >
      requires indirectly_comparable<iterator_t<_Range>, const _Tp*,
         _Pred, _Proj>
      constexpr borrowed_subrange_t<_Range>
      operator()(_Range&& __r, range_difference_t<_Range> __count,
        const _Tp& __value, _Pred __pred = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__count), __value,
         std::move(__pred), std::move(__proj));
      }
  };

  inline constexpr __search_n_fn search_n{};

  struct __find_end_fn
  {
    template<forward_iterator _Iter1, sentinel_for<_Iter1> _Sent1,
      forward_iterator _Iter2, sentinel_for<_Iter2> _Sent2,
      typename _Pred = ranges::equal_to,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires indirectly_comparable<_Iter1, _Iter2, _Pred, _Proj1, _Proj2>
      constexpr subrange<_Iter1>
      operator()(_Iter1 __first1, _Sent1 __last1,
   _Iter2 __first2, _Sent2 __last2, _Pred __pred = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 if constexpr (bidirectional_iterator<_Iter1>
        && bidirectional_iterator<_Iter2>)
   {
     auto __i1 = ranges::next(__first1, __last1);
     auto __i2 = ranges::next(__first2, __last2);
     auto __rresult
       = ranges::search(reverse_iterator<_Iter1>{__i1},
          reverse_iterator<_Iter1>{__first1},
          reverse_iterator<_Iter2>{__i2},
          reverse_iterator<_Iter2>{__first2},
          std::move(__pred),
          std::move(__proj1), std::move(__proj2));
     auto __result_first = ranges::end(__rresult).base();
     auto __result_last = ranges::begin(__rresult).base();
     if (__result_last == __first1)
       return {__i1, __i1};
     else
       return {__result_first, __result_last};
   }
 else
   {
     auto __i = ranges::next(__first1, __last1);
     if (__first2 == __last2)
       return {__i, __i};

     auto __result_begin = __i;
     auto __result_end = __i;
     for (;;)
       {
  auto __new_range = ranges::search(__first1, __last1,
        __first2, __last2,
        __pred, __proj1, __proj2);
  auto __new_result_begin = ranges::begin(__new_range);
  auto __new_result_end = ranges::end(__new_range);
  if (__new_result_begin == __last1)
    return {__result_begin, __result_end};
  else
    {
      __result_begin = __new_result_begin;
      __result_end = __new_result_end;
      __first1 = __result_begin;
      ++__first1;
    }
       }
   }
      }

    template<forward_range _Range1, forward_range _Range2,
      typename _Pred = ranges::equal_to,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires indirectly_comparable<iterator_t<_Range1>, iterator_t<_Range2>,
         _Pred, _Proj1, _Proj2>
      constexpr borrowed_subrange_t<_Range1>
      operator()(_Range1&& __r1, _Range2&& __r2, _Pred __pred = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 return (*this)(ranges::begin(__r1), ranges::end(__r1),
         ranges::begin(__r2), ranges::end(__r2),
         std::move(__pred),
         std::move(__proj1), std::move(__proj2));
      }
  };

  inline constexpr __find_end_fn find_end{};



  struct __is_permutation_fn
  {
    template<forward_iterator _Iter1, sentinel_for<_Iter1> _Sent1,
      forward_iterator _Iter2, sentinel_for<_Iter2> _Sent2,
      typename _Proj1 = identity, typename _Proj2 = identity,
      indirect_equivalence_relation<projected<_Iter1, _Proj1>,
        projected<_Iter2, _Proj2>> _Pred
        = ranges::equal_to>
      constexpr bool
      operator()(_Iter1 __first1, _Sent1 __last1,
   _Iter2 __first2, _Sent2 __last2, _Pred __pred = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 constexpr bool __sized_iters
   = (sized_sentinel_for<_Sent1, _Iter1>
      && sized_sentinel_for<_Sent2, _Iter2>);
 if constexpr (__sized_iters)
   {
     auto __d1 = ranges::distance(__first1, __last1);
     auto __d2 = ranges::distance(__first2, __last2);
     if (__d1 != __d2)
       return false;
   }



 for (; __first1 != __last1 && __first2 != __last2;
      ++__first1, (void)++__first2)
   if (!(bool)std::__invoke(__pred,
       std::__invoke(__proj1, *__first1),
       std::__invoke(__proj2, *__first2)))
       break;

 if constexpr (__sized_iters)
   {
     if (__first1 == __last1)
       return true;
   }
 else
   {
     auto __d1 = ranges::distance(__first1, __last1);
     auto __d2 = ranges::distance(__first2, __last2);
     if (__d1 == 0 && __d2 == 0)
       return true;
     if (__d1 != __d2)
       return false;
   }

 for (auto __scan = __first1; __scan != __last1; ++__scan)
   {
     auto&& __scan_deref = *__scan;
     auto&& __proj_scan =
       std::__invoke(__proj1, std::forward<decltype(__scan_deref)>(__scan_deref));
     auto __comp_scan = [&] <typename _Tp> (_Tp&& __arg) -> bool {
       return std::__invoke(__pred,
       std::forward<decltype(__proj_scan)>(__proj_scan),
       std::forward<_Tp>(__arg));
     };
     if (__scan != ranges::find_if(__first1, __scan,
       __comp_scan, __proj1))
       continue;

     auto __matches = ranges::count_if(__first2, __last2,
           __comp_scan, __proj2);
     if (__matches == 0
  || ranges::count_if(__scan, __last1,
        __comp_scan, __proj1) != __matches)
       return false;
   }
 return true;
      }

    template<forward_range _Range1, forward_range _Range2,
      typename _Proj1 = identity, typename _Proj2 = identity,
      indirect_equivalence_relation<
        projected<iterator_t<_Range1>, _Proj1>,
        projected<iterator_t<_Range2>, _Proj2>> _Pred = ranges::equal_to>
      constexpr bool
      operator()(_Range1&& __r1, _Range2&& __r2, _Pred __pred = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {


 if constexpr (sized_range<_Range1>)
   if constexpr (sized_range<_Range2>)
     if (ranges::distance(__r1) != ranges::distance(__r2))
       return false;

 return (*this)(ranges::begin(__r1), ranges::end(__r1),
         ranges::begin(__r2), ranges::end(__r2),
         std::move(__pred),
         std::move(__proj1), std::move(__proj2));
      }
  };

  inline constexpr __is_permutation_fn is_permutation{};

  template<typename _Iter, typename _Out>
    using copy_if_result = in_out_result<_Iter, _Out>;

  struct __copy_if_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      weakly_incrementable _Out, typename _Proj = identity,
      indirect_unary_predicate<projected<_Iter, _Proj>> _Pred>
      requires indirectly_copyable<_Iter, _Out>
      constexpr copy_if_result<_Iter, _Out>
      operator()(_Iter __first, _Sent __last, _Out __result,
   _Pred __pred, _Proj __proj = {}) const
      {
 for (; __first != __last; ++__first)
   if (std::__invoke(__pred, std::__invoke(__proj, *__first)))
     {
       *__result = *__first;
       ++__result;
     }
 return {std::move(__first), std::move(__result)};
      }

    template<input_range _Range, weakly_incrementable _Out,
      typename _Proj = identity,
      indirect_unary_predicate<projected<iterator_t<_Range>, _Proj>>
        _Pred>
      requires indirectly_copyable<iterator_t<_Range>, _Out>
      constexpr copy_if_result<borrowed_iterator_t<_Range>, _Out>
      operator()(_Range&& __r, _Out __result,
   _Pred __pred, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__result),
         std::move(__pred), std::move(__proj));
      }
  };

  inline constexpr __copy_if_fn copy_if{};

  template<typename _Iter1, typename _Iter2>
    using swap_ranges_result = in_in_result<_Iter1, _Iter2>;

  struct __swap_ranges_fn
  {
    template<input_iterator _Iter1, sentinel_for<_Iter1> _Sent1,
      input_iterator _Iter2, sentinel_for<_Iter2> _Sent2>
      requires indirectly_swappable<_Iter1, _Iter2>
      constexpr swap_ranges_result<_Iter1, _Iter2>
      operator()(_Iter1 __first1, _Sent1 __last1,
   _Iter2 __first2, _Sent2 __last2) const
      {
 for (; __first1 != __last1 && __first2 != __last2;
      ++__first1, (void)++__first2)
   ranges::iter_swap(__first1, __first2);
 return {std::move(__first1), std::move(__first2)};
      }

    template<input_range _Range1, input_range _Range2>
      requires indirectly_swappable<iterator_t<_Range1>, iterator_t<_Range2>>
      constexpr swap_ranges_result<borrowed_iterator_t<_Range1>,
       borrowed_iterator_t<_Range2>>
      operator()(_Range1&& __r1, _Range2&& __r2) const
      {
 return (*this)(ranges::begin(__r1), ranges::end(__r1),
         ranges::begin(__r2), ranges::end(__r2));
      }
  };

  inline constexpr __swap_ranges_fn swap_ranges{};

  template<typename _Iter, typename _Out>
    using unary_transform_result = in_out_result<_Iter, _Out>;

  template<typename _Iter1, typename _Iter2, typename _Out>
    struct in_in_out_result
    {
      [[no_unique_address]] _Iter1 in1;
      [[no_unique_address]] _Iter2 in2;
      [[no_unique_address]] _Out out;

      template<typename _IIter1, typename _IIter2, typename _OOut>
 requires convertible_to<const _Iter1&, _IIter1>
   && convertible_to<const _Iter2&, _IIter2>
   && convertible_to<const _Out&, _OOut>
 constexpr
 operator in_in_out_result<_IIter1, _IIter2, _OOut>() const &
 { return {in1, in2, out}; }

      template<typename _IIter1, typename _IIter2, typename _OOut>
 requires convertible_to<_Iter1, _IIter1>
   && convertible_to<_Iter2, _IIter2>
   && convertible_to<_Out, _OOut>
 constexpr
 operator in_in_out_result<_IIter1, _IIter2, _OOut>() &&
 { return {std::move(in1), std::move(in2), std::move(out)}; }
    };

  template<typename _Iter1, typename _Iter2, typename _Out>
    using binary_transform_result = in_in_out_result<_Iter1, _Iter2, _Out>;

  struct __transform_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      weakly_incrementable _Out,
      copy_constructible _Fp, typename _Proj = identity>
      requires indirectly_writable<_Out,
       indirect_result_t<_Fp&,
         projected<_Iter, _Proj>>>
      constexpr unary_transform_result<_Iter, _Out>
      operator()(_Iter __first1, _Sent __last1, _Out __result,
   _Fp __op, _Proj __proj = {}) const
      {
 for (; __first1 != __last1; ++__first1, (void)++__result)
   *__result = std::__invoke(__op, std::__invoke(__proj, *__first1));
 return {std::move(__first1), std::move(__result)};
      }

    template<input_range _Range, weakly_incrementable _Out,
      copy_constructible _Fp, typename _Proj = identity>
      requires indirectly_writable<_Out,
       indirect_result_t<_Fp&,
         projected<iterator_t<_Range>, _Proj>>>
      constexpr unary_transform_result<borrowed_iterator_t<_Range>, _Out>
      operator()(_Range&& __r, _Out __result, _Fp __op, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__result),
         std::move(__op), std::move(__proj));
      }

    template<input_iterator _Iter1, sentinel_for<_Iter1> _Sent1,
      input_iterator _Iter2, sentinel_for<_Iter2> _Sent2,
      weakly_incrementable _Out, copy_constructible _Fp,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires indirectly_writable<_Out,
       indirect_result_t<_Fp&,
         projected<_Iter1, _Proj1>,
         projected<_Iter2, _Proj2>>>
      constexpr binary_transform_result<_Iter1, _Iter2, _Out>
      operator()(_Iter1 __first1, _Sent1 __last1,
   _Iter2 __first2, _Sent2 __last2,
   _Out __result, _Fp __binary_op,
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 for (; __first1 != __last1 && __first2 != __last2;
      ++__first1, (void)++__first2, ++__result)
   *__result = std::__invoke(__binary_op,
        std::__invoke(__proj1, *__first1),
        std::__invoke(__proj2, *__first2));
 return {std::move(__first1), std::move(__first2), std::move(__result)};
      }

    template<input_range _Range1, input_range _Range2,
      weakly_incrementable _Out, copy_constructible _Fp,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires indirectly_writable<_Out,
       indirect_result_t<_Fp&,
         projected<iterator_t<_Range1>, _Proj1>,
         projected<iterator_t<_Range2>, _Proj2>>>
      constexpr binary_transform_result<borrowed_iterator_t<_Range1>,
     borrowed_iterator_t<_Range2>, _Out>
      operator()(_Range1&& __r1, _Range2&& __r2, _Out __result, _Fp __binary_op,
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 return (*this)(ranges::begin(__r1), ranges::end(__r1),
         ranges::begin(__r2), ranges::end(__r2),
         std::move(__result), std::move(__binary_op),
         std::move(__proj1), std::move(__proj2));
      }
  };

  inline constexpr __transform_fn transform{};

  struct __replace_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      typename _Tp1 ,
      typename _Tp2 >
      requires indirectly_writable<_Iter, const _Tp2&>
 && indirect_binary_predicate<ranges::equal_to, projected<_Iter, _Proj>,
         const _Tp1*>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last,
   const _Tp1& __old_value, const _Tp2& __new_value,
   _Proj __proj = {}) const
      {
 for (; __first != __last; ++__first)
   if (std::__invoke(__proj, *__first) == __old_value)
     *__first = __new_value;
 return __first;
      }

    template<input_range _Range, typename _Proj = identity,
      typename _Tp1
        ,
      typename _Tp2 >
      requires indirectly_writable<iterator_t<_Range>, const _Tp2&>
 && indirect_binary_predicate<ranges::equal_to,
         projected<iterator_t<_Range>, _Proj>,
         const _Tp1*>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r,
   const _Tp1& __old_value, const _Tp2& __new_value,
   _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         __old_value, __new_value, std::move(__proj));
      }
  };

  inline constexpr __replace_fn replace{};

  struct __replace_if_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      typename _Tp ,
      indirect_unary_predicate<projected<_Iter, _Proj>> _Pred>
      requires indirectly_writable<_Iter, const _Tp&>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last,
   _Pred __pred, const _Tp& __new_value, _Proj __proj = {}) const
      {
 for (; __first != __last; ++__first)
   if (std::__invoke(__pred, std::__invoke(__proj, *__first)))
     *__first = __new_value;
 return std::move(__first);
      }

    template<input_range _Range, typename _Proj = identity,
      typename _Tp
        ,
      indirect_unary_predicate<projected<iterator_t<_Range>, _Proj>>
        _Pred>
      requires indirectly_writable<iterator_t<_Range>, const _Tp&>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r,
   _Pred __pred, const _Tp& __new_value, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__pred), __new_value, std::move(__proj));
      }
  };

  inline constexpr __replace_if_fn replace_if{};

  template<typename _Iter, typename _Out>
    using replace_copy_result = in_out_result<_Iter, _Out>;

  struct __replace_copy_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Out, typename _Proj = identity,
      typename _Tp1 ,
      typename _Tp2 >
      requires indirectly_copyable<_Iter, _Out>
 && indirect_binary_predicate<ranges::equal_to,
         projected<_Iter, _Proj>, const _Tp1*>
 && output_iterator<_Out, const _Tp2&>
      constexpr replace_copy_result<_Iter, _Out>
      operator()(_Iter __first, _Sent __last, _Out __result,
   const _Tp1& __old_value, const _Tp2& __new_value,
   _Proj __proj = {}) const
      {
 for (; __first != __last; ++__first, (void)++__result)
   if (std::__invoke(__proj, *__first) == __old_value)
     *__result = __new_value;
   else
     *__result = *__first;
 return {std::move(__first), std::move(__result)};
      }

    template<input_range _Range, typename _Out,
      typename _Proj = identity,
      typename _Tp1
        ,
      typename _Tp2 >
      requires indirectly_copyable<iterator_t<_Range>, _Out>
 && indirect_binary_predicate<ranges::equal_to,
         projected<iterator_t<_Range>, _Proj>,
         const _Tp1*>
 && output_iterator<_Out, const _Tp2&>
      constexpr replace_copy_result<borrowed_iterator_t<_Range>, _Out>
      operator()(_Range&& __r, _Out __result,
   const _Tp1& __old_value, const _Tp2& __new_value,
   _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__result), __old_value,
         __new_value, std::move(__proj));
      }
  };

  inline constexpr __replace_copy_fn replace_copy{};

  template<typename _Iter, typename _Out>
    using replace_copy_if_result = in_out_result<_Iter, _Out>;

  struct __replace_copy_if_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Out,
      typename _Tp ,
      typename _Proj = identity,
      indirect_unary_predicate<projected<_Iter, _Proj>> _Pred>
      requires indirectly_copyable<_Iter, _Out>
 && output_iterator<_Out, const _Tp&>
      constexpr replace_copy_if_result<_Iter, _Out>
      operator()(_Iter __first, _Sent __last, _Out __result,
   _Pred __pred, const _Tp& __new_value, _Proj __proj = {}) const
      {
 for (; __first != __last; ++__first, (void)++__result)
   if (std::__invoke(__pred, std::__invoke(__proj, *__first)))
     *__result = __new_value;
   else
     *__result = *__first;
 return {std::move(__first), std::move(__result)};
      }

    template<input_range _Range,
      typename _Out,
      typename _Tp ,
      typename _Proj = identity,
      indirect_unary_predicate<projected<iterator_t<_Range>, _Proj>>
        _Pred>
      requires indirectly_copyable<iterator_t<_Range>, _Out>
 && output_iterator<_Out, const _Tp&>
      constexpr replace_copy_if_result<borrowed_iterator_t<_Range>, _Out>
      operator()(_Range&& __r, _Out __result,
   _Pred __pred, const _Tp& __new_value, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__result), std::move(__pred),
         __new_value, std::move(__proj));
      }
  };

  inline constexpr __replace_copy_if_fn replace_copy_if{};

  struct __generate_n_fn
  {
    template<input_or_output_iterator _Out, copy_constructible _Fp>
      requires invocable<_Fp&>
 && indirectly_writable<_Out, invoke_result_t<_Fp&>>
      constexpr _Out
      operator()(_Out __first, iter_difference_t<_Out> __n, _Fp __gen) const
      {
 for (; __n > 0; --__n, (void)++__first)
   *__first = std::__invoke(__gen);
 return __first;
      }
  };

  inline constexpr __generate_n_fn generate_n{};

  struct __generate_fn
  {
    template<input_or_output_iterator _Out, sentinel_for<_Out> _Sent,
      copy_constructible _Fp>
      requires invocable<_Fp&>
 && indirectly_writable<_Out, invoke_result_t<_Fp&>>
      constexpr _Out
      operator()(_Out __first, _Sent __last, _Fp __gen) const
      {
 for (; __first != __last; ++__first)
   *__first = std::__invoke(__gen);
 return __first;
      }

    template<typename _Range, copy_constructible _Fp>
      requires invocable<_Fp&> && output_range<_Range, invoke_result_t<_Fp&>>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r, _Fp __gen) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r), std::move(__gen));
      }
  };

  inline constexpr __generate_fn generate{};

  struct __remove_if_fn
  {
    template<permutable _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_unary_predicate<projected<_Iter, _Proj>> _Pred>
      constexpr subrange<_Iter>
      operator()(_Iter __first, _Sent __last,
   _Pred __pred, _Proj __proj = {}) const
      {
 __first = ranges::find_if(__first, __last, __pred, __proj);
 if (__first == __last)
   return {__first, __first};

 auto __result = __first;
 ++__first;
 for (; __first != __last; ++__first)
   if (!std::__invoke(__pred, std::__invoke(__proj, *__first)))
     {
       *__result = std::move(*__first);
       ++__result;
     }

 return {__result, __first};
      }

    template<forward_range _Range, typename _Proj = identity,
      indirect_unary_predicate<projected<iterator_t<_Range>, _Proj>>
        _Pred>
      requires permutable<iterator_t<_Range>>
      constexpr borrowed_subrange_t<_Range>
      operator()(_Range&& __r, _Pred __pred, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__pred), std::move(__proj));
      }
  };

  inline constexpr __remove_if_fn remove_if{};

  struct __remove_fn
  {
    template<permutable _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      typename _Tp >
      requires indirect_binary_predicate<ranges::equal_to,
      projected<_Iter, _Proj>,
      const _Tp*>
      constexpr subrange<_Iter>
      operator()(_Iter __first, _Sent __last,
   const _Tp& __value, _Proj __proj = {}) const
      {
 auto __pred = [&] (auto&& __arg) -> bool {
   return std::forward<decltype(__arg)>(__arg) == __value;
 };
 return ranges::remove_if(__first, __last,
     std::move(__pred), std::move(__proj));
      }

    template<forward_range _Range, typename _Proj = identity,
      typename _Tp
        >
      requires permutable<iterator_t<_Range>>
 && indirect_binary_predicate<ranges::equal_to,
         projected<iterator_t<_Range>, _Proj>,
         const _Tp*>
      constexpr borrowed_subrange_t<_Range>
      operator()(_Range&& __r, const _Tp& __value, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         __value, std::move(__proj));
      }
  };

  inline constexpr __remove_fn remove{};

  template<typename _Iter, typename _Out>
    using remove_copy_if_result = in_out_result<_Iter, _Out>;

  struct __remove_copy_if_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      weakly_incrementable _Out, typename _Proj = identity,
      indirect_unary_predicate<projected<_Iter, _Proj>> _Pred>
      requires indirectly_copyable<_Iter, _Out>
      constexpr remove_copy_if_result<_Iter, _Out>
      operator()(_Iter __first, _Sent __last, _Out __result,
   _Pred __pred, _Proj __proj = {}) const
      {
 for (; __first != __last; ++__first)
   if (!std::__invoke(__pred, std::__invoke(__proj, *__first)))
     {
       *__result = *__first;
       ++__result;
     }
 return {std::move(__first), std::move(__result)};
      }

    template<input_range _Range, weakly_incrementable _Out,
      typename _Proj = identity,
      indirect_unary_predicate<projected<iterator_t<_Range>, _Proj>>
        _Pred>
      requires indirectly_copyable<iterator_t<_Range>, _Out>
      constexpr remove_copy_if_result<borrowed_iterator_t<_Range>, _Out>
      operator()(_Range&& __r, _Out __result,
   _Pred __pred, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__result),
         std::move(__pred), std::move(__proj));
      }
  };

  inline constexpr __remove_copy_if_fn remove_copy_if{};

  template<typename _Iter, typename _Out>
    using remove_copy_result = in_out_result<_Iter, _Out>;

  struct __remove_copy_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      weakly_incrementable _Out, typename _Proj = identity,
      typename _Tp >
      requires indirectly_copyable<_Iter, _Out>
 && indirect_binary_predicate<ranges::equal_to,
         projected<_Iter, _Proj>,
         const _Tp*>
      constexpr remove_copy_result<_Iter, _Out>
      operator()(_Iter __first, _Sent __last, _Out __result,
   const _Tp& __value, _Proj __proj = {}) const
      {
 for (; __first != __last; ++__first)
   if (!(std::__invoke(__proj, *__first) == __value))
     {
       *__result = *__first;
       ++__result;
     }
 return {std::move(__first), std::move(__result)};
      }

    template<input_range _Range, weakly_incrementable _Out,
      typename _Proj = identity,
      typename _Tp
        >
      requires indirectly_copyable<iterator_t<_Range>, _Out>
 && indirect_binary_predicate<ranges::equal_to,
         projected<iterator_t<_Range>, _Proj>,
         const _Tp*>
      constexpr remove_copy_result<borrowed_iterator_t<_Range>, _Out>
      operator()(_Range&& __r, _Out __result,
   const _Tp& __value, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__result), __value, std::move(__proj));
      }
  };

  inline constexpr __remove_copy_fn remove_copy{};

  struct __unique_fn
  {
    template<permutable _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_equivalence_relation<
        projected<_Iter, _Proj>> _Comp = ranges::equal_to>
      constexpr subrange<_Iter>
      operator()(_Iter __first, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 __first = ranges::adjacent_find(__first, __last, __comp, __proj);
 if (__first == __last)
   return {__first, __first};

 auto __dest = __first;
 ++__first;
 while (++__first != __last)
   if (!std::__invoke(__comp,
        std::__invoke(__proj, *__dest),
        std::__invoke(__proj, *__first)))
     *++__dest = std::move(*__first);
 return {++__dest, __first};
      }

    template<forward_range _Range, typename _Proj = identity,
      indirect_equivalence_relation<
        projected<iterator_t<_Range>, _Proj>> _Comp = ranges::equal_to>
      requires permutable<iterator_t<_Range>>
      constexpr borrowed_subrange_t<_Range>
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __unique_fn unique{};

  namespace __detail
  {
    template<typename _Out, typename _Tp>
      concept __can_reread_output = input_iterator<_Out>
 && same_as<_Tp, iter_value_t<_Out>>;
  }

  template<typename _Iter, typename _Out>
    using unique_copy_result = in_out_result<_Iter, _Out>;

  struct __unique_copy_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      weakly_incrementable _Out, typename _Proj = identity,
      indirect_equivalence_relation<
        projected<_Iter, _Proj>> _Comp = ranges::equal_to>
      requires indirectly_copyable<_Iter, _Out>
 && (forward_iterator<_Iter>
     || __detail::__can_reread_output<_Out, iter_value_t<_Iter>>
     || indirectly_copyable_storable<_Iter, _Out>)
      constexpr unique_copy_result<_Iter, _Out>
      operator()(_Iter __first, _Sent __last, _Out __result,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 if (__first == __last)
   return {std::move(__first), std::move(__result)};


 if constexpr (forward_iterator<_Iter>)
   {
     auto __next = __first;
     *__result = *__next;
     while (++__next != __last)
       if (!std::__invoke(__comp,
     std::__invoke(__proj, *__first),
     std::__invoke(__proj, *__next)))
  {
    __first = __next;
    *++__result = *__first;
  }
     return {__next, std::move(++__result)};
   }
 else if constexpr (__detail::__can_reread_output<_Out, iter_value_t<_Iter>>)
   {
     *__result = *__first;
     while (++__first != __last)
       if (!std::__invoke(__comp,
     std::__invoke(__proj, *__result),
     std::__invoke(__proj, *__first)))
    *++__result = *__first;
     return {std::move(__first), std::move(++__result)};
   }
 else
   {
     auto __value = *__first;
     *__result = __value;
     while (++__first != __last)
       {
  if (!(bool)std::__invoke(__comp,
      std::__invoke(__proj, *__first),
      std::__invoke(__proj, __value)))
    {
      __value = *__first;
      *++__result = __value;
    }
       }
     return {std::move(__first), std::move(++__result)};
   }
      }

    template<input_range _Range,
      weakly_incrementable _Out, typename _Proj = identity,
      indirect_equivalence_relation<
        projected<iterator_t<_Range>, _Proj>> _Comp = ranges::equal_to>
      requires indirectly_copyable<iterator_t<_Range>, _Out>
 && (forward_iterator<iterator_t<_Range>>
     || __detail::__can_reread_output<_Out, range_value_t<_Range>>
     || indirectly_copyable_storable<iterator_t<_Range>, _Out>)
      constexpr unique_copy_result<borrowed_iterator_t<_Range>, _Out>
      operator()(_Range&& __r, _Out __result,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__result),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __unique_copy_fn unique_copy{};

  struct __reverse_fn
  {
    template<bidirectional_iterator _Iter, sentinel_for<_Iter> _Sent>
      requires permutable<_Iter>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last) const
      {
 auto __i = ranges::next(__first, __last);
 auto __tail = __i;

 if constexpr (random_access_iterator<_Iter>)
   {
     if (__first != __last)
       {
  --__tail;
  while (__first < __tail)
    {
      ranges::iter_swap(__first, __tail);
      ++__first;
      --__tail;
    }
       }
     return __i;
   }
 else
   {
     for (;;)
       if (__first == __tail || __first == --__tail)
  break;
       else
  {
    ranges::iter_swap(__first, __tail);
    ++__first;
  }
     return __i;
   }
      }

    template<bidirectional_range _Range>
      requires permutable<iterator_t<_Range>>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r));
      }
  };

  inline constexpr __reverse_fn reverse{};

  template<typename _Iter, typename _Out>
    using reverse_copy_result = in_out_result<_Iter, _Out>;

  struct __reverse_copy_fn
  {
    template<bidirectional_iterator _Iter, sentinel_for<_Iter> _Sent,
      weakly_incrementable _Out>
      requires indirectly_copyable<_Iter, _Out>
      constexpr reverse_copy_result<_Iter, _Out>
      operator()(_Iter __first, _Sent __last, _Out __result) const
      {
 auto __i = ranges::next(__first, __last);
 auto __tail = __i;
 while (__first != __tail)
   {
     --__tail;
     *__result = *__tail;
     ++__result;
   }
 return {__i, std::move(__result)};
      }

    template<bidirectional_range _Range, weakly_incrementable _Out>
      requires indirectly_copyable<iterator_t<_Range>, _Out>
      constexpr reverse_copy_result<borrowed_iterator_t<_Range>, _Out>
      operator()(_Range&& __r, _Out __result) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__result));
      }
  };

  inline constexpr __reverse_copy_fn reverse_copy{};

  struct __rotate_fn
  {
    template<permutable _Iter, sentinel_for<_Iter> _Sent>
      constexpr subrange<_Iter>
      operator()(_Iter __first, _Iter __middle, _Sent __last) const
      {
 auto __lasti = ranges::next(__first, __last);
 if (__first == __middle)
   return {__lasti, __lasti};
 if (__last == __middle)
   return {std::move(__first), std::move(__lasti)};

 if constexpr (random_access_iterator<_Iter>)
   {
     auto __n = __lasti - __first;
     auto __k = __middle - __first;

     if (__k == __n - __k)
       {
  ranges::swap_ranges(__first, __middle, __middle, __middle + __k);
  return {std::move(__middle), std::move(__lasti)};
       }

     auto __p = __first;
     auto __ret = __first + (__lasti - __middle);

     for (;;)
       {
  if (__k < __n - __k)
    {


      if constexpr (__is_pod(iter_value_t<_Iter>))
        if (__k == 1)
   {
     auto __t = std::move(*__p);
     ranges::move(__p + 1, __p + __n, __p);
     *(__p + __n - 1) = std::move(__t);
     return {std::move(__ret), std::move(__lasti)};
   }
      auto __q = __p + __k;
      for (decltype(__n) __i = 0; __i < __n - __k; ++ __i)
        {
   ranges::iter_swap(__p, __q);
   ++__p;
   ++__q;
        }
      __n %= __k;
      if (__n == 0)
        return {std::move(__ret), std::move(__lasti)};
      ranges::swap(__n, __k);
      __k = __n - __k;
    }
  else
    {
      __k = __n - __k;


      if constexpr (__is_pod(iter_value_t<_Iter>))
        if (__k == 1)
   {
     auto __t = std::move(*(__p + __n - 1));
     ranges::move_backward(__p, __p + __n - 1, __p + __n);
     *__p = std::move(__t);
     return {std::move(__ret), std::move(__lasti)};
   }
      auto __q = __p + __n;
      __p = __q - __k;
      for (decltype(__n) __i = 0; __i < __n - __k; ++ __i)
        {
   --__p;
   --__q;
   ranges::iter_swap(__p, __q);
        }
      __n %= __k;
      if (__n == 0)
        return {std::move(__ret), std::move(__lasti)};
      std::swap(__n, __k);
    }
       }
   }
 else if constexpr (bidirectional_iterator<_Iter>)
   {
     auto __tail = __lasti;

     ranges::reverse(__first, __middle);
     ranges::reverse(__middle, __tail);

     while (__first != __middle && __middle != __tail)
       {
  ranges::iter_swap(__first, --__tail);
  ++__first;
       }

     if (__first == __middle)
       {
  ranges::reverse(__middle, __tail);
  return {std::move(__tail), std::move(__lasti)};
       }
     else
       {
  ranges::reverse(__first, __middle);
  return {std::move(__first), std::move(__lasti)};
       }
   }
 else
   {
     auto __first2 = __middle;
     do
       {
  ranges::iter_swap(__first, __first2);
  ++__first;
  ++__first2;
  if (__first == __middle)
    __middle = __first2;
       } while (__first2 != __last);

     auto __ret = __first;

     __first2 = __middle;

     while (__first2 != __last)
       {
  ranges::iter_swap(__first, __first2);
  ++__first;
  ++__first2;
  if (__first == __middle)
    __middle = __first2;
  else if (__first2 == __last)
    __first2 = __middle;
       }
     return {std::move(__ret), std::move(__lasti)};
   }
      }

    template<forward_range _Range>
      requires permutable<iterator_t<_Range>>
      constexpr borrowed_subrange_t<_Range>
      operator()(_Range&& __r, iterator_t<_Range> __middle) const
      {
 return (*this)(ranges::begin(__r), std::move(__middle),
         ranges::end(__r));
      }
  };

  inline constexpr __rotate_fn rotate{};

  template<typename _Iter, typename _Out>
    using rotate_copy_result = in_out_result<_Iter, _Out>;

  struct __rotate_copy_fn
  {
    template<forward_iterator _Iter, sentinel_for<_Iter> _Sent,
      weakly_incrementable _Out>
      requires indirectly_copyable<_Iter, _Out>
      constexpr rotate_copy_result<_Iter, _Out>
      operator()(_Iter __first, _Iter __middle, _Sent __last,
   _Out __result) const
      {
 auto __copy1 = ranges::copy(__middle,
        std::move(__last),
        std::move(__result));
 auto __copy2 = ranges::copy(std::move(__first),
        std::move(__middle),
        std::move(__copy1.out));
 return { std::move(__copy1.in), std::move(__copy2.out) };
      }

    template<forward_range _Range, weakly_incrementable _Out>
      requires indirectly_copyable<iterator_t<_Range>, _Out>
      constexpr rotate_copy_result<borrowed_iterator_t<_Range>, _Out>
      operator()(_Range&& __r, iterator_t<_Range> __middle, _Out __result) const
      {
 return (*this)(ranges::begin(__r), std::move(__middle),
         ranges::end(__r), std::move(__result));
      }
  };

  inline constexpr __rotate_copy_fn rotate_copy{};

  struct __sample_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      weakly_incrementable _Out, typename _Gen>
      requires (forward_iterator<_Iter> || random_access_iterator<_Out>)
 && indirectly_copyable<_Iter, _Out>
 && uniform_random_bit_generator<remove_reference_t<_Gen>>
      _Out
      operator()(_Iter __first, _Sent __last, _Out __out,
   iter_difference_t<_Iter> __n, _Gen&& __g) const
      {
 if constexpr (forward_iterator<_Iter>)
   {


     auto __lasti = ranges::next(__first, __last);
     return std::
       sample(std::move(__first), std::move(__lasti), std::move(__out),
       __n, std::forward<_Gen>(__g));
   }
 else
   {
     using __distrib_type
       = uniform_int_distribution<iter_difference_t<_Iter>>;
     using __param_type = typename __distrib_type::param_type;
     __distrib_type __d{};
     iter_difference_t<_Iter> __sample_sz = 0;
     while (__first != __last && __sample_sz != __n)
       {
  __out[__sample_sz++] = *__first;
  ++__first;
       }
     for (auto __pop_sz = __sample_sz; __first != __last;
  ++__first, (void) ++__pop_sz)
       {
  const auto __k = __d(__g, __param_type{0, __pop_sz});
  if (__k < __n)
    __out[__k] = *__first;
       }
     return __out + __sample_sz;
   }
      }

    template<input_range _Range, weakly_incrementable _Out, typename _Gen>
      requires (forward_range<_Range> || random_access_iterator<_Out>)
 && indirectly_copyable<iterator_t<_Range>, _Out>
 && uniform_random_bit_generator<remove_reference_t<_Gen>>
      _Out
      operator()(_Range&& __r, _Out __out,
   range_difference_t<_Range> __n, _Gen&& __g) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__out), __n,
         std::forward<_Gen>(__g));
      }
  };

  inline constexpr __sample_fn sample{};

  struct __shuffle_fn
  {
    template<random_access_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Gen>
      requires permutable<_Iter>
 && uniform_random_bit_generator<remove_reference_t<_Gen>>
      _Iter
      operator()(_Iter __first, _Sent __last, _Gen&& __g) const
      {
 auto __lasti = ranges::next(__first, __last);
 std::shuffle(std::move(__first), __lasti, std::forward<_Gen>(__g));
 return __lasti;
      }

    template<random_access_range _Range, typename _Gen>
      requires permutable<iterator_t<_Range>>
 && uniform_random_bit_generator<remove_reference_t<_Gen>>
      borrowed_iterator_t<_Range>
      operator()(_Range&& __r, _Gen&& __g) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::forward<_Gen>(__g));
      }
  };

  inline constexpr __shuffle_fn shuffle{};

  struct __push_heap_fn
  {
    template<random_access_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<_Iter, _Comp, _Proj>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 auto __lasti = ranges::next(__first, __last);
 std::push_heap(__first, __lasti,
         __detail::__make_comp_proj(__comp, __proj));
 return __lasti;
      }

    template<random_access_range _Range,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<iterator_t<_Range>, _Comp, _Proj>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __push_heap_fn push_heap{};

  struct __pop_heap_fn
  {
    template<random_access_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<_Iter, _Comp, _Proj>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 auto __lasti = ranges::next(__first, __last);
 std::pop_heap(__first, __lasti,
        __detail::__make_comp_proj(__comp, __proj));
 return __lasti;
      }

    template<random_access_range _Range,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<iterator_t<_Range>, _Comp, _Proj>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __pop_heap_fn pop_heap{};

  struct __make_heap_fn
  {
    template<random_access_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<_Iter, _Comp, _Proj>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 auto __lasti = ranges::next(__first, __last);
 std::make_heap(__first, __lasti,
         __detail::__make_comp_proj(__comp, __proj));
 return __lasti;
      }

    template<random_access_range _Range,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<iterator_t<_Range>, _Comp, _Proj>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __make_heap_fn make_heap{};

  struct __sort_heap_fn
  {
    template<random_access_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<_Iter, _Comp, _Proj>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 auto __lasti = ranges::next(__first, __last);
 std::sort_heap(__first, __lasti,
         __detail::__make_comp_proj(__comp, __proj));
 return __lasti;
      }

    template<random_access_range _Range,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<iterator_t<_Range>, _Comp, _Proj>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __sort_heap_fn sort_heap{};

  struct __is_heap_until_fn
  {
    template<random_access_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_strict_weak_order<projected<_Iter, _Proj>>
        _Comp = ranges::less>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 iter_difference_t<_Iter> __n = ranges::distance(__first, __last);
 iter_difference_t<_Iter> __parent = 0, __child = 1;
 for (; __child < __n; ++__child)
   if (std::__invoke(__comp,
       std::__invoke(__proj, *(__first + __parent)),
       std::__invoke(__proj, *(__first + __child))))
     return __first + __child;
   else if ((__child & 1) == 0)
     ++__parent;

 return __first + __n;
      }

    template<random_access_range _Range,
      typename _Proj = identity,
      indirect_strict_weak_order<projected<iterator_t<_Range>, _Proj>>
        _Comp = ranges::less>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __is_heap_until_fn is_heap_until{};

  struct __is_heap_fn
  {
    template<random_access_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_strict_weak_order<projected<_Iter, _Proj>>
        _Comp = ranges::less>
      constexpr bool
      operator()(_Iter __first, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (__last
  == ranges::is_heap_until(__first, __last,
      std::move(__comp),
      std::move(__proj)));
      }

    template<random_access_range _Range,
      typename _Proj = identity,
      indirect_strict_weak_order<projected<iterator_t<_Range>, _Proj>>
        _Comp = ranges::less>
      constexpr bool
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __is_heap_fn is_heap{};

  struct __sort_fn
  {
    template<random_access_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<_Iter, _Comp, _Proj>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 auto __lasti = ranges::next(__first, __last);
 std::sort(std::move(__first), __lasti,
        __detail::__make_comp_proj(__comp, __proj));
 return __lasti;
      }

    template<random_access_range _Range,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<iterator_t<_Range>, _Comp, _Proj>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __sort_fn sort{};

  struct __stable_sort_fn
  {
    template<random_access_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<_Iter, _Comp, _Proj>
     
      _Iter
      operator()(_Iter __first, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 auto __lasti = ranges::next(__first, __last);
 std::stable_sort(std::move(__first), __lasti,
    __detail::__make_comp_proj(__comp, __proj));
 return __lasti;
      }

    template<random_access_range _Range,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<iterator_t<_Range>, _Comp, _Proj>
     
      borrowed_iterator_t<_Range>
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __stable_sort_fn stable_sort{};

  struct __partial_sort_fn
  {
    template<random_access_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<_Iter, _Comp, _Proj>
      constexpr _Iter
      operator()(_Iter __first, _Iter __middle, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 if (__first == __middle)
   return ranges::next(__first, __last);

 ranges::make_heap(__first, __middle, __comp, __proj);
 auto __i = __middle;
 for (; __i != __last; ++__i)
   if (std::__invoke(__comp,
       std::__invoke(__proj, *__i),
       std::__invoke(__proj, *__first)))
     {
       ranges::pop_heap(__first, __middle, __comp, __proj);
       ranges::iter_swap(__middle-1, __i);
       ranges::push_heap(__first, __middle, __comp, __proj);
     }
 ranges::sort_heap(__first, __middle, __comp, __proj);

 return __i;
      }

    template<random_access_range _Range,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<iterator_t<_Range>, _Comp, _Proj>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r, iterator_t<_Range> __middle,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), std::move(__middle),
         ranges::end(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __partial_sort_fn partial_sort{};

  template<typename _Iter, typename _Out>
    using partial_sort_copy_result = in_out_result<_Iter, _Out>;

  struct __partial_sort_copy_fn
  {
    template<input_iterator _Iter1, sentinel_for<_Iter1> _Sent1,
      random_access_iterator _Iter2, sentinel_for<_Iter2> _Sent2,
      typename _Comp = ranges::less,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires indirectly_copyable<_Iter1, _Iter2>
 && sortable<_Iter2, _Comp, _Proj2>
 && indirect_strict_weak_order<_Comp,
          projected<_Iter1, _Proj1>,
          projected<_Iter2, _Proj2>>
      constexpr partial_sort_copy_result<_Iter1, _Iter2>
      operator()(_Iter1 __first, _Sent1 __last,
   _Iter2 __result_first, _Sent2 __result_last,
   _Comp __comp = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 if (__result_first == __result_last)
   {

     auto __lasti = ranges::next(std::move(__first),
     std::move(__last));
     return {std::move(__lasti), std::move(__result_first)};
   }

 auto __result_real_last = __result_first;
 while (__first != __last && __result_real_last != __result_last)
   {
     *__result_real_last = *__first;
     ++__result_real_last;
     ++__first;
   }

 ranges::make_heap(__result_first, __result_real_last, __comp, __proj2);
 for (; __first != __last; ++__first)
   if (std::__invoke(__comp,
       std::__invoke(__proj1, *__first),
       std::__invoke(__proj2, *__result_first)))
     {
       ranges::pop_heap(__result_first, __result_real_last,
          __comp, __proj2);
       *(__result_real_last-1) = *__first;
       ranges::push_heap(__result_first, __result_real_last,
    __comp, __proj2);
     }
 ranges::sort_heap(__result_first, __result_real_last, __comp, __proj2);

 return {std::move(__first), std::move(__result_real_last)};
      }

    template<input_range _Range1, random_access_range _Range2,
      typename _Comp = ranges::less,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires indirectly_copyable<iterator_t<_Range1>, iterator_t<_Range2>>
 && sortable<iterator_t<_Range2>, _Comp, _Proj2>
 && indirect_strict_weak_order<_Comp,
          projected<iterator_t<_Range1>, _Proj1>,
          projected<iterator_t<_Range2>, _Proj2>>
      constexpr partial_sort_copy_result<borrowed_iterator_t<_Range1>,
      borrowed_iterator_t<_Range2>>
      operator()(_Range1&& __r, _Range2&& __out, _Comp __comp = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         ranges::begin(__out), ranges::end(__out),
         std::move(__comp),
         std::move(__proj1), std::move(__proj2));
      }
  };

  inline constexpr __partial_sort_copy_fn partial_sort_copy{};

  struct __is_sorted_until_fn
  {
    template<forward_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_strict_weak_order<projected<_Iter, _Proj>>
        _Comp = ranges::less>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 if (__first == __last)
   return __first;

 auto __next = __first;
 for (++__next; __next != __last; __first = __next, (void)++__next)
   if (std::__invoke(__comp,
       std::__invoke(__proj, *__next),
       std::__invoke(__proj, *__first)))
     return __next;
 return __next;
      }

    template<forward_range _Range, typename _Proj = identity,
      indirect_strict_weak_order<projected<iterator_t<_Range>, _Proj>>
        _Comp = ranges::less>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __is_sorted_until_fn is_sorted_until{};

  struct __is_sorted_fn
  {
    template<forward_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_strict_weak_order<projected<_Iter, _Proj>>
        _Comp = ranges::less>
      constexpr bool
      operator()(_Iter __first, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 if (__first == __last)
   return true;

 auto __next = __first;
 for (++__next; __next != __last; __first = __next, (void)++__next)
   if (std::__invoke(__comp,
       std::__invoke(__proj, *__next),
       std::__invoke(__proj, *__first)))
     return false;
 return true;
      }

    template<forward_range _Range, typename _Proj = identity,
      indirect_strict_weak_order<projected<iterator_t<_Range>, _Proj>>
        _Comp = ranges::less>
      constexpr bool
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __is_sorted_fn is_sorted{};

  struct __nth_element_fn
  {
    template<random_access_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<_Iter, _Comp, _Proj>
      constexpr _Iter
      operator()(_Iter __first, _Iter __nth, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 auto __lasti = ranges::next(__first, __last);
 std::nth_element(std::move(__first), std::move(__nth),
        __lasti,
        __detail::__make_comp_proj(__comp, __proj));
 return __lasti;
      }

    template<random_access_range _Range,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<iterator_t<_Range>, _Comp, _Proj>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r, iterator_t<_Range> __nth,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), std::move(__nth),
         ranges::end(__r), std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __nth_element_fn nth_element{};

  struct __lower_bound_fn
  {
    template<forward_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      typename _Tp ,
      indirect_strict_weak_order<const _Tp*, projected<_Iter, _Proj>>
        _Comp = ranges::less>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last,
   const _Tp& __value, _Comp __comp = {}, _Proj __proj = {}) const
      {
 auto __len = ranges::distance(__first, __last);

 while (__len > 0)
   {
     auto __half = __len / 2;
     auto __middle = __first;
     ranges::advance(__middle, __half);
     if (std::__invoke(__comp, std::__invoke(__proj, *__middle), __value))
       {
  __first = __middle;
  ++__first;
  __len = __len - __half - 1;
       }
     else
       __len = __half;
   }
 return __first;
      }

    template<forward_range _Range,
      typename _Proj = identity,
      typename _Tp
        ,
      indirect_strict_weak_order<const _Tp*,
     projected<iterator_t<_Range>, _Proj>>
        _Comp = ranges::less>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r,
   const _Tp& __value, _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         __value, std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __lower_bound_fn lower_bound{};

  struct __upper_bound_fn
  {
    template<forward_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      typename _Tp ,
      indirect_strict_weak_order<const _Tp*, projected<_Iter, _Proj>>
        _Comp = ranges::less>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last,
   const _Tp& __value, _Comp __comp = {}, _Proj __proj = {}) const
      {
 auto __len = ranges::distance(__first, __last);

 while (__len > 0)
   {
     auto __half = __len / 2;
     auto __middle = __first;
     ranges::advance(__middle, __half);
     if (std::__invoke(__comp, __value, std::__invoke(__proj, *__middle)))
       __len = __half;
     else
       {
  __first = __middle;
  ++__first;
  __len = __len - __half - 1;
       }
   }
 return __first;
      }

    template<forward_range _Range,
      typename _Proj = identity,
      typename _Tp
        ,
      indirect_strict_weak_order<const _Tp*,
     projected<iterator_t<_Range>, _Proj>>
        _Comp = ranges::less>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r,
   const _Tp& __value, _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         __value, std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __upper_bound_fn upper_bound{};

  struct __equal_range_fn
  {
    template<forward_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      typename _Tp ,
      indirect_strict_weak_order<const _Tp*, projected<_Iter, _Proj>>
        _Comp = ranges::less>
      constexpr subrange<_Iter>
      operator()(_Iter __first, _Sent __last,
   const _Tp& __value, _Comp __comp = {}, _Proj __proj = {}) const
      {
 auto __len = ranges::distance(__first, __last);

 while (__len > 0)
   {
     auto __half = __len / 2;
     auto __middle = __first;
     ranges::advance(__middle, __half);
     if (std::__invoke(__comp,
         std::__invoke(__proj, *__middle),
         __value))
       {
  __first = __middle;
  ++__first;
  __len = __len - __half - 1;
       }
     else if (std::__invoke(__comp,
       __value,
       std::__invoke(__proj, *__middle)))
       __len = __half;
     else
       {
  auto __left
    = ranges::lower_bound(__first, __middle,
     __value, __comp, __proj);
  ranges::advance(__first, __len);
  auto __right
    = ranges::upper_bound(++__middle, __first,
     __value, __comp, __proj);
  return {__left, __right};
       }
   }
 return {__first, __first};
      }

    template<forward_range _Range,
      typename _Proj = identity,
      typename _Tp
        ,
      indirect_strict_weak_order<const _Tp*,
     projected<iterator_t<_Range>, _Proj>>
        _Comp = ranges::less>
      constexpr borrowed_subrange_t<_Range>
      operator()(_Range&& __r, const _Tp& __value,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         __value, std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __equal_range_fn equal_range{};

  struct __binary_search_fn
  {
    template<forward_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      typename _Tp ,
      indirect_strict_weak_order<const _Tp*, projected<_Iter, _Proj>>
        _Comp = ranges::less>
      constexpr bool
      operator()(_Iter __first, _Sent __last,
   const _Tp& __value, _Comp __comp = {}, _Proj __proj = {}) const
      {
 auto __i = ranges::lower_bound(__first, __last, __value, __comp, __proj);
 if (__i == __last)
   return false;
 return !(bool)std::__invoke(__comp, __value,
        std::__invoke(__proj, *__i));
      }

    template<forward_range _Range,
      typename _Proj = identity,
      typename _Tp
        ,
      indirect_strict_weak_order<const _Tp*,
     projected<iterator_t<_Range>, _Proj>>
        _Comp = ranges::less>
      constexpr bool
      operator()(_Range&& __r, const _Tp& __value, _Comp __comp = {},
   _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         __value, std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __binary_search_fn binary_search{};

  struct __is_partitioned_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_unary_predicate<projected<_Iter, _Proj>> _Pred>
      constexpr bool
      operator()(_Iter __first, _Sent __last,
   _Pred __pred, _Proj __proj = {}) const
      {
 __first = ranges::find_if_not(std::move(__first), __last,
          __pred, __proj);
 if (__first == __last)
   return true;
 ++__first;
 return ranges::none_of(std::move(__first), std::move(__last),
          std::move(__pred), std::move(__proj));
      }

    template<input_range _Range, typename _Proj = identity,
      indirect_unary_predicate<projected<iterator_t<_Range>, _Proj>>
        _Pred>
      constexpr bool
      operator()(_Range&& __r, _Pred __pred, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__pred), std::move(__proj));
      }
  };

  inline constexpr __is_partitioned_fn is_partitioned{};

  struct __partition_fn
  {
    template<permutable _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_unary_predicate<projected<_Iter, _Proj>> _Pred>
      constexpr subrange<_Iter>
      operator()(_Iter __first, _Sent __last,
   _Pred __pred, _Proj __proj = {}) const
      {
 if constexpr (bidirectional_iterator<_Iter>)
   {
     auto __lasti = ranges::next(__first, __last);
     auto __tail = __lasti;
     for (;;)
       {
  for (;;)
    if (__first == __tail)
      return {std::move(__first), std::move(__lasti)};
    else if (std::__invoke(__pred,
      std::__invoke(__proj, *__first)))
      ++__first;
    else
      break;
  --__tail;
  for (;;)
    if (__first == __tail)
      return {std::move(__first), std::move(__lasti)};
    else if (!(bool)std::__invoke(__pred,
      std::__invoke(__proj, *__tail)))
      --__tail;
    else
      break;
  ranges::iter_swap(__first, __tail);
  ++__first;
       }
   }
 else
   {
     if (__first == __last)
       return {__first, __first};

     while (std::__invoke(__pred, std::__invoke(__proj, *__first)))
       if (++__first == __last)
  return {__first, __first};

     auto __next = __first;
     while (++__next != __last)
       if (std::__invoke(__pred, std::__invoke(__proj, *__next)))
  {
    ranges::iter_swap(__first, __next);
    ++__first;
  }

     return {std::move(__first), std::move(__next)};
   }
      }

    template<forward_range _Range, typename _Proj = identity,
      indirect_unary_predicate<projected<iterator_t<_Range>, _Proj>>
        _Pred>
      requires permutable<iterator_t<_Range>>
      constexpr borrowed_subrange_t<_Range>
      operator()(_Range&& __r, _Pred __pred, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__pred), std::move(__proj));
      }
  };

  inline constexpr __partition_fn partition{};


  struct __stable_partition_fn
  {
    template<bidirectional_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_unary_predicate<projected<_Iter, _Proj>> _Pred>
      requires permutable<_Iter>
     
      subrange<_Iter>
      operator()(_Iter __first, _Sent __last,
   _Pred __pred, _Proj __proj = {}) const
      {
 auto __lasti = ranges::next(__first, __last);
 auto __middle
   = std::stable_partition(std::move(__first), __lasti,
      __detail::__make_pred_proj(__pred, __proj));
 return {std::move(__middle), std::move(__lasti)};
      }

    template<bidirectional_range _Range, typename _Proj = identity,
      indirect_unary_predicate<projected<iterator_t<_Range>, _Proj>>
        _Pred>
      requires permutable<iterator_t<_Range>>
     
      borrowed_subrange_t<_Range>
      operator()(_Range&& __r, _Pred __pred, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__pred), std::move(__proj));
      }
  };

  inline constexpr __stable_partition_fn stable_partition{};


  template<typename _Iter, typename _Out1, typename _Out2>
    struct in_out_out_result
    {
      [[no_unique_address]] _Iter in;
      [[no_unique_address]] _Out1 out1;
      [[no_unique_address]] _Out2 out2;

      template<typename _IIter, typename _OOut1, typename _OOut2>
 requires convertible_to<const _Iter&, _IIter>
   && convertible_to<const _Out1&, _OOut1>
   && convertible_to<const _Out2&, _OOut2>
 constexpr
 operator in_out_out_result<_IIter, _OOut1, _OOut2>() const &
 { return {in, out1, out2}; }

      template<typename _IIter, typename _OOut1, typename _OOut2>
 requires convertible_to<_Iter, _IIter>
   && convertible_to<_Out1, _OOut1>
   && convertible_to<_Out2, _OOut2>
 constexpr
 operator in_out_out_result<_IIter, _OOut1, _OOut2>() &&
 { return {std::move(in), std::move(out1), std::move(out2)}; }
    };

  template<typename _Iter, typename _Out1, typename _Out2>
    using partition_copy_result = in_out_out_result<_Iter, _Out1, _Out2>;

  struct __partition_copy_fn
  {
    template<input_iterator _Iter, sentinel_for<_Iter> _Sent,
      weakly_incrementable _Out1, weakly_incrementable _Out2,
      typename _Proj = identity,
      indirect_unary_predicate<projected<_Iter, _Proj>> _Pred>
      requires indirectly_copyable<_Iter, _Out1>
 && indirectly_copyable<_Iter, _Out2>
      constexpr partition_copy_result<_Iter, _Out1, _Out2>
      operator()(_Iter __first, _Sent __last,
   _Out1 __out_true, _Out2 __out_false,
   _Pred __pred, _Proj __proj = {}) const
      {
 for (; __first != __last; ++__first)
   if (std::__invoke(__pred, std::__invoke(__proj, *__first)))
     {
       *__out_true = *__first;
       ++__out_true;
     }
   else
     {
       *__out_false = *__first;
       ++__out_false;
     }

 return {std::move(__first),
  std::move(__out_true), std::move(__out_false)};
      }

    template<input_range _Range, weakly_incrementable _Out1,
      weakly_incrementable _Out2,
      typename _Proj = identity,
      indirect_unary_predicate<projected<iterator_t<_Range>, _Proj>>
        _Pred>
      requires indirectly_copyable<iterator_t<_Range>, _Out1>
 && indirectly_copyable<iterator_t<_Range>, _Out2>
      constexpr partition_copy_result<borrowed_iterator_t<_Range>, _Out1, _Out2>
      operator()(_Range&& __r, _Out1 __out_true, _Out2 __out_false,
   _Pred __pred, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__out_true), std::move(__out_false),
         std::move(__pred), std::move(__proj));
      }
  };

  inline constexpr __partition_copy_fn partition_copy{};

  struct __partition_point_fn
  {
    template<forward_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_unary_predicate<projected<_Iter, _Proj>> _Pred>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last,
   _Pred __pred, _Proj __proj = {}) const
      {
 auto __len = ranges::distance(__first, __last);

 while (__len > 0)
   {
     auto __half = __len / 2;
     auto __middle = __first;
     ranges::advance(__middle, __half);
     if (std::__invoke(__pred, std::__invoke(__proj, *__middle)))
       {
  __first = __middle;
  ++__first;
  __len = __len - __half - 1;
       }
     else
       __len = __half;
   }
 return __first;
      }

    template<forward_range _Range, typename _Proj = identity,
      indirect_unary_predicate<projected<iterator_t<_Range>, _Proj>>
        _Pred>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r, _Pred __pred, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__pred), std::move(__proj));
      }
  };

  inline constexpr __partition_point_fn partition_point{};

  template<typename _Iter1, typename _Iter2, typename _Out>
    using merge_result = in_in_out_result<_Iter1, _Iter2, _Out>;

  struct __merge_fn
  {
    template<input_iterator _Iter1, sentinel_for<_Iter1> _Sent1,
      input_iterator _Iter2, sentinel_for<_Iter2> _Sent2,
      weakly_incrementable _Out, typename _Comp = ranges::less,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires mergeable<_Iter1, _Iter2, _Out, _Comp, _Proj1, _Proj2>
      constexpr merge_result<_Iter1, _Iter2, _Out>
      operator()(_Iter1 __first1, _Sent1 __last1,
   _Iter2 __first2, _Sent2 __last2, _Out __result,
   _Comp __comp = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 while (__first1 != __last1 && __first2 != __last2)
   {
     if (std::__invoke(__comp,
         std::__invoke(__proj2, *__first2),
         std::__invoke(__proj1, *__first1)))
       {
  *__result = *__first2;
  ++__first2;
       }
     else
       {
  *__result = *__first1;
  ++__first1;
       }
     ++__result;
   }
 auto __copy1 = ranges::copy(std::move(__first1), std::move(__last1),
        std::move(__result));
 auto __copy2 = ranges::copy(std::move(__first2), std::move(__last2),
        std::move(__copy1.out));
 return { std::move(__copy1.in), std::move(__copy2.in),
   std::move(__copy2.out) };
      }

    template<input_range _Range1, input_range _Range2, weakly_incrementable _Out,
      typename _Comp = ranges::less,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires mergeable<iterator_t<_Range1>, iterator_t<_Range2>, _Out,
    _Comp, _Proj1, _Proj2>
      constexpr merge_result<borrowed_iterator_t<_Range1>,
        borrowed_iterator_t<_Range2>,
        _Out>
      operator()(_Range1&& __r1, _Range2&& __r2, _Out __result,
   _Comp __comp = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 return (*this)(ranges::begin(__r1), ranges::end(__r1),
         ranges::begin(__r2), ranges::end(__r2),
         std::move(__result), std::move(__comp),
         std::move(__proj1), std::move(__proj2));
      }
  };

  inline constexpr __merge_fn merge{};

  struct __inplace_merge_fn
  {
    template<bidirectional_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Comp = ranges::less,
      typename _Proj = identity>
      requires sortable<_Iter, _Comp, _Proj>
     
      _Iter
      operator()(_Iter __first, _Iter __middle, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 auto __lasti = ranges::next(__first, __last);
 std::inplace_merge(std::move(__first), std::move(__middle), __lasti,
      __detail::__make_comp_proj(__comp, __proj));
 return __lasti;
      }

    template<bidirectional_range _Range,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<iterator_t<_Range>, _Comp, _Proj>
     
      borrowed_iterator_t<_Range>
      operator()(_Range&& __r, iterator_t<_Range> __middle,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), std::move(__middle),
         ranges::end(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __inplace_merge_fn inplace_merge{};

  struct __includes_fn
  {
    template<input_iterator _Iter1, sentinel_for<_Iter1> _Sent1,
      input_iterator _Iter2, sentinel_for<_Iter2> _Sent2,
      typename _Proj1 = identity, typename _Proj2 = identity,
      indirect_strict_weak_order<projected<_Iter1, _Proj1>,
     projected<_Iter2, _Proj2>>
        _Comp = ranges::less>
      constexpr bool
      operator()(_Iter1 __first1, _Sent1 __last1,
   _Iter2 __first2, _Sent2 __last2,
   _Comp __comp = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 while (__first1 != __last1 && __first2 != __last2)
   if (std::__invoke(__comp,
       std::__invoke(__proj2, *__first2),
       std::__invoke(__proj1, *__first1)))
     return false;
   else if (std::__invoke(__comp,
     std::__invoke(__proj1, *__first1),
     std::__invoke(__proj2, *__first2)))
     ++__first1;
   else
     {
       ++__first1;
       ++__first2;
     }

 return __first2 == __last2;
      }

    template<input_range _Range1, input_range _Range2,
      typename _Proj1 = identity, typename _Proj2 = identity,
      indirect_strict_weak_order<projected<iterator_t<_Range1>, _Proj1>,
     projected<iterator_t<_Range2>, _Proj2>>
        _Comp = ranges::less>
      constexpr bool
      operator()(_Range1&& __r1, _Range2&& __r2, _Comp __comp = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 return (*this)(ranges::begin(__r1), ranges::end(__r1),
         ranges::begin(__r2), ranges::end(__r2),
         std::move(__comp),
         std::move(__proj1), std::move(__proj2));
      }
  };

  inline constexpr __includes_fn includes{};

  template<typename _Iter1, typename _Iter2, typename _Out>
    using set_union_result = in_in_out_result<_Iter1, _Iter2, _Out>;

  struct __set_union_fn
  {
    template<input_iterator _Iter1, sentinel_for<_Iter1> _Sent1,
      input_iterator _Iter2, sentinel_for<_Iter2> _Sent2,
      weakly_incrementable _Out, typename _Comp = ranges::less,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires mergeable<_Iter1, _Iter2, _Out, _Comp, _Proj1, _Proj2>
      constexpr set_union_result<_Iter1, _Iter2, _Out>
      operator()(_Iter1 __first1, _Sent1 __last1,
   _Iter2 __first2, _Sent2 __last2,
   _Out __result, _Comp __comp = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 while (__first1 != __last1 && __first2 != __last2)
   {
     if (std::__invoke(__comp,
         std::__invoke(__proj1, *__first1),
         std::__invoke(__proj2, *__first2)))
       {
  *__result = *__first1;
  ++__first1;
       }
     else if (std::__invoke(__comp,
       std::__invoke(__proj2, *__first2),
       std::__invoke(__proj1, *__first1)))
       {
  *__result = *__first2;
  ++__first2;
       }
     else
       {
  *__result = *__first1;
  ++__first1;
  ++__first2;
       }
     ++__result;
   }
 auto __copy1 = ranges::copy(std::move(__first1), std::move(__last1),
        std::move(__result));
 auto __copy2 = ranges::copy(std::move(__first2), std::move(__last2),
        std::move(__copy1.out));
 return {std::move(__copy1.in), std::move(__copy2.in),
  std::move(__copy2.out)};
      }

    template<input_range _Range1, input_range _Range2, weakly_incrementable _Out,
      typename _Comp = ranges::less,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires mergeable<iterator_t<_Range1>, iterator_t<_Range2>, _Out,
    _Comp, _Proj1, _Proj2>
      constexpr set_union_result<borrowed_iterator_t<_Range1>,
     borrowed_iterator_t<_Range2>, _Out>
      operator()(_Range1&& __r1, _Range2&& __r2,
   _Out __result, _Comp __comp = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 return (*this)(ranges::begin(__r1), ranges::end(__r1),
         ranges::begin(__r2), ranges::end(__r2),
         std::move(__result), std::move(__comp),
         std::move(__proj1), std::move(__proj2));
      }
  };

  inline constexpr __set_union_fn set_union{};

  template<typename _Iter1, typename _Iter2, typename _Out>
    using set_intersection_result = in_in_out_result<_Iter1, _Iter2, _Out>;

  struct __set_intersection_fn
  {
    template<input_iterator _Iter1, sentinel_for<_Iter1> _Sent1,
      input_iterator _Iter2, sentinel_for<_Iter2> _Sent2,
      weakly_incrementable _Out, typename _Comp = ranges::less,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires mergeable<_Iter1, _Iter2, _Out, _Comp, _Proj1, _Proj2>
      constexpr set_intersection_result<_Iter1, _Iter2, _Out>
      operator()(_Iter1 __first1, _Sent1 __last1,
   _Iter2 __first2, _Sent2 __last2, _Out __result,
   _Comp __comp = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 while (__first1 != __last1 && __first2 != __last2)
   if (std::__invoke(__comp,
       std::__invoke(__proj1, *__first1),
       std::__invoke(__proj2, *__first2)))
     ++__first1;
   else if (std::__invoke(__comp,
     std::__invoke(__proj2, *__first2),
     std::__invoke(__proj1, *__first1)))
     ++__first2;
   else
     {
       *__result = *__first1;
       ++__first1;
       ++__first2;
       ++__result;
     }

 auto __last1i = ranges::next(std::move(__first1), std::move(__last1));
 auto __last2i = ranges::next(std::move(__first2), std::move(__last2));
 return {std::move(__last1i), std::move(__last2i), std::move(__result)};
      }

    template<input_range _Range1, input_range _Range2, weakly_incrementable _Out,
      typename _Comp = ranges::less,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires mergeable<iterator_t<_Range1>, iterator_t<_Range2>, _Out,
    _Comp, _Proj1, _Proj2>
      constexpr set_intersection_result<borrowed_iterator_t<_Range1>,
     borrowed_iterator_t<_Range2>, _Out>
      operator()(_Range1&& __r1, _Range2&& __r2, _Out __result,
   _Comp __comp = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 return (*this)(ranges::begin(__r1), ranges::end(__r1),
         ranges::begin(__r2), ranges::end(__r2),
         std::move(__result), std::move(__comp),
         std::move(__proj1), std::move(__proj2));
      }
  };

  inline constexpr __set_intersection_fn set_intersection{};

  template<typename _Iter, typename _Out>
    using set_difference_result = in_out_result<_Iter, _Out>;

  struct __set_difference_fn
  {
    template<input_iterator _Iter1, sentinel_for<_Iter1> _Sent1,
      input_iterator _Iter2, sentinel_for<_Iter2> _Sent2,
      weakly_incrementable _Out, typename _Comp = ranges::less,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires mergeable<_Iter1, _Iter2, _Out, _Comp, _Proj1, _Proj2>
      constexpr set_difference_result<_Iter1, _Out>
      operator()(_Iter1 __first1, _Sent1 __last1,
   _Iter2 __first2, _Sent2 __last2, _Out __result,
   _Comp __comp = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 while (__first1 != __last1 && __first2 != __last2)
   if (std::__invoke(__comp,
       std::__invoke(__proj1, *__first1),
       std::__invoke(__proj2, *__first2)))
     {
       *__result = *__first1;
       ++__first1;
       ++__result;
     }
   else if (std::__invoke(__comp,
     std::__invoke(__proj2, *__first2),
     std::__invoke(__proj1, *__first1)))
     ++__first2;
   else
     {
       ++__first1;
       ++__first2;
     }
 return ranges::copy(std::move(__first1), std::move(__last1),
       std::move(__result));
      }

    template<input_range _Range1, input_range _Range2, weakly_incrementable _Out,
      typename _Comp = ranges::less,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires mergeable<iterator_t<_Range1>, iterator_t<_Range2>, _Out,
    _Comp, _Proj1, _Proj2>
      constexpr set_difference_result<borrowed_iterator_t<_Range1>, _Out>
      operator()(_Range1&& __r1, _Range2&& __r2, _Out __result,
   _Comp __comp = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 return (*this)(ranges::begin(__r1), ranges::end(__r1),
         ranges::begin(__r2), ranges::end(__r2),
         std::move(__result), std::move(__comp),
         std::move(__proj1), std::move(__proj2));
      }
  };

  inline constexpr __set_difference_fn set_difference{};

  template<typename _Iter1, typename _Iter2, typename _Out>
    using set_symmetric_difference_result
      = in_in_out_result<_Iter1, _Iter2, _Out>;

  struct __set_symmetric_difference_fn
  {
    template<input_iterator _Iter1, sentinel_for<_Iter1> _Sent1,
      input_iterator _Iter2, sentinel_for<_Iter2> _Sent2,
      weakly_incrementable _Out, typename _Comp = ranges::less,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires mergeable<_Iter1, _Iter2, _Out, _Comp, _Proj1, _Proj2>
      constexpr set_symmetric_difference_result<_Iter1, _Iter2, _Out>
      operator()(_Iter1 __first1, _Sent1 __last1,
   _Iter2 __first2, _Sent2 __last2,
   _Out __result, _Comp __comp = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 while (__first1 != __last1 && __first2 != __last2)
   if (std::__invoke(__comp,
       std::__invoke(__proj1, *__first1),
       std::__invoke(__proj2, *__first2)))
     {
       *__result = *__first1;
       ++__first1;
       ++__result;
     }
   else if (std::__invoke(__comp,
     std::__invoke(__proj2, *__first2),
     std::__invoke(__proj1, *__first1)))
     {
       *__result = *__first2;
       ++__first2;
       ++__result;
     }
   else
     {
       ++__first1;
       ++__first2;
     }
 auto __copy1 = ranges::copy(std::move(__first1), std::move(__last1),
        std::move(__result));
 auto __copy2 = ranges::copy(std::move(__first2), std::move(__last2),
        std::move(__copy1.out));
 return {std::move(__copy1.in), std::move(__copy2.in),
  std::move(__copy2.out)};
      }

    template<input_range _Range1, input_range _Range2, weakly_incrementable _Out,
      typename _Comp = ranges::less,
      typename _Proj1 = identity, typename _Proj2 = identity>
      requires mergeable<iterator_t<_Range1>, iterator_t<_Range2>, _Out,
    _Comp, _Proj1, _Proj2>
      constexpr set_symmetric_difference_result<borrowed_iterator_t<_Range1>,
      borrowed_iterator_t<_Range2>,
      _Out>
      operator()(_Range1&& __r1, _Range2&& __r2, _Out __result,
   _Comp __comp = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 return (*this)(ranges::begin(__r1), ranges::end(__r1),
         ranges::begin(__r2), ranges::end(__r2),
         std::move(__result), std::move(__comp),
         std::move(__proj1), std::move(__proj2));
      }
  };

  inline constexpr __set_symmetric_difference_fn set_symmetric_difference{};



  struct __max_fn
  {
    template<typename _Tp, typename _Proj = identity,
      indirect_strict_weak_order<projected<const _Tp*, _Proj>>
        _Comp = ranges::less>
      constexpr const _Tp&
      operator()(const _Tp& __a, const _Tp& __b,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 if (std::__invoke(__comp,
     std::__invoke(__proj, __a),
     std::__invoke(__proj, __b)))
   return __b;
 else
   return __a;
      }

    template<input_range _Range, typename _Proj = identity,
      indirect_strict_weak_order<projected<iterator_t<_Range>, _Proj>>
        _Comp = ranges::less>
      requires indirectly_copyable_storable<iterator_t<_Range>,
         range_value_t<_Range>*>
      constexpr range_value_t<_Range>
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 auto __first = ranges::begin(__r);
 auto __last = ranges::end(__r);
 do { if (__builtin_expect(!bool(__first != __last), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_algo.h", 2960, __PRETTY_FUNCTION__, "__first != __last"); } while (false);
 auto __result = *__first;
 while (++__first != __last)
   {
     auto&& __tmp = *__first;
     if (std::__invoke(__comp,
         std::__invoke(__proj, __result),
         std::__invoke(__proj, __tmp)))
       __result = std::forward<decltype(__tmp)>(__tmp);
   }
 return __result;
      }

    template<copyable _Tp, typename _Proj = identity,
      indirect_strict_weak_order<projected<const _Tp*, _Proj>>
        _Comp = ranges::less>
      constexpr _Tp
      operator()(initializer_list<_Tp> __r,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::subrange(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __max_fn max{};

  struct __clamp_fn
  {
    template<typename _Tp, typename _Proj = identity,
      indirect_strict_weak_order<projected<const _Tp*, _Proj>> _Comp
        = ranges::less>
      constexpr const _Tp&
      operator()(const _Tp& __val, const _Tp& __lo, const _Tp& __hi,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 do { if (__builtin_expect(!bool(!(std::__invoke(__comp, std::__invoke(__proj, __hi), std::__invoke(__proj, __lo)))), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_algo.h", 2996, __PRETTY_FUNCTION__, "!(std::__invoke(__comp, std::__invoke(__proj, __hi), std::__invoke(__proj, __lo)))"); } while (false)

                                    ;
 auto&& __proj_val = std::__invoke(__proj, __val);
 if (std::__invoke(__comp,
     std::forward<decltype(__proj_val)>(__proj_val),
     std::__invoke(__proj, __lo)))
   return __lo;
 else if (std::__invoke(__comp,
          std::__invoke(__proj, __hi),
          std::forward<decltype(__proj_val)>(__proj_val)))
   return __hi;
 else
   return __val;
      }
  };

  inline constexpr __clamp_fn clamp{};

  template<typename _Tp>
    struct min_max_result
    {
      [[no_unique_address]] _Tp min;
      [[no_unique_address]] _Tp max;

      template<typename _Tp2>
 requires convertible_to<const _Tp&, _Tp2>
 constexpr
 operator min_max_result<_Tp2>() const &
 { return {min, max}; }

      template<typename _Tp2>
 requires convertible_to<_Tp, _Tp2>
 constexpr
 operator min_max_result<_Tp2>() &&
 { return {std::move(min), std::move(max)}; }
    };

  template<typename _Tp>
    using minmax_result = min_max_result<_Tp>;

  struct __minmax_fn
  {
    template<typename _Tp, typename _Proj = identity,
      indirect_strict_weak_order<projected<const _Tp*, _Proj>>
        _Comp = ranges::less>
      constexpr minmax_result<const _Tp&>
      operator()(const _Tp& __a, const _Tp& __b,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 if (std::__invoke(__comp,
     std::__invoke(__proj, __b),
     std::__invoke(__proj, __a)))
   return {__b, __a};
 else
   return {__a, __b};
      }

    template<input_range _Range, typename _Proj = identity,
      indirect_strict_weak_order<projected<iterator_t<_Range>, _Proj>>
        _Comp = ranges::less>
      requires indirectly_copyable_storable<iterator_t<_Range>, range_value_t<_Range>*>
      constexpr minmax_result<range_value_t<_Range>>
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 auto __first = ranges::begin(__r);
 auto __last = ranges::end(__r);
 do { if (__builtin_expect(!bool(__first != __last), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_algo.h", 3063, __PRETTY_FUNCTION__, "__first != __last"); } while (false);
 auto __comp_proj = __detail::__make_comp_proj(__comp, __proj);
 minmax_result<range_value_t<_Range>> __result = {*__first, __result.min};
 if (++__first == __last)
   return __result;
 else
   {


     auto&& __val = *__first;
     if (__comp_proj(__val, __result.min))
       __result.min = std::forward<decltype(__val)>(__val);
     else
       __result.max = std::forward<decltype(__val)>(__val);
   }
 while (++__first != __last)
   {



     range_value_t<_Range> __val1 = *__first;
     if (++__first == __last)
       {



  if (__comp_proj(__val1, __result.min))
    __result.min = std::move(__val1);
  else if (!__comp_proj(__val1, __result.max))
    __result.max = std::move(__val1);
  break;
       }
     auto&& __val2 = *__first;
     if (!__comp_proj(__val2, __val1))
       {
  if (__comp_proj(__val1, __result.min))
    __result.min = std::move(__val1);
  if (!__comp_proj(__val2, __result.max))
    __result.max = std::forward<decltype(__val2)>(__val2);
       }
     else
       {
  if (__comp_proj(__val2, __result.min))
    __result.min = std::forward<decltype(__val2)>(__val2);
  if (!__comp_proj(__val1, __result.max))
    __result.max = std::move(__val1);
       }
   }
 return __result;
      }

    template<copyable _Tp, typename _Proj = identity,
      indirect_strict_weak_order<projected<const _Tp*, _Proj>>
        _Comp = ranges::less>
      constexpr minmax_result<_Tp>
      operator()(initializer_list<_Tp> __r,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::subrange(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __minmax_fn minmax{};

  struct __min_element_fn
  {
    template<forward_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_strict_weak_order<projected<_Iter, _Proj>>
        _Comp = ranges::less>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 if (__first == __last)
   return __first;

 auto __i = __first;
 while (++__i != __last)
   {
     if (std::__invoke(__comp,
         std::__invoke(__proj, *__i),
         std::__invoke(__proj, *__first)))
       __first = __i;
   }
 return __first;
      }

    template<forward_range _Range, typename _Proj = identity,
      indirect_strict_weak_order<projected<iterator_t<_Range>, _Proj>>
        _Comp = ranges::less>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __min_element_fn min_element{};

  struct __max_element_fn
  {
    template<forward_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_strict_weak_order<projected<_Iter, _Proj>>
        _Comp = ranges::less>
      constexpr _Iter
      operator()(_Iter __first, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 if (__first == __last)
   return __first;

 auto __i = __first;
 while (++__i != __last)
   {
     if (std::__invoke(__comp,
         std::__invoke(__proj, *__first),
         std::__invoke(__proj, *__i)))
       __first = __i;
   }
 return __first;
      }

    template<forward_range _Range, typename _Proj = identity,
      indirect_strict_weak_order<projected<iterator_t<_Range>, _Proj>>
        _Comp = ranges::less>
      constexpr borrowed_iterator_t<_Range>
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __max_element_fn max_element{};

  template<typename _Iter>
    using minmax_element_result = min_max_result<_Iter>;

  struct __minmax_element_fn
  {
    template<forward_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Proj = identity,
      indirect_strict_weak_order<projected<_Iter, _Proj>>
        _Comp = ranges::less>
      constexpr minmax_element_result<_Iter>
      operator()(_Iter __first, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 auto __comp_proj = __detail::__make_comp_proj(__comp, __proj);
 minmax_element_result<_Iter> __result = {__first, __first};
 if (__first == __last || ++__first == __last)
   return __result;
 else
   {


     if (__comp_proj(*__first, *__result.min))
       __result.min = __first;
     else
       __result.max = __first;
   }
 while (++__first != __last)
   {



     auto __prev = __first;
     if (++__first == __last)
       {



  if (__comp_proj(*__prev, *__result.min))
    __result.min = __prev;
  else if (!__comp_proj(*__prev, *__result.max))
    __result.max = __prev;
  break;
       }
     if (!__comp_proj(*__first, *__prev))
       {
  if (__comp_proj(*__prev, *__result.min))
    __result.min = __prev;
  if (!__comp_proj(*__first, *__result.max))
    __result.max = __first;
       }
     else
       {
  if (__comp_proj(*__first, *__result.min))
    __result.min = __first;
  if (!__comp_proj(*__prev, *__result.max))
    __result.max = __prev;
       }
   }
 return __result;
      }

    template<forward_range _Range, typename _Proj = identity,
      indirect_strict_weak_order<projected<iterator_t<_Range>, _Proj>>
        _Comp = ranges::less>
      constexpr minmax_element_result<borrowed_iterator_t<_Range>>
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __minmax_element_fn minmax_element{};

  struct __lexicographical_compare_fn
  {
    template<input_iterator _Iter1, sentinel_for<_Iter1> _Sent1,
      input_iterator _Iter2, sentinel_for<_Iter2> _Sent2,
      typename _Proj1 = identity, typename _Proj2 = identity,
      indirect_strict_weak_order<projected<_Iter1, _Proj1>,
     projected<_Iter2, _Proj2>>
        _Comp = ranges::less>
      constexpr bool
      operator()(_Iter1 __first1, _Sent1 __last1,
   _Iter2 __first2, _Sent2 __last2,
   _Comp __comp = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 if constexpr (__detail::__is_normal_iterator<_Iter1>
        && same_as<_Iter1, _Sent1>)
   return (*this)(__first1.base(), __last1.base(),
    std::move(__first2), std::move(__last2),
    std::move(__comp),
    std::move(__proj1), std::move(__proj2));
 else if constexpr (__detail::__is_normal_iterator<_Iter2>
      && same_as<_Iter2, _Sent2>)
   return (*this)(std::move(__first1), std::move(__last1),
    __first2.base(), __last2.base(),
    std::move(__comp),
    std::move(__proj1), std::move(__proj2));
 else
   {
     constexpr bool __sized_iters
       = (sized_sentinel_for<_Sent1, _Iter1>
   && sized_sentinel_for<_Sent2, _Iter2>);
     if constexpr (__sized_iters)
       {
  using _ValueType1 = iter_value_t<_Iter1>;
  using _ValueType2 = iter_value_t<_Iter2>;


  constexpr bool __use_memcmp
    = (__is_memcmp_ordered_with<_ValueType1, _ValueType2>::__value
       && __ptr_to_nonvolatile<_Iter1>
       && __ptr_to_nonvolatile<_Iter2>
       && (is_same_v<_Comp, ranges::less>
    || is_same_v<_Comp, ranges::greater>)
       && is_same_v<_Proj1, identity>
       && is_same_v<_Proj2, identity>);
  if constexpr (__use_memcmp)
    {
      const auto __d1 = __last1 - __first1;
      const auto __d2 = __last2 - __first2;

      if (const auto __len = std::min(__d1, __d2))
        {
   const auto __c
     = std::__memcmp(__first1, __first2, __len);
   if constexpr (is_same_v<_Comp, ranges::less>)
     {
       if (__c < 0)
         return true;
       if (__c > 0)
         return false;
     }
   else if constexpr (is_same_v<_Comp, ranges::greater>)
     {
       if (__c > 0)
         return true;
       if (__c < 0)
         return false;
     }
        }
      return __d1 < __d2;
    }
       }

     for (; __first1 != __last1 && __first2 != __last2;
   ++__first1, (void) ++__first2)
       {
  if (std::__invoke(__comp,
      std::__invoke(__proj1, *__first1),
      std::__invoke(__proj2, *__first2)))
    return true;
  if (std::__invoke(__comp,
      std::__invoke(__proj2, *__first2),
      std::__invoke(__proj1, *__first1)))
    return false;
       }
     return __first1 == __last1 && __first2 != __last2;
   }
      }

    template<input_range _Range1, input_range _Range2,
      typename _Proj1 = identity, typename _Proj2 = identity,
      indirect_strict_weak_order<projected<iterator_t<_Range1>, _Proj1>,
     projected<iterator_t<_Range2>, _Proj2>>
        _Comp = ranges::less>
      constexpr bool
      operator()(_Range1&& __r1, _Range2&& __r2, _Comp __comp = {},
   _Proj1 __proj1 = {}, _Proj2 __proj2 = {}) const
      {
 return (*this)(ranges::begin(__r1), ranges::end(__r1),
         ranges::begin(__r2), ranges::end(__r2),
         std::move(__comp),
         std::move(__proj1), std::move(__proj2));
      }

  private:
    template<typename _Iter, typename _Ref = iter_reference_t<_Iter>>
      static constexpr bool __ptr_to_nonvolatile
 = is_pointer_v<_Iter> && !is_volatile_v<remove_reference_t<_Ref>>;
  };

  inline constexpr __lexicographical_compare_fn lexicographical_compare;

  template<typename _Iter>
    struct in_found_result
    {
      [[no_unique_address]] _Iter in;
      bool found;

      template<typename _Iter2>
 requires convertible_to<const _Iter&, _Iter2>
 constexpr
 operator in_found_result<_Iter2>() const &
 { return {in, found}; }

      template<typename _Iter2>
 requires convertible_to<_Iter, _Iter2>
 constexpr
 operator in_found_result<_Iter2>() &&
 { return {std::move(in), found}; }
    };

  template<typename _Iter>
    using next_permutation_result = in_found_result<_Iter>;

  struct __next_permutation_fn
  {
    template<bidirectional_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<_Iter, _Comp, _Proj>
      constexpr next_permutation_result<_Iter>
      operator()(_Iter __first, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 if (__first == __last)
   return {std::move(__first), false};

 auto __i = __first;
 ++__i;
 if (__i == __last)
   return {std::move(__i), false};

 auto __lasti = ranges::next(__first, __last);
 __i = __lasti;
 --__i;

 for (;;)
   {
     auto __ii = __i;
     --__i;
     if (std::__invoke(__comp,
         std::__invoke(__proj, *__i),
         std::__invoke(__proj, *__ii)))
       {
  auto __j = __lasti;
  while (!(bool)std::__invoke(__comp,
         std::__invoke(__proj, *__i),
         std::__invoke(__proj, *--__j)))
    ;
  ranges::iter_swap(__i, __j);
  ranges::reverse(__ii, __last);
  return {std::move(__lasti), true};
       }
     if (__i == __first)
       {
  ranges::reverse(__first, __last);
  return {std::move(__lasti), false};
       }
   }
      }

    template<bidirectional_range _Range, typename _Comp = ranges::less,
      typename _Proj = identity>
      requires sortable<iterator_t<_Range>, _Comp, _Proj>
      constexpr next_permutation_result<borrowed_iterator_t<_Range>>
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __next_permutation_fn next_permutation{};

  template<typename _Iter>
    using prev_permutation_result = in_found_result<_Iter>;

  struct __prev_permutation_fn
  {
    template<bidirectional_iterator _Iter, sentinel_for<_Iter> _Sent,
      typename _Comp = ranges::less, typename _Proj = identity>
      requires sortable<_Iter, _Comp, _Proj>
      constexpr prev_permutation_result<_Iter>
      operator()(_Iter __first, _Sent __last,
   _Comp __comp = {}, _Proj __proj = {}) const
      {
 if (__first == __last)
   return {std::move(__first), false};

 auto __i = __first;
 ++__i;
 if (__i == __last)
   return {std::move(__i), false};

 auto __lasti = ranges::next(__first, __last);
 __i = __lasti;
 --__i;

 for (;;)
   {
     auto __ii = __i;
     --__i;
     if (std::__invoke(__comp,
         std::__invoke(__proj, *__ii),
         std::__invoke(__proj, *__i)))
       {
  auto __j = __lasti;
  while (!(bool)std::__invoke(__comp,
         std::__invoke(__proj, *--__j),
         std::__invoke(__proj, *__i)))
    ;
  ranges::iter_swap(__i, __j);
  ranges::reverse(__ii, __last);
  return {std::move(__lasti), true};
       }
     if (__i == __first)
       {
  ranges::reverse(__first, __last);
  return {std::move(__lasti), false};
       }
   }
      }

    template<bidirectional_range _Range, typename _Comp = ranges::less,
      typename _Proj = identity>
      requires sortable<iterator_t<_Range>, _Comp, _Proj>
      constexpr prev_permutation_result<borrowed_iterator_t<_Range>>
      operator()(_Range&& __r, _Comp __comp = {}, _Proj __proj = {}) const
      {
 return (*this)(ranges::begin(__r), ranges::end(__r),
         std::move(__comp), std::move(__proj));
      }
  };

  inline constexpr __prev_permutation_fn prev_permutation{};
# 3979 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_algo.h" 3
}

  template<typename _ForwardIterator>
    constexpr _ForwardIterator
    shift_left(_ForwardIterator __first, _ForwardIterator __last,
        typename iterator_traits<_ForwardIterator>::difference_type __n)
    {
      do { if (__builtin_expect(!bool(__n >= 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_algo.h", 3986, __PRETTY_FUNCTION__, "__n >= 0"); } while (false);
      if (__n == 0)
 return __last;

      auto __mid = ranges::next(__first, __n, __last);
      if (__mid == __last)
 return __first;
      return std::move(std::move(__mid), std::move(__last), std::move(__first));
    }

  template<typename _ForwardIterator>
    constexpr _ForwardIterator
    shift_right(_ForwardIterator __first, _ForwardIterator __last,
  typename iterator_traits<_ForwardIterator>::difference_type __n)
    {
      do { if (__builtin_expect(!bool(__n >= 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_algo.h", 4001, __PRETTY_FUNCTION__, "__n >= 0"); } while (false);
      if (__n == 0)
 return __first;

      using _Cat
 = typename iterator_traits<_ForwardIterator>::iterator_category;
      if constexpr (derived_from<_Cat, bidirectional_iterator_tag>)
 {
   auto __mid = ranges::next(__last, -__n, __first);
   if (__mid == __first)
     return __last;

   return std::move_backward(std::move(__first), std::move(__mid),
        std::move(__last));
 }
      else
 {
   auto __result = ranges::next(__first, __n, __last);
   if (__result == __last)
     return __last;

   auto __dest_head = __first, __dest_tail = __result;
   while (__dest_head != __result)
     {
       if (__dest_tail == __last)
  {





    std::move(std::move(__first), std::move(__dest_head), __result);
    return __result;
  }
       ++__dest_head;
       ++__dest_tail;
     }

   for (;;)
     {
# 4049 "C:/msys64/mingw64/include/c++/15.2.0/bits/ranges_algo.h" 3
       auto __cursor = __first;
       while (__cursor != __result)
  {
    if (__dest_tail == __last)
      {



        __dest_head = std::move(__cursor, __result,
           std::move(__dest_head));
        std::move(std::move(__first), std::move(__cursor),
    std::move(__dest_head));
        return __result;
      }
    std::iter_swap(__cursor, __dest_head);
    ++__dest_head;
    ++__dest_tail;
    ++__cursor;
  }
     }
 }
    }


}
# 66 "C:/msys64/mingw64/include/c++/15.2.0/algorithm" 2 3
# 80 "C:/msys64/mingw64/include/c++/15.2.0/algorithm" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 81 "C:/msys64/mingw64/include/c++/15.2.0/algorithm" 2 3
# 89 "C:/msys64/mingw64/include/c++/15.2.0/algorithm" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/pstl/glue_algorithm_defs.h" 1 3
# 16 "C:/msys64/mingw64/include/c++/15.2.0/pstl/glue_algorithm_defs.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/pstl/execution_defs.h" 1 3
# 15 "C:/msys64/mingw64/include/c++/15.2.0/pstl/execution_defs.h" 3
namespace __pstl
{
namespace execution
{
inline namespace v1
{


class sequenced_policy
{
};


class parallel_policy
{
};


class parallel_unsequenced_policy
{
};

class unsequenced_policy
{
};


inline constexpr sequenced_policy seq{};
inline constexpr parallel_policy par{};
inline constexpr parallel_unsequenced_policy par_unseq{};
inline constexpr unsequenced_policy unseq{};


template <class _Tp>
struct is_execution_policy : std::false_type
{
};

template <>
struct is_execution_policy<__pstl::execution::sequenced_policy> : std::true_type
{
};
template <>
struct is_execution_policy<__pstl::execution::parallel_policy> : std::true_type
{
};
template <>
struct is_execution_policy<__pstl::execution::parallel_unsequenced_policy> : std::true_type
{
};
template <>
struct is_execution_policy<__pstl::execution::unsequenced_policy> : std::true_type
{
};


template <class _Tp>
constexpr bool is_execution_policy_v = __pstl::execution::is_execution_policy<_Tp>::value;


}
}

namespace __internal
{
template <class _ExecPolicy, class _Tp>

using __enable_if_execution_policy =
    typename std::enable_if<__pstl::execution::is_execution_policy<std::__remove_cvref_t<_ExecPolicy>>::value,
                            _Tp>::type;






template <class _IsVector>
struct __serial_tag;
template <class _IsVector>
struct __parallel_tag;

}

}
# 17 "C:/msys64/mingw64/include/c++/15.2.0/pstl/glue_algorithm_defs.h" 2 3

namespace std
{



template <class _ExecutionPolicy, class _ForwardIterator, class _Predicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, bool>
any_of(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _Predicate __pred);



template <class _ExecutionPolicy, class _ForwardIterator, class _Predicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, bool>
all_of(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _Predicate __pred);



template <class _ExecutionPolicy, class _ForwardIterator, class _Predicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, bool>
none_of(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _Predicate __pred);



template <class _ExecutionPolicy, class _ForwardIterator, class _Function>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, void>
for_each(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _Function __f);

template <class _ExecutionPolicy, class _ForwardIterator, class _Size, class _Function>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
for_each_n(_ExecutionPolicy&& __exec, _ForwardIterator __first, _Size __n, _Function __f);



template <class _ExecutionPolicy, class _ForwardIterator, class _Predicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
find_if(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _Predicate __pred);

template <class _ExecutionPolicy, class _ForwardIterator, class _Predicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
find_if_not(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _Predicate __pred);

template <class _ExecutionPolicy, class _ForwardIterator, class _Tp >
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
find(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, const _Tp& __value);



template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _BinaryPredicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator1>
find_end(_ExecutionPolicy&& __exec, _ForwardIterator1 __first, _ForwardIterator1 __last, _ForwardIterator2 __s_first,
         _ForwardIterator2 __s_last, _BinaryPredicate __pred);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator1>
find_end(_ExecutionPolicy&& __exec, _ForwardIterator1 __first, _ForwardIterator1 __last, _ForwardIterator2 __s_first,
         _ForwardIterator2 __s_last);



template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _BinaryPredicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator1>
find_first_of(_ExecutionPolicy&& __exec, _ForwardIterator1 __first, _ForwardIterator1 __last,
              _ForwardIterator2 __s_first, _ForwardIterator2 __s_last, _BinaryPredicate __pred);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator1>
find_first_of(_ExecutionPolicy&& __exec, _ForwardIterator1 __first, _ForwardIterator1 __last,
              _ForwardIterator2 __s_first, _ForwardIterator2 __s_last);



template <class _ExecutionPolicy, class _ForwardIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
adjacent_find(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last);

template <class _ExecutionPolicy, class _ForwardIterator, class _BinaryPredicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
adjacent_find(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _BinaryPredicate __pred);



template <class _ExecutionPolicy, class _ForwardIterator, class _Tp >
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy,
                                                 typename iterator_traits<_ForwardIterator>::difference_type>
count(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, const _Tp& __value);

template <class _ExecutionPolicy, class _ForwardIterator, class _Predicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy,
                                                 typename iterator_traits<_ForwardIterator>::difference_type>
count_if(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _Predicate __pred);



template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _BinaryPredicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator1>
search(_ExecutionPolicy&& __exec, _ForwardIterator1 __first, _ForwardIterator1 __last, _ForwardIterator2 __s_first,
       _ForwardIterator2 __s_last, _BinaryPredicate __pred);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator1>
search(_ExecutionPolicy&& __exec, _ForwardIterator1 __first, _ForwardIterator1 __last, _ForwardIterator2 __s_first,
       _ForwardIterator2 __s_last);

template <class _ExecutionPolicy, class _ForwardIterator, class _Size, class _Tp , class _BinaryPredicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
search_n(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _Size __count,
         const _Tp& __value, _BinaryPredicate __pred);

template <class _ExecutionPolicy, class _ForwardIterator, class _Size, class _Tp >
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
search_n(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _Size __count,
         const _Tp& __value);



template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator2>
copy(_ExecutionPolicy&& __exec, _ForwardIterator1 __first, _ForwardIterator1 __last, _ForwardIterator2 __result);

template <class _ExecutionPolicy, class _ForwardIterator1, class _Size, class _ForwardIterator2>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator2>
copy_n(_ExecutionPolicy&& __exec, _ForwardIterator1 __first, _Size __n, _ForwardIterator2 __result);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _Predicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator2>
copy_if(_ExecutionPolicy&& __exec, _ForwardIterator1 __first, _ForwardIterator1 __last, _ForwardIterator2 result,
        _Predicate __pred);



template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator2>
swap_ranges(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1,
            _ForwardIterator2 __first2);



template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _UnaryOperation>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator2>
transform(_ExecutionPolicy&& __exec, _ForwardIterator1 __first, _ForwardIterator1 __last, _ForwardIterator2 __result,
          _UnaryOperation __op);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _ForwardIterator,
          class _BinaryOperation>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
transform(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1, _ForwardIterator2 __first2,
          _ForwardIterator __result, _BinaryOperation __op);



template <class _ExecutionPolicy, class _ForwardIterator, class _UnaryPredicate, class _Tp >
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, void>
replace_if(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _UnaryPredicate __pred,
           const _Tp& __new_value);

template <class _ExecutionPolicy, class _ForwardIterator, class _Tp >
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, void>
replace(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, const _Tp& __old_value,
        const _Tp& __new_value);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _UnaryPredicate, class _Tp >
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator2>
replace_copy_if(_ExecutionPolicy&& __exec, _ForwardIterator1 __first, _ForwardIterator1 __last,
                _ForwardIterator2 __result, _UnaryPredicate __pred, const _Tp& __new_value);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _Tp>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator2>
replace_copy(_ExecutionPolicy&& __exec, _ForwardIterator1 __first, _ForwardIterator1 __last, _ForwardIterator2 __result,
             const _Tp& __old_value, const _Tp& __new_value);



template <class _ExecutionPolicy, class _ForwardIterator, class _Tp >
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, void>
fill(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, const _Tp& __value);

template <class _ExecutionPolicy, class _ForwardIterator, class _Size, class _Tp >
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
fill_n(_ExecutionPolicy&& __exec, _ForwardIterator __first, _Size __count, const _Tp& __value);


template <class _ExecutionPolicy, class _ForwardIterator, class _Generator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, void>
generate(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _Generator __g);

template <class _ExecutionPolicy, class _ForwardIterator, class _Size, class _Generator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
generate_n(_ExecutionPolicy&& __exec, _ForwardIterator __first, _Size count, _Generator __g);



template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _Predicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator2>
remove_copy_if(_ExecutionPolicy&& __exec, _ForwardIterator1 __first, _ForwardIterator1 __last,
               _ForwardIterator2 __result, _Predicate __pred);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _Tp >
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator2>
remove_copy(_ExecutionPolicy&& __exec, _ForwardIterator1 __first, _ForwardIterator1 __last, _ForwardIterator2 __result,
            const _Tp& __value);

template <class _ExecutionPolicy, class _ForwardIterator, class _UnaryPredicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
remove_if(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _UnaryPredicate __pred);

template <class _ExecutionPolicy, class _ForwardIterator, class _Tp >
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
remove(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, const _Tp& __value);



template <class _ExecutionPolicy, class _ForwardIterator, class _BinaryPredicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
unique(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _BinaryPredicate __pred);

template <class _ExecutionPolicy, class _ForwardIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
unique(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _BinaryPredicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator2>
unique_copy(_ExecutionPolicy&& __exec, _ForwardIterator1 __first, _ForwardIterator1 __last, _ForwardIterator2 __result,
            _BinaryPredicate __pred);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator2>
unique_copy(_ExecutionPolicy&& __exec, _ForwardIterator1 __first, _ForwardIterator1 __last, _ForwardIterator2 __result);



template <class _ExecutionPolicy, class _BidirectionalIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, void>
reverse(_ExecutionPolicy&& __exec, _BidirectionalIterator __first, _BidirectionalIterator __last);

template <class _ExecutionPolicy, class _BidirectionalIterator, class _ForwardIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
reverse_copy(_ExecutionPolicy&& __exec, _BidirectionalIterator __first, _BidirectionalIterator __last,
             _ForwardIterator __d_first);



template <class _ExecutionPolicy, class _ForwardIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
rotate(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __middle, _ForwardIterator __last);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator2>
rotate_copy(_ExecutionPolicy&& __exec, _ForwardIterator1 __first, _ForwardIterator1 __middle, _ForwardIterator1 __last,
            _ForwardIterator2 __result);



template <class _ExecutionPolicy, class _ForwardIterator, class _UnaryPredicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, bool>
is_partitioned(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _UnaryPredicate __pred);

template <class _ExecutionPolicy, class _ForwardIterator, class _UnaryPredicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
partition(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _UnaryPredicate __pred);

template <class _ExecutionPolicy, class _BidirectionalIterator, class _UnaryPredicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _BidirectionalIterator>
stable_partition(_ExecutionPolicy&& __exec, _BidirectionalIterator __first, _BidirectionalIterator __last,
                 _UnaryPredicate __pred);

template <class _ExecutionPolicy, class _ForwardIterator, class _ForwardIterator1, class _ForwardIterator2,
          class _UnaryPredicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, std::pair<_ForwardIterator1, _ForwardIterator2>>
partition_copy(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last,
               _ForwardIterator1 __out_true, _ForwardIterator2 __out_false, _UnaryPredicate __pred);



template <class _ExecutionPolicy, class _RandomAccessIterator, class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, void>
sort(_ExecutionPolicy&& __exec, _RandomAccessIterator __first, _RandomAccessIterator __last, _Compare __comp);

template <class _ExecutionPolicy, class _RandomAccessIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, void>
sort(_ExecutionPolicy&& __exec, _RandomAccessIterator __first, _RandomAccessIterator __last);



template <class _ExecutionPolicy, class _RandomAccessIterator, class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, void>
stable_sort(_ExecutionPolicy&& __exec, _RandomAccessIterator __first, _RandomAccessIterator __last, _Compare __comp);

template <class _ExecutionPolicy, class _RandomAccessIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, void>
stable_sort(_ExecutionPolicy&& __exec, _RandomAccessIterator __first, _RandomAccessIterator __last);



template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _BinaryPredicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, std::pair<_ForwardIterator1, _ForwardIterator2>>
mismatch(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1, _ForwardIterator2 __first2,
         _ForwardIterator2 __last2, _BinaryPredicate __pred);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _BinaryPredicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, std::pair<_ForwardIterator1, _ForwardIterator2>>
mismatch(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1, _ForwardIterator2 __first2,
         _BinaryPredicate __pred);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, std::pair<_ForwardIterator1, _ForwardIterator2>>
mismatch(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1, _ForwardIterator2 __first2,
         _ForwardIterator2 __last2);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, std::pair<_ForwardIterator1, _ForwardIterator2>>
mismatch(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1, _ForwardIterator2 __first2);



template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _BinaryPredicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, bool>
equal(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1, _ForwardIterator2 __first2,
      _BinaryPredicate __p);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, bool>
equal(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1, _ForwardIterator2 __first2);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _BinaryPredicate>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, bool>
equal(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1, _ForwardIterator2 __first2,
      _ForwardIterator2 __last2, _BinaryPredicate __p);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, bool>
equal(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1, _ForwardIterator2 __first2,
      _ForwardIterator2 __last2);


template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator2>
move(_ExecutionPolicy&& __exec, _ForwardIterator1 __first, _ForwardIterator1 __last, _ForwardIterator2 __d_first);



template <class _ExecutionPolicy, class _RandomAccessIterator, class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, void>
partial_sort(_ExecutionPolicy&& __exec, _RandomAccessIterator __first, _RandomAccessIterator __middle,
             _RandomAccessIterator __last, _Compare __comp);

template <class _ExecutionPolicy, class _RandomAccessIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, void>
partial_sort(_ExecutionPolicy&& __exec, _RandomAccessIterator __first, _RandomAccessIterator __middle,
             _RandomAccessIterator __last);



template <class _ExecutionPolicy, class _ForwardIterator, class _RandomAccessIterator, class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _RandomAccessIterator>
partial_sort_copy(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last,
                  _RandomAccessIterator __d_first, _RandomAccessIterator __d_last, _Compare __comp);

template <class _ExecutionPolicy, class _ForwardIterator, class _RandomAccessIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _RandomAccessIterator>
partial_sort_copy(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last,
                  _RandomAccessIterator __d_first, _RandomAccessIterator __d_last);


template <class _ExecutionPolicy, class _ForwardIterator, class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
is_sorted_until(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _Compare __comp);

template <class _ExecutionPolicy, class _ForwardIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
is_sorted_until(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last);

template <class _ExecutionPolicy, class _ForwardIterator, class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, bool>
is_sorted(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _Compare __comp);

template <class _ExecutionPolicy, class _ForwardIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, bool>
is_sorted(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last);



template <class _ExecutionPolicy, class _RandomAccessIterator, class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, void>
nth_element(_ExecutionPolicy&& __exec, _RandomAccessIterator __first, _RandomAccessIterator __nth,
            _RandomAccessIterator __last, _Compare __comp);

template <class _ExecutionPolicy, class _RandomAccessIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, void>
nth_element(_ExecutionPolicy&& __exec, _RandomAccessIterator __first, _RandomAccessIterator __nth,
            _RandomAccessIterator __last);


template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _ForwardIterator,
          class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
merge(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1, _ForwardIterator2 __first2,
      _ForwardIterator2 __last2, _ForwardIterator __d_first, _Compare __comp);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _ForwardIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
merge(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1, _ForwardIterator2 __first2,
      _ForwardIterator2 __last2, _ForwardIterator __d_first);

template <class _ExecutionPolicy, class _BidirectionalIterator, class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, void>
inplace_merge(_ExecutionPolicy&& __exec, _BidirectionalIterator __first, _BidirectionalIterator __middle,
              _BidirectionalIterator __last, _Compare __comp);

template <class _ExecutionPolicy, class _BidirectionalIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, void>
inplace_merge(_ExecutionPolicy&& __exec, _BidirectionalIterator __first, _BidirectionalIterator __middle,
              _BidirectionalIterator __last);



template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, bool>
includes(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1, _ForwardIterator2 __first2,
         _ForwardIterator2 __last2, _Compare __comp);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, bool>
includes(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1, _ForwardIterator2 __first2,
         _ForwardIterator2 __last2);



template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _ForwardIterator,
          class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
set_union(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1, _ForwardIterator2 __first2,
          _ForwardIterator2 __last2, _ForwardIterator __result, _Compare __comp);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _ForwardIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
set_union(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1, _ForwardIterator2 __first2,
          _ForwardIterator2 __last2, _ForwardIterator __result);



template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _ForwardIterator,
          class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
set_intersection(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1,
                 _ForwardIterator2 __first2, _ForwardIterator2 __last2, _ForwardIterator __result, _Compare __comp);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _ForwardIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
set_intersection(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1,
                 _ForwardIterator2 __first2, _ForwardIterator2 __last2, _ForwardIterator __result);



template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _ForwardIterator,
          class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
set_difference(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1,
               _ForwardIterator2 __first2, _ForwardIterator2 __last2, _ForwardIterator __result, _Compare __comp);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _ForwardIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
set_difference(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1,
               _ForwardIterator2 __first2, _ForwardIterator2 __last2, _ForwardIterator __result);



template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _ForwardIterator,
          class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
set_symmetric_difference(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1,
                         _ForwardIterator2 __first2, _ForwardIterator2 __last2, _ForwardIterator result,
                         _Compare __comp);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _ForwardIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
set_symmetric_difference(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1,
                         _ForwardIterator2 __first2, _ForwardIterator2 __last2, _ForwardIterator __result);


template <class _ExecutionPolicy, class _RandomAccessIterator, class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _RandomAccessIterator>
is_heap_until(_ExecutionPolicy&& __exec, _RandomAccessIterator __first, _RandomAccessIterator __last, _Compare __comp);

template <class _ExecutionPolicy, class _RandomAccessIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _RandomAccessIterator>
is_heap_until(_ExecutionPolicy&& __exec, _RandomAccessIterator __first, _RandomAccessIterator __last);

template <class _ExecutionPolicy, class _RandomAccessIterator, class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, bool>
is_heap(_ExecutionPolicy&& __exec, _RandomAccessIterator __first, _RandomAccessIterator __last, _Compare __comp);

template <class _ExecutionPolicy, class _RandomAccessIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, bool>
is_heap(_ExecutionPolicy&& __exec, _RandomAccessIterator __first, _RandomAccessIterator __last);



template <class _ExecutionPolicy, class _ForwardIterator, class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
min_element(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _Compare __comp);

template <class _ExecutionPolicy, class _ForwardIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
min_element(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last);

template <class _ExecutionPolicy, class _ForwardIterator, class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
max_element(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _Compare __comp);

template <class _ExecutionPolicy, class _ForwardIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, _ForwardIterator>
max_element(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last);

template <class _ExecutionPolicy, class _ForwardIterator, class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, std::pair<_ForwardIterator, _ForwardIterator>>
minmax_element(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last, _Compare __comp);

template <class _ExecutionPolicy, class _ForwardIterator>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, std::pair<_ForwardIterator, _ForwardIterator>>
minmax_element(_ExecutionPolicy&& __exec, _ForwardIterator __first, _ForwardIterator __last);



template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2, class _Compare>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, bool>
lexicographical_compare(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1,
                        _ForwardIterator2 __first2, _ForwardIterator2 __last2, _Compare __comp);

template <class _ExecutionPolicy, class _ForwardIterator1, class _ForwardIterator2>
__pstl::__internal::__enable_if_execution_policy<_ExecutionPolicy, bool>
lexicographical_compare(_ExecutionPolicy&& __exec, _ForwardIterator1 __first1, _ForwardIterator1 __last1,
                        _ForwardIterator2 __first2, _ForwardIterator2 __last2);

}
# 90 "C:/msys64/mingw64/include/c++/15.2.0/algorithm" 2 3
# 2915 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 2
# 1 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 1 3
# 36 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/requires_hosted.h" 1 3
# 37 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 2 3





# 1 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 1 3
# 41 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/uses_allocator.h" 1 3
# 40 "C:/msys64/mingw64/include/c++/15.2.0/bits/uses_allocator.h" 3
namespace std
{




  struct __erased_type { };




  template<typename _Alloc, typename _Tp>
    using __is_erased_or_convertible
      = __or_<is_convertible<_Alloc, _Tp>, is_same<_Tp, __erased_type>>;


  struct allocator_arg_t { explicit allocator_arg_t() = default; };

  inline constexpr allocator_arg_t allocator_arg =
    allocator_arg_t();

  template<typename _Tp, typename _Alloc, typename = __void_t<>>
    struct __uses_allocator_helper
    : false_type { };

  template<typename _Tp, typename _Alloc>
    struct __uses_allocator_helper<_Tp, _Alloc,
       __void_t<typename _Tp::allocator_type>>
    : __is_erased_or_convertible<_Alloc, typename _Tp::allocator_type>::type
    { };


  template<typename _Tp, typename _Alloc>
    struct uses_allocator
    : __uses_allocator_helper<_Tp, _Alloc>::type
    { };

  struct __uses_alloc_base { };

  struct __uses_alloc0 : __uses_alloc_base
  {
    struct _Sink { void constexpr operator=(const void*) { } } _M_a;
  };

  template<typename _Alloc>
    struct __uses_alloc1 : __uses_alloc_base { const _Alloc* _M_a; };

  template<typename _Alloc>
    struct __uses_alloc2 : __uses_alloc_base { const _Alloc* _M_a; };

  template<bool, typename _Tp, typename _Alloc, typename... _Args>
    struct __uses_alloc;

  template<typename _Tp, typename _Alloc, typename... _Args>
    struct __uses_alloc<true, _Tp, _Alloc, _Args...>
    : __conditional_t<
        is_constructible<_Tp, allocator_arg_t, const _Alloc&, _Args...>::value,
        __uses_alloc1<_Alloc>,
        __uses_alloc2<_Alloc>>
    {


      static_assert(__or_<
   is_constructible<_Tp, allocator_arg_t, const _Alloc&, _Args...>,
   is_constructible<_Tp, _Args..., const _Alloc&>>::value,
   "construction with an allocator must be possible"
   " if uses_allocator is true");
    };

  template<typename _Tp, typename _Alloc, typename... _Args>
    struct __uses_alloc<false, _Tp, _Alloc, _Args...>
    : __uses_alloc0 { };

  template<typename _Tp, typename _Alloc, typename... _Args>
    using __uses_alloc_t =
      __uses_alloc<uses_allocator<_Tp, _Alloc>::value, _Tp, _Alloc, _Args...>;

  template<typename _Tp, typename _Alloc, typename... _Args>
    constexpr
    inline __uses_alloc_t<_Tp, _Alloc, _Args...>
    __use_alloc(const _Alloc& __a)
    {
      __uses_alloc_t<_Tp, _Alloc, _Args...> __ret;
      __ret._M_a = std::__addressof(__a);
      return __ret;
    }

  template<typename _Tp, typename _Alloc, typename... _Args>
    void
    __use_alloc(const _Alloc&&) = delete;


  template <typename _Tp, typename _Alloc>
    inline constexpr bool uses_allocator_v =
      uses_allocator<_Tp, _Alloc>::value;



  template<typename _Alloc, typename... _Ts>
    concept __allocator_for = (uses_allocator_v<_Ts, _Alloc> && ...);


  template<template<typename...> class _Predicate,
    typename _Tp, typename _Alloc, typename... _Args>
    struct __is_uses_allocator_predicate
    : __conditional_t<uses_allocator<_Tp, _Alloc>::value,
      __or_<_Predicate<_Tp, allocator_arg_t, _Alloc, _Args...>,
     _Predicate<_Tp, _Args..., _Alloc>>,
      _Predicate<_Tp, _Args...>> { };

  template<typename _Tp, typename _Alloc, typename... _Args>
    struct __is_uses_allocator_constructible
    : __is_uses_allocator_predicate<is_constructible, _Tp, _Alloc, _Args...>
    { };


  template<typename _Tp, typename _Alloc, typename... _Args>
    inline constexpr bool __is_uses_allocator_constructible_v =
      __is_uses_allocator_constructible<_Tp, _Alloc, _Args...>::value;


  template<typename _Tp, typename _Alloc, typename... _Args>
    struct __is_nothrow_uses_allocator_constructible
    : __is_uses_allocator_predicate<is_nothrow_constructible,
        _Tp, _Alloc, _Args...>
    { };



  template<typename _Tp, typename _Alloc, typename... _Args>
    inline constexpr bool
    __is_nothrow_uses_allocator_constructible_v =
      __is_nothrow_uses_allocator_constructible<_Tp, _Alloc, _Args...>::value;


  template<typename _Tp, typename... _Args>
    void __uses_allocator_construct_impl(__uses_alloc0, _Tp* __ptr,
      _Args&&... __args)
    { ::new ((void*)__ptr) _Tp(std::forward<_Args>(__args)...); }

  template<typename _Tp, typename _Alloc, typename... _Args>
    void __uses_allocator_construct_impl(__uses_alloc1<_Alloc> __a, _Tp* __ptr,
      _Args&&... __args)
    {
      ::new ((void*)__ptr) _Tp(allocator_arg, *__a._M_a,
          std::forward<_Args>(__args)...);
    }

  template<typename _Tp, typename _Alloc, typename... _Args>
    void __uses_allocator_construct_impl(__uses_alloc2<_Alloc> __a, _Tp* __ptr,
      _Args&&... __args)
    { ::new ((void*)__ptr) _Tp(std::forward<_Args>(__args)..., *__a._M_a); }

  template<typename _Tp, typename _Alloc, typename... _Args>
    void __uses_allocator_construct(const _Alloc& __a, _Tp* __ptr,
        _Args&&... __args)
    {
      std::__uses_allocator_construct_impl(
   std::__use_alloc<_Tp, _Alloc, _Args...>(__a), __ptr,
   std::forward<_Args>(__args)...);
    }



}
# 42 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 2 3
# 57 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 58 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 2 3

namespace std
{







  template<typename... _Elements>
    class tuple;


  template<typename _Tp>
    struct __is_empty_non_tuple : is_empty<_Tp> { };


  template<typename _El0, typename... _El>
    struct __is_empty_non_tuple<tuple<_El0, _El...>> : false_type { };


  template<typename _Tp>
    using __empty_not_final
    = __conditional_t<__is_final(_Tp), false_type,
        __is_empty_non_tuple<_Tp>>;

  template<size_t _Idx, typename _Head,
    bool = __empty_not_final<_Head>::value>
    struct _Head_base;


  template<size_t _Idx, typename _Head>
    struct _Head_base<_Idx, _Head, true>
    {
      constexpr _Head_base()
      : _M_head_impl() { }

      constexpr _Head_base(const _Head& __h)
      : _M_head_impl(__h) { }

      constexpr _Head_base(const _Head_base&) = default;
      constexpr _Head_base(_Head_base&&) = default;

      template<typename _UHead>
 constexpr _Head_base(_UHead&& __h)
 : _M_head_impl(std::forward<_UHead>(__h)) { }

      constexpr
      _Head_base(allocator_arg_t, __uses_alloc0)
      : _M_head_impl() { }

      template<typename _Alloc>
 constexpr
 _Head_base(allocator_arg_t, __uses_alloc1<_Alloc> __a)
 : _M_head_impl(allocator_arg, *__a._M_a) { }

      template<typename _Alloc>
 constexpr
 _Head_base(allocator_arg_t, __uses_alloc2<_Alloc> __a)
 : _M_head_impl(*__a._M_a) { }

      template<typename _UHead>
 constexpr
 _Head_base(__uses_alloc0, _UHead&& __uhead)
 : _M_head_impl(std::forward<_UHead>(__uhead)) { }

      template<typename _Alloc, typename _UHead>
 constexpr
 _Head_base(__uses_alloc1<_Alloc> __a, _UHead&& __uhead)
 : _M_head_impl(allocator_arg, *__a._M_a, std::forward<_UHead>(__uhead))
 { }

      template<typename _Alloc, typename _UHead>
 constexpr
 _Head_base(__uses_alloc2<_Alloc> __a, _UHead&& __uhead)
 : _M_head_impl(std::forward<_UHead>(__uhead), *__a._M_a) { }

      static constexpr _Head&
      _M_head(_Head_base& __b) noexcept { return __b._M_head_impl; }

      static constexpr const _Head&
      _M_head(const _Head_base& __b) noexcept { return __b._M_head_impl; }

      [[__no_unique_address__]] _Head _M_head_impl;
    };
# 199 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
  template<size_t _Idx, typename _Head>
    struct _Head_base<_Idx, _Head, false>
    {
      constexpr _Head_base()
      : _M_head_impl() { }

      constexpr _Head_base(const _Head& __h)
      : _M_head_impl(__h) { }

      constexpr _Head_base(const _Head_base&) = default;
      constexpr _Head_base(_Head_base&&) = default;

      template<typename _UHead>
        constexpr _Head_base(_UHead&& __h)
 : _M_head_impl(std::forward<_UHead>(__h)) { }

      constexpr
      _Head_base(allocator_arg_t, __uses_alloc0)
      : _M_head_impl() { }

      template<typename _Alloc>
 constexpr
 _Head_base(allocator_arg_t, __uses_alloc1<_Alloc> __a)
 : _M_head_impl(allocator_arg, *__a._M_a) { }

      template<typename _Alloc>
 constexpr
 _Head_base(allocator_arg_t, __uses_alloc2<_Alloc> __a)
 : _M_head_impl(*__a._M_a) { }

      template<typename _UHead>
 constexpr
 _Head_base(__uses_alloc0, _UHead&& __uhead)
 : _M_head_impl(std::forward<_UHead>(__uhead)) { }

      template<typename _Alloc, typename _UHead>
 constexpr
 _Head_base(__uses_alloc1<_Alloc> __a, _UHead&& __uhead)
 : _M_head_impl(allocator_arg, *__a._M_a, std::forward<_UHead>(__uhead))
 { }

      template<typename _Alloc, typename _UHead>
 constexpr
 _Head_base(__uses_alloc2<_Alloc> __a, _UHead&& __uhead)
 : _M_head_impl(std::forward<_UHead>(__uhead), *__a._M_a) { }

      static constexpr _Head&
      _M_head(_Head_base& __b) noexcept { return __b._M_head_impl; }

      static constexpr const _Head&
      _M_head(const _Head_base& __b) noexcept { return __b._M_head_impl; }

      _Head _M_head_impl;
    };
# 272 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
  template<size_t _Idx, typename... _Elements>
    struct _Tuple_impl;






  template<size_t _Idx, typename _Head, typename... _Tail>
    struct _Tuple_impl<_Idx, _Head, _Tail...>
    : public _Tuple_impl<_Idx + 1, _Tail...>,
      private _Head_base<_Idx, _Head>
    {
      template<size_t, typename...> friend struct _Tuple_impl;

      typedef _Tuple_impl<_Idx + 1, _Tail...> _Inherited;
      typedef _Head_base<_Idx, _Head> _Base;

      static constexpr _Head&
      _M_head(_Tuple_impl& __t) noexcept { return _Base::_M_head(__t); }

      static constexpr const _Head&
      _M_head(const _Tuple_impl& __t) noexcept { return _Base::_M_head(__t); }

      static constexpr _Inherited&
      _M_tail(_Tuple_impl& __t) noexcept { return __t; }

      static constexpr const _Inherited&
      _M_tail(const _Tuple_impl& __t) noexcept { return __t; }

      constexpr _Tuple_impl()
      : _Inherited(), _Base() { }

      explicit constexpr
      _Tuple_impl(const _Head& __head, const _Tail&... __tail)
      : _Inherited(__tail...), _Base(__head)
      { }

      template<typename _UHead, typename... _UTail,
        typename = __enable_if_t<sizeof...(_Tail) == sizeof...(_UTail)>>
 explicit constexpr
 _Tuple_impl(_UHead&& __head, _UTail&&... __tail)
 : _Inherited(std::forward<_UTail>(__tail)...),
   _Base(std::forward<_UHead>(__head))
 { }

      constexpr _Tuple_impl(const _Tuple_impl&) = default;



      _Tuple_impl& operator=(const _Tuple_impl&) = delete;

      _Tuple_impl(_Tuple_impl&&) = default;

      template<typename... _UElements>
 constexpr
 _Tuple_impl(const _Tuple_impl<_Idx, _UElements...>& __in)
 : _Inherited(_Tuple_impl<_Idx, _UElements...>::_M_tail(__in)),
   _Base(_Tuple_impl<_Idx, _UElements...>::_M_head(__in))
 { }

      template<typename _UHead, typename... _UTails>
 constexpr
 _Tuple_impl(_Tuple_impl<_Idx, _UHead, _UTails...>&& __in)
 : _Inherited(std::move
       (_Tuple_impl<_Idx, _UHead, _UTails...>::_M_tail(__in))),
   _Base(std::forward<_UHead>
  (_Tuple_impl<_Idx, _UHead, _UTails...>::_M_head(__in)))
 { }
# 368 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
      template<typename _Alloc>
 constexpr
 _Tuple_impl(allocator_arg_t __tag, const _Alloc& __a)
 : _Inherited(__tag, __a),
   _Base(__tag, __use_alloc<_Head>(__a))
 { }

      template<typename _Alloc>
 constexpr
 _Tuple_impl(allocator_arg_t __tag, const _Alloc& __a,
      const _Head& __head, const _Tail&... __tail)
 : _Inherited(__tag, __a, __tail...),
   _Base(__use_alloc<_Head, _Alloc, _Head>(__a), __head)
 { }

      template<typename _Alloc, typename _UHead, typename... _UTail,
        typename = __enable_if_t<sizeof...(_Tail) == sizeof...(_UTail)>>
 constexpr
 _Tuple_impl(allocator_arg_t __tag, const _Alloc& __a,
      _UHead&& __head, _UTail&&... __tail)
 : _Inherited(__tag, __a, std::forward<_UTail>(__tail)...),
   _Base(__use_alloc<_Head, _Alloc, _UHead>(__a),
  std::forward<_UHead>(__head))
 { }

      template<typename _Alloc>
 constexpr
 _Tuple_impl(allocator_arg_t __tag, const _Alloc& __a,
      const _Tuple_impl& __in)
 : _Inherited(__tag, __a, _M_tail(__in)),
   _Base(__use_alloc<_Head, _Alloc, _Head>(__a), _M_head(__in))
 { }

      template<typename _Alloc>
 constexpr
 _Tuple_impl(allocator_arg_t __tag, const _Alloc& __a,
      _Tuple_impl&& __in)
 : _Inherited(__tag, __a, std::move(_M_tail(__in))),
   _Base(__use_alloc<_Head, _Alloc, _Head>(__a),
  std::forward<_Head>(_M_head(__in)))
 { }

      template<typename _Alloc, typename _UHead, typename... _UTails>
 constexpr
 _Tuple_impl(allocator_arg_t __tag, const _Alloc& __a,
      const _Tuple_impl<_Idx, _UHead, _UTails...>& __in)
 : _Inherited(__tag, __a,
       _Tuple_impl<_Idx, _UHead, _UTails...>::_M_tail(__in)),
   _Base(__use_alloc<_Head, _Alloc, const _UHead&>(__a),
  _Tuple_impl<_Idx, _UHead, _UTails...>::_M_head(__in))
 { }

      template<typename _Alloc, typename _UHead, typename... _UTails>
 constexpr
 _Tuple_impl(allocator_arg_t __tag, const _Alloc& __a,
      _Tuple_impl<_Idx, _UHead, _UTails...>&& __in)
 : _Inherited(__tag, __a, std::move
       (_Tuple_impl<_Idx, _UHead, _UTails...>::_M_tail(__in))),
   _Base(__use_alloc<_Head, _Alloc, _UHead>(__a),
  std::forward<_UHead>
  (_Tuple_impl<_Idx, _UHead, _UTails...>::_M_head(__in)))
 { }
# 463 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
      template<typename... _UElements>
 constexpr
 void
 _M_assign(const _Tuple_impl<_Idx, _UElements...>& __in)
 {
   _M_head(*this) = _Tuple_impl<_Idx, _UElements...>::_M_head(__in);
   _M_tail(*this)._M_assign(
       _Tuple_impl<_Idx, _UElements...>::_M_tail(__in));
 }

      template<typename _UHead, typename... _UTails>
 constexpr
 void
 _M_assign(_Tuple_impl<_Idx, _UHead, _UTails...>&& __in)
 {
   _M_head(*this) = std::forward<_UHead>
     (_Tuple_impl<_Idx, _UHead, _UTails...>::_M_head(__in));
   _M_tail(*this)._M_assign(
       std::move(_Tuple_impl<_Idx, _UHead, _UTails...>::_M_tail(__in)));
 }
# 523 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
    protected:
      constexpr
      void
      _M_swap(_Tuple_impl& __in)
      {
 using std::swap;
 swap(_M_head(*this), _M_head(__in));
 _Inherited::_M_swap(_M_tail(__in));
      }
# 542 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
    };


  template<size_t _Idx, typename _Head>
    struct _Tuple_impl<_Idx, _Head>
    : private _Head_base<_Idx, _Head>
    {
      template<size_t, typename...> friend struct _Tuple_impl;

      typedef _Head_base<_Idx, _Head> _Base;

      static constexpr _Head&
      _M_head(_Tuple_impl& __t) noexcept { return _Base::_M_head(__t); }

      static constexpr const _Head&
      _M_head(const _Tuple_impl& __t) noexcept { return _Base::_M_head(__t); }

      constexpr
      _Tuple_impl()
      : _Base() { }

      explicit constexpr
      _Tuple_impl(const _Head& __head)
      : _Base(__head)
      { }

      template<typename _UHead>
 explicit constexpr
 _Tuple_impl(_UHead&& __head)
 : _Base(std::forward<_UHead>(__head))
 { }

      constexpr _Tuple_impl(const _Tuple_impl&) = default;



      _Tuple_impl& operator=(const _Tuple_impl&) = delete;




      constexpr
      _Tuple_impl(_Tuple_impl&& __in)
      noexcept(is_nothrow_move_constructible<_Head>::value)
      : _Base(static_cast<_Base&&>(__in))
      { }


      template<typename _UHead>
 constexpr
 _Tuple_impl(const _Tuple_impl<_Idx, _UHead>& __in)
 : _Base(_Tuple_impl<_Idx, _UHead>::_M_head(__in))
 { }

      template<typename _UHead>
 constexpr
 _Tuple_impl(_Tuple_impl<_Idx, _UHead>&& __in)
 : _Base(std::forward<_UHead>(_Tuple_impl<_Idx, _UHead>::_M_head(__in)))
 { }
# 624 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
      template<typename _Alloc>
 constexpr
 _Tuple_impl(allocator_arg_t __tag, const _Alloc& __a)
 : _Base(__tag, __use_alloc<_Head>(__a))
 { }

      template<typename _Alloc>
 constexpr
 _Tuple_impl(allocator_arg_t, const _Alloc& __a,
      const _Head& __head)
 : _Base(__use_alloc<_Head, _Alloc, const _Head&>(__a), __head)
 { }

      template<typename _Alloc, typename _UHead>
 constexpr
 _Tuple_impl(allocator_arg_t, const _Alloc& __a,
      _UHead&& __head)
 : _Base(__use_alloc<_Head, _Alloc, _UHead>(__a),
  std::forward<_UHead>(__head))
 { }

      template<typename _Alloc>
 constexpr
 _Tuple_impl(allocator_arg_t, const _Alloc& __a,
      const _Tuple_impl& __in)
 : _Base(__use_alloc<_Head, _Alloc, const _Head&>(__a), _M_head(__in))
 { }

      template<typename _Alloc>
 constexpr
 _Tuple_impl(allocator_arg_t, const _Alloc& __a,
      _Tuple_impl&& __in)
 : _Base(__use_alloc<_Head, _Alloc, _Head>(__a),
  std::forward<_Head>(_M_head(__in)))
 { }

      template<typename _Alloc, typename _UHead>
 constexpr
 _Tuple_impl(allocator_arg_t, const _Alloc& __a,
      const _Tuple_impl<_Idx, _UHead>& __in)
 : _Base(__use_alloc<_Head, _Alloc, const _UHead&>(__a),
  _Tuple_impl<_Idx, _UHead>::_M_head(__in))
 { }

      template<typename _Alloc, typename _UHead>
 constexpr
 _Tuple_impl(allocator_arg_t, const _Alloc& __a,
      _Tuple_impl<_Idx, _UHead>&& __in)
 : _Base(__use_alloc<_Head, _Alloc, _UHead>(__a),
  std::forward<_UHead>(_Tuple_impl<_Idx, _UHead>::_M_head(__in)))
 { }
# 703 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
      template<typename _UHead>
 constexpr
 void
 _M_assign(const _Tuple_impl<_Idx, _UHead>& __in)
 {
   _M_head(*this) = _Tuple_impl<_Idx, _UHead>::_M_head(__in);
 }

      template<typename _UHead>
 constexpr
 void
 _M_assign(_Tuple_impl<_Idx, _UHead>&& __in)
 {
   _M_head(*this)
     = std::forward<_UHead>(_Tuple_impl<_Idx, _UHead>::_M_head(__in));
 }
# 749 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
    protected:
      constexpr
      void
      _M_swap(_Tuple_impl& __in)
      {
 using std::swap;
 swap(_M_head(*this), _M_head(__in));
      }
# 766 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
    };



  template<bool, typename... _Types>
    struct _TupleConstraints
    {
      template<typename... _UTypes>
 using __constructible = __and_<is_constructible<_Types, _UTypes>...>;

      template<typename... _UTypes>
 using __convertible = __and_<is_convertible<_UTypes, _Types>...>;




      template<typename... _UTypes>
 static constexpr bool __is_implicitly_constructible()
 {
   return __and_<__constructible<_UTypes...>,
   __convertible<_UTypes...>
   >::value;
 }




      template<typename... _UTypes>
 static constexpr bool __is_explicitly_constructible()
 {
   return __and_<__constructible<_UTypes...>,
   __not_<__convertible<_UTypes...>>
   >::value;
 }

      static constexpr bool __is_implicitly_default_constructible()
      {
 return __and_<std::__is_implicitly_default_constructible<_Types>...
        >::value;
      }

      static constexpr bool __is_explicitly_default_constructible()
      {
 return __and_<is_default_constructible<_Types>...,
        __not_<__and_<
   std::__is_implicitly_default_constructible<_Types>...>
        >>::value;
      }
    };



  template<typename... _Types>
    struct _TupleConstraints<false, _Types...>
    {
      template<typename... _UTypes>
 static constexpr bool __is_implicitly_constructible()
 { return false; }

      template<typename... _UTypes>
 static constexpr bool __is_explicitly_constructible()
 { return false; }
    };



  template<typename... _Elements>
    class tuple : public _Tuple_impl<0, _Elements...>
    {
      using _Inherited = _Tuple_impl<0, _Elements...>;


      template<typename... _UTypes>
 static consteval bool
 __constructible()
 {
   if constexpr (sizeof...(_UTypes) == sizeof...(_Elements))
     return __and_v<is_constructible<_Elements, _UTypes>...>;
   else
     return false;
 }

      template<typename... _UTypes>
 static consteval bool
 __nothrow_constructible()
 {
   if constexpr (sizeof...(_UTypes) == sizeof...(_Elements))
     return __and_v<is_nothrow_constructible<_Elements, _UTypes>...>;
   else
     return false;
 }

      template<typename... _UTypes>
 static consteval bool
 __convertible()
 {
   if constexpr (sizeof...(_UTypes) == sizeof...(_Elements))
     return __and_v<is_convertible<_UTypes, _Elements>...>;
   else
     return false;
 }



      template<typename... _UTypes>
 static consteval bool
 __disambiguating_constraint()
 {
   if constexpr (sizeof...(_Elements) != sizeof...(_UTypes))
     return false;
   else if constexpr (sizeof...(_Elements) == 1)
     {
       using _U0 = typename _Nth_type<0, _UTypes...>::type;
       return !is_same_v<remove_cvref_t<_U0>, tuple>;
     }
   else if constexpr (sizeof...(_Elements) < 4)
     {
       using _U0 = typename _Nth_type<0, _UTypes...>::type;
       if constexpr (!is_same_v<remove_cvref_t<_U0>, allocator_arg_t>)
  return true;
       else
  {
    using _T0 = typename _Nth_type<0, _Elements...>::type;
    return is_same_v<remove_cvref_t<_T0>, allocator_arg_t>;
  }
     }
   return true;
 }




      template<typename _Tuple>
 static consteval bool
 __use_other_ctor()
 {
   if constexpr (sizeof...(_Elements) != 1)
     return false;
   else if constexpr (is_same_v<remove_cvref_t<_Tuple>, tuple>)
     return true;
   else
     {
       using _Tp = typename _Nth_type<0, _Elements...>::type;
       if constexpr (is_convertible_v<_Tuple, _Tp>)
  return true;
       else if constexpr (is_constructible_v<_Tp, _Tuple>)
  return true;
     }
   return false;
 }

      template<typename... _Up>
 static consteval bool
 __dangles()
 {

   return (__reference_constructs_from_temporary(_Elements, _Up&&)
      || ...);



 }
# 960 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
    public:
      constexpr
      explicit(!(__is_implicitly_default_constructible_v<_Elements> && ...))
      tuple()
      noexcept((is_nothrow_default_constructible_v<_Elements> && ...))
      requires (is_default_constructible_v<_Elements> && ...)
      : _Inherited()
      { }


      template<typename = void>
 constexpr explicit(!__convertible<const _Elements&...>())
 tuple(const _Elements&... __elements)
 noexcept(__nothrow_constructible<const _Elements&...>())
 requires (__constructible<const _Elements&...>())
 : _Inherited(__elements...)
 { }

      template<typename... _UTypes>
 requires (__disambiguating_constraint<_UTypes...>())
   && (__constructible<_UTypes...>())
   && (!__dangles<_UTypes...>())
 constexpr explicit(!__convertible<_UTypes...>())
 tuple(_UTypes&&... __u)
 noexcept(__nothrow_constructible<_UTypes...>())
 : _Inherited(std::forward<_UTypes>(__u)...)
 { }

      template<typename... _UTypes>
 requires (__disambiguating_constraint<_UTypes...>())
   && (__constructible<_UTypes...>())
   && (__dangles<_UTypes...>())
 tuple(_UTypes&&...) = delete;

      constexpr tuple(const tuple&) = default;

      constexpr tuple(tuple&&) = default;

      template<typename... _UTypes>
 requires (__constructible<const _UTypes&...>())
   && (!__use_other_ctor<const tuple<_UTypes...>&>())
   && (!__dangles<const _UTypes&...>())
 constexpr explicit(!__convertible<const _UTypes&...>())
 tuple(const tuple<_UTypes...>& __u)
 noexcept(__nothrow_constructible<const _UTypes&...>())
 : _Inherited(static_cast<const _Tuple_impl<0, _UTypes...>&>(__u))
 { }

      template<typename... _UTypes>
 requires (__constructible<const _UTypes&...>())
   && (!__use_other_ctor<const tuple<_UTypes...>&>())
   && (__dangles<const _UTypes&...>())
 tuple(const tuple<_UTypes...>&) = delete;

      template<typename... _UTypes>
 requires (__constructible<_UTypes...>())
   && (!__use_other_ctor<tuple<_UTypes...>>())
   && (!__dangles<_UTypes...>())
 constexpr explicit(!__convertible<_UTypes...>())
 tuple(tuple<_UTypes...>&& __u)
 noexcept(__nothrow_constructible<_UTypes...>())
 : _Inherited(static_cast<_Tuple_impl<0, _UTypes...>&&>(__u))
 { }

      template<typename... _UTypes>
 requires (__constructible<_UTypes...>())
   && (!__use_other_ctor<tuple<_UTypes...>>())
   && (__dangles<_UTypes...>())
 tuple(tuple<_UTypes...>&&) = delete;
# 1064 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
      template<typename _U1, typename _U2>
 requires (sizeof...(_Elements) == 2)
   && (__constructible<const _U1&, const _U2&>())
   && (!__dangles<const _U1&, const _U2&>())
 constexpr explicit(!__convertible<const _U1&, const _U2&>())
 tuple(const pair<_U1, _U2>& __u)
 noexcept(__nothrow_constructible<const _U1&, const _U2&>())
 : _Inherited(__u.first, __u.second)
 { }

      template<typename _U1, typename _U2>
 requires (sizeof...(_Elements) == 2)
   && (__constructible<const _U1&, const _U2&>())
   && (__dangles<const _U1&, const _U2&>())
 tuple(const pair<_U1, _U2>&) = delete;

      template<typename _U1, typename _U2>
 requires (sizeof...(_Elements) == 2)
   && (__constructible<_U1, _U2>())
   && (!__dangles<_U1, _U2>())
 constexpr explicit(!__convertible<_U1, _U2>())
 tuple(pair<_U1, _U2>&& __u)
 noexcept(__nothrow_constructible<_U1, _U2>())
 : _Inherited(std::forward<_U1>(__u.first),
       std::forward<_U2>(__u.second))
 { }

      template<typename _U1, typename _U2>
 requires (sizeof...(_Elements) == 2)
   && (__constructible<_U1, _U2>())
   && (__dangles<_U1, _U2>())
 tuple(pair<_U1, _U2>&&) = delete;
# 1153 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
      template<typename _Alloc>
 constexpr
 explicit(!(__is_implicitly_default_constructible_v<_Elements> && ...))
 tuple(allocator_arg_t __tag, const _Alloc& __a)
 requires (is_default_constructible_v<_Elements> && ...)
 : _Inherited(__tag, __a)
 { }

      template<typename _Alloc>
 constexpr explicit(!__convertible<const _Elements&...>())
 tuple(allocator_arg_t __tag, const _Alloc& __a,
       const _Elements&... __elements)
 requires (__constructible<const _Elements&...>())
 : _Inherited(__tag, __a, __elements...)
 { }

      template<typename _Alloc, typename... _UTypes>
 requires (__disambiguating_constraint<_UTypes...>())
   && (__constructible<_UTypes...>())
   && (!__dangles<_UTypes...>())
 constexpr explicit(!__convertible<_UTypes...>())
 tuple(allocator_arg_t __tag, const _Alloc& __a, _UTypes&&... __u)
 : _Inherited(__tag, __a, std::forward<_UTypes>(__u)...)
 { }

      template<typename _Alloc, typename... _UTypes>
 requires (__disambiguating_constraint<_UTypes...>())
   && (__constructible<_UTypes...>())
   && (__dangles<_UTypes...>())
 tuple(allocator_arg_t, const _Alloc&, _UTypes&&...) = delete;

      template<typename _Alloc>
 constexpr
 tuple(allocator_arg_t __tag, const _Alloc& __a, const tuple& __u)
 : _Inherited(__tag, __a, static_cast<const _Inherited&>(__u))
 { }

      template<typename _Alloc>
 requires (__constructible<_Elements...>())
 constexpr
 tuple(allocator_arg_t __tag, const _Alloc& __a, tuple&& __u)
 : _Inherited(__tag, __a, static_cast<_Inherited&&>(__u))
 { }

      template<typename _Alloc, typename... _UTypes>
 requires (__constructible<const _UTypes&...>())
   && (!__use_other_ctor<const tuple<_UTypes...>&>())
   && (!__dangles<const _UTypes&...>())
 constexpr explicit(!__convertible<const _UTypes&...>())
 tuple(allocator_arg_t __tag, const _Alloc& __a,
       const tuple<_UTypes...>& __u)
 : _Inherited(__tag, __a,
       static_cast<const _Tuple_impl<0, _UTypes...>&>(__u))
 { }

      template<typename _Alloc, typename... _UTypes>
 requires (__constructible<const _UTypes&...>())
   && (!__use_other_ctor<const tuple<_UTypes...>&>())
   && (__dangles<const _UTypes&...>())
 tuple(allocator_arg_t, const _Alloc&, const tuple<_UTypes...>&) = delete;

      template<typename _Alloc, typename... _UTypes>
 requires (__constructible<_UTypes...>())
   && (!__use_other_ctor<tuple<_UTypes...>>())
   && (!__dangles<_UTypes...>())
 constexpr explicit(!__use_other_ctor<tuple<_UTypes...>>())
 tuple(allocator_arg_t __tag, const _Alloc& __a, tuple<_UTypes...>&& __u)
 : _Inherited(__tag, __a, static_cast<_Tuple_impl<0, _UTypes...>&&>(__u))
 { }

      template<typename _Alloc, typename... _UTypes>
 requires (__constructible<_UTypes...>())
   && (!__use_other_ctor<tuple<_UTypes...>>())
   && (__dangles<_UTypes...>())
 tuple(allocator_arg_t, const _Alloc&, tuple<_UTypes...>&&) = delete;
# 1263 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
      template<typename _Alloc, typename _U1, typename _U2>
 requires (sizeof...(_Elements) == 2)
   && (__constructible<const _U1&, const _U2&>())
   && (!__dangles<const _U1&, const _U2&>())
 constexpr explicit(!__convertible<const _U1&, const _U2&>())
 tuple(allocator_arg_t __tag, const _Alloc& __a,
       const pair<_U1, _U2>& __u)
 noexcept(__nothrow_constructible<const _U1&, const _U2&>())
 : _Inherited(__tag, __a, __u.first, __u.second)
 { }

      template<typename _Alloc, typename _U1, typename _U2>
 requires (sizeof...(_Elements) == 2)
   && (__constructible<const _U1&, const _U2&>())
   && (__dangles<const _U1&, const _U2&>())
 tuple(allocator_arg_t, const _Alloc&, const pair<_U1, _U2>&) = delete;

      template<typename _Alloc, typename _U1, typename _U2>
 requires (sizeof...(_Elements) == 2)
   && (__constructible<_U1, _U2>())
   && (!__dangles<_U1, _U2>())
 constexpr explicit(!__convertible<_U1, _U2>())
 tuple(allocator_arg_t __tag, const _Alloc& __a, pair<_U1, _U2>&& __u)
 noexcept(__nothrow_constructible<_U1, _U2>())
 : _Inherited(__tag, __a, std::move(__u.first), std::move(__u.second))
 { }

      template<typename _Alloc, typename _U1, typename _U2>
 requires (sizeof...(_Elements) == 2)
   && (__constructible<_U1, _U2>())
   && (__dangles<_U1, _U2>())
 tuple(allocator_arg_t, const _Alloc&, pair<_U1, _U2>&&) = delete;
# 1655 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
    private:
      template<typename... _UTypes>
 static consteval bool
 __assignable()
 {
   if constexpr (sizeof...(_UTypes) == sizeof...(_Elements))
     return __and_v<is_assignable<_Elements&, _UTypes>...>;
   else
     return false;
 }

      template<typename... _UTypes>
 static consteval bool
 __nothrow_assignable()
 {
   if constexpr (sizeof...(_UTypes) == sizeof...(_Elements))
     return __and_v<is_nothrow_assignable<_Elements&, _UTypes>...>;
   else
     return false;
 }
# 1708 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
    public:

      tuple& operator=(const tuple& __u) = delete;

      constexpr tuple&
      operator=(const tuple& __u)
      noexcept(__nothrow_assignable<const _Elements&...>())
      requires (__assignable<const _Elements&...>())
      {
 this->_M_assign(__u);
 return *this;
      }

      constexpr tuple&
      operator=(tuple&& __u)
      noexcept(__nothrow_assignable<_Elements...>())
      requires (__assignable<_Elements...>())
      {
 this->_M_assign(std::move(__u));
 return *this;
      }

      template<typename... _UTypes>
 requires (__assignable<const _UTypes&...>())
 constexpr tuple&
 operator=(const tuple<_UTypes...>& __u)
 noexcept(__nothrow_assignable<const _UTypes&...>())
 {
   this->_M_assign(__u);
   return *this;
 }

      template<typename... _UTypes>
 requires (__assignable<_UTypes...>())
 constexpr tuple&
 operator=(tuple<_UTypes...>&& __u)
 noexcept(__nothrow_assignable<_UTypes...>())
 {
   this->_M_assign(std::move(__u));
   return *this;
 }
# 1786 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
      template<typename _U1, typename _U2>
 requires (__assignable<const _U1&, const _U2&>())
 constexpr tuple&
 operator=(const pair<_U1, _U2>& __u)
 noexcept(__nothrow_assignable<const _U1&, const _U2&>())
 {
   this->_M_head(*this) = __u.first;
   this->_M_tail(*this)._M_head(*this) = __u.second;
   return *this;
 }

      template<typename _U1, typename _U2>
 requires (__assignable<_U1, _U2>())
 constexpr tuple&
 operator=(pair<_U1, _U2>&& __u)
 noexcept(__nothrow_assignable<_U1, _U2>())
 {
   this->_M_head(*this) = std::forward<_U1>(__u.first);
   this->_M_tail(*this)._M_head(*this) = std::forward<_U2>(__u.second);
   return *this;
 }
# 1948 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
      constexpr
      void
      swap(tuple& __in)
      noexcept(__and_<__is_nothrow_swappable<_Elements>...>::value)
      { _Inherited::_M_swap(__in); }
# 1967 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
    };


  template<typename... _UTypes>
    tuple(_UTypes...) -> tuple<_UTypes...>;
  template<typename _T1, typename _T2>
    tuple(pair<_T1, _T2>) -> tuple<_T1, _T2>;
  template<typename _Alloc, typename... _UTypes>
    tuple(allocator_arg_t, _Alloc, _UTypes...) -> tuple<_UTypes...>;
  template<typename _Alloc, typename _T1, typename _T2>
    tuple(allocator_arg_t, _Alloc, pair<_T1, _T2>) -> tuple<_T1, _T2>;
  template<typename _Alloc, typename... _UTypes>
    tuple(allocator_arg_t, _Alloc, tuple<_UTypes...>) -> tuple<_UTypes...>;



  template<>
    class tuple<>
    {
    public:
      constexpr
      void swap(tuple&) noexcept { }





      tuple() = default;

      template<typename _Alloc>
 constexpr
 tuple(allocator_arg_t, const _Alloc&) noexcept { }
      template<typename _Alloc>
 constexpr
 tuple(allocator_arg_t, const _Alloc&, const tuple&) noexcept { }
    };
# 2403 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
  template<typename... _Elements>
    struct tuple_size<tuple<_Elements...>>
    : public integral_constant<size_t, sizeof...(_Elements)> { };


  template<typename... _Types>
    inline constexpr size_t tuple_size_v<tuple<_Types...>>
      = sizeof...(_Types);

  template<typename... _Types>
    inline constexpr size_t tuple_size_v<const tuple<_Types...>>
      = sizeof...(_Types);



  template<size_t __i, typename... _Types>
    struct tuple_element<__i, tuple<_Types...>>
    {
      static_assert(__i < sizeof...(_Types), "tuple index must be in range");

      using type = typename _Nth_type<__i, _Types...>::type;
    };

  template<size_t __i, typename _Head, typename... _Tail>
    constexpr _Head&
    __get_helper(_Tuple_impl<__i, _Head, _Tail...>& __t) noexcept
    { return _Tuple_impl<__i, _Head, _Tail...>::_M_head(__t); }

  template<size_t __i, typename _Head, typename... _Tail>
    constexpr const _Head&
    __get_helper(const _Tuple_impl<__i, _Head, _Tail...>& __t) noexcept
    { return _Tuple_impl<__i, _Head, _Tail...>::_M_head(__t); }


  template<size_t __i, typename... _Types>
    __enable_if_t<(__i >= sizeof...(_Types))>
    __get_helper(const tuple<_Types...>&) = delete;


  template<size_t __i, typename... _Elements>
    constexpr __tuple_element_t<__i, tuple<_Elements...>>&
    get(tuple<_Elements...>& __t) noexcept
    { return std::__get_helper<__i>(__t); }


  template<size_t __i, typename... _Elements>
    constexpr const __tuple_element_t<__i, tuple<_Elements...>>&
    get(const tuple<_Elements...>& __t) noexcept
    { return std::__get_helper<__i>(__t); }


  template<size_t __i, typename... _Elements>
    constexpr __tuple_element_t<__i, tuple<_Elements...>>&&
    get(tuple<_Elements...>&& __t) noexcept
    {
      typedef __tuple_element_t<__i, tuple<_Elements...>> __element_type;
      return std::forward<__element_type>(std::__get_helper<__i>(__t));
    }


  template<size_t __i, typename... _Elements>
    constexpr const __tuple_element_t<__i, tuple<_Elements...>>&&
    get(const tuple<_Elements...>&& __t) noexcept
    {
      typedef __tuple_element_t<__i, tuple<_Elements...>> __element_type;
      return std::forward<const __element_type>(std::__get_helper<__i>(__t));
    }



  template<size_t __i, typename... _Elements>
    constexpr __enable_if_t<(__i >= sizeof...(_Elements))>
    get(const tuple<_Elements...>&) = delete;




  template <typename _Tp, typename... _Types>
    constexpr _Tp&
    get(tuple<_Types...>& __t) noexcept
    {
      constexpr size_t __idx = __find_uniq_type_in_pack<_Tp, _Types...>();
      static_assert(__idx < sizeof...(_Types),
   "the type T in std::get<T> must occur exactly once in the tuple");
      return std::__get_helper<__idx>(__t);
    }


  template <typename _Tp, typename... _Types>
    constexpr _Tp&&
    get(tuple<_Types...>&& __t) noexcept
    {
      constexpr size_t __idx = __find_uniq_type_in_pack<_Tp, _Types...>();
      static_assert(__idx < sizeof...(_Types),
   "the type T in std::get<T> must occur exactly once in the tuple");
      return std::forward<_Tp>(std::__get_helper<__idx>(__t));
    }


  template <typename _Tp, typename... _Types>
    constexpr const _Tp&
    get(const tuple<_Types...>& __t) noexcept
    {
      constexpr size_t __idx = __find_uniq_type_in_pack<_Tp, _Types...>();
      static_assert(__idx < sizeof...(_Types),
   "the type T in std::get<T> must occur exactly once in the tuple");
      return std::__get_helper<__idx>(__t);
    }



  template <typename _Tp, typename... _Types>
    constexpr const _Tp&&
    get(const tuple<_Types...>&& __t) noexcept
    {
      constexpr size_t __idx = __find_uniq_type_in_pack<_Tp, _Types...>();
      static_assert(__idx < sizeof...(_Types),
   "the type T in std::get<T> must occur exactly once in the tuple");
      return std::forward<const _Tp>(std::__get_helper<__idx>(__t));
    }



  template<typename... _Tps, typename... _Ups>
    requires (sizeof...(_Tps) == sizeof...(_Ups))
      && (requires (const _Tps& __t, const _Ups& __u) {
 { __t == __u } -> __detail::__boolean_testable;
      } && ...)
    constexpr bool
    operator== [[nodiscard]] (const tuple<_Tps...>& __t,
         const tuple<_Ups...>& __u)
    {
      return [&]<size_t... _Inds>(index_sequence<_Inds...>) {

 return (bool(std::get<_Inds>(__t) == std::get<_Inds>(__u)) && ...);
      }(index_sequence_for<_Tps...>{});
    }

  template<typename _Cat, typename _Tp, typename _Up, typename _IndexSeq>
    [[nodiscard]]
    constexpr _Cat
    __tuple_cmp(const _Tp& __t, const _Up& __u, _IndexSeq __indices)
    {
      _Cat __c = _Cat::equivalent;



      auto __cmp = [&]<size_t _Ind>(integral_constant<size_t, _Ind>) {
 __c = __detail::__synth3way(std::get<_Ind>(__t), std::get<_Ind>(__u));
 return __c == 0;
      };

      [&]<size_t... _Inds>(index_sequence<_Inds...>) {

 (void)(__cmp(integral_constant<size_t, _Inds>{}) && ...);
      }(__indices);

      return __c;
    }

  template<typename... _Tps, typename... _Ups>
    requires (sizeof...(_Tps) == sizeof...(_Ups))
      && (requires { typename __detail::__synth3way_t<_Tps, _Ups>; } && ...)
    constexpr
    common_comparison_category_t<__detail::__synth3way_t<_Tps, _Ups>...>
    operator<=> [[nodiscard]] (const tuple<_Tps...>& __t,
          const tuple<_Ups...>& __u)
    {
      using _Cat
 = common_comparison_category_t<__detail::__synth3way_t<_Tps, _Ups>...>;
      return std::__tuple_cmp<_Cat>(__t, __u, index_sequence_for<_Tps...>());
    }
# 2666 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
  template<typename... _Elements>
    constexpr tuple<typename __decay_and_strip<_Elements>::__type...>
    make_tuple(_Elements&&... __args)
    {
      typedef tuple<typename __decay_and_strip<_Elements>::__type...>
 __result_type;
      return __result_type(std::forward<_Elements>(__args)...);
    }




  template<typename... _Elements>
    constexpr tuple<_Elements&&...>
    forward_as_tuple(_Elements&&... __args) noexcept
    { return tuple<_Elements&&...>(std::forward<_Elements>(__args)...); }


  template<size_t, typename, typename, size_t>
    struct __make_tuple_impl;

  template<size_t _Idx, typename _Tuple, typename... _Tp, size_t _Nm>
    struct __make_tuple_impl<_Idx, tuple<_Tp...>, _Tuple, _Nm>
    : __make_tuple_impl<_Idx + 1,
   tuple<_Tp..., __tuple_element_t<_Idx, _Tuple>>,
   _Tuple, _Nm>
    { };

  template<size_t _Nm, typename _Tuple, typename... _Tp>
    struct __make_tuple_impl<_Nm, tuple<_Tp...>, _Tuple, _Nm>
    {
      typedef tuple<_Tp...> __type;
    };

  template<typename _Tuple>
    struct __do_make_tuple
    : __make_tuple_impl<0, tuple<>, _Tuple, tuple_size<_Tuple>::value>
    { };


  template<typename _Tuple>
    struct __make_tuple
    : public __do_make_tuple<__remove_cvref_t<_Tuple>>
    { };


  template<typename...>
    struct __combine_tuples;

  template<>
    struct __combine_tuples<>
    {
      typedef tuple<> __type;
    };

  template<typename... _Ts>
    struct __combine_tuples<tuple<_Ts...>>
    {
      typedef tuple<_Ts...> __type;
    };

  template<typename... _T1s, typename... _T2s, typename... _Rem>
    struct __combine_tuples<tuple<_T1s...>, tuple<_T2s...>, _Rem...>
    {
      typedef typename __combine_tuples<tuple<_T1s..., _T2s...>,
     _Rem...>::__type __type;
    };


  template<typename... _Tpls>
    struct __tuple_cat_result
    {
      typedef typename __combine_tuples
        <typename __make_tuple<_Tpls>::__type...>::__type __type;
    };



  template<typename...>
    struct __make_1st_indices;

  template<>
    struct __make_1st_indices<>
    {
      typedef _Index_tuple<> __type;
    };

  template<typename _Tp, typename... _Tpls>
    struct __make_1st_indices<_Tp, _Tpls...>
    {
      typedef typename _Build_index_tuple<tuple_size<
 typename remove_reference<_Tp>::type>::value>::__type __type;
    };




  template<typename _Ret, typename _Indices, typename... _Tpls>
    struct __tuple_concater;

  template<typename _Ret, size_t... _Is, typename _Tp, typename... _Tpls>
    struct __tuple_concater<_Ret, _Index_tuple<_Is...>, _Tp, _Tpls...>
    {
      template<typename... _Us>
        static constexpr _Ret
        _S_do(_Tp&& __tp, _Tpls&&... __tps, _Us&&... __us)
        {
   typedef typename __make_1st_indices<_Tpls...>::__type __idx;
   typedef __tuple_concater<_Ret, __idx, _Tpls...> __next;
   return __next::_S_do(std::forward<_Tpls>(__tps)...,
          std::forward<_Us>(__us)...,
          std::get<_Is>(std::forward<_Tp>(__tp))...);
 }
    };

  template<typename _Ret>
    struct __tuple_concater<_Ret, _Index_tuple<>>
    {
      template<typename... _Us>
 static constexpr _Ret
 _S_do(_Us&&... __us)
        {
   return _Ret(std::forward<_Us>(__us)...);
 }
    };

  template<typename... _Tps>
    struct __is_tuple_like_impl<tuple<_Tps...>> : true_type
    { };






  template<typename... _Tpls, typename = typename
           enable_if<__and_<__is_tuple_like<_Tpls>...>::value>::type>

    constexpr auto
    tuple_cat(_Tpls&&... __tpls)
    -> typename __tuple_cat_result<_Tpls...>::__type
    {
      typedef typename __tuple_cat_result<_Tpls...>::__type __ret;
      typedef typename __make_1st_indices<_Tpls...>::__type __idx;
      typedef __tuple_concater<__ret, __idx, _Tpls...> __concater;
      return __concater::_S_do(std::forward<_Tpls>(__tpls)...);
    }




  template<typename... _Elements>
    constexpr tuple<_Elements&...>
    tie(_Elements&... __args) noexcept
    { return tuple<_Elements&...>(__args...); }


  template<typename... _Elements>
    constexpr
    inline


    typename enable_if<__and_<__is_swappable<_Elements>...>::value
      >::type



    swap(tuple<_Elements...>& __x, tuple<_Elements...>& __y)
    noexcept(noexcept(__x.swap(__y)))
    { __x.swap(__y); }
# 2848 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
  template<typename... _Elements>
    constexpr
    typename enable_if<!__and_<__is_swappable<_Elements>...>::value>::type
    swap(tuple<_Elements...>&, tuple<_Elements...>&) = delete;



  template<typename... _Types, typename _Alloc>
    struct uses_allocator<tuple<_Types...>, _Alloc> : true_type { };
# 2867 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3
  template<class _T1, class _T2>
    template<typename... _Args1, typename... _Args2>
      constexpr
      inline
      pair<_T1, _T2>::
      pair(piecewise_construct_t,
    tuple<_Args1...> __first, tuple<_Args2...> __second)
      : pair(__first, __second,
      typename _Build_index_tuple<sizeof...(_Args1)>::__type(),
      typename _Build_index_tuple<sizeof...(_Args2)>::__type())
      { }

  template<class _T1, class _T2>
    template<typename... _Args1, size_t... _Indexes1,
      typename... _Args2, size_t... _Indexes2>
      constexpr inline
      pair<_T1, _T2>::
      pair(tuple<_Args1...>& __tuple1, tuple<_Args2...>& __tuple2,
    _Index_tuple<_Indexes1...>, _Index_tuple<_Indexes2...>)
      : first(std::forward<_Args1>(std::get<_Indexes1>(__tuple1))...),
 second(std::forward<_Args2>(std::get<_Indexes2>(__tuple2))...)
      { }






  template<template<typename...> class _Trait, typename _Tp, typename _Tuple>
    inline constexpr bool __unpack_std_tuple = false;

  template<template<typename...> class _Trait, typename _Tp, typename... _Up>
    inline constexpr bool __unpack_std_tuple<_Trait, _Tp, tuple<_Up...>>
      = _Trait<_Tp, _Up...>::value;

  template<template<typename...> class _Trait, typename _Tp, typename... _Up>
    inline constexpr bool __unpack_std_tuple<_Trait, _Tp, tuple<_Up...>&>
      = _Trait<_Tp, _Up&...>::value;

  template<template<typename...> class _Trait, typename _Tp, typename... _Up>
    inline constexpr bool __unpack_std_tuple<_Trait, _Tp, const tuple<_Up...>>
      = _Trait<_Tp, const _Up...>::value;

  template<template<typename...> class _Trait, typename _Tp, typename... _Up>
    inline constexpr bool __unpack_std_tuple<_Trait, _Tp, const tuple<_Up...>&>
      = _Trait<_Tp, const _Up&...>::value;



  template <typename _Fn, typename _Tuple, size_t... _Idx>
    constexpr decltype(auto)
    __apply_impl(_Fn&& __f, _Tuple&& __t, index_sequence<_Idx...>)
    {
      return std::__invoke(std::forward<_Fn>(__f),
      std::get<_Idx>(std::forward<_Tuple>(__t))...);
    }




  template <typename _Fn, typename _Tuple>

    constexpr decltype(auto)
    apply(_Fn&& __f, _Tuple&& __t)
    noexcept(__unpack_std_tuple<is_nothrow_invocable, _Fn, _Tuple>)
    {
      using _Indices
 = make_index_sequence<tuple_size_v<remove_reference_t<_Tuple>>>;
      return std::__apply_impl(std::forward<_Fn>(__f),
          std::forward<_Tuple>(__t),
          _Indices{});
    }



  template <typename _Tp, typename _Tuple, size_t... _Idx>
    constexpr _Tp
    __make_from_tuple_impl(_Tuple&& __t, index_sequence<_Idx...>)
    { return _Tp(std::get<_Idx>(std::forward<_Tuple>(__t))...); }




  template <typename _Tp, typename _Tuple>

    constexpr _Tp
    make_from_tuple(_Tuple&& __t)
    noexcept(__unpack_std_tuple<is_nothrow_constructible, _Tp, _Tuple>)
    {
      constexpr size_t __n = tuple_size_v<remove_reference_t<_Tuple>>;

      if constexpr (__n == 1)
 {
   using _Elt = decltype(std::get<0>(std::declval<_Tuple>()));
   static_assert(!__reference_constructs_from_temporary(_Tp, _Elt));
 }

      return __make_from_tuple_impl<_Tp>(std::forward<_Tuple>(__t),
      make_index_sequence<__n>{});
    }
# 3029 "C:/msys64/mingw64/include/c++/15.2.0/tuple" 3

}
# 43 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 2 3


# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 1 3
# 39 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/ratio" 1 3
# 45 "C:/msys64/mingw64/include/c++/15.2.0/ratio" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 46 "C:/msys64/mingw64/include/c++/15.2.0/ratio" 2 3

namespace std
{

# 61 "C:/msys64/mingw64/include/c++/15.2.0/ratio" 3
  template<intmax_t _Pn>
    struct __static_sign
    : integral_constant<intmax_t, (_Pn < 0) ? -1 : 1>
    { };

  template<intmax_t _Pn>
    struct __static_abs
    : integral_constant<intmax_t, _Pn * __static_sign<_Pn>::value>
    { };

  template<intmax_t _Pn, intmax_t _Qn>
    struct __static_gcd
    : __static_gcd<_Qn, (_Pn % _Qn)>
    { };

  template<intmax_t _Pn>
    struct __static_gcd<_Pn, 0>
    : integral_constant<intmax_t, __static_abs<_Pn>::value>
    { };

  template<intmax_t _Qn>
    struct __static_gcd<0, _Qn>
    : integral_constant<intmax_t, __static_abs<_Qn>::value>
    { };







  template<intmax_t _Pn, intmax_t _Qn>
    struct __safe_multiply
    {
    private:
      static const uintmax_t __c = uintmax_t(1) << (sizeof(intmax_t) * 4);

      static const uintmax_t __a0 = __static_abs<_Pn>::value % __c;
      static const uintmax_t __a1 = __static_abs<_Pn>::value / __c;
      static const uintmax_t __b0 = __static_abs<_Qn>::value % __c;
      static const uintmax_t __b1 = __static_abs<_Qn>::value / __c;

      static_assert(__a1 == 0 || __b1 == 0,
      "overflow in multiplication");
      static_assert(__a0 * __b1 + __b0 * __a1 < (__c >> 1),
      "overflow in multiplication");
      static_assert(__b0 * __a0 <= 0x7fffffffffffffffLL,
      "overflow in multiplication");
      static_assert((__a0 * __b1 + __b0 * __a1) * __c
      <= 0x7fffffffffffffffLL - __b0 * __a0,
      "overflow in multiplication");

    public:
      static const intmax_t value = _Pn * _Qn;
    };



  template<uintmax_t __hi1, uintmax_t __lo1, uintmax_t __hi2, uintmax_t __lo2>
    struct __big_less
    : integral_constant<bool, (__hi1 < __hi2
          || (__hi1 == __hi2 && __lo1 < __lo2))>
    { };

  template<uintmax_t __hi1, uintmax_t __lo1, uintmax_t __hi2, uintmax_t __lo2>
    struct __big_add
    {
      static constexpr uintmax_t __lo = __lo1 + __lo2;
      static constexpr uintmax_t __hi = (__hi1 + __hi2 +
      (__lo1 + __lo2 < __lo1));
    };


  template<uintmax_t __hi1, uintmax_t __lo1, uintmax_t __hi2, uintmax_t __lo2>
    struct __big_sub
    {
      static_assert(!__big_less<__hi1, __lo1, __hi2, __lo2>::value,
      "Internal library error");
      static constexpr uintmax_t __lo = __lo1 - __lo2;
      static constexpr uintmax_t __hi = (__hi1 - __hi2 -
      (__lo1 < __lo2));
    };


  template<uintmax_t __x, uintmax_t __y>
    struct __big_mul
    {
    private:
      static constexpr uintmax_t __c = uintmax_t(1) << (sizeof(intmax_t) * 4);
      static constexpr uintmax_t __x0 = __x % __c;
      static constexpr uintmax_t __x1 = __x / __c;
      static constexpr uintmax_t __y0 = __y % __c;
      static constexpr uintmax_t __y1 = __y / __c;
      static constexpr uintmax_t __x0y0 = __x0 * __y0;
      static constexpr uintmax_t __x0y1 = __x0 * __y1;
      static constexpr uintmax_t __x1y0 = __x1 * __y0;
      static constexpr uintmax_t __x1y1 = __x1 * __y1;
      static constexpr uintmax_t __mix = __x0y1 + __x1y0;
      static constexpr uintmax_t __mix_lo = __mix * __c;
      static constexpr uintmax_t __mix_hi
      = __mix / __c + ((__mix < __x0y1) ? __c : 0);
      typedef __big_add<__mix_hi, __mix_lo, __x1y1, __x0y0> _Res;
    public:
      static constexpr uintmax_t __hi = _Res::__hi;
      static constexpr uintmax_t __lo = _Res::__lo;
    };



  template<uintmax_t __n1, uintmax_t __n0, uintmax_t __d>
    struct __big_div_impl
    {
    private:
      static_assert(__d >= (uintmax_t(1) << (sizeof(intmax_t) * 8 - 1)),
      "Internal library error");
      static_assert(__n1 < __d, "Internal library error");
      static constexpr uintmax_t __c = uintmax_t(1) << (sizeof(intmax_t) * 4);
      static constexpr uintmax_t __d1 = __d / __c;
      static constexpr uintmax_t __d0 = __d % __c;

      static constexpr uintmax_t __q1x = __n1 / __d1;
      static constexpr uintmax_t __r1x = __n1 % __d1;
      static constexpr uintmax_t __m = __q1x * __d0;
      static constexpr uintmax_t __r1y = __r1x * __c + __n0 / __c;
      static constexpr uintmax_t __r1z = __r1y + __d;
      static constexpr uintmax_t __r1
      = ((__r1y < __m) ? ((__r1z >= __d) && (__r1z < __m))
  ? (__r1z + __d) : __r1z : __r1y) - __m;
      static constexpr uintmax_t __q1
      = __q1x - ((__r1y < __m)
   ? ((__r1z >= __d) && (__r1z < __m)) ? 2 : 1 : 0);
      static constexpr uintmax_t __q0x = __r1 / __d1;
      static constexpr uintmax_t __r0x = __r1 % __d1;
      static constexpr uintmax_t __n = __q0x * __d0;
      static constexpr uintmax_t __r0y = __r0x * __c + __n0 % __c;
      static constexpr uintmax_t __r0z = __r0y + __d;
      static constexpr uintmax_t __r0
      = ((__r0y < __n) ? ((__r0z >= __d) && (__r0z < __n))
  ? (__r0z + __d) : __r0z : __r0y) - __n;
      static constexpr uintmax_t __q0
      = __q0x - ((__r0y < __n) ? ((__r0z >= __d)
      && (__r0z < __n)) ? 2 : 1 : 0);

    public:
      static constexpr uintmax_t __quot = __q1 * __c + __q0;
      static constexpr uintmax_t __rem = __r0;

    private:
      typedef __big_mul<__quot, __d> _Prod;
      typedef __big_add<_Prod::__hi, _Prod::__lo, 0, __rem> _Sum;
      static_assert(_Sum::__hi == __n1 && _Sum::__lo == __n0,
      "Internal library error");
  };

  template<uintmax_t __n1, uintmax_t __n0, uintmax_t __d>
    struct __big_div
    {
    private:
      static_assert(__d != 0, "Internal library error");
      static_assert(sizeof (uintmax_t) == sizeof (unsigned long long),
      "This library calls __builtin_clzll on uintmax_t, which "
      "is unsafe on your platform. Please complain to "
      "http://gcc.gnu.org/bugzilla/");
      static constexpr int __shift = __builtin_clzll(__d);
      static constexpr int __coshift_ = sizeof(uintmax_t) * 8 - __shift;
      static constexpr int __coshift = (__shift != 0) ? __coshift_ : 0;
      static constexpr uintmax_t __c1 = uintmax_t(1) << __shift;
      static constexpr uintmax_t __c2 = uintmax_t(1) << __coshift;
      static constexpr uintmax_t __new_d = __d * __c1;
      static constexpr uintmax_t __new_n0 = __n0 * __c1;
      static constexpr uintmax_t __n1_shifted = (__n1 % __d) * __c1;
      static constexpr uintmax_t __n0_top = (__shift != 0) ? (__n0 / __c2) : 0;
      static constexpr uintmax_t __new_n1 = __n1_shifted + __n0_top;
      typedef __big_div_impl<__new_n1, __new_n0, __new_d> _Res;

    public:
      static constexpr uintmax_t __quot_hi = __n1 / __d;
      static constexpr uintmax_t __quot_lo = _Res::__quot;
      static constexpr uintmax_t __rem = _Res::__rem / __c1;

    private:
      typedef __big_mul<__quot_lo, __d> _P0;
      typedef __big_mul<__quot_hi, __d> _P1;
      typedef __big_add<_P0::__hi, _P0::__lo, _P1::__lo, __rem> _Sum;

      static_assert(_P1::__hi == 0, "Internal library error");
      static_assert(_Sum::__hi >= _P0::__hi, "Internal library error");

      static_assert(_Sum::__hi == __n1 && _Sum::__lo == __n0,
      "Internal library error");
      static_assert(__rem < __d, "Internal library error");
    };
# 270 "C:/msys64/mingw64/include/c++/15.2.0/ratio" 3
  template<intmax_t _Num, intmax_t _Den = 1>
    struct ratio
    {
      static_assert(_Den != 0, "denominator cannot be zero");
      static_assert(_Num >= -0x7fffffffffffffffLL && _Den >= -0x7fffffffffffffffLL,
      "out of range");


      static constexpr intmax_t num =
        _Num * __static_sign<_Den>::value / __static_gcd<_Num, _Den>::value;

      static constexpr intmax_t den =
        __static_abs<_Den>::value / __static_gcd<_Num, _Den>::value;

      typedef ratio<num, den> type;
    };
# 297 "C:/msys64/mingw64/include/c++/15.2.0/ratio" 3
  template<typename _Tp>
    struct __is_ratio
    : std::false_type
    { };

  template<intmax_t _Num, intmax_t _Den>
    struct __is_ratio<ratio<_Num, _Den>>
    : std::true_type
    { };


  template<typename _Tp>
    constexpr bool __is_ratio_v = false;
  template<intmax_t _Num, intmax_t _Den>
    constexpr bool __is_ratio_v<ratio<_Num, _Den>> = true;


  template<typename _R1, typename _R2>
    constexpr bool
    __are_both_ratios() noexcept
    {

      if constexpr (__is_ratio_v<_R1>)
 if constexpr (__is_ratio_v<_R2>)
   return true;
      return false;



    }

  template<typename _R1, typename _R2>
    struct __ratio_multiply
    {
      static_assert(std::__are_both_ratios<_R1, _R2>(),
      "both template arguments must be a std::ratio");

    private:
      static const intmax_t __gcd1 =
        __static_gcd<_R1::num, _R2::den>::value;
      static const intmax_t __gcd2 =
        __static_gcd<_R2::num, _R1::den>::value;

    public:
      typedef ratio<
        __safe_multiply<(_R1::num / __gcd1),
                        (_R2::num / __gcd2)>::value,
        __safe_multiply<(_R1::den / __gcd2),
                        (_R2::den / __gcd1)>::value> type;

      static constexpr intmax_t num = type::num;
      static constexpr intmax_t den = type::den;
    };
# 362 "C:/msys64/mingw64/include/c++/15.2.0/ratio" 3
  template<typename _R1, typename _R2>
    using ratio_multiply = typename __ratio_multiply<_R1, _R2>::type;



  template<typename _R1, typename _R2>
    struct __ratio_divide
    {
      static_assert(_R2::num != 0, "division by 0");

      typedef typename __ratio_multiply<
        _R1,
        ratio<_R2::den, _R2::num>>::type type;

      static constexpr intmax_t num = type::num;
      static constexpr intmax_t den = type::den;
    };
# 391 "C:/msys64/mingw64/include/c++/15.2.0/ratio" 3
  template<typename _R1, typename _R2>
    using ratio_divide = typename __ratio_divide<_R1, _R2>::type;


  template<typename _R1, typename _R2>
    struct ratio_equal
    : integral_constant<bool, _R1::num == _R2::num && _R1::den == _R2::den>
    {
      static_assert(std::__are_both_ratios<_R1, _R2>(),
      "both template arguments must be a std::ratio");
    };


  template<typename _R1, typename _R2>
    struct ratio_not_equal
    : integral_constant<bool, !ratio_equal<_R1, _R2>::value>
    { };




  template<typename _R1, typename _R2,
           typename _Left = __big_mul<_R1::num,_R2::den>,
           typename _Right = __big_mul<_R2::num,_R1::den> >
    struct __ratio_less_impl_1
    : integral_constant<bool, __big_less<_Left::__hi, _Left::__lo,
           _Right::__hi, _Right::__lo>::value>
    { };

  template<typename _R1, typename _R2,
    bool = (_R1::num == 0 || _R2::num == 0
     || (__static_sign<_R1::num>::value
         != __static_sign<_R2::num>::value)),
    bool = (__static_sign<_R1::num>::value == -1
     && __static_sign<_R2::num>::value == -1)>
    struct __ratio_less_impl
    : __ratio_less_impl_1<_R1, _R2>::type
    { };

  template<typename _R1, typename _R2>
    struct __ratio_less_impl<_R1, _R2, true, false>
    : integral_constant<bool, _R1::num < _R2::num>
    { };

  template<typename _R1, typename _R2>
    struct __ratio_less_impl<_R1, _R2, false, true>
    : __ratio_less_impl_1<ratio<-_R2::num, _R2::den>,
           ratio<-_R1::num, _R1::den> >::type
    { };




  template<typename _R1, typename _R2>
    struct ratio_less
    : __ratio_less_impl<_R1, _R2>::type
    {
      static_assert(std::__are_both_ratios<_R1, _R2>(),
      "both template arguments must be a std::ratio");
    };


  template<typename _R1, typename _R2>
    struct ratio_less_equal
    : integral_constant<bool, !ratio_less<_R2, _R1>::value>
    { };


  template<typename _R1, typename _R2>
    struct ratio_greater
    : integral_constant<bool, ratio_less<_R2, _R1>::value>
    { };


  template<typename _R1, typename _R2>
    struct ratio_greater_equal
    : integral_constant<bool, !ratio_less<_R1, _R2>::value>
    { };


  template <typename _R1, typename _R2>
    inline constexpr bool ratio_equal_v = ratio_equal<_R1, _R2>::value;
  template <typename _R1, typename _R2>
    inline constexpr bool ratio_not_equal_v = ratio_not_equal<_R1, _R2>::value;
  template <typename _R1, typename _R2>
    inline constexpr bool ratio_less_v = ratio_less<_R1, _R2>::value;
  template <typename _R1, typename _R2>
    inline constexpr bool ratio_less_equal_v
      = ratio_less_equal<_R1, _R2>::value;
  template <typename _R1, typename _R2>
    inline constexpr bool ratio_greater_v = ratio_greater<_R1, _R2>::value;
  template <typename _R1, typename _R2>
    inline constexpr bool ratio_greater_equal_v
      = ratio_greater_equal<_R1, _R2>::value;




  template<typename _R1, typename _R2,
      bool = (_R1::num >= 0),
      bool = (_R2::num >= 0),
      bool = ratio_less<ratio<__static_abs<_R1::num>::value, _R1::den>,
        ratio<__static_abs<_R2::num>::value, _R2::den> >::value>
    struct __ratio_add_impl
    {
    private:
      typedef typename __ratio_add_impl<
        ratio<-_R1::num, _R1::den>,
        ratio<-_R2::num, _R2::den> >::type __t;
    public:
      typedef ratio<-__t::num, __t::den> type;
    };


  template<typename _R1, typename _R2, bool __b>
    struct __ratio_add_impl<_R1, _R2, true, true, __b>
    {
    private:
      static constexpr uintmax_t __g = __static_gcd<_R1::den, _R2::den>::value;
      static constexpr uintmax_t __d2 = _R2::den / __g;
      typedef __big_mul<_R1::den, __d2> __d;
      typedef __big_mul<_R1::num, _R2::den / __g> __x;
      typedef __big_mul<_R2::num, _R1::den / __g> __y;
      typedef __big_add<__x::__hi, __x::__lo, __y::__hi, __y::__lo> __n;
      static_assert(__n::__hi >= __x::__hi, "Internal library error");
      typedef __big_div<__n::__hi, __n::__lo, __g> __ng;
      static constexpr uintmax_t __g2 = __static_gcd<__ng::__rem, __g>::value;
      typedef __big_div<__n::__hi, __n::__lo, __g2> __n_final;
      static_assert(__n_final::__rem == 0, "Internal library error");
      static_assert(__n_final::__quot_hi == 0 &&
        __n_final::__quot_lo <= 0x7fffffffffffffffLL, "overflow in addition");
      typedef __big_mul<_R1::den / __g2, __d2> __d_final;
      static_assert(__d_final::__hi == 0 &&
        __d_final::__lo <= 0x7fffffffffffffffLL, "overflow in addition");
    public:
      typedef ratio<__n_final::__quot_lo, __d_final::__lo> type;
    };

  template<typename _R1, typename _R2>
    struct __ratio_add_impl<_R1, _R2, false, true, true>
    : __ratio_add_impl<_R2, _R1>
    { };


  template<typename _R1, typename _R2>
    struct __ratio_add_impl<_R1, _R2, true, false, false>
    {
    private:
      static constexpr uintmax_t __g = __static_gcd<_R1::den, _R2::den>::value;
      static constexpr uintmax_t __d2 = _R2::den / __g;
      typedef __big_mul<_R1::den, __d2> __d;
      typedef __big_mul<_R1::num, _R2::den / __g> __x;
      typedef __big_mul<-_R2::num, _R1::den / __g> __y;
      typedef __big_sub<__x::__hi, __x::__lo, __y::__hi, __y::__lo> __n;
      typedef __big_div<__n::__hi, __n::__lo, __g> __ng;
      static constexpr uintmax_t __g2 = __static_gcd<__ng::__rem, __g>::value;
      typedef __big_div<__n::__hi, __n::__lo, __g2> __n_final;
      static_assert(__n_final::__rem == 0, "Internal library error");
      static_assert(__n_final::__quot_hi == 0 &&
        __n_final::__quot_lo <= 0x7fffffffffffffffLL, "overflow in addition");
      typedef __big_mul<_R1::den / __g2, __d2> __d_final;
      static_assert(__d_final::__hi == 0 &&
        __d_final::__lo <= 0x7fffffffffffffffLL, "overflow in addition");
    public:
      typedef ratio<__n_final::__quot_lo, __d_final::__lo> type;
    };

  template<typename _R1, typename _R2>
    struct __ratio_add
    {
      static_assert(std::__are_both_ratios<_R1, _R2>(),
      "both template arguments must be a std::ratio");

      typedef typename __ratio_add_impl<_R1, _R2>::type type;
      static constexpr intmax_t num = type::num;
      static constexpr intmax_t den = type::den;
    };
# 580 "C:/msys64/mingw64/include/c++/15.2.0/ratio" 3
  template<typename _R1, typename _R2>
    using ratio_add = typename __ratio_add<_R1, _R2>::type;



  template<typename _R1, typename _R2>
    struct __ratio_subtract
    {
      typedef typename __ratio_add<
        _R1,
        ratio<-_R2::num, _R2::den>>::type type;

      static constexpr intmax_t num = type::num;
      static constexpr intmax_t den = type::den;
    };
# 607 "C:/msys64/mingw64/include/c++/15.2.0/ratio" 3
  template<typename _R1, typename _R2>
    using ratio_subtract = typename __ratio_subtract<_R1, _R2>::type;
# 620 "C:/msys64/mingw64/include/c++/15.2.0/ratio" 3
  using atto = ratio< 1, 1000000000000000000>;
  using femto = ratio< 1, 1000000000000000>;
  using pico = ratio< 1, 1000000000000>;
  using nano = ratio< 1, 1000000000>;
  using micro = ratio< 1, 1000000>;
  using milli = ratio< 1, 1000>;
  using centi = ratio< 1, 100>;
  using deci = ratio< 1, 10>;
  using deca = ratio< 10, 1>;
  using hecto = ratio< 100, 1>;
  using kilo = ratio< 1000, 1>;
  using mega = ratio< 1000000, 1>;
  using giga = ratio< 1000000000, 1>;
  using tera = ratio< 1000000000000, 1>;
  using peta = ratio< 1000000000000000, 1>;
  using exa = ratio< 1000000000000000000, 1>;
# 648 "C:/msys64/mingw64/include/c++/15.2.0/ratio" 3

}
# 40 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 2 3

# 1 "C:/msys64/mingw64/include/c++/15.2.0/limits" 1 3
# 44 "C:/msys64/mingw64/include/c++/15.2.0/limits" 3
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wpedantic"
#pragma GCC diagnostic ignored "-Wlong-long"
#pragma GCC diagnostic ignored "-Wc++23-extensions"
# 165 "C:/msys64/mingw64/include/c++/15.2.0/limits" 3
namespace std
{







  enum float_round_style
  {
    round_indeterminate = -1,
    round_toward_zero = 0,
    round_to_nearest = 1,
    round_toward_infinity = 2,
    round_toward_neg_infinity = 3
  };







  enum float_denorm_style
  {

    denorm_indeterminate = -1,

    denorm_absent = 0,

    denorm_present = 1
  };
# 209 "C:/msys64/mingw64/include/c++/15.2.0/limits" 3
  struct __numeric_limits_base
  {


    static constexpr bool is_specialized = false;




    static constexpr int digits = 0;


    static constexpr int digits10 = 0;




    static constexpr int max_digits10 = 0;



    static constexpr bool is_signed = false;


    static constexpr bool is_integer = false;




    static constexpr bool is_exact = false;



    static constexpr int radix = 0;



    static constexpr int min_exponent = 0;



    static constexpr int min_exponent10 = 0;




    static constexpr int max_exponent = 0;



    static constexpr int max_exponent10 = 0;


    static constexpr bool has_infinity = false;



    static constexpr bool has_quiet_NaN = false;



    static constexpr bool has_signaling_NaN = false;


    static constexpr float_denorm_style has_denorm = denorm_absent;



    static constexpr bool has_denorm_loss = false;



    static constexpr bool is_iec559 = false;




    static constexpr bool is_bounded = false;
# 295 "C:/msys64/mingw64/include/c++/15.2.0/limits" 3
    static constexpr bool is_modulo = false;


    static constexpr bool traps = false;


    static constexpr bool tinyness_before = false;




    static constexpr float_round_style round_style =
          round_toward_zero;
  };
# 318 "C:/msys64/mingw64/include/c++/15.2.0/limits" 3
  template<typename _Tp>
    struct numeric_limits : public __numeric_limits_base
    {


      static constexpr _Tp
      min() noexcept { return _Tp(); }


      static constexpr _Tp
      max() noexcept { return _Tp(); }




      static constexpr _Tp
      lowest() noexcept { return _Tp(); }




      static constexpr _Tp
      epsilon() noexcept { return _Tp(); }


      static constexpr _Tp
      round_error() noexcept { return _Tp(); }


      static constexpr _Tp
      infinity() noexcept { return _Tp(); }



      static constexpr _Tp
      quiet_NaN() noexcept { return _Tp(); }



      static constexpr _Tp
      signaling_NaN() noexcept { return _Tp(); }




      static constexpr _Tp
      denorm_min() noexcept { return _Tp(); }
    };




  template<typename _Tp>
    struct numeric_limits<const _Tp>
    : public numeric_limits<_Tp> { };

  template<typename _Tp>
    struct numeric_limits<volatile _Tp>
    : public numeric_limits<_Tp> { };

  template<typename _Tp>
    struct numeric_limits<const volatile _Tp>
    : public numeric_limits<_Tp> { };
# 390 "C:/msys64/mingw64/include/c++/15.2.0/limits" 3
  template<>
    struct numeric_limits<bool>
    {
      static constexpr bool is_specialized = true;

      static constexpr bool
      min() noexcept { return false; }

      static constexpr bool
      max() noexcept { return true; }


      static constexpr bool
      lowest() noexcept { return min(); }

      static constexpr int digits = 1;
      static constexpr int digits10 = 0;

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = false;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr bool
      epsilon() noexcept { return false; }

      static constexpr bool
      round_error() noexcept { return false; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr bool
      infinity() noexcept { return false; }

      static constexpr bool
      quiet_NaN() noexcept { return false; }

      static constexpr bool
      signaling_NaN() noexcept { return false; }

      static constexpr bool
      denorm_min() noexcept { return false; }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;




      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<char>
    {
      static constexpr bool is_specialized = true;

      static constexpr char
      min() noexcept { return (((char)(-1) < 0) ? -(((char)(-1) < 0) ? (((((char)1 << ((sizeof(char) * 8 - ((char)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(char)0) - 1 : (char)0); }

      static constexpr char
      max() noexcept { return (((char)(-1) < 0) ? (((((char)1 << ((sizeof(char) * 8 - ((char)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(char)0); }


      static constexpr char
      lowest() noexcept { return min(); }


      static constexpr int digits = (sizeof(char) * 8 - ((char)(-1) < 0));
      static constexpr int digits10 = ((sizeof(char) * 8 - ((char)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = ((char)(-1) < 0);
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr char
      epsilon() noexcept { return 0; }

      static constexpr char
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr
      char infinity() noexcept { return char(); }

      static constexpr char
      quiet_NaN() noexcept { return char(); }

      static constexpr char
      signaling_NaN() noexcept { return char(); }

      static constexpr char
      denorm_min() noexcept { return static_cast<char>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = !is_signed;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<signed char>
    {
      static constexpr bool is_specialized = true;

      static constexpr signed char
      min() noexcept { return -0x7f - 1; }

      static constexpr signed char
      max() noexcept { return 0x7f; }


      static constexpr signed char
      lowest() noexcept { return min(); }


      static constexpr int digits = (sizeof(signed char) * 8 - ((signed char)(-1) < 0));
      static constexpr int digits10
       = ((sizeof(signed char) * 8 - ((signed char)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = true;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr signed char
      epsilon() noexcept { return 0; }

      static constexpr signed char
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr signed char
      infinity() noexcept { return static_cast<signed char>(0); }

      static constexpr signed char
      quiet_NaN() noexcept { return static_cast<signed char>(0); }

      static constexpr signed char
      signaling_NaN() noexcept
      { return static_cast<signed char>(0); }

      static constexpr signed char
      denorm_min() noexcept
      { return static_cast<signed char>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<unsigned char>
    {
      static constexpr bool is_specialized = true;

      static constexpr unsigned char
      min() noexcept { return 0; }

      static constexpr unsigned char
      max() noexcept { return 0x7f * 2U + 1; }


      static constexpr unsigned char
      lowest() noexcept { return min(); }


      static constexpr int digits
       = (sizeof(unsigned char) * 8 - ((unsigned char)(-1) < 0));
      static constexpr int digits10
       = ((sizeof(unsigned char) * 8 - ((unsigned char)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = false;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr unsigned char
      epsilon() noexcept { return 0; }

      static constexpr unsigned char
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr unsigned char
      infinity() noexcept
      { return static_cast<unsigned char>(0); }

      static constexpr unsigned char
      quiet_NaN() noexcept
      { return static_cast<unsigned char>(0); }

      static constexpr unsigned char
      signaling_NaN() noexcept
      { return static_cast<unsigned char>(0); }

      static constexpr unsigned char
      denorm_min() noexcept
      { return static_cast<unsigned char>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = true;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<wchar_t>
    {
      static constexpr bool is_specialized = true;

      static constexpr wchar_t
      min() noexcept { return (((wchar_t)(-1) < 0) ? -(((wchar_t)(-1) < 0) ? (((((wchar_t)1 << ((sizeof(wchar_t) * 8 - ((wchar_t)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(wchar_t)0) - 1 : (wchar_t)0); }

      static constexpr wchar_t
      max() noexcept { return (((wchar_t)(-1) < 0) ? (((((wchar_t)1 << ((sizeof(wchar_t) * 8 - ((wchar_t)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(wchar_t)0); }


      static constexpr wchar_t
      lowest() noexcept { return min(); }


      static constexpr int digits = (sizeof(wchar_t) * 8 - ((wchar_t)(-1) < 0));
      static constexpr int digits10
       = ((sizeof(wchar_t) * 8 - ((wchar_t)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = ((wchar_t)(-1) < 0);
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr wchar_t
      epsilon() noexcept { return 0; }

      static constexpr wchar_t
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr wchar_t
      infinity() noexcept { return wchar_t(); }

      static constexpr wchar_t
      quiet_NaN() noexcept { return wchar_t(); }

      static constexpr wchar_t
      signaling_NaN() noexcept { return wchar_t(); }

      static constexpr wchar_t
      denorm_min() noexcept { return wchar_t(); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = !is_signed;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };



  template<>
    struct numeric_limits<char8_t>
    {
      static constexpr bool is_specialized = true;

      static constexpr char8_t
      min() noexcept { return (((char8_t)(-1) < 0) ? -(((char8_t)(-1) < 0) ? (((((char8_t)1 << ((sizeof(char8_t) * 8 - ((char8_t)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(char8_t)0) - 1 : (char8_t)0); }

      static constexpr char8_t
      max() noexcept { return (((char8_t)(-1) < 0) ? (((((char8_t)1 << ((sizeof(char8_t) * 8 - ((char8_t)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(char8_t)0); }

      static constexpr char8_t
      lowest() noexcept { return min(); }

      static constexpr int digits = (sizeof(char8_t) * 8 - ((char8_t)(-1) < 0));
      static constexpr int digits10 = ((sizeof(char8_t) * 8 - ((char8_t)(-1) < 0)) * 643L / 2136);
      static constexpr int max_digits10 = 0;
      static constexpr bool is_signed = ((char8_t)(-1) < 0);
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr char8_t
      epsilon() noexcept { return 0; }

      static constexpr char8_t
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
 = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr char8_t
      infinity() noexcept { return char8_t(); }

      static constexpr char8_t
      quiet_NaN() noexcept { return char8_t(); }

      static constexpr char8_t
      signaling_NaN() noexcept { return char8_t(); }

      static constexpr char8_t
      denorm_min() noexcept { return char8_t(); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = !is_signed;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
 = round_toward_zero;
    };




  template<>
    struct numeric_limits<char16_t>
    {
      static constexpr bool is_specialized = true;

      static constexpr char16_t
      min() noexcept { return (((char16_t)(-1) < 0) ? -(((char16_t)(-1) < 0) ? (((((char16_t)1 << ((sizeof(char16_t) * 8 - ((char16_t)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(char16_t)0) - 1 : (char16_t)0); }

      static constexpr char16_t
      max() noexcept { return (((char16_t)(-1) < 0) ? (((((char16_t)1 << ((sizeof(char16_t) * 8 - ((char16_t)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(char16_t)0); }

      static constexpr char16_t
      lowest() noexcept { return min(); }

      static constexpr int digits = (sizeof(char16_t) * 8 - ((char16_t)(-1) < 0));
      static constexpr int digits10 = ((sizeof(char16_t) * 8 - ((char16_t)(-1) < 0)) * 643L / 2136);
      static constexpr int max_digits10 = 0;
      static constexpr bool is_signed = ((char16_t)(-1) < 0);
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr char16_t
      epsilon() noexcept { return 0; }

      static constexpr char16_t
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr char16_t
      infinity() noexcept { return char16_t(); }

      static constexpr char16_t
      quiet_NaN() noexcept { return char16_t(); }

      static constexpr char16_t
      signaling_NaN() noexcept { return char16_t(); }

      static constexpr char16_t
      denorm_min() noexcept { return char16_t(); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = !is_signed;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style = round_toward_zero;
    };


  template<>
    struct numeric_limits<char32_t>
    {
      static constexpr bool is_specialized = true;

      static constexpr char32_t
      min() noexcept { return (((char32_t)(-1) < 0) ? -(((char32_t)(-1) < 0) ? (((((char32_t)1 << ((sizeof(char32_t) * 8 - ((char32_t)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(char32_t)0) - 1 : (char32_t)0); }

      static constexpr char32_t
      max() noexcept { return (((char32_t)(-1) < 0) ? (((((char32_t)1 << ((sizeof(char32_t) * 8 - ((char32_t)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(char32_t)0); }

      static constexpr char32_t
      lowest() noexcept { return min(); }

      static constexpr int digits = (sizeof(char32_t) * 8 - ((char32_t)(-1) < 0));
      static constexpr int digits10 = ((sizeof(char32_t) * 8 - ((char32_t)(-1) < 0)) * 643L / 2136);
      static constexpr int max_digits10 = 0;
      static constexpr bool is_signed = ((char32_t)(-1) < 0);
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr char32_t
      epsilon() noexcept { return 0; }

      static constexpr char32_t
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr char32_t
      infinity() noexcept { return char32_t(); }

      static constexpr char32_t
      quiet_NaN() noexcept { return char32_t(); }

      static constexpr char32_t
      signaling_NaN() noexcept { return char32_t(); }

      static constexpr char32_t
      denorm_min() noexcept { return char32_t(); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = !is_signed;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style = round_toward_zero;
    };



  template<>
    struct numeric_limits<short>
    {
      static constexpr bool is_specialized = true;

      static constexpr short
      min() noexcept { return -0x7fff - 1; }

      static constexpr short
      max() noexcept { return 0x7fff; }


      static constexpr short
      lowest() noexcept { return min(); }


      static constexpr int digits = (sizeof(short) * 8 - ((short)(-1) < 0));
      static constexpr int digits10 = ((sizeof(short) * 8 - ((short)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = true;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr short
      epsilon() noexcept { return 0; }

      static constexpr short
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr short
      infinity() noexcept { return short(); }

      static constexpr short
      quiet_NaN() noexcept { return short(); }

      static constexpr short
      signaling_NaN() noexcept { return short(); }

      static constexpr short
      denorm_min() noexcept { return short(); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<unsigned short>
    {
      static constexpr bool is_specialized = true;

      static constexpr unsigned short
      min() noexcept { return 0; }

      static constexpr unsigned short
      max() noexcept { return 0x7fff * 2U + 1; }


      static constexpr unsigned short
      lowest() noexcept { return min(); }


      static constexpr int digits
       = (sizeof(unsigned short) * 8 - ((unsigned short)(-1) < 0));
      static constexpr int digits10
       = ((sizeof(unsigned short) * 8 - ((unsigned short)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = false;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr unsigned short
      epsilon() noexcept { return 0; }

      static constexpr unsigned short
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr unsigned short
      infinity() noexcept
      { return static_cast<unsigned short>(0); }

      static constexpr unsigned short
      quiet_NaN() noexcept
      { return static_cast<unsigned short>(0); }

      static constexpr unsigned short
      signaling_NaN() noexcept
      { return static_cast<unsigned short>(0); }

      static constexpr unsigned short
      denorm_min() noexcept
      { return static_cast<unsigned short>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = true;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<int>
    {
      static constexpr bool is_specialized = true;

      static constexpr int
      min() noexcept { return -0x7fffffff - 1; }

      static constexpr int
      max() noexcept { return 0x7fffffff; }


      static constexpr int
      lowest() noexcept { return min(); }


      static constexpr int digits = (sizeof(int) * 8 - ((int)(-1) < 0));
      static constexpr int digits10 = ((sizeof(int) * 8 - ((int)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = true;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr int
      epsilon() noexcept { return 0; }

      static constexpr int
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr int
      infinity() noexcept { return static_cast<int>(0); }

      static constexpr int
      quiet_NaN() noexcept { return static_cast<int>(0); }

      static constexpr int
      signaling_NaN() noexcept { return static_cast<int>(0); }

      static constexpr int
      denorm_min() noexcept { return static_cast<int>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<unsigned int>
    {
      static constexpr bool is_specialized = true;

      static constexpr unsigned int
      min() noexcept { return 0; }

      static constexpr unsigned int
      max() noexcept { return 0x7fffffff * 2U + 1; }


      static constexpr unsigned int
      lowest() noexcept { return min(); }


      static constexpr int digits
       = (sizeof(unsigned int) * 8 - ((unsigned int)(-1) < 0));
      static constexpr int digits10
       = ((sizeof(unsigned int) * 8 - ((unsigned int)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = false;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr unsigned int
      epsilon() noexcept { return 0; }

      static constexpr unsigned int
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr unsigned int
      infinity() noexcept { return static_cast<unsigned int>(0); }

      static constexpr unsigned int
      quiet_NaN() noexcept
      { return static_cast<unsigned int>(0); }

      static constexpr unsigned int
      signaling_NaN() noexcept
      { return static_cast<unsigned int>(0); }

      static constexpr unsigned int
      denorm_min() noexcept
      { return static_cast<unsigned int>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = true;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<long>
    {
      static constexpr bool is_specialized = true;

      static constexpr long
      min() noexcept { return -0x7fffffffL - 1; }

      static constexpr long
      max() noexcept { return 0x7fffffffL; }


      static constexpr long
      lowest() noexcept { return min(); }


      static constexpr int digits = (sizeof(long) * 8 - ((long)(-1) < 0));
      static constexpr int digits10 = ((sizeof(long) * 8 - ((long)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = true;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr long
      epsilon() noexcept { return 0; }

      static constexpr long
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr long
      infinity() noexcept { return static_cast<long>(0); }

      static constexpr long
      quiet_NaN() noexcept { return static_cast<long>(0); }

      static constexpr long
      signaling_NaN() noexcept { return static_cast<long>(0); }

      static constexpr long
      denorm_min() noexcept { return static_cast<long>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<unsigned long>
    {
      static constexpr bool is_specialized = true;

      static constexpr unsigned long
      min() noexcept { return 0; }

      static constexpr unsigned long
      max() noexcept { return 0x7fffffffL * 2UL + 1; }


      static constexpr unsigned long
      lowest() noexcept { return min(); }


      static constexpr int digits
       = (sizeof(unsigned long) * 8 - ((unsigned long)(-1) < 0));
      static constexpr int digits10
       = ((sizeof(unsigned long) * 8 - ((unsigned long)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = false;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr unsigned long
      epsilon() noexcept { return 0; }

      static constexpr unsigned long
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr unsigned long
      infinity() noexcept
      { return static_cast<unsigned long>(0); }

      static constexpr unsigned long
      quiet_NaN() noexcept
      { return static_cast<unsigned long>(0); }

      static constexpr unsigned long
      signaling_NaN() noexcept
      { return static_cast<unsigned long>(0); }

      static constexpr unsigned long
      denorm_min() noexcept
      { return static_cast<unsigned long>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = true;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<long long>
    {
      static constexpr bool is_specialized = true;

      static constexpr long long
      min() noexcept { return -0x7fffffffffffffffLL - 1; }

      static constexpr long long
      max() noexcept { return 0x7fffffffffffffffLL; }


      static constexpr long long
      lowest() noexcept { return min(); }


      static constexpr int digits
       = (sizeof(long long) * 8 - ((long long)(-1) < 0));
      static constexpr int digits10
       = ((sizeof(long long) * 8 - ((long long)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = true;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr long long
      epsilon() noexcept { return 0; }

      static constexpr long long
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr long long
      infinity() noexcept { return static_cast<long long>(0); }

      static constexpr long long
      quiet_NaN() noexcept { return static_cast<long long>(0); }

      static constexpr long long
      signaling_NaN() noexcept
      { return static_cast<long long>(0); }

      static constexpr long long
      denorm_min() noexcept { return static_cast<long long>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<unsigned long long>
    {
      static constexpr bool is_specialized = true;

      static constexpr unsigned long long
      min() noexcept { return 0; }

      static constexpr unsigned long long
      max() noexcept { return 0x7fffffffffffffffLL * 2ULL + 1; }


      static constexpr unsigned long long
      lowest() noexcept { return min(); }


      static constexpr int digits
       = (sizeof(unsigned long long) * 8 - ((unsigned long long)(-1) < 0));
      static constexpr int digits10
       = ((sizeof(unsigned long long) * 8 - ((unsigned long long)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = false;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr unsigned long long
      epsilon() noexcept { return 0; }

      static constexpr unsigned long long
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr unsigned long long
      infinity() noexcept
      { return static_cast<unsigned long long>(0); }

      static constexpr unsigned long long
      quiet_NaN() noexcept
      { return static_cast<unsigned long long>(0); }

      static constexpr unsigned long long
      signaling_NaN() noexcept
      { return static_cast<unsigned long long>(0); }

      static constexpr unsigned long long
      denorm_min() noexcept
      { return static_cast<unsigned long long>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = true;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };
# 1644 "C:/msys64/mingw64/include/c++/15.2.0/limits" 3
  __extension__ template<> struct numeric_limits<__int128> { static constexpr bool is_specialized = true; static constexpr __int128 min() noexcept { return (((__int128)(-1) < 0) ? -(((__int128)(-1) < 0) ? (((((__int128)1 << ((128 - ((__int128)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(__int128)0) - 1 : (__int128)0); } static constexpr __int128 max() noexcept { return (((__int128)(-1) < 0) ? (((((__int128)1 << ((128 - ((__int128)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(__int128)0); } static constexpr int digits = 128 - 1; static constexpr int digits10 = (128 - 1) * 643L / 2136; static constexpr bool is_signed = true; static constexpr bool is_integer = true; static constexpr bool is_exact = true; static constexpr int radix = 2; static constexpr __int128 epsilon() noexcept { return 0; } static constexpr __int128 round_error() noexcept { return 0; } static constexpr __int128 lowest() noexcept { return min(); } static constexpr int max_digits10 = 0; static constexpr int min_exponent = 0; static constexpr int min_exponent10 = 0; static constexpr int max_exponent = 0; static constexpr int max_exponent10 = 0; static constexpr bool has_infinity = false; static constexpr bool has_quiet_NaN = false; static constexpr bool has_signaling_NaN = false; static constexpr float_denorm_style has_denorm = denorm_absent; static constexpr bool has_denorm_loss = false; static constexpr __int128 infinity() noexcept { return static_cast<__int128>(0); } static constexpr __int128 quiet_NaN() noexcept { return static_cast<__int128>(0); } static constexpr __int128 signaling_NaN() noexcept { return static_cast<__int128>(0); } static constexpr __int128 denorm_min() noexcept { return static_cast<__int128>(0); } static constexpr bool is_iec559 = false; static constexpr bool is_bounded = true; static constexpr bool is_modulo = false; static constexpr bool traps = true; static constexpr bool tinyness_before = false; static constexpr float_round_style round_style = round_toward_zero; }; __extension__ template<> struct numeric_limits<unsigned __int128> { static constexpr bool is_specialized = true; static constexpr unsigned __int128 min() noexcept { return 0; } static constexpr unsigned __int128 max() noexcept { return (((unsigned __int128)(-1) < 0) ? (((((unsigned __int128)1 << ((128 - ((unsigned __int128)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(unsigned __int128)0); } static constexpr unsigned __int128 lowest() noexcept { return min(); } static constexpr int max_digits10 = 0; static constexpr int digits = 128; static constexpr int digits10 = 128 * 643L / 2136; static constexpr bool is_signed = false; static constexpr bool is_integer = true; static constexpr bool is_exact = true; static constexpr int radix = 2; static constexpr unsigned __int128 epsilon() noexcept { return 0; } static constexpr unsigned __int128 round_error() noexcept { return 0; } static constexpr int min_exponent = 0; static constexpr int min_exponent10 = 0; static constexpr int max_exponent = 0; static constexpr int max_exponent10 = 0; static constexpr bool has_infinity = false; static constexpr bool has_quiet_NaN = false; static constexpr bool has_signaling_NaN = false; static constexpr float_denorm_style has_denorm = denorm_absent; static constexpr bool has_denorm_loss = false; static constexpr unsigned __int128 infinity() noexcept { return static_cast<unsigned __int128>(0); } static constexpr unsigned __int128 quiet_NaN() noexcept { return static_cast<unsigned __int128>(0); } static constexpr unsigned __int128 signaling_NaN() noexcept { return static_cast<unsigned __int128>(0); } static constexpr unsigned __int128 denorm_min() noexcept { return static_cast<unsigned __int128>(0); } static constexpr bool is_iec559 = false; static constexpr bool is_bounded = true; static constexpr bool is_modulo = true; static constexpr bool traps = true; static constexpr bool tinyness_before = false; static constexpr float_round_style round_style = round_toward_zero; };
# 1676 "C:/msys64/mingw64/include/c++/15.2.0/limits" 3
  template<>
    struct numeric_limits<float>
    {
      static constexpr bool is_specialized = true;

      static constexpr float
      min() noexcept { return 1.17549435082228750796873653722224568e-38F; }

      static constexpr float
      max() noexcept { return 3.40282346638528859811704183484516925e+38F; }


      static constexpr float
      lowest() noexcept { return -3.40282346638528859811704183484516925e+38F; }


      static constexpr int digits = 24;
      static constexpr int digits10 = 6;

      static constexpr int max_digits10
  = (2 + (24) * 643L / 2136);

      static constexpr bool is_signed = true;
      static constexpr bool is_integer = false;
      static constexpr bool is_exact = false;
      static constexpr int radix = 2;

      static constexpr float
      epsilon() noexcept { return 1.19209289550781250000000000000000000e-7F; }

      static constexpr float
      round_error() noexcept { return 0.5F; }

      static constexpr int min_exponent = (-125);
      static constexpr int min_exponent10 = (-37);
      static constexpr int max_exponent = 128;
      static constexpr int max_exponent10 = 38;

      static constexpr bool has_infinity = 1;
      static constexpr bool has_quiet_NaN = 1;
      static constexpr bool has_signaling_NaN = has_quiet_NaN;
      static constexpr float_denorm_style has_denorm
 = bool(1) ? denorm_present : denorm_absent;
      static constexpr bool has_denorm_loss
       = false;

      static constexpr float
      infinity() noexcept { return __builtin_huge_valf(); }

      static constexpr float
      quiet_NaN() noexcept { return __builtin_nanf(""); }

      static constexpr float
      signaling_NaN() noexcept { return __builtin_nansf(""); }

      static constexpr float
      denorm_min() noexcept { return 1.40129846432481707092372958328991613e-45F; }

      static constexpr bool is_iec559
 = has_infinity && has_quiet_NaN && has_denorm == denorm_present;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;

      static constexpr bool traps = false;
      static constexpr bool tinyness_before
       = false;
      static constexpr float_round_style round_style
       = round_to_nearest;
    };






  template<>
    struct numeric_limits<double>
    {
      static constexpr bool is_specialized = true;

      static constexpr double
      min() noexcept { return double(2.22507385850720138309023271733240406e-308L); }

      static constexpr double
      max() noexcept { return double(1.79769313486231570814527423731704357e+308L); }


      static constexpr double
      lowest() noexcept { return -double(1.79769313486231570814527423731704357e+308L); }


      static constexpr int digits = 53;
      static constexpr int digits10 = 15;

      static constexpr int max_digits10
  = (2 + (53) * 643L / 2136);

      static constexpr bool is_signed = true;
      static constexpr bool is_integer = false;
      static constexpr bool is_exact = false;
      static constexpr int radix = 2;

      static constexpr double
      epsilon() noexcept { return double(2.22044604925031308084726333618164062e-16L); }

      static constexpr double
      round_error() noexcept { return 0.5; }

      static constexpr int min_exponent = (-1021);
      static constexpr int min_exponent10 = (-307);
      static constexpr int max_exponent = 1024;
      static constexpr int max_exponent10 = 308;

      static constexpr bool has_infinity = 1;
      static constexpr bool has_quiet_NaN = 1;
      static constexpr bool has_signaling_NaN = has_quiet_NaN;
      static constexpr float_denorm_style has_denorm
 = bool(1) ? denorm_present : denorm_absent;
      static constexpr bool has_denorm_loss
        = false;

      static constexpr double
      infinity() noexcept { return __builtin_huge_val(); }

      static constexpr double
      quiet_NaN() noexcept { return __builtin_nan(""); }

      static constexpr double
      signaling_NaN() noexcept { return __builtin_nans(""); }

      static constexpr double
      denorm_min() noexcept { return double(4.94065645841246544176568792868221372e-324L); }

      static constexpr bool is_iec559
 = has_infinity && has_quiet_NaN && has_denorm == denorm_present;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;

      static constexpr bool traps = false;
      static constexpr bool tinyness_before
       = false;
      static constexpr float_round_style round_style
       = round_to_nearest;
    };






  template<>
    struct numeric_limits<long double>
    {
      static constexpr bool is_specialized = true;

      static constexpr long double
      min() noexcept { return 3.36210314311209350626267781732175260e-4932L; }

      static constexpr long double
      max() noexcept { return 1.18973149535723176502126385303097021e+4932L; }


      static constexpr long double
      lowest() noexcept { return -1.18973149535723176502126385303097021e+4932L; }


      static constexpr int digits = 64;
      static constexpr int digits10 = 18;

      static constexpr int max_digits10
  = (2 + (64) * 643L / 2136);

      static constexpr bool is_signed = true;
      static constexpr bool is_integer = false;
      static constexpr bool is_exact = false;
      static constexpr int radix = 2;

      static constexpr long double
      epsilon() noexcept { return 1.08420217248550443400745280086994171e-19L; }

      static constexpr long double
      round_error() noexcept { return 0.5L; }

      static constexpr int min_exponent = (-16381);
      static constexpr int min_exponent10 = (-4931);
      static constexpr int max_exponent = 16384;
      static constexpr int max_exponent10 = 4932;

      static constexpr bool has_infinity = 1;
      static constexpr bool has_quiet_NaN = 1;
      static constexpr bool has_signaling_NaN = has_quiet_NaN;
      static constexpr float_denorm_style has_denorm
 = bool(1) ? denorm_present : denorm_absent;
      static constexpr bool has_denorm_loss
 = false;

      static constexpr long double
      infinity() noexcept { return __builtin_huge_vall(); }

      static constexpr long double
      quiet_NaN() noexcept { return __builtin_nanl(""); }

      static constexpr long double
      signaling_NaN() noexcept { return __builtin_nansl(""); }

      static constexpr long double
      denorm_min() noexcept { return 3.64519953188247460252840593361941982e-4951L; }

      static constexpr bool is_iec559
 = has_infinity && has_quiet_NaN && has_denorm == denorm_present;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;

      static constexpr bool traps = false;
      static constexpr bool tinyness_before =
      false;
      static constexpr float_round_style round_style =
            round_to_nearest;
    };
# 1996 "C:/msys64/mingw64/include/c++/15.2.0/limits" 3
__extension__ template<> struct numeric_limits<_Float32> { static constexpr bool is_specialized = true; static constexpr _Float32 min() noexcept { return 1.17549435082228750796873653722224568e-38F32; } static constexpr _Float32 max() noexcept { return 3.40282346638528859811704183484516925e+38F32; } static constexpr _Float32 lowest() noexcept { return -3.40282346638528859811704183484516925e+38F32; } static constexpr int digits = 24; static constexpr int digits10 = 6; static constexpr int max_digits10 = (2 + (24) * 643L / 2136); static constexpr bool is_signed = true; static constexpr bool is_integer = false; static constexpr bool is_exact = false; static constexpr int radix = 2; static constexpr _Float32 epsilon() noexcept { return 1.19209289550781250000000000000000000e-7F32; } static constexpr _Float32 round_error() noexcept { return 0.5F32; } static constexpr int min_exponent = (-125); static constexpr int min_exponent10 = (-37); static constexpr int max_exponent = 128; static constexpr int max_exponent10 = 38; static constexpr bool has_infinity = 1; static constexpr bool has_quiet_NaN = 1; static constexpr bool has_signaling_NaN = has_quiet_NaN; static constexpr float_denorm_style has_denorm = bool(1) ? denorm_present : denorm_absent; static constexpr bool has_denorm_loss = false; static constexpr _Float32 infinity() noexcept { return __builtin_huge_valf32(); } static constexpr _Float32 quiet_NaN() noexcept { return __builtin_nanf32(""); } static constexpr _Float32 signaling_NaN() noexcept { return __builtin_nansf32(""); } static constexpr _Float32 denorm_min() noexcept { return 1.40129846432481707092372958328991613e-45F32; } static constexpr bool is_iec559 = has_infinity && has_quiet_NaN && has_denorm == denorm_present; static constexpr bool is_bounded = true; static constexpr bool is_modulo = false; static constexpr bool traps = false; static constexpr bool tinyness_before = false; static constexpr float_round_style round_style = round_to_nearest; };


__extension__ template<> struct numeric_limits<_Float64> { static constexpr bool is_specialized = true; static constexpr _Float64 min() noexcept { return 2.22507385850720138309023271733240406e-308F64; } static constexpr _Float64 max() noexcept { return 1.79769313486231570814527423731704357e+308F64; } static constexpr _Float64 lowest() noexcept { return -1.79769313486231570814527423731704357e+308F64; } static constexpr int digits = 53; static constexpr int digits10 = 15; static constexpr int max_digits10 = (2 + (53) * 643L / 2136); static constexpr bool is_signed = true; static constexpr bool is_integer = false; static constexpr bool is_exact = false; static constexpr int radix = 2; static constexpr _Float64 epsilon() noexcept { return 2.22044604925031308084726333618164062e-16F64; } static constexpr _Float64 round_error() noexcept { return 0.5F64; } static constexpr int min_exponent = (-1021); static constexpr int min_exponent10 = (-307); static constexpr int max_exponent = 1024; static constexpr int max_exponent10 = 308; static constexpr bool has_infinity = 1; static constexpr bool has_quiet_NaN = 1; static constexpr bool has_signaling_NaN = has_quiet_NaN; static constexpr float_denorm_style has_denorm = bool(1) ? denorm_present : denorm_absent; static constexpr bool has_denorm_loss = false; static constexpr _Float64 infinity() noexcept { return __builtin_huge_valf64(); } static constexpr _Float64 quiet_NaN() noexcept { return __builtin_nanf64(""); } static constexpr _Float64 signaling_NaN() noexcept { return __builtin_nansf64(""); } static constexpr _Float64 denorm_min() noexcept { return 4.94065645841246544176568792868221372e-324F64; } static constexpr bool is_iec559 = has_infinity && has_quiet_NaN && has_denorm == denorm_present; static constexpr bool is_bounded = true; static constexpr bool is_modulo = false; static constexpr bool traps = false; static constexpr bool tinyness_before = false; static constexpr float_round_style round_style = round_to_nearest; };


__extension__ template<> struct numeric_limits<_Float128> { static constexpr bool is_specialized = true; static constexpr _Float128 min() noexcept { return 3.36210314311209350626267781732175260e-4932F128; } static constexpr _Float128 max() noexcept { return 1.18973149535723176508575932662800702e+4932F128; } static constexpr _Float128 lowest() noexcept { return -1.18973149535723176508575932662800702e+4932F128; } static constexpr int digits = 113; static constexpr int digits10 = 33; static constexpr int max_digits10 = (2 + (113) * 643L / 2136); static constexpr bool is_signed = true; static constexpr bool is_integer = false; static constexpr bool is_exact = false; static constexpr int radix = 2; static constexpr _Float128 epsilon() noexcept { return 1.92592994438723585305597794258492732e-34F128; } static constexpr _Float128 round_error() noexcept { return 0.5F128; } static constexpr int min_exponent = (-16381); static constexpr int min_exponent10 = (-4931); static constexpr int max_exponent = 16384; static constexpr int max_exponent10 = 4932; static constexpr bool has_infinity = 1; static constexpr bool has_quiet_NaN = 1; static constexpr bool has_signaling_NaN = has_quiet_NaN; static constexpr float_denorm_style has_denorm = bool(1) ? denorm_present : denorm_absent; static constexpr bool has_denorm_loss = false; static constexpr _Float128 infinity() noexcept { return __builtin_huge_valf128(); } static constexpr _Float128 quiet_NaN() noexcept { return __builtin_nanf128(""); } static constexpr _Float128 signaling_NaN() noexcept { return __builtin_nansf128(""); } static constexpr _Float128 denorm_min() noexcept { return 6.47517511943802511092443895822764655e-4966F128; } static constexpr bool is_iec559 = has_infinity && has_quiet_NaN && has_denorm == denorm_present; static constexpr bool is_bounded = true; static constexpr bool is_modulo = false; static constexpr bool traps = false; static constexpr bool tinyness_before = false; static constexpr float_round_style round_style = round_to_nearest; };
# 2094 "C:/msys64/mingw64/include/c++/15.2.0/limits" 3
  __extension__
  template<>
    struct numeric_limits<__float128>
    {
      static constexpr bool is_specialized = true;

      static constexpr __float128
      min() noexcept
      {




 return __extension__ 0x1.0p-16382Q;

      }

      static constexpr __float128
      max() noexcept
      {







 return __extension__ 0x1.ffffffffffffffffffffffffffffp+16383Q;

      }

      static constexpr __float128
      lowest() noexcept
      { return -max(); }

      static constexpr int digits = 113;
      static constexpr int digits10 = 33;

      static constexpr int max_digits10 = 35;

      static constexpr bool is_signed = true;
      static constexpr bool is_integer = false;
      static constexpr bool is_exact = false;
      static constexpr int radix = 2;

      static constexpr __float128
      epsilon() noexcept
      { return double(1.9259299443872359e-34); }

      static constexpr __float128
      round_error() noexcept { return 0.5; }

      static constexpr int min_exponent = -16381;
      static constexpr int min_exponent10 = -4931;
      static constexpr int max_exponent = 16384;
      static constexpr int max_exponent10 = 4932;

      static constexpr bool has_infinity = 1;
      static constexpr bool has_quiet_NaN = 1;


      static constexpr bool has_signaling_NaN = true;



      static constexpr float_denorm_style has_denorm
 = denorm_present;
      static constexpr bool has_denorm_loss = false;

      static constexpr __float128
      infinity() noexcept
      { return __builtin_huge_val(); }

      static constexpr __float128
      quiet_NaN() noexcept
      { return __builtin_nan(""); }

      static constexpr __float128
      signaling_NaN() noexcept
      {

 return __builtin_nansq("");





      }

      static constexpr __float128
      denorm_min() noexcept
      {




 return __extension__ 0x1.0p-16494Q;

      }

      static constexpr bool is_iec559 = has_signaling_NaN;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;

      static constexpr bool traps = false;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
 = round_to_nearest;
# 2225 "C:/msys64/mingw64/include/c++/15.2.0/limits" 3
    };




}
# 2239 "C:/msys64/mingw64/include/c++/15.2.0/limits" 3
#pragma GCC diagnostic pop
# 42 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 2 3

# 1 "C:/msys64/mingw64/include/c++/15.2.0/ctime" 1 3
# 47 "C:/msys64/mingw64/include/c++/15.2.0/ctime" 3
# 1 "C:/msys64/mingw64/include/time.h" 1 3
# 25 "C:/msys64/mingw64/include/time.h" 3
# 1 "C:/msys64/mingw64/include/sys/timeb.h" 1 3
# 15 "C:/msys64/mingw64/include/sys/timeb.h" 3
#pragma pack(push,_CRT_PACKING)


extern "C" {
# 53 "C:/msys64/mingw64/include/sys/timeb.h" 3
  struct __timeb32 {
    __time32_t time;
    unsigned short millitm;
    short timezone;
    short dstflag;
  };


  struct timeb {
    time_t time;
    unsigned short millitm;
    short timezone;
    short dstflag;
  };


  struct __timeb64 {
    __time64_t time;
    unsigned short millitm;
    short timezone;
    short dstflag;
  };



  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _ftime64(struct __timeb64 *_Time);
  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _ftime32(struct __timeb32 *_Time);
# 89 "C:/msys64/mingw64/include/sys/timeb.h" 3
struct _timespec32 {
  __time32_t tv_sec;
  long tv_nsec;
};

struct _timespec64 {
  __time64_t tv_sec;
  long tv_nsec;
};



struct timespec {
  time_t tv_sec;
  long tv_nsec;
};

struct itimerspec {
  struct timespec it_interval;
  struct timespec it_value;
};




  void __attribute__((__cdecl__)) ftime (struct timeb *) __asm__("_ftime64");






}


#pragma pack(pop)

# 1 "C:/msys64/mingw64/include/sec_api/sys/timeb_s.h" 1 3
# 10 "C:/msys64/mingw64/include/sec_api/sys/timeb_s.h" 3
# 1 "C:/msys64/mingw64/include/sys/timeb.h" 1 3
# 11 "C:/msys64/mingw64/include/sec_api/sys/timeb_s.h" 2 3


extern "C" {


  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _ftime32_s(struct __timeb32 *_Time);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _ftime64_s(struct __timeb64 *_Time);
# 26 "C:/msys64/mingw64/include/sec_api/sys/timeb_s.h" 3
}
# 127 "C:/msys64/mingw64/include/sys/timeb.h" 2 3
# 26 "C:/msys64/mingw64/include/time.h" 2 3

#pragma pack(push,_CRT_PACKING)


extern "C" {
# 63 "C:/msys64/mingw64/include/time.h" 3
  typedef long clock_t;
# 100 "C:/msys64/mingw64/include/time.h" 3
  struct tm {
    int tm_sec;
    int tm_min;
    int tm_hour;
    int tm_mday;
    int tm_mon;
    int tm_year;
    int tm_wday;
    int tm_yday;
    int tm_isdst;
  };
# 119 "C:/msys64/mingw64/include/time.h" 3
  __attribute__ ((__dllimport__)) int *__attribute__((__cdecl__)) __daylight(void);
  __attribute__ ((__dllimport__)) long *__attribute__((__cdecl__)) __dstbias(void);
  __attribute__ ((__dllimport__)) long *__attribute__((__cdecl__)) __timezone(void);
  __attribute__ ((__dllimport__)) char **__attribute__((__cdecl__)) __tzname(void);
# 138 "C:/msys64/mingw64/include/time.h" 3
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _get_daylight(int *_Daylight);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _get_dstbias(long *_Daylight_savings_bias);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _get_timezone(long *_Timezone);
  __attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _get_tzname(size_t *_ReturnValue,char *_Buffer,size_t _SizeInBytes,int _Index);
  char *__attribute__((__cdecl__)) asctime(const struct tm *_Tm) ;
  __attribute__((dllimport)) errno_t __attribute__((__cdecl__)) asctime_s (char *_Buf,size_t _SizeInWords,const struct tm *_Tm);
  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _ctime32(const __time32_t *_Time) ;
  __attribute__((dllimport)) errno_t __attribute__((__cdecl__)) _ctime32_s (char *_Buf,size_t _SizeInBytes,const __time32_t *_Time);
  clock_t __attribute__((__cdecl__)) clock(void);
  __attribute__ ((__dllimport__)) double __attribute__((__cdecl__)) _difftime32(__time32_t _Time1,__time32_t _Time2);
  __attribute__ ((__dllimport__)) struct tm *__attribute__((__cdecl__)) _gmtime32(const __time32_t *_Time) ;
  __attribute__((dllimport)) errno_t __attribute__((__cdecl__)) _gmtime32_s (struct tm *_Tm,const __time32_t *_Time);
  __attribute__ ((__dllimport__)) struct tm *__attribute__((__cdecl__)) _localtime32(const __time32_t *_Time) ;
  __attribute__((dllimport)) errno_t __attribute__((__cdecl__)) _localtime32_s (struct tm *_Tm,const __time32_t *_Time);
  size_t __attribute__((__cdecl__)) strftime(char * __restrict__ _Buf,size_t _SizeInBytes,const char * __restrict__ _Format,const struct tm * __restrict__ _Tm) __attribute__((__format__ (ms_strftime, 3, 0)));
  __attribute__ ((__dllimport__)) size_t __attribute__((__cdecl__)) _strftime_l(char * __restrict__ _Buf,size_t _Max_size,const char * __restrict__ _Format,const struct tm * __restrict__ _Tm,_locale_t _Locale);
  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _strdate(char *_Buffer) ;
  __attribute__((dllimport)) errno_t __attribute__((__cdecl__)) _strdate_s (char *_Buf,size_t _SizeInBytes);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _strdate_s(char (&_Str)[__size]) { return _strdate_s(_Str,__size); } }
  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _strtime(char *_Buffer) ;
  __attribute__((dllimport)) errno_t __attribute__((__cdecl__)) _strtime_s (char *_Buf ,size_t _SizeInBytes);
  extern "C++" { template <size_t __size> inline errno_t __attribute__((__cdecl__)) _strtime_s(char (&_Str)[__size]) { return _strtime_s(_Str,__size); } }
  __attribute__ ((__dllimport__)) __time32_t __attribute__((__cdecl__)) _time32(__time32_t *_Time);



  __attribute__ ((__dllimport__)) __time32_t __attribute__((__cdecl__)) _mktime32(struct tm *_Tm);
  __attribute__ ((__dllimport__)) __time32_t __attribute__((__cdecl__)) _mkgmtime32(struct tm *_Tm);


  void __attribute__((__cdecl__)) tzset(void) ;



  __attribute__ ((__dllimport__))

  void __attribute__((__cdecl__)) _tzset(void);


  __attribute__ ((__dllimport__)) double __attribute__((__cdecl__)) _difftime64(__time64_t _Time1,__time64_t _Time2);
  __attribute__ ((__dllimport__)) char *__attribute__((__cdecl__)) _ctime64(const __time64_t *_Time) ;
  __attribute__((dllimport)) errno_t __attribute__((__cdecl__)) _ctime64_s (char *_Buf,size_t _SizeInBytes,const __time64_t *_Time);
  __attribute__ ((__dllimport__)) struct tm *__attribute__((__cdecl__)) _gmtime64(const __time64_t *_Time) ;
  __attribute__((dllimport)) errno_t __attribute__((__cdecl__)) _gmtime64_s (struct tm *_Tm,const __time64_t *_Time);
  __attribute__ ((__dllimport__)) struct tm *__attribute__((__cdecl__)) _localtime64(const __time64_t *_Time) ;
  __attribute__((dllimport)) errno_t __attribute__((__cdecl__)) _localtime64_s (struct tm *_Tm,const __time64_t *_Time);
  __attribute__ ((__dllimport__)) __time64_t __attribute__((__cdecl__)) _mktime64(struct tm *_Tm);
  __attribute__ ((__dllimport__)) __time64_t __attribute__((__cdecl__)) _mkgmtime64(struct tm *_Tm);
  __attribute__ ((__dllimport__)) __time64_t __attribute__((__cdecl__)) _time64(__time64_t *_Time);



  unsigned __attribute__((__cdecl__)) _getsystime(struct tm *_Tm);
  unsigned __attribute__((__cdecl__)) _setsystime(struct tm *_Tm,unsigned _MilliSec);


  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _wasctime(const struct tm *_Tm);
  __attribute__((dllimport)) errno_t __attribute__((__cdecl__)) _wasctime_s (wchar_t *_Buf,size_t _SizeInWords,const struct tm *_Tm);
  wchar_t *__attribute__((__cdecl__)) _wctime32(const __time32_t *_Time) ;
  __attribute__((dllimport)) errno_t __attribute__((__cdecl__)) _wctime32_s (wchar_t *_Buf,size_t _SizeInWords,const __time32_t *_Time);
  size_t __attribute__((__cdecl__)) wcsftime(wchar_t * __restrict__ _Buf,size_t _SizeInWords,const wchar_t * __restrict__ _Format,const struct tm * __restrict__ _Tm);
  __attribute__ ((__dllimport__)) size_t __attribute__((__cdecl__)) _wcsftime_l(wchar_t * __restrict__ _Buf,size_t _SizeInWords,const wchar_t * __restrict__ _Format,const struct tm * __restrict__ _Tm,_locale_t _Locale);
  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _wstrdate(wchar_t *_Buffer) ;
  __attribute__((dllimport)) errno_t __attribute__((__cdecl__)) _wstrdate_s (wchar_t *_Buf,size_t _SizeInWords);
  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _wstrtime(wchar_t *_Buffer) ;
  __attribute__((dllimport)) errno_t __attribute__((__cdecl__)) _wstrtime_s (wchar_t *_Buf,size_t _SizeInWords);
  __attribute__ ((__dllimport__)) wchar_t *__attribute__((__cdecl__)) _wctime64(const __time64_t *_Time) ;
  __attribute__((dllimport)) errno_t __attribute__((__cdecl__)) _wctime64_s (wchar_t *_Buf,size_t _SizeInWords,const __time64_t *_Time);




  wchar_t *__attribute__((__cdecl__)) _wctime(const time_t *_Time) __asm__("_wctime64") ;
# 219 "C:/msys64/mingw64/include/time.h" 3
  errno_t __attribute__((__cdecl__)) _wctime_s (wchar_t *_Buffer,size_t _SizeInWords,const time_t *_Time) __asm__("_wctime64_s");
# 245 "C:/msys64/mingw64/include/time.h" 3
time_t __attribute__((__cdecl__)) time(time_t *_Time) __asm__("_time64");



double __attribute__((__cdecl__)) difftime(time_t _Time1,time_t _Time2) __asm__("_difftime64");
struct tm *__attribute__((__cdecl__)) localtime(const time_t *_Time) __asm__("_localtime64");
errno_t __attribute__((__cdecl__)) localtime_s(struct tm *_Tm,const time_t *_Time) __asm__("_localtime64_s");
struct tm *__attribute__((__cdecl__)) gmtime(const time_t *_Time) __asm__("_gmtime64");
errno_t __attribute__((__cdecl__)) gmtime_s(struct tm *_Tm, const time_t *_Time) __asm__("_gmtime64_s");
char *__attribute__((__cdecl__)) ctime(const time_t *_Time) __asm__("_ctime64");
errno_t __attribute__((__cdecl__)) ctime_s(char *_Buf,size_t _SizeInBytes,const time_t *_Time) __asm__("_ctime64_s");
time_t __attribute__((__cdecl__)) mktime(struct tm *_Tm) __asm__("_mktime64");
time_t __attribute__((__cdecl__)) _mkgmtime(struct tm *_Tm) __asm__("_mkgmtime64");
# 274 "C:/msys64/mingw64/include/time.h" 3
  __attribute__ ((__dllimport__)) extern int daylight ;
  __attribute__ ((__dllimport__)) extern long timezone ;
  __attribute__ ((__dllimport__)) extern char *tzname[2] ;
  void __attribute__((__cdecl__)) tzset(void) ;


# 1 "C:/msys64/mingw64/include/_timeval.h" 1 3
# 10 "C:/msys64/mingw64/include/_timeval.h" 3
struct timeval
{
 long tv_sec;
 long tv_usec;
};
# 281 "C:/msys64/mingw64/include/time.h" 2 3



struct timezone {
  int tz_minuteswest;
  int tz_dsttime;
};

  extern int __attribute__((__cdecl__)) mingw_gettimeofday (struct timeval *p, struct timezone *z);


#pragma pack(pop)
# 314 "C:/msys64/mingw64/include/time.h" 3
}
# 323 "C:/msys64/mingw64/include/time.h" 3
# 1 "C:/msys64/mingw64/include/pthread_time.h" 1 3
# 27 "C:/msys64/mingw64/include/pthread_time.h" 3
# 1 "C:/msys64/mingw64/include/pthread_compat.h" 1 3 4
# 78 "C:/msys64/mingw64/include/pthread_compat.h" 3 4
typedef int clockid_t;





typedef unsigned short mode_t;
# 28 "C:/msys64/mingw64/include/pthread_time.h" 2 3
# 74 "C:/msys64/mingw64/include/pthread_time.h" 3
extern "C" {


 int __attribute__((__cdecl__)) nanosleep32(const struct _timespec32 *request, struct _timespec32 *remain);
 int __attribute__((__cdecl__)) nanosleep64(const struct _timespec64 *request, struct _timespec64 *remain);
__inline__ __attribute__((__always_inline__)) int __attribute__((__cdecl__)) nanosleep(const struct timespec *request, struct timespec *remain)
{



  return nanosleep64 ((struct _timespec64 *)request, (struct _timespec64 *)remain);

}

 int __attribute__((__cdecl__)) clock_nanosleep32(clockid_t clock_id, int flags, const struct _timespec32 *request, struct _timespec32 *remain);
 int __attribute__((__cdecl__)) clock_nanosleep64(clockid_t clock_id, int flags, const struct _timespec64 *request, struct _timespec64 *remain);
__inline__ __attribute__((__always_inline__)) int __attribute__((__cdecl__)) clock_nanosleep(clockid_t clock_id, int flags, const struct timespec *request, struct timespec *remain)
{



  return clock_nanosleep64 (clock_id, flags, (struct _timespec64 *)request, (struct _timespec64 *)remain);

}

 int __attribute__((__cdecl__)) clock_getres32(clockid_t clock_id, struct _timespec32 *res);
 int __attribute__((__cdecl__)) clock_getres64(clockid_t clock_id, struct _timespec64 *res);
__inline__ __attribute__((__always_inline__)) int __attribute__((__cdecl__)) clock_getres(clockid_t clock_id, struct timespec *res)
{



  return clock_getres64 (clock_id, (struct _timespec64 *)res);

}

 int __attribute__((__cdecl__)) clock_gettime32(clockid_t clock_id, struct _timespec32 *tp);
 int __attribute__((__cdecl__)) clock_gettime64(clockid_t clock_id, struct _timespec64 *tp);
__inline__ __attribute__((__always_inline__)) int __attribute__((__cdecl__)) clock_gettime(clockid_t clock_id, struct timespec *tp)
{



  return clock_gettime64 (clock_id, (struct _timespec64 *)tp);

}

 int __attribute__((__cdecl__)) clock_settime32(clockid_t clock_id, const struct _timespec32 *tp);
 int __attribute__((__cdecl__)) clock_settime64(clockid_t clock_id, const struct _timespec64 *tp);
__inline__ __attribute__((__always_inline__)) int __attribute__((__cdecl__)) clock_settime(clockid_t clock_id, const struct timespec *tp)
{



  return clock_settime64 (clock_id, (struct _timespec64 *)tp);

}


}
# 324 "C:/msys64/mingw64/include/time.h" 2 3
# 48 "C:/msys64/mingw64/include/c++/15.2.0/ctime" 2 3
# 60 "C:/msys64/mingw64/include/c++/15.2.0/ctime" 3
namespace std
{
  using ::clock_t;
  using ::time_t;
  using ::tm;

  using ::clock;
  using ::difftime;
  using ::mktime;
  using ::time;
  using ::asctime;
  using ::ctime;
  using ::gmtime;
  using ::localtime;
  using ::strftime;
}
# 44 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 2 3

# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/parse_numbers.h" 1 3
# 44 "C:/msys64/mingw64/include/c++/15.2.0/bits/parse_numbers.h" 3
namespace std
{


namespace __parse_int
{
  template<unsigned _Base, char _Dig>
    struct _Digit;

  template<unsigned _Base>
    struct _Digit<_Base, '0'> : integral_constant<unsigned, 0>
    {
      using __valid = true_type;
    };

  template<unsigned _Base>
    struct _Digit<_Base, '1'> : integral_constant<unsigned, 1>
    {
      using __valid = true_type;
    };

  template<unsigned _Base, unsigned _Val>
    struct _Digit_impl : integral_constant<unsigned, _Val>
    {
      static_assert(_Base > _Val, "invalid digit");
      using __valid = true_type;
    };

  template<unsigned _Base>
    struct _Digit<_Base, '2'> : _Digit_impl<_Base, 2>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, '3'> : _Digit_impl<_Base, 3>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, '4'> : _Digit_impl<_Base, 4>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, '5'> : _Digit_impl<_Base, 5>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, '6'> : _Digit_impl<_Base, 6>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, '7'> : _Digit_impl<_Base, 7>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, '8'> : _Digit_impl<_Base, 8>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, '9'> : _Digit_impl<_Base, 9>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, 'a'> : _Digit_impl<_Base, 0xa>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, 'A'> : _Digit_impl<_Base, 0xa>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, 'b'> : _Digit_impl<_Base, 0xb>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, 'B'> : _Digit_impl<_Base, 0xb>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, 'c'> : _Digit_impl<_Base, 0xc>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, 'C'> : _Digit_impl<_Base, 0xc>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, 'd'> : _Digit_impl<_Base, 0xd>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, 'D'> : _Digit_impl<_Base, 0xd>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, 'e'> : _Digit_impl<_Base, 0xe>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, 'E'> : _Digit_impl<_Base, 0xe>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, 'f'> : _Digit_impl<_Base, 0xf>
    { };

  template<unsigned _Base>
    struct _Digit<_Base, 'F'> : _Digit_impl<_Base, 0xf>
    { };


  template<unsigned _Base>
    struct _Digit<_Base, '\''> : integral_constant<unsigned, 0>
    {
      using __valid = false_type;
    };



  template<unsigned long long _Val>
    using __ull_constant = integral_constant<unsigned long long, _Val>;

  template<unsigned _Base, char _Dig, char... _Digs>
    struct _Power_help
    {
      using __next = typename _Power_help<_Base, _Digs...>::type;
      using __valid_digit = typename _Digit<_Base, _Dig>::__valid;
      using type
 = __ull_constant<__next::value * (__valid_digit{} ? _Base : 1ULL)>;
    };

  template<unsigned _Base, char _Dig>
    struct _Power_help<_Base, _Dig>
    {
      using __valid_digit = typename _Digit<_Base, _Dig>::__valid;
      using type = __ull_constant<__valid_digit::value>;
    };

  template<unsigned _Base, char... _Digs>
    struct _Power : _Power_help<_Base, _Digs...>::type
    { };

  template<unsigned _Base>
    struct _Power<_Base> : __ull_constant<0>
    { };



  template<unsigned _Base, unsigned long long _Pow, char _Dig, char... _Digs>
    struct _Number_help
    {
      using __digit = _Digit<_Base, _Dig>;
      using __valid_digit = typename __digit::__valid;
      using __next = _Number_help<_Base,
      __valid_digit::value ? _Pow / _Base : _Pow,
      _Digs...>;
      using type = __ull_constant<_Pow * __digit::value + __next::type::value>;
      static_assert((type::value / _Pow) == __digit::value,
      "integer literal does not fit in unsigned long long");
    };


  template<unsigned _Base, unsigned long long _Pow, char _Dig, char..._Digs>
    struct _Number_help<_Base, _Pow, '\'', _Dig, _Digs...>
    : _Number_help<_Base, _Pow, _Dig, _Digs...>
    { };


  template<unsigned _Base, char _Dig>
    struct _Number_help<_Base, 1ULL, _Dig>
    {
      using type = __ull_constant<_Digit<_Base, _Dig>::value>;
    };

  template<unsigned _Base, char... _Digs>
    struct _Number
    : _Number_help<_Base, _Power<_Base, _Digs...>::value, _Digs...>::type
    { };

  template<unsigned _Base>
    struct _Number<_Base>
    : __ull_constant<0>
    { };



  template<char... _Digs>
    struct _Parse_int;

  template<char... _Digs>
    struct _Parse_int<'0', 'b', _Digs...>
    : _Number<2U, _Digs...>::type
    { };

  template<char... _Digs>
    struct _Parse_int<'0', 'B', _Digs...>
    : _Number<2U, _Digs...>::type
    { };

  template<char... _Digs>
    struct _Parse_int<'0', 'x', _Digs...>
    : _Number<16U, _Digs...>::type
    { };

  template<char... _Digs>
    struct _Parse_int<'0', 'X', _Digs...>
    : _Number<16U, _Digs...>::type
    { };

  template<char... _Digs>
    struct _Parse_int<'0', _Digs...>
    : _Number<8U, _Digs...>::type
    { };

  template<char... _Digs>
    struct _Parse_int
    : _Number<10U, _Digs...>::type
    { };

}


namespace __select_int
{
  template<unsigned long long _Val, typename... _Ints>
    struct _Select_int_base;

  template<unsigned long long _Val, typename _IntType, typename... _Ints>
    struct _Select_int_base<_Val, _IntType, _Ints...>
    : __conditional_t<(_Val <= __gnu_cxx::__int_traits<_IntType>::__max),
        integral_constant<_IntType, (_IntType)_Val>,
        _Select_int_base<_Val, _Ints...>>
    { };

  template<unsigned long long _Val>
    struct _Select_int_base<_Val>
    { };

  template<char... _Digs>
    using _Select_int = typename _Select_int_base<
 __parse_int::_Parse_int<_Digs...>::value,
 unsigned char,
 unsigned short,
 unsigned int,
 unsigned long,
 unsigned long long
      >::type;

}


}
# 46 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 2 3





# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 52 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 2 3

namespace std
{



  namespace filesystem { struct __file_clock; };


  namespace chrono
  {




    template<typename _Rep, typename _Period = ratio<1>>
      class duration;


    template<typename _Clock, typename _Dur = typename _Clock::duration>
      class time_point;

  }
# 83 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
  template<typename _CT, typename _Period1, typename _Period2, typename = void>
    struct __duration_common_type
    { };

  template<typename _CT, typename _Period1, typename _Period2>
    struct __duration_common_type<_CT, _Period1, _Period2,
      __void_t<typename _CT::type>>
    {
    private:
      using __gcd_num = __static_gcd<_Period1::num, _Period2::num>;
      using __gcd_den = __static_gcd<_Period1::den, _Period2::den>;
      using __cr = typename _CT::type;
      using __r = ratio<__gcd_num::value,
   (_Period1::den / __gcd_den::value) * _Period2::den>;

    public:
      using type = chrono::duration<__cr, typename __r::type>;
    };







  template<typename _Rep1, typename _Period1, typename _Rep2, typename _Period2>
    struct common_type<chrono::duration<_Rep1, _Period1>,
         chrono::duration<_Rep2, _Period2>>
    : __duration_common_type<common_type<_Rep1, _Rep2>,
        typename _Period1::type,
        typename _Period2::type>
    { };


  template<typename _Rep, typename _Period>
    struct common_type<chrono::duration<_Rep, _Period>,
         chrono::duration<_Rep, _Period>>
    {
      using type = chrono::duration<typename common_type<_Rep>::type,
        typename _Period::type>;
    };


  template<typename _Rep, typename _Period>
    struct common_type<chrono::duration<_Rep, _Period>>
    {
      using type = chrono::duration<typename common_type<_Rep>::type,
        typename _Period::type>;
    };






  template<typename _CT, typename _Clock, typename = void>
    struct __timepoint_common_type
    { };

  template<typename _CT, typename _Clock>
    struct __timepoint_common_type<_CT, _Clock, __void_t<typename _CT::type>>
    {
      using type = chrono::time_point<_Clock, typename _CT::type>;
    };







  template<typename _Clock, typename _Duration1, typename _Duration2>
    struct common_type<chrono::time_point<_Clock, _Duration1>,
         chrono::time_point<_Clock, _Duration2>>
    : __timepoint_common_type<common_type<_Duration1, _Duration2>, _Clock>
    { };


  template<typename _Clock, typename _Duration>
    struct common_type<chrono::time_point<_Clock, _Duration>,
         chrono::time_point<_Clock, _Duration>>
    { using type = chrono::time_point<_Clock, _Duration>; };


  template<typename _Clock, typename _Duration>
    struct common_type<chrono::time_point<_Clock, _Duration>>
    { using type = chrono::time_point<_Clock, _Duration>; };




  namespace chrono
  {






    template<typename _ToDur, typename _CF, typename _CR,
      bool _NumIsOne = false, bool _DenIsOne = false>
      struct __duration_cast_impl
      {
 template<typename _Rep, typename _Period>
   static constexpr _ToDur
   __cast(const duration<_Rep, _Period>& __d)
   {
     typedef typename _ToDur::rep __to_rep;
     return _ToDur(static_cast<__to_rep>(static_cast<_CR>(__d.count())
       * static_cast<_CR>(_CF::num)
       / static_cast<_CR>(_CF::den)));
   }
      };

    template<typename _ToDur, typename _CF, typename _CR>
      struct __duration_cast_impl<_ToDur, _CF, _CR, true, true>
      {
 template<typename _Rep, typename _Period>
   static constexpr _ToDur
   __cast(const duration<_Rep, _Period>& __d)
   {
     typedef typename _ToDur::rep __to_rep;
     return _ToDur(static_cast<__to_rep>(__d.count()));
   }
      };

    template<typename _ToDur, typename _CF, typename _CR>
      struct __duration_cast_impl<_ToDur, _CF, _CR, true, false>
      {
 template<typename _Rep, typename _Period>
   static constexpr _ToDur
   __cast(const duration<_Rep, _Period>& __d)
   {
     typedef typename _ToDur::rep __to_rep;
     return _ToDur(static_cast<__to_rep>(
       static_cast<_CR>(__d.count()) / static_cast<_CR>(_CF::den)));
   }
      };

    template<typename _ToDur, typename _CF, typename _CR>
      struct __duration_cast_impl<_ToDur, _CF, _CR, false, true>
      {
 template<typename _Rep, typename _Period>
   static constexpr _ToDur
   __cast(const duration<_Rep, _Period>& __d)
   {
     typedef typename _ToDur::rep __to_rep;
     return _ToDur(static_cast<__to_rep>(
       static_cast<_CR>(__d.count()) * static_cast<_CR>(_CF::num)));
   }
      };

    template<typename _Tp>
      struct __is_duration
      : std::false_type
      { };

    template<typename _Rep, typename _Period>
      struct __is_duration<duration<_Rep, _Period>>
      : std::true_type
      { };

    template<typename _Tp>
      using __enable_if_is_duration
 = typename enable_if<__is_duration<_Tp>::value, _Tp>::type;

    template<typename _Tp>
      using __disable_if_is_duration
 = typename enable_if<!__is_duration<_Tp>::value, _Tp>::type;


    template<typename _Tp>
      inline constexpr bool __is_duration_v = false;
    template<typename _Rep, typename _Period>
      inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;
    template<typename _Tp>
      inline constexpr bool __is_time_point_v = false;
    template<typename _Clock, typename _Dur>
      inline constexpr bool __is_time_point_v<time_point<_Clock, _Dur>> = true;
# 276 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    template<typename _ToDur, typename _Rep, typename _Period>
      [[__nodiscard__]]
      constexpr __enable_if_is_duration<_ToDur>
      duration_cast(const duration<_Rep, _Period>& __d)
      {

 if constexpr (is_same_v<_ToDur, duration<_Rep, _Period>>)
   return __d;
 else
   {

   using __to_period = typename _ToDur::period;
   using __to_rep = typename _ToDur::rep;
   using __cf = ratio_divide<_Period, __to_period>;
   using __cr = typename common_type<__to_rep, _Rep, intmax_t>::type;
   using __dc = __duration_cast_impl<_ToDur, __cf, __cr,
         __cf::num == 1, __cf::den == 1>;
   return __dc::__cast(__d);

   }

      }
# 310 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    template<typename _Rep>
      struct treat_as_floating_point
      : is_floating_point<_Rep>
      { };


    template <typename _Rep>
      inline constexpr bool treat_as_floating_point_v =
 treat_as_floating_point<_Rep>::value;

    template<>
      inline constexpr bool treat_as_floating_point_v<int> = false;
    template<>
      inline constexpr bool treat_as_floating_point_v<long> = false;
    template<>
      inline constexpr bool treat_as_floating_point_v<long long> = false;
    template<>
      inline constexpr bool treat_as_floating_point_v<float> = true;
    template<>
      inline constexpr bool treat_as_floating_point_v<double> = true;
    template<>
      inline constexpr bool treat_as_floating_point_v<long double> = true;




    template<typename _Tp>
      inline constexpr bool is_clock_v = false;

    template<typename _Tp>
      requires requires {
 typename _Tp::rep;
 typename _Tp::period;
 typename _Tp::duration;
 typename _Tp::time_point::clock;
 typename _Tp::time_point::duration;
 { &_Tp::is_steady } -> same_as<const bool*>;
 { _Tp::now() } -> same_as<typename _Tp::time_point>;
 requires same_as<typename _Tp::duration,
    duration<typename _Tp::rep, typename _Tp::period>>;
 requires same_as<typename _Tp::time_point::duration,
    typename _Tp::duration>;
      }
    inline constexpr bool is_clock_v<_Tp> = true;
# 373 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    template<typename _Tp>
      struct is_clock
      : bool_constant<is_clock_v<_Tp>>
      { };
# 390 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    template<typename _ToDur, typename _Rep, typename _Period>
      [[nodiscard]] constexpr __enable_if_is_duration<_ToDur>
      floor(const duration<_Rep, _Period>& __d)
      {
 auto __to = chrono::duration_cast<_ToDur>(__d);
 if (__to > __d)
   return __to - _ToDur{1};
 return __to;
      }
# 410 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    template<typename _ToDur, typename _Rep, typename _Period>
      [[nodiscard]] constexpr __enable_if_is_duration<_ToDur>
      ceil(const duration<_Rep, _Period>& __d)
      {
 auto __to = chrono::duration_cast<_ToDur>(__d);
 if (__to < __d)
   return __to + _ToDur{1};
 return __to;
      }
# 431 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    template <typename _ToDur, typename _Rep, typename _Period>
      [[nodiscard]] constexpr
      enable_if_t<
 __and_<__is_duration<_ToDur>,
        __not_<treat_as_floating_point<typename _ToDur::rep>>>::value,
 _ToDur>
      round(const duration<_Rep, _Period>& __d)
      {
 _ToDur __t0 = chrono::floor<_ToDur>(__d);
 _ToDur __t1 = __t0 + _ToDur{1};
 auto __diff0 = __d - __t0;
 auto __diff1 = __t1 - __d;
 if (__diff0 == __diff1)
   {
     if (__t0.count() & 1)
       return __t1;
     return __t0;
   }
 else if (__diff0 < __diff1)
   return __t0;
 return __t1;
      }







    template<typename _Rep, typename _Period>
      [[nodiscard]] constexpr
      enable_if_t<numeric_limits<_Rep>::is_signed, duration<_Rep, _Period>>
      abs(duration<_Rep, _Period> __d)
      {
 if (__d >= __d.zero())
   return __d;
 return -__d;
      }


    namespace __detail { using chrono::ceil; }
# 498 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    template<typename _Rep>
      struct duration_values
      {
 static constexpr _Rep
 zero() noexcept
 { return _Rep(0); }

 static constexpr _Rep
 max() noexcept
 { return numeric_limits<_Rep>::max(); }

 static constexpr _Rep
 min() noexcept
 { return numeric_limits<_Rep>::lowest(); }
      };

    template<typename _Rep, typename _Period>
      class duration
      {
 static_assert(!__is_duration<_Rep>::value,
        "rep cannot be a std::chrono::duration");
 static_assert(__is_ratio<_Period>::value,
        "period must be a specialization of std::ratio");
 static_assert(_Period::num > 0, "period must be positive");

 template<typename _Rep2>
   using __is_float = treat_as_floating_point<_Rep2>;

 static constexpr intmax_t
 _S_gcd(intmax_t __m, intmax_t __n) noexcept
 {



   do
     {
       intmax_t __rem = __m % __n;
       __m = __n;
       __n = __rem;
     }
   while (__n != 0);
   return __m;





 }





 template<typename _R1, typename _R2,
   intmax_t __gcd1 = _S_gcd(_R1::num, _R2::num),
   intmax_t __gcd2 = _S_gcd(_R1::den, _R2::den)>
   using __divide = ratio<(_R1::num / __gcd1) * (_R2::den / __gcd2),
     (_R1::den / __gcd2) * (_R2::num / __gcd1)>;


 template<typename _Period2>
   using __is_harmonic
     = __bool_constant<__divide<_Period2, _Period>::den == 1>;

      public:

 using rep = _Rep;
 using period = typename _Period::type;


 constexpr duration() = default;

 duration(const duration&) = default;



 template<typename _Rep2, typename = _Require<
   is_convertible<const _Rep2&, rep>,
   __or_<__is_float<rep>, __not_<__is_float<_Rep2>>>>>
   constexpr explicit duration(const _Rep2& __rep)
   : __r(static_cast<rep>(__rep)) { }

 template<typename _Rep2, typename _Period2, typename = _Require<
   is_convertible<const _Rep2&, rep>,
   __or_<__is_float<rep>,
         __and_<__is_harmonic<_Period2>,
         __not_<__is_float<_Rep2>>>>>>
   constexpr duration(const duration<_Rep2, _Period2>& __d)
   : __r(duration_cast<duration>(__d).count()) { }

 ~duration() = default;
 duration& operator=(const duration&) = default;


 constexpr rep
 count() const
 { return __r; }



 constexpr duration<typename common_type<rep>::type, period>
 operator+() const
 { return duration<typename common_type<rep>::type, period>(__r); }

 constexpr duration<typename common_type<rep>::type, period>
 operator-() const
 { return duration<typename common_type<rep>::type, period>(-__r); }

 constexpr duration&
 operator++()
 {
   ++__r;
   return *this;
 }

 constexpr duration
 operator++(int)
 { return duration(__r++); }

 constexpr duration&
 operator--()
 {
   --__r;
   return *this;
 }

 constexpr duration
 operator--(int)
 { return duration(__r--); }

 constexpr duration&
 operator+=(const duration& __d)
 {
   __r += __d.count();
   return *this;
 }

 constexpr duration&
 operator-=(const duration& __d)
 {
   __r -= __d.count();
   return *this;
 }

 constexpr duration&
 operator*=(const rep& __rhs)
 {
   __r *= __rhs;
   return *this;
 }

 constexpr duration&
 operator/=(const rep& __rhs)
 {
   __r /= __rhs;
   return *this;
 }


 template<typename _Rep2 = rep>
   constexpr
   __enable_if_t<!treat_as_floating_point<_Rep2>::value, duration&>
   operator%=(const rep& __rhs)
   {
     __r %= __rhs;
     return *this;
   }

 template<typename _Rep2 = rep>
   constexpr
   __enable_if_t<!treat_as_floating_point<_Rep2>::value, duration&>
   operator%=(const duration& __d)
   {
     __r %= __d.count();
     return *this;
   }


 static constexpr duration
 zero() noexcept
 { return duration(duration_values<rep>::zero()); }

 static constexpr duration
 min() noexcept
 { return duration(duration_values<rep>::min()); }

 static constexpr duration
 max() noexcept
 { return duration(duration_values<rep>::max()); }

      private:
 rep __r;
      };





    template<typename _Rep1, typename _Period1,
      typename _Rep2, typename _Period2>
      constexpr typename common_type<duration<_Rep1, _Period1>,
         duration<_Rep2, _Period2>>::type
      operator+(const duration<_Rep1, _Period1>& __lhs,
  const duration<_Rep2, _Period2>& __rhs)
      {
 typedef duration<_Rep1, _Period1> __dur1;
 typedef duration<_Rep2, _Period2> __dur2;
 typedef typename common_type<__dur1,__dur2>::type __cd;
 return __cd(__cd(__lhs).count() + __cd(__rhs).count());
      }


    template<typename _Rep1, typename _Period1,
      typename _Rep2, typename _Period2>
      constexpr typename common_type<duration<_Rep1, _Period1>,
         duration<_Rep2, _Period2>>::type
      operator-(const duration<_Rep1, _Period1>& __lhs,
  const duration<_Rep2, _Period2>& __rhs)
      {
 typedef duration<_Rep1, _Period1> __dur1;
 typedef duration<_Rep2, _Period2> __dur2;
 typedef typename common_type<__dur1,__dur2>::type __cd;
 return __cd(__cd(__lhs).count() - __cd(__rhs).count());
      }
# 731 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    template<typename _Rep1, typename _Rep2,
      typename _CRep = typename common_type<_Rep1, _Rep2>::type>
      using __common_rep_t = typename
 enable_if<is_convertible<const _Rep2&, _CRep>::value, _CRep>::type;
# 743 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    template<typename _Rep1, typename _Period, typename _Rep2>
      constexpr duration<__common_rep_t<_Rep1, _Rep2>, _Period>
      operator*(const duration<_Rep1, _Period>& __d, const _Rep2& __s)
      {
 typedef duration<typename common_type<_Rep1, _Rep2>::type, _Period>
   __cd;
 return __cd(__cd(__d).count() * __s);
      }

    template<typename _Rep1, typename _Rep2, typename _Period>
      constexpr duration<__common_rep_t<_Rep2, _Rep1>, _Period>
      operator*(const _Rep1& __s, const duration<_Rep2, _Period>& __d)
      { return __d * __s; }

    template<typename _Rep1, typename _Period, typename _Rep2>
      constexpr
      duration<__common_rep_t<_Rep1, __disable_if_is_duration<_Rep2>>, _Period>
      operator/(const duration<_Rep1, _Period>& __d, const _Rep2& __s)
      {
 typedef duration<typename common_type<_Rep1, _Rep2>::type, _Period>
   __cd;
 return __cd(__cd(__d).count() / __s);
      }

    template<typename _Rep1, typename _Period1,
      typename _Rep2, typename _Period2>
      constexpr typename common_type<_Rep1, _Rep2>::type
      operator/(const duration<_Rep1, _Period1>& __lhs,
  const duration<_Rep2, _Period2>& __rhs)
      {
 typedef duration<_Rep1, _Period1> __dur1;
 typedef duration<_Rep2, _Period2> __dur2;
 typedef typename common_type<__dur1,__dur2>::type __cd;
 return __cd(__lhs).count() / __cd(__rhs).count();
      }


    template<typename _Rep1, typename _Period, typename _Rep2>
      constexpr
      duration<__common_rep_t<_Rep1, __disable_if_is_duration<_Rep2>>, _Period>
      operator%(const duration<_Rep1, _Period>& __d, const _Rep2& __s)
      {
 typedef duration<typename common_type<_Rep1, _Rep2>::type, _Period>
   __cd;
 return __cd(__cd(__d).count() % __s);
      }

    template<typename _Rep1, typename _Period1,
      typename _Rep2, typename _Period2>
      constexpr typename common_type<duration<_Rep1, _Period1>,
         duration<_Rep2, _Period2>>::type
      operator%(const duration<_Rep1, _Period1>& __lhs,
  const duration<_Rep2, _Period2>& __rhs)
      {
 typedef duration<_Rep1, _Period1> __dur1;
 typedef duration<_Rep2, _Period2> __dur2;
 typedef typename common_type<__dur1,__dur2>::type __cd;
 return __cd(__cd(__lhs).count() % __cd(__rhs).count());
      }
# 811 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    template<typename _Rep1, typename _Period1,
      typename _Rep2, typename _Period2>
      constexpr bool
      operator==(const duration<_Rep1, _Period1>& __lhs,
   const duration<_Rep2, _Period2>& __rhs)
      {
 typedef duration<_Rep1, _Period1> __dur1;
 typedef duration<_Rep2, _Period2> __dur2;
 typedef typename common_type<__dur1,__dur2>::type __ct;
 return __ct(__lhs).count() == __ct(__rhs).count();
      }

    template<typename _Rep1, typename _Period1,
      typename _Rep2, typename _Period2>
      constexpr bool
      operator<(const duration<_Rep1, _Period1>& __lhs,
  const duration<_Rep2, _Period2>& __rhs)
      {
 typedef duration<_Rep1, _Period1> __dur1;
 typedef duration<_Rep2, _Period2> __dur2;
 typedef typename common_type<__dur1,__dur2>::type __ct;
 return __ct(__lhs).count() < __ct(__rhs).count();
      }


    template<typename _Rep1, typename _Period1,
      typename _Rep2, typename _Period2>
      requires three_way_comparable<common_type_t<_Rep1, _Rep2>>
      constexpr auto
      operator<=>(const duration<_Rep1, _Period1>& __lhs,
    const duration<_Rep2, _Period2>& __rhs)
      {
 using __ct = common_type_t<duration<_Rep1, _Period1>,
       duration<_Rep2, _Period2>>;
 return __ct(__lhs).count() <=> __ct(__rhs).count();
      }
# 856 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    template<typename _Rep1, typename _Period1,
      typename _Rep2, typename _Period2>
      constexpr bool
      operator<=(const duration<_Rep1, _Period1>& __lhs,
   const duration<_Rep2, _Period2>& __rhs)
      { return !(__rhs < __lhs); }

    template<typename _Rep1, typename _Period1,
      typename _Rep2, typename _Period2>
      constexpr bool
      operator>(const duration<_Rep1, _Period1>& __lhs,
  const duration<_Rep2, _Period2>& __rhs)
      { return __rhs < __lhs; }

    template<typename _Rep1, typename _Period1,
      typename _Rep2, typename _Period2>
      constexpr bool
      operator>=(const duration<_Rep1, _Period1>& __lhs,
   const duration<_Rep2, _Period2>& __rhs)
      { return !(__lhs < __rhs); }
# 892 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    using nanoseconds = duration<int64_t, nano>;


    using microseconds = duration<int64_t, micro>;


    using milliseconds = duration<int64_t, milli>;


    using seconds = duration<int64_t>;


    using minutes = duration<int64_t, ratio< 60>>;


    using hours = duration<int64_t, ratio<3600>>;



    using days = duration<int64_t, ratio<86400>>;


    using weeks = duration<int64_t, ratio<604800>>;


    using years = duration<int64_t, ratio<31556952>>;


    using months = duration<int64_t, ratio<2629746>>;




    template<typename _Clock, typename _Dur>
      class time_point
      {
 static_assert(__is_duration<_Dur>::value,
     "duration must be a specialization of std::chrono::duration");

      public:
 typedef _Clock clock;
 typedef _Dur duration;
 typedef typename duration::rep rep;
 typedef typename duration::period period;

 constexpr time_point() : __d(duration::zero())
 { }

 constexpr explicit time_point(const duration& __dur)
 : __d(__dur)
 { }


 template<typename _Dur2,
   typename = _Require<is_convertible<_Dur2, _Dur>>>
   constexpr time_point(const time_point<clock, _Dur2>& __t)
   : __d(__t.time_since_epoch())
   { }


 constexpr duration
 time_since_epoch() const
 { return __d; }


 constexpr time_point&
 operator++()
 {
   ++__d;
   return *this;
 }

 constexpr time_point
 operator++(int)
 { return time_point{__d++}; }

 constexpr time_point&
 operator--()
 {
   --__d;
   return *this;
 }

 constexpr time_point
 operator--(int)
 { return time_point{__d--}; }



 constexpr time_point&
 operator+=(const duration& __dur)
 {
   __d += __dur;
   return *this;
 }

 constexpr time_point&
 operator-=(const duration& __dur)
 {
   __d -= __dur;
   return *this;
 }


 static constexpr time_point
 min() noexcept
 { return time_point(duration::min()); }

 static constexpr time_point
 max() noexcept
 { return time_point(duration::max()); }

      private:
 duration __d;
      };
# 1020 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    template<typename _ToDur, typename _Clock, typename _Dur>
      [[__nodiscard__]] constexpr
      __enable_if_t<__is_duration<_ToDur>::value, time_point<_Clock, _ToDur>>
      time_point_cast(const time_point<_Clock, _Dur>& __t)
      {
 typedef time_point<_Clock, _ToDur> __time_point;
 return __time_point(duration_cast<_ToDur>(__t.time_since_epoch()));
      }
# 1042 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    template<typename _ToDur, typename _Clock, typename _Dur>
      [[nodiscard]] constexpr
      enable_if_t<__is_duration_v<_ToDur>, time_point<_Clock, _ToDur>>
      floor(const time_point<_Clock, _Dur>& __tp)
      {
 return time_point<_Clock, _ToDur>{
     chrono::floor<_ToDur>(__tp.time_since_epoch())};
      }
# 1063 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    template<typename _ToDur, typename _Clock, typename _Dur>
      [[nodiscard]] constexpr
      enable_if_t<__is_duration_v<_ToDur>, time_point<_Clock, _ToDur>>
      ceil(const time_point<_Clock, _Dur>& __tp)
      {
 return time_point<_Clock, _ToDur>{
     chrono::ceil<_ToDur>(__tp.time_since_epoch())};
      }
# 1085 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    template<typename _ToDur, typename _Clock, typename _Dur>
      [[nodiscard]] constexpr
      enable_if_t<__is_duration_v<_ToDur>
      && !treat_as_floating_point_v<typename _ToDur::rep>,
    time_point<_Clock, _ToDur>>
      round(const time_point<_Clock, _Dur>& __tp)
      {
 return time_point<_Clock, _ToDur>{
     chrono::round<_ToDur>(__tp.time_since_epoch())};
      }






    template<typename _Clock, typename _Dur1,
      typename _Rep2, typename _Period2>
      constexpr time_point<_Clock,
 typename common_type<_Dur1, duration<_Rep2, _Period2>>::type>
      operator+(const time_point<_Clock, _Dur1>& __lhs,
  const duration<_Rep2, _Period2>& __rhs)
      {
 typedef duration<_Rep2, _Period2> __dur2;
 typedef typename common_type<_Dur1,__dur2>::type __ct;
 typedef time_point<_Clock, __ct> __time_point;
 return __time_point(__lhs.time_since_epoch() + __rhs);
      }


    template<typename _Rep1, typename _Period1,
      typename _Clock, typename _Dur2>
      constexpr time_point<_Clock,
 typename common_type<duration<_Rep1, _Period1>, _Dur2>::type>
      operator+(const duration<_Rep1, _Period1>& __lhs,
  const time_point<_Clock, _Dur2>& __rhs)
      {
 typedef duration<_Rep1, _Period1> __dur1;
 typedef typename common_type<__dur1,_Dur2>::type __ct;
 typedef time_point<_Clock, __ct> __time_point;
 return __time_point(__rhs.time_since_epoch() + __lhs);
      }


    template<typename _Clock, typename _Dur1,
      typename _Rep2, typename _Period2>
      constexpr time_point<_Clock,
 typename common_type<_Dur1, duration<_Rep2, _Period2>>::type>
      operator-(const time_point<_Clock, _Dur1>& __lhs,
  const duration<_Rep2, _Period2>& __rhs)
      {
 typedef duration<_Rep2, _Period2> __dur2;
 typedef typename common_type<_Dur1,__dur2>::type __ct;
 typedef time_point<_Clock, __ct> __time_point;
 return __time_point(__lhs.time_since_epoch() -__rhs);
      }


    template<typename _Clock, typename _Dur1, typename _Dur2>
      constexpr typename common_type<_Dur1, _Dur2>::type
      operator-(const time_point<_Clock, _Dur1>& __lhs,
  const time_point<_Clock, _Dur2>& __rhs)
      { return __lhs.time_since_epoch() - __rhs.time_since_epoch(); }







    template<typename _Clock, typename _Dur1, typename _Dur2>
      constexpr bool
      operator==(const time_point<_Clock, _Dur1>& __lhs,
   const time_point<_Clock, _Dur2>& __rhs)
      { return __lhs.time_since_epoch() == __rhs.time_since_epoch(); }


    template<typename _Clock, typename _Dur1,
      three_way_comparable_with<_Dur1> _Dur2>
      constexpr auto
      operator<=>(const time_point<_Clock, _Dur1>& __lhs,
    const time_point<_Clock, _Dur2>& __rhs)
      { return __lhs.time_since_epoch() <=> __rhs.time_since_epoch(); }
# 1176 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    template<typename _Clock, typename _Dur1, typename _Dur2>
      constexpr bool
      operator<(const time_point<_Clock, _Dur1>& __lhs,
  const time_point<_Clock, _Dur2>& __rhs)
      { return __lhs.time_since_epoch() < __rhs.time_since_epoch(); }

    template<typename _Clock, typename _Dur1, typename _Dur2>
      constexpr bool
      operator<=(const time_point<_Clock, _Dur1>& __lhs,
   const time_point<_Clock, _Dur2>& __rhs)
      { return !(__rhs < __lhs); }

    template<typename _Clock, typename _Dur1, typename _Dur2>
      constexpr bool
      operator>(const time_point<_Clock, _Dur1>& __lhs,
  const time_point<_Clock, _Dur2>& __rhs)
      { return __rhs < __lhs; }

    template<typename _Clock, typename _Dur1, typename _Dur2>
      constexpr bool
      operator>=(const time_point<_Clock, _Dur1>& __lhs,
   const time_point<_Clock, _Dur2>& __rhs)
      { return !(__lhs < __rhs); }
# 1222 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
inline namespace _V2 {







    struct system_clock
    {
      typedef chrono::nanoseconds duration;
      typedef duration::rep rep;
      typedef duration::period period;
      typedef chrono::time_point<system_clock, duration> time_point;

      static_assert(system_clock::duration::min()
      < system_clock::duration::zero(),
      "a clock's minimum duration cannot be less than its epoch");

      static constexpr bool is_steady = false;

      static time_point
      now() noexcept;


      [[__gnu__::__always_inline__]]
      static std::time_t
      to_time_t(const time_point& __t) noexcept
      {
 return std::time_t(duration_cast<chrono::seconds>
      (__t.time_since_epoch()).count());
      }

      [[__gnu__::__always_inline__]]
      static time_point
      from_time_t(std::time_t __t) noexcept
      {
 typedef chrono::time_point<system_clock, seconds> __from;
 return time_point_cast<system_clock::duration>
        (__from(chrono::seconds(__t)));
      }
    };
# 1272 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    struct steady_clock
    {
      typedef chrono::nanoseconds duration;
      typedef duration::rep rep;
      typedef duration::period period;
      typedef chrono::time_point<steady_clock, duration> time_point;

      static constexpr bool is_steady = true;

      static time_point
      now() noexcept;
    };
# 1294 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
    using high_resolution_clock = system_clock;

}




    template<typename _Duration>
      using sys_time = time_point<system_clock, _Duration>;
    using sys_seconds = sys_time<seconds>;
    using sys_days = sys_time<days>;

    using file_clock = ::std::filesystem::__file_clock;

    template<typename _Duration>
      using file_time = time_point<file_clock, _Duration>;

    template<> struct is_clock<system_clock> : true_type { };
    template<> struct is_clock<steady_clock> : true_type { };
    template<> struct is_clock<file_clock> : true_type { };

    template<> inline constexpr bool is_clock_v<system_clock> = true;
    template<> inline constexpr bool is_clock_v<steady_clock> = true;
    template<> inline constexpr bool is_clock_v<file_clock> = true;
# 1329 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
  }


  inline namespace literals
  {
# 1358 "C:/msys64/mingw64/include/c++/15.2.0/bits/chrono.h" 3
  inline namespace chrono_literals
  {



#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wliteral-suffix"

    template<typename _Dur, char... _Digits>
      constexpr _Dur __check_overflow()
      {
 using _Val = __parse_int::_Parse_int<_Digits...>;
 constexpr typename _Dur::rep __repval = _Val::value;
 static_assert(__repval >= 0 && __repval == _Val::value,
        "literal value cannot be represented by duration type");
 return _Dur(__repval);
      }



    constexpr chrono::duration<long double, ratio<3600,1>>
    operator""h(long double __hours)
    { return chrono::duration<long double, ratio<3600,1>>{__hours}; }


    template <char... _Digits>
      constexpr chrono::hours
      operator""h()
      { return __check_overflow<chrono::hours, _Digits...>(); }


    constexpr chrono::duration<long double, ratio<60,1>>
    operator""min(long double __mins)
    { return chrono::duration<long double, ratio<60,1>>{__mins}; }


    template <char... _Digits>
      constexpr chrono::minutes
      operator""min()
      { return __check_overflow<chrono::minutes, _Digits...>(); }


    constexpr chrono::duration<long double>
    operator""s(long double __secs)
    { return chrono::duration<long double>{__secs}; }


    template <char... _Digits>
      constexpr chrono::seconds
      operator""s()
      { return __check_overflow<chrono::seconds, _Digits...>(); }


    constexpr chrono::duration<long double, milli>
    operator""ms(long double __msecs)
    { return chrono::duration<long double, milli>{__msecs}; }


    template <char... _Digits>
      constexpr chrono::milliseconds
      operator""ms()
      { return __check_overflow<chrono::milliseconds, _Digits...>(); }


    constexpr chrono::duration<long double, micro>
    operator""us(long double __usecs)
    { return chrono::duration<long double, micro>{__usecs}; }


    template <char... _Digits>
      constexpr chrono::microseconds
      operator""us()
      { return __check_overflow<chrono::microseconds, _Digits...>(); }


    constexpr chrono::duration<long double, nano>
    operator""ns(long double __nsecs)
    { return chrono::duration<long double, nano>{__nsecs}; }


    template <char... _Digits>
      constexpr chrono::nanoseconds
      operator""ns()
      { return __check_overflow<chrono::nanoseconds, _Digits...>(); }

#pragma GCC diagnostic pop

  }
  }

  namespace chrono
  {
    using namespace literals::chrono_literals;
  }



  namespace filesystem
  {
    struct __file_clock
    {
      using duration = chrono::nanoseconds;
      using rep = duration::rep;
      using period = duration::period;
      using time_point = chrono::time_point<__file_clock>;
      static constexpr bool is_steady = false;

      static time_point
      now() noexcept
      { return _S_from_sys(chrono::system_clock::now()); }


      template<typename _Dur>
 static
 chrono::file_time<common_type_t<_Dur, chrono::seconds>>
 from_sys(const chrono::sys_time<_Dur>& __t) noexcept
 { return _S_from_sys(__t); }


      template<typename _Dur>
 static
 chrono::sys_time<common_type_t<_Dur, chrono::seconds>>
 to_sys(const chrono::file_time<_Dur>& __t) noexcept
 { return _S_to_sys(__t); }


    private:
      using __sys_clock = chrono::system_clock;




      static constexpr chrono::seconds _S_epoch_diff{6437664000};

    protected:

      template<typename _Dur>
 static
 chrono::time_point<__file_clock, common_type_t<_Dur, chrono::seconds>>
 _S_from_sys(const chrono::time_point<__sys_clock, _Dur>& __t) noexcept
 {
   using _CDur = common_type_t<_Dur, chrono::seconds>;
   using __file_time = chrono::time_point<__file_clock, _CDur>;
   return __file_time{__t.time_since_epoch()} - _S_epoch_diff;
 }


      template<typename _Dur>
 static
 chrono::time_point<__sys_clock, common_type_t<_Dur, chrono::seconds>>
 _S_to_sys(const chrono::time_point<__file_clock, _Dur>& __t) noexcept
 {
   using _CDur = common_type_t<_Dur, chrono::seconds>;
   using __sys_time = chrono::time_point<__sys_clock, _CDur>;
   return __sys_time{__t.time_since_epoch()} + _S_epoch_diff;
 }
    };
  }



}
# 46 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 2 3



# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/std_mutex.h" 1 3
# 43 "C:/msys64/mingw64/include/c++/15.2.0/bits/std_mutex.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/gthr.h" 1 3
# 30 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/gthr.h" 3
#pragma GCC visibility push(default)
# 157 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/gthr.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/gthr-default.h" 1 3
# 35 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/gthr-default.h" 3
# 1 "C:/msys64/mingw64/include/pthread.h" 1 3
# 62 "C:/msys64/mingw64/include/pthread.h" 3
# 1 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/stddef.h" 1 3 4
# 1 "C:/msys64/mingw64/include/stddef.h" 1 3 4
# 2 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/stddef.h" 2 3 4
# 63 "C:/msys64/mingw64/include/pthread.h" 2 3

# 1 "C:/msys64/mingw64/include/sys/types.h" 1 3
# 43 "C:/msys64/mingw64/include/sys/types.h" 3
typedef unsigned short _ino_t;

typedef unsigned short ino_t;





typedef unsigned int _dev_t;

typedef unsigned int dev_t;
# 62 "C:/msys64/mingw64/include/sys/types.h" 3
__extension__
typedef long long _pid_t;




typedef _pid_t pid_t;
# 84 "C:/msys64/mingw64/include/sys/types.h" 3
typedef unsigned int useconds_t;
# 103 "C:/msys64/mingw64/include/sys/types.h" 3
__extension__
typedef unsigned long long _sigset_t;
# 65 "C:/msys64/mingw64/include/pthread.h" 2 3

# 1 "C:/msys64/mingw64/include/process.h" 1 3
# 10 "C:/msys64/mingw64/include/process.h" 3
# 1 "C:/msys64/mingw64/include/corecrt_startup.h" 1 3
# 13 "C:/msys64/mingw64/include/corecrt_startup.h" 3
extern "C" {


typedef enum _crt_app_type {
    _crt_unknown_app,
    _crt_console_app,
    _crt_gui_app
} _crt_app_type;

__attribute__ ((__dllimport__)) _crt_app_type __attribute__((__cdecl__)) _query_app_type(void);
__attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _set_app_type(_crt_app_type _Type);

typedef enum _crt_argv_mode {
    _crt_argv_no_arguments,
    _crt_argv_unexpanded_arguments,
    _crt_argv_expanded_arguments
} _crt_argv_mode;

__attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _configure_narrow_argv(_crt_argv_mode mode);
__attribute__ ((__dllimport__)) errno_t __attribute__((__cdecl__)) _configure_wide_argv(_crt_argv_mode mode);

__attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _initialize_narrow_environment(void);
__attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _initialize_wide_environment(void);

__attribute__ ((__dllimport__)) char** __attribute__((__cdecl__)) _get_initial_narrow_environment(void);
__attribute__ ((__dllimport__)) wchar_t** __attribute__((__cdecl__)) _get_initial_wide_environment(void);

__attribute__ ((__dllimport__)) char* __attribute__((__cdecl__)) _get_narrow_winmain_command_line(void);
__attribute__ ((__dllimport__)) wchar_t* __attribute__((__cdecl__)) _get_wide_winmain_command_line(void);

__attribute__ ((__dllimport__)) char **__attribute__((__cdecl__)) __p__acmdln(void);


__attribute__ ((__dllimport__)) wchar_t **__attribute__((__cdecl__)) __p__wcmdln(void);


typedef void (__attribute__((__cdecl__)) *_PVFV)(void);
typedef int (__attribute__((__cdecl__)) *_PIFV)(void);
typedef void (__attribute__((__cdecl__)) *_PVFI)(int);

__attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _initterm(_PVFV* _First, _PVFV* _Last);
__attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _initterm_e(_PIFV* _First, _PIFV* _Last);

typedef struct _onexit_table_t {
    _PVFV* _first;
    _PVFV* _last;
    _PVFV* _end;
} _onexit_table_t;

typedef int (__attribute__((__cdecl__)) *_onexit_t)(void);

__attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _initialize_onexit_table(_onexit_table_t*);
__attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _register_onexit_function(_onexit_table_t*,_onexit_t);
__attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _execute_onexit_table(_onexit_table_t*);
__attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _crt_atexit(_PVFV func);
__attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _crt_at_quick_exit(_PVFV func);


}
# 11 "C:/msys64/mingw64/include/process.h" 2 3






extern "C" {
# 32 "C:/msys64/mingw64/include/process.h" 3
  typedef void (__attribute__((__cdecl__)) *_beginthread_proc_type)(void *);
  typedef unsigned (__attribute__((__stdcall__)) *_beginthreadex_proc_type)(void *);

  __attribute__ ((__dllimport__)) uintptr_t __attribute__((__cdecl__)) _beginthread(_beginthread_proc_type _StartAddress,unsigned _StackSize,void *_ArgList);
  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _endthread(void) __attribute__ ((__noreturn__));
  __attribute__ ((__dllimport__)) uintptr_t __attribute__((__cdecl__)) _beginthreadex(void *_Security,unsigned _StackSize,_beginthreadex_proc_type _StartAddress,void *_ArgList,unsigned _InitFlag,unsigned *_ThrdAddr);
  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _endthreadex(unsigned _Retval) __attribute__ ((__noreturn__));
# 64 "C:/msys64/mingw64/include/process.h" 3
  typedef void (__attribute__((__stdcall__)) *_tls_callback_type)(void*,unsigned long,void*);
  __attribute__ ((__dllimport__)) void __attribute__((__cdecl__)) _register_thread_local_exe_atexit_callback(_tls_callback_type callback);

  void __attribute__((__cdecl__)) __attribute__ ((__nothrow__)) _cexit(void);
  void __attribute__((__cdecl__)) __attribute__ ((__nothrow__)) _c_exit(void);

  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) _getpid(void);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _cwait(int *_TermStat,intptr_t _ProcHandle,int _Action);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _execl(const char *_Filename,const char *_ArgList,...);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _execle(const char *_Filename,const char *_ArgList,...);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _execlp(const char *_Filename,const char *_ArgList,...);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _execlpe(const char *_Filename,const char *_ArgList,...);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _execv(const char *_Filename,const char *const *_ArgList);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _execve(const char *_Filename,const char *const *_ArgList,const char *const *_Env);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _execvp(const char *_Filename,const char *const *_ArgList);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _execvpe(const char *_Filename,const char *const *_ArgList,const char *const *_Env);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _spawnl(int _Mode,const char *_Filename,const char *_ArgList,...);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _spawnle(int _Mode,const char *_Filename,const char *_ArgList,...);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _spawnlp(int _Mode,const char *_Filename,const char *_ArgList,...);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _spawnlpe(int _Mode,const char *_Filename,const char *_ArgList,...);
# 100 "C:/msys64/mingw64/include/process.h" 3
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _wexecl(const wchar_t *_Filename,const wchar_t *_ArgList,...);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _wexecle(const wchar_t *_Filename,const wchar_t *_ArgList,...);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _wexeclp(const wchar_t *_Filename,const wchar_t *_ArgList,...);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _wexeclpe(const wchar_t *_Filename,const wchar_t *_ArgList,...);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _wexecv(const wchar_t *_Filename,const wchar_t *const *_ArgList);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _wexecve(const wchar_t *_Filename,const wchar_t *const *_ArgList,const wchar_t *const *_Env);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _wexecvp(const wchar_t *_Filename,const wchar_t *const *_ArgList);
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) _wexecvpe(const wchar_t *_Filename,const wchar_t *const *_ArgList,const wchar_t *const *_Env);
# 129 "C:/msys64/mingw64/include/process.h" 3
  intptr_t __attribute__((__cdecl__)) _loaddll(char *_Filename);
  int __attribute__((__cdecl__)) _unloaddll(intptr_t _Handle);
  int (__attribute__((__cdecl__)) *__attribute__((__cdecl__)) _getdllprocaddr(intptr_t _Handle,char *_ProcedureName,intptr_t _Ordinal))(void);
# 161 "C:/msys64/mingw64/include/process.h" 3
  int __attribute__((__cdecl__)) getpid(void) ;



  intptr_t __attribute__((__cdecl__)) cwait(int *_TermStat,intptr_t _ProcHandle,int _Action) ;

  int __attribute__((__cdecl__)) execl(const char *_Filename,const char *_ArgList,...) ;
  int __attribute__((__cdecl__)) execle(const char *_Filename,const char *_ArgList,...) ;
  int __attribute__((__cdecl__)) execlp(const char *_Filename,const char *_ArgList,...) ;
  int __attribute__((__cdecl__)) execlpe(const char *_Filename,const char *_ArgList,...) ;






  intptr_t __attribute__((__cdecl__)) spawnl(int,const char *_Filename,const char *_ArgList,...) ;
  intptr_t __attribute__((__cdecl__)) spawnle(int,const char *_Filename,const char *_ArgList,...) ;
  intptr_t __attribute__((__cdecl__)) spawnlp(int,const char *_Filename,const char *_ArgList,...) ;
  intptr_t __attribute__((__cdecl__)) spawnlpe(int,const char *_Filename,const char *_ArgList,...) ;





  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) execv(const char *_Filename,char *const _ArgList[]) ;
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) execve(const char *_Filename,char *const _ArgList[],char *const _Env[]) ;
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) execvp(const char *_Filename,char *const _ArgList[]) ;
  __attribute__ ((__dllimport__)) int __attribute__((__cdecl__)) execvpe(const char *_Filename,char *const _ArgList[],char *const _Env[]) ;






  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) spawnv(int,const char *_Filename,char *const _ArgList[]) ;
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) spawnve(int,const char *_Filename,char *const _ArgList[],char *const _Env[]) ;
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) spawnvp(int,const char *_Filename,char *const _ArgList[]) ;
  __attribute__ ((__dllimport__)) intptr_t __attribute__((__cdecl__)) spawnvpe(int,const char *_Filename,char *const _ArgList[],char *const _Env[]) ;




}
# 67 "C:/msys64/mingw64/include/pthread.h" 2 3
# 1 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/limits.h" 1 3 4
# 68 "C:/msys64/mingw64/include/pthread.h" 2 3
# 1 "C:/msys64/mingw64/include/signal.h" 1 3
# 10 "C:/msys64/mingw64/include/signal.h" 3
# 1 "C:/msys64/mingw64/include/pthread_signal.h" 1 3
# 11 "C:/msys64/mingw64/include/signal.h" 2 3


extern "C" {




  typedef int sig_atomic_t;
# 48 "C:/msys64/mingw64/include/signal.h" 3
  typedef void (*__p_sig_fn_t)(int);
# 57 "C:/msys64/mingw64/include/signal.h" 3
  extern void **__attribute__((__cdecl__)) __pxcptinfoptrs(void);


  __p_sig_fn_t __attribute__((__cdecl__)) signal(int _SigNum,__p_sig_fn_t _Func);
  int __attribute__((__cdecl__)) raise(int _SigNum);


}
# 69 "C:/msys64/mingw64/include/pthread.h" 2 3



# 1 "C:/msys64/mingw64/include/sched.h" 1 3 4
# 25 "C:/msys64/mingw64/include/sched.h" 3 4
# 1 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/stddef.h" 1 3 4
# 1 "C:/msys64/mingw64/include/stddef.h" 1 3 4
# 2 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/stddef.h" 2 3 4
# 26 "C:/msys64/mingw64/include/sched.h" 2 3 4




# 1 "C:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/15.2.0/include/limits.h" 1 3 4
# 31 "C:/msys64/mingw64/include/sched.h" 2 3 4
# 42 "C:/msys64/mingw64/include/sched.h" 3 4
struct sched_param {
  int sched_priority;
};


extern "C" {


 int sched_yield(void);
 int sched_get_priority_min(int pol);
 int sched_get_priority_max(int pol);
 int sched_getscheduler(pid_t pid);
 int sched_setscheduler(pid_t pid, int pol, const struct sched_param *param);


}
# 73 "C:/msys64/mingw64/include/pthread.h" 2 3






extern "C" {
# 141 "C:/msys64/mingw64/include/pthread.h" 3
 void * pthread_timechange_handler_np(void * dummy);
 int pthread_delay32_np (const struct _timespec32 *interval);
 int pthread_delay64_np (const struct _timespec64 *interval);
__inline__ __attribute__((__always_inline__)) int pthread_delay_np (const struct timespec *interval)
{



  return pthread_delay64_np ((const struct _timespec64 *) interval);

}
 int pthread_num_processors_np(void);
 int pthread_set_num_processors_np(int n);
# 170 "C:/msys64/mingw64/include/pthread.h" 3
typedef long pthread_once_t;
typedef unsigned pthread_mutexattr_t;
typedef unsigned pthread_key_t;
typedef void *pthread_barrierattr_t;
typedef int pthread_condattr_t;
typedef int pthread_rwlockattr_t;
typedef uintptr_t pthread_t;

typedef struct _pthread_cleanup _pthread_cleanup;
struct _pthread_cleanup
{
    void (*func)(void *);
    void *arg;
    _pthread_cleanup *next;
};
# 212 "C:/msys64/mingw64/include/pthread.h" 3
typedef struct pthread_attr_t pthread_attr_t;
struct pthread_attr_t
{
    unsigned p_state;
    void *stack;
    size_t s_size;
    struct sched_param param;
};

 int pthread_attr_setschedparam(pthread_attr_t *attr, const struct sched_param *param);
 int pthread_attr_getschedparam(const pthread_attr_t *attr, struct sched_param *param);
 int pthread_getschedparam(pthread_t thread, int *pol, struct sched_param *param);
 int pthread_setschedparam(pthread_t thread, int pol, const struct sched_param *param);
 int pthread_attr_setschedpolicy (pthread_attr_t *attr, int pol);
 int pthread_attr_getschedpolicy (const pthread_attr_t *attr, int *pol);


typedef intptr_t pthread_spinlock_t;
typedef intptr_t pthread_mutex_t;
typedef intptr_t pthread_cond_t;
typedef intptr_t pthread_rwlock_t;
typedef void *pthread_barrier_t;
# 252 "C:/msys64/mingw64/include/pthread.h" 3
 extern void (**_pthread_key_dest)(void *);
 int pthread_key_create(pthread_key_t *key, void (* dest)(void *));
 int pthread_key_delete(pthread_key_t key);
 void * pthread_getspecific(pthread_key_t key);
 int pthread_setspecific(pthread_key_t key, const void *value);

 pthread_t pthread_self(void);
 int pthread_once(pthread_once_t *o, void (*func)(void));
 void pthread_testcancel(void);
 int pthread_equal(pthread_t t1, pthread_t t2);
 void pthread_tls_init(void);
 void _pthread_cleanup_dest(pthread_t t);
 int pthread_get_concurrency(int *val);
 int pthread_set_concurrency(int val);
 void pthread_exit(void *res);
 void _pthread_invoke_cancel(void);
 int pthread_cancel(pthread_t t);
 int pthread_kill(pthread_t t, int sig);
 unsigned _pthread_get_state(const pthread_attr_t *attr, unsigned flag);
 int _pthread_set_state(pthread_attr_t *attr, unsigned flag, unsigned val);
 int pthread_setcancelstate(int state, int *oldstate);
 int pthread_setcanceltype(int type, int *oldtype);
 unsigned __attribute__((__stdcall__)) pthread_create_wrapper(void *args);
 int pthread_create(pthread_t *th, const pthread_attr_t *attr, void *(* func)(void *), void *arg);
 int pthread_join(pthread_t t, void **res);
 int pthread_detach(pthread_t t);
 int pthread_setname_np(pthread_t thread, const char *name);
 int pthread_getname_np(pthread_t thread, char *name, size_t len);

 int pthread_rwlock_init(pthread_rwlock_t *rwlock_, const pthread_rwlockattr_t *attr);
 int pthread_rwlock_wrlock(pthread_rwlock_t *l);
 int pthread_rwlock_timedwrlock32(pthread_rwlock_t *rwlock, const struct _timespec32 *ts);
 int pthread_rwlock_timedwrlock64(pthread_rwlock_t *rwlock, const struct _timespec64 *ts);
__inline__ __attribute__((__always_inline__)) int pthread_rwlock_timedwrlock(pthread_rwlock_t *rwlock, const struct timespec *ts)
{



  return pthread_rwlock_timedwrlock64 (rwlock, (const struct _timespec64 *) ts);

}
 int pthread_rwlock_rdlock(pthread_rwlock_t *l);
 int pthread_rwlock_timedrdlock32(pthread_rwlock_t *l, const struct _timespec32 *ts);
 int pthread_rwlock_timedrdlock64(pthread_rwlock_t *l, const struct _timespec64 *ts);
__inline__ __attribute__((__always_inline__)) int pthread_rwlock_timedrdlock(pthread_rwlock_t *l, const struct timespec *ts)
{



  return pthread_rwlock_timedrdlock64 (l, (const struct _timespec64 *) ts);

}
 int pthread_rwlock_unlock(pthread_rwlock_t *l);
 int pthread_rwlock_tryrdlock(pthread_rwlock_t *l);
 int pthread_rwlock_trywrlock(pthread_rwlock_t *l);
 int pthread_rwlock_destroy (pthread_rwlock_t *l);

 int pthread_cond_init(pthread_cond_t *cv, const pthread_condattr_t *a);
 int pthread_cond_destroy(pthread_cond_t *cv);
 int pthread_cond_signal (pthread_cond_t *cv);
 int pthread_cond_broadcast (pthread_cond_t *cv);
 int pthread_cond_wait (pthread_cond_t *cv, pthread_mutex_t *external_mutex);
 int pthread_cond_timedwait32(pthread_cond_t *cv, pthread_mutex_t *external_mutex, const struct _timespec32 *t);
 int pthread_cond_timedwait64(pthread_cond_t *cv, pthread_mutex_t *external_mutex, const struct _timespec64 *t);
__inline__ __attribute__((__always_inline__)) int pthread_cond_timedwait(pthread_cond_t *cv, pthread_mutex_t *external_mutex, const struct timespec *t)
{



  return pthread_cond_timedwait64 (cv, external_mutex, (const struct _timespec64 *) t);

}
 int pthread_cond_timedwait32_relative_np(pthread_cond_t *cv, pthread_mutex_t *external_mutex, const struct _timespec32 *t);
 int pthread_cond_timedwait64_relative_np(pthread_cond_t *cv, pthread_mutex_t *external_mutex, const struct _timespec64 *t);
__inline__ __attribute__((__always_inline__)) int pthread_cond_timedwait_relative_np(pthread_cond_t *cv, pthread_mutex_t *external_mutex, const struct timespec *t)
{



  return pthread_cond_timedwait64_relative_np (cv, external_mutex, (const struct _timespec64 *) t);

}

 int pthread_mutex_lock(pthread_mutex_t *m);
 int pthread_mutex_timedlock32(pthread_mutex_t *m, const struct _timespec32 *ts);
 int pthread_mutex_timedlock64(pthread_mutex_t *m, const struct _timespec64 *ts);
__inline__ __attribute__((__always_inline__)) int pthread_mutex_timedlock(pthread_mutex_t *m, const struct timespec *ts)
{



  return pthread_mutex_timedlock64 (m, (const struct _timespec64 *) ts);

}
 int pthread_mutex_unlock(pthread_mutex_t *m);
 int pthread_mutex_trylock(pthread_mutex_t *m);
 int pthread_mutex_init(pthread_mutex_t *m, const pthread_mutexattr_t *a);
 int pthread_mutex_destroy(pthread_mutex_t *m);

 int pthread_barrier_destroy(pthread_barrier_t *b);
 int pthread_barrier_init(pthread_barrier_t *b, const void *attr, unsigned int count);
 int pthread_barrier_wait(pthread_barrier_t *b);

 int pthread_spin_init(pthread_spinlock_t *l, int pshared);
 int pthread_spin_destroy(pthread_spinlock_t *l);

 int pthread_spin_lock(pthread_spinlock_t *l);
 int pthread_spin_trylock(pthread_spinlock_t *l);
 int pthread_spin_unlock(pthread_spinlock_t *l);

 int pthread_attr_init(pthread_attr_t *attr);
 int pthread_attr_destroy(pthread_attr_t *attr);
 int pthread_attr_setdetachstate(pthread_attr_t *a, int flag);
 int pthread_attr_getdetachstate(const pthread_attr_t *a, int *flag);
 int pthread_attr_setinheritsched(pthread_attr_t *a, int flag);
 int pthread_attr_getinheritsched(const pthread_attr_t *a, int *flag);
 int pthread_attr_setscope(pthread_attr_t *a, int flag);
 int pthread_attr_getscope(const pthread_attr_t *a, int *flag);
 int pthread_attr_getstack(const pthread_attr_t *attr, void **stack, size_t *size);
 int pthread_attr_setstack(pthread_attr_t *attr, void *stack, size_t size);
 int pthread_attr_getstackaddr(const pthread_attr_t *attr, void **stack);
 int pthread_attr_setstackaddr(pthread_attr_t *attr, void *stack);
 int pthread_attr_getstacksize(const pthread_attr_t *attr, size_t *size);
 int pthread_attr_setstacksize(pthread_attr_t *attr, size_t size);

 int pthread_mutexattr_init(pthread_mutexattr_t *a);
 int pthread_mutexattr_destroy(pthread_mutexattr_t *a);
 int pthread_mutexattr_gettype(const pthread_mutexattr_t *a, int *type);
 int pthread_mutexattr_settype(pthread_mutexattr_t *a, int type);
 int pthread_mutexattr_getpshared(const pthread_mutexattr_t *a, int *type);
 int pthread_mutexattr_setpshared(pthread_mutexattr_t * a, int type);
 int pthread_mutexattr_getprotocol(const pthread_mutexattr_t *a, int *type);
 int pthread_mutexattr_setprotocol(pthread_mutexattr_t *a, int type);
 int pthread_mutexattr_getprioceiling(const pthread_mutexattr_t *a, int * prio);
 int pthread_mutexattr_setprioceiling(pthread_mutexattr_t *a, int prio);
 int pthread_getconcurrency(void);
 int pthread_setconcurrency(int new_level);

 int pthread_condattr_destroy(pthread_condattr_t *a);
 int pthread_condattr_init(pthread_condattr_t *a);
 int pthread_condattr_getpshared(const pthread_condattr_t *a, int *s);
 int pthread_condattr_setpshared(pthread_condattr_t *a, int s);

 int pthread_condattr_getclock (const pthread_condattr_t *attr,
       clockid_t *clock_id);
 int pthread_condattr_setclock(pthread_condattr_t *attr,
       clockid_t clock_id);

 int pthread_barrierattr_init(void **attr);
 int pthread_barrierattr_destroy(void **attr);
 int pthread_barrierattr_setpshared(void **attr, int s);
 int pthread_barrierattr_getpshared(void **attr, int *s);


 struct _pthread_cleanup ** pthread_getclean (void);
 void * pthread_gethandle (pthread_t t);
 void * pthread_getevent (void);

 int _pthread_tryjoin (pthread_t t, void **res);
 int pthread_rwlockattr_destroy(pthread_rwlockattr_t *a);
 int pthread_rwlockattr_getpshared(pthread_rwlockattr_t *a, int *s);
 int pthread_rwlockattr_init(pthread_rwlockattr_t *a);
 int pthread_rwlockattr_setpshared(pthread_rwlockattr_t *a, int s);
# 426 "C:/msys64/mingw64/include/pthread.h" 3
# 1 "C:/msys64/mingw64/include/pthread_unistd.h" 1 3
# 427 "C:/msys64/mingw64/include/pthread.h" 2 3
# 688 "C:/msys64/mingw64/include/pthread.h" 3
}
# 36 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/gthr-default.h" 2 3
# 62 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/gthr-default.h" 3
typedef pthread_t __gthread_t;
typedef pthread_key_t __gthread_key_t;
typedef pthread_once_t __gthread_once_t;
typedef pthread_mutex_t __gthread_mutex_t;



typedef pthread_mutex_t __gthread_recursive_mutex_t;
typedef pthread_cond_t __gthread_cond_t;
typedef struct timespec __gthread_time_t;
# 123 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/gthr-default.h" 3



































# 345 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/gthr-default.h" 3
inline __attribute__((__always_inline__)) int
__gthread_active_p (void)
{
  return 1;
}
# 705 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/gthr-default.h" 3
inline __attribute__((__always_inline__)) int
__gthread_create (__gthread_t *__threadid, void *(*__func) (void*),
    void *__args)
{
  return pthread_create (__threadid, __null, __func, __args);
}

inline __attribute__((__always_inline__)) int
__gthread_join (__gthread_t __threadid, void **__value_ptr)
{
  return pthread_join (__threadid, __value_ptr);
}

inline __attribute__((__always_inline__)) int
__gthread_detach (__gthread_t __threadid)
{
  return pthread_detach (__threadid);
}

inline __attribute__((__always_inline__)) int
__gthread_equal (__gthread_t __t1, __gthread_t __t2)
{
  return pthread_equal (__t1, __t2);
}

inline __attribute__((__always_inline__)) __gthread_t
__gthread_self (void)
{
  return pthread_self ();
}

inline __attribute__((__always_inline__)) int
__gthread_yield (void)
{
  return sched_yield ();
}

inline __attribute__((__always_inline__)) int
__gthread_once (__gthread_once_t *__once, void (*__func) (void))
{
  if (__gthread_active_p ())
    return pthread_once (__once, __func);
  else
    return -1;
}

inline __attribute__((__always_inline__)) int
__gthread_key_create (__gthread_key_t *__key, void (*__dtor) (void *))
{
  return pthread_key_create (__key, __dtor);
}

inline __attribute__((__always_inline__)) int
__gthread_key_delete (__gthread_key_t __key)
{
  return pthread_key_delete (__key);
}

inline __attribute__((__always_inline__)) void *
__gthread_getspecific (__gthread_key_t __key)
{
  return pthread_getspecific (__key);
}

inline __attribute__((__always_inline__)) int
__gthread_setspecific (__gthread_key_t __key, const void *__ptr)
{
  return pthread_setspecific (__key, __ptr);
}

inline __attribute__((__always_inline__)) void
__gthread_mutex_init_function (__gthread_mutex_t *__mutex)
{
  if (__gthread_active_p ())
    pthread_mutex_init (__mutex, __null);
}

inline __attribute__((__always_inline__)) int
__gthread_mutex_destroy (__gthread_mutex_t *__mutex)
{
  if (__gthread_active_p ())
    return pthread_mutex_destroy (__mutex);
  else
    return 0;
}

inline __attribute__((__always_inline__)) int
__gthread_mutex_lock (__gthread_mutex_t *__mutex)
{
  if (__gthread_active_p ())
    return pthread_mutex_lock (__mutex);
  else
    return 0;
}

inline __attribute__((__always_inline__)) int
__gthread_mutex_trylock (__gthread_mutex_t *__mutex)
{
  if (__gthread_active_p ())
    return pthread_mutex_trylock (__mutex);
  else
    return 0;
}


inline __attribute__((__always_inline__)) int
__gthread_mutex_timedlock (__gthread_mutex_t *__mutex,
      const __gthread_time_t *__abs_timeout)
{
  if (__gthread_active_p ())
    return pthread_mutex_timedlock (__mutex, __abs_timeout);
  else
    return 0;
}


inline __attribute__((__always_inline__)) int
__gthread_mutex_unlock (__gthread_mutex_t *__mutex)
{
  if (__gthread_active_p ())
    return pthread_mutex_unlock (__mutex);
  else
    return 0;
}



inline __attribute__((__always_inline__)) int
__gthread_recursive_mutex_init_function (__gthread_recursive_mutex_t *__mutex)
{
  if (__gthread_active_p ())
    {
      pthread_mutexattr_t __attr;
      int __r;

      __r = pthread_mutexattr_init (&__attr);
      if (!__r)
 __r = pthread_mutexattr_settype (&__attr,
         2);
      if (!__r)
 __r = pthread_mutex_init (__mutex, &__attr);
      if (!__r)
 __r = pthread_mutexattr_destroy (&__attr);
      return __r;
    }
  return 0;
}


inline __attribute__((__always_inline__)) int
__gthread_recursive_mutex_lock (__gthread_recursive_mutex_t *__mutex)
{
  return __gthread_mutex_lock (__mutex);
}

inline __attribute__((__always_inline__)) int
__gthread_recursive_mutex_trylock (__gthread_recursive_mutex_t *__mutex)
{
  return __gthread_mutex_trylock (__mutex);
}


inline __attribute__((__always_inline__)) int
__gthread_recursive_mutex_timedlock (__gthread_recursive_mutex_t *__mutex,
         const __gthread_time_t *__abs_timeout)
{
  return __gthread_mutex_timedlock (__mutex, __abs_timeout);
}


inline __attribute__((__always_inline__)) int
__gthread_recursive_mutex_unlock (__gthread_recursive_mutex_t *__mutex)
{
  return __gthread_mutex_unlock (__mutex);
}

inline __attribute__((__always_inline__)) int
__gthread_recursive_mutex_destroy (__gthread_recursive_mutex_t *__mutex)
{
  return __gthread_mutex_destroy (__mutex);
}
# 896 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/gthr-default.h" 3
inline __attribute__((__always_inline__)) int
__gthread_cond_broadcast (__gthread_cond_t *__cond)
{
  return pthread_cond_broadcast (__cond);
}

inline __attribute__((__always_inline__)) int
__gthread_cond_signal (__gthread_cond_t *__cond)
{
  return pthread_cond_signal (__cond);
}

inline __attribute__((__always_inline__)) int
__gthread_cond_wait (__gthread_cond_t *__cond, __gthread_mutex_t *__mutex)
{
  return pthread_cond_wait (__cond, __mutex);
}

inline __attribute__((__always_inline__)) int
__gthread_cond_timedwait (__gthread_cond_t *__cond, __gthread_mutex_t *__mutex,
     const __gthread_time_t *__abs_timeout)
{
  return pthread_cond_timedwait (__cond, __mutex, __abs_timeout);
}

inline __attribute__((__always_inline__)) int
__gthread_cond_wait_recursive (__gthread_cond_t *__cond,
          __gthread_recursive_mutex_t *__mutex)
{
  return __gthread_cond_wait (__cond, __mutex);
}

inline __attribute__((__always_inline__)) int
__gthread_cond_destroy (__gthread_cond_t* __cond)
{
  return pthread_cond_destroy (__cond);
}
# 158 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/gthr.h" 2 3


#pragma GCC visibility pop
# 44 "C:/msys64/mingw64/include/c++/15.2.0/bits/std_mutex.h" 2 3

namespace std
{

# 61 "C:/msys64/mingw64/include/c++/15.2.0/bits/std_mutex.h" 3
  class __mutex_base
  {
  protected:
    typedef __gthread_mutex_t __native_type;






    __native_type _M_mutex;

    __mutex_base() noexcept
    {

      __gthread_mutex_init_function(&_M_mutex);
    }

    ~__mutex_base() noexcept { __gthread_mutex_destroy(&_M_mutex); }


    __mutex_base(const __mutex_base&) = delete;
    __mutex_base& operator=(const __mutex_base&) = delete;
  };
# 98 "C:/msys64/mingw64/include/c++/15.2.0/bits/std_mutex.h" 3
  class mutex : private __mutex_base
  {
  public:
    typedef __native_type* native_handle_type;




    mutex() noexcept = default;
    ~mutex() = default;

    mutex(const mutex&) = delete;
    mutex& operator=(const mutex&) = delete;

    void
    lock()
    {
      int __e = __gthread_mutex_lock(&_M_mutex);


      if (__e)
 __throw_system_error(__e);
    }

    [[__nodiscard__]]
    bool
    try_lock() noexcept
    {

      return !__gthread_mutex_trylock(&_M_mutex);
    }

    void
    unlock()
    {

      __gthread_mutex_unlock(&_M_mutex);
    }

    native_handle_type
    native_handle() noexcept
    { return &_M_mutex; }
  };




  class __condvar
  {
    using timespec = __gthread_time_t;

  public:
    __condvar() noexcept
    {



    }

    ~__condvar()
    {
      int __e __attribute__((__unused__)) = __gthread_cond_destroy(&_M_cond);
      do { if (__builtin_expect(!bool(__e != 16), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/std_mutex.h", 160, __PRETTY_FUNCTION__, "__e != 16"); } while (false);
    }

    __condvar(const __condvar&) = delete;
    __condvar& operator=(const __condvar&) = delete;

    __gthread_cond_t* native_handle() noexcept { return &_M_cond; }


    void
    wait(mutex& __m)
    {
      int __e __attribute__((__unused__))
 = __gthread_cond_wait(&_M_cond, __m.native_handle());
      do { if (__builtin_expect(!bool(__e == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/std_mutex.h", 174, __PRETTY_FUNCTION__, "__e == 0"); } while (false);
    }

    void
    wait_until(mutex& __m, timespec& __abs_time)
    {
      __gthread_cond_timedwait(&_M_cond, __m.native_handle(), &__abs_time);
    }
# 192 "C:/msys64/mingw64/include/c++/15.2.0/bits/std_mutex.h" 3
    void
    notify_one() noexcept
    {
      int __e __attribute__((__unused__)) = __gthread_cond_signal(&_M_cond);
      do { if (__builtin_expect(!bool(__e == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/std_mutex.h", 196, __PRETTY_FUNCTION__, "__e == 0"); } while (false);
    }

    void
    notify_all() noexcept
    {
      int __e __attribute__((__unused__)) = __gthread_cond_broadcast(&_M_cond);
      do { if (__builtin_expect(!bool(__e == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/std_mutex.h", 203, __PRETTY_FUNCTION__, "__e == 0"); } while (false);
    }

  protected:

    __gthread_cond_t _M_cond = (pthread_cond_t)-1;



  };





  struct defer_lock_t { explicit defer_lock_t() = default; };


  struct try_to_lock_t { explicit try_to_lock_t() = default; };



  struct adopt_lock_t { explicit adopt_lock_t() = default; };


  inline constexpr defer_lock_t defer_lock { };


  inline constexpr try_to_lock_t try_to_lock { };


  inline constexpr adopt_lock_t adopt_lock { };
# 244 "C:/msys64/mingw64/include/c++/15.2.0/bits/std_mutex.h" 3
  template<typename _Mutex>
    class lock_guard
    {
    public:
      typedef _Mutex mutex_type;

      [[__nodiscard__]]
      explicit lock_guard(mutex_type& __m) : _M_device(__m)
      { _M_device.lock(); }

      [[__nodiscard__]]
      lock_guard(mutex_type& __m, adopt_lock_t) noexcept : _M_device(__m)
      { }

      ~lock_guard()
      { _M_device.unlock(); }

      lock_guard(const lock_guard&) = delete;
      lock_guard& operator=(const lock_guard&) = delete;

    private:
      mutex_type& _M_device;
    };



}
# 50 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 2 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/unique_lock.h" 1 3
# 42 "C:/msys64/mingw64/include/c++/15.2.0/bits/unique_lock.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/error_constants.h" 1 3
# 34 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/error_constants.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/cerrno" 1 3
# 35 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/error_constants.h" 2 3

namespace std
{




  enum class errc
    {
      address_family_not_supported = 102,
      address_in_use = 100,
      address_not_available = 101,
      already_connected = 113,
      argument_list_too_long = 7,
      argument_out_of_domain = 33,
      bad_address = 14,
      bad_file_descriptor = 9,

      bad_message = 104,

      broken_pipe = 32,
      connection_aborted = 106,
      connection_already_in_progress = 103,
      connection_refused = 107,
      connection_reset = 108,
      cross_device_link = 18,
      destination_address_required = 109,
      device_or_resource_busy = 16,
      directory_not_empty = 41,
      executable_format_error = 8,
      file_exists = 17,
      file_too_large = 27,
      filename_too_long = 38,
      function_not_supported = 40,
      host_unreachable = 110,

      identifier_removed = 111,

      illegal_byte_sequence = 42,
      inappropriate_io_control_operation = 25,
      interrupted = 4,
      invalid_argument = 22,
      invalid_seek = 29,
      io_error = 5,
      is_a_directory = 21,
      message_size = 115,
      network_down = 116,
      network_reset = 117,
      network_unreachable = 118,
      no_buffer_space = 119,

      no_child_process = 10,


      no_link = 121,

      no_lock_available = 39,

      no_message_available = 120,


      no_message = 122,

      no_protocol_option = 123,

      no_space_on_device = 28,


      no_stream_resources = 124,

      no_such_device_or_address = 6,
      no_such_device = 19,
      no_such_file_or_directory = 2,
      no_such_process = 3,
      not_a_directory = 20,
      not_a_socket = 128,

      not_a_stream = 125,

      not_connected = 126,
      not_enough_memory = 12,

      not_supported = 129,

      operation_canceled = 105,
      operation_in_progress = 112,

      operation_not_permitted = 1,

      operation_not_supported = 130,

      operation_would_block = 140,


      owner_dead = 133,

      permission_denied = 13,
      protocol_error = 134,
      protocol_not_supported = 135,
      read_only_file_system = 30,
      resource_deadlock_would_occur = 36,
      resource_unavailable_try_again = 11,
      result_out_of_range = 34,

      state_not_recoverable = 127,


      stream_timeout = 137,


      text_file_busy = 139,


      timed_out = 138,

      too_many_files_open_in_system = 23,
      too_many_files_open = 24,
      too_many_links = 31,
      too_many_symbolic_link_levels = 114,

      value_too_large = 132,

      wrong_protocol_type = 136
   };


}
# 43 "C:/msys64/mingw64/include/c++/15.2.0/bits/unique_lock.h" 2 3



namespace std
{

# 61 "C:/msys64/mingw64/include/c++/15.2.0/bits/unique_lock.h" 3
  template<typename _Mutex>
    class unique_lock
    {
    public:
      typedef _Mutex mutex_type;

      unique_lock() noexcept
      : _M_device(0), _M_owns(false)
      { }

      [[__nodiscard__]]
      explicit unique_lock(mutex_type& __m)
      : _M_device(std::__addressof(__m)), _M_owns(false)
      {
 lock();
 _M_owns = true;
      }

      unique_lock(mutex_type& __m, defer_lock_t) noexcept
      : _M_device(std::__addressof(__m)), _M_owns(false)
      { }

      [[__nodiscard__]]
      unique_lock(mutex_type& __m, try_to_lock_t)
      : _M_device(std::__addressof(__m)), _M_owns(_M_device->try_lock())
      { }

      [[__nodiscard__]]
      unique_lock(mutex_type& __m, adopt_lock_t) noexcept
      : _M_device(std::__addressof(__m)), _M_owns(true)
      {

      }

      template<typename _Clock, typename _Duration>
 [[__nodiscard__]]
 unique_lock(mutex_type& __m,
      const chrono::time_point<_Clock, _Duration>& __atime)
 : _M_device(std::__addressof(__m)),
   _M_owns(_M_device->try_lock_until(__atime))
 { }

      template<typename _Rep, typename _Period>
 [[__nodiscard__]]
 unique_lock(mutex_type& __m,
      const chrono::duration<_Rep, _Period>& __rtime)
 : _M_device(std::__addressof(__m)),
   _M_owns(_M_device->try_lock_for(__rtime))
 { }

      ~unique_lock()
      {
 if (_M_owns)
   unlock();
      }

      unique_lock(const unique_lock&) = delete;
      unique_lock& operator=(const unique_lock&) = delete;

      unique_lock(unique_lock&& __u) noexcept
      : _M_device(__u._M_device), _M_owns(__u._M_owns)
      {
 __u._M_device = 0;
 __u._M_owns = false;
      }

      unique_lock& operator=(unique_lock&& __u) noexcept
      {


 unique_lock(std::move(__u)).swap(*this);
 return *this;
      }

      void
      lock()
      {
 if (!_M_device)
   __throw_system_error(int(errc::operation_not_permitted));
 else if (_M_owns)
   __throw_system_error(int(errc::resource_deadlock_would_occur));
 else
   {
     _M_device->lock();
     _M_owns = true;
   }
      }

      [[__nodiscard__]]
      bool
      try_lock()
      {
 if (!_M_device)
   __throw_system_error(int(errc::operation_not_permitted));
 else if (_M_owns)
   __throw_system_error(int(errc::resource_deadlock_would_occur));
 else
   {
     _M_owns = _M_device->try_lock();
     return _M_owns;
   }
      }

      template<typename _Clock, typename _Duration>
 [[__nodiscard__]]
 bool
 try_lock_until(const chrono::time_point<_Clock, _Duration>& __atime)
 {
   if (!_M_device)
     __throw_system_error(int(errc::operation_not_permitted));
   else if (_M_owns)
     __throw_system_error(int(errc::resource_deadlock_would_occur));
   else
     {
       _M_owns = _M_device->try_lock_until(__atime);
       return _M_owns;
     }
 }

      template<typename _Rep, typename _Period>
 [[__nodiscard__]]
 bool
 try_lock_for(const chrono::duration<_Rep, _Period>& __rtime)
 {
   if (!_M_device)
     __throw_system_error(int(errc::operation_not_permitted));
   else if (_M_owns)
     __throw_system_error(int(errc::resource_deadlock_would_occur));
   else
     {
       _M_owns = _M_device->try_lock_for(__rtime);
       return _M_owns;
     }
  }

      void
      unlock()
      {
 if (!_M_owns)
   __throw_system_error(int(errc::operation_not_permitted));
 else if (_M_device)
   {
     _M_device->unlock();
     _M_owns = false;
   }
      }

      void
      swap(unique_lock& __u) noexcept
      {
 std::swap(_M_device, __u._M_device);
 std::swap(_M_owns, __u._M_owns);
      }

      mutex_type*
      release() noexcept
      {
 mutex_type* __ret = _M_device;
 _M_device = 0;
 _M_owns = false;
 return __ret;
      }

      [[__nodiscard__]]
      bool
      owns_lock() const noexcept
      { return _M_owns; }

      explicit operator bool() const noexcept
      { return owns_lock(); }

      [[__nodiscard__]]
      mutex_type*
      mutex() const noexcept
      { return _M_device; }

    private:
      mutex_type* _M_device;
      bool _M_owns;
    };



  template<typename _Mutex>
    inline void
    swap(unique_lock<_Mutex>& __x, unique_lock<_Mutex>& __y) noexcept
    { __x.swap(__y); }


}
# 51 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 2 3




# 1 "C:/msys64/mingw64/include/c++/15.2.0/ext/atomicity.h" 1 3
# 38 "C:/msys64/mingw64/include/c++/15.2.0/ext/atomicity.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/atomic_word.h" 1 3
# 32 "C:/msys64/mingw64/include/c++/15.2.0/x86_64-w64-mingw32/bits/atomic_word.h" 3
typedef int _Atomic_word;
# 39 "C:/msys64/mingw64/include/c++/15.2.0/ext/atomicity.h" 2 3




namespace __gnu_cxx
{


  __attribute__((__always_inline__))
  inline bool
  __is_single_threaded() noexcept
  {





    return !__gthread_active_p();

  }






  inline _Atomic_word
  __attribute__((__always_inline__))
  __exchange_and_add(volatile _Atomic_word* __mem, int __val)
  { return __atomic_fetch_add(__mem, __val, 4); }

  inline void
  __attribute__((__always_inline__))
  __atomic_add(volatile _Atomic_word* __mem, int __val)
  { __atomic_fetch_add(__mem, __val, 4); }
# 82 "C:/msys64/mingw64/include/c++/15.2.0/ext/atomicity.h" 3
  inline _Atomic_word
  __attribute__((__always_inline__))
  __exchange_and_add_single(_Atomic_word* __mem, int __val)
  {
    _Atomic_word __result = *__mem;
    *__mem += __val;
    return __result;
  }

  inline void
  __attribute__((__always_inline__))
  __atomic_add_single(_Atomic_word* __mem, int __val)
  { *__mem += __val; }

  inline _Atomic_word
  __attribute__ ((__always_inline__))
  __exchange_and_add_dispatch(_Atomic_word* __mem, int __val)
  {
    if (__is_single_threaded())
      return __exchange_and_add_single(__mem, __val);
    else
      return __exchange_and_add(__mem, __val);
  }

  inline void
  __attribute__ ((__always_inline__))
  __atomic_add_dispatch(_Atomic_word* __mem, int __val)
  {
    if (__is_single_threaded())
      __atomic_add_single(__mem, __val);
    else
      __atomic_add(__mem, __val);
  }


}
# 56 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 2 3






# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 63 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 2 3

namespace std
{

# 77 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 3
  class __recursive_mutex_base
  {
  protected:
    typedef __gthread_recursive_mutex_t __native_type;

    __recursive_mutex_base(const __recursive_mutex_base&) = delete;
    __recursive_mutex_base& operator=(const __recursive_mutex_base&) = delete;


    __native_type _M_mutex = (pthread_mutex_t)-3;

    __recursive_mutex_base() = default;
# 101 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 3
  };
# 113 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 3
  class recursive_mutex : private __recursive_mutex_base
  {
  public:
    typedef __native_type* native_handle_type;

    recursive_mutex() = default;
    ~recursive_mutex() = default;

    recursive_mutex(const recursive_mutex&) = delete;
    recursive_mutex& operator=(const recursive_mutex&) = delete;

    void
    lock()
    {
      int __e = __gthread_recursive_mutex_lock(&_M_mutex);


      if (__e)
 __throw_system_error(__e);
    }

    [[__nodiscard__]]
    bool
    try_lock() noexcept
    {

      return !__gthread_recursive_mutex_trylock(&_M_mutex);
    }

    void
    unlock()
    {

      __gthread_recursive_mutex_unlock(&_M_mutex);
    }

    native_handle_type
    native_handle() noexcept
    { return &_M_mutex; }
  };




  template<typename _Derived>
    class __timed_mutex_impl
    {
    protected:
      template<typename _Rep, typename _Period>
 bool
 _M_try_lock_for(const chrono::duration<_Rep, _Period>& __rtime)
 {



   using __clock = chrono::system_clock;


   auto __rt = chrono::duration_cast<__clock::duration>(__rtime);
   if (ratio_greater<__clock::period, _Period>())
     ++__rt;
   return _M_try_lock_until(__clock::now() + __rt);
 }

      template<typename _Duration>
 bool
 _M_try_lock_until(const chrono::time_point<chrono::system_clock,
         _Duration>& __atime)
 {
   auto __s = chrono::time_point_cast<chrono::seconds>(__atime);
   auto __ns = chrono::duration_cast<chrono::nanoseconds>(__atime - __s);

   __gthread_time_t __ts = {
     static_cast<std::time_t>(__s.time_since_epoch().count()),
     static_cast<long>(__ns.count())
   };

   return static_cast<_Derived*>(this)->_M_timedlock(__ts);
 }
# 212 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 3
      template<typename _Clock, typename _Duration>
 bool
 _M_try_lock_until(const chrono::time_point<_Clock, _Duration>& __atime)
 {

   static_assert(chrono::is_clock_v<_Clock>);




   auto __now = _Clock::now();
   do {
     auto __rtime = __atime - __now;
     if (_M_try_lock_for(__rtime))
       return true;
     __now = _Clock::now();
   } while (__atime > __now);
   return false;
 }
    };
# 242 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 3
  class timed_mutex
  : private __mutex_base, public __timed_mutex_impl<timed_mutex>
  {
  public:
    typedef __native_type* native_handle_type;

    timed_mutex() = default;
    ~timed_mutex() = default;

    timed_mutex(const timed_mutex&) = delete;
    timed_mutex& operator=(const timed_mutex&) = delete;

    void
    lock()
    {
      int __e = __gthread_mutex_lock(&_M_mutex);


      if (__e)
 __throw_system_error(__e);
    }

    [[__nodiscard__]]
    bool
    try_lock() noexcept
    {

      return !__gthread_mutex_trylock(&_M_mutex);
    }

    template <class _Rep, class _Period>
      [[__nodiscard__]]
      bool
      try_lock_for(const chrono::duration<_Rep, _Period>& __rtime)
      { return _M_try_lock_for(__rtime); }

    template <class _Clock, class _Duration>
      [[__nodiscard__]]
      bool
      try_lock_until(const chrono::time_point<_Clock, _Duration>& __atime)
      { return _M_try_lock_until(__atime); }

    void
    unlock()
    {

      __gthread_mutex_unlock(&_M_mutex);
    }

    native_handle_type
    native_handle() noexcept
    { return &_M_mutex; }

    private:
      friend class __timed_mutex_impl<timed_mutex>;

      bool
      _M_timedlock(const __gthread_time_t& __ts)
      { return !__gthread_mutex_timedlock(&_M_mutex, &__ts); }






  };
# 319 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 3
  class recursive_timed_mutex
  : private __recursive_mutex_base,
    public __timed_mutex_impl<recursive_timed_mutex>
  {
  public:
    typedef __native_type* native_handle_type;

    recursive_timed_mutex() = default;
    ~recursive_timed_mutex() = default;

    recursive_timed_mutex(const recursive_timed_mutex&) = delete;
    recursive_timed_mutex& operator=(const recursive_timed_mutex&) = delete;

    void
    lock()
    {
      int __e = __gthread_recursive_mutex_lock(&_M_mutex);


      if (__e)
 __throw_system_error(__e);
    }

    [[__nodiscard__]]
    bool
    try_lock() noexcept
    {

      return !__gthread_recursive_mutex_trylock(&_M_mutex);
    }

    template <class _Rep, class _Period>
      [[__nodiscard__]]
      bool
      try_lock_for(const chrono::duration<_Rep, _Period>& __rtime)
      { return _M_try_lock_for(__rtime); }

    template <class _Clock, class _Duration>
      [[__nodiscard__]]
      bool
      try_lock_until(const chrono::time_point<_Clock, _Duration>& __atime)
      { return _M_try_lock_until(__atime); }

    void
    unlock()
    {

      __gthread_recursive_mutex_unlock(&_M_mutex);
    }

    native_handle_type
    native_handle() noexcept
    { return &_M_mutex; }

    private:
      friend class __timed_mutex_impl<recursive_timed_mutex>;

      bool
      _M_timedlock(const __gthread_time_t& __ts)
      { return !__gthread_recursive_mutex_timedlock(&_M_mutex, &__ts); }






  };
# 566 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 3
  namespace __detail
  {

    template<typename _Lockable>
      inline int
      __try_lock_impl(_Lockable& __l)
      {
 if (unique_lock<_Lockable> __lock{__l, try_to_lock})
   {
     __lock.release();
     return -1;
   }
 else
   return 0;
      }



    template<typename _L0, typename... _Lockables>
      inline int
      __try_lock_impl(_L0& __l0, _Lockables&... __lockables)
      {

 if constexpr ((is_same_v<_L0, _Lockables> && ...))
   {
     constexpr int _Np = 1 + sizeof...(_Lockables);
     unique_lock<_L0> __locks[_Np] = {
  {__l0, defer_lock}, {__lockables, defer_lock}...
     };
     for (int __i = 0; __i < _Np; ++__i)
       {
  if (!__locks[__i].try_lock())
    {
      const int __failed = __i;
      while (__i--)
        __locks[__i].unlock();
      return __failed;
    }
       }
     for (auto& __l : __locks)
       __l.release();
     return -1;
   }
 else

 if (unique_lock<_L0> __lock{__l0, try_to_lock})
   {
     int __idx = __detail::__try_lock_impl(__lockables...);
     if (__idx == -1)
       {
  __lock.release();
  return -1;
       }
     return __idx + 1;
   }
 else
   return 0;
      }

  }
# 638 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 3
  template<typename _L1, typename _L2, typename... _L3>
    [[__nodiscard__]]
    inline int
    try_lock(_L1& __l1, _L2& __l2, _L3&... __l3)
    {
      return __detail::__try_lock_impl(__l1, __l2, __l3...);
    }


  namespace __detail
  {





    template<typename _L0, typename... _L1>
      void
      __lock_impl(int& __i, int __depth, _L0& __l0, _L1&... __l1)
      {
 while (__i >= __depth)
   {
     if (__i == __depth)
       {
  int __failed = 1;
  {
    unique_lock<_L0> __first(__l0);
    __failed += __detail::__try_lock_impl(__l1...);
    if (!__failed)
      {
        __i = -1;
        __first.release();
        return;
      }
  }

  __gthread_yield();

  constexpr auto __n = 1 + sizeof...(_L1);
  __i = (__depth + __failed) % __n;
       }
     else
       __detail::__lock_impl(__i, __depth + 1, __l1..., __l0);
   }
      }

  }
# 698 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 3
  template<typename _L1, typename _L2, typename... _L3>
    void
    lock(_L1& __l1, _L2& __l2, _L3&... __l3)
    {

      if constexpr (is_same_v<_L1, _L2> && (is_same_v<_L1, _L3> && ...))
 {
   constexpr int _Np = 2 + sizeof...(_L3);
   unique_lock<_L1> __locks[] = {
       {__l1, defer_lock}, {__l2, defer_lock}, {__l3, defer_lock}...
   };
   int __first = 0;
   do {
     __locks[__first].lock();
     for (int __j = 1; __j < _Np; ++__j)
       {
  const int __idx = (__first + __j) % _Np;
  if (!__locks[__idx].try_lock())
    {
      for (int __k = __j; __k != 0; --__k)
        __locks[(__first + __k - 1) % _Np].unlock();
      __first = __idx;
      break;
    }
       }
   } while (!__locks[__first].owns_lock());

   for (auto& __l : __locks)
     __l.release();
 }
      else

 {
   int __i = 0;
   __detail::__lock_impl(__i, 0, __l1, __l2, __l3...);
 }
    }
# 745 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 3
  template<typename... _MutexTypes>
    class scoped_lock
    {
    public:

      [[nodiscard]]
      explicit scoped_lock(_MutexTypes&... __m) : _M_devices(std::tie(__m...))
      { std::lock(__m...); }

      [[nodiscard]]
      explicit scoped_lock(adopt_lock_t, _MutexTypes&... __m) noexcept
      : _M_devices(std::tie(__m...))
      { }

      ~scoped_lock()
      { std::apply([](auto&... __m) { (__m.unlock(), ...); }, _M_devices); }

      scoped_lock(const scoped_lock&) = delete;
      scoped_lock& operator=(const scoped_lock&) = delete;

    private:
      tuple<_MutexTypes&...> _M_devices;
    };

  template<>
    class scoped_lock<>
    {
    public:
      explicit scoped_lock() = default;
      explicit scoped_lock(adopt_lock_t) noexcept { }
      ~scoped_lock() = default;

      scoped_lock(const scoped_lock&) = delete;
      scoped_lock& operator=(const scoped_lock&) = delete;
    };

  template<typename _Mutex>
    class scoped_lock<_Mutex>
    {
    public:
      using mutex_type = _Mutex;

      [[nodiscard]]
      explicit scoped_lock(mutex_type& __m) : _M_device(__m)
      { _M_device.lock(); }

      [[nodiscard]]
      explicit scoped_lock(adopt_lock_t, mutex_type& __m) noexcept
      : _M_device(__m)
      { }

      ~scoped_lock()
      { _M_device.unlock(); }

      scoped_lock(const scoped_lock&) = delete;
      scoped_lock& operator=(const scoped_lock&) = delete;

    private:
      mutex_type& _M_device;
    };




  struct once_flag
  {
    constexpr once_flag() noexcept = default;


    once_flag(const once_flag&) = delete;

    once_flag& operator=(const once_flag&) = delete;

  private:


    __gthread_once_t _M_once = 0;

    struct _Prepare_execution;

    template<typename _Callable, typename... _Args>
      friend void
      call_once(once_flag& __once, _Callable&& __f, _Args&&... __args);
  };





  extern __thread void* __once_callable;
  extern __thread void (*__once_call)();


  struct once_flag::_Prepare_execution
  {
    template<typename _Callable>
      explicit
      _Prepare_execution(_Callable& __c)
      {

 __once_callable = std::__addressof(__c);

 __once_call = [] { (*static_cast<_Callable*>(__once_callable))(); };
      }

    ~_Prepare_execution()
    {

      __once_callable = nullptr;
      __once_call = nullptr;
    }

    _Prepare_execution(const _Prepare_execution&) = delete;
    _Prepare_execution& operator=(const _Prepare_execution&) = delete;
  };
# 902 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 3
  extern "C" void __once_proxy(void);


  template<typename _Callable, typename... _Args>
    void
    call_once(once_flag& __once, _Callable&& __f, _Args&&... __args)
    {

      auto __callable = [&] {
   std::__invoke(std::forward<_Callable>(__f),
   std::forward<_Args>(__args)...);
      };

      once_flag::_Prepare_execution __exec(__callable);


      if (int __e = __gthread_once(&__once._M_once, &__once_proxy))
 __throw_system_error(__e);
    }
# 1023 "C:/msys64/mingw64/include/c++/15.2.0/mutex" 3

}
# 2916 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 2
# 3010 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"

# 3010 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
static void* vma_aligned_alloc(size_t alignment, size_t size)
{
    return _aligned_malloc(size, alignment);
}
# 3028 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
static void vma_aligned_free(void* ptr)
{
    _aligned_free(ptr);
}
# 3118 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    static inline void VmaUint32ToStr(char* outStr, size_t strLen, uint32_t num)
    {
        snprintf(outStr, strLen, "%" 
# 3120 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                                    "u"
# 3120 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                          , num);
    }
    static inline void VmaUint64ToStr(char* outStr, size_t strLen, uint64_t num)
    {
        snprintf(outStr, strLen, "%" 
# 3124 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                                    "llu"
# 3124 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                          , num);
    }
    static inline void VmaPtrToStr(char* outStr, size_t strLen, const void* ptr)
    {
        snprintf(outStr, strLen, "%p", ptr);
    }



    class VmaMutex
    {
    private: VmaMutex(const VmaMutex&) = delete; VmaMutex(VmaMutex&&) = delete; VmaMutex& operator=(const VmaMutex&) = delete; VmaMutex& operator=(VmaMutex&&) = delete;
    public:
        VmaMutex() { }
        void Lock() { m_Mutex.lock(); }
        void Unlock() { m_Mutex.unlock(); }
        bool TryLock() { return m_Mutex.try_lock(); }
    private:
        std::mutex m_Mutex;
    };







# 1 "C:/msys64/mingw64/include/c++/15.2.0/shared_mutex" 1 3
# 48 "C:/msys64/mingw64/include/c++/15.2.0/shared_mutex" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 49 "C:/msys64/mingw64/include/c++/15.2.0/shared_mutex" 2 3






# 54 "C:/msys64/mingw64/include/c++/15.2.0/shared_mutex" 3
namespace std
{

# 66 "C:/msys64/mingw64/include/c++/15.2.0/shared_mutex" 3
  class shared_mutex;


  class shared_timed_mutex;
# 85 "C:/msys64/mingw64/include/c++/15.2.0/shared_mutex" 3
  ; inline int __glibcxx_rwlock_rdlock (pthread_rwlock_t *__rwlock) { if (__gthread_active_p ()) return pthread_rwlock_rdlock (__rwlock); else return 0; }
  ; inline int __glibcxx_rwlock_tryrdlock (pthread_rwlock_t *__rwlock) { if (__gthread_active_p ()) return pthread_rwlock_tryrdlock (__rwlock); else return 0; }
  ; inline int __glibcxx_rwlock_wrlock (pthread_rwlock_t *__rwlock) { if (__gthread_active_p ()) return pthread_rwlock_wrlock (__rwlock); else return 0; }
  ; inline int __glibcxx_rwlock_trywrlock (pthread_rwlock_t *__rwlock) { if (__gthread_active_p ()) return pthread_rwlock_trywrlock (__rwlock); else return 0; }
  ; inline int __glibcxx_rwlock_unlock (pthread_rwlock_t *__rwlock) { if (__gthread_active_p ()) return pthread_rwlock_unlock (__rwlock); else return 0; }
# 103 "C:/msys64/mingw64/include/c++/15.2.0/shared_mutex" 3
   ;
  inline int
  __glibcxx_rwlock_timedrdlock (pthread_rwlock_t *__rwlock,
    const timespec *__ts)
  {
    if (__gthread_active_p ())
      return pthread_rwlock_timedrdlock (__rwlock, __ts);
    else
      return 0;
  }
   ;
  inline int
  __glibcxx_rwlock_timedwrlock (pthread_rwlock_t *__rwlock,
    const timespec *__ts)
  {
    if (__gthread_active_p ())
      return pthread_rwlock_timedwrlock (__rwlock, __ts);
    else
      return 0;
  }
# 159 "C:/msys64/mingw64/include/c++/15.2.0/shared_mutex" 3
  class __shared_mutex_pthread
  {
    friend class shared_timed_mutex;


    pthread_rwlock_t _M_rwlock = (pthread_rwlock_t)-1;

  public:
    __shared_mutex_pthread() = default;
    ~__shared_mutex_pthread() = default;
# 194 "C:/msys64/mingw64/include/c++/15.2.0/shared_mutex" 3
    __shared_mutex_pthread(const __shared_mutex_pthread&) = delete;
    __shared_mutex_pthread& operator=(const __shared_mutex_pthread&) = delete;

    void
    lock()
    {
      int __ret = __glibcxx_rwlock_wrlock(&_M_rwlock);
      if (__ret == 36)
 __throw_system_error(int(errc::resource_deadlock_would_occur));

      do { if (__builtin_expect(!bool(__ret == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/shared_mutex", 204, __PRETTY_FUNCTION__, "__ret == 0"); } while (false);
    }

    bool
    try_lock()
    {
      int __ret = __glibcxx_rwlock_trywrlock(&_M_rwlock);
      if (__ret == 16) return false;

      do { if (__builtin_expect(!bool(__ret == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/shared_mutex", 213, __PRETTY_FUNCTION__, "__ret == 0"); } while (false);
      return true;
    }

    void
    unlock()
    {
      int __ret __attribute((__unused__)) = __glibcxx_rwlock_unlock(&_M_rwlock);

      do { if (__builtin_expect(!bool(__ret == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/shared_mutex", 222, __PRETTY_FUNCTION__, "__ret == 0"); } while (false);
    }



    void
    lock_shared()
    {
      int __ret;




      do
 __ret = __glibcxx_rwlock_rdlock(&_M_rwlock);
      while (__ret == 11);
      if (__ret == 36)
 __throw_system_error(int(errc::resource_deadlock_would_occur));

      do { if (__builtin_expect(!bool(__ret == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/shared_mutex", 241, __PRETTY_FUNCTION__, "__ret == 0"); } while (false);
    }

    bool
    try_lock_shared()
    {
      int __ret = __glibcxx_rwlock_tryrdlock(&_M_rwlock);



      if (__ret == 16 || __ret == 11) return false;

      do { if (__builtin_expect(!bool(__ret == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/shared_mutex", 253, __PRETTY_FUNCTION__, "__ret == 0"); } while (false);
      return true;
    }

    void
    unlock_shared()
    {
      unlock();
    }

    void* native_handle() { return &_M_rwlock; }
  };
# 416 "C:/msys64/mingw64/include/c++/15.2.0/shared_mutex" 3
  class shared_mutex
  {
  public:
    shared_mutex() = default;
    ~shared_mutex() = default;

    shared_mutex(const shared_mutex&) = delete;
    shared_mutex& operator=(const shared_mutex&) = delete;



    void lock() { _M_impl.lock(); }
    [[nodiscard]] bool try_lock() { return _M_impl.try_lock(); }
    void unlock() { _M_impl.unlock(); }



    void lock_shared() { _M_impl.lock_shared(); }
    [[nodiscard]] bool try_lock_shared() { return _M_impl.try_lock_shared(); }
    void unlock_shared() { _M_impl.unlock_shared(); }


    typedef void* native_handle_type;
    native_handle_type native_handle() { return _M_impl.native_handle(); }

  private:
    __shared_mutex_pthread _M_impl;




  };




  using __shared_timed_mutex_base = __shared_mutex_pthread;






  class shared_timed_mutex
  : private __shared_timed_mutex_base
  {
    using _Base = __shared_timed_mutex_base;





    using __clock_t = chrono::system_clock;


  public:
    shared_timed_mutex() = default;
    ~shared_timed_mutex() = default;

    shared_timed_mutex(const shared_timed_mutex&) = delete;
    shared_timed_mutex& operator=(const shared_timed_mutex&) = delete;



    void lock() { _Base::lock(); }
    [[__nodiscard__]] bool try_lock() { return _Base::try_lock(); }
    void unlock() { _Base::unlock(); }

    template<typename _Rep, typename _Period>
      [[__nodiscard__]]
      bool
      try_lock_for(const chrono::duration<_Rep, _Period>& __rtime)
      {
 auto __rt = chrono::duration_cast<__clock_t::duration>(__rtime);
 if (ratio_greater<__clock_t::period, _Period>())
   ++__rt;
 return try_lock_until(__clock_t::now() + __rt);
      }



    void lock_shared() { _Base::lock_shared(); }
    [[__nodiscard__]]
    bool try_lock_shared() { return _Base::try_lock_shared(); }
    void unlock_shared() { _Base::unlock_shared(); }

    template<typename _Rep, typename _Period>
      [[__nodiscard__]]
      bool
      try_lock_shared_for(const chrono::duration<_Rep, _Period>& __rtime)
      {
 auto __rt = chrono::duration_cast<__clock_t::duration>(__rtime);
 if (ratio_greater<__clock_t::period, _Period>())
   ++__rt;
 return try_lock_shared_until(__clock_t::now() + __rt);
      }





    template<typename _Duration>
      [[__nodiscard__]]
      bool
      try_lock_until(const chrono::time_point<chrono::system_clock,
       _Duration>& __atime)
      {
 auto __s = chrono::time_point_cast<chrono::seconds>(__atime);
 auto __ns = chrono::duration_cast<chrono::nanoseconds>(__atime - __s);

 __gthread_time_t __ts =
   {
     static_cast<std::time_t>(__s.time_since_epoch().count()),
     static_cast<long>(__ns.count())
   };

 int __ret = __glibcxx_rwlock_timedwrlock(&_M_rwlock, &__ts);


 if (__ret == 138 || __ret == 36)
   return false;

 do { if (__builtin_expect(!bool(__ret == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/shared_mutex", 538, __PRETTY_FUNCTION__, "__ret == 0"); } while (false);
 return true;
      }
# 570 "C:/msys64/mingw64/include/c++/15.2.0/shared_mutex" 3
    template<typename _Clock, typename _Duration>
      [[__nodiscard__]]
      bool
      try_lock_until(const chrono::time_point<_Clock, _Duration>& __atime)
      {

 static_assert(chrono::is_clock_v<_Clock>);




 typename _Clock::time_point __now = _Clock::now();
 do {
     auto __rtime = __atime - __now;
     if (try_lock_for(__rtime))
       return true;
     __now = _Clock::now();
 } while (__atime > __now);
 return false;
      }



    template<typename _Duration>
      [[__nodiscard__]]
      bool
      try_lock_shared_until(const chrono::time_point<chrono::system_clock,
       _Duration>& __atime)
      {
 auto __s = chrono::time_point_cast<chrono::seconds>(__atime);
 auto __ns = chrono::duration_cast<chrono::nanoseconds>(__atime - __s);

 __gthread_time_t __ts =
   {
     static_cast<std::time_t>(__s.time_since_epoch().count()),
     static_cast<long>(__ns.count())
   };

 int __ret;
# 622 "C:/msys64/mingw64/include/c++/15.2.0/shared_mutex" 3
 do
   __ret = __glibcxx_rwlock_timedrdlock(&_M_rwlock, &__ts);
 while (__ret == 11 || __ret == 36);
 if (__ret == 138)
   return false;

 do { if (__builtin_expect(!bool(__ret == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/shared_mutex", 628, __PRETTY_FUNCTION__, "__ret == 0"); } while (false);
 return true;
      }
# 660 "C:/msys64/mingw64/include/c++/15.2.0/shared_mutex" 3
    template<typename _Clock, typename _Duration>
      [[__nodiscard__]]
      bool
      try_lock_shared_until(const chrono::time_point<_Clock,
           _Duration>& __atime)
      {

 static_assert(chrono::is_clock_v<_Clock>);




 typename _Clock::time_point __now = _Clock::now();
 do {
     auto __rtime = __atime - __now;
     if (try_lock_shared_for(__rtime))
       return true;
     __now = _Clock::now();
 } while (__atime > __now);
 return false;
      }
# 728 "C:/msys64/mingw64/include/c++/15.2.0/shared_mutex" 3
  };



  template<typename _Mutex>
    class shared_lock
    {
    public:
      typedef _Mutex mutex_type;



      shared_lock() noexcept : _M_pm(nullptr), _M_owns(false) { }

      explicit
      shared_lock(mutex_type& __m)
      : _M_pm(std::__addressof(__m)), _M_owns(true)
      { __m.lock_shared(); }

      shared_lock(mutex_type& __m, defer_lock_t) noexcept
      : _M_pm(std::__addressof(__m)), _M_owns(false) { }

      shared_lock(mutex_type& __m, try_to_lock_t)
      : _M_pm(std::__addressof(__m)), _M_owns(__m.try_lock_shared()) { }

      shared_lock(mutex_type& __m, adopt_lock_t)
      : _M_pm(std::__addressof(__m)), _M_owns(true) { }

      template<typename _Clock, typename _Duration>
 shared_lock(mutex_type& __m,
      const chrono::time_point<_Clock, _Duration>& __abs_time)
      : _M_pm(std::__addressof(__m)),
 _M_owns(__m.try_lock_shared_until(__abs_time)) { }

      template<typename _Rep, typename _Period>
 shared_lock(mutex_type& __m,
      const chrono::duration<_Rep, _Period>& __rel_time)
      : _M_pm(std::__addressof(__m)),
 _M_owns(__m.try_lock_shared_for(__rel_time)) { }

      ~shared_lock()
      {
 if (_M_owns)
   _M_pm->unlock_shared();
      }

      shared_lock(shared_lock const&) = delete;
      shared_lock& operator=(shared_lock const&) = delete;

      shared_lock(shared_lock&& __sl) noexcept : shared_lock()
      { swap(__sl); }

      shared_lock&
      operator=(shared_lock&& __sl) noexcept
      {


 shared_lock(std::move(__sl)).swap(*this);
 return *this;
      }

      void
      lock()
      {
 _M_lockable();
 _M_pm->lock_shared();
 _M_owns = true;
      }

      [[__nodiscard__]]
      bool
      try_lock()
      {
 _M_lockable();
 return _M_owns = _M_pm->try_lock_shared();
      }

      template<typename _Rep, typename _Period>
 [[__nodiscard__]]
 bool
 try_lock_for(const chrono::duration<_Rep, _Period>& __rel_time)
 {
   _M_lockable();
   return _M_owns = _M_pm->try_lock_shared_for(__rel_time);
 }

      template<typename _Clock, typename _Duration>
 [[__nodiscard__]]
 bool
 try_lock_until(const chrono::time_point<_Clock, _Duration>& __abs_time)
 {
   _M_lockable();
   return _M_owns = _M_pm->try_lock_shared_until(__abs_time);
 }

      void
      unlock()
      {
 if (!_M_owns)
   __throw_system_error(int(errc::operation_not_permitted));
 _M_pm->unlock_shared();
 _M_owns = false;
      }



      void
      swap(shared_lock& __u) noexcept
      {
 std::swap(_M_pm, __u._M_pm);
 std::swap(_M_owns, __u._M_owns);
      }

      mutex_type*
      release() noexcept
      {
 _M_owns = false;
 return std::__exchange(_M_pm, nullptr);
      }



      [[__nodiscard__]]
      bool owns_lock() const noexcept { return _M_owns; }

      explicit operator bool() const noexcept { return _M_owns; }

      [[__nodiscard__]]
      mutex_type* mutex() const noexcept { return _M_pm; }

    private:
      void
      _M_lockable() const
      {
 if (_M_pm == nullptr)
   __throw_system_error(int(errc::operation_not_permitted));
 if (_M_owns)
   __throw_system_error(int(errc::resource_deadlock_would_occur));
      }

      mutex_type* _M_pm;
      bool _M_owns;
    };



  template<typename _Mutex>
    void
    swap(shared_lock<_Mutex>& __x, shared_lock<_Mutex>& __y) noexcept
    { __x.swap(__y); }



}
# 3152 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 2
        
# 3152 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       class VmaRWMutex
        {
        public:
            void LockRead() { m_Mutex.lock_shared(); }
            void UnlockRead() { m_Mutex.unlock_shared(); }
            bool TryLockRead() { return m_Mutex.try_lock_shared(); }
            void LockWrite() { m_Mutex.lock(); }
            void UnlockWrite() { m_Mutex.unlock(); }
            bool TryLockWrite() { return m_Mutex.try_lock(); }
        private:
            std::shared_mutex m_Mutex;
        };
# 3204 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
# 1 "C:/msys64/mingw64/include/c++/15.2.0/atomic" 1 3
# 50 "C:/msys64/mingw64/include/c++/15.2.0/atomic" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 51 "C:/msys64/mingw64/include/c++/15.2.0/atomic" 2 3

# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h" 1 3
# 39 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_lockfree_defines.h" 1 3
# 40 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h" 2 3



# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_wait.h" 1 3
# 37 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_wait.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 38 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_wait.h" 2 3



# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/functional_hash.h" 1 3
# 38 "C:/msys64/mingw64/include/c++/15.2.0/bits/functional_hash.h" 3
# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/hash_bytes.h" 1 3
# 39 "C:/msys64/mingw64/include/c++/15.2.0/bits/hash_bytes.h" 3

# 39 "C:/msys64/mingw64/include/c++/15.2.0/bits/hash_bytes.h" 3
namespace std
{







  size_t
  _Hash_bytes(const void* __ptr, size_t __len, size_t __seed);





  size_t
  _Fnv_hash_bytes(const void* __ptr, size_t __len, size_t __seed);


}
# 39 "C:/msys64/mingw64/include/c++/15.2.0/bits/functional_hash.h" 2 3

namespace std
{

# 52 "C:/msys64/mingw64/include/c++/15.2.0/bits/functional_hash.h" 3
  template<typename _Result, typename _Arg>
    struct __hash_base
    {




    };



  template<typename _Tp> struct __hash_empty_base { };



  template<typename _Tp>
    struct hash;

#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wc++14-extensions"
  template<typename _Tp, typename = void>
    constexpr bool __is_hash_enabled_for = false;

  template<typename _Tp>
    constexpr bool
    __is_hash_enabled_for<_Tp,
     __void_t<decltype(hash<_Tp>()(declval<_Tp>()))>>
      = true;
#pragma GCC diagnostic pop


  template<typename _Tp>
    struct __hash_not_enabled
    {
      __hash_not_enabled(__hash_not_enabled&&) = delete;
      ~__hash_not_enabled() = delete;
    };


  template<typename _Tp, bool = true>
    struct __hash_enum : public __hash_base<size_t, _Tp>
    {
      size_t
      operator()(_Tp __val) const noexcept
      {
       using __type = typename underlying_type<_Tp>::type;
       return hash<__type>{}(static_cast<__type>(__val));
      }
    };


  template<typename _Tp>
    struct hash
    : __conditional_t<__is_enum(_Tp), __hash_enum<_Tp>, __hash_not_enabled<_Tp>>
    { };


  template<typename _Tp>
    struct hash<_Tp*> : public __hash_base<size_t, _Tp*>
    {
      size_t
      operator()(_Tp* __p) const noexcept
      { return reinterpret_cast<size_t>(__p); }
    };
# 128 "C:/msys64/mingw64/include/c++/15.2.0/bits/functional_hash.h" 3
  template<> struct hash<bool> : public __hash_base<size_t, bool> { size_t operator()(bool __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<char> : public __hash_base<size_t, char> { size_t operator()(char __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<signed char> : public __hash_base<size_t, signed char> { size_t operator()(signed char __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<unsigned char> : public __hash_base<size_t, unsigned char> { size_t operator()(unsigned char __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<wchar_t> : public __hash_base<size_t, wchar_t> { size_t operator()(wchar_t __val) const noexcept { return static_cast<size_t>(__val); } };



  template<> struct hash<char8_t> : public __hash_base<size_t, char8_t> { size_t operator()(char8_t __val) const noexcept { return static_cast<size_t>(__val); } };



  template<> struct hash<char16_t> : public __hash_base<size_t, char16_t> { size_t operator()(char16_t __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<char32_t> : public __hash_base<size_t, char32_t> { size_t operator()(char32_t __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<short> : public __hash_base<size_t, short> { size_t operator()(short __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<int> : public __hash_base<size_t, int> { size_t operator()(int __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<long> : public __hash_base<size_t, long> { size_t operator()(long __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<long long> : public __hash_base<size_t, long long> { size_t operator()(long long __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<unsigned short> : public __hash_base<size_t, unsigned short> { size_t operator()(unsigned short __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<unsigned int> : public __hash_base<size_t, unsigned int> { size_t operator()(unsigned int __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<unsigned long> : public __hash_base<size_t, unsigned long> { size_t operator()(unsigned long __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<unsigned long long> : public __hash_base<size_t, unsigned long long> { size_t operator()(unsigned long long __val) const noexcept { return static_cast<size_t>(__val); } };


  __extension__
  template<> struct hash<__int128> : public __hash_base<size_t, __int128> { size_t operator()(__int128 __val) const noexcept { return static_cast<size_t>(__val); } };
  __extension__
  template<> struct hash<__int128 unsigned> : public __hash_base<size_t, __int128 unsigned> { size_t operator()(__int128 unsigned __val) const noexcept { return static_cast<size_t>(__val); } };
# 204 "C:/msys64/mingw64/include/c++/15.2.0/bits/functional_hash.h" 3
  struct _Hash_impl
  {
    static size_t
    hash(const void* __ptr, size_t __clength,
  size_t __seed = static_cast<size_t>(0xc70f6907UL))
    { return _Hash_bytes(__ptr, __clength, __seed); }

    template<typename _Tp>
      static size_t
      hash(const _Tp& __val)
      { return hash(&__val, sizeof(__val)); }

    template<typename _Tp>
      static size_t
      __hash_combine(const _Tp& __val, size_t __hash)
      { return hash(&__val, sizeof(__val), __hash); }
  };


  struct _Fnv_hash_impl
  {
    static size_t
    hash(const void* __ptr, size_t __clength,
  size_t __seed = static_cast<size_t>(2166136261UL))
    { return _Fnv_hash_bytes(__ptr, __clength, __seed); }

    template<typename _Tp>
      static size_t
      hash(const _Tp& __val)
      { return hash(&__val, sizeof(__val)); }

    template<typename _Tp>
      static size_t
      __hash_combine(const _Tp& __val, size_t __hash)
      { return hash(&__val, sizeof(__val), __hash); }
  };


  template<>
    struct hash<float> : public __hash_base<size_t, float>
    {
      size_t
      operator()(float __val) const noexcept
      {

 return __val != 0.0f ? std::_Hash_impl::hash(__val) : 0;
      }
    };


  template<>
    struct hash<double> : public __hash_base<size_t, double>
    {
      size_t
      operator()(double __val) const noexcept
      {

 return __val != 0.0 ? std::_Hash_impl::hash(__val) : 0;
      }
    };


  template<>
    struct hash<long double>
    : public __hash_base<size_t, long double>
    {
      __attribute__ ((__pure__)) size_t
      operator()(long double __val) const noexcept;
    };


  template<>
    struct hash<nullptr_t> : public __hash_base<size_t, nullptr_t>
    {
      size_t
      operator()(nullptr_t) const noexcept
      { return 0; }
    };
# 297 "C:/msys64/mingw64/include/c++/15.2.0/bits/functional_hash.h" 3
  template<typename _Hash>
    struct __is_fast_hash : public std::true_type
    { };

  template<>
    struct __is_fast_hash<hash<long double>> : public std::false_type
    { };


}
# 42 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_wait.h" 2 3
# 55 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_wait.h" 3
namespace std
{

  namespace __detail
  {
# 70 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_wait.h" 3
    using __platform_wait_t = unsigned long;



    inline constexpr size_t __platform_wait_alignment
      = __alignof__(__platform_wait_t);

  }

  template<typename _Tp>
    inline constexpr bool __platform_wait_uses_type





      = false;


  namespace __detail
  {
# 133 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_wait.h" 3
    inline void
    __thread_yield() noexcept
    {

     __gthread_yield();

    }

    inline void
    __thread_relax() noexcept
    {

      __builtin_ia32_pause();



    }

    inline constexpr auto __atomic_spin_count_relax = 12;
    inline constexpr auto __atomic_spin_count = 16;

    struct __default_spin_policy
    {
      bool
      operator()() const noexcept
      { return false; }
    };

    template<typename _Pred,
      typename _Spin = __default_spin_policy>
      bool
      __atomic_spin(_Pred& __pred, _Spin __spin = _Spin{ }) noexcept
      {
 for (auto __i = 0; __i < __atomic_spin_count; ++__i)
   {
     if (__pred())
       return true;

     if (__i < __atomic_spin_count_relax)
       __detail::__thread_relax();
     else
       __detail::__thread_yield();
   }

 while (__spin())
   {
     if (__pred())
       return true;
   }

 return false;
      }


    template<typename _Tp>
      bool __atomic_compare(const _Tp& __a, const _Tp& __b)
      {

 return __builtin_memcmp(&__a, &__b, sizeof(_Tp)) == 0;
      }

    struct __waiter_pool_base
    {


      static constexpr auto _S_align = 64;

      alignas(_S_align) __platform_wait_t _M_wait = 0;


      mutex _M_mtx;


      alignas(_S_align) __platform_wait_t _M_ver = 0;


      __condvar _M_cv;

      __waiter_pool_base() = default;

      void
      _M_enter_wait() noexcept
      { __atomic_fetch_add(&_M_wait, 1, 5); }

      void
      _M_leave_wait() noexcept
      { __atomic_fetch_sub(&_M_wait, 1, 3); }

      bool
      _M_waiting() const noexcept
      {
 __platform_wait_t __res;
 __atomic_load(&_M_wait, &__res, 5);
 return __res != 0;
      }

      void
      _M_notify(__platform_wait_t* __addr, [[maybe_unused]] bool __all,
  bool __bare) noexcept
      {
# 243 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_wait.h" 3
 {
   lock_guard<mutex> __l(_M_mtx);
   __atomic_fetch_add(__addr, 1, 0);
 }
 if (__bare || _M_waiting())
   _M_cv.notify_all();

      }

      static __waiter_pool_base&
      _S_for(const void* __addr) noexcept
      {
 constexpr long long unsigned int __ct = 16;
 static __waiter_pool_base __w[__ct];
 auto __key = ((long long unsigned int)__addr >> 2) % __ct;
 return __w[__key];
      }
    };

    struct __waiter_pool : __waiter_pool_base
    {
      void
      _M_do_wait(const __platform_wait_t* __addr, __platform_wait_t __old) noexcept
      {



 __platform_wait_t __val;
 __atomic_load(__addr, &__val, 5);
 if (__val == __old)
   {
     lock_guard<mutex> __l(_M_mtx);
     __atomic_load(__addr, &__val, 0);
     if (__val == __old)
       _M_cv.wait(_M_mtx);
   }

      }
    };

    template<typename _Tp>
      struct __waiter_base
      {
 using __waiter_type = _Tp;

 __waiter_type& _M_w;
 __platform_wait_t* _M_addr;

 template<typename _Up>
   static __platform_wait_t*
   _S_wait_addr(const _Up* __a, __platform_wait_t* __b)
   {
     if constexpr (__platform_wait_uses_type<_Up>)
       return reinterpret_cast<__platform_wait_t*>(const_cast<_Up*>(__a));
     else
       return __b;
   }

 static __waiter_type&
 _S_for(const void* __addr) noexcept
 {
   static_assert(sizeof(__waiter_type) == sizeof(__waiter_pool_base));
   auto& res = __waiter_pool_base::_S_for(__addr);
   return reinterpret_cast<__waiter_type&>(res);
 }

 template<typename _Up>
   explicit __waiter_base(const _Up* __addr) noexcept
     : _M_w(_S_for(__addr))
     , _M_addr(_S_wait_addr(__addr, &_M_w._M_ver))
   { }

 void
 _M_notify(bool __all, bool __bare = false) noexcept
 { _M_w._M_notify(_M_addr, __all, __bare); }

 template<typename _Up, typename _ValFn,
   typename _Spin = __default_spin_policy>
   static bool
   _S_do_spin_v(__platform_wait_t* __addr,
         const _Up& __old, _ValFn __vfn,
         __platform_wait_t& __val,
         _Spin __spin = _Spin{ })
   {
     auto const __pred = [=]
       { return !__detail::__atomic_compare(__old, __vfn()); };

     if constexpr (__platform_wait_uses_type<_Up>)
       {
  __builtin_memcpy(&__val, &__old, sizeof(__val));
       }
     else
       {
  __atomic_load(__addr, &__val, 2);
       }
     return __atomic_spin(__pred, __spin);
   }

 template<typename _Up, typename _ValFn,
   typename _Spin = __default_spin_policy>
   bool
   _M_do_spin_v(const _Up& __old, _ValFn __vfn,
         __platform_wait_t& __val,
         _Spin __spin = _Spin{ })
   { return _S_do_spin_v(_M_addr, __old, __vfn, __val, __spin); }

 template<typename _Pred,
   typename _Spin = __default_spin_policy>
   static bool
   _S_do_spin(const __platform_wait_t* __addr,
       _Pred __pred,
       __platform_wait_t& __val,
       _Spin __spin = _Spin{ })
   {
     __atomic_load(__addr, &__val, 2);
     return __atomic_spin(__pred, __spin);
   }

 template<typename _Pred,
   typename _Spin = __default_spin_policy>
   bool
   _M_do_spin(_Pred __pred, __platform_wait_t& __val,
       _Spin __spin = _Spin{ })
   { return _S_do_spin(_M_addr, __pred, __val, __spin); }
      };

    template<typename _EntersWait>
      struct __waiter : __waiter_base<__waiter_pool>
      {
 using __base_type = __waiter_base<__waiter_pool>;

 template<typename _Tp>
   explicit __waiter(const _Tp* __addr) noexcept
     : __base_type(__addr)
   {
     if constexpr (_EntersWait::value)
       _M_w._M_enter_wait();
   }

 ~__waiter()
 {
   if constexpr (_EntersWait::value)
     _M_w._M_leave_wait();
 }

 template<typename _Tp, typename _ValFn>
   void
   _M_do_wait_v(_Tp __old, _ValFn __vfn)
   {
     do
       {
  __platform_wait_t __val;
  if (__base_type::_M_do_spin_v(__old, __vfn, __val))
    return;
  __base_type::_M_w._M_do_wait(__base_type::_M_addr, __val);
       }
     while (__detail::__atomic_compare(__old, __vfn()));
   }

 template<typename _Pred>
   void
   _M_do_wait(_Pred __pred) noexcept
   {
     do
       {
  __platform_wait_t __val;
  if (__base_type::_M_do_spin(__pred, __val))
    return;
  __base_type::_M_w._M_do_wait(__base_type::_M_addr, __val);
       }
     while (!__pred());
   }
      };

    using __enters_wait = __waiter<std::true_type>;
    using __bare_wait = __waiter<std::false_type>;
  }

  template<typename _Tp, typename _ValFn>
    void
    __atomic_wait_address_v(const _Tp* __addr, _Tp __old,
       _ValFn __vfn) noexcept
    {
      __detail::__enters_wait __w(__addr);
      __w._M_do_wait_v(__old, __vfn);
    }

  template<typename _Tp, typename _Pred>
    void
    __atomic_wait_address(const _Tp* __addr, _Pred __pred) noexcept
    {
      __detail::__enters_wait __w(__addr);
      __w._M_do_wait(__pred);
    }


  template<typename _Pred>
    void
    __atomic_wait_address_bare(const __detail::__platform_wait_t* __addr,
          _Pred __pred) noexcept
    {
# 454 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_wait.h" 3
      __detail::__bare_wait __w(__addr);
      __w._M_do_wait(__pred);

    }

  template<typename _Tp>
    void
    __atomic_notify_address(const _Tp* __addr, bool __all) noexcept
    {
      __detail::__bare_wait __w(__addr);
      __w._M_notify(__all);
    }


  inline void
  __atomic_notify_address_bare(const __detail::__platform_wait_t* __addr,
          bool __all) noexcept
  {



    __detail::__bare_wait __w(__addr);
    __w._M_notify(__all, true);

  }

}
# 44 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h" 2 3






# 1 "C:/msys64/mingw64/include/c++/15.2.0/bits/version.h" 1 3
# 51 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h" 2 3

namespace std
{

# 65 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h" 3
  enum class memory_order : int
    {
      relaxed,
      consume,
      acquire,
      release,
      acq_rel,
      seq_cst
    };

  inline constexpr memory_order memory_order_relaxed = memory_order::relaxed;
  inline constexpr memory_order memory_order_consume = memory_order::consume;
  inline constexpr memory_order memory_order_acquire = memory_order::acquire;
  inline constexpr memory_order memory_order_release = memory_order::release;
  inline constexpr memory_order memory_order_acq_rel = memory_order::acq_rel;
  inline constexpr memory_order memory_order_seq_cst = memory_order::seq_cst;
# 94 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h" 3
  enum __memory_order_modifier
    {
      __memory_order_mask = 0x0ffff,
      __memory_order_modifier_mask = 0xffff0000,
      __memory_order_hle_acquire = 0x10000,
      __memory_order_hle_release = 0x20000
    };


  constexpr memory_order
  operator|(memory_order __m, __memory_order_modifier __mod) noexcept
  {
    return memory_order(int(__m) | int(__mod));
  }

  constexpr memory_order
  operator&(memory_order __m, __memory_order_modifier __mod) noexcept
  {
    return memory_order(int(__m) & int(__mod));
  }




  constexpr memory_order
  __cmpexch_failure_order2(memory_order __m) noexcept
  {
    return __m == memory_order_acq_rel ? memory_order_acquire
      : __m == memory_order_release ? memory_order_relaxed : __m;
  }

  constexpr memory_order
  __cmpexch_failure_order(memory_order __m) noexcept
  {
    return memory_order(__cmpexch_failure_order2(__m & __memory_order_mask)
      | __memory_order_modifier(__m & __memory_order_modifier_mask));
  }

  constexpr bool
  __is_valid_cmpexch_failure_order(memory_order __m) noexcept
  {
    return (__m & __memory_order_mask) != memory_order_release
 && (__m & __memory_order_mask) != memory_order_acq_rel;
  }


  template<typename _IntTp>
    struct __atomic_base;



  inline __attribute__((__always_inline__)) void
  atomic_thread_fence(memory_order __m) noexcept
  { __atomic_thread_fence(int(__m)); }

  inline __attribute__((__always_inline__)) void
  atomic_signal_fence(memory_order __m) noexcept
  { __atomic_signal_fence(int(__m)); }


  template<typename _Tp>
    inline _Tp
    kill_dependency(_Tp __y) noexcept
    {
      _Tp __ret(__y);
      return __ret;
    }
# 172 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h" 3
  template<typename _Tp>
    struct atomic;

  template<typename _Tp>
    struct atomic<_Tp*>;



    typedef bool __atomic_flag_data_type;
# 197 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h" 3
  extern "C" {

  struct __atomic_flag_base
  {
    __atomic_flag_data_type _M_i = {};
  };

  }






  struct atomic_flag : public __atomic_flag_base
  {
    atomic_flag() noexcept = default;
    ~atomic_flag() noexcept = default;
    atomic_flag(const atomic_flag&) = delete;
    atomic_flag& operator=(const atomic_flag&) = delete;
    atomic_flag& operator=(const atomic_flag&) volatile = delete;


    constexpr atomic_flag(bool __i) noexcept
      : __atomic_flag_base{ _S_init(__i) }
    { }

    inline __attribute__((__always_inline__)) bool
    test_and_set(memory_order __m = memory_order_seq_cst) noexcept
    {
      return __atomic_test_and_set (&_M_i, int(__m));
    }

    inline __attribute__((__always_inline__)) bool
    test_and_set(memory_order __m = memory_order_seq_cst) volatile noexcept
    {
      return __atomic_test_and_set (&_M_i, int(__m));
    }


    inline __attribute__((__always_inline__)) bool
    test(memory_order __m = memory_order_seq_cst) const noexcept
    {
      __atomic_flag_data_type __v;
      __atomic_load(&_M_i, &__v, int(__m));
      return __v == 1;
    }

    inline __attribute__((__always_inline__)) bool
    test(memory_order __m = memory_order_seq_cst) const volatile noexcept
    {
      __atomic_flag_data_type __v;
      __atomic_load(&_M_i, &__v, int(__m));
      return __v == 1;
    }



    inline __attribute__((__always_inline__)) void
    wait(bool __old,
 memory_order __m = memory_order_seq_cst) const noexcept
    {
      const __atomic_flag_data_type __v
 = __old ? 1 : 0;

      std::__atomic_wait_address_v(&_M_i, __v,
   [__m, this] { return __atomic_load_n(&_M_i, int(__m)); });
    }



    inline __attribute__((__always_inline__)) void
    notify_one() noexcept
    { std::__atomic_notify_address(&_M_i, false); }



    inline __attribute__((__always_inline__)) void
    notify_all() noexcept
    { std::__atomic_notify_address(&_M_i, true); }




    inline __attribute__((__always_inline__)) void
    clear(memory_order __m = memory_order_seq_cst) noexcept
    {
      memory_order __b __attribute__ ((__unused__))
 = __m & __memory_order_mask;
      do { if (__builtin_expect(!bool(__b != memory_order_consume), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 286, __PRETTY_FUNCTION__, "__b != memory_order_consume"); } while (false);
      do { if (__builtin_expect(!bool(__b != memory_order_acquire), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 287, __PRETTY_FUNCTION__, "__b != memory_order_acquire"); } while (false);
      do { if (__builtin_expect(!bool(__b != memory_order_acq_rel), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 288, __PRETTY_FUNCTION__, "__b != memory_order_acq_rel"); } while (false);

      __atomic_clear (&_M_i, int(__m));
    }

    inline __attribute__((__always_inline__)) void
    clear(memory_order __m = memory_order_seq_cst) volatile noexcept
    {
      memory_order __b __attribute__ ((__unused__))
 = __m & __memory_order_mask;
      do { if (__builtin_expect(!bool(__b != memory_order_consume), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 298, __PRETTY_FUNCTION__, "__b != memory_order_consume"); } while (false);
      do { if (__builtin_expect(!bool(__b != memory_order_acquire), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 299, __PRETTY_FUNCTION__, "__b != memory_order_acquire"); } while (false);
      do { if (__builtin_expect(!bool(__b != memory_order_acq_rel), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 300, __PRETTY_FUNCTION__, "__b != memory_order_acq_rel"); } while (false);

      __atomic_clear (&_M_i, int(__m));
    }

  private:
    static constexpr __atomic_flag_data_type
    _S_init(bool __i)
    { return __i ? 1 : 0; }
  };
# 337 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h" 3
  template<typename _ITp>
    struct __atomic_base
    {
      using value_type = _ITp;
      using difference_type = value_type;

    private:
      typedef _ITp __int_type;

      static constexpr int _S_alignment =
 sizeof(_ITp) > alignof(_ITp) ? sizeof(_ITp) : alignof(_ITp);

      alignas(_S_alignment) __int_type _M_i = 0;

    public:
      __atomic_base() noexcept = default;
      ~__atomic_base() noexcept = default;
      __atomic_base(const __atomic_base&) = delete;
      __atomic_base& operator=(const __atomic_base&) = delete;
      __atomic_base& operator=(const __atomic_base&) volatile = delete;

      constexpr __atomic_base(__int_type __i) noexcept : _M_i (__i) { }

      operator __int_type() const noexcept
      { return load(); }

      operator __int_type() const volatile noexcept
      { return load(); }

      __int_type
      operator=(__int_type __i) noexcept
      {
 store(__i);
 return __i;
      }

      __int_type
      operator=(__int_type __i) volatile noexcept
      {
 store(__i);
 return __i;
      }

      __int_type
      operator++(int) noexcept
      { return fetch_add(1); }

      __int_type
      operator++(int) volatile noexcept
      { return fetch_add(1); }

      __int_type
      operator--(int) noexcept
      { return fetch_sub(1); }

      __int_type
      operator--(int) volatile noexcept
      { return fetch_sub(1); }

      __int_type
      operator++() noexcept
      { return __atomic_add_fetch(&_M_i, 1, int(memory_order_seq_cst)); }

      __int_type
      operator++() volatile noexcept
      { return __atomic_add_fetch(&_M_i, 1, int(memory_order_seq_cst)); }

      __int_type
      operator--() noexcept
      { return __atomic_sub_fetch(&_M_i, 1, int(memory_order_seq_cst)); }

      __int_type
      operator--() volatile noexcept
      { return __atomic_sub_fetch(&_M_i, 1, int(memory_order_seq_cst)); }

      __int_type
      operator+=(__int_type __i) noexcept
      { return __atomic_add_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      __int_type
      operator+=(__int_type __i) volatile noexcept
      { return __atomic_add_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      __int_type
      operator-=(__int_type __i) noexcept
      { return __atomic_sub_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      __int_type
      operator-=(__int_type __i) volatile noexcept
      { return __atomic_sub_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      __int_type
      operator&=(__int_type __i) noexcept
      { return __atomic_and_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      __int_type
      operator&=(__int_type __i) volatile noexcept
      { return __atomic_and_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      __int_type
      operator|=(__int_type __i) noexcept
      { return __atomic_or_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      __int_type
      operator|=(__int_type __i) volatile noexcept
      { return __atomic_or_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      __int_type
      operator^=(__int_type __i) noexcept
      { return __atomic_xor_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      __int_type
      operator^=(__int_type __i) volatile noexcept
      { return __atomic_xor_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      bool
      is_lock_free() const noexcept
      {

 return __atomic_is_lock_free(sizeof(_M_i),
     reinterpret_cast<void *>(-_S_alignment));
      }

      bool
      is_lock_free() const volatile noexcept
      {

 return __atomic_is_lock_free(sizeof(_M_i),
     reinterpret_cast<void *>(-_S_alignment));
      }

      inline __attribute__((__always_inline__)) void
      store(__int_type __i, memory_order __m = memory_order_seq_cst) noexcept
      {
 memory_order __b __attribute__ ((__unused__))
   = __m & __memory_order_mask;
 do { if (__builtin_expect(!bool(__b != memory_order_acquire), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 473, __PRETTY_FUNCTION__, "__b != memory_order_acquire"); } while (false);
 do { if (__builtin_expect(!bool(__b != memory_order_acq_rel), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 474, __PRETTY_FUNCTION__, "__b != memory_order_acq_rel"); } while (false);
 do { if (__builtin_expect(!bool(__b != memory_order_consume), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 475, __PRETTY_FUNCTION__, "__b != memory_order_consume"); } while (false);

 __atomic_store_n(&_M_i, __i, int(__m));
      }

      inline __attribute__((__always_inline__)) void
      store(__int_type __i,
     memory_order __m = memory_order_seq_cst) volatile noexcept
      {
 memory_order __b __attribute__ ((__unused__))
   = __m & __memory_order_mask;
 do { if (__builtin_expect(!bool(__b != memory_order_acquire), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 486, __PRETTY_FUNCTION__, "__b != memory_order_acquire"); } while (false);
 do { if (__builtin_expect(!bool(__b != memory_order_acq_rel), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 487, __PRETTY_FUNCTION__, "__b != memory_order_acq_rel"); } while (false);
 do { if (__builtin_expect(!bool(__b != memory_order_consume), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 488, __PRETTY_FUNCTION__, "__b != memory_order_consume"); } while (false);

 __atomic_store_n(&_M_i, __i, int(__m));
      }

      inline __attribute__((__always_inline__)) __int_type
      load(memory_order __m = memory_order_seq_cst) const noexcept
      {
 memory_order __b __attribute__ ((__unused__))
   = __m & __memory_order_mask;
 do { if (__builtin_expect(!bool(__b != memory_order_release), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 498, __PRETTY_FUNCTION__, "__b != memory_order_release"); } while (false);
 do { if (__builtin_expect(!bool(__b != memory_order_acq_rel), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 499, __PRETTY_FUNCTION__, "__b != memory_order_acq_rel"); } while (false);

 return __atomic_load_n(&_M_i, int(__m));
      }

      inline __attribute__((__always_inline__)) __int_type
      load(memory_order __m = memory_order_seq_cst) const volatile noexcept
      {
 memory_order __b __attribute__ ((__unused__))
   = __m & __memory_order_mask;
 do { if (__builtin_expect(!bool(__b != memory_order_release), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 509, __PRETTY_FUNCTION__, "__b != memory_order_release"); } while (false);
 do { if (__builtin_expect(!bool(__b != memory_order_acq_rel), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 510, __PRETTY_FUNCTION__, "__b != memory_order_acq_rel"); } while (false);

 return __atomic_load_n(&_M_i, int(__m));
      }

      inline __attribute__((__always_inline__)) __int_type
      exchange(__int_type __i,
        memory_order __m = memory_order_seq_cst) noexcept
      {
 return __atomic_exchange_n(&_M_i, __i, int(__m));
      }


      inline __attribute__((__always_inline__)) __int_type
      exchange(__int_type __i,
        memory_order __m = memory_order_seq_cst) volatile noexcept
      {
 return __atomic_exchange_n(&_M_i, __i, int(__m));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_weak(__int_type& __i1, __int_type __i2,
       memory_order __m1, memory_order __m2) noexcept
      {
 do { if (__builtin_expect(!bool(__is_valid_cmpexch_failure_order(__m2)), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 534, __PRETTY_FUNCTION__, "__is_valid_cmpexch_failure_order(__m2)"); } while (false);

 return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 1,
        int(__m1), int(__m2));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_weak(__int_type& __i1, __int_type __i2,
       memory_order __m1,
       memory_order __m2) volatile noexcept
      {
 do { if (__builtin_expect(!bool(__is_valid_cmpexch_failure_order(__m2)), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 545, __PRETTY_FUNCTION__, "__is_valid_cmpexch_failure_order(__m2)"); } while (false);

 return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 1,
        int(__m1), int(__m2));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_weak(__int_type& __i1, __int_type __i2,
       memory_order __m = memory_order_seq_cst) noexcept
      {
 return compare_exchange_weak(__i1, __i2, __m,
         __cmpexch_failure_order(__m));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_weak(__int_type& __i1, __int_type __i2,
     memory_order __m = memory_order_seq_cst) volatile noexcept
      {
 return compare_exchange_weak(__i1, __i2, __m,
         __cmpexch_failure_order(__m));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_strong(__int_type& __i1, __int_type __i2,
         memory_order __m1, memory_order __m2) noexcept
      {
 do { if (__builtin_expect(!bool(__is_valid_cmpexch_failure_order(__m2)), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 571, __PRETTY_FUNCTION__, "__is_valid_cmpexch_failure_order(__m2)"); } while (false);

 return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 0,
        int(__m1), int(__m2));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_strong(__int_type& __i1, __int_type __i2,
         memory_order __m1,
         memory_order __m2) volatile noexcept
      {
 do { if (__builtin_expect(!bool(__is_valid_cmpexch_failure_order(__m2)), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 582, __PRETTY_FUNCTION__, "__is_valid_cmpexch_failure_order(__m2)"); } while (false);

 return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 0,
        int(__m1), int(__m2));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_strong(__int_type& __i1, __int_type __i2,
         memory_order __m = memory_order_seq_cst) noexcept
      {
 return compare_exchange_strong(__i1, __i2, __m,
           __cmpexch_failure_order(__m));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_strong(__int_type& __i1, __int_type __i2,
   memory_order __m = memory_order_seq_cst) volatile noexcept
      {
 return compare_exchange_strong(__i1, __i2, __m,
           __cmpexch_failure_order(__m));
      }


      inline __attribute__((__always_inline__)) void
      wait(__int_type __old,
   memory_order __m = memory_order_seq_cst) const noexcept
      {
 std::__atomic_wait_address_v(&_M_i, __old,
      [__m, this] { return this->load(__m); });
      }



      inline __attribute__((__always_inline__)) void
      notify_one() noexcept
      { std::__atomic_notify_address(&_M_i, false); }



      inline __attribute__((__always_inline__)) void
      notify_all() noexcept
      { std::__atomic_notify_address(&_M_i, true); }




      inline __attribute__((__always_inline__)) __int_type
      fetch_add(__int_type __i,
  memory_order __m = memory_order_seq_cst) noexcept
      { return __atomic_fetch_add(&_M_i, __i, int(__m)); }

      inline __attribute__((__always_inline__)) __int_type
      fetch_add(__int_type __i,
  memory_order __m = memory_order_seq_cst) volatile noexcept
      { return __atomic_fetch_add(&_M_i, __i, int(__m)); }

      inline __attribute__((__always_inline__)) __int_type
      fetch_sub(__int_type __i,
  memory_order __m = memory_order_seq_cst) noexcept
      { return __atomic_fetch_sub(&_M_i, __i, int(__m)); }

      inline __attribute__((__always_inline__)) __int_type
      fetch_sub(__int_type __i,
  memory_order __m = memory_order_seq_cst) volatile noexcept
      { return __atomic_fetch_sub(&_M_i, __i, int(__m)); }

      inline __attribute__((__always_inline__)) __int_type
      fetch_and(__int_type __i,
  memory_order __m = memory_order_seq_cst) noexcept
      { return __atomic_fetch_and(&_M_i, __i, int(__m)); }

      inline __attribute__((__always_inline__)) __int_type
      fetch_and(__int_type __i,
  memory_order __m = memory_order_seq_cst) volatile noexcept
      { return __atomic_fetch_and(&_M_i, __i, int(__m)); }

      inline __attribute__((__always_inline__)) __int_type
      fetch_or(__int_type __i,
        memory_order __m = memory_order_seq_cst) noexcept
      { return __atomic_fetch_or(&_M_i, __i, int(__m)); }

      inline __attribute__((__always_inline__)) __int_type
      fetch_or(__int_type __i,
        memory_order __m = memory_order_seq_cst) volatile noexcept
      { return __atomic_fetch_or(&_M_i, __i, int(__m)); }

      inline __attribute__((__always_inline__)) __int_type
      fetch_xor(__int_type __i,
  memory_order __m = memory_order_seq_cst) noexcept
      { return __atomic_fetch_xor(&_M_i, __i, int(__m)); }

      inline __attribute__((__always_inline__)) __int_type
      fetch_xor(__int_type __i,
  memory_order __m = memory_order_seq_cst) volatile noexcept
      { return __atomic_fetch_xor(&_M_i, __i, int(__m)); }
    };



  template<typename _PTp>
    struct __atomic_base<_PTp*>
    {
    private:
      typedef _PTp* __pointer_type;

      __pointer_type _M_p = nullptr;

      static constexpr ptrdiff_t
      _S_type_size(ptrdiff_t __d)
      { return __d * sizeof(_PTp); }

    public:
      __atomic_base() noexcept = default;
      ~__atomic_base() noexcept = default;
      __atomic_base(const __atomic_base&) = delete;
      __atomic_base& operator=(const __atomic_base&) = delete;
      __atomic_base& operator=(const __atomic_base&) volatile = delete;


      constexpr __atomic_base(__pointer_type __p) noexcept : _M_p (__p) { }

      operator __pointer_type() const noexcept
      { return load(); }

      operator __pointer_type() const volatile noexcept
      { return load(); }

      __pointer_type
      operator=(__pointer_type __p) noexcept
      {
 store(__p);
 return __p;
      }

      __pointer_type
      operator=(__pointer_type __p) volatile noexcept
      {
 store(__p);
 return __p;
      }

      __pointer_type
      operator++(int) noexcept
      { return fetch_add(1); }

      __pointer_type
      operator++(int) volatile noexcept
      { return fetch_add(1); }

      __pointer_type
      operator--(int) noexcept
      { return fetch_sub(1); }

      __pointer_type
      operator--(int) volatile noexcept
      { return fetch_sub(1); }

      __pointer_type
      operator++() noexcept
      { return __atomic_add_fetch(&_M_p, _S_type_size(1),
      int(memory_order_seq_cst)); }

      __pointer_type
      operator++() volatile noexcept
      { return __atomic_add_fetch(&_M_p, _S_type_size(1),
      int(memory_order_seq_cst)); }

      __pointer_type
      operator--() noexcept
      { return __atomic_sub_fetch(&_M_p, _S_type_size(1),
      int(memory_order_seq_cst)); }

      __pointer_type
      operator--() volatile noexcept
      { return __atomic_sub_fetch(&_M_p, _S_type_size(1),
      int(memory_order_seq_cst)); }

      __pointer_type
      operator+=(ptrdiff_t __d) noexcept
      { return __atomic_add_fetch(&_M_p, _S_type_size(__d),
      int(memory_order_seq_cst)); }

      __pointer_type
      operator+=(ptrdiff_t __d) volatile noexcept
      { return __atomic_add_fetch(&_M_p, _S_type_size(__d),
      int(memory_order_seq_cst)); }

      __pointer_type
      operator-=(ptrdiff_t __d) noexcept
      { return __atomic_sub_fetch(&_M_p, _S_type_size(__d),
      int(memory_order_seq_cst)); }

      __pointer_type
      operator-=(ptrdiff_t __d) volatile noexcept
      { return __atomic_sub_fetch(&_M_p, _S_type_size(__d),
      int(memory_order_seq_cst)); }

      bool
      is_lock_free() const noexcept
      {

 return __atomic_is_lock_free(sizeof(_M_p),
     reinterpret_cast<void *>(-__alignof(_M_p)));
      }

      bool
      is_lock_free() const volatile noexcept
      {

 return __atomic_is_lock_free(sizeof(_M_p),
     reinterpret_cast<void *>(-__alignof(_M_p)));
      }

      inline __attribute__((__always_inline__)) void
      store(__pointer_type __p,
     memory_order __m = memory_order_seq_cst) noexcept
      {
 memory_order __b __attribute__ ((__unused__))
   = __m & __memory_order_mask;

 do { if (__builtin_expect(!bool(__b != memory_order_acquire), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 802, __PRETTY_FUNCTION__, "__b != memory_order_acquire"); } while (false);
 do { if (__builtin_expect(!bool(__b != memory_order_acq_rel), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 803, __PRETTY_FUNCTION__, "__b != memory_order_acq_rel"); } while (false);
 do { if (__builtin_expect(!bool(__b != memory_order_consume), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 804, __PRETTY_FUNCTION__, "__b != memory_order_consume"); } while (false);

 __atomic_store_n(&_M_p, __p, int(__m));
      }

      inline __attribute__((__always_inline__)) void
      store(__pointer_type __p,
     memory_order __m = memory_order_seq_cst) volatile noexcept
      {
 memory_order __b __attribute__ ((__unused__))
   = __m & __memory_order_mask;
 do { if (__builtin_expect(!bool(__b != memory_order_acquire), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 815, __PRETTY_FUNCTION__, "__b != memory_order_acquire"); } while (false);
 do { if (__builtin_expect(!bool(__b != memory_order_acq_rel), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 816, __PRETTY_FUNCTION__, "__b != memory_order_acq_rel"); } while (false);
 do { if (__builtin_expect(!bool(__b != memory_order_consume), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 817, __PRETTY_FUNCTION__, "__b != memory_order_consume"); } while (false);

 __atomic_store_n(&_M_p, __p, int(__m));
      }

      inline __attribute__((__always_inline__)) __pointer_type
      load(memory_order __m = memory_order_seq_cst) const noexcept
      {
 memory_order __b __attribute__ ((__unused__))
   = __m & __memory_order_mask;
 do { if (__builtin_expect(!bool(__b != memory_order_release), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 827, __PRETTY_FUNCTION__, "__b != memory_order_release"); } while (false);
 do { if (__builtin_expect(!bool(__b != memory_order_acq_rel), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 828, __PRETTY_FUNCTION__, "__b != memory_order_acq_rel"); } while (false);

 return __atomic_load_n(&_M_p, int(__m));
      }

      inline __attribute__((__always_inline__)) __pointer_type
      load(memory_order __m = memory_order_seq_cst) const volatile noexcept
      {
 memory_order __b __attribute__ ((__unused__))
   = __m & __memory_order_mask;
 do { if (__builtin_expect(!bool(__b != memory_order_release), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 838, __PRETTY_FUNCTION__, "__b != memory_order_release"); } while (false);
 do { if (__builtin_expect(!bool(__b != memory_order_acq_rel), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 839, __PRETTY_FUNCTION__, "__b != memory_order_acq_rel"); } while (false);

 return __atomic_load_n(&_M_p, int(__m));
      }

      inline __attribute__((__always_inline__)) __pointer_type
      exchange(__pointer_type __p,
        memory_order __m = memory_order_seq_cst) noexcept
      {
 return __atomic_exchange_n(&_M_p, __p, int(__m));
      }


      inline __attribute__((__always_inline__)) __pointer_type
      exchange(__pointer_type __p,
        memory_order __m = memory_order_seq_cst) volatile noexcept
      {
 return __atomic_exchange_n(&_M_p, __p, int(__m));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_weak(__pointer_type& __p1, __pointer_type __p2,
       memory_order __m1,
       memory_order __m2) noexcept
      {
 do { if (__builtin_expect(!bool(__is_valid_cmpexch_failure_order(__m2)), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 864, __PRETTY_FUNCTION__, "__is_valid_cmpexch_failure_order(__m2)"); } while (false);

 return __atomic_compare_exchange_n(&_M_p, &__p1, __p2, 1,
        int(__m1), int(__m2));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_weak(__pointer_type& __p1, __pointer_type __p2,
       memory_order __m1,
       memory_order __m2) volatile noexcept
      {
 do { if (__builtin_expect(!bool(__is_valid_cmpexch_failure_order(__m2)), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 875, __PRETTY_FUNCTION__, "__is_valid_cmpexch_failure_order(__m2)"); } while (false);

 return __atomic_compare_exchange_n(&_M_p, &__p1, __p2, 1,
        int(__m1), int(__m2));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_strong(__pointer_type& __p1, __pointer_type __p2,
         memory_order __m1,
         memory_order __m2) noexcept
      {
 do { if (__builtin_expect(!bool(__is_valid_cmpexch_failure_order(__m2)), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 886, __PRETTY_FUNCTION__, "__is_valid_cmpexch_failure_order(__m2)"); } while (false);

 return __atomic_compare_exchange_n(&_M_p, &__p1, __p2, 0,
        int(__m1), int(__m2));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_strong(__pointer_type& __p1, __pointer_type __p2,
         memory_order __m1,
         memory_order __m2) volatile noexcept
      {
 do { if (__builtin_expect(!bool(__is_valid_cmpexch_failure_order(__m2)), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 897, __PRETTY_FUNCTION__, "__is_valid_cmpexch_failure_order(__m2)"); } while (false);

 return __atomic_compare_exchange_n(&_M_p, &__p1, __p2, 0,
        int(__m1), int(__m2));
      }


      inline __attribute__((__always_inline__)) void
      wait(__pointer_type __old,
    memory_order __m = memory_order_seq_cst) const noexcept
      {
 std::__atomic_wait_address_v(&_M_p, __old,
         [__m, this]
         { return this->load(__m); });
      }



      inline __attribute__((__always_inline__)) void
      notify_one() const noexcept
      { std::__atomic_notify_address(&_M_p, false); }



      inline __attribute__((__always_inline__)) void
      notify_all() const noexcept
      { std::__atomic_notify_address(&_M_p, true); }




      inline __attribute__((__always_inline__)) __pointer_type
      fetch_add(ptrdiff_t __d,
  memory_order __m = memory_order_seq_cst) noexcept
      { return __atomic_fetch_add(&_M_p, _S_type_size(__d), int(__m)); }

      inline __attribute__((__always_inline__)) __pointer_type
      fetch_add(ptrdiff_t __d,
  memory_order __m = memory_order_seq_cst) volatile noexcept
      { return __atomic_fetch_add(&_M_p, _S_type_size(__d), int(__m)); }

      inline __attribute__((__always_inline__)) __pointer_type
      fetch_sub(ptrdiff_t __d,
  memory_order __m = memory_order_seq_cst) noexcept
      { return __atomic_fetch_sub(&_M_p, _S_type_size(__d), int(__m)); }

      inline __attribute__((__always_inline__)) __pointer_type
      fetch_sub(ptrdiff_t __d,
  memory_order __m = memory_order_seq_cst) volatile noexcept
      { return __atomic_fetch_sub(&_M_p, _S_type_size(__d), int(__m)); }
    };

  namespace __atomic_impl
  {


    template<typename _Tp>
      constexpr bool
      __maybe_has_padding()
      {



 return !__has_unique_object_representations(_Tp)
   && !is_same<_Tp, float>::value && !is_same<_Tp, double>::value;



      }

    template<typename _Tp>
      inline __attribute__((__always_inline__)) constexpr _Tp*
      __clear_padding(_Tp& __val) noexcept
      {
 auto* __ptr = std::__addressof(__val);

 if constexpr (__atomic_impl::__maybe_has_padding<_Tp>())
   __builtin_clear_padding(__ptr);

 return __ptr;
      }


    template<typename _Tp>
      using _Val = typename remove_volatile<_Tp>::type;

#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wc++17-extensions"

    template<bool _AtomicRef = false, typename _Tp>
      inline __attribute__((__always_inline__)) bool
      __compare_exchange(_Tp& __val, _Val<_Tp>& __e, _Val<_Tp>& __i,
    bool __is_weak,
    memory_order __s, memory_order __f) noexcept
      {
 do { if (__builtin_expect(!bool(__is_valid_cmpexch_failure_order(__f)), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 992, __PRETTY_FUNCTION__, "__is_valid_cmpexch_failure_order(__f)"); } while (false);

 using _Vp = _Val<_Tp>;
 _Tp* const __pval = std::__addressof(__val);

 if constexpr (!__atomic_impl::__maybe_has_padding<_Vp>())
   {
     return __atomic_compare_exchange(__pval, std::__addressof(__e),
          std::__addressof(__i), __is_weak,
          int(__s), int(__f));
   }
 else if constexpr (!_AtomicRef)
   {

     _Vp* const __pi = __atomic_impl::__clear_padding(__i);

     _Vp __exp = __e;

     _Vp* const __pexp = __atomic_impl::__clear_padding(__exp);



     if (__atomic_compare_exchange(__pval, __pexp, __pi,
       __is_weak, int(__s), int(__f)))
       return true;

     __builtin_memcpy(std::__addressof(__e), __pexp, sizeof(_Vp));
     return false;
   }
 else
   {

     _Vp* const __pi = __atomic_impl::__clear_padding(__i);


     _Vp __exp = __e;


     _Vp* const __pexp = __atomic_impl::__clear_padding(__exp);
# 1042 "C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h" 3
     while (true)
       {

  _Vp __orig = __exp;

  if (__atomic_compare_exchange(__pval, __pexp, __pi,
           __is_weak, int(__s), int(__f)))
    return true;


  _Vp __curr = __exp;


  if (__builtin_memcmp(__atomic_impl::__clear_padding(__orig),
         __atomic_impl::__clear_padding(__curr),
         sizeof(_Vp)))
    {

      __builtin_memcpy(std::__addressof(__e), __pexp,
         sizeof(_Vp));
      return false;
    }
       }
   }
      }
#pragma GCC diagnostic pop
  }



  namespace __atomic_impl
  {

    template<typename _Tp>
      using _Diff = __conditional_t<is_pointer_v<_Tp>, ptrdiff_t, _Val<_Tp>>;

    template<size_t _Size, size_t _Align>
      inline __attribute__((__always_inline__)) bool
      is_lock_free() noexcept
      {

 return __atomic_is_lock_free(_Size, reinterpret_cast<void *>(-_Align));
      }

    template<typename _Tp>
      inline __attribute__((__always_inline__)) void
      store(_Tp* __ptr, _Val<_Tp> __t, memory_order __m) noexcept
      {
 __atomic_store(__ptr, __atomic_impl::__clear_padding(__t), int(__m));
      }

    template<typename _Tp>
      inline __attribute__((__always_inline__)) _Val<_Tp>
      load(const _Tp* __ptr, memory_order __m) noexcept
      {
 alignas(_Tp) unsigned char __buf[sizeof(_Tp)];
 auto* __dest = reinterpret_cast<_Val<_Tp>*>(__buf);
 __atomic_load(__ptr, __dest, int(__m));
 return *__dest;
      }

    template<typename _Tp>
      inline __attribute__((__always_inline__)) _Val<_Tp>
      exchange(_Tp* __ptr, _Val<_Tp> __desired, memory_order __m) noexcept
      {
        alignas(_Tp) unsigned char __buf[sizeof(_Tp)];
 auto* __dest = reinterpret_cast<_Val<_Tp>*>(__buf);
 __atomic_exchange(__ptr, __atomic_impl::__clear_padding(__desired),
     __dest, int(__m));
 return *__dest;
      }

    template<bool _AtomicRef = false, typename _Tp>
      inline __attribute__((__always_inline__)) bool
      compare_exchange_weak(_Tp* __ptr, _Val<_Tp>& __expected,
       _Val<_Tp> __desired, memory_order __success,
       memory_order __failure) noexcept
      {
 return __atomic_impl::__compare_exchange<_AtomicRef>(
     *__ptr, __expected, __desired, true, __success, __failure);
      }

    template<bool _AtomicRef = false, typename _Tp>
      inline __attribute__((__always_inline__)) bool
      compare_exchange_strong(_Tp* __ptr, _Val<_Tp>& __expected,
         _Val<_Tp> __desired, memory_order __success,
         memory_order __failure) noexcept
      {
 return __atomic_impl::__compare_exchange<_AtomicRef>(
     *__ptr, __expected, __desired, false, __success, __failure);
      }


    template<typename _Tp>
      inline __attribute__((__always_inline__)) void
      wait(const _Tp* __ptr, _Val<_Tp> __old,
    memory_order __m = memory_order_seq_cst) noexcept
      {
 std::__atomic_wait_address_v(__ptr, __old,
     [__ptr, __m]() { return __atomic_impl::load(__ptr, __m); });
      }



    template<typename _Tp>
      inline __attribute__((__always_inline__)) void
      notify_one(const _Tp* __ptr) noexcept
      { std::__atomic_notify_address(__ptr, false); }



    template<typename _Tp>
      inline __attribute__((__always_inline__)) void
      notify_all(const _Tp* __ptr) noexcept
      { std::__atomic_notify_address(__ptr, true); }




    template<typename _Tp>
      inline __attribute__((__always_inline__)) _Tp
      fetch_add(_Tp* __ptr, _Diff<_Tp> __i, memory_order __m) noexcept
      { return __atomic_fetch_add(__ptr, __i, int(__m)); }

    template<typename _Tp>
      inline __attribute__((__always_inline__)) _Tp
      fetch_sub(_Tp* __ptr, _Diff<_Tp> __i, memory_order __m) noexcept
      { return __atomic_fetch_sub(__ptr, __i, int(__m)); }

    template<typename _Tp>
      inline __attribute__((__always_inline__)) _Tp
      fetch_and(_Tp* __ptr, _Val<_Tp> __i, memory_order __m) noexcept
      { return __atomic_fetch_and(__ptr, __i, int(__m)); }

    template<typename _Tp>
      inline __attribute__((__always_inline__)) _Tp
      fetch_or(_Tp* __ptr, _Val<_Tp> __i, memory_order __m) noexcept
      { return __atomic_fetch_or(__ptr, __i, int(__m)); }

    template<typename _Tp>
      inline __attribute__((__always_inline__)) _Tp
      fetch_xor(_Tp* __ptr, _Val<_Tp> __i, memory_order __m) noexcept
      { return __atomic_fetch_xor(__ptr, __i, int(__m)); }

    template<typename _Tp>
      inline __attribute__((__always_inline__)) _Tp
      __add_fetch(_Tp* __ptr, _Diff<_Tp> __i) noexcept
      { return __atomic_add_fetch(__ptr, __i, 5); }

    template<typename _Tp>
      inline __attribute__((__always_inline__)) _Tp
      __sub_fetch(_Tp* __ptr, _Diff<_Tp> __i) noexcept
      { return __atomic_sub_fetch(__ptr, __i, 5); }

    template<typename _Tp>
      inline __attribute__((__always_inline__)) _Tp
      __and_fetch(_Tp* __ptr, _Val<_Tp> __i) noexcept
      { return __atomic_and_fetch(__ptr, __i, 5); }

    template<typename _Tp>
      inline __attribute__((__always_inline__)) _Tp
      __or_fetch(_Tp* __ptr, _Val<_Tp> __i) noexcept
      { return __atomic_or_fetch(__ptr, __i, 5); }

    template<typename _Tp>
      inline __attribute__((__always_inline__)) _Tp
      __xor_fetch(_Tp* __ptr, _Val<_Tp> __i) noexcept
      { return __atomic_xor_fetch(__ptr, __i, 5); }

    template<typename _Tp>
      concept __atomic_fetch_addable
 = requires (_Tp __t) { __atomic_fetch_add(&__t, __t, 0); };

    template<typename _Tp>
      _Tp
      __fetch_add_flt(_Tp* __ptr, _Val<_Tp> __i, memory_order __m) noexcept
      {
 if constexpr (__atomic_fetch_addable<_Tp>)
   return __atomic_fetch_add(__ptr, __i, int(__m));
 else
   {
     _Val<_Tp> __oldval = load (__ptr, memory_order_relaxed);
     _Val<_Tp> __newval = __oldval + __i;
     while (!compare_exchange_weak (__ptr, __oldval, __newval, __m,
        memory_order_relaxed))
       __newval = __oldval + __i;
     return __oldval;
   }
      }

    template<typename _Tp>
      concept __atomic_fetch_subtractable
 = requires (_Tp __t) { __atomic_fetch_sub(&__t, __t, 0); };

    template<typename _Tp>
      _Tp
      __fetch_sub_flt(_Tp* __ptr, _Val<_Tp> __i, memory_order __m) noexcept
      {
 if constexpr (__atomic_fetch_subtractable<_Tp>)
   return __atomic_fetch_sub(__ptr, __i, int(__m));
 else
   {
     _Val<_Tp> __oldval = load (__ptr, memory_order_relaxed);
     _Val<_Tp> __newval = __oldval - __i;
     while (!compare_exchange_weak (__ptr, __oldval, __newval, __m,
        memory_order_relaxed))
       __newval = __oldval - __i;
     return __oldval;
   }
      }

    template<typename _Tp>
      concept __atomic_add_fetchable
 = requires (_Tp __t) { __atomic_add_fetch(&__t, __t, 0); };

    template<typename _Tp>
      _Tp
      __add_fetch_flt(_Tp* __ptr, _Val<_Tp> __i) noexcept
      {
 if constexpr (__atomic_add_fetchable<_Tp>)
   return __atomic_add_fetch(__ptr, __i, 5);
 else
   {
     _Val<_Tp> __oldval = load (__ptr, memory_order_relaxed);
     _Val<_Tp> __newval = __oldval + __i;
     while (!compare_exchange_weak (__ptr, __oldval, __newval,
        memory_order_seq_cst,
        memory_order_relaxed))
       __newval = __oldval + __i;
     return __newval;
   }
      }

    template<typename _Tp>
      concept __atomic_sub_fetchable
 = requires (_Tp __t) { __atomic_sub_fetch(&__t, __t, 0); };

    template<typename _Tp>
      _Tp
      __sub_fetch_flt(_Tp* __ptr, _Val<_Tp> __i) noexcept
      {
 if constexpr (__atomic_sub_fetchable<_Tp>)
   return __atomic_sub_fetch(__ptr, __i, 5);
 else
   {
     _Val<_Tp> __oldval = load (__ptr, memory_order_relaxed);
     _Val<_Tp> __newval = __oldval - __i;
     while (!compare_exchange_weak (__ptr, __oldval, __newval,
        memory_order_seq_cst,
        memory_order_relaxed))
       __newval = __oldval - __i;
     return __newval;
   }
      }
  }


  template<typename _Fp>
    struct __atomic_float
    {
      static_assert(is_floating_point_v<_Fp>);

      static constexpr size_t _S_alignment = __alignof__(_Fp);

    public:
      using value_type = _Fp;
      using difference_type = value_type;

      static constexpr bool is_always_lock_free
 = __atomic_always_lock_free(sizeof(_Fp), 0);

      __atomic_float() = default;

      constexpr
      __atomic_float(_Fp __t) : _M_fp(__t)
      { __atomic_impl::__clear_padding(_M_fp); }

      __atomic_float(const __atomic_float&) = delete;
      __atomic_float& operator=(const __atomic_float&) = delete;
      __atomic_float& operator=(const __atomic_float&) volatile = delete;

      _Fp
      operator=(_Fp __t) volatile noexcept
      {
 this->store(__t);
 return __t;
      }

      _Fp
      operator=(_Fp __t) noexcept
      {
 this->store(__t);
 return __t;
      }

      bool
      is_lock_free() const volatile noexcept
      { return __atomic_impl::is_lock_free<sizeof(_Fp), _S_alignment>(); }

      bool
      is_lock_free() const noexcept
      { return __atomic_impl::is_lock_free<sizeof(_Fp), _S_alignment>(); }

      void
      store(_Fp __t, memory_order __m = memory_order_seq_cst) volatile noexcept
      { __atomic_impl::store(&_M_fp, __t, __m); }

      void
      store(_Fp __t, memory_order __m = memory_order_seq_cst) noexcept
      { __atomic_impl::store(&_M_fp, __t, __m); }

      _Fp
      load(memory_order __m = memory_order_seq_cst) const volatile noexcept
      { return __atomic_impl::load(&_M_fp, __m); }

      _Fp
      load(memory_order __m = memory_order_seq_cst) const noexcept
      { return __atomic_impl::load(&_M_fp, __m); }

      operator _Fp() const volatile noexcept { return this->load(); }
      operator _Fp() const noexcept { return this->load(); }

      _Fp
      exchange(_Fp __desired,
        memory_order __m = memory_order_seq_cst) volatile noexcept
      { return __atomic_impl::exchange(&_M_fp, __desired, __m); }

      _Fp
      exchange(_Fp __desired,
        memory_order __m = memory_order_seq_cst) noexcept
      { return __atomic_impl::exchange(&_M_fp, __desired, __m); }

      bool
      compare_exchange_weak(_Fp& __expected, _Fp __desired,
       memory_order __success,
       memory_order __failure) noexcept
      {
 return __atomic_impl::compare_exchange_weak(&_M_fp,
          __expected, __desired,
          __success, __failure);
      }

      bool
      compare_exchange_weak(_Fp& __expected, _Fp __desired,
       memory_order __success,
       memory_order __failure) volatile noexcept
      {
 return __atomic_impl::compare_exchange_weak(&_M_fp,
          __expected, __desired,
          __success, __failure);
      }

      bool
      compare_exchange_strong(_Fp& __expected, _Fp __desired,
         memory_order __success,
         memory_order __failure) noexcept
      {
 return __atomic_impl::compare_exchange_strong(&_M_fp,
            __expected, __desired,
            __success, __failure);
      }

      bool
      compare_exchange_strong(_Fp& __expected, _Fp __desired,
         memory_order __success,
         memory_order __failure) volatile noexcept
      {
 return __atomic_impl::compare_exchange_strong(&_M_fp,
            __expected, __desired,
            __success, __failure);
      }

      bool
      compare_exchange_weak(_Fp& __expected, _Fp __desired,
       memory_order __order = memory_order_seq_cst)
      noexcept
      {
 return compare_exchange_weak(__expected, __desired, __order,
                                     __cmpexch_failure_order(__order));
      }

      bool
      compare_exchange_weak(_Fp& __expected, _Fp __desired,
       memory_order __order = memory_order_seq_cst)
      volatile noexcept
      {
 return compare_exchange_weak(__expected, __desired, __order,
                                     __cmpexch_failure_order(__order));
      }

      bool
      compare_exchange_strong(_Fp& __expected, _Fp __desired,
         memory_order __order = memory_order_seq_cst)
      noexcept
      {
 return compare_exchange_strong(__expected, __desired, __order,
           __cmpexch_failure_order(__order));
      }

      bool
      compare_exchange_strong(_Fp& __expected, _Fp __desired,
         memory_order __order = memory_order_seq_cst)
      volatile noexcept
      {
 return compare_exchange_strong(__expected, __desired, __order,
           __cmpexch_failure_order(__order));
      }


      inline __attribute__((__always_inline__)) void
      wait(_Fp __old, memory_order __m = memory_order_seq_cst) const noexcept
      { __atomic_impl::wait(&_M_fp, __old, __m); }



      inline __attribute__((__always_inline__)) void
      notify_one() const noexcept
      { __atomic_impl::notify_one(&_M_fp); }



      inline __attribute__((__always_inline__)) void
      notify_all() const noexcept
      { __atomic_impl::notify_all(&_M_fp); }




      value_type
      fetch_add(value_type __i,
  memory_order __m = memory_order_seq_cst) noexcept
      { return __atomic_impl::__fetch_add_flt(&_M_fp, __i, __m); }

      value_type
      fetch_add(value_type __i,
  memory_order __m = memory_order_seq_cst) volatile noexcept
      { return __atomic_impl::__fetch_add_flt(&_M_fp, __i, __m); }

      value_type
      fetch_sub(value_type __i,
  memory_order __m = memory_order_seq_cst) noexcept
      { return __atomic_impl::__fetch_sub_flt(&_M_fp, __i, __m); }

      value_type
      fetch_sub(value_type __i,
  memory_order __m = memory_order_seq_cst) volatile noexcept
      { return __atomic_impl::__fetch_sub_flt(&_M_fp, __i, __m); }

      value_type
      operator+=(value_type __i) noexcept
      { return __atomic_impl::__add_fetch_flt(&_M_fp, __i); }

      value_type
      operator+=(value_type __i) volatile noexcept
      { return __atomic_impl::__add_fetch_flt(&_M_fp, __i); }

      value_type
      operator-=(value_type __i) noexcept
      { return __atomic_impl::__sub_fetch_flt(&_M_fp, __i); }

      value_type
      operator-=(value_type __i) volatile noexcept
      { return __atomic_impl::__sub_fetch_flt(&_M_fp, __i); }

    private:
      alignas(_S_alignment) _Fp _M_fp = 0;
    };


  template<typename _Tp,
           bool = is_integral_v<_Tp> && !is_same_v<_Tp, bool>,
           bool = is_floating_point_v<_Tp>>
    struct __atomic_ref;


  template<typename _Tp>
    struct __atomic_ref<_Tp, false, false>
    {
      static_assert(is_trivially_copyable_v<_Tp>);


      static constexpr int _S_min_alignment
 = (sizeof(_Tp) & (sizeof(_Tp) - 1)) || sizeof(_Tp) > 16
 ? 0 : sizeof(_Tp);

    public:
      using value_type = _Tp;

      static constexpr bool is_always_lock_free
 = __atomic_always_lock_free(sizeof(_Tp), 0);

      static constexpr size_t required_alignment
 = _S_min_alignment > alignof(_Tp) ? _S_min_alignment : alignof(_Tp);

      __atomic_ref& operator=(const __atomic_ref&) = delete;

      explicit
      __atomic_ref(_Tp& __t) : _M_ptr(std::__addressof(__t))
      {
 do { if (__builtin_expect(!bool(((long long unsigned int)_M_ptr % required_alignment) == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 1541, __PRETTY_FUNCTION__, "((long long unsigned int)_M_ptr % required_alignment) == 0"); } while (false);
      }

      __atomic_ref(const __atomic_ref&) noexcept = default;

      _Tp
      operator=(_Tp __t) const noexcept
      {
 this->store(__t);
 return __t;
      }

      operator _Tp() const noexcept { return this->load(); }

      bool
      is_lock_free() const noexcept
      { return __atomic_impl::is_lock_free<sizeof(_Tp), required_alignment>(); }

      void
      store(_Tp __t, memory_order __m = memory_order_seq_cst) const noexcept
      { __atomic_impl::store(_M_ptr, __t, __m); }

      _Tp
      load(memory_order __m = memory_order_seq_cst) const noexcept
      { return __atomic_impl::load(_M_ptr, __m); }

      _Tp
      exchange(_Tp __desired, memory_order __m = memory_order_seq_cst)
      const noexcept
      { return __atomic_impl::exchange(_M_ptr, __desired, __m); }

      bool
      compare_exchange_weak(_Tp& __expected, _Tp __desired,
       memory_order __success,
       memory_order __failure) const noexcept
      {
 return __atomic_impl::compare_exchange_weak<true>(
   _M_ptr, __expected, __desired, __success, __failure);
      }

      bool
      compare_exchange_strong(_Tp& __expected, _Tp __desired,
       memory_order __success,
       memory_order __failure) const noexcept
      {
 return __atomic_impl::compare_exchange_strong<true>(
   _M_ptr, __expected, __desired, __success, __failure);
      }

      bool
      compare_exchange_weak(_Tp& __expected, _Tp __desired,
       memory_order __order = memory_order_seq_cst)
      const noexcept
      {
 return compare_exchange_weak(__expected, __desired, __order,
                                     __cmpexch_failure_order(__order));
      }

      bool
      compare_exchange_strong(_Tp& __expected, _Tp __desired,
         memory_order __order = memory_order_seq_cst)
      const noexcept
      {
 return compare_exchange_strong(__expected, __desired, __order,
           __cmpexch_failure_order(__order));
      }


      inline __attribute__((__always_inline__)) void
      wait(_Tp __old, memory_order __m = memory_order_seq_cst) const noexcept
      { __atomic_impl::wait(_M_ptr, __old, __m); }



      inline __attribute__((__always_inline__)) void
      notify_one() const noexcept
      { __atomic_impl::notify_one(_M_ptr); }



      inline __attribute__((__always_inline__)) void
      notify_all() const noexcept
      { __atomic_impl::notify_all(_M_ptr); }




    private:
      _Tp* _M_ptr;
    };


  template<typename _Tp>
    struct __atomic_ref<_Tp, true, false>
    {
      static_assert(is_integral_v<_Tp>);

    public:
      using value_type = _Tp;
      using difference_type = value_type;

      static constexpr bool is_always_lock_free
 = __atomic_always_lock_free(sizeof(_Tp), 0);

      static constexpr size_t required_alignment
 = sizeof(_Tp) > alignof(_Tp) ? sizeof(_Tp) : alignof(_Tp);

      __atomic_ref() = delete;
      __atomic_ref& operator=(const __atomic_ref&) = delete;

      explicit
      __atomic_ref(_Tp& __t) : _M_ptr(&__t)
      {
 do { if (__builtin_expect(!bool(((long long unsigned int)_M_ptr % required_alignment) == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 1654, __PRETTY_FUNCTION__, "((long long unsigned int)_M_ptr % required_alignment) == 0"); } while (false);
      }

      __atomic_ref(const __atomic_ref&) noexcept = default;

      _Tp
      operator=(_Tp __t) const noexcept
      {
 this->store(__t);
 return __t;
      }

      operator _Tp() const noexcept { return this->load(); }

      bool
      is_lock_free() const noexcept
      {
 return __atomic_impl::is_lock_free<sizeof(_Tp), required_alignment>();
      }

      void
      store(_Tp __t, memory_order __m = memory_order_seq_cst) const noexcept
      { __atomic_impl::store(_M_ptr, __t, __m); }

      _Tp
      load(memory_order __m = memory_order_seq_cst) const noexcept
      { return __atomic_impl::load(_M_ptr, __m); }

      _Tp
      exchange(_Tp __desired,
        memory_order __m = memory_order_seq_cst) const noexcept
      { return __atomic_impl::exchange(_M_ptr, __desired, __m); }

      bool
      compare_exchange_weak(_Tp& __expected, _Tp __desired,
       memory_order __success,
       memory_order __failure) const noexcept
      {
 return __atomic_impl::compare_exchange_weak<true>(
   _M_ptr, __expected, __desired, __success, __failure);
      }

      bool
      compare_exchange_strong(_Tp& __expected, _Tp __desired,
         memory_order __success,
         memory_order __failure) const noexcept
      {
 return __atomic_impl::compare_exchange_strong<true>(
   _M_ptr, __expected, __desired, __success, __failure);
      }

      bool
      compare_exchange_weak(_Tp& __expected, _Tp __desired,
       memory_order __order = memory_order_seq_cst)
      const noexcept
      {
 return compare_exchange_weak(__expected, __desired, __order,
                                     __cmpexch_failure_order(__order));
      }

      bool
      compare_exchange_strong(_Tp& __expected, _Tp __desired,
         memory_order __order = memory_order_seq_cst)
      const noexcept
      {
 return compare_exchange_strong(__expected, __desired, __order,
           __cmpexch_failure_order(__order));
      }


      inline __attribute__((__always_inline__)) void
      wait(_Tp __old, memory_order __m = memory_order_seq_cst) const noexcept
      { __atomic_impl::wait(_M_ptr, __old, __m); }



      inline __attribute__((__always_inline__)) void
      notify_one() const noexcept
      { __atomic_impl::notify_one(_M_ptr); }



      inline __attribute__((__always_inline__)) void
      notify_all() const noexcept
      { __atomic_impl::notify_all(_M_ptr); }




      value_type
      fetch_add(value_type __i,
  memory_order __m = memory_order_seq_cst) const noexcept
      { return __atomic_impl::fetch_add(_M_ptr, __i, __m); }

      value_type
      fetch_sub(value_type __i,
  memory_order __m = memory_order_seq_cst) const noexcept
      { return __atomic_impl::fetch_sub(_M_ptr, __i, __m); }

      value_type
      fetch_and(value_type __i,
  memory_order __m = memory_order_seq_cst) const noexcept
      { return __atomic_impl::fetch_and(_M_ptr, __i, __m); }

      value_type
      fetch_or(value_type __i,
        memory_order __m = memory_order_seq_cst) const noexcept
      { return __atomic_impl::fetch_or(_M_ptr, __i, __m); }

      value_type
      fetch_xor(value_type __i,
  memory_order __m = memory_order_seq_cst) const noexcept
      { return __atomic_impl::fetch_xor(_M_ptr, __i, __m); }

      inline __attribute__((__always_inline__)) value_type
      operator++(int) const noexcept
      { return fetch_add(1); }

      inline __attribute__((__always_inline__)) value_type
      operator--(int) const noexcept
      { return fetch_sub(1); }

      value_type
      operator++() const noexcept
      { return __atomic_impl::__add_fetch(_M_ptr, value_type(1)); }

      value_type
      operator--() const noexcept
      { return __atomic_impl::__sub_fetch(_M_ptr, value_type(1)); }

      value_type
      operator+=(value_type __i) const noexcept
      { return __atomic_impl::__add_fetch(_M_ptr, __i); }

      value_type
      operator-=(value_type __i) const noexcept
      { return __atomic_impl::__sub_fetch(_M_ptr, __i); }

      value_type
      operator&=(value_type __i) const noexcept
      { return __atomic_impl::__and_fetch(_M_ptr, __i); }

      value_type
      operator|=(value_type __i) const noexcept
      { return __atomic_impl::__or_fetch(_M_ptr, __i); }

      value_type
      operator^=(value_type __i) const noexcept
      { return __atomic_impl::__xor_fetch(_M_ptr, __i); }

    private:
      _Tp* _M_ptr;
    };


  template<typename _Fp>
    struct __atomic_ref<_Fp, false, true>
    {
      static_assert(is_floating_point_v<_Fp>);

    public:
      using value_type = _Fp;
      using difference_type = value_type;

      static constexpr bool is_always_lock_free
 = __atomic_always_lock_free(sizeof(_Fp), 0);

      static constexpr size_t required_alignment = __alignof__(_Fp);

      __atomic_ref() = delete;
      __atomic_ref& operator=(const __atomic_ref&) = delete;

      explicit
      __atomic_ref(_Fp& __t) : _M_ptr(&__t)
      {
 do { if (__builtin_expect(!bool(((long long unsigned int)_M_ptr % required_alignment) == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 1829, __PRETTY_FUNCTION__, "((long long unsigned int)_M_ptr % required_alignment) == 0"); } while (false);
      }

      __atomic_ref(const __atomic_ref&) noexcept = default;

      _Fp
      operator=(_Fp __t) const noexcept
      {
 this->store(__t);
 return __t;
      }

      operator _Fp() const noexcept { return this->load(); }

      bool
      is_lock_free() const noexcept
      {
 return __atomic_impl::is_lock_free<sizeof(_Fp), required_alignment>();
      }

      void
      store(_Fp __t, memory_order __m = memory_order_seq_cst) const noexcept
      { __atomic_impl::store(_M_ptr, __t, __m); }

      _Fp
      load(memory_order __m = memory_order_seq_cst) const noexcept
      { return __atomic_impl::load(_M_ptr, __m); }

      _Fp
      exchange(_Fp __desired,
        memory_order __m = memory_order_seq_cst) const noexcept
      { return __atomic_impl::exchange(_M_ptr, __desired, __m); }

      bool
      compare_exchange_weak(_Fp& __expected, _Fp __desired,
       memory_order __success,
       memory_order __failure) const noexcept
      {
 return __atomic_impl::compare_exchange_weak<true>(
   _M_ptr, __expected, __desired, __success, __failure);
      }

      bool
      compare_exchange_strong(_Fp& __expected, _Fp __desired,
         memory_order __success,
         memory_order __failure) const noexcept
      {
 return __atomic_impl::compare_exchange_strong<true>(
   _M_ptr, __expected, __desired, __success, __failure);
      }

      bool
      compare_exchange_weak(_Fp& __expected, _Fp __desired,
       memory_order __order = memory_order_seq_cst)
      const noexcept
      {
 return compare_exchange_weak(__expected, __desired, __order,
                                     __cmpexch_failure_order(__order));
      }

      bool
      compare_exchange_strong(_Fp& __expected, _Fp __desired,
         memory_order __order = memory_order_seq_cst)
      const noexcept
      {
 return compare_exchange_strong(__expected, __desired, __order,
           __cmpexch_failure_order(__order));
      }


      inline __attribute__((__always_inline__)) void
      wait(_Fp __old, memory_order __m = memory_order_seq_cst) const noexcept
      { __atomic_impl::wait(_M_ptr, __old, __m); }



      inline __attribute__((__always_inline__)) void
      notify_one() const noexcept
      { __atomic_impl::notify_one(_M_ptr); }



      inline __attribute__((__always_inline__)) void
      notify_all() const noexcept
      { __atomic_impl::notify_all(_M_ptr); }




      value_type
      fetch_add(value_type __i,
  memory_order __m = memory_order_seq_cst) const noexcept
      { return __atomic_impl::__fetch_add_flt(_M_ptr, __i, __m); }

      value_type
      fetch_sub(value_type __i,
  memory_order __m = memory_order_seq_cst) const noexcept
      { return __atomic_impl::__fetch_sub_flt(_M_ptr, __i, __m); }

      value_type
      operator+=(value_type __i) const noexcept
      { return __atomic_impl::__add_fetch_flt(_M_ptr, __i); }

      value_type
      operator-=(value_type __i) const noexcept
      { return __atomic_impl::__sub_fetch_flt(_M_ptr, __i); }

    private:
      _Fp* _M_ptr;
    };


  template<typename _Tp>
    struct __atomic_ref<_Tp*, false, false>
    {
    public:
      using value_type = _Tp*;
      using difference_type = ptrdiff_t;

      static constexpr bool is_always_lock_free = 2 == 2;

      static constexpr size_t required_alignment = __alignof__(_Tp*);

      __atomic_ref() = delete;
      __atomic_ref& operator=(const __atomic_ref&) = delete;

      explicit
      __atomic_ref(_Tp*& __t) : _M_ptr(std::__addressof(__t))
      {
 do { if (__builtin_expect(!bool(((long long unsigned int)_M_ptr % required_alignment) == 0), false)) std::__glibcxx_assert_fail("C:/msys64/mingw64/include/c++/15.2.0/bits/atomic_base.h", 1958, __PRETTY_FUNCTION__, "((long long unsigned int)_M_ptr % required_alignment) == 0"); } while (false);
      }

      __atomic_ref(const __atomic_ref&) noexcept = default;

      _Tp*
      operator=(_Tp* __t) const noexcept
      {
 this->store(__t);
 return __t;
      }

      operator _Tp*() const noexcept { return this->load(); }

      bool
      is_lock_free() const noexcept
      {
 return __atomic_impl::is_lock_free<sizeof(_Tp*), required_alignment>();
      }

      void
      store(_Tp* __t, memory_order __m = memory_order_seq_cst) const noexcept
      { __atomic_impl::store(_M_ptr, __t, __m); }

      _Tp*
      load(memory_order __m = memory_order_seq_cst) const noexcept
      { return __atomic_impl::load(_M_ptr, __m); }

      _Tp*
      exchange(_Tp* __desired,
        memory_order __m = memory_order_seq_cst) const noexcept
      { return __atomic_impl::exchange(_M_ptr, __desired, __m); }

      bool
      compare_exchange_weak(_Tp*& __expected, _Tp* __desired,
       memory_order __success,
       memory_order __failure) const noexcept
      {
 return __atomic_impl::compare_exchange_weak<true>(
   _M_ptr, __expected, __desired, __success, __failure);
      }

      bool
      compare_exchange_strong(_Tp*& __expected, _Tp* __desired,
       memory_order __success,
       memory_order __failure) const noexcept
      {
 return __atomic_impl::compare_exchange_strong<true>(
   _M_ptr, __expected, __desired, __success, __failure);
      }

      bool
      compare_exchange_weak(_Tp*& __expected, _Tp* __desired,
       memory_order __order = memory_order_seq_cst)
      const noexcept
      {
 return compare_exchange_weak(__expected, __desired, __order,
                                     __cmpexch_failure_order(__order));
      }

      bool
      compare_exchange_strong(_Tp*& __expected, _Tp* __desired,
         memory_order __order = memory_order_seq_cst)
      const noexcept
      {
 return compare_exchange_strong(__expected, __desired, __order,
           __cmpexch_failure_order(__order));
      }


      inline __attribute__((__always_inline__)) void
      wait(_Tp* __old, memory_order __m = memory_order_seq_cst) const noexcept
      { __atomic_impl::wait(_M_ptr, __old, __m); }



      inline __attribute__((__always_inline__)) void
      notify_one() const noexcept
      { __atomic_impl::notify_one(_M_ptr); }



      inline __attribute__((__always_inline__)) void
      notify_all() const noexcept
      { __atomic_impl::notify_all(_M_ptr); }




      inline __attribute__((__always_inline__)) value_type
      fetch_add(difference_type __d,
  memory_order __m = memory_order_seq_cst) const noexcept
      { return __atomic_impl::fetch_add(_M_ptr, _S_type_size(__d), __m); }

      inline __attribute__((__always_inline__)) value_type
      fetch_sub(difference_type __d,
  memory_order __m = memory_order_seq_cst) const noexcept
      { return __atomic_impl::fetch_sub(_M_ptr, _S_type_size(__d), __m); }

      value_type
      operator++(int) const noexcept
      { return fetch_add(1); }

      value_type
      operator--(int) const noexcept
      { return fetch_sub(1); }

      value_type
      operator++() const noexcept
      {
 return __atomic_impl::__add_fetch(_M_ptr, _S_type_size(1));
      }

      value_type
      operator--() const noexcept
      {
 return __atomic_impl::__sub_fetch(_M_ptr, _S_type_size(1));
      }

      value_type
      operator+=(difference_type __d) const noexcept
      {
 return __atomic_impl::__add_fetch(_M_ptr, _S_type_size(__d));
      }

      value_type
      operator-=(difference_type __d) const noexcept
      {
 return __atomic_impl::__sub_fetch(_M_ptr, _S_type_size(__d));
      }

    private:
      static constexpr ptrdiff_t
      _S_type_size(ptrdiff_t __d) noexcept
      {
 static_assert(is_object_v<_Tp>);
 return __d * sizeof(_Tp);
      }

      _Tp** _M_ptr;
    };







}
# 53 "C:/msys64/mingw64/include/c++/15.2.0/atomic" 2 3



namespace std
{







  template<typename _Tp>
    struct atomic;



  template<>
  struct atomic<bool>
  {
    using value_type = bool;

  private:
    __atomic_base<bool> _M_base;

  public:
    atomic() noexcept = default;
    ~atomic() noexcept = default;
    atomic(const atomic&) = delete;
    atomic& operator=(const atomic&) = delete;
    atomic& operator=(const atomic&) volatile = delete;

    constexpr atomic(bool __i) noexcept : _M_base(__i) { }

    bool
    operator=(bool __i) noexcept
    { return _M_base.operator=(__i); }

    bool
    operator=(bool __i) volatile noexcept
    { return _M_base.operator=(__i); }

    operator bool() const noexcept
    { return _M_base.load(); }

    operator bool() const volatile noexcept
    { return _M_base.load(); }

    bool
    is_lock_free() const noexcept { return _M_base.is_lock_free(); }

    bool
    is_lock_free() const volatile noexcept { return _M_base.is_lock_free(); }


    static constexpr bool is_always_lock_free = 2 == 2;


    void
    store(bool __i, memory_order __m = memory_order_seq_cst) noexcept
    { _M_base.store(__i, __m); }

    void
    store(bool __i, memory_order __m = memory_order_seq_cst) volatile noexcept
    { _M_base.store(__i, __m); }

    bool
    load(memory_order __m = memory_order_seq_cst) const noexcept
    { return _M_base.load(__m); }

    bool
    load(memory_order __m = memory_order_seq_cst) const volatile noexcept
    { return _M_base.load(__m); }

    bool
    exchange(bool __i, memory_order __m = memory_order_seq_cst) noexcept
    { return _M_base.exchange(__i, __m); }

    bool
    exchange(bool __i,
      memory_order __m = memory_order_seq_cst) volatile noexcept
    { return _M_base.exchange(__i, __m); }

    bool
    compare_exchange_weak(bool& __i1, bool __i2, memory_order __m1,
     memory_order __m2) noexcept
    { return _M_base.compare_exchange_weak(__i1, __i2, __m1, __m2); }

    bool
    compare_exchange_weak(bool& __i1, bool __i2, memory_order __m1,
     memory_order __m2) volatile noexcept
    { return _M_base.compare_exchange_weak(__i1, __i2, __m1, __m2); }

    bool
    compare_exchange_weak(bool& __i1, bool __i2,
     memory_order __m = memory_order_seq_cst) noexcept
    { return _M_base.compare_exchange_weak(__i1, __i2, __m); }

    bool
    compare_exchange_weak(bool& __i1, bool __i2,
       memory_order __m = memory_order_seq_cst) volatile noexcept
    { return _M_base.compare_exchange_weak(__i1, __i2, __m); }

    bool
    compare_exchange_strong(bool& __i1, bool __i2, memory_order __m1,
       memory_order __m2) noexcept
    { return _M_base.compare_exchange_strong(__i1, __i2, __m1, __m2); }

    bool
    compare_exchange_strong(bool& __i1, bool __i2, memory_order __m1,
       memory_order __m2) volatile noexcept
    { return _M_base.compare_exchange_strong(__i1, __i2, __m1, __m2); }

    bool
    compare_exchange_strong(bool& __i1, bool __i2,
       memory_order __m = memory_order_seq_cst) noexcept
    { return _M_base.compare_exchange_strong(__i1, __i2, __m); }

    bool
    compare_exchange_strong(bool& __i1, bool __i2,
      memory_order __m = memory_order_seq_cst) volatile noexcept
    { return _M_base.compare_exchange_strong(__i1, __i2, __m); }


    void
    wait(bool __old, memory_order __m = memory_order_seq_cst) const noexcept
    { _M_base.wait(__old, __m); }



    void
    notify_one() noexcept
    { _M_base.notify_one(); }

    void
    notify_all() noexcept
    { _M_base.notify_all(); }

  };






  template<typename _Tp>
    struct atomic
    {
      using value_type = _Tp;

    private:

      static constexpr int _S_min_alignment
 = (sizeof(_Tp) & (sizeof(_Tp) - 1)) || sizeof(_Tp) > 16
 ? 0 : sizeof(_Tp);

      static constexpr int _S_alignment
        = _S_min_alignment > alignof(_Tp) ? _S_min_alignment : alignof(_Tp);

      alignas(_S_alignment) _Tp _M_i;

      static_assert(__is_trivially_copyable(_Tp),
      "std::atomic requires a trivially copyable type");

      static_assert(sizeof(_Tp) > 0,
      "Incomplete or zero-sized types are not supported");


      static_assert(is_copy_constructible_v<_Tp>);
      static_assert(is_move_constructible_v<_Tp>);
      static_assert(is_copy_assignable_v<_Tp>);
      static_assert(is_move_assignable_v<_Tp>);


    public:



      constexpr atomic() noexcept(is_nothrow_default_constructible_v<_Tp>)
 requires is_default_constructible_v<_Tp>
 : _M_i()
      {}




      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(_Tp __i) noexcept : _M_i(__i)
      {

 if constexpr (__atomic_impl::__maybe_has_padding<_Tp>())
   __builtin_clear_padding(std::__addressof(_M_i));

      }

      operator _Tp() const noexcept
      { return load(); }

      operator _Tp() const volatile noexcept
      { return load(); }

      _Tp
      operator=(_Tp __i) noexcept
      { store(__i); return __i; }

      _Tp
      operator=(_Tp __i) volatile noexcept
      { store(__i); return __i; }

      bool
      is_lock_free() const noexcept
      {

 return __atomic_is_lock_free(sizeof(_M_i),
     reinterpret_cast<void *>(-_S_alignment));
      }

      bool
      is_lock_free() const volatile noexcept
      {

 return __atomic_is_lock_free(sizeof(_M_i),
     reinterpret_cast<void *>(-_S_alignment));
      }


      static constexpr bool is_always_lock_free
 = __atomic_always_lock_free(sizeof(_M_i), 0);


      void
      store(_Tp __i, memory_order __m = memory_order_seq_cst) noexcept
      {
 __atomic_store(std::__addressof(_M_i),
         __atomic_impl::__clear_padding(__i),
         int(__m));
      }

      void
      store(_Tp __i, memory_order __m = memory_order_seq_cst) volatile noexcept
      {
 __atomic_store(std::__addressof(_M_i),
         __atomic_impl::__clear_padding(__i),
         int(__m));
      }

      _Tp
      load(memory_order __m = memory_order_seq_cst) const noexcept
      {
 alignas(_Tp) unsigned char __buf[sizeof(_Tp)];
 _Tp* __ptr = reinterpret_cast<_Tp*>(__buf);
 __atomic_load(std::__addressof(_M_i), __ptr, int(__m));
 return *__ptr;
      }

      _Tp
      load(memory_order __m = memory_order_seq_cst) const volatile noexcept
      {
        alignas(_Tp) unsigned char __buf[sizeof(_Tp)];
 _Tp* __ptr = reinterpret_cast<_Tp*>(__buf);
 __atomic_load(std::__addressof(_M_i), __ptr, int(__m));
 return *__ptr;
      }

      _Tp
      exchange(_Tp __i, memory_order __m = memory_order_seq_cst) noexcept
      {
        alignas(_Tp) unsigned char __buf[sizeof(_Tp)];
 _Tp* __ptr = reinterpret_cast<_Tp*>(__buf);
 __atomic_exchange(std::__addressof(_M_i),
     __atomic_impl::__clear_padding(__i),
     __ptr, int(__m));
 return *__ptr;
      }

      _Tp
      exchange(_Tp __i,
        memory_order __m = memory_order_seq_cst) volatile noexcept
      {
        alignas(_Tp) unsigned char __buf[sizeof(_Tp)];
 _Tp* __ptr = reinterpret_cast<_Tp*>(__buf);
 __atomic_exchange(std::__addressof(_M_i),
     __atomic_impl::__clear_padding(__i),
     __ptr, int(__m));
 return *__ptr;
      }

      bool
      compare_exchange_weak(_Tp& __e, _Tp __i, memory_order __s,
       memory_order __f) noexcept
      {
 return __atomic_impl::__compare_exchange(_M_i, __e, __i, true,
       __s, __f);
      }

      bool
      compare_exchange_weak(_Tp& __e, _Tp __i, memory_order __s,
       memory_order __f) volatile noexcept
      {
 return __atomic_impl::__compare_exchange(_M_i, __e, __i, true,
       __s, __f);
      }

      bool
      compare_exchange_weak(_Tp& __e, _Tp __i,
       memory_order __m = memory_order_seq_cst) noexcept
      { return compare_exchange_weak(__e, __i, __m,
                                     __cmpexch_failure_order(__m)); }

      bool
      compare_exchange_weak(_Tp& __e, _Tp __i,
       memory_order __m = memory_order_seq_cst) volatile noexcept
      { return compare_exchange_weak(__e, __i, __m,
                                     __cmpexch_failure_order(__m)); }

      bool
      compare_exchange_strong(_Tp& __e, _Tp __i, memory_order __s,
         memory_order __f) noexcept
      {
 return __atomic_impl::__compare_exchange(_M_i, __e, __i, false,
       __s, __f);
      }

      bool
      compare_exchange_strong(_Tp& __e, _Tp __i, memory_order __s,
         memory_order __f) volatile noexcept
      {
 return __atomic_impl::__compare_exchange(_M_i, __e, __i, false,
       __s, __f);
      }

      bool
      compare_exchange_strong(_Tp& __e, _Tp __i,
          memory_order __m = memory_order_seq_cst) noexcept
      { return compare_exchange_strong(__e, __i, __m,
                                       __cmpexch_failure_order(__m)); }

      bool
      compare_exchange_strong(_Tp& __e, _Tp __i,
       memory_order __m = memory_order_seq_cst) volatile noexcept
      { return compare_exchange_strong(__e, __i, __m,
                                       __cmpexch_failure_order(__m)); }


      void
      wait(_Tp __old, memory_order __m = memory_order_seq_cst) const noexcept
      {
 std::__atomic_wait_address_v(&_M_i, __old,
      [__m, this] { return this->load(__m); });
      }



      void
      notify_one() noexcept
      { std::__atomic_notify_address(&_M_i, false); }

      void
      notify_all() noexcept
      { std::__atomic_notify_address(&_M_i, true); }


    };


  template<typename _Tp>
    struct atomic<_Tp*>
    {
      using value_type = _Tp*;
      using difference_type = ptrdiff_t;

      typedef _Tp* __pointer_type;
      typedef __atomic_base<_Tp*> __base_type;
      __base_type _M_b;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__pointer_type __p) noexcept : _M_b(__p) { }

      operator __pointer_type() const noexcept
      { return __pointer_type(_M_b); }

      operator __pointer_type() const volatile noexcept
      { return __pointer_type(_M_b); }

      __pointer_type
      operator=(__pointer_type __p) noexcept
      { return _M_b.operator=(__p); }

      __pointer_type
      operator=(__pointer_type __p) volatile noexcept
      { return _M_b.operator=(__p); }

      __pointer_type
      operator++(int) noexcept
      {

 static_assert( is_object_v<_Tp>, "pointer to object type" );

 return _M_b++;
      }

      __pointer_type
      operator++(int) volatile noexcept
      {

 static_assert( is_object_v<_Tp>, "pointer to object type" );

 return _M_b++;
      }

      __pointer_type
      operator--(int) noexcept
      {

 static_assert( is_object_v<_Tp>, "pointer to object type" );

 return _M_b--;
      }

      __pointer_type
      operator--(int) volatile noexcept
      {

 static_assert( is_object_v<_Tp>, "pointer to object type" );

 return _M_b--;
      }

      __pointer_type
      operator++() noexcept
      {

 static_assert( is_object_v<_Tp>, "pointer to object type" );

 return ++_M_b;
      }

      __pointer_type
      operator++() volatile noexcept
      {

 static_assert( is_object_v<_Tp>, "pointer to object type" );

 return ++_M_b;
      }

      __pointer_type
      operator--() noexcept
      {

 static_assert( is_object_v<_Tp>, "pointer to object type" );

 return --_M_b;
      }

      __pointer_type
      operator--() volatile noexcept
      {

 static_assert( is_object_v<_Tp>, "pointer to object type" );

 return --_M_b;
      }

      __pointer_type
      operator+=(ptrdiff_t __d) noexcept
      {

 static_assert( is_object_v<_Tp>, "pointer to object type" );

 return _M_b.operator+=(__d);
      }

      __pointer_type
      operator+=(ptrdiff_t __d) volatile noexcept
      {

 static_assert( is_object_v<_Tp>, "pointer to object type" );

 return _M_b.operator+=(__d);
      }

      __pointer_type
      operator-=(ptrdiff_t __d) noexcept
      {

 static_assert( is_object_v<_Tp>, "pointer to object type" );

 return _M_b.operator-=(__d);
      }

      __pointer_type
      operator-=(ptrdiff_t __d) volatile noexcept
      {

 static_assert( is_object_v<_Tp>, "pointer to object type" );

 return _M_b.operator-=(__d);
      }

      bool
      is_lock_free() const noexcept
      { return _M_b.is_lock_free(); }

      bool
      is_lock_free() const volatile noexcept
      { return _M_b.is_lock_free(); }


      static constexpr bool is_always_lock_free
 = 2 == 2;


      void
      store(__pointer_type __p,
     memory_order __m = memory_order_seq_cst) noexcept
      { return _M_b.store(__p, __m); }

      void
      store(__pointer_type __p,
     memory_order __m = memory_order_seq_cst) volatile noexcept
      { return _M_b.store(__p, __m); }

      __pointer_type
      load(memory_order __m = memory_order_seq_cst) const noexcept
      { return _M_b.load(__m); }

      __pointer_type
      load(memory_order __m = memory_order_seq_cst) const volatile noexcept
      { return _M_b.load(__m); }

      __pointer_type
      exchange(__pointer_type __p,
        memory_order __m = memory_order_seq_cst) noexcept
      { return _M_b.exchange(__p, __m); }

      __pointer_type
      exchange(__pointer_type __p,
        memory_order __m = memory_order_seq_cst) volatile noexcept
      { return _M_b.exchange(__p, __m); }

      bool
      compare_exchange_weak(__pointer_type& __p1, __pointer_type __p2,
       memory_order __m1, memory_order __m2) noexcept
      { return _M_b.compare_exchange_weak(__p1, __p2, __m1, __m2); }

      bool
      compare_exchange_weak(__pointer_type& __p1, __pointer_type __p2,
       memory_order __m1,
       memory_order __m2) volatile noexcept
      { return _M_b.compare_exchange_weak(__p1, __p2, __m1, __m2); }

      bool
      compare_exchange_weak(__pointer_type& __p1, __pointer_type __p2,
       memory_order __m = memory_order_seq_cst) noexcept
      {
 return compare_exchange_weak(__p1, __p2, __m,
         __cmpexch_failure_order(__m));
      }

      bool
      compare_exchange_weak(__pointer_type& __p1, __pointer_type __p2,
      memory_order __m = memory_order_seq_cst) volatile noexcept
      {
 return compare_exchange_weak(__p1, __p2, __m,
         __cmpexch_failure_order(__m));
      }

      bool
      compare_exchange_strong(__pointer_type& __p1, __pointer_type __p2,
         memory_order __m1, memory_order __m2) noexcept
      { return _M_b.compare_exchange_strong(__p1, __p2, __m1, __m2); }

      bool
      compare_exchange_strong(__pointer_type& __p1, __pointer_type __p2,
         memory_order __m1,
         memory_order __m2) volatile noexcept
      { return _M_b.compare_exchange_strong(__p1, __p2, __m1, __m2); }

      bool
      compare_exchange_strong(__pointer_type& __p1, __pointer_type __p2,
         memory_order __m = memory_order_seq_cst) noexcept
      {
 return _M_b.compare_exchange_strong(__p1, __p2, __m,
         __cmpexch_failure_order(__m));
      }

      bool
      compare_exchange_strong(__pointer_type& __p1, __pointer_type __p2,
      memory_order __m = memory_order_seq_cst) volatile noexcept
      {
 return _M_b.compare_exchange_strong(__p1, __p2, __m,
         __cmpexch_failure_order(__m));
      }


    void
    wait(__pointer_type __old, memory_order __m = memory_order_seq_cst) const noexcept
    { _M_b.wait(__old, __m); }



    void
    notify_one() noexcept
    { _M_b.notify_one(); }

    void
    notify_all() noexcept
    { _M_b.notify_all(); }


      __pointer_type
      fetch_add(ptrdiff_t __d,
  memory_order __m = memory_order_seq_cst) noexcept
      {

 static_assert( is_object_v<_Tp>, "pointer to object type" );

 return _M_b.fetch_add(__d, __m);
      }

      __pointer_type
      fetch_add(ptrdiff_t __d,
  memory_order __m = memory_order_seq_cst) volatile noexcept
      {

 static_assert( is_object_v<_Tp>, "pointer to object type" );

 return _M_b.fetch_add(__d, __m);
      }

      __pointer_type
      fetch_sub(ptrdiff_t __d,
  memory_order __m = memory_order_seq_cst) noexcept
      {

 static_assert( is_object_v<_Tp>, "pointer to object type" );

 return _M_b.fetch_sub(__d, __m);
      }

      __pointer_type
      fetch_sub(ptrdiff_t __d,
  memory_order __m = memory_order_seq_cst) volatile noexcept
      {

 static_assert( is_object_v<_Tp>, "pointer to object type" );

 return _M_b.fetch_sub(__d, __m);
      }
    };



  template<>
    struct atomic<char> : __atomic_base<char>
    {
      typedef char __integral_type;
      typedef __atomic_base<char> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 2 == 2;

    };


  template<>
    struct atomic<signed char> : __atomic_base<signed char>
    {
      typedef signed char __integral_type;
      typedef __atomic_base<signed char> __base_type;

      atomic() noexcept= default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 2 == 2;

    };


  template<>
    struct atomic<unsigned char> : __atomic_base<unsigned char>
    {
      typedef unsigned char __integral_type;
      typedef __atomic_base<unsigned char> __base_type;

      atomic() noexcept= default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 2 == 2;

    };


  template<>
    struct atomic<short> : __atomic_base<short>
    {
      typedef short __integral_type;
      typedef __atomic_base<short> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 2 == 2;

    };


  template<>
    struct atomic<unsigned short> : __atomic_base<unsigned short>
    {
      typedef unsigned short __integral_type;
      typedef __atomic_base<unsigned short> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 2 == 2;

    };


  template<>
    struct atomic<int> : __atomic_base<int>
    {
      typedef int __integral_type;
      typedef __atomic_base<int> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 2 == 2;

    };


  template<>
    struct atomic<unsigned int> : __atomic_base<unsigned int>
    {
      typedef unsigned int __integral_type;
      typedef __atomic_base<unsigned int> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 2 == 2;

    };


  template<>
    struct atomic<long> : __atomic_base<long>
    {
      typedef long __integral_type;
      typedef __atomic_base<long> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 2 == 2;

    };


  template<>
    struct atomic<unsigned long> : __atomic_base<unsigned long>
    {
      typedef unsigned long __integral_type;
      typedef __atomic_base<unsigned long> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 2 == 2;

    };


  template<>
    struct atomic<long long> : __atomic_base<long long>
    {
      typedef long long __integral_type;
      typedef __atomic_base<long long> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 2 == 2;

    };


  template<>
    struct atomic<unsigned long long> : __atomic_base<unsigned long long>
    {
      typedef unsigned long long __integral_type;
      typedef __atomic_base<unsigned long long> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 2 == 2;

    };


  template<>
    struct atomic<wchar_t> : __atomic_base<wchar_t>
    {
      typedef wchar_t __integral_type;
      typedef __atomic_base<wchar_t> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 2 == 2;

    };



  template<>
    struct atomic<char8_t> : __atomic_base<char8_t>
    {
      typedef char8_t __integral_type;
      typedef __atomic_base<char8_t> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free
 = 2 == 2;

    };



  template<>
    struct atomic<char16_t> : __atomic_base<char16_t>
    {
      typedef char16_t __integral_type;
      typedef __atomic_base<char16_t> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free
 = 2 == 2;

    };


  template<>
    struct atomic<char32_t> : __atomic_base<char32_t>
    {
      typedef char32_t __integral_type;
      typedef __atomic_base<char32_t> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free
 = 2 == 2;

    };



  typedef atomic<bool> atomic_bool;


  typedef atomic<char> atomic_char;


  typedef atomic<signed char> atomic_schar;


  typedef atomic<unsigned char> atomic_uchar;


  typedef atomic<short> atomic_short;


  typedef atomic<unsigned short> atomic_ushort;


  typedef atomic<int> atomic_int;


  typedef atomic<unsigned int> atomic_uint;


  typedef atomic<long> atomic_long;


  typedef atomic<unsigned long> atomic_ulong;


  typedef atomic<long long> atomic_llong;


  typedef atomic<unsigned long long> atomic_ullong;


  typedef atomic<wchar_t> atomic_wchar_t;



  typedef atomic<char8_t> atomic_char8_t;



  typedef atomic<char16_t> atomic_char16_t;


  typedef atomic<char32_t> atomic_char32_t;






  typedef atomic<int8_t> atomic_int8_t;


  typedef atomic<uint8_t> atomic_uint8_t;


  typedef atomic<int16_t> atomic_int16_t;


  typedef atomic<uint16_t> atomic_uint16_t;


  typedef atomic<int32_t> atomic_int32_t;


  typedef atomic<uint32_t> atomic_uint32_t;


  typedef atomic<int64_t> atomic_int64_t;


  typedef atomic<uint64_t> atomic_uint64_t;



  typedef atomic<int_least8_t> atomic_int_least8_t;


  typedef atomic<uint_least8_t> atomic_uint_least8_t;


  typedef atomic<int_least16_t> atomic_int_least16_t;


  typedef atomic<uint_least16_t> atomic_uint_least16_t;


  typedef atomic<int_least32_t> atomic_int_least32_t;


  typedef atomic<uint_least32_t> atomic_uint_least32_t;


  typedef atomic<int_least64_t> atomic_int_least64_t;


  typedef atomic<uint_least64_t> atomic_uint_least64_t;



  typedef atomic<int_fast8_t> atomic_int_fast8_t;


  typedef atomic<uint_fast8_t> atomic_uint_fast8_t;


  typedef atomic<int_fast16_t> atomic_int_fast16_t;


  typedef atomic<uint_fast16_t> atomic_uint_fast16_t;


  typedef atomic<int_fast32_t> atomic_int_fast32_t;


  typedef atomic<uint_fast32_t> atomic_uint_fast32_t;


  typedef atomic<int_fast64_t> atomic_int_fast64_t;


  typedef atomic<uint_fast64_t> atomic_uint_fast64_t;



  typedef atomic<intptr_t> atomic_intptr_t;


  typedef atomic<uintptr_t> atomic_uintptr_t;


  typedef atomic<size_t> atomic_size_t;


  typedef atomic<ptrdiff_t> atomic_ptrdiff_t;


  typedef atomic<intmax_t> atomic_intmax_t;


  typedef atomic<uintmax_t> atomic_uintmax_t;


  inline bool
  atomic_flag_test_and_set_explicit(atomic_flag* __a,
        memory_order __m) noexcept
  { return __a->test_and_set(__m); }

  inline bool
  atomic_flag_test_and_set_explicit(volatile atomic_flag* __a,
        memory_order __m) noexcept
  { return __a->test_and_set(__m); }


  inline bool
  atomic_flag_test(const atomic_flag* __a) noexcept
  { return __a->test(); }

  inline bool
  atomic_flag_test(const volatile atomic_flag* __a) noexcept
  { return __a->test(); }

  inline bool
  atomic_flag_test_explicit(const atomic_flag* __a,
       memory_order __m) noexcept
  { return __a->test(__m); }

  inline bool
  atomic_flag_test_explicit(const volatile atomic_flag* __a,
       memory_order __m) noexcept
  { return __a->test(__m); }


  inline void
  atomic_flag_clear_explicit(atomic_flag* __a, memory_order __m) noexcept
  { __a->clear(__m); }

  inline void
  atomic_flag_clear_explicit(volatile atomic_flag* __a,
        memory_order __m) noexcept
  { __a->clear(__m); }

  inline bool
  atomic_flag_test_and_set(atomic_flag* __a) noexcept
  { return atomic_flag_test_and_set_explicit(__a, memory_order_seq_cst); }

  inline bool
  atomic_flag_test_and_set(volatile atomic_flag* __a) noexcept
  { return atomic_flag_test_and_set_explicit(__a, memory_order_seq_cst); }

  inline void
  atomic_flag_clear(atomic_flag* __a) noexcept
  { atomic_flag_clear_explicit(__a, memory_order_seq_cst); }

  inline void
  atomic_flag_clear(volatile atomic_flag* __a) noexcept
  { atomic_flag_clear_explicit(__a, memory_order_seq_cst); }


  inline void
  atomic_flag_wait(atomic_flag* __a, bool __old) noexcept
  { __a->wait(__old); }

  inline void
  atomic_flag_wait_explicit(atomic_flag* __a, bool __old,
                                memory_order __m) noexcept
  { __a->wait(__old, __m); }

  inline void
  atomic_flag_notify_one(atomic_flag* __a) noexcept
  { __a->notify_one(); }

  inline void
  atomic_flag_notify_all(atomic_flag* __a) noexcept
  { __a->notify_all(); }





  template<typename _Tp>
    using __atomic_val_t = __type_identity_t<_Tp>;
  template<typename _Tp>
    using __atomic_diff_t = typename atomic<_Tp>::difference_type;




  template<typename _ITp>
    inline bool
    atomic_is_lock_free(const atomic<_ITp>* __a) noexcept
    { return __a->is_lock_free(); }

  template<typename _ITp>
    inline bool
    atomic_is_lock_free(const volatile atomic<_ITp>* __a) noexcept
    { return __a->is_lock_free(); }

  template<typename _ITp>
    inline void
    atomic_init(atomic<_ITp>* __a, __atomic_val_t<_ITp> __i) noexcept
    { __a->store(__i, memory_order_relaxed); }

  template<typename _ITp>
    inline void
    atomic_init(volatile atomic<_ITp>* __a, __atomic_val_t<_ITp> __i) noexcept
    { __a->store(__i, memory_order_relaxed); }

  template<typename _ITp>
    inline void
    atomic_store_explicit(atomic<_ITp>* __a, __atomic_val_t<_ITp> __i,
     memory_order __m) noexcept
    { __a->store(__i, __m); }

  template<typename _ITp>
    inline void
    atomic_store_explicit(volatile atomic<_ITp>* __a, __atomic_val_t<_ITp> __i,
     memory_order __m) noexcept
    { __a->store(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_load_explicit(const atomic<_ITp>* __a, memory_order __m) noexcept
    { return __a->load(__m); }

  template<typename _ITp>
    inline _ITp
    atomic_load_explicit(const volatile atomic<_ITp>* __a,
    memory_order __m) noexcept
    { return __a->load(__m); }

  template<typename _ITp>
    inline _ITp
    atomic_exchange_explicit(atomic<_ITp>* __a, __atomic_val_t<_ITp> __i,
        memory_order __m) noexcept
    { return __a->exchange(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_exchange_explicit(volatile atomic<_ITp>* __a,
        __atomic_val_t<_ITp> __i,
        memory_order __m) noexcept
    { return __a->exchange(__i, __m); }

  template<typename _ITp>
    inline bool
    atomic_compare_exchange_weak_explicit(atomic<_ITp>* __a,
       __atomic_val_t<_ITp>* __i1,
       __atomic_val_t<_ITp> __i2,
       memory_order __m1,
       memory_order __m2) noexcept
    { return __a->compare_exchange_weak(*__i1, __i2, __m1, __m2); }

  template<typename _ITp>
    inline bool
    atomic_compare_exchange_weak_explicit(volatile atomic<_ITp>* __a,
       __atomic_val_t<_ITp>* __i1,
       __atomic_val_t<_ITp> __i2,
       memory_order __m1,
       memory_order __m2) noexcept
    { return __a->compare_exchange_weak(*__i1, __i2, __m1, __m2); }

  template<typename _ITp>
    inline bool
    atomic_compare_exchange_strong_explicit(atomic<_ITp>* __a,
         __atomic_val_t<_ITp>* __i1,
         __atomic_val_t<_ITp> __i2,
         memory_order __m1,
         memory_order __m2) noexcept
    { return __a->compare_exchange_strong(*__i1, __i2, __m1, __m2); }

  template<typename _ITp>
    inline bool
    atomic_compare_exchange_strong_explicit(volatile atomic<_ITp>* __a,
         __atomic_val_t<_ITp>* __i1,
         __atomic_val_t<_ITp> __i2,
         memory_order __m1,
         memory_order __m2) noexcept
    { return __a->compare_exchange_strong(*__i1, __i2, __m1, __m2); }


  template<typename _ITp>
    inline void
    atomic_store(atomic<_ITp>* __a, __atomic_val_t<_ITp> __i) noexcept
    { atomic_store_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline void
    atomic_store(volatile atomic<_ITp>* __a, __atomic_val_t<_ITp> __i) noexcept
    { atomic_store_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_load(const atomic<_ITp>* __a) noexcept
    { return atomic_load_explicit(__a, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_load(const volatile atomic<_ITp>* __a) noexcept
    { return atomic_load_explicit(__a, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_exchange(atomic<_ITp>* __a, __atomic_val_t<_ITp> __i) noexcept
    { return atomic_exchange_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_exchange(volatile atomic<_ITp>* __a,
      __atomic_val_t<_ITp> __i) noexcept
    { return atomic_exchange_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline bool
    atomic_compare_exchange_weak(atomic<_ITp>* __a,
     __atomic_val_t<_ITp>* __i1,
     __atomic_val_t<_ITp> __i2) noexcept
    {
      return atomic_compare_exchange_weak_explicit(__a, __i1, __i2,
         memory_order_seq_cst,
         memory_order_seq_cst);
    }

  template<typename _ITp>
    inline bool
    atomic_compare_exchange_weak(volatile atomic<_ITp>* __a,
     __atomic_val_t<_ITp>* __i1,
     __atomic_val_t<_ITp> __i2) noexcept
    {
      return atomic_compare_exchange_weak_explicit(__a, __i1, __i2,
         memory_order_seq_cst,
         memory_order_seq_cst);
    }

  template<typename _ITp>
    inline bool
    atomic_compare_exchange_strong(atomic<_ITp>* __a,
       __atomic_val_t<_ITp>* __i1,
       __atomic_val_t<_ITp> __i2) noexcept
    {
      return atomic_compare_exchange_strong_explicit(__a, __i1, __i2,
           memory_order_seq_cst,
           memory_order_seq_cst);
    }

  template<typename _ITp>
    inline bool
    atomic_compare_exchange_strong(volatile atomic<_ITp>* __a,
       __atomic_val_t<_ITp>* __i1,
       __atomic_val_t<_ITp> __i2) noexcept
    {
      return atomic_compare_exchange_strong_explicit(__a, __i1, __i2,
           memory_order_seq_cst,
           memory_order_seq_cst);
    }



  template<typename _Tp>
    inline void
    atomic_wait(const atomic<_Tp>* __a,
         typename std::atomic<_Tp>::value_type __old) noexcept
    { __a->wait(__old); }

  template<typename _Tp>
    inline void
    atomic_wait_explicit(const atomic<_Tp>* __a,
    typename std::atomic<_Tp>::value_type __old,
    std::memory_order __m) noexcept
    { __a->wait(__old, __m); }

  template<typename _Tp>
    inline void
    atomic_notify_one(atomic<_Tp>* __a) noexcept
    { __a->notify_one(); }

  template<typename _Tp>
    inline void
    atomic_notify_all(atomic<_Tp>* __a) noexcept
    { __a->notify_all(); }






  template<typename _ITp>
    inline _ITp
    atomic_fetch_add_explicit(atomic<_ITp>* __a,
         __atomic_diff_t<_ITp> __i,
         memory_order __m) noexcept
    { return __a->fetch_add(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_add_explicit(volatile atomic<_ITp>* __a,
         __atomic_diff_t<_ITp> __i,
         memory_order __m) noexcept
    { return __a->fetch_add(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_sub_explicit(atomic<_ITp>* __a,
         __atomic_diff_t<_ITp> __i,
         memory_order __m) noexcept
    { return __a->fetch_sub(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_sub_explicit(volatile atomic<_ITp>* __a,
         __atomic_diff_t<_ITp> __i,
         memory_order __m) noexcept
    { return __a->fetch_sub(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_and_explicit(__atomic_base<_ITp>* __a,
         __atomic_val_t<_ITp> __i,
         memory_order __m) noexcept
    { return __a->fetch_and(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_and_explicit(volatile __atomic_base<_ITp>* __a,
         __atomic_val_t<_ITp> __i,
         memory_order __m) noexcept
    { return __a->fetch_and(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_or_explicit(__atomic_base<_ITp>* __a,
        __atomic_val_t<_ITp> __i,
        memory_order __m) noexcept
    { return __a->fetch_or(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_or_explicit(volatile __atomic_base<_ITp>* __a,
        __atomic_val_t<_ITp> __i,
        memory_order __m) noexcept
    { return __a->fetch_or(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_xor_explicit(__atomic_base<_ITp>* __a,
         __atomic_val_t<_ITp> __i,
         memory_order __m) noexcept
    { return __a->fetch_xor(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_xor_explicit(volatile __atomic_base<_ITp>* __a,
         __atomic_val_t<_ITp> __i,
         memory_order __m) noexcept
    { return __a->fetch_xor(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_add(atomic<_ITp>* __a,
       __atomic_diff_t<_ITp> __i) noexcept
    { return atomic_fetch_add_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_add(volatile atomic<_ITp>* __a,
       __atomic_diff_t<_ITp> __i) noexcept
    { return atomic_fetch_add_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_sub(atomic<_ITp>* __a,
       __atomic_diff_t<_ITp> __i) noexcept
    { return atomic_fetch_sub_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_sub(volatile atomic<_ITp>* __a,
       __atomic_diff_t<_ITp> __i) noexcept
    { return atomic_fetch_sub_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_and(__atomic_base<_ITp>* __a,
       __atomic_val_t<_ITp> __i) noexcept
    { return atomic_fetch_and_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_and(volatile __atomic_base<_ITp>* __a,
       __atomic_val_t<_ITp> __i) noexcept
    { return atomic_fetch_and_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_or(__atomic_base<_ITp>* __a,
      __atomic_val_t<_ITp> __i) noexcept
    { return atomic_fetch_or_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_or(volatile __atomic_base<_ITp>* __a,
      __atomic_val_t<_ITp> __i) noexcept
    { return atomic_fetch_or_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_xor(__atomic_base<_ITp>* __a,
       __atomic_val_t<_ITp> __i) noexcept
    { return atomic_fetch_xor_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_xor(volatile __atomic_base<_ITp>* __a,
       __atomic_val_t<_ITp> __i) noexcept
    { return atomic_fetch_xor_explicit(__a, __i, memory_order_seq_cst); }


  template<>
    struct atomic<float> : __atomic_float<float>
    {
      atomic() noexcept = default;

      constexpr
      atomic(float __fp) noexcept : __atomic_float<float>(__fp)
      { }

      atomic& operator=(const atomic&) volatile = delete;
      atomic& operator=(const atomic&) = delete;

      using __atomic_float<float>::operator=;
    };

  template<>
    struct atomic<double> : __atomic_float<double>
    {
      atomic() noexcept = default;

      constexpr
      atomic(double __fp) noexcept : __atomic_float<double>(__fp)
      { }

      atomic& operator=(const atomic&) volatile = delete;
      atomic& operator=(const atomic&) = delete;

      using __atomic_float<double>::operator=;
    };

  template<>
    struct atomic<long double> : __atomic_float<long double>
    {
      atomic() noexcept = default;

      constexpr
      atomic(long double __fp) noexcept : __atomic_float<long double>(__fp)
      { }

      atomic& operator=(const atomic&) volatile = delete;
      atomic& operator=(const atomic&) = delete;

      using __atomic_float<long double>::operator=;
    };
# 1761 "C:/msys64/mingw64/include/c++/15.2.0/atomic" 3
  template<typename _Tp>
    struct atomic_ref : __atomic_ref<_Tp>
    {
      explicit
      atomic_ref(_Tp& __t) noexcept : __atomic_ref<_Tp>(__t)
      { }

      atomic_ref& operator=(const atomic_ref&) = delete;

      atomic_ref(const atomic_ref&) = default;

      using __atomic_ref<_Tp>::operator=;
    };
# 1783 "C:/msys64/mingw64/include/c++/15.2.0/atomic" 3
  using atomic_signed_lock_free = atomic<signed int>;
  using atomic_unsigned_lock_free = atomic<unsigned int>;
# 1798 "C:/msys64/mingw64/include/c++/15.2.0/atomic" 3

}
# 3205 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 2
# 3314 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"

# 3314 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
static const uint8_t VMA_ALLOCATION_FILL_PATTERN_CREATED = 0xDC;
static const uint8_t VMA_ALLOCATION_FILL_PATTERN_DESTROYED = 0xEF;

static const uint32_t VMA_CORRUPTION_DETECTION_MAGIC_VALUE = 0x7F84E666;


static const uint32_t VK_MEMORY_PROPERTY_DEVICE_COHERENT_BIT_AMD_COPY = 0x00000040;
static const uint32_t VK_MEMORY_PROPERTY_DEVICE_UNCACHED_BIT_AMD_COPY = 0x00000080;
static const uint32_t VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT_COPY = 0x00020000;
static const uint32_t VK_IMAGE_CREATE_DISJOINT_BIT_COPY = 0x00000200;
static const int32_t VK_IMAGE_TILING_DRM_FORMAT_MODIFIER_EXT_COPY = 1000158000;
static const uint32_t VMA_ALLOCATION_INTERNAL_STRATEGY_MIN_OFFSET = 0x10000000u;
static const uint32_t VMA_ALLOCATION_TRY_COUNT = 32;
static const uint32_t VMA_VENDOR_ID_AMD = 4098;
# 3337 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
static const char* VMA_SUBALLOCATION_TYPE_NAMES[] =
{
    "FREE",
    "UNKNOWN",
    "BUFFER",
    "IMAGE_UNKNOWN",
    "IMAGE_LINEAR",
    "IMAGE_OPTIMAL",
};


static VkAllocationCallbacks VmaEmptyAllocationCallbacks =
    { nullptr, nullptr, nullptr, nullptr, nullptr, nullptr };




enum VmaSuballocationType
{
    VMA_SUBALLOCATION_TYPE_FREE = 0,
    VMA_SUBALLOCATION_TYPE_UNKNOWN = 1,
    VMA_SUBALLOCATION_TYPE_BUFFER = 2,
    VMA_SUBALLOCATION_TYPE_IMAGE_UNKNOWN = 3,
    VMA_SUBALLOCATION_TYPE_IMAGE_LINEAR = 4,
    VMA_SUBALLOCATION_TYPE_IMAGE_OPTIMAL = 5,
    VMA_SUBALLOCATION_TYPE_MAX_ENUM = 0x7FFFFFFF
};

enum VMA_CACHE_OPERATION
{
    VMA_CACHE_FLUSH,
    VMA_CACHE_INVALIDATE
};

enum class VmaAllocationRequestType
{
    Normal,
    TLSF,

    UpperAddress,
    EndOf1st,
    EndOf2nd,
};






# 3385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
typedef struct 
# 3385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
VmaAllocHandle_T 
# 3385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
*
# 3385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
VmaAllocHandle
# 3385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
;
# 3385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                ;

struct VmaMutexLock;
struct VmaMutexLockRead;
struct VmaMutexLockWrite;

template<typename T>
struct AtomicTransactionalIncrement;

template<typename T>
struct VmaStlAllocator;

template<typename T, typename AllocatorT>
class VmaVector;

template<typename T, typename AllocatorT, size_t N>
class VmaSmallVector;

template<typename T>
class VmaPoolAllocator;

template<typename T>
struct VmaListItem;

template<typename T>
class VmaRawList;

template<typename T, typename AllocatorT>
class VmaList;

template<typename ItemTypeTraits>
class VmaIntrusiveLinkedList;


class VmaStringBuilder;
class VmaJsonWriter;


class VmaDeviceMemoryBlock;

struct VmaDedicatedAllocationListItemTraits;
class VmaDedicatedAllocationList;

struct VmaSuballocation;
struct VmaSuballocationOffsetLess;
struct VmaSuballocationOffsetGreater;
struct VmaSuballocationItemSizeLess;

typedef VmaList<VmaSuballocation, VmaStlAllocator<VmaSuballocation>> VmaSuballocationList;

struct VmaAllocationRequest;

class VmaBlockMetadata;
class VmaBlockMetadata_Linear;
class VmaBlockMetadata_TLSF;

class VmaBlockVector;

struct VmaPoolListItemTraits;

struct VmaCurrentBudgetData;

class VmaAllocationObjectAllocator;
# 3467 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
static inline uint32_t VmaCountBitsSet(uint32_t v)
{

    return std::popcount(v);
# 3479 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
}

static inline uint8_t VmaBitScanLSB(uint64_t mask)
{






    if(mask)
        return static_cast<uint8_t>(std::countr_zero(mask));
    return 
# 3491 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
          255
# 3491 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                   ;
# 3505 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
}

static inline uint8_t VmaBitScanLSB(uint32_t mask)
{






    if(mask)
        return static_cast<uint8_t>(std::countr_zero(mask));
    return 
# 3517 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
          255
# 3517 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                   ;
# 3531 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
}

static inline uint8_t VmaBitScanMSB(uint64_t mask)
{





    if(mask)
        return 63 - static_cast<uint8_t>(std::countl_zero(mask));
# 3555 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    return 
# 3555 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
          255
# 3555 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                   ;
}

static inline uint8_t VmaBitScanMSB(uint32_t mask)
{





    if(mask)
        return 31 - static_cast<uint8_t>(std::countl_zero(mask));
# 3580 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    return 
# 3580 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
          255
# 3580 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                   ;
}






template <typename T>
inline bool VmaIsPow2(T x)
{
    return (x & (x - 1)) == 0;
}



template <typename T>
static inline T VmaAlignUp(T val, T alignment)
{
    ;
    return (val + alignment - 1) & ~(alignment - 1);
}



template <typename T>
static inline T VmaAlignDown(T val, T alignment)
{
    ;
    return val & ~(alignment - 1);
}


template <typename T>
static inline T VmaRoundDiv(T x, T y)
{
    return (x + (y / (T)2)) / y;
}


template <typename T>
static inline T VmaDivideRoundingUp(T x, T y)
{
    return (x + y - (T)1) / y;
}


static inline uint32_t VmaNextPow2(uint32_t v)
{
    v--;
    v |= v >> 1;
    v |= v >> 2;
    v |= v >> 4;
    v |= v >> 8;
    v |= v >> 16;
    v++;
    return v;
}

static inline uint64_t VmaNextPow2(uint64_t v)
{
    v--;
    v |= v >> 1;
    v |= v >> 2;
    v |= v >> 4;
    v |= v >> 8;
    v |= v >> 16;
    v |= v >> 32;
    v++;
    return v;
}


static inline uint32_t VmaPrevPow2(uint32_t v)
{
    v |= v >> 1;
    v |= v >> 2;
    v |= v >> 4;
    v |= v >> 8;
    v |= v >> 16;
    v = v ^ (v >> 1);
    return v;
}

static inline uint64_t VmaPrevPow2(uint64_t v)
{
    v |= v >> 1;
    v |= v >> 2;
    v |= v >> 4;
    v |= v >> 8;
    v |= v >> 16;
    v |= v >> 32;
    v = v ^ (v >> 1);
    return v;
}

static inline bool VmaStrIsEmpty(const char* pStr)
{
    return pStr == nullptr || *pStr == '\0';
}
# 3688 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
static inline bool VmaBlocksOnSamePage(
    VkDeviceSize resourceAOffset,
    VkDeviceSize resourceASize,
    VkDeviceSize resourceBOffset,
    VkDeviceSize pageSize)
{
    
# 3694 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 3694 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   resourceAOffset + resourceASize <= resourceBOffset && resourceASize > 0 && pageSize > 0
# 3694 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 3694 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "resourceAOffset + resourceASize <= resourceBOffset && resourceASize > 0 && pageSize > 0"
# 3694 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",3694),0))
# 3694 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                      ;
    VkDeviceSize resourceAEnd = resourceAOffset + resourceASize - 1;
    VkDeviceSize resourceAEndPage = resourceAEnd & ~(pageSize - 1);
    VkDeviceSize resourceBStart = resourceBOffset;
    VkDeviceSize resourceBStartPage = resourceBStart & ~(pageSize - 1);
    return resourceAEndPage == resourceBStartPage;
}







static inline bool VmaIsBufferImageGranularityConflict(
    VmaSuballocationType suballocType1,
    VmaSuballocationType suballocType2)
{
    if (suballocType1 > suballocType2)
    {
        std::swap(suballocType1, suballocType2);
    }

    switch (suballocType1)
    {
    case VMA_SUBALLOCATION_TYPE_FREE:
        return false;
    case VMA_SUBALLOCATION_TYPE_UNKNOWN:
        return true;
    case VMA_SUBALLOCATION_TYPE_BUFFER:
        return
            suballocType2 == VMA_SUBALLOCATION_TYPE_IMAGE_UNKNOWN ||
            suballocType2 == VMA_SUBALLOCATION_TYPE_IMAGE_OPTIMAL;
    case VMA_SUBALLOCATION_TYPE_IMAGE_UNKNOWN:
        return
            suballocType2 == VMA_SUBALLOCATION_TYPE_IMAGE_UNKNOWN ||
            suballocType2 == VMA_SUBALLOCATION_TYPE_IMAGE_LINEAR ||
            suballocType2 == VMA_SUBALLOCATION_TYPE_IMAGE_OPTIMAL;
    case VMA_SUBALLOCATION_TYPE_IMAGE_LINEAR:
        return
            suballocType2 == VMA_SUBALLOCATION_TYPE_IMAGE_OPTIMAL;
    case VMA_SUBALLOCATION_TYPE_IMAGE_OPTIMAL:
        return false;
    default:
        
# 3738 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 3738 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0
# 3738 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 3738 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0"
# 3738 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",3738),0))
# 3738 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                    ;
        return true;
    }
}

static void VmaWriteMagicValue(void* pData, VkDeviceSize offset)
{
# 3755 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
}

static bool VmaValidateMagicValue(const void* pData, VkDeviceSize offset)
{
# 3770 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    return true;
}





static void VmaFillGpuDefragmentationBufferCreateInfo(VkBufferCreateInfo& outBufCreateInfo)
{
    memset(&outBufCreateInfo, 0, sizeof(outBufCreateInfo));
    outBufCreateInfo.sType = VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO;
    outBufCreateInfo.usage = VK_BUFFER_USAGE_TRANSFER_SRC_BIT | VK_BUFFER_USAGE_TRANSFER_DST_BIT;
    outBufCreateInfo.size = (VkDeviceSize)(256ull * 1024 * 1024);
}
# 3795 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
template <typename CmpLess, typename IterT, typename KeyT>
static IterT VmaBinaryFindFirstNotLess(IterT beg, IterT end, const KeyT& key, const CmpLess& cmp)
{
    size_t down = 0, up = size_t(end - beg);
    while (down < up)
    {
        const size_t mid = down + (up - down) / 2;
        if (cmp(*(beg + mid), key))
        {
            down = mid + 1;
        }
        else
        {
            up = mid;
        }
    }
    return beg + down;
}

template<typename CmpLess, typename IterT, typename KeyT>
IterT VmaBinaryFindSorted(const IterT& beg, const IterT& end, const KeyT& value, const CmpLess& cmp)
{
    IterT it = VmaBinaryFindFirstNotLess<CmpLess, IterT, KeyT>(
        beg, end, value, cmp);
    if (it == end ||
        (!cmp(*it, value) && !cmp(value, *it)))
    {
        return it;
    }
    return end;
}






template<typename T>
static bool VmaValidatePointerArray(uint32_t count, const T* arr)
{
    for (uint32_t i = 0; i < count; ++i)
    {
        const T iPtr = arr[i];
        if (iPtr == nullptr)
        {
            return false;
        }
        for (uint32_t j = i + 1; j < count; ++j)
        {
            if (iPtr == arr[j])
            {
                return false;
            }
        }
    }
    return true;
}

template<typename MainT, typename NewT>
static inline void VmaPnextChainPushFront(MainT* mainStruct, NewT* newStruct)
{
    newStruct->pNext = mainStruct->pNext;
    mainStruct->pNext = newStruct;
}


template<typename FindT, typename MainT>
static inline const FindT* VmaPnextChainFind(const MainT* mainStruct, VkStructureType sType)
{
    for(const VkBaseInStructure* s = (const VkBaseInStructure*)mainStruct->pNext;
        s != nullptr; s = s->pNext)
    {
        if(s->sType == sType)
        {
            return (const FindT*)s;
        }
    }
    return nullptr;
}


struct VmaBufferImageUsage
{

    typedef uint64_t BaseType;




    static const VmaBufferImageUsage UNKNOWN;

    BaseType Value;

    VmaBufferImageUsage() { *this = UNKNOWN; }
    explicit VmaBufferImageUsage(BaseType usage) : Value(usage) { }
    VmaBufferImageUsage(const VkBufferCreateInfo &createInfo, bool useKhrMaintenance5);
    explicit VmaBufferImageUsage(const VkImageCreateInfo &createInfo);

    bool operator==(const VmaBufferImageUsage& rhs) const { return Value == rhs.Value; }
    bool operator!=(const VmaBufferImageUsage& rhs) const { return Value != rhs.Value; }

    bool Contains(BaseType flag) const { return (Value & flag) != 0; }
    bool ContainsDeviceAccess() const
    {

        return (Value & ~BaseType(VK_BUFFER_USAGE_TRANSFER_DST_BIT | VK_BUFFER_USAGE_TRANSFER_SRC_BIT)) != 0;
    }
};

const VmaBufferImageUsage VmaBufferImageUsage::UNKNOWN = VmaBufferImageUsage(0);

VmaBufferImageUsage::VmaBufferImageUsage(const VkBufferCreateInfo &createInfo,
    bool useKhrMaintenance5)
{

    if(useKhrMaintenance5)
    {



        const VkBufferUsageFlags2CreateInfoKHR* const usageFlags2 =
            VmaPnextChainFind<VkBufferUsageFlags2CreateInfoKHR>(&createInfo, VK_STRUCTURE_TYPE_BUFFER_USAGE_FLAGS_2_CREATE_INFO_KHR);
        if(usageFlags2)
        {
            this->Value = usageFlags2->usage;
            return;
        }
    }


    this->Value = (BaseType)createInfo.usage;
}

VmaBufferImageUsage::VmaBufferImageUsage(const VkImageCreateInfo &createInfo)
{



    this->Value = (BaseType)createInfo.usage;
}



static bool FindMemoryPreferences(
    bool isIntegratedGPU,
    const VmaAllocationCreateInfo& allocCreateInfo,
    VmaBufferImageUsage bufImgUsage,
    VkMemoryPropertyFlags& outRequiredFlags,
    VkMemoryPropertyFlags& outPreferredFlags,
    VkMemoryPropertyFlags& outNotPreferredFlags)
{
    outRequiredFlags = allocCreateInfo.requiredFlags;
    outPreferredFlags = allocCreateInfo.preferredFlags;
    outNotPreferredFlags = 0;

    switch(allocCreateInfo.usage)
    {
    case VMA_MEMORY_USAGE_UNKNOWN:
        break;
    case VMA_MEMORY_USAGE_GPU_ONLY:
        if(!isIntegratedGPU || (outPreferredFlags & VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT) == 0)
        {
            outPreferredFlags |= VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT;
        }
        break;
    case VMA_MEMORY_USAGE_CPU_ONLY:
        outRequiredFlags |= VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT;
        break;
    case VMA_MEMORY_USAGE_CPU_TO_GPU:
        outRequiredFlags |= VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT;
        if(!isIntegratedGPU || (outPreferredFlags & VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT) == 0)
        {
            outPreferredFlags |= VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT;
        }
        break;
    case VMA_MEMORY_USAGE_GPU_TO_CPU:
        outRequiredFlags |= VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT;
        outPreferredFlags |= VK_MEMORY_PROPERTY_HOST_CACHED_BIT;
        break;
    case VMA_MEMORY_USAGE_CPU_COPY:
        outNotPreferredFlags |= VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT;
        break;
    case VMA_MEMORY_USAGE_GPU_LAZILY_ALLOCATED:
        outRequiredFlags |= VK_MEMORY_PROPERTY_LAZILY_ALLOCATED_BIT;
        break;
    case VMA_MEMORY_USAGE_AUTO:
    case VMA_MEMORY_USAGE_AUTO_PREFER_DEVICE:
    case VMA_MEMORY_USAGE_AUTO_PREFER_HOST:
    {
        if(bufImgUsage == VmaBufferImageUsage::UNKNOWN)
        {
            
# 3986 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 3986 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0 && "VMA_MEMORY_USAGE_AUTO* values can only be used with functions like vmaCreateBuffer, vmaCreateImage so that the details of the created resource are known." " Maybe you use VkBufferUsageFlags2CreateInfoKHR but forgot to use VMA_ALLOCATOR_CREATE_KHR_MAINTENANCE5_BIT?"
# 3986 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 3986 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0 && \"VMA_MEMORY_USAGE_AUTO* values can only be used with functions like vmaCreateBuffer, vmaCreateImage so that the details of the created resource are known.\" \" Maybe you use VkBufferUsageFlags2CreateInfoKHR but forgot to use VMA_ALLOCATOR_CREATE_KHR_MAINTENANCE5_BIT?\""
# 3986 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",3986),0))
                                                                                                                                
# 3987 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                               ;
            return false;
        }

        const bool deviceAccess = bufImgUsage.ContainsDeviceAccess();
        const bool hostAccessSequentialWrite = (allocCreateInfo.flags & VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT) != 0;
        const bool hostAccessRandom = (allocCreateInfo.flags & VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT) != 0;
        const bool hostAccessAllowTransferInstead = (allocCreateInfo.flags & VMA_ALLOCATION_CREATE_HOST_ACCESS_ALLOW_TRANSFER_INSTEAD_BIT) != 0;
        const bool preferDevice = allocCreateInfo.usage == VMA_MEMORY_USAGE_AUTO_PREFER_DEVICE;
        const bool preferHost = allocCreateInfo.usage == VMA_MEMORY_USAGE_AUTO_PREFER_HOST;


        if(hostAccessRandom)
        {

            outPreferredFlags |= VK_MEMORY_PROPERTY_HOST_CACHED_BIT;

            if (!isIntegratedGPU && deviceAccess && hostAccessAllowTransferInstead && !preferHost)
            {




                outPreferredFlags |= VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT;
            }
            else
            {

                outRequiredFlags |= VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT;
            }
        }

        else if(hostAccessSequentialWrite)
        {

            outNotPreferredFlags |= VK_MEMORY_PROPERTY_HOST_CACHED_BIT;

            if(!isIntegratedGPU && deviceAccess && hostAccessAllowTransferInstead && !preferHost)
            {
                outPreferredFlags |= VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT | VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT;
            }
            else
            {
                outRequiredFlags |= VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT;

                if(deviceAccess)
                {

                    if(preferHost)
                        outNotPreferredFlags |= VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT;
                    else
                        outPreferredFlags |= VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT;
                }

                else
                {

                    if(preferDevice)
                        outPreferredFlags |= VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT;
                    else
                        outNotPreferredFlags |= VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT;
                }
            }
        }

        else
        {
# 4066 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
            if(preferHost)
                outNotPreferredFlags |= VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT;
            else
                outPreferredFlags |= VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT;
        }
        break;
    }
    default:
        
# 4074 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 4074 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0
# 4074 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 4074 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0"
# 4074 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",4074),0))
# 4074 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                    ;
    }


    if(((allocCreateInfo.requiredFlags | allocCreateInfo.preferredFlags) &
        (VK_MEMORY_PROPERTY_DEVICE_COHERENT_BIT_AMD_COPY | VK_MEMORY_PROPERTY_DEVICE_UNCACHED_BIT_AMD_COPY)) == 0)
    {
        outNotPreferredFlags |= VK_MEMORY_PROPERTY_DEVICE_UNCACHED_BIT_AMD_COPY;
    }

    return true;
}




static void* VmaMalloc(const VkAllocationCallbacks* pAllocationCallbacks, size_t size, size_t alignment)
{
    void* result = nullptr;
    if ((pAllocationCallbacks != nullptr) &&
        (pAllocationCallbacks->pfnAllocation != nullptr))
    {
        result = (*pAllocationCallbacks->pfnAllocation)(
            pAllocationCallbacks->pUserData,
            size,
            alignment,
            VK_SYSTEM_ALLOCATION_SCOPE_OBJECT);
    }
    else
    {
        result = vma_aligned_alloc((alignment), (size));
    }
    
# 4106 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 4106 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   result != nullptr && "CPU memory allocation failed."
# 4106 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 4106 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "result != nullptr && \"CPU memory allocation failed.\""
# 4106 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",4106),0))
# 4106 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                    ;
    return result;
}

static void VmaFree(const VkAllocationCallbacks* pAllocationCallbacks, void* ptr)
{
    if ((pAllocationCallbacks != nullptr) &&
        (pAllocationCallbacks->pfnFree != nullptr))
    {
        (*pAllocationCallbacks->pfnFree)(pAllocationCallbacks->pUserData, ptr);
    }
    else
    {
        vma_aligned_free(ptr);
    }
}

template<typename T>
static T* VmaAllocate(const VkAllocationCallbacks* pAllocationCallbacks)
{
    return (T*)VmaMalloc(pAllocationCallbacks, sizeof(T), (alignof(T)));
}

template<typename T>
static T* VmaAllocateArray(const VkAllocationCallbacks* pAllocationCallbacks, size_t count)
{
    return (T*)VmaMalloc(pAllocationCallbacks, sizeof(T) * count, (alignof(T)));
}





template<typename T>
static void vma_delete(const VkAllocationCallbacks* pAllocationCallbacks, T* ptr)
{
    ptr->~T();
    VmaFree(pAllocationCallbacks, ptr);
}

template<typename T>
static void vma_delete_array(const VkAllocationCallbacks* pAllocationCallbacks, T* ptr, size_t count)
{
    if (ptr != nullptr)
    {
        for (size_t i = count; i--; )
        {
            ptr[i].~T();
        }
        VmaFree(pAllocationCallbacks, ptr);
    }
}

static char* VmaCreateStringCopy(const VkAllocationCallbacks* allocs, const char* srcStr)
{
    if (srcStr != nullptr)
    {
        const size_t len = strlen(srcStr);
        char* const result = new(VmaAllocateArray<char>((allocs), (len + 1)))(char);
        memcpy(result, srcStr, len + 1);
        return result;
    }
    return nullptr;
}


static char* VmaCreateStringCopy(const VkAllocationCallbacks* allocs, const char* srcStr, size_t strLen)
{
    if (srcStr != nullptr)
    {
        char* const result = new(VmaAllocateArray<char>((allocs), (strLen + 1)))(char);
        memcpy(result, srcStr, strLen);
        result[strLen] = '\0';
        return result;
    }
    return nullptr;
}


static void VmaFreeString(const VkAllocationCallbacks* allocs, char* str)
{
    if (str != nullptr)
    {
        const size_t len = strlen(str);
        vma_delete_array(allocs, str, len + 1);
    }
}

template<typename CmpLess, typename VectorT>
size_t VmaVectorInsertSorted(VectorT& vector, const typename VectorT::value_type& value)
{
    const size_t indexToInsert = VmaBinaryFindFirstNotLess(
        vector.data(),
        vector.data() + vector.size(),
        value,
        CmpLess()) - vector.data();
    VmaVectorInsert(vector, indexToInsert, value);
    return indexToInsert;
}

template<typename CmpLess, typename VectorT>
bool VmaVectorRemoveSorted(VectorT& vector, const typename VectorT::value_type& value)
{
    CmpLess comparator;
    typename VectorT::iterator it = VmaBinaryFindFirstNotLess(
        vector.begin(),
        vector.end(),
        value,
        comparator);
    if ((it != vector.end()) && !comparator(*it, value) && !comparator(value, *it))
    {
        size_t indexToRemove = it - vector.begin();
        VmaVectorRemove(vector, indexToRemove);
        return true;
    }
    return false;
}




static void VmaClearStatistics(VmaStatistics& outStats)
{
    outStats.blockCount = 0;
    outStats.allocationCount = 0;
    outStats.blockBytes = 0;
    outStats.allocationBytes = 0;
}

static void VmaAddStatistics(VmaStatistics& inoutStats, const VmaStatistics& src)
{
    inoutStats.blockCount += src.blockCount;
    inoutStats.allocationCount += src.allocationCount;
    inoutStats.blockBytes += src.blockBytes;
    inoutStats.allocationBytes += src.allocationBytes;
}

static void VmaClearDetailedStatistics(VmaDetailedStatistics& outStats)
{
    VmaClearStatistics(outStats.statistics);
    outStats.unusedRangeCount = 0;
    outStats.allocationSizeMin = 
# 4247 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                (~0ULL)
# 4247 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                             ;
    outStats.allocationSizeMax = 0;
    outStats.unusedRangeSizeMin = 
# 4249 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                 (~0ULL)
# 4249 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                              ;
    outStats.unusedRangeSizeMax = 0;
}

static void VmaAddDetailedStatisticsAllocation(VmaDetailedStatistics& inoutStats, VkDeviceSize size)
{
    inoutStats.statistics.allocationCount++;
    inoutStats.statistics.allocationBytes += size;
    inoutStats.allocationSizeMin = ((std::min)((inoutStats.allocationSizeMin), (size)));
    inoutStats.allocationSizeMax = ((std::max)((inoutStats.allocationSizeMax), (size)));
}

static void VmaAddDetailedStatisticsUnusedRange(VmaDetailedStatistics& inoutStats, VkDeviceSize size)
{
    inoutStats.unusedRangeCount++;
    inoutStats.unusedRangeSizeMin = ((std::min)((inoutStats.unusedRangeSizeMin), (size)));
    inoutStats.unusedRangeSizeMax = ((std::max)((inoutStats.unusedRangeSizeMax), (size)));
}

static void VmaAddDetailedStatistics(VmaDetailedStatistics& inoutStats, const VmaDetailedStatistics& src)
{
    VmaAddStatistics(inoutStats.statistics, src.statistics);
    inoutStats.unusedRangeCount += src.unusedRangeCount;
    inoutStats.allocationSizeMin = ((std::min)((inoutStats.allocationSizeMin), (src.allocationSizeMin)));
    inoutStats.allocationSizeMax = ((std::max)((inoutStats.allocationSizeMax), (src.allocationSizeMax)));
    inoutStats.unusedRangeSizeMin = ((std::min)((inoutStats.unusedRangeSizeMin), (src.unusedRangeSizeMin)));
    inoutStats.unusedRangeSizeMax = ((std::max)((inoutStats.unusedRangeSizeMax), (src.unusedRangeSizeMax)));
}





struct VmaMutexLock
{
    private: VmaMutexLock(const VmaMutexLock&) = delete; VmaMutexLock(VmaMutexLock&&) = delete; VmaMutexLock& operator=(const VmaMutexLock&) = delete; VmaMutexLock& operator=(VmaMutexLock&&) = delete;
public:
    VmaMutexLock(VmaMutex& mutex, bool useMutex = true) :
        m_pMutex(useMutex ? &mutex : nullptr)
    {
        if (m_pMutex) { m_pMutex->Lock(); }
    }
    ~VmaMutexLock() { if (m_pMutex) { m_pMutex->Unlock(); } }

private:
    VmaMutex* m_pMutex;
};


struct VmaMutexLockRead
{
    private: VmaMutexLockRead(const VmaMutexLockRead&) = delete; VmaMutexLockRead(VmaMutexLockRead&&) = delete; VmaMutexLockRead& operator=(const VmaMutexLockRead&) = delete; VmaMutexLockRead& operator=(VmaMutexLockRead&&) = delete;
public:
    VmaMutexLockRead(VmaRWMutex& mutex, bool useMutex) :
        m_pMutex(useMutex ? &mutex : nullptr)
    {
        if (m_pMutex) { m_pMutex->LockRead(); }
    }
    ~VmaMutexLockRead() { if (m_pMutex) { m_pMutex->UnlockRead(); } }

private:
    VmaRWMutex* m_pMutex;
};


struct VmaMutexLockWrite
{
    private: VmaMutexLockWrite(const VmaMutexLockWrite&) = delete; VmaMutexLockWrite(VmaMutexLockWrite&&) = delete; VmaMutexLockWrite& operator=(const VmaMutexLockWrite&) = delete; VmaMutexLockWrite& operator=(VmaMutexLockWrite&&) = delete;
public:
    VmaMutexLockWrite(VmaRWMutex& mutex, bool useMutex)
        : m_pMutex(useMutex ? &mutex : nullptr)
    {
        if (m_pMutex) { m_pMutex->LockWrite(); }
    }
    ~VmaMutexLockWrite() { if (m_pMutex) { m_pMutex->UnlockWrite(); } }

private:
    VmaRWMutex* m_pMutex;
};
# 4339 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
template<typename AtomicT>
struct AtomicTransactionalIncrement
{
public:
    using T = decltype(AtomicT().load());

    ~AtomicTransactionalIncrement()
    {
        if(m_Atomic)
            --(*m_Atomic);
    }

    void Commit() { m_Atomic = nullptr; }
    T Increment(AtomicT* atomic)
    {
        m_Atomic = atomic;
        return m_Atomic->fetch_add(1);
    }

private:
    AtomicT* m_Atomic = nullptr;
};




template<typename T>
struct VmaStlAllocator
{
    const VkAllocationCallbacks* const m_pCallbacks;
    typedef T value_type;

    VmaStlAllocator(const VkAllocationCallbacks* pCallbacks) : m_pCallbacks(pCallbacks) {}
    template<typename U>
    VmaStlAllocator(const VmaStlAllocator<U>& src) : m_pCallbacks(src.m_pCallbacks) {}
    VmaStlAllocator(const VmaStlAllocator&) = default;
    VmaStlAllocator& operator=(const VmaStlAllocator&) = delete;

    T* allocate(size_t n) { return VmaAllocateArray<T>(m_pCallbacks, n); }
    void deallocate(T* p, size_t n) { VmaFree(m_pCallbacks, p); }

    template<typename U>
    bool operator==(const VmaStlAllocator<U>& rhs) const
    {
        return m_pCallbacks == rhs.m_pCallbacks;
    }
    template<typename U>
    bool operator!=(const VmaStlAllocator<U>& rhs) const
    {
        return m_pCallbacks != rhs.m_pCallbacks;
    }
};






template<typename T, typename AllocatorT>
class VmaVector
{
public:
    typedef T value_type;
    typedef T* iterator;
    typedef const T* const_iterator;

    VmaVector(const AllocatorT& allocator);
    VmaVector(size_t count, const AllocatorT& allocator);


    VmaVector(size_t count, const T& value, const AllocatorT& allocator) : VmaVector(count, allocator) {}
    VmaVector(const VmaVector<T, AllocatorT>& src);
    VmaVector& operator=(const VmaVector& rhs);
    ~VmaVector() { VmaFree(m_Allocator.m_pCallbacks, m_pArray); }

    bool empty() const { return m_Count == 0; }
    size_t size() const { return m_Count; }
    T* data() { return m_pArray; }
    T& front() { ; return m_pArray[0]; }
    T& back() { ; return m_pArray[m_Count - 1]; }
    const T* data() const { return m_pArray; }
    const T& front() const { ; return m_pArray[0]; }
    const T& back() const { ; return m_pArray[m_Count - 1]; }

    iterator begin() { return m_pArray; }
    iterator end() { return m_pArray + m_Count; }
    const_iterator cbegin() const { return m_pArray; }
    const_iterator cend() const { return m_pArray + m_Count; }
    const_iterator begin() const { return cbegin(); }
    const_iterator end() const { return cend(); }

    void pop_front() { ; remove(0); }
    void pop_back() { ; resize(size() - 1); }
    void push_front(const T& src) { insert(0, src); }

    void push_back(const T& src);
    void reserve(size_t newCapacity, bool freeMemory = false);
    void resize(size_t newCount);
    void clear() { resize(0); }
    void shrink_to_fit();
    void insert(size_t index, const T& src);
    void remove(size_t index);

    T& operator[](size_t index) { ; return m_pArray[index]; }
    const T& operator[](size_t index) const { ; return m_pArray[index]; }

private:
    AllocatorT m_Allocator;
    T* m_pArray;
    size_t m_Count;
    size_t m_Capacity;
};


template<typename T, typename AllocatorT>
VmaVector<T, AllocatorT>::VmaVector(const AllocatorT& allocator)
    : m_Allocator(allocator),
    m_pArray(nullptr),
    m_Count(0),
    m_Capacity(0) {}

template<typename T, typename AllocatorT>
VmaVector<T, AllocatorT>::VmaVector(size_t count, const AllocatorT& allocator)
    : m_Allocator(allocator),
    m_pArray(count ? (T*)VmaAllocateArray<T>(allocator.m_pCallbacks, count) : nullptr),
    m_Count(count),
    m_Capacity(count) {}

template<typename T, typename AllocatorT>
VmaVector<T, AllocatorT>::VmaVector(const VmaVector& src)
    : m_Allocator(src.m_Allocator),
    m_pArray(src.m_Count ? (T*)VmaAllocateArray<T>(src.m_Allocator.m_pCallbacks, src.m_Count) : nullptr),
    m_Count(src.m_Count),
    m_Capacity(src.m_Count)
{
    if (m_Count != 0)
    {
        memcpy(m_pArray, src.m_pArray, m_Count * sizeof(T));
    }
}

template<typename T, typename AllocatorT>
VmaVector<T, AllocatorT>& VmaVector<T, AllocatorT>::operator=(const VmaVector& rhs)
{
    if (&rhs != this)
    {
        resize(rhs.m_Count);
        if (m_Count != 0)
        {
            memcpy(m_pArray, rhs.m_pArray, m_Count * sizeof(T));
        }
    }
    return *this;
}

template<typename T, typename AllocatorT>
void VmaVector<T, AllocatorT>::push_back(const T& src)
{
    const size_t newIndex = size();
    resize(newIndex + 1);
    m_pArray[newIndex] = src;
}

template<typename T, typename AllocatorT>
void VmaVector<T, AllocatorT>::reserve(size_t newCapacity, bool freeMemory)
{
    newCapacity = ((std::max)((newCapacity), (m_Count)));

    if ((newCapacity < m_Capacity) && !freeMemory)
    {
        newCapacity = m_Capacity;
    }

    if (newCapacity != m_Capacity)
    {
        T* const newArray = newCapacity ? VmaAllocateArray<T>(m_Allocator, newCapacity) : nullptr;
        if (m_Count != 0)
        {
            memcpy(newArray, m_pArray, m_Count * sizeof(T));
        }
        VmaFree(m_Allocator.m_pCallbacks, m_pArray);
        m_Capacity = newCapacity;
        m_pArray = newArray;
    }
}

template<typename T, typename AllocatorT>
void VmaVector<T, AllocatorT>::resize(size_t newCount)
{
    size_t newCapacity = m_Capacity;
    if (newCount > m_Capacity)
    {
        newCapacity = ((std::max)((newCount), (((std::max)((m_Capacity * 3 / 2), ((size_t)8))))));
    }

    if (newCapacity != m_Capacity)
    {
        T* const newArray = newCapacity ? VmaAllocateArray<T>(m_Allocator.m_pCallbacks, newCapacity) : nullptr;
        const size_t elementsToCopy = ((std::min)((m_Count), (newCount)));
        if (elementsToCopy != 0)
        {
            memcpy(newArray, m_pArray, elementsToCopy * sizeof(T));
        }
        VmaFree(m_Allocator.m_pCallbacks, m_pArray);
        m_Capacity = newCapacity;
        m_pArray = newArray;
    }

    m_Count = newCount;
}

template<typename T, typename AllocatorT>
void VmaVector<T, AllocatorT>::shrink_to_fit()
{
    if (m_Capacity > m_Count)
    {
        T* newArray = nullptr;
        if (m_Count > 0)
        {
            newArray = VmaAllocateArray<T>(m_Allocator.m_pCallbacks, m_Count);
            memcpy(newArray, m_pArray, m_Count * sizeof(T));
        }
        VmaFree(m_Allocator.m_pCallbacks, m_pArray);
        m_Capacity = m_Count;
        m_pArray = newArray;
    }
}

template<typename T, typename AllocatorT>
void VmaVector<T, AllocatorT>::insert(size_t index, const T& src)
{
    ;
    const size_t oldCount = size();
    resize(oldCount + 1);
    if (index < oldCount)
    {
        memmove(m_pArray + (index + 1), m_pArray + index, (oldCount - index) * sizeof(T));
    }
    m_pArray[index] = src;
}

template<typename T, typename AllocatorT>
void VmaVector<T, AllocatorT>::remove(size_t index)
{
    ;
    const size_t oldCount = size();
    if (index < oldCount - 1)
    {
        memmove(m_pArray + index, m_pArray + (index + 1), (oldCount - index - 1) * sizeof(T));
    }
    resize(oldCount - 1);
}


template<typename T, typename allocatorT>
static void VmaVectorInsert(VmaVector<T, allocatorT>& vec, size_t index, const T& item)
{
    vec.insert(index, item);
}

template<typename T, typename allocatorT>
static void VmaVectorRemove(VmaVector<T, allocatorT>& vec, size_t index)
{
    vec.remove(index);
}
# 4614 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
template<typename T, typename AllocatorT, size_t N>
class VmaSmallVector
{
public:
    typedef T value_type;
    typedef T* iterator;

    VmaSmallVector(const AllocatorT& allocator);
    VmaSmallVector(size_t count, const AllocatorT& allocator);
    template<typename SrcT, typename SrcAllocatorT, size_t SrcN>
    VmaSmallVector(const VmaSmallVector<SrcT, SrcAllocatorT, SrcN>&) = delete;
    template<typename SrcT, typename SrcAllocatorT, size_t SrcN>
    VmaSmallVector<T, AllocatorT, N>& operator=(const VmaSmallVector<SrcT, SrcAllocatorT, SrcN>&) = delete;
    ~VmaSmallVector() = default;

    bool empty() const { return m_Count == 0; }
    size_t size() const { return m_Count; }
    T* data() { return m_Count > N ? m_DynamicArray.data() : m_StaticArray; }
    T& front() { ; return data()[0]; }
    T& back() { ; return data()[m_Count - 1]; }
    const T* data() const { return m_Count > N ? m_DynamicArray.data() : m_StaticArray; }
    const T& front() const { ; return data()[0]; }
    const T& back() const { ; return data()[m_Count - 1]; }

    iterator begin() { return data(); }
    iterator end() { return data() + m_Count; }

    void pop_front() { ; remove(0); }
    void pop_back() { ; resize(size() - 1); }
    void push_front(const T& src) { insert(0, src); }

    void push_back(const T& src);
    void resize(size_t newCount, bool freeMemory = false);
    void clear(bool freeMemory = false);
    void insert(size_t index, const T& src);
    void remove(size_t index);

    T& operator[](size_t index) { ; return data()[index]; }
    const T& operator[](size_t index) const { ; return data()[index]; }

private:
    size_t m_Count;
    T m_StaticArray[N];
    VmaVector<T, AllocatorT> m_DynamicArray;
};


template<typename T, typename AllocatorT, size_t N>
VmaSmallVector<T, AllocatorT, N>::VmaSmallVector(const AllocatorT& allocator)
    : m_Count(0),
    m_DynamicArray(allocator) {}

template<typename T, typename AllocatorT, size_t N>
VmaSmallVector<T, AllocatorT, N>::VmaSmallVector(size_t count, const AllocatorT& allocator)
    : m_Count(count),
    m_DynamicArray(count > N ? count : 0, allocator) {}

template<typename T, typename AllocatorT, size_t N>
void VmaSmallVector<T, AllocatorT, N>::push_back(const T& src)
{
    const size_t newIndex = size();
    resize(newIndex + 1);
    data()[newIndex] = src;
}

template<typename T, typename AllocatorT, size_t N>
void VmaSmallVector<T, AllocatorT, N>::resize(size_t newCount, bool freeMemory)
{
    if (newCount > N && m_Count > N)
    {

        m_DynamicArray.resize(newCount);
        if (freeMemory)
        {
            m_DynamicArray.shrink_to_fit();
        }
    }
    else if (newCount > N && m_Count <= N)
    {

        m_DynamicArray.resize(newCount);
        if (m_Count > 0)
        {
            memcpy(m_DynamicArray.data(), m_StaticArray, m_Count * sizeof(T));
        }
    }
    else if (newCount <= N && m_Count > N)
    {

        if (newCount > 0)
        {
            memcpy(m_StaticArray, m_DynamicArray.data(), newCount * sizeof(T));
        }
        m_DynamicArray.resize(0);
        if (freeMemory)
        {
            m_DynamicArray.shrink_to_fit();
        }
    }
    else
    {

    }
    m_Count = newCount;
}

template<typename T, typename AllocatorT, size_t N>
void VmaSmallVector<T, AllocatorT, N>::clear(bool freeMemory)
{
    m_DynamicArray.clear();
    if (freeMemory)
    {
        m_DynamicArray.shrink_to_fit();
    }
    m_Count = 0;
}

template<typename T, typename AllocatorT, size_t N>
void VmaSmallVector<T, AllocatorT, N>::insert(size_t index, const T& src)
{
    ;
    const size_t oldCount = size();
    resize(oldCount + 1);
    T* const dataPtr = data();
    if (index < oldCount)
    {

        memmove(dataPtr + (index + 1), dataPtr + index, (oldCount - index) * sizeof(T));
    }
    dataPtr[index] = src;
}

template<typename T, typename AllocatorT, size_t N>
void VmaSmallVector<T, AllocatorT, N>::remove(size_t index)
{
    ;
    const size_t oldCount = size();
    if (index < oldCount - 1)
    {

        T* const dataPtr = data();
        memmove(dataPtr + index, dataPtr + (index + 1), (oldCount - index - 1) * sizeof(T));
    }
    resize(oldCount - 1);
}
# 4768 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
template<typename T>
class VmaPoolAllocator
{
    private: VmaPoolAllocator(const VmaPoolAllocator&) = delete; VmaPoolAllocator(VmaPoolAllocator&&) = delete; VmaPoolAllocator& operator=(const VmaPoolAllocator&) = delete; VmaPoolAllocator& operator=(VmaPoolAllocator&&) = delete;
public:
    VmaPoolAllocator(const VkAllocationCallbacks* pAllocationCallbacks, uint32_t firstBlockCapacity);
    ~VmaPoolAllocator();
    template<typename... Types> T* Alloc(Types&&... args);
    void Free(T* ptr);

private:
    union Item
    {
        uint32_t NextFreeIndex;
        alignas(T) char Value[sizeof(T)];
    };
    struct ItemBlock
    {
        Item* pItems;
        uint32_t Capacity;
        uint32_t FirstFreeIndex;
    };

    const VkAllocationCallbacks* m_pAllocationCallbacks;
    const uint32_t m_FirstBlockCapacity;
    VmaVector<ItemBlock, VmaStlAllocator<ItemBlock>> m_ItemBlocks;

    ItemBlock& CreateNewBlock();
};


template<typename T>
VmaPoolAllocator<T>::VmaPoolAllocator(const VkAllocationCallbacks* pAllocationCallbacks, uint32_t firstBlockCapacity)
    : m_pAllocationCallbacks(pAllocationCallbacks),
    m_FirstBlockCapacity(firstBlockCapacity),
    m_ItemBlocks(VmaStlAllocator<ItemBlock>(pAllocationCallbacks))
{
    
# 4805 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 4805 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_FirstBlockCapacity > 1
# 4805 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 4805 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_FirstBlockCapacity > 1"
# 4805 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",4805),0))
# 4805 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                       ;
}

template<typename T>
VmaPoolAllocator<T>::~VmaPoolAllocator()
{
    for (size_t i = m_ItemBlocks.size(); i--;)
        vma_delete_array(m_pAllocationCallbacks, m_ItemBlocks[i].pItems, m_ItemBlocks[i].Capacity);
    m_ItemBlocks.clear();
}

template<typename T>
template<typename... Types> T* VmaPoolAllocator<T>::Alloc(Types&&... args)
{
    for (size_t i = m_ItemBlocks.size(); i--; )
    {
        ItemBlock& block = m_ItemBlocks[i];

        if (block.FirstFreeIndex != 
# 4823 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                   0xffffffffU
# 4823 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                             )
        {
            Item* const pItem = &block.pItems[block.FirstFreeIndex];
            block.FirstFreeIndex = pItem->NextFreeIndex;
            T* result = (T*)&pItem->Value;
            new(result)T(std::forward<Types>(args)...);
            return result;
        }
    }


    ItemBlock& newBlock = CreateNewBlock();
    Item* const pItem = &newBlock.pItems[0];
    newBlock.FirstFreeIndex = pItem->NextFreeIndex;
    T* result = (T*)&pItem->Value;
    new(result) T(std::forward<Types>(args)...);
    return result;
}

template<typename T>
void VmaPoolAllocator<T>::Free(T* ptr)
{

    for (size_t i = m_ItemBlocks.size(); i--; )
    {
        ItemBlock& block = m_ItemBlocks[i];


        Item* pItemPtr;
        memcpy(&pItemPtr, &ptr, sizeof(pItemPtr));


        if ((pItemPtr >= block.pItems) && (pItemPtr < block.pItems + block.Capacity))
        {
            ptr->~T();
            const uint32_t index = static_cast<uint32_t>(pItemPtr - block.pItems);
            pItemPtr->NextFreeIndex = block.FirstFreeIndex;
            block.FirstFreeIndex = index;
            return;
        }
    }
    
# 4864 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 4864 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Pointer doesn't belong to this memory pool."
# 4864 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 4864 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Pointer doesn't belong to this memory pool.\""
# 4864 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",4864),0))
# 4864 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                 ;
}

template<typename T>
typename VmaPoolAllocator<T>::ItemBlock& VmaPoolAllocator<T>::CreateNewBlock()
{
    const uint32_t newBlockCapacity = m_ItemBlocks.empty() ?
        m_FirstBlockCapacity : m_ItemBlocks.back().Capacity * 3 / 2;

    const ItemBlock newBlock =
    {
        new(VmaAllocateArray<Item>((m_pAllocationCallbacks), (newBlockCapacity)))(Item),
        newBlockCapacity,
        0
    };

    m_ItemBlocks.push_back(newBlock);


    for (uint32_t i = 0; i < newBlockCapacity - 1; ++i)
        newBlock.pItems[i].NextFreeIndex = i + 1;
    newBlock.pItems[newBlockCapacity - 1].NextFreeIndex = 
# 4885 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                         0xffffffffU
# 4885 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                   ;
    return m_ItemBlocks.back();
}




template<typename T>
struct VmaListItem
{
    VmaListItem* pPrev;
    VmaListItem* pNext;
    T Value;
};


template<typename T>
class VmaRawList
{
    private: VmaRawList(const VmaRawList&) = delete; VmaRawList(VmaRawList&&) = delete; VmaRawList& operator=(const VmaRawList&) = delete; VmaRawList& operator=(VmaRawList&&) = delete;
public:
    typedef VmaListItem<T> ItemType;

    VmaRawList(const VkAllocationCallbacks* pAllocationCallbacks);


    ~VmaRawList() = default;

    size_t GetCount() const { return m_Count; }
    bool IsEmpty() const { return m_Count == 0; }

    ItemType* Front() { return m_pFront; }
    ItemType* Back() { return m_pBack; }
    const ItemType* Front() const { return m_pFront; }
    const ItemType* Back() const { return m_pBack; }

    ItemType* PushFront();
    ItemType* PushBack();
    ItemType* PushFront(const T& value);
    ItemType* PushBack(const T& value);
    void PopFront();
    void PopBack();


    ItemType* InsertBefore(ItemType* pItem);

    ItemType* InsertAfter(ItemType* pItem);
    ItemType* InsertBefore(ItemType* pItem, const T& value);
    ItemType* InsertAfter(ItemType* pItem, const T& value);

    void Clear();
    void Remove(ItemType* pItem);

private:
    const VkAllocationCallbacks* const m_pAllocationCallbacks;
    VmaPoolAllocator<ItemType> m_ItemAllocator;
    ItemType* m_pFront;
    ItemType* m_pBack;
    size_t m_Count;
};


template<typename T>
VmaRawList<T>::VmaRawList(const VkAllocationCallbacks* pAllocationCallbacks)
    : m_pAllocationCallbacks(pAllocationCallbacks),
    m_ItemAllocator(pAllocationCallbacks, 128),
    m_pFront(nullptr),
    m_pBack(nullptr),
    m_Count(0) {}

template<typename T>
VmaListItem<T>* VmaRawList<T>::PushFront()
{
    ItemType* const pNewItem = m_ItemAllocator.Alloc();
    pNewItem->pPrev = nullptr;
    if (IsEmpty())
    {
        pNewItem->pNext = nullptr;
        m_pFront = pNewItem;
        m_pBack = pNewItem;
        m_Count = 1;
    }
    else
    {
        pNewItem->pNext = m_pFront;
        m_pFront->pPrev = pNewItem;
        m_pFront = pNewItem;
        ++m_Count;
    }
    return pNewItem;
}

template<typename T>
VmaListItem<T>* VmaRawList<T>::PushBack()
{
    ItemType* const pNewItem = m_ItemAllocator.Alloc();
    pNewItem->pNext = nullptr;
    if(IsEmpty())
    {
        pNewItem->pPrev = nullptr;
        m_pFront = pNewItem;
        m_pBack = pNewItem;
        m_Count = 1;
    }
    else
    {
        pNewItem->pPrev = m_pBack;
        m_pBack->pNext = pNewItem;
        m_pBack = pNewItem;
        ++m_Count;
    }
    return pNewItem;
}

template<typename T>
VmaListItem<T>* VmaRawList<T>::PushFront(const T& value)
{
    ItemType* const pNewItem = PushFront();
    pNewItem->Value = value;
    return pNewItem;
}

template<typename T>
VmaListItem<T>* VmaRawList<T>::PushBack(const T& value)
{
    ItemType* const pNewItem = PushBack();
    pNewItem->Value = value;
    return pNewItem;
}

template<typename T>
void VmaRawList<T>::PopFront()
{
    ;
    ItemType* const pFrontItem = m_pFront;
    ItemType* const pNextItem = pFrontItem->pNext;
    if (pNextItem != nullptr)
    {
        pNextItem->pPrev = nullptr;
    }
    m_pFront = pNextItem;
    m_ItemAllocator.Free(pFrontItem);
    --m_Count;
}

template<typename T>
void VmaRawList<T>::PopBack()
{
    ;
    ItemType* const pBackItem = m_pBack;
    ItemType* const pPrevItem = pBackItem->pPrev;
    if(pPrevItem != nullptr)
    {
        pPrevItem->pNext = nullptr;
    }
    m_pBack = pPrevItem;
    m_ItemAllocator.Free(pBackItem);
    --m_Count;
}

template<typename T>
void VmaRawList<T>::Clear()
{
    if (IsEmpty() == false)
    {
        ItemType* pItem = m_pBack;
        while (pItem != nullptr)
        {
            ItemType* const pPrevItem = pItem->pPrev;
            m_ItemAllocator.Free(pItem);
            pItem = pPrevItem;
        }
        m_pFront = nullptr;
        m_pBack = nullptr;
        m_Count = 0;
    }
}

template<typename T>
void VmaRawList<T>::Remove(ItemType* pItem)
{
    ;
    ;

    if(pItem->pPrev != nullptr)
    {
        pItem->pPrev->pNext = pItem->pNext;
    }
    else
    {
        ;
        m_pFront = pItem->pNext;
    }

    if(pItem->pNext != nullptr)
    {
        pItem->pNext->pPrev = pItem->pPrev;
    }
    else
    {
        ;
        m_pBack = pItem->pPrev;
    }

    m_ItemAllocator.Free(pItem);
    --m_Count;
}

template<typename T>
VmaListItem<T>* VmaRawList<T>::InsertBefore(ItemType* pItem)
{
    if(pItem != nullptr)
    {
        ItemType* const prevItem = pItem->pPrev;
        ItemType* const newItem = m_ItemAllocator.Alloc();
        newItem->pPrev = prevItem;
        newItem->pNext = pItem;
        pItem->pPrev = newItem;
        if(prevItem != nullptr)
        {
            prevItem->pNext = newItem;
        }
        else
        {
            ;
            m_pFront = newItem;
        }
        ++m_Count;
        return newItem;
    }
    else
        return PushBack();
}

template<typename T>
VmaListItem<T>* VmaRawList<T>::InsertAfter(ItemType* pItem)
{
    if(pItem != nullptr)
    {
        ItemType* const nextItem = pItem->pNext;
        ItemType* const newItem = m_ItemAllocator.Alloc();
        newItem->pNext = nextItem;
        newItem->pPrev = pItem;
        pItem->pNext = newItem;
        if(nextItem != nullptr)
        {
            nextItem->pPrev = newItem;
        }
        else
        {
            ;
            m_pBack = newItem;
        }
        ++m_Count;
        return newItem;
    }
    else
        return PushFront();
}

template<typename T>
VmaListItem<T>* VmaRawList<T>::InsertBefore(ItemType* pItem, const T& value)
{
    ItemType* const newItem = InsertBefore(pItem);
    newItem->Value = value;
    return newItem;
}

template<typename T>
VmaListItem<T>* VmaRawList<T>::InsertAfter(ItemType* pItem, const T& value)
{
    ItemType* const newItem = InsertAfter(pItem);
    newItem->Value = value;
    return newItem;
}




template<typename T, typename AllocatorT>
class VmaList
{
    private: VmaList(const VmaList&) = delete; VmaList(VmaList&&) = delete; VmaList& operator=(const VmaList&) = delete; VmaList& operator=(VmaList&&) = delete;
public:
    class reverse_iterator;
    class const_iterator;
    class const_reverse_iterator;

    class iterator
    {
        friend class const_iterator;
        friend class VmaList<T, AllocatorT>;
    public:
        iterator() : m_pList(nullptr), m_pItem(nullptr) {}
        iterator(const reverse_iterator& src) : m_pList(src.m_pList), m_pItem(src.m_pItem) {}

        T& operator*() const { ; return m_pItem->Value; }
        T* operator->() const { ; return &m_pItem->Value; }

        bool operator==(const iterator& rhs) const { ; return m_pItem == rhs.m_pItem; }
        bool operator!=(const iterator& rhs) const { ; return m_pItem != rhs.m_pItem; }

        iterator operator++(int) { iterator result = *this; ++*this; return result; }
        iterator operator--(int) { iterator result = *this; --*this; return result; }

        iterator& operator++() { ; m_pItem = m_pItem->pNext; return *this; }
        iterator& operator--();

    private:
        VmaRawList<T>* m_pList;
        VmaListItem<T>* m_pItem;

        iterator(VmaRawList<T>* pList, VmaListItem<T>* pItem) : m_pList(pList), m_pItem(pItem) {}
    };
    class reverse_iterator
    {
        friend class const_reverse_iterator;
        friend class VmaList<T, AllocatorT>;
    public:
        reverse_iterator() : m_pList(nullptr), m_pItem(nullptr) {}
        reverse_iterator(const iterator& src) : m_pList(src.m_pList), m_pItem(src.m_pItem) {}

        T& operator*() const { ; return m_pItem->Value; }
        T* operator->() const { ; return &m_pItem->Value; }

        bool operator==(const reverse_iterator& rhs) const { ; return m_pItem == rhs.m_pItem; }
        bool operator!=(const reverse_iterator& rhs) const { ; return m_pItem != rhs.m_pItem; }

        reverse_iterator operator++(int) { reverse_iterator result = *this; ++* this; return result; }
        reverse_iterator operator--(int) { reverse_iterator result = *this; --* this; return result; }

        reverse_iterator& operator++() { ; m_pItem = m_pItem->pPrev; return *this; }
        reverse_iterator& operator--();

    private:
        VmaRawList<T>* m_pList;
        VmaListItem<T>* m_pItem;

        reverse_iterator(VmaRawList<T>* pList, VmaListItem<T>* pItem) : m_pList(pList), m_pItem(pItem) {}
    };
    class const_iterator
    {
        friend class VmaList<T, AllocatorT>;
    public:
        const_iterator() : m_pList(nullptr), m_pItem(nullptr) {}
        const_iterator(const iterator& src) : m_pList(src.m_pList), m_pItem(src.m_pItem) {}
        const_iterator(const reverse_iterator& src) : m_pList(src.m_pList), m_pItem(src.m_pItem) {}

        iterator drop_const() { return { const_cast<VmaRawList<T>*>(m_pList), const_cast<VmaListItem<T>*>(m_pItem) }; }

        const T& operator*() const { ; return m_pItem->Value; }
        const T* operator->() const { ; return &m_pItem->Value; }

        bool operator==(const const_iterator& rhs) const { ; return m_pItem == rhs.m_pItem; }
        bool operator!=(const const_iterator& rhs) const { ; return m_pItem != rhs.m_pItem; }

        const_iterator operator++(int) { const_iterator result = *this; ++* this; return result; }
        const_iterator operator--(int) { const_iterator result = *this; --* this; return result; }

        const_iterator& operator++() { ; m_pItem = m_pItem->pNext; return *this; }
        const_iterator& operator--();

    private:
        const VmaRawList<T>* m_pList;
        const VmaListItem<T>* m_pItem;

        const_iterator(const VmaRawList<T>* pList, const VmaListItem<T>* pItem) : m_pList(pList), m_pItem(pItem) {}
    };
    class const_reverse_iterator
    {
        friend class VmaList<T, AllocatorT>;
    public:
        const_reverse_iterator() : m_pList(nullptr), m_pItem(nullptr) {}
        const_reverse_iterator(const reverse_iterator& src) : m_pList(src.m_pList), m_pItem(src.m_pItem) {}
        const_reverse_iterator(const iterator& src) : m_pList(src.m_pList), m_pItem(src.m_pItem) {}

        reverse_iterator drop_const() { return { const_cast<VmaRawList<T>*>(m_pList), const_cast<VmaListItem<T>*>(m_pItem) }; }

        const T& operator*() const { ; return m_pItem->Value; }
        const T* operator->() const { ; return &m_pItem->Value; }

        bool operator==(const const_reverse_iterator& rhs) const { ; return m_pItem == rhs.m_pItem; }
        bool operator!=(const const_reverse_iterator& rhs) const { ; return m_pItem != rhs.m_pItem; }

        const_reverse_iterator operator++(int) { const_reverse_iterator result = *this; ++* this; return result; }
        const_reverse_iterator operator--(int) { const_reverse_iterator result = *this; --* this; return result; }

        const_reverse_iterator& operator++() { ; m_pItem = m_pItem->pPrev; return *this; }
        const_reverse_iterator& operator--();

    private:
        const VmaRawList<T>* m_pList;
        const VmaListItem<T>* m_pItem;

        const_reverse_iterator(const VmaRawList<T>* pList, const VmaListItem<T>* pItem) : m_pList(pList), m_pItem(pItem) {}
    };

    VmaList(const AllocatorT& allocator) : m_RawList(allocator.m_pCallbacks) {}

    bool empty() const { return m_RawList.IsEmpty(); }
    size_t size() const { return m_RawList.GetCount(); }

    iterator begin() { return iterator(&m_RawList, m_RawList.Front()); }
    iterator end() { return iterator(&m_RawList, nullptr); }

    const_iterator cbegin() const { return const_iterator(&m_RawList, m_RawList.Front()); }
    const_iterator cend() const { return const_iterator(&m_RawList, nullptr); }

    const_iterator begin() const { return cbegin(); }
    const_iterator end() const { return cend(); }

    reverse_iterator rbegin() { return reverse_iterator(&m_RawList, m_RawList.Back()); }
    reverse_iterator rend() { return reverse_iterator(&m_RawList, nullptr); }

    const_reverse_iterator crbegin() const { return const_reverse_iterator(&m_RawList, m_RawList.Back()); }
    const_reverse_iterator crend() const { return const_reverse_iterator(&m_RawList, nullptr); }

    const_reverse_iterator rbegin() const { return crbegin(); }
    const_reverse_iterator rend() const { return crend(); }

    void push_back(const T& value) { m_RawList.PushBack(value); }
    iterator insert(iterator it, const T& value) { return iterator(&m_RawList, m_RawList.InsertBefore(it.m_pItem, value)); }

    void clear() { m_RawList.Clear(); }
    void erase(iterator it) { m_RawList.Remove(it.m_pItem); }

private:
    VmaRawList<T> m_RawList;
};


template<typename T, typename AllocatorT>
typename VmaList<T, AllocatorT>::iterator& VmaList<T, AllocatorT>::iterator::operator--()
{
    if (m_pItem != nullptr)
    {
        m_pItem = m_pItem->pPrev;
    }
    else
    {
        ;
        m_pItem = m_pList->Back();
    }
    return *this;
}

template<typename T, typename AllocatorT>
typename VmaList<T, AllocatorT>::reverse_iterator& VmaList<T, AllocatorT>::reverse_iterator::operator--()
{
    if (m_pItem != nullptr)
    {
        m_pItem = m_pItem->pNext;
    }
    else
    {
        ;
        m_pItem = m_pList->Front();
    }
    return *this;
}

template<typename T, typename AllocatorT>
typename VmaList<T, AllocatorT>::const_iterator& VmaList<T, AllocatorT>::const_iterator::operator--()
{
    if (m_pItem != nullptr)
    {
        m_pItem = m_pItem->pPrev;
    }
    else
    {
        ;
        m_pItem = m_pList->Back();
    }
    return *this;
}

template<typename T, typename AllocatorT>
typename VmaList<T, AllocatorT>::const_reverse_iterator& VmaList<T, AllocatorT>::const_reverse_iterator::operator--()
{
    if (m_pItem != nullptr)
    {
        m_pItem = m_pItem->pNext;
    }
    else
    {
        ;
        m_pItem = m_pList->Back();
    }
    return *this;
}
# 5390 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
template<typename ItemTypeTraits>
class VmaIntrusiveLinkedList
{
public:
    typedef typename ItemTypeTraits::ItemType ItemType;
    static ItemType* GetPrev(const ItemType* item) { return ItemTypeTraits::GetPrev(item); }
    static ItemType* GetNext(const ItemType* item) { return ItemTypeTraits::GetNext(item); }


    VmaIntrusiveLinkedList() = default;
    VmaIntrusiveLinkedList(VmaIntrusiveLinkedList && src);
    VmaIntrusiveLinkedList(const VmaIntrusiveLinkedList&) = delete;
    VmaIntrusiveLinkedList& operator=(VmaIntrusiveLinkedList&& src);
    VmaIntrusiveLinkedList& operator=(const VmaIntrusiveLinkedList&) = delete;
    ~VmaIntrusiveLinkedList() { ; }

    size_t GetCount() const { return m_Count; }
    bool IsEmpty() const { return m_Count == 0; }
    ItemType* Front() { return m_Front; }
    ItemType* Back() { return m_Back; }
    const ItemType* Front() const { return m_Front; }
    const ItemType* Back() const { return m_Back; }

    void PushBack(ItemType* item);
    void PushFront(ItemType* item);
    ItemType* PopBack();
    ItemType* PopFront();


    void InsertBefore(ItemType* existingItem, ItemType* newItem);

    void InsertAfter(ItemType* existingItem, ItemType* newItem);
    void Remove(ItemType* item);
    void RemoveAll();

private:
    ItemType* m_Front = nullptr;
    ItemType* m_Back = nullptr;
    size_t m_Count = 0;
};


template<typename ItemTypeTraits>
VmaIntrusiveLinkedList<ItemTypeTraits>::VmaIntrusiveLinkedList(VmaIntrusiveLinkedList&& src)
    : m_Front(src.m_Front), m_Back(src.m_Back), m_Count(src.m_Count)
{
    src.m_Front = src.m_Back = nullptr;
    src.m_Count = 0;
}

template<typename ItemTypeTraits>
VmaIntrusiveLinkedList<ItemTypeTraits>& VmaIntrusiveLinkedList<ItemTypeTraits>::operator=(VmaIntrusiveLinkedList&& src)
{
    if (&src != this)
    {
        ;
        m_Front = src.m_Front;
        m_Back = src.m_Back;
        m_Count = src.m_Count;
        src.m_Front = src.m_Back = nullptr;
        src.m_Count = 0;
    }
    return *this;
}

template<typename ItemTypeTraits>
void VmaIntrusiveLinkedList<ItemTypeTraits>::PushBack(ItemType* item)
{
    ;
    if (IsEmpty())
    {
        m_Front = item;
        m_Back = item;
        m_Count = 1;
    }
    else
    {
        ItemTypeTraits::AccessPrev(item) = m_Back;
        ItemTypeTraits::AccessNext(m_Back) = item;
        m_Back = item;
        ++m_Count;
    }
}

template<typename ItemTypeTraits>
void VmaIntrusiveLinkedList<ItemTypeTraits>::PushFront(ItemType* item)
{
    ;
    if (IsEmpty())
    {
        m_Front = item;
        m_Back = item;
        m_Count = 1;
    }
    else
    {
        ItemTypeTraits::AccessNext(item) = m_Front;
        ItemTypeTraits::AccessPrev(m_Front) = item;
        m_Front = item;
        ++m_Count;
    }
}

template<typename ItemTypeTraits>
typename VmaIntrusiveLinkedList<ItemTypeTraits>::ItemType* VmaIntrusiveLinkedList<ItemTypeTraits>::PopBack()
{
    ;
    ItemType* const backItem = m_Back;
    ItemType* const prevItem = ItemTypeTraits::GetPrev(backItem);
    if (prevItem != nullptr)
    {
        ItemTypeTraits::AccessNext(prevItem) = nullptr;
    }
    m_Back = prevItem;
    --m_Count;
    ItemTypeTraits::AccessPrev(backItem) = nullptr;
    ItemTypeTraits::AccessNext(backItem) = nullptr;
    return backItem;
}

template<typename ItemTypeTraits>
typename VmaIntrusiveLinkedList<ItemTypeTraits>::ItemType* VmaIntrusiveLinkedList<ItemTypeTraits>::PopFront()
{
    ;
    ItemType* const frontItem = m_Front;
    ItemType* const nextItem = ItemTypeTraits::GetNext(frontItem);
    if (nextItem != nullptr)
    {
        ItemTypeTraits::AccessPrev(nextItem) = nullptr;
    }
    m_Front = nextItem;
    --m_Count;
    ItemTypeTraits::AccessPrev(frontItem) = nullptr;
    ItemTypeTraits::AccessNext(frontItem) = nullptr;
    return frontItem;
}

template<typename ItemTypeTraits>
void VmaIntrusiveLinkedList<ItemTypeTraits>::InsertBefore(ItemType* existingItem, ItemType* newItem)
{
    ;
    if (existingItem != nullptr)
    {
        ItemType* const prevItem = ItemTypeTraits::GetPrev(existingItem);
        ItemTypeTraits::AccessPrev(newItem) = prevItem;
        ItemTypeTraits::AccessNext(newItem) = existingItem;
        ItemTypeTraits::AccessPrev(existingItem) = newItem;
        if (prevItem != nullptr)
        {
            ItemTypeTraits::AccessNext(prevItem) = newItem;
        }
        else
        {
            ;
            m_Front = newItem;
        }
        ++m_Count;
    }
    else
        PushBack(newItem);
}

template<typename ItemTypeTraits>
void VmaIntrusiveLinkedList<ItemTypeTraits>::InsertAfter(ItemType* existingItem, ItemType* newItem)
{
    ;
    if (existingItem != nullptr)
    {
        ItemType* const nextItem = ItemTypeTraits::GetNext(existingItem);
        ItemTypeTraits::AccessNext(newItem) = nextItem;
        ItemTypeTraits::AccessPrev(newItem) = existingItem;
        ItemTypeTraits::AccessNext(existingItem) = newItem;
        if (nextItem != nullptr)
        {
            ItemTypeTraits::AccessPrev(nextItem) = newItem;
        }
        else
        {
            ;
            m_Back = newItem;
        }
        ++m_Count;
    }
    else
        return PushFront(newItem);
}

template<typename ItemTypeTraits>
void VmaIntrusiveLinkedList<ItemTypeTraits>::Remove(ItemType* item)
{
    ;
    if (ItemTypeTraits::GetPrev(item) != nullptr)
    {
        ItemTypeTraits::AccessNext(ItemTypeTraits::AccessPrev(item)) = ItemTypeTraits::GetNext(item);
    }
    else
    {
        ;
        m_Front = ItemTypeTraits::GetNext(item);
    }

    if (ItemTypeTraits::GetNext(item) != nullptr)
    {
        ItemTypeTraits::AccessPrev(ItemTypeTraits::AccessNext(item)) = ItemTypeTraits::GetPrev(item);
    }
    else
    {
        ;
        m_Back = ItemTypeTraits::GetPrev(item);
    }
    ItemTypeTraits::AccessPrev(item) = nullptr;
    ItemTypeTraits::AccessNext(item) = nullptr;
    --m_Count;
}

template<typename ItemTypeTraits>
void VmaIntrusiveLinkedList<ItemTypeTraits>::RemoveAll()
{
    if (!IsEmpty())
    {
        ItemType* item = m_Back;
        while (item != nullptr)
        {
            ItemType* const prevItem = ItemTypeTraits::AccessPrev(item);
            ItemTypeTraits::AccessPrev(item) = nullptr;
            ItemTypeTraits::AccessNext(item) = nullptr;
            item = prevItem;
        }
        m_Front = nullptr;
        m_Back = nullptr;
        m_Count = 0;
    }
}




class VmaStringBuilder
{
public:
    VmaStringBuilder(const VkAllocationCallbacks* allocationCallbacks) : m_Data(VmaStlAllocator<char>(allocationCallbacks)) {}
    ~VmaStringBuilder() = default;

    size_t GetLength() const { return m_Data.size(); }
    const char* GetData() const { return m_Data.data(); }
    void AddNewLine() { Add('\n'); }
    void Add(char ch) { m_Data.push_back(ch); }

    void Add(const char* pStr);
    void AddNumber(uint32_t num);
    void AddNumber(uint64_t num);
    void AddPointer(const void* ptr);

private:
    VmaVector<char, VmaStlAllocator<char>> m_Data;
};


void VmaStringBuilder::Add(const char* pStr)
{
    const size_t strLen = strlen(pStr);
    if (strLen > 0)
    {
        const size_t oldCount = m_Data.size();
        m_Data.resize(oldCount + strLen);
        memcpy(m_Data.data() + oldCount, pStr, strLen);
    }
}

void VmaStringBuilder::AddNumber(uint32_t num)
{
    char buf[11];
    buf[10] = '\0';
    char* p = &buf[10];
    do
    {
        *--p = '0' + (char)(num % 10);
        num /= 10;
    } while (num);
    Add(p);
}

void VmaStringBuilder::AddNumber(uint64_t num)
{
    char buf[21];
    buf[20] = '\0';
    char* p = &buf[20];
    do
    {
        *--p = '0' + (char)(num % 10);
        num /= 10;
    } while (num);
    Add(p);
}

void VmaStringBuilder::AddPointer(const void* ptr)
{
    char buf[21];
    VmaPtrToStr(buf, sizeof(buf), ptr);
    Add(buf);
}
# 5699 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
class VmaJsonWriter
{
    private: VmaJsonWriter(const VmaJsonWriter&) = delete; VmaJsonWriter(VmaJsonWriter&&) = delete; VmaJsonWriter& operator=(const VmaJsonWriter&) = delete; VmaJsonWriter& operator=(VmaJsonWriter&&) = delete;
public:

    VmaJsonWriter(const VkAllocationCallbacks* pAllocationCallbacks, VmaStringBuilder& sb);
    ~VmaJsonWriter();





    void BeginObject(bool singleLine = false);

    void EndObject();



    void BeginArray(bool singleLine = false);

    void EndArray();



    void WriteString(const char* pStr);





    void BeginString(const char* pStr = nullptr);

    void ContinueString(const char* pStr);

    void ContinueString(uint32_t n);
    void ContinueString(uint64_t n);


    void ContinueString_Pointer(const void* ptr);

    void EndString(const char* pStr = nullptr);


    void WriteNumber(uint32_t n);
    void WriteNumber(uint64_t n);

    void WriteBool(bool b);

    void WriteNull();

private:
    enum COLLECTION_TYPE
    {
        COLLECTION_TYPE_OBJECT,
        COLLECTION_TYPE_ARRAY,
    };
    struct StackItem
    {
        COLLECTION_TYPE type;
        uint32_t valueCount;
        bool singleLineMode;
    };

    static const char* const INDENT;

    VmaStringBuilder& m_SB;
    VmaVector< StackItem, VmaStlAllocator<StackItem> > m_Stack;
    bool m_InsideString;

    void BeginValue(bool isString);
    void WriteIndent(bool oneLess = false);
};
const char* const VmaJsonWriter::INDENT = "  ";


VmaJsonWriter::VmaJsonWriter(const VkAllocationCallbacks* pAllocationCallbacks, VmaStringBuilder& sb)
    : m_SB(sb),
    m_Stack(VmaStlAllocator<StackItem>(pAllocationCallbacks)),
    m_InsideString(false) {}

VmaJsonWriter::~VmaJsonWriter()
{
    
# 5781 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 5781 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !m_InsideString
# 5781 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 5781 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!m_InsideString"
# 5781 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5781),0))
# 5781 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                              ;
    
# 5782 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 5782 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_Stack.empty()
# 5782 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 5782 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_Stack.empty()"
# 5782 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5782),0))
# 5782 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                              ;
}

void VmaJsonWriter::BeginObject(bool singleLine)
{
    
# 5787 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 5787 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !m_InsideString
# 5787 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 5787 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!m_InsideString"
# 5787 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5787),0))
# 5787 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                              ;

    BeginValue(false);
    m_SB.Add('{');

    StackItem item;
    item.type = COLLECTION_TYPE_OBJECT;
    item.valueCount = 0;
    item.singleLineMode = singleLine;
    m_Stack.push_back(item);
}

void VmaJsonWriter::EndObject()
{
    
# 5801 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 5801 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !m_InsideString
# 5801 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 5801 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!m_InsideString"
# 5801 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5801),0))
# 5801 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                              ;

    WriteIndent(true);
    m_SB.Add('}');

    
# 5806 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 5806 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !m_Stack.empty() && m_Stack.back().type == COLLECTION_TYPE_OBJECT
# 5806 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 5806 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!m_Stack.empty() && m_Stack.back().type == COLLECTION_TYPE_OBJECT"
# 5806 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5806),0))
# 5806 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                ;
    m_Stack.pop_back();
}

void VmaJsonWriter::BeginArray(bool singleLine)
{
    
# 5812 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 5812 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !m_InsideString
# 5812 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 5812 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!m_InsideString"
# 5812 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5812),0))
# 5812 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                              ;

    BeginValue(false);
    m_SB.Add('[');

    StackItem item;
    item.type = COLLECTION_TYPE_ARRAY;
    item.valueCount = 0;
    item.singleLineMode = singleLine;
    m_Stack.push_back(item);
}

void VmaJsonWriter::EndArray()
{
    
# 5826 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 5826 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !m_InsideString
# 5826 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 5826 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!m_InsideString"
# 5826 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5826),0))
# 5826 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                              ;

    WriteIndent(true);
    m_SB.Add(']');

    
# 5831 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 5831 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !m_Stack.empty() && m_Stack.back().type == COLLECTION_TYPE_ARRAY
# 5831 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 5831 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!m_Stack.empty() && m_Stack.back().type == COLLECTION_TYPE_ARRAY"
# 5831 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5831),0))
# 5831 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                               ;
    m_Stack.pop_back();
}

void VmaJsonWriter::WriteString(const char* pStr)
{
    BeginString(pStr);
    EndString();
}

void VmaJsonWriter::BeginString(const char* pStr)
{
    
# 5843 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 5843 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !m_InsideString
# 5843 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 5843 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!m_InsideString"
# 5843 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5843),0))
# 5843 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                              ;

    BeginValue(true);
    m_SB.Add('"');
    m_InsideString = true;
    if (pStr != nullptr && pStr[0] != '\0')
    {
        ContinueString(pStr);
    }
}

void VmaJsonWriter::ContinueString(const char* pStr)
{
    
# 5856 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 5856 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_InsideString
# 5856 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 5856 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_InsideString"
# 5856 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5856),0))
# 5856 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                             ;

    const size_t strLen = strlen(pStr);
    for (size_t i = 0; i < strLen; ++i)
    {
        char ch = pStr[i];
        if (ch == '\\')
        {
            m_SB.Add("\\\\");
        }
        else if (ch == '"')
        {
            m_SB.Add("\\\"");
        }
        else if ((uint8_t)ch >= 32)
        {
            m_SB.Add(ch);
        }
        else switch (ch)
        {
        case '\b':
            m_SB.Add("\\b");
            break;
        case '\f':
            m_SB.Add("\\f");
            break;
        case '\n':
            m_SB.Add("\\n");
            break;
        case '\r':
            m_SB.Add("\\r");
            break;
        case '\t':
            m_SB.Add("\\t");
            break;
        default:
            
# 5892 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 5892 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0 && "Character not currently supported."
# 5892 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 5892 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0 && \"Character not currently supported.\""
# 5892 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5892),0))
# 5892 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                ;
        }
    }
}

void VmaJsonWriter::ContinueString(uint32_t n)
{
    
# 5899 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 5899 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_InsideString
# 5899 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 5899 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_InsideString"
# 5899 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5899),0))
# 5899 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                             ;
    m_SB.AddNumber(n);
}

void VmaJsonWriter::ContinueString(uint64_t n)
{
    
# 5905 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 5905 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_InsideString
# 5905 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 5905 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_InsideString"
# 5905 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5905),0))
# 5905 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                             ;
    m_SB.AddNumber(n);
}

void VmaJsonWriter::ContinueString_Pointer(const void* ptr)
{
    
# 5911 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 5911 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_InsideString
# 5911 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 5911 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_InsideString"
# 5911 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5911),0))
# 5911 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                             ;
    m_SB.AddPointer(ptr);
}

void VmaJsonWriter::EndString(const char* pStr)
{
    
# 5917 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 5917 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_InsideString
# 5917 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 5917 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_InsideString"
# 5917 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5917),0))
# 5917 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                             ;
    if (pStr != nullptr && pStr[0] != '\0')
    {
        ContinueString(pStr);
    }
    m_SB.Add('"');
    m_InsideString = false;
}

void VmaJsonWriter::WriteNumber(uint32_t n)
{
    
# 5928 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 5928 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !m_InsideString
# 5928 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 5928 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!m_InsideString"
# 5928 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5928),0))
# 5928 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                              ;
    BeginValue(false);
    m_SB.AddNumber(n);
}

void VmaJsonWriter::WriteNumber(uint64_t n)
{
    
# 5935 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 5935 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !m_InsideString
# 5935 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 5935 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!m_InsideString"
# 5935 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5935),0))
# 5935 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                              ;
    BeginValue(false);
    m_SB.AddNumber(n);
}

void VmaJsonWriter::WriteBool(bool b)
{
    
# 5942 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 5942 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !m_InsideString
# 5942 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 5942 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!m_InsideString"
# 5942 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5942),0))
# 5942 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                              ;
    BeginValue(false);
    m_SB.Add(b ? "true" : "false");
}

void VmaJsonWriter::WriteNull()
{
    
# 5949 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 5949 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !m_InsideString
# 5949 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 5949 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!m_InsideString"
# 5949 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5949),0))
# 5949 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                              ;
    BeginValue(false);
    m_SB.Add("null");
}

void VmaJsonWriter::BeginValue(bool isString)
{
    if (!m_Stack.empty())
    {
        StackItem& currItem = m_Stack.back();
        if (currItem.type == COLLECTION_TYPE_OBJECT &&
            currItem.valueCount % 2 == 0)
        {
            
# 5962 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 5962 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           isString
# 5962 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 5962 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "isString"
# 5962 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",5962),0))
# 5962 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                               ;
        }

        if (currItem.type == COLLECTION_TYPE_OBJECT &&
            currItem.valueCount % 2 != 0)
        {
            m_SB.Add(": ");
        }
        else if (currItem.valueCount > 0)
        {
            m_SB.Add(", ");
            WriteIndent();
        }
        else
        {
            WriteIndent();
        }
        ++currItem.valueCount;
    }
}

void VmaJsonWriter::WriteIndent(bool oneLess)
{
    if (!m_Stack.empty() && !m_Stack.back().singleLineMode)
    {
        m_SB.AddNewLine();

        size_t count = m_Stack.size();
        if (count > 0 && oneLess)
        {
            --count;
        }
        for (size_t i = 0; i < count; ++i)
        {
            m_SB.Add(INDENT);
        }
    }
}


static void VmaPrintDetailedStatistics(VmaJsonWriter& json, const VmaDetailedStatistics& stat)
{
    json.BeginObject();

    json.WriteString("BlockCount");
    json.WriteNumber(stat.statistics.blockCount);
    json.WriteString("BlockBytes");
    json.WriteNumber(stat.statistics.blockBytes);
    json.WriteString("AllocationCount");
    json.WriteNumber(stat.statistics.allocationCount);
    json.WriteString("AllocationBytes");
    json.WriteNumber(stat.statistics.allocationBytes);
    json.WriteString("UnusedRangeCount");
    json.WriteNumber(stat.unusedRangeCount);

    if (stat.statistics.allocationCount > 1)
    {
        json.WriteString("AllocationSizeMin");
        json.WriteNumber(stat.allocationSizeMin);
        json.WriteString("AllocationSizeMax");
        json.WriteNumber(stat.allocationSizeMax);
    }
    if (stat.unusedRangeCount > 1)
    {
        json.WriteString("UnusedRangeSizeMin");
        json.WriteNumber(stat.unusedRangeSizeMin);
        json.WriteString("UnusedRangeSizeMax");
        json.WriteNumber(stat.unusedRangeSizeMax);
    }
    json.EndObject();
}




class VmaMappingHysteresis
{
    private: VmaMappingHysteresis(const VmaMappingHysteresis&) = delete; VmaMappingHysteresis(VmaMappingHysteresis&&) = delete; VmaMappingHysteresis& operator=(const VmaMappingHysteresis&) = delete; VmaMappingHysteresis& operator=(VmaMappingHysteresis&&) = delete;
public:
    VmaMappingHysteresis() = default;

    uint32_t GetExtraMapping() const { return m_ExtraMapping; }



    bool PostMap()
    {

        if(m_ExtraMapping == 0)
        {
            ++m_MajorCounter;
            if(m_MajorCounter >= COUNTER_MIN_EXTRA_MAPPING)
            {
                m_ExtraMapping = 1;
                m_MajorCounter = 0;
                m_MinorCounter = 0;
                return true;
            }
        }
        else
            PostMinorCounter();

        return false;
    }


    void PostUnmap()
    {

        if(m_ExtraMapping == 0)
            ++m_MajorCounter;
        else
            PostMinorCounter();

    }


    void PostAlloc()
    {

        if(m_ExtraMapping == 1)
            ++m_MajorCounter;
        else
            PostMinorCounter();

    }



    bool PostFree()
    {

        if(m_ExtraMapping == 1)
        {
            ++m_MajorCounter;
            if(m_MajorCounter >= COUNTER_MIN_EXTRA_MAPPING &&
                m_MajorCounter > m_MinorCounter + 1)
            {
                m_ExtraMapping = 0;
                m_MajorCounter = 0;
                m_MinorCounter = 0;
                return true;
            }
        }
        else
            PostMinorCounter();

        return false;
    }

private:
    static const int32_t COUNTER_MIN_EXTRA_MAPPING = 7;

    uint32_t m_MinorCounter = 0;
    uint32_t m_MajorCounter = 0;
    uint32_t m_ExtraMapping = 0;

    void PostMinorCounter()
    {
        if(m_MinorCounter < m_MajorCounter)
        {
            ++m_MinorCounter;
        }
        else if(m_MajorCounter > 0)
        {
            --m_MajorCounter;
            --m_MinorCounter;
        }
    }
};
# 6204 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
class VmaWin32Handle
{

    void* placeholder = nullptr;
    VmaRWMutex placeholder2;
};
# 6222 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
class VmaDeviceMemoryBlock
{
    private: VmaDeviceMemoryBlock(const VmaDeviceMemoryBlock&) = delete; VmaDeviceMemoryBlock(VmaDeviceMemoryBlock&&) = delete; VmaDeviceMemoryBlock& operator=(const VmaDeviceMemoryBlock&) = delete; VmaDeviceMemoryBlock& operator=(VmaDeviceMemoryBlock&&) = delete;
public:
    VmaBlockMetadata* m_pMetadata;

    VmaDeviceMemoryBlock(VmaAllocator hAllocator);
    ~VmaDeviceMemoryBlock();


    void Init(
        VmaAllocator hAllocator,
        VmaPool hParentPool,
        uint32_t newMemoryTypeIndex,
        VkDeviceMemory newMemory,
        VkDeviceSize newSize,
        uint32_t id,
        uint32_t algorithm,
        VkDeviceSize bufferImageGranularity);

    void Destroy(VmaAllocator allocator);

    VmaPool GetParentPool() const { return m_hParentPool; }
    VkDeviceMemory GetDeviceMemory() const { return m_hMemory; }
    uint32_t GetMemoryTypeIndex() const { return m_MemoryTypeIndex; }
    uint32_t GetId() const { return m_Id; }
    void* GetMappedData() const { return m_pMappedData; }
    uint32_t GetMapRefCount() const { return m_MapCount; }



    void PostAlloc(VmaAllocator hAllocator);
    void PostFree(VmaAllocator hAllocator);


    bool Validate() const;
    VkResult CheckCorruption(VmaAllocator hAllocator);


    VkResult Map(VmaAllocator hAllocator, uint32_t count, void** ppData);
    void Unmap(VmaAllocator hAllocator, uint32_t count);

    VkResult WriteMagicValueAfterAllocation(VmaAllocator hAllocator, VkDeviceSize allocOffset, VkDeviceSize allocSize);
    VkResult ValidateMagicValueAfterAllocation(VmaAllocator hAllocator, VkDeviceSize allocOffset, VkDeviceSize allocSize);

    VkResult BindBufferMemory(
        const VmaAllocator hAllocator,
        const VmaAllocation hAllocation,
        VkDeviceSize allocationLocalOffset,
        VkBuffer hBuffer,
        const void* pNext);
    VkResult BindImageMemory(
        const VmaAllocator hAllocator,
        const VmaAllocation hAllocation,
        VkDeviceSize allocationLocalOffset,
        VkImage hImage,
        const void* pNext);







private:
    VmaPool m_hParentPool;
    uint32_t m_MemoryTypeIndex;
    uint32_t m_Id;
    VkDeviceMemory m_hMemory;






    VmaMutex m_MapAndBindMutex;
    VmaMappingHysteresis m_MappingHysteresis;
    uint32_t m_MapCount;
    void* m_pMappedData;

    VmaWin32Handle m_Handle;
};



struct VmaAllocationExtraData
{
    void* m_pMappedData = nullptr;
    VmaWin32Handle m_Handle;
};

struct VmaAllocation_T
{
    friend struct VmaDedicatedAllocationListItemTraits;

    enum FLAGS
    {
        FLAG_PERSISTENT_MAP = 0x01,
        FLAG_MAPPING_ALLOWED = 0x02,
    };

public:
    enum ALLOCATION_TYPE
    {
        ALLOCATION_TYPE_NONE,
        ALLOCATION_TYPE_BLOCK,
        ALLOCATION_TYPE_DEDICATED,
    };


    VmaAllocation_T(bool mappingAllowed);
    ~VmaAllocation_T();

    void InitBlockAllocation(
        VmaDeviceMemoryBlock* block,
        VmaAllocHandle allocHandle,
        VkDeviceSize alignment,
        VkDeviceSize size,
        uint32_t memoryTypeIndex,
        VmaSuballocationType suballocationType,
        bool mapped);

    void InitDedicatedAllocation(
        VmaAllocator allocator,
        VmaPool hParentPool,
        uint32_t memoryTypeIndex,
        VkDeviceMemory hMemory,
        VmaSuballocationType suballocationType,
        void* pMappedData,
        VkDeviceSize size);
    void Destroy(VmaAllocator allocator);

    ALLOCATION_TYPE GetType() const { return (ALLOCATION_TYPE)m_Type; }
    VkDeviceSize GetAlignment() const { return m_Alignment; }
    VkDeviceSize GetSize() const { return m_Size; }
    void* GetUserData() const { return m_pUserData; }
    const char* GetName() const { return m_pName; }
    VmaSuballocationType GetSuballocationType() const { return (VmaSuballocationType)m_SuballocationType; }

    VmaDeviceMemoryBlock* GetBlock() const { 
# 6361 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                                            (void) ((!!(
# 6361 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                            m_Type == ALLOCATION_TYPE_BLOCK
# 6361 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                                            )) || (_assert(
# 6361 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                            "m_Type == ALLOCATION_TYPE_BLOCK"
# 6361 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                                            ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",6361),0))
# 6361 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                       ; return m_BlockAllocation.m_Block; }
    uint32_t GetMemoryTypeIndex() const { return m_MemoryTypeIndex; }
    bool IsPersistentMap() const { return (m_Flags & FLAG_PERSISTENT_MAP) != 0; }
    bool IsMappingAllowed() const { return (m_Flags & FLAG_MAPPING_ALLOWED) != 0; }

    void SetUserData(VmaAllocator hAllocator, void* pUserData) { m_pUserData = pUserData; }
    void SetName(VmaAllocator hAllocator, const char* pName);
    void FreeName(VmaAllocator hAllocator);
    uint8_t SwapBlockAllocation(VmaAllocator hAllocator, VmaAllocation allocation);
    VmaAllocHandle GetAllocHandle() const;
    VkDeviceSize GetOffset() const;
    VmaPool GetParentPool() const;
    VkDeviceMemory GetMemory() const;
    void* GetMappedData() const;

    void BlockAllocMap();
    void BlockAllocUnmap();
    VkResult DedicatedAllocMap(VmaAllocator hAllocator, void** ppData);
    void DedicatedAllocUnmap(VmaAllocator hAllocator);


    VmaBufferImageUsage GetBufferImageUsage() const { return m_BufferImageUsage; }
    void InitBufferUsage(const VkBufferCreateInfo &createInfo, bool useKhrMaintenance5)
    {
        
# 6385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 6385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       m_BufferImageUsage == VmaBufferImageUsage::UNKNOWN
# 6385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 6385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "m_BufferImageUsage == VmaBufferImageUsage::UNKNOWN"
# 6385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",6385),0))
# 6385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                     ;
        m_BufferImageUsage = VmaBufferImageUsage(createInfo, useKhrMaintenance5);
    }
    void InitImageUsage(const VkImageCreateInfo &createInfo)
    {
        
# 6390 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 6390 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       m_BufferImageUsage == VmaBufferImageUsage::UNKNOWN
# 6390 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 6390 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "m_BufferImageUsage == VmaBufferImageUsage::UNKNOWN"
# 6390 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",6390),0))
# 6390 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                     ;
        m_BufferImageUsage = VmaBufferImageUsage(createInfo);
    }
    void PrintParameters(class VmaJsonWriter& json) const;






private:

    struct BlockAllocation
    {
        VmaDeviceMemoryBlock* m_Block;
        VmaAllocHandle m_AllocHandle;
    };

    struct DedicatedAllocation
    {
        VmaPool m_hParentPool;
        VkDeviceMemory m_hMemory;
        VmaAllocationExtraData* m_ExtraData;
        VmaAllocation_T* m_Prev;
        VmaAllocation_T* m_Next;
    };
    union
    {

        BlockAllocation m_BlockAllocation;

        DedicatedAllocation m_DedicatedAllocation;
    };

    VkDeviceSize m_Alignment;
    VkDeviceSize m_Size;
    void* m_pUserData;
    char* m_pName;
    uint32_t m_MemoryTypeIndex;
    uint8_t m_Type;
    uint8_t m_SuballocationType;

    uint8_t m_MapCount;
    uint8_t m_Flags;

    VmaBufferImageUsage m_BufferImageUsage;


    void EnsureExtraData(VmaAllocator hAllocator);
};



struct VmaDedicatedAllocationListItemTraits
{
    typedef VmaAllocation_T ItemType;

    static ItemType* GetPrev(const ItemType* item)
    {
        ;
        return item->m_DedicatedAllocation.m_Prev;
    }
    static ItemType* GetNext(const ItemType* item)
    {
        ;
        return item->m_DedicatedAllocation.m_Next;
    }
    static ItemType*& AccessPrev(ItemType* item)
    {
        ;
        return item->m_DedicatedAllocation.m_Prev;
    }
    static ItemType*& AccessNext(ItemType* item)
    {
        ;
        return item->m_DedicatedAllocation.m_Next;
    }
};







class VmaDedicatedAllocationList
{
    private: VmaDedicatedAllocationList(const VmaDedicatedAllocationList&) = delete; VmaDedicatedAllocationList(VmaDedicatedAllocationList&&) = delete; VmaDedicatedAllocationList& operator=(const VmaDedicatedAllocationList&) = delete; VmaDedicatedAllocationList& operator=(VmaDedicatedAllocationList&&) = delete;
public:
    VmaDedicatedAllocationList() {}
    ~VmaDedicatedAllocationList();

    void Init(bool useMutex) { m_UseMutex = useMutex; }
    bool Validate();

    void AddDetailedStatistics(VmaDetailedStatistics& inoutStats);
    void AddStatistics(VmaStatistics& inoutStats);


    void BuildStatsString(VmaJsonWriter& json);


    bool IsEmpty();
    void Register(VmaAllocation alloc);
    void Unregister(VmaAllocation alloc);

private:
    typedef VmaIntrusiveLinkedList<VmaDedicatedAllocationListItemTraits> DedicatedAllocationLinkedList;

    bool m_UseMutex = true;
    VmaRWMutex m_Mutex;
    DedicatedAllocationLinkedList m_AllocationList;
};



VmaDedicatedAllocationList::~VmaDedicatedAllocationList()
{
    ;

    if (!m_AllocationList.IsEmpty())
    {
        
# 6512 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 6512 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       false && "Unfreed dedicated allocations found!"
# 6512 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 6512 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "false && \"Unfreed dedicated allocations found!\""
# 6512 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",6512),0))
# 6512 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                       ;
    }
}

bool VmaDedicatedAllocationList::Validate()
{
    const size_t declaredCount = m_AllocationList.GetCount();
    size_t actualCount = 0;
    VmaMutexLockRead lock(m_Mutex, m_UseMutex);
    for (VmaAllocation alloc = m_AllocationList.Front();
        alloc != nullptr; alloc = m_AllocationList.GetNext(alloc))
    {
        ++actualCount;
    }
    do { if(!(actualCount == declaredCount)) { 
# 6526 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 6526 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Validation failed: " "actualCount == declaredCount"
# 6526 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 6526 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Validation failed: \" \"actualCount == declaredCount\""
# 6526 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",6526),0))
# 6526 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   ; return false; } } while(false);

    return true;
}

void VmaDedicatedAllocationList::AddDetailedStatistics(VmaDetailedStatistics& inoutStats)
{
    for(auto* item = m_AllocationList.Front(); item != nullptr; item = DedicatedAllocationLinkedList::GetNext(item))
    {
        const VkDeviceSize size = item->GetSize();
        inoutStats.statistics.blockCount++;
        inoutStats.statistics.blockBytes += size;
        VmaAddDetailedStatisticsAllocation(inoutStats, item->GetSize());
    }
}

void VmaDedicatedAllocationList::AddStatistics(VmaStatistics& inoutStats)
{
    VmaMutexLockRead lock(m_Mutex, m_UseMutex);

    const uint32_t allocCount = (uint32_t)m_AllocationList.GetCount();
    inoutStats.blockCount += allocCount;
    inoutStats.allocationCount += allocCount;

    for(auto* item = m_AllocationList.Front(); item != nullptr; item = DedicatedAllocationLinkedList::GetNext(item))
    {
        const VkDeviceSize size = item->GetSize();
        inoutStats.blockBytes += size;
        inoutStats.allocationBytes += size;
    }
}


void VmaDedicatedAllocationList::BuildStatsString(VmaJsonWriter& json)
{
    VmaMutexLockRead lock(m_Mutex, m_UseMutex);
    json.BeginArray();
    for (VmaAllocation alloc = m_AllocationList.Front();
        alloc != nullptr; alloc = m_AllocationList.GetNext(alloc))
    {
        json.BeginObject(true);
        alloc->PrintParameters(json);
        json.EndObject();
    }
    json.EndArray();
}


bool VmaDedicatedAllocationList::IsEmpty()
{
    VmaMutexLockRead lock(m_Mutex, m_UseMutex);
    return m_AllocationList.IsEmpty();
}

void VmaDedicatedAllocationList::Register(VmaAllocation alloc)
{
    VmaMutexLockWrite lock(m_Mutex, m_UseMutex);
    m_AllocationList.PushBack(alloc);
}

void VmaDedicatedAllocationList::Unregister(VmaAllocation alloc)
{
    VmaMutexLockWrite lock(m_Mutex, m_UseMutex);
    m_AllocationList.Remove(alloc);
}
# 6599 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
struct VmaSuballocation
{
    VkDeviceSize offset;
    VkDeviceSize size;
    void* userData;
    VmaSuballocationType type;
};


struct VmaSuballocationOffsetLess
{
    bool operator()(const VmaSuballocation& lhs, const VmaSuballocation& rhs) const
    {
        return lhs.offset < rhs.offset;
    }
};

struct VmaSuballocationOffsetGreater
{
    bool operator()(const VmaSuballocation& lhs, const VmaSuballocation& rhs) const
    {
        return lhs.offset > rhs.offset;
    }
};

struct VmaSuballocationItemSizeLess
{
    bool operator()(const VmaSuballocationList::iterator lhs,
        const VmaSuballocationList::iterator rhs) const
    {
        return lhs->size < rhs->size;
    }

    bool operator()(const VmaSuballocationList::iterator lhs,
        VkDeviceSize rhsSize) const
    {
        return lhs->size < rhsSize;
    }
};







struct VmaAllocationRequest
{
    VmaAllocHandle allocHandle;
    VkDeviceSize size;
    VmaSuballocationList::iterator item;
    void* customData;
    uint64_t algorithmData;
    VmaAllocationRequestType type;
};







class VmaBlockMetadata
{
    private: VmaBlockMetadata(const VmaBlockMetadata&) = delete; VmaBlockMetadata(VmaBlockMetadata&&) = delete; VmaBlockMetadata& operator=(const VmaBlockMetadata&) = delete; VmaBlockMetadata& operator=(VmaBlockMetadata&&) = delete;
public:

    VmaBlockMetadata(const VkAllocationCallbacks* pAllocationCallbacks,
        VkDeviceSize bufferImageGranularity, bool isVirtual);
    virtual ~VmaBlockMetadata() = default;

    virtual void Init(VkDeviceSize size) { m_Size = size; }
    bool IsVirtual() const { return m_IsVirtual; }
    VkDeviceSize GetSize() const { return m_Size; }


    virtual bool Validate() const = 0;
    virtual size_t GetAllocationCount() const = 0;
    virtual size_t GetFreeRegionsCount() const = 0;
    virtual VkDeviceSize GetSumFreeSize() const = 0;

    virtual bool IsEmpty() const = 0;
    virtual void GetAllocationInfo(VmaAllocHandle allocHandle, VmaVirtualAllocationInfo& outInfo) = 0;
    virtual VkDeviceSize GetAllocationOffset(VmaAllocHandle allocHandle) const = 0;
    virtual void* GetAllocationUserData(VmaAllocHandle allocHandle) const = 0;

    virtual VmaAllocHandle GetAllocationListBegin() const = 0;
    virtual VmaAllocHandle GetNextAllocation(VmaAllocHandle prevAlloc) const = 0;
    virtual VkDeviceSize GetNextFreeRegionSize(VmaAllocHandle alloc) const = 0;


    virtual void AddDetailedStatistics(VmaDetailedStatistics& inoutStats) const = 0;
    virtual void AddStatistics(VmaStatistics& inoutStats) const = 0;


    virtual void PrintDetailedMap(class VmaJsonWriter& json) const = 0;





    virtual bool CreateAllocationRequest(
        VkDeviceSize allocSize,
        VkDeviceSize allocAlignment,
        bool upperAddress,
        VmaSuballocationType allocType,

        uint32_t strategy,
        VmaAllocationRequest* pAllocationRequest) = 0;

    virtual VkResult CheckCorruption(const void* pBlockData) = 0;


    virtual void Alloc(
        const VmaAllocationRequest& request,
        VmaSuballocationType type,
        void* userData) = 0;


    virtual void Free(VmaAllocHandle allocHandle) = 0;



    virtual void Clear() = 0;

    virtual void SetAllocationUserData(VmaAllocHandle allocHandle, void* userData) = 0;
    virtual void DebugLogAllAllocations() const = 0;

protected:
    const VkAllocationCallbacks* GetAllocationCallbacks() const { return m_pAllocationCallbacks; }
    VkDeviceSize GetBufferImageGranularity() const { return m_BufferImageGranularity; }
    VkDeviceSize GetDebugMargin() const { return VkDeviceSize(IsVirtual() ? 0 : (0)); }

    void DebugLogAllocation(VkDeviceSize offset, VkDeviceSize size, void* userData) const;


    void PrintDetailedMap_Begin(class VmaJsonWriter& json,
        VkDeviceSize unusedBytes,
        size_t allocationCount,
        size_t unusedRangeCount) const;
    void PrintDetailedMap_Allocation(class VmaJsonWriter& json,
        VkDeviceSize offset, VkDeviceSize size, void* userData) const;
    void PrintDetailedMap_UnusedRange(class VmaJsonWriter& json,
        VkDeviceSize offset,
        VkDeviceSize size) const;
    void PrintDetailedMap_End(class VmaJsonWriter& json) const;


private:
    VkDeviceSize m_Size;
    const VkAllocationCallbacks* m_pAllocationCallbacks;
    const VkDeviceSize m_BufferImageGranularity;
    const bool m_IsVirtual;
};


VmaBlockMetadata::VmaBlockMetadata(const VkAllocationCallbacks* pAllocationCallbacks,
    VkDeviceSize bufferImageGranularity, bool isVirtual)
    : m_Size(0),
    m_pAllocationCallbacks(pAllocationCallbacks),
    m_BufferImageGranularity(bufferImageGranularity),
    m_IsVirtual(isVirtual) {}

void VmaBlockMetadata::DebugLogAllocation(VkDeviceSize offset, VkDeviceSize size, void* userData) const
{
    if (IsVirtual())
    {
        ;
    }
    else
    {
        
# 6770 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 6770 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       userData != nullptr
# 6770 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 6770 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "userData != nullptr"
# 6770 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",6770),0))
# 6770 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                       ;
        VmaAllocation allocation = reinterpret_cast<VmaAllocation>(userData);

        userData = allocation->GetUserData();
        const char* name = allocation->GetName();


       


                                                              ;





    }

}


void VmaBlockMetadata::PrintDetailedMap_Begin(class VmaJsonWriter& json,
    VkDeviceSize unusedBytes, size_t allocationCount, size_t unusedRangeCount) const
{
    json.WriteString("TotalBytes");
    json.WriteNumber(GetSize());

    json.WriteString("UnusedBytes");
    json.WriteNumber(unusedBytes);

    json.WriteString("Allocations");
    json.WriteNumber((uint64_t)allocationCount);

    json.WriteString("UnusedRanges");
    json.WriteNumber((uint64_t)unusedRangeCount);

    json.WriteString("Suballocations");
    json.BeginArray();
}

void VmaBlockMetadata::PrintDetailedMap_Allocation(class VmaJsonWriter& json,
    VkDeviceSize offset, VkDeviceSize size, void* userData) const
{
    json.BeginObject(true);

    json.WriteString("Offset");
    json.WriteNumber(offset);

    if (IsVirtual())
    {
        json.WriteString("Size");
        json.WriteNumber(size);
        if (userData)
        {
            json.WriteString("CustomData");
            json.BeginString();
            json.ContinueString_Pointer(userData);
            json.EndString();
        }
    }
    else
    {
        ((VmaAllocation)userData)->PrintParameters(json);
    }

    json.EndObject();
}

void VmaBlockMetadata::PrintDetailedMap_UnusedRange(class VmaJsonWriter& json,
    VkDeviceSize offset, VkDeviceSize size) const
{
    json.BeginObject(true);

    json.WriteString("Offset");
    json.WriteNumber(offset);

    json.WriteString("Type");
    json.WriteString(VMA_SUBALLOCATION_TYPE_NAMES[VMA_SUBALLOCATION_TYPE_FREE]);

    json.WriteString("Size");
    json.WriteNumber(size);

    json.EndObject();
}

void VmaBlockMetadata::PrintDetailedMap_End(class VmaJsonWriter& json) const
{
    json.EndArray();
}






class VmaBlockBufferImageGranularity final
{
public:
    struct ValidationContext
    {
        const VkAllocationCallbacks* allocCallbacks;
        uint16_t* pageAllocs;
    };

    VmaBlockBufferImageGranularity(VkDeviceSize bufferImageGranularity);
    ~VmaBlockBufferImageGranularity();

    bool IsEnabled() const { return m_BufferImageGranularity > MAX_LOW_BUFFER_IMAGE_GRANULARITY; }

    void Init(const VkAllocationCallbacks* pAllocationCallbacks, VkDeviceSize size);

    void Destroy(const VkAllocationCallbacks* pAllocationCallbacks);

    void RoundupAllocRequest(VmaSuballocationType allocType,
        VkDeviceSize& inOutAllocSize,
        VkDeviceSize& inOutAllocAlignment) const;

    bool CheckConflictAndAlignUp(VkDeviceSize& inOutAllocOffset,
        VkDeviceSize allocSize,
        VkDeviceSize blockOffset,
        VkDeviceSize blockSize,
        VmaSuballocationType allocType) const;

    void AllocPages(uint8_t allocType, VkDeviceSize offset, VkDeviceSize size);
    void FreePages(VkDeviceSize offset, VkDeviceSize size);
    void Clear();

    ValidationContext StartValidation(const VkAllocationCallbacks* pAllocationCallbacks,
        bool isVirutal) const;
    bool Validate(ValidationContext& ctx, VkDeviceSize offset, VkDeviceSize size) const;
    bool FinishValidation(ValidationContext& ctx) const;

private:
    static const uint16_t MAX_LOW_BUFFER_IMAGE_GRANULARITY = 256;

    struct RegionInfo
    {
        uint8_t allocType;
        uint16_t allocCount;
    };

    VkDeviceSize m_BufferImageGranularity;
    uint32_t m_RegionCount;
    RegionInfo* m_RegionInfo;

    uint32_t GetStartPage(VkDeviceSize offset) const { return OffsetToPageIndex(offset & ~(m_BufferImageGranularity - 1)); }
    uint32_t GetEndPage(VkDeviceSize offset, VkDeviceSize size) const { return OffsetToPageIndex((offset + size - 1) & ~(m_BufferImageGranularity - 1)); }

    uint32_t OffsetToPageIndex(VkDeviceSize offset) const;
    void AllocPage(RegionInfo& page, uint8_t allocType);
};


VmaBlockBufferImageGranularity::VmaBlockBufferImageGranularity(VkDeviceSize bufferImageGranularity)
    : m_BufferImageGranularity(bufferImageGranularity),
    m_RegionCount(0),
    m_RegionInfo(nullptr) {}

VmaBlockBufferImageGranularity::~VmaBlockBufferImageGranularity()
{
    
# 6930 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 6930 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_RegionInfo == nullptr && "Free not called before destroying object!"
# 6930 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 6930 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_RegionInfo == nullptr && \"Free not called before destroying object!\""
# 6930 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",6930),0))
# 6930 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                      ;
}

void VmaBlockBufferImageGranularity::Init(const VkAllocationCallbacks* pAllocationCallbacks, VkDeviceSize size)
{
    if (IsEnabled())
    {
        m_RegionCount = static_cast<uint32_t>(VmaDivideRoundingUp(size, m_BufferImageGranularity));
        m_RegionInfo = new(VmaAllocateArray<RegionInfo>((pAllocationCallbacks), (m_RegionCount)))(RegionInfo);
        memset(m_RegionInfo, 0, m_RegionCount * sizeof(RegionInfo));
    }
}

void VmaBlockBufferImageGranularity::Destroy(const VkAllocationCallbacks* pAllocationCallbacks)
{
    if (m_RegionInfo)
    {
        vma_delete_array(pAllocationCallbacks, m_RegionInfo, m_RegionCount);
        m_RegionInfo = nullptr;
    }
}

void VmaBlockBufferImageGranularity::RoundupAllocRequest(VmaSuballocationType allocType,
    VkDeviceSize& inOutAllocSize,
    VkDeviceSize& inOutAllocAlignment) const
{
    if (m_BufferImageGranularity > 1 &&
        m_BufferImageGranularity <= MAX_LOW_BUFFER_IMAGE_GRANULARITY)
    {
        if (allocType == VMA_SUBALLOCATION_TYPE_UNKNOWN ||
            allocType == VMA_SUBALLOCATION_TYPE_IMAGE_UNKNOWN ||
            allocType == VMA_SUBALLOCATION_TYPE_IMAGE_OPTIMAL)
        {
            inOutAllocAlignment = ((std::max)((inOutAllocAlignment), (m_BufferImageGranularity)));
            inOutAllocSize = VmaAlignUp(inOutAllocSize, m_BufferImageGranularity);
        }
    }
}

bool VmaBlockBufferImageGranularity::CheckConflictAndAlignUp(VkDeviceSize& inOutAllocOffset,
    VkDeviceSize allocSize,
    VkDeviceSize blockOffset,
    VkDeviceSize blockSize,
    VmaSuballocationType allocType) const
{
    if (IsEnabled())
    {
        uint32_t startPage = GetStartPage(inOutAllocOffset);
        if (m_RegionInfo[startPage].allocCount > 0 &&
            VmaIsBufferImageGranularityConflict(static_cast<VmaSuballocationType>(m_RegionInfo[startPage].allocType), allocType))
        {
            inOutAllocOffset = VmaAlignUp(inOutAllocOffset, m_BufferImageGranularity);
            if (blockSize < allocSize + inOutAllocOffset - blockOffset)
                return true;
            ++startPage;
        }
        uint32_t endPage = GetEndPage(inOutAllocOffset, allocSize);
        if (endPage != startPage &&
            m_RegionInfo[endPage].allocCount > 0 &&
            VmaIsBufferImageGranularityConflict(static_cast<VmaSuballocationType>(m_RegionInfo[endPage].allocType), allocType))
        {
            return true;
        }
    }
    return false;
}

void VmaBlockBufferImageGranularity::AllocPages(uint8_t allocType, VkDeviceSize offset, VkDeviceSize size)
{
    if (IsEnabled())
    {
        uint32_t startPage = GetStartPage(offset);
        AllocPage(m_RegionInfo[startPage], allocType);

        uint32_t endPage = GetEndPage(offset, size);
        if (startPage != endPage)
            AllocPage(m_RegionInfo[endPage], allocType);
    }
}

void VmaBlockBufferImageGranularity::FreePages(VkDeviceSize offset, VkDeviceSize size)
{
    if (IsEnabled())
    {
        uint32_t startPage = GetStartPage(offset);
        --m_RegionInfo[startPage].allocCount;
        if (m_RegionInfo[startPage].allocCount == 0)
            m_RegionInfo[startPage].allocType = VMA_SUBALLOCATION_TYPE_FREE;
        uint32_t endPage = GetEndPage(offset, size);
        if (startPage != endPage)
        {
            --m_RegionInfo[endPage].allocCount;
            if (m_RegionInfo[endPage].allocCount == 0)
                m_RegionInfo[endPage].allocType = VMA_SUBALLOCATION_TYPE_FREE;
        }
    }
}

void VmaBlockBufferImageGranularity::Clear()
{
    if (m_RegionInfo)
        memset(m_RegionInfo, 0, m_RegionCount * sizeof(RegionInfo));
}

VmaBlockBufferImageGranularity::ValidationContext VmaBlockBufferImageGranularity::StartValidation(
    const VkAllocationCallbacks* pAllocationCallbacks, bool isVirutal) const
{
    ValidationContext ctx{ pAllocationCallbacks, nullptr };
    if (!isVirutal && IsEnabled())
    {
        ctx.pageAllocs = new(VmaAllocateArray<uint16_t>((pAllocationCallbacks), (m_RegionCount)))(uint16_t);
        memset(ctx.pageAllocs, 0, m_RegionCount * sizeof(uint16_t));
    }
    return ctx;
}

bool VmaBlockBufferImageGranularity::Validate(ValidationContext& ctx,
    VkDeviceSize offset, VkDeviceSize size) const
{
    if (IsEnabled())
    {
        uint32_t start = GetStartPage(offset);
        ++ctx.pageAllocs[start];
        do { if(!(m_RegionInfo[start].allocCount > 0)) { 
# 7053 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 7053 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Validation failed: " "m_RegionInfo[start].allocCount > 0"
# 7053 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 7053 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Validation failed: \" \"m_RegionInfo[start].allocCount > 0\""
# 7053 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7053),0))
# 7053 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       ; return false; } } while(false);

        uint32_t end = GetEndPage(offset, size);
        if (start != end)
        {
            ++ctx.pageAllocs[end];
            do { if(!(m_RegionInfo[end].allocCount > 0)) { 
# 7059 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 7059 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0 && "Validation failed: " "m_RegionInfo[end].allocCount > 0"
# 7059 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 7059 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0 && \"Validation failed: \" \"m_RegionInfo[end].allocCount > 0\""
# 7059 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7059),0))
# 7059 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           ; return false; } } while(false);
        }
    }
    return true;
}

bool VmaBlockBufferImageGranularity::FinishValidation(ValidationContext& ctx) const
{

    if (IsEnabled())
    {
        
# 7070 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 7070 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       ctx.pageAllocs != nullptr && "Validation context not initialized!"
# 7070 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 7070 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "ctx.pageAllocs != nullptr && \"Validation context not initialized!\""
# 7070 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7070),0))
# 7070 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                      ;

        for (uint32_t page = 0; page < m_RegionCount; ++page)
        {
            do { if(!(ctx.pageAllocs[page] == m_RegionInfo[page].allocCount)) { 
# 7074 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 7074 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0 && "Validation failed: " "ctx.pageAllocs[page] == m_RegionInfo[page].allocCount"
# 7074 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 7074 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0 && \"Validation failed: \" \"ctx.pageAllocs[page] == m_RegionInfo[page].allocCount\""
# 7074 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7074),0))
# 7074 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           ; return false; } } while(false);
        }
        vma_delete_array(ctx.allocCallbacks, ctx.pageAllocs, m_RegionCount);
        ctx.pageAllocs = nullptr;
    }
    return true;
}

uint32_t VmaBlockBufferImageGranularity::OffsetToPageIndex(VkDeviceSize offset) const
{
    return static_cast<uint32_t>(offset >> VmaBitScanMSB(m_BufferImageGranularity));
}

void VmaBlockBufferImageGranularity::AllocPage(RegionInfo& page, uint8_t allocType)
{

    if (page.allocCount == 0 || (page.allocCount > 0 && page.allocType == VMA_SUBALLOCATION_TYPE_FREE))
        page.allocType = allocType;

    ++page.allocCount;
}
# 7177 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
class VmaBlockMetadata_Linear : public VmaBlockMetadata
{
    private: VmaBlockMetadata_Linear(const VmaBlockMetadata_Linear&) = delete; VmaBlockMetadata_Linear(VmaBlockMetadata_Linear&&) = delete; VmaBlockMetadata_Linear& operator=(const VmaBlockMetadata_Linear&) = delete; VmaBlockMetadata_Linear& operator=(VmaBlockMetadata_Linear&&) = delete;
public:
    VmaBlockMetadata_Linear(const VkAllocationCallbacks* pAllocationCallbacks,
        VkDeviceSize bufferImageGranularity, bool isVirtual);
    virtual ~VmaBlockMetadata_Linear() = default;

    VkDeviceSize GetSumFreeSize() const override { return m_SumFreeSize; }
    bool IsEmpty() const override { return GetAllocationCount() == 0; }
    VkDeviceSize GetAllocationOffset(VmaAllocHandle allocHandle) const override { return (VkDeviceSize)allocHandle - 1; }

    void Init(VkDeviceSize size) override;
    bool Validate() const override;
    size_t GetAllocationCount() const override;
    size_t GetFreeRegionsCount() const override;

    void AddDetailedStatistics(VmaDetailedStatistics& inoutStats) const override;
    void AddStatistics(VmaStatistics& inoutStats) const override;


    void PrintDetailedMap(class VmaJsonWriter& json) const override;


    bool CreateAllocationRequest(
        VkDeviceSize allocSize,
        VkDeviceSize allocAlignment,
        bool upperAddress,
        VmaSuballocationType allocType,
        uint32_t strategy,
        VmaAllocationRequest* pAllocationRequest) override;

    VkResult CheckCorruption(const void* pBlockData) override;

    void Alloc(
        const VmaAllocationRequest& request,
        VmaSuballocationType type,
        void* userData) override;

    void Free(VmaAllocHandle allocHandle) override;
    void GetAllocationInfo(VmaAllocHandle allocHandle, VmaVirtualAllocationInfo& outInfo) override;
    void* GetAllocationUserData(VmaAllocHandle allocHandle) const override;
    VmaAllocHandle GetAllocationListBegin() const override;
    VmaAllocHandle GetNextAllocation(VmaAllocHandle prevAlloc) const override;
    VkDeviceSize GetNextFreeRegionSize(VmaAllocHandle alloc) const override;
    void Clear() override;
    void SetAllocationUserData(VmaAllocHandle allocHandle, void* userData) override;
    void DebugLogAllAllocations() const override;

private:







    typedef VmaVector<VmaSuballocation, VmaStlAllocator<VmaSuballocation>> SuballocationVectorType;

    enum SECOND_VECTOR_MODE
    {
        SECOND_VECTOR_EMPTY,




        SECOND_VECTOR_RING_BUFFER,





        SECOND_VECTOR_DOUBLE_STACK,
    };

    VkDeviceSize m_SumFreeSize;
    SuballocationVectorType m_Suballocations0, m_Suballocations1;
    uint32_t m_1stVectorIndex;
    SECOND_VECTOR_MODE m_2ndVectorMode;

    size_t m_1stNullItemsBeginCount;

    size_t m_1stNullItemsMiddleCount;

    size_t m_2ndNullItemsCount;

    SuballocationVectorType& AccessSuballocations1st() { return m_1stVectorIndex ? m_Suballocations1 : m_Suballocations0; }
    SuballocationVectorType& AccessSuballocations2nd() { return m_1stVectorIndex ? m_Suballocations0 : m_Suballocations1; }
    const SuballocationVectorType& AccessSuballocations1st() const { return m_1stVectorIndex ? m_Suballocations1 : m_Suballocations0; }
    const SuballocationVectorType& AccessSuballocations2nd() const { return m_1stVectorIndex ? m_Suballocations0 : m_Suballocations1; }

    VmaSuballocation& FindSuballocation(VkDeviceSize offset) const;
    bool ShouldCompact1st() const;
    void CleanupAfterFree();

    bool CreateAllocationRequest_LowerAddress(
        VkDeviceSize allocSize,
        VkDeviceSize allocAlignment,
        VmaSuballocationType allocType,
        uint32_t strategy,
        VmaAllocationRequest* pAllocationRequest);
    bool CreateAllocationRequest_UpperAddress(
        VkDeviceSize allocSize,
        VkDeviceSize allocAlignment,
        VmaSuballocationType allocType,
        uint32_t strategy,
        VmaAllocationRequest* pAllocationRequest);
};


VmaBlockMetadata_Linear::VmaBlockMetadata_Linear(const VkAllocationCallbacks* pAllocationCallbacks,
    VkDeviceSize bufferImageGranularity, bool isVirtual)
    : VmaBlockMetadata(pAllocationCallbacks, bufferImageGranularity, isVirtual),
    m_SumFreeSize(0),
    m_Suballocations0(VmaStlAllocator<VmaSuballocation>(pAllocationCallbacks)),
    m_Suballocations1(VmaStlAllocator<VmaSuballocation>(pAllocationCallbacks)),
    m_1stVectorIndex(0),
    m_2ndVectorMode(SECOND_VECTOR_EMPTY),
    m_1stNullItemsBeginCount(0),
    m_1stNullItemsMiddleCount(0),
    m_2ndNullItemsCount(0) {}

void VmaBlockMetadata_Linear::Init(VkDeviceSize size)
{
    VmaBlockMetadata::Init(size);
    m_SumFreeSize = size;
}

bool VmaBlockMetadata_Linear::Validate() const
{
    const SuballocationVectorType& suballocations1st = AccessSuballocations1st();
    const SuballocationVectorType& suballocations2nd = AccessSuballocations2nd();

    do { if(!(suballocations2nd.empty() == (m_2ndVectorMode == SECOND_VECTOR_EMPTY))) { 
# 7310 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 7310 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Validation failed: " "suballocations2nd.empty() == (m_2ndVectorMode == SECOND_VECTOR_EMPTY)"
# 7310 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 7310 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Validation failed: \" \"suballocations2nd.empty() == (m_2ndVectorMode == SECOND_VECTOR_EMPTY)\""
# 7310 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7310),0))
# 7310 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   ; return false; } } while(false);
    do { if(!(!suballocations1st.empty() || suballocations2nd.empty() || m_2ndVectorMode != SECOND_VECTOR_RING_BUFFER)) { 
# 7311 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 7311 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Validation failed: " "!suballocations1st.empty() || suballocations2nd.empty() || m_2ndVectorMode != SECOND_VECTOR_RING_BUFFER"
# 7311 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 7311 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Validation failed: \" \"!suballocations1st.empty() || suballocations2nd.empty() || m_2ndVectorMode != SECOND_VECTOR_RING_BUFFER\""
# 7311 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7311),0))
# 7311 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   ; return false; } } while(false)

                                                     ;

    if (!suballocations1st.empty())
    {

        do { if(!(suballocations1st[m_1stNullItemsBeginCount].type != VMA_SUBALLOCATION_TYPE_FREE)) { 
# 7318 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 7318 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Validation failed: " "suballocations1st[m_1stNullItemsBeginCount].type != VMA_SUBALLOCATION_TYPE_FREE"
# 7318 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 7318 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Validation failed: \" \"suballocations1st[m_1stNullItemsBeginCount].type != VMA_SUBALLOCATION_TYPE_FREE\""
# 7318 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7318),0))
# 7318 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       ; return false; } } while(false);

        do { if(!(suballocations1st.back().type != VMA_SUBALLOCATION_TYPE_FREE)) { 
# 7320 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 7320 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Validation failed: " "suballocations1st.back().type != VMA_SUBALLOCATION_TYPE_FREE"
# 7320 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 7320 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Validation failed: \" \"suballocations1st.back().type != VMA_SUBALLOCATION_TYPE_FREE\""
# 7320 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7320),0))
# 7320 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       ; return false; } } while(false);
    }
    if (!suballocations2nd.empty())
    {

        do { if(!(suballocations2nd.back().type != VMA_SUBALLOCATION_TYPE_FREE)) { 
# 7325 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 7325 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Validation failed: " "suballocations2nd.back().type != VMA_SUBALLOCATION_TYPE_FREE"
# 7325 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 7325 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Validation failed: \" \"suballocations2nd.back().type != VMA_SUBALLOCATION_TYPE_FREE\""
# 7325 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7325),0))
# 7325 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       ; return false; } } while(false);
    }

    do { if(!(m_1stNullItemsBeginCount + m_1stNullItemsMiddleCount <= suballocations1st.size())) { 
# 7328 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 7328 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Validation failed: " "m_1stNullItemsBeginCount + m_1stNullItemsMiddleCount <= suballocations1st.size()"
# 7328 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 7328 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Validation failed: \" \"m_1stNullItemsBeginCount + m_1stNullItemsMiddleCount <= suballocations1st.size()\""
# 7328 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7328),0))
# 7328 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   ; return false; } } while(false);
    do { if(!(m_2ndNullItemsCount <= suballocations2nd.size())) { 
# 7329 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 7329 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Validation failed: " "m_2ndNullItemsCount <= suballocations2nd.size()"
# 7329 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 7329 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Validation failed: \" \"m_2ndNullItemsCount <= suballocations2nd.size()\""
# 7329 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7329),0))
# 7329 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   ; return false; } } while(false);

    VkDeviceSize sumUsedSize = 0;
    const size_t suballoc1stCount = suballocations1st.size();
    const VkDeviceSize debugMargin = GetDebugMargin();
    VkDeviceSize offset = 0;

    if (m_2ndVectorMode == SECOND_VECTOR_RING_BUFFER)
    {
        const size_t suballoc2ndCount = suballocations2nd.size();
        size_t nullItem2ndCount = 0;
        for (size_t i = 0; i < suballoc2ndCount; ++i)
        {
            const VmaSuballocation& suballoc = suballocations2nd[i];
            const bool currFree = (suballoc.type == VMA_SUBALLOCATION_TYPE_FREE);

            VmaAllocation const alloc = (VmaAllocation)suballoc.userData;
            if (!IsVirtual())
            {
                do { if(!(currFree == (alloc == 
# 7348 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
               nullptr
# 7348 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               ))) { 
# 7348 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 7348 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               0 && "Validation failed: " "currFree == (alloc == VK_NULL_HANDLE)"
# 7348 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 7348 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "0 && \"Validation failed: \" \"currFree == (alloc == VK_NULL_HANDLE)\""
# 7348 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7348),0))
# 7348 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               ; return false; } } while(false);
            }
            do { if(!(suballoc.offset >= offset)) { 
# 7350 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 7350 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0 && "Validation failed: " "suballoc.offset >= offset"
# 7350 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 7350 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0 && \"Validation failed: \" \"suballoc.offset >= offset\""
# 7350 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7350),0))
# 7350 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           ; return false; } } while(false);

            if (!currFree)
            {
                if (!IsVirtual())
                {
                    do { if(!((VkDeviceSize)alloc->GetAllocHandle() == suballoc.offset + 1)) { 
# 7356 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                   (void) ((!!(
# 7356 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                   0 && "Validation failed: " "(VkDeviceSize)alloc->GetAllocHandle() == suballoc.offset + 1"
# 7356 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                   )) || (_assert(
# 7356 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                   "0 && \"Validation failed: \" \"(VkDeviceSize)alloc->GetAllocHandle() == suballoc.offset + 1\""
# 7356 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7356),0))
# 7356 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                   ; return false; } } while(false);
                    do { if(!(alloc->GetSize() == suballoc.size)) { 
# 7357 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                   (void) ((!!(
# 7357 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                   0 && "Validation failed: " "alloc->GetSize() == suballoc.size"
# 7357 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                   )) || (_assert(
# 7357 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                   "0 && \"Validation failed: \" \"alloc->GetSize() == suballoc.size\""
# 7357 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7357),0))
# 7357 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                   ; return false; } } while(false);
                }
                sumUsedSize += suballoc.size;
            }
            else
            {
                ++nullItem2ndCount;
            }

            offset = suballoc.offset + suballoc.size + debugMargin;
        }

        do { if(!(nullItem2ndCount == m_2ndNullItemsCount)) { 
# 7369 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 7369 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Validation failed: " "nullItem2ndCount == m_2ndNullItemsCount"
# 7369 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 7369 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Validation failed: \" \"nullItem2ndCount == m_2ndNullItemsCount\""
# 7369 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7369),0))
# 7369 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       ; return false; } } while(false);
    }

    for (size_t i = 0; i < m_1stNullItemsBeginCount; ++i)
    {
        const VmaSuballocation& suballoc = suballocations1st[i];
        do { if(!(suballoc.type == VMA_SUBALLOCATION_TYPE_FREE && suballoc.userData == nullptr)) { 
# 7375 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 7375 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Validation failed: " "suballoc.type == VMA_SUBALLOCATION_TYPE_FREE && suballoc.userData == VMA_NULL"
# 7375 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 7375 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Validation failed: \" \"suballoc.type == VMA_SUBALLOCATION_TYPE_FREE && suballoc.userData == VMA_NULL\""
# 7375 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7375),0))
# 7375 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       ; return false; } } while(false)
                                          ;
    }

    size_t nullItem1stCount = m_1stNullItemsBeginCount;

    for (size_t i = m_1stNullItemsBeginCount; i < suballoc1stCount; ++i)
    {
        const VmaSuballocation& suballoc = suballocations1st[i];
        const bool currFree = (suballoc.type == VMA_SUBALLOCATION_TYPE_FREE);

        VmaAllocation const alloc = (VmaAllocation)suballoc.userData;
        if (!IsVirtual())
        {
            do { if(!(currFree == (alloc == 
# 7389 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
           nullptr
# 7389 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           ))) { 
# 7389 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 7389 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0 && "Validation failed: " "currFree == (alloc == VK_NULL_HANDLE)"
# 7389 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 7389 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0 && \"Validation failed: \" \"currFree == (alloc == VK_NULL_HANDLE)\""
# 7389 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7389),0))
# 7389 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           ; return false; } } while(false);
        }
        do { if(!(suballoc.offset >= offset)) { 
# 7391 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 7391 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Validation failed: " "suballoc.offset >= offset"
# 7391 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 7391 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Validation failed: \" \"suballoc.offset >= offset\""
# 7391 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7391),0))
# 7391 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       ; return false; } } while(false);
        do { if(!(i >= m_1stNullItemsBeginCount || currFree)) { 
# 7392 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 7392 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Validation failed: " "i >= m_1stNullItemsBeginCount || currFree"
# 7392 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 7392 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Validation failed: \" \"i >= m_1stNullItemsBeginCount || currFree\""
# 7392 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7392),0))
# 7392 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       ; return false; } } while(false);

        if (!currFree)
        {
            if (!IsVirtual())
            {
                do { if(!((VkDeviceSize)alloc->GetAllocHandle() == suballoc.offset + 1)) { 
# 7398 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 7398 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               0 && "Validation failed: " "(VkDeviceSize)alloc->GetAllocHandle() == suballoc.offset + 1"
# 7398 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 7398 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "0 && \"Validation failed: \" \"(VkDeviceSize)alloc->GetAllocHandle() == suballoc.offset + 1\""
# 7398 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7398),0))
# 7398 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               ; return false; } } while(false);
                do { if(!(alloc->GetSize() == suballoc.size)) { 
# 7399 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 7399 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               0 && "Validation failed: " "alloc->GetSize() == suballoc.size"
# 7399 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 7399 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "0 && \"Validation failed: \" \"alloc->GetSize() == suballoc.size\""
# 7399 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7399),0))
# 7399 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               ; return false; } } while(false);
            }
            sumUsedSize += suballoc.size;
        }
        else
        {
            ++nullItem1stCount;
        }

        offset = suballoc.offset + suballoc.size + debugMargin;
    }
    do { if(!(nullItem1stCount == m_1stNullItemsBeginCount + m_1stNullItemsMiddleCount)) { 
# 7410 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 7410 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Validation failed: " "nullItem1stCount == m_1stNullItemsBeginCount + m_1stNullItemsMiddleCount"
# 7410 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 7410 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Validation failed: \" \"nullItem1stCount == m_1stNullItemsBeginCount + m_1stNullItemsMiddleCount\""
# 7410 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7410),0))
# 7410 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   ; return false; } } while(false);

    if (m_2ndVectorMode == SECOND_VECTOR_DOUBLE_STACK)
    {
        const size_t suballoc2ndCount = suballocations2nd.size();
        size_t nullItem2ndCount = 0;
        for (size_t i = suballoc2ndCount; i--; )
        {
            const VmaSuballocation& suballoc = suballocations2nd[i];
            const bool currFree = (suballoc.type == VMA_SUBALLOCATION_TYPE_FREE);

            VmaAllocation const alloc = (VmaAllocation)suballoc.userData;
            if (!IsVirtual())
            {
                do { if(!(currFree == (alloc == 
# 7424 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
               nullptr
# 7424 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               ))) { 
# 7424 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 7424 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               0 && "Validation failed: " "currFree == (alloc == VK_NULL_HANDLE)"
# 7424 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 7424 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "0 && \"Validation failed: \" \"currFree == (alloc == VK_NULL_HANDLE)\""
# 7424 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7424),0))
# 7424 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               ; return false; } } while(false);
            }
            do { if(!(suballoc.offset >= offset)) { 
# 7426 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 7426 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0 && "Validation failed: " "suballoc.offset >= offset"
# 7426 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 7426 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0 && \"Validation failed: \" \"suballoc.offset >= offset\""
# 7426 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7426),0))
# 7426 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           ; return false; } } while(false);

            if (!currFree)
            {
                if (!IsVirtual())
                {
                    do { if(!((VkDeviceSize)alloc->GetAllocHandle() == suballoc.offset + 1)) { 
# 7432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                   (void) ((!!(
# 7432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                   0 && "Validation failed: " "(VkDeviceSize)alloc->GetAllocHandle() == suballoc.offset + 1"
# 7432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                   )) || (_assert(
# 7432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                   "0 && \"Validation failed: \" \"(VkDeviceSize)alloc->GetAllocHandle() == suballoc.offset + 1\""
# 7432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7432),0))
# 7432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                   ; return false; } } while(false);
                    do { if(!(alloc->GetSize() == suballoc.size)) { 
# 7433 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                   (void) ((!!(
# 7433 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                   0 && "Validation failed: " "alloc->GetSize() == suballoc.size"
# 7433 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                   )) || (_assert(
# 7433 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                   "0 && \"Validation failed: \" \"alloc->GetSize() == suballoc.size\""
# 7433 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7433),0))
# 7433 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                   ; return false; } } while(false);
                }
                sumUsedSize += suballoc.size;
            }
            else
            {
                ++nullItem2ndCount;
            }

            offset = suballoc.offset + suballoc.size + debugMargin;
        }

        do { if(!(nullItem2ndCount == m_2ndNullItemsCount)) { 
# 7445 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 7445 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Validation failed: " "nullItem2ndCount == m_2ndNullItemsCount"
# 7445 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 7445 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Validation failed: \" \"nullItem2ndCount == m_2ndNullItemsCount\""
# 7445 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7445),0))
# 7445 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       ; return false; } } while(false);
    }

    do { if(!(offset <= GetSize())) { 
# 7448 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 7448 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Validation failed: " "offset <= GetSize()"
# 7448 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 7448 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Validation failed: \" \"offset <= GetSize()\""
# 7448 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7448),0))
# 7448 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   ; return false; } } while(false);
    do { if(!(m_SumFreeSize == GetSize() - sumUsedSize)) { 
# 7449 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 7449 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Validation failed: " "m_SumFreeSize == GetSize() - sumUsedSize"
# 7449 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 7449 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Validation failed: \" \"m_SumFreeSize == GetSize() - sumUsedSize\""
# 7449 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7449),0))
# 7449 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   ; return false; } } while(false);

    return true;
}

size_t VmaBlockMetadata_Linear::GetAllocationCount() const
{
    return AccessSuballocations1st().size() - m_1stNullItemsBeginCount - m_1stNullItemsMiddleCount +
        AccessSuballocations2nd().size() - m_2ndNullItemsCount;
}

size_t VmaBlockMetadata_Linear::GetFreeRegionsCount() const
{

    
# 7463 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 7463 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0
# 7463 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 7463 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0"
# 7463 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",7463),0))
# 7463 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                ;
    return 
# 7464 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
          0xffffffffffffffffULL
# 7464 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                  ;
}

void VmaBlockMetadata_Linear::AddDetailedStatistics(VmaDetailedStatistics& inoutStats) const
{
    const VkDeviceSize size = GetSize();
    const SuballocationVectorType& suballocations1st = AccessSuballocations1st();
    const SuballocationVectorType& suballocations2nd = AccessSuballocations2nd();
    const size_t suballoc1stCount = suballocations1st.size();
    const size_t suballoc2ndCount = suballocations2nd.size();

    inoutStats.statistics.blockCount++;
    inoutStats.statistics.blockBytes += size;

    VkDeviceSize lastOffset = 0;

    if (m_2ndVectorMode == SECOND_VECTOR_RING_BUFFER)
    {
        const VkDeviceSize freeSpace2ndTo1stEnd = suballocations1st[m_1stNullItemsBeginCount].offset;
        size_t nextAlloc2ndIndex = 0;
        while (lastOffset < freeSpace2ndTo1stEnd)
        {

            while (nextAlloc2ndIndex < suballoc2ndCount &&
                suballocations2nd[nextAlloc2ndIndex].userData == nullptr)
            {
                ++nextAlloc2ndIndex;
            }


            if (nextAlloc2ndIndex < suballoc2ndCount)
            {
                const VmaSuballocation& suballoc = suballocations2nd[nextAlloc2ndIndex];


                if (lastOffset < suballoc.offset)
                {

                    const VkDeviceSize unusedRangeSize = suballoc.offset - lastOffset;
                    VmaAddDetailedStatisticsUnusedRange(inoutStats, unusedRangeSize);
                }



                VmaAddDetailedStatisticsAllocation(inoutStats, suballoc.size);


                lastOffset = suballoc.offset + suballoc.size;
                ++nextAlloc2ndIndex;
            }

            else
            {

                if (lastOffset < freeSpace2ndTo1stEnd)
                {
                    const VkDeviceSize unusedRangeSize = freeSpace2ndTo1stEnd - lastOffset;
                    VmaAddDetailedStatisticsUnusedRange(inoutStats, unusedRangeSize);
                }


                lastOffset = freeSpace2ndTo1stEnd;
            }
        }
    }

    size_t nextAlloc1stIndex = m_1stNullItemsBeginCount;
    const VkDeviceSize freeSpace1stTo2ndEnd =
        m_2ndVectorMode == SECOND_VECTOR_DOUBLE_STACK ? suballocations2nd.back().offset : size;
    while (lastOffset < freeSpace1stTo2ndEnd)
    {

        while (nextAlloc1stIndex < suballoc1stCount &&
            suballocations1st[nextAlloc1stIndex].userData == nullptr)
        {
            ++nextAlloc1stIndex;
        }


        if (nextAlloc1stIndex < suballoc1stCount)
        {
            const VmaSuballocation& suballoc = suballocations1st[nextAlloc1stIndex];


            if (lastOffset < suballoc.offset)
            {

                const VkDeviceSize unusedRangeSize = suballoc.offset - lastOffset;
                VmaAddDetailedStatisticsUnusedRange(inoutStats, unusedRangeSize);
            }



            VmaAddDetailedStatisticsAllocation(inoutStats, suballoc.size);


            lastOffset = suballoc.offset + suballoc.size;
            ++nextAlloc1stIndex;
        }

        else
        {

            if (lastOffset < freeSpace1stTo2ndEnd)
            {
                const VkDeviceSize unusedRangeSize = freeSpace1stTo2ndEnd - lastOffset;
                VmaAddDetailedStatisticsUnusedRange(inoutStats, unusedRangeSize);
            }


            lastOffset = freeSpace1stTo2ndEnd;
        }
    }

    if (m_2ndVectorMode == SECOND_VECTOR_DOUBLE_STACK)
    {
        size_t nextAlloc2ndIndex = suballocations2nd.size() - 1;
        while (lastOffset < size)
        {

            while (nextAlloc2ndIndex != 
# 7584 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                       0xffffffffffffffffULL 
# 7584 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                &&
                suballocations2nd[nextAlloc2ndIndex].userData == nullptr)
            {
                --nextAlloc2ndIndex;
            }


            if (nextAlloc2ndIndex != 
# 7591 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                    0xffffffffffffffffULL
# 7591 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                            )
            {
                const VmaSuballocation& suballoc = suballocations2nd[nextAlloc2ndIndex];


                if (lastOffset < suballoc.offset)
                {

                    const VkDeviceSize unusedRangeSize = suballoc.offset - lastOffset;
                    VmaAddDetailedStatisticsUnusedRange(inoutStats, unusedRangeSize);
                }



                VmaAddDetailedStatisticsAllocation(inoutStats, suballoc.size);


                lastOffset = suballoc.offset + suballoc.size;
                --nextAlloc2ndIndex;
            }

            else
            {

                if (lastOffset < size)
                {
                    const VkDeviceSize unusedRangeSize = size - lastOffset;
                    VmaAddDetailedStatisticsUnusedRange(inoutStats, unusedRangeSize);
                }


                lastOffset = size;
            }
        }
    }
}

void VmaBlockMetadata_Linear::AddStatistics(VmaStatistics& inoutStats) const
{
    const SuballocationVectorType& suballocations1st = AccessSuballocations1st();
    const SuballocationVectorType& suballocations2nd = AccessSuballocations2nd();
    const VkDeviceSize size = GetSize();
    const size_t suballoc1stCount = suballocations1st.size();
    const size_t suballoc2ndCount = suballocations2nd.size();

    inoutStats.blockCount++;
    inoutStats.blockBytes += size;
    inoutStats.allocationBytes += size - m_SumFreeSize;

    VkDeviceSize lastOffset = 0;

    if (m_2ndVectorMode == SECOND_VECTOR_RING_BUFFER)
    {
        const VkDeviceSize freeSpace2ndTo1stEnd = suballocations1st[m_1stNullItemsBeginCount].offset;
        size_t nextAlloc2ndIndex = m_1stNullItemsBeginCount;
        while (lastOffset < freeSpace2ndTo1stEnd)
        {

            while (nextAlloc2ndIndex < suballoc2ndCount &&
                suballocations2nd[nextAlloc2ndIndex].userData == nullptr)
            {
                ++nextAlloc2ndIndex;
            }


            if (nextAlloc2ndIndex < suballoc2ndCount)
            {
                const VmaSuballocation& suballoc = suballocations2nd[nextAlloc2ndIndex];



                ++inoutStats.allocationCount;


                lastOffset = suballoc.offset + suballoc.size;
                ++nextAlloc2ndIndex;
            }

            else
            {

                lastOffset = freeSpace2ndTo1stEnd;
            }
        }
    }

    size_t nextAlloc1stIndex = m_1stNullItemsBeginCount;
    const VkDeviceSize freeSpace1stTo2ndEnd =
        m_2ndVectorMode == SECOND_VECTOR_DOUBLE_STACK ? suballocations2nd.back().offset : size;
    while (lastOffset < freeSpace1stTo2ndEnd)
    {

        while (nextAlloc1stIndex < suballoc1stCount &&
            suballocations1st[nextAlloc1stIndex].userData == nullptr)
        {
            ++nextAlloc1stIndex;
        }


        if (nextAlloc1stIndex < suballoc1stCount)
        {
            const VmaSuballocation& suballoc = suballocations1st[nextAlloc1stIndex];



            ++inoutStats.allocationCount;


            lastOffset = suballoc.offset + suballoc.size;
            ++nextAlloc1stIndex;
        }

        else
        {

            lastOffset = freeSpace1stTo2ndEnd;
        }
    }

    if (m_2ndVectorMode == SECOND_VECTOR_DOUBLE_STACK)
    {
        size_t nextAlloc2ndIndex = suballocations2nd.size() - 1;
        while (lastOffset < size)
        {

            while (nextAlloc2ndIndex != 
# 7716 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                       0xffffffffffffffffULL 
# 7716 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                &&
                suballocations2nd[nextAlloc2ndIndex].userData == nullptr)
            {
                --nextAlloc2ndIndex;
            }


            if (nextAlloc2ndIndex != 
# 7723 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                    0xffffffffffffffffULL
# 7723 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                            )
            {
                const VmaSuballocation& suballoc = suballocations2nd[nextAlloc2ndIndex];



                ++inoutStats.allocationCount;


                lastOffset = suballoc.offset + suballoc.size;
                --nextAlloc2ndIndex;
            }

            else
            {

                lastOffset = size;
            }
        }
    }
}


void VmaBlockMetadata_Linear::PrintDetailedMap(class VmaJsonWriter& json) const
{
    const VkDeviceSize size = GetSize();
    const SuballocationVectorType& suballocations1st = AccessSuballocations1st();
    const SuballocationVectorType& suballocations2nd = AccessSuballocations2nd();
    const size_t suballoc1stCount = suballocations1st.size();
    const size_t suballoc2ndCount = suballocations2nd.size();



    size_t unusedRangeCount = 0;
    VkDeviceSize usedBytes = 0;

    VkDeviceSize lastOffset = 0;

    size_t alloc2ndCount = 0;
    if (m_2ndVectorMode == SECOND_VECTOR_RING_BUFFER)
    {
        const VkDeviceSize freeSpace2ndTo1stEnd = suballocations1st[m_1stNullItemsBeginCount].offset;
        size_t nextAlloc2ndIndex = 0;
        while (lastOffset < freeSpace2ndTo1stEnd)
        {

            while (nextAlloc2ndIndex < suballoc2ndCount &&
                suballocations2nd[nextAlloc2ndIndex].userData == nullptr)
            {
                ++nextAlloc2ndIndex;
            }


            if (nextAlloc2ndIndex < suballoc2ndCount)
            {
                const VmaSuballocation& suballoc = suballocations2nd[nextAlloc2ndIndex];


                if (lastOffset < suballoc.offset)
                {

                    ++unusedRangeCount;
                }



                ++alloc2ndCount;
                usedBytes += suballoc.size;


                lastOffset = suballoc.offset + suballoc.size;
                ++nextAlloc2ndIndex;
            }

            else
            {
                if (lastOffset < freeSpace2ndTo1stEnd)
                {

                    ++unusedRangeCount;
                }


                lastOffset = freeSpace2ndTo1stEnd;
            }
        }
    }

    size_t nextAlloc1stIndex = m_1stNullItemsBeginCount;
    size_t alloc1stCount = 0;
    const VkDeviceSize freeSpace1stTo2ndEnd =
        m_2ndVectorMode == SECOND_VECTOR_DOUBLE_STACK ? suballocations2nd.back().offset : size;
    while (lastOffset < freeSpace1stTo2ndEnd)
    {

        while (nextAlloc1stIndex < suballoc1stCount &&
            suballocations1st[nextAlloc1stIndex].userData == nullptr)
        {
            ++nextAlloc1stIndex;
        }


        if (nextAlloc1stIndex < suballoc1stCount)
        {
            const VmaSuballocation& suballoc = suballocations1st[nextAlloc1stIndex];


            if (lastOffset < suballoc.offset)
            {

                ++unusedRangeCount;
            }



            ++alloc1stCount;
            usedBytes += suballoc.size;


            lastOffset = suballoc.offset + suballoc.size;
            ++nextAlloc1stIndex;
        }

        else
        {
            if (lastOffset < freeSpace1stTo2ndEnd)
            {

                ++unusedRangeCount;
            }


            lastOffset = freeSpace1stTo2ndEnd;
        }
    }

    if (m_2ndVectorMode == SECOND_VECTOR_DOUBLE_STACK)
    {
        size_t nextAlloc2ndIndex = suballocations2nd.size() - 1;
        while (lastOffset < size)
        {

            while (nextAlloc2ndIndex != 
# 7865 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                       0xffffffffffffffffULL 
# 7865 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                &&
                suballocations2nd[nextAlloc2ndIndex].userData == nullptr)
            {
                --nextAlloc2ndIndex;
            }


            if (nextAlloc2ndIndex != 
# 7872 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                    0xffffffffffffffffULL
# 7872 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                            )
            {
                const VmaSuballocation& suballoc = suballocations2nd[nextAlloc2ndIndex];


                if (lastOffset < suballoc.offset)
                {

                    ++unusedRangeCount;
                }



                ++alloc2ndCount;
                usedBytes += suballoc.size;


                lastOffset = suballoc.offset + suballoc.size;
                --nextAlloc2ndIndex;
            }

            else
            {
                if (lastOffset < size)
                {

                    ++unusedRangeCount;
                }


                lastOffset = size;
            }
        }
    }

    const VkDeviceSize unusedBytes = size - usedBytes;
    PrintDetailedMap_Begin(json, unusedBytes, alloc1stCount + alloc2ndCount, unusedRangeCount);


    lastOffset = 0;

    if (m_2ndVectorMode == SECOND_VECTOR_RING_BUFFER)
    {
        const VkDeviceSize freeSpace2ndTo1stEnd = suballocations1st[m_1stNullItemsBeginCount].offset;
        size_t nextAlloc2ndIndex = 0;
        while (lastOffset < freeSpace2ndTo1stEnd)
        {

            while (nextAlloc2ndIndex < suballoc2ndCount &&
                suballocations2nd[nextAlloc2ndIndex].userData == nullptr)
            {
                ++nextAlloc2ndIndex;
            }


            if (nextAlloc2ndIndex < suballoc2ndCount)
            {
                const VmaSuballocation& suballoc = suballocations2nd[nextAlloc2ndIndex];


                if (lastOffset < suballoc.offset)
                {

                    const VkDeviceSize unusedRangeSize = suballoc.offset - lastOffset;
                    PrintDetailedMap_UnusedRange(json, lastOffset, unusedRangeSize);
                }



                PrintDetailedMap_Allocation(json, suballoc.offset, suballoc.size, suballoc.userData);


                lastOffset = suballoc.offset + suballoc.size;
                ++nextAlloc2ndIndex;
            }

            else
            {
                if (lastOffset < freeSpace2ndTo1stEnd)
                {

                    const VkDeviceSize unusedRangeSize = freeSpace2ndTo1stEnd - lastOffset;
                    PrintDetailedMap_UnusedRange(json, lastOffset, unusedRangeSize);
                }


                lastOffset = freeSpace2ndTo1stEnd;
            }
        }
    }

    nextAlloc1stIndex = m_1stNullItemsBeginCount;
    while (lastOffset < freeSpace1stTo2ndEnd)
    {

        while (nextAlloc1stIndex < suballoc1stCount &&
            suballocations1st[nextAlloc1stIndex].userData == nullptr)
        {
            ++nextAlloc1stIndex;
        }


        if (nextAlloc1stIndex < suballoc1stCount)
        {
            const VmaSuballocation& suballoc = suballocations1st[nextAlloc1stIndex];


            if (lastOffset < suballoc.offset)
            {

                const VkDeviceSize unusedRangeSize = suballoc.offset - lastOffset;
                PrintDetailedMap_UnusedRange(json, lastOffset, unusedRangeSize);
            }



            PrintDetailedMap_Allocation(json, suballoc.offset, suballoc.size, suballoc.userData);


            lastOffset = suballoc.offset + suballoc.size;
            ++nextAlloc1stIndex;
        }

        else
        {
            if (lastOffset < freeSpace1stTo2ndEnd)
            {

                const VkDeviceSize unusedRangeSize = freeSpace1stTo2ndEnd - lastOffset;
                PrintDetailedMap_UnusedRange(json, lastOffset, unusedRangeSize);
            }


            lastOffset = freeSpace1stTo2ndEnd;
        }
    }

    if (m_2ndVectorMode == SECOND_VECTOR_DOUBLE_STACK)
    {
        size_t nextAlloc2ndIndex = suballocations2nd.size() - 1;
        while (lastOffset < size)
        {

            while (nextAlloc2ndIndex != 
# 8015 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                       0xffffffffffffffffULL 
# 8015 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                &&
                suballocations2nd[nextAlloc2ndIndex].userData == nullptr)
            {
                --nextAlloc2ndIndex;
            }


            if (nextAlloc2ndIndex != 
# 8022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                    0xffffffffffffffffULL
# 8022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                            )
            {
                const VmaSuballocation& suballoc = suballocations2nd[nextAlloc2ndIndex];


                if (lastOffset < suballoc.offset)
                {

                    const VkDeviceSize unusedRangeSize = suballoc.offset - lastOffset;
                    PrintDetailedMap_UnusedRange(json, lastOffset, unusedRangeSize);
                }



                PrintDetailedMap_Allocation(json, suballoc.offset, suballoc.size, suballoc.userData);


                lastOffset = suballoc.offset + suballoc.size;
                --nextAlloc2ndIndex;
            }

            else
            {
                if (lastOffset < size)
                {

                    const VkDeviceSize unusedRangeSize = size - lastOffset;
                    PrintDetailedMap_UnusedRange(json, lastOffset, unusedRangeSize);
                }


                lastOffset = size;
            }
        }
    }

    PrintDetailedMap_End(json);
}


bool VmaBlockMetadata_Linear::CreateAllocationRequest(
    VkDeviceSize allocSize,
    VkDeviceSize allocAlignment,
    bool upperAddress,
    VmaSuballocationType allocType,
    uint32_t strategy,
    VmaAllocationRequest* pAllocationRequest)
{
    
# 8070 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 8070 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocSize > 0
# 8070 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 8070 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocSize > 0"
# 8070 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8070),0))
# 8070 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            ;
    
# 8071 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 8071 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocType != VMA_SUBALLOCATION_TYPE_FREE
# 8071 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 8071 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocType != VMA_SUBALLOCATION_TYPE_FREE"
# 8071 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8071),0))
# 8071 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                       ;
    
# 8072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 8072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pAllocationRequest != nullptr
# 8072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 8072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pAllocationRequest != nullptr"
# 8072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8072),0))
# 8072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                             ;
    ;

    if(allocSize > GetSize())
        return false;

    pAllocationRequest->size = allocSize;
    return upperAddress ?
        CreateAllocationRequest_UpperAddress(
            allocSize, allocAlignment, allocType, strategy, pAllocationRequest) :
        CreateAllocationRequest_LowerAddress(
            allocSize, allocAlignment, allocType, strategy, pAllocationRequest);
}

VkResult VmaBlockMetadata_Linear::CheckCorruption(const void* pBlockData)
{
    
# 8088 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 8088 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !IsVirtual()
# 8088 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 8088 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!IsVirtual()"
# 8088 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8088),0))
# 8088 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                           ;
    SuballocationVectorType& suballocations1st = AccessSuballocations1st();
    for (size_t i = m_1stNullItemsBeginCount, count = suballocations1st.size(); i < count; ++i)
    {
        const VmaSuballocation& suballoc = suballocations1st[i];
        if (suballoc.type != VMA_SUBALLOCATION_TYPE_FREE)
        {
            if (!VmaValidateMagicValue(pBlockData, suballoc.offset + suballoc.size))
            {
                
# 8097 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 8097 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               0 && "MEMORY CORRUPTION DETECTED AFTER VALIDATED ALLOCATION!"
# 8097 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 8097 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "0 && \"MEMORY CORRUPTION DETECTED AFTER VALIDATED ALLOCATION!\""
# 8097 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8097),0))
# 8097 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                        ;
                return ((VkResult)-13);
            }
        }
    }

    SuballocationVectorType& suballocations2nd = AccessSuballocations2nd();
    for (size_t i = 0, count = suballocations2nd.size(); i < count; ++i)
    {
        const VmaSuballocation& suballoc = suballocations2nd[i];
        if (suballoc.type != VMA_SUBALLOCATION_TYPE_FREE)
        {
            if (!VmaValidateMagicValue(pBlockData, suballoc.offset + suballoc.size))
            {
                
# 8111 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 8111 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               0 && "MEMORY CORRUPTION DETECTED AFTER VALIDATED ALLOCATION!"
# 8111 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 8111 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "0 && \"MEMORY CORRUPTION DETECTED AFTER VALIDATED ALLOCATION!\""
# 8111 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8111),0))
# 8111 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                        ;
                return ((VkResult)-13);
            }
        }
    }

    return VK_SUCCESS;
}

void VmaBlockMetadata_Linear::Alloc(
    const VmaAllocationRequest& request,
    VmaSuballocationType type,
    void* userData)
{
    const VkDeviceSize offset = (VkDeviceSize)request.allocHandle - 1;
    const VmaSuballocation newSuballoc = { offset, request.size, userData, type };

    switch (request.type)
    {
    case VmaAllocationRequestType::UpperAddress:
    {
        
# 8132 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 8132 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       m_2ndVectorMode != SECOND_VECTOR_RING_BUFFER && "CRITICAL ERROR: Trying to use linear allocator as double stack while it was already used as ring buffer."
# 8132 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 8132 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "m_2ndVectorMode != SECOND_VECTOR_RING_BUFFER && \"CRITICAL ERROR: Trying to use linear allocator as double stack while it was already used as ring buffer.\""
# 8132 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8132),0))
                                                                                                                       
# 8133 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                      ;
        SuballocationVectorType& suballocations2nd = AccessSuballocations2nd();
        suballocations2nd.push_back(newSuballoc);
        m_2ndVectorMode = SECOND_VECTOR_DOUBLE_STACK;
    }
    break;
    case VmaAllocationRequestType::EndOf1st:
    {
        SuballocationVectorType& suballocations1st = AccessSuballocations1st();

        
# 8143 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 8143 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       suballocations1st.empty() || offset >= suballocations1st.back().offset + suballocations1st.back().size
# 8143 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 8143 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "suballocations1st.empty() || offset >= suballocations1st.back().offset + suballocations1st.back().size"
# 8143 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8143),0))
                                                                                      
# 8144 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                     ;

        
# 8146 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 8146 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       offset + request.size <= GetSize()
# 8146 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 8146 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "offset + request.size <= GetSize()"
# 8146 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8146),0))
# 8146 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                     ;

        suballocations1st.push_back(newSuballoc);
    }
    break;
    case VmaAllocationRequestType::EndOf2nd:
    {
        SuballocationVectorType& suballocations1st = AccessSuballocations1st();

        
# 8155 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 8155 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       !suballocations1st.empty() && offset + request.size <= suballocations1st[m_1stNullItemsBeginCount].offset
# 8155 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 8155 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "!suballocations1st.empty() && offset + request.size <= suballocations1st[m_1stNullItemsBeginCount].offset"
# 8155 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8155),0))
                                                                                        
# 8156 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                       ;
        SuballocationVectorType& suballocations2nd = AccessSuballocations2nd();

        switch (m_2ndVectorMode)
        {
        case SECOND_VECTOR_EMPTY:

            
# 8163 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 8163 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           suballocations2nd.empty()
# 8163 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 8163 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "suballocations2nd.empty()"
# 8163 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8163),0))
# 8163 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                ;
            m_2ndVectorMode = SECOND_VECTOR_RING_BUFFER;
            break;
        case SECOND_VECTOR_RING_BUFFER:

            
# 8168 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 8168 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           !suballocations2nd.empty()
# 8168 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 8168 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "!suballocations2nd.empty()"
# 8168 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8168),0))
# 8168 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                 ;
            break;
        case SECOND_VECTOR_DOUBLE_STACK:
            
# 8171 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 8171 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0 && "CRITICAL ERROR: Trying to use linear allocator as ring buffer while it was already used as double stack."
# 8171 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 8171 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0 && \"CRITICAL ERROR: Trying to use linear allocator as ring buffer while it was already used as double stack.\""
# 8171 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8171),0))
# 8171 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                      ;
            break;
        default:
            
# 8174 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 8174 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0
# 8174 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 8174 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0"
# 8174 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8174),0))
# 8174 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;
        }

        suballocations2nd.push_back(newSuballoc);
    }
    break;
    default:
        
# 8181 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 8181 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "CRITICAL INTERNAL ERROR."
# 8181 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 8181 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"CRITICAL INTERNAL ERROR.\""
# 8181 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8181),0))
# 8181 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                  ;
    }

    m_SumFreeSize -= newSuballoc.size;
}

void VmaBlockMetadata_Linear::Free(VmaAllocHandle allocHandle)
{
    SuballocationVectorType& suballocations1st = AccessSuballocations1st();
    SuballocationVectorType& suballocations2nd = AccessSuballocations2nd();
    VkDeviceSize offset = (VkDeviceSize)allocHandle - 1;

    if (!suballocations1st.empty())
    {

        VmaSuballocation& firstSuballoc = suballocations1st[m_1stNullItemsBeginCount];
        if (firstSuballoc.offset == offset)
        {
            firstSuballoc.type = VMA_SUBALLOCATION_TYPE_FREE;
            firstSuballoc.userData = nullptr;
            m_SumFreeSize += firstSuballoc.size;
            ++m_1stNullItemsBeginCount;
            CleanupAfterFree();
            return;
        }
    }


    if (m_2ndVectorMode == SECOND_VECTOR_RING_BUFFER ||
        m_2ndVectorMode == SECOND_VECTOR_DOUBLE_STACK)
    {
        VmaSuballocation& lastSuballoc = suballocations2nd.back();
        if (lastSuballoc.offset == offset)
        {
            m_SumFreeSize += lastSuballoc.size;
            suballocations2nd.pop_back();
            CleanupAfterFree();
            return;
        }
    }

    else if (m_2ndVectorMode == SECOND_VECTOR_EMPTY)
    {
        VmaSuballocation& lastSuballoc = suballocations1st.back();
        if (lastSuballoc.offset == offset)
        {
            m_SumFreeSize += lastSuballoc.size;
            suballocations1st.pop_back();
            CleanupAfterFree();
            return;
        }
    }

    VmaSuballocation refSuballoc;
    refSuballoc.offset = offset;



    {
        const SuballocationVectorType::iterator it = VmaBinaryFindSorted(
            suballocations1st.begin() + m_1stNullItemsBeginCount,
            suballocations1st.end(),
            refSuballoc,
            VmaSuballocationOffsetLess());
        if (it != suballocations1st.end())
        {
            it->type = VMA_SUBALLOCATION_TYPE_FREE;
            it->userData = nullptr;
            ++m_1stNullItemsMiddleCount;
            m_SumFreeSize += it->size;
            CleanupAfterFree();
            return;
        }
    }

    if (m_2ndVectorMode != SECOND_VECTOR_EMPTY)
    {

        const SuballocationVectorType::iterator it = m_2ndVectorMode == SECOND_VECTOR_RING_BUFFER ?
            VmaBinaryFindSorted(suballocations2nd.begin(), suballocations2nd.end(), refSuballoc, VmaSuballocationOffsetLess()) :
            VmaBinaryFindSorted(suballocations2nd.begin(), suballocations2nd.end(), refSuballoc, VmaSuballocationOffsetGreater());
        if (it != suballocations2nd.end())
        {
            it->type = VMA_SUBALLOCATION_TYPE_FREE;
            it->userData = nullptr;
            ++m_2ndNullItemsCount;
            m_SumFreeSize += it->size;
            CleanupAfterFree();
            return;
        }
    }

    
# 8273 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 8273 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Allocation to free not found in linear allocator!"
# 8273 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 8273 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Allocation to free not found in linear allocator!\""
# 8273 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8273),0))
# 8273 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                       ;
}

void VmaBlockMetadata_Linear::GetAllocationInfo(VmaAllocHandle allocHandle, VmaVirtualAllocationInfo& outInfo)
{
    outInfo.offset = (VkDeviceSize)allocHandle - 1;
    VmaSuballocation& suballoc = FindSuballocation(outInfo.offset);
    outInfo.size = suballoc.size;
    outInfo.pUserData = suballoc.userData;
}

void* VmaBlockMetadata_Linear::GetAllocationUserData(VmaAllocHandle allocHandle) const
{
    return FindSuballocation((VkDeviceSize)allocHandle - 1).userData;
}

VmaAllocHandle VmaBlockMetadata_Linear::GetAllocationListBegin() const
{

    
# 8292 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 8292 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0
# 8292 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 8292 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0"
# 8292 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8292),0))
# 8292 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                ;
    return 
# 8293 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
          nullptr
# 8293 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;
}

VmaAllocHandle VmaBlockMetadata_Linear::GetNextAllocation(VmaAllocHandle prevAlloc) const
{

    
# 8299 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 8299 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0
# 8299 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 8299 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0"
# 8299 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8299),0))
# 8299 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                ;
    return 
# 8300 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
          nullptr
# 8300 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;
}

VkDeviceSize VmaBlockMetadata_Linear::GetNextFreeRegionSize(VmaAllocHandle alloc) const
{

    
# 8306 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 8306 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0
# 8306 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 8306 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0"
# 8306 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8306),0))
# 8306 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                ;
    return 0;
}

void VmaBlockMetadata_Linear::Clear()
{
    m_SumFreeSize = GetSize();
    m_Suballocations0.clear();
    m_Suballocations1.clear();

    m_2ndVectorMode = SECOND_VECTOR_EMPTY;
    m_1stNullItemsBeginCount = 0;
    m_1stNullItemsMiddleCount = 0;
    m_2ndNullItemsCount = 0;
}

void VmaBlockMetadata_Linear::SetAllocationUserData(VmaAllocHandle allocHandle, void* userData)
{
    VmaSuballocation& suballoc = FindSuballocation((VkDeviceSize)allocHandle - 1);
    suballoc.userData = userData;
}

void VmaBlockMetadata_Linear::DebugLogAllAllocations() const
{
    const SuballocationVectorType& suballocations1st = AccessSuballocations1st();
    for (auto it = suballocations1st.begin() + m_1stNullItemsBeginCount; it != suballocations1st.end(); ++it)
        if (it->type != VMA_SUBALLOCATION_TYPE_FREE)
            DebugLogAllocation(it->offset, it->size, it->userData);

    const SuballocationVectorType& suballocations2nd = AccessSuballocations2nd();
    for (auto it = suballocations2nd.begin(); it != suballocations2nd.end(); ++it)
        if (it->type != VMA_SUBALLOCATION_TYPE_FREE)
            DebugLogAllocation(it->offset, it->size, it->userData);
}

VmaSuballocation& VmaBlockMetadata_Linear::FindSuballocation(VkDeviceSize offset) const
{
    const SuballocationVectorType& suballocations1st = AccessSuballocations1st();
    const SuballocationVectorType& suballocations2nd = AccessSuballocations2nd();

    VmaSuballocation refSuballoc;
    refSuballoc.offset = offset;



    {
        SuballocationVectorType::const_iterator it = VmaBinaryFindSorted(
            suballocations1st.begin() + m_1stNullItemsBeginCount,
            suballocations1st.end(),
            refSuballoc,
            VmaSuballocationOffsetLess());
        if (it != suballocations1st.end())
        {
            return const_cast<VmaSuballocation&>(*it);
        }
    }

    if (m_2ndVectorMode != SECOND_VECTOR_EMPTY)
    {

        SuballocationVectorType::const_iterator it = m_2ndVectorMode == SECOND_VECTOR_RING_BUFFER ?
            VmaBinaryFindSorted(suballocations2nd.begin(), suballocations2nd.end(), refSuballoc, VmaSuballocationOffsetLess()) :
            VmaBinaryFindSorted(suballocations2nd.begin(), suballocations2nd.end(), refSuballoc, VmaSuballocationOffsetGreater());
        if (it != suballocations2nd.end())
        {
            return const_cast<VmaSuballocation&>(*it);
        }
    }

    
# 8375 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 8375 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Allocation not found in linear allocator!"
# 8375 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 8375 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Allocation not found in linear allocator!\""
# 8375 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8375),0))
# 8375 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                               ;
    return const_cast<VmaSuballocation&>(suballocations1st.back());
}

bool VmaBlockMetadata_Linear::ShouldCompact1st() const
{
    const size_t nullItemCount = m_1stNullItemsBeginCount + m_1stNullItemsMiddleCount;
    const size_t suballocCount = AccessSuballocations1st().size();
    return suballocCount > 32 && nullItemCount * 2 >= (suballocCount - nullItemCount) * 3;
}

void VmaBlockMetadata_Linear::CleanupAfterFree()
{
    SuballocationVectorType& suballocations1st = AccessSuballocations1st();
    SuballocationVectorType& suballocations2nd = AccessSuballocations2nd();

    if (IsEmpty())
    {
        suballocations1st.clear();
        suballocations2nd.clear();
        m_1stNullItemsBeginCount = 0;
        m_1stNullItemsMiddleCount = 0;
        m_2ndNullItemsCount = 0;
        m_2ndVectorMode = SECOND_VECTOR_EMPTY;
    }
    else
    {
        const size_t suballoc1stCount = suballocations1st.size();
        const size_t nullItem1stCount = m_1stNullItemsBeginCount + m_1stNullItemsMiddleCount;
        
# 8404 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 8404 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       nullItem1stCount <= suballoc1stCount
# 8404 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 8404 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "nullItem1stCount <= suballoc1stCount"
# 8404 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8404),0))
# 8404 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                       ;


        while (m_1stNullItemsBeginCount < suballoc1stCount &&
            suballocations1st[m_1stNullItemsBeginCount].type == VMA_SUBALLOCATION_TYPE_FREE)
        {
            ++m_1stNullItemsBeginCount;
            --m_1stNullItemsMiddleCount;
        }


        while (m_1stNullItemsMiddleCount > 0 &&
            suballocations1st.back().type == VMA_SUBALLOCATION_TYPE_FREE)
        {
            --m_1stNullItemsMiddleCount;
            suballocations1st.pop_back();
        }


        while (m_2ndNullItemsCount > 0 &&
            suballocations2nd.back().type == VMA_SUBALLOCATION_TYPE_FREE)
        {
            --m_2ndNullItemsCount;
            suballocations2nd.pop_back();
        }


        while (m_2ndNullItemsCount > 0 &&
            suballocations2nd[0].type == VMA_SUBALLOCATION_TYPE_FREE)
        {
            --m_2ndNullItemsCount;
            VmaVectorRemove(suballocations2nd, 0);
        }

        if (ShouldCompact1st())
        {
            const size_t nonNullItemCount = suballoc1stCount - nullItem1stCount;
            size_t srcIndex = m_1stNullItemsBeginCount;
            for (size_t dstIndex = 0; dstIndex < nonNullItemCount; ++dstIndex)
            {
                while (suballocations1st[srcIndex].type == VMA_SUBALLOCATION_TYPE_FREE)
                {
                    ++srcIndex;
                }
                if (dstIndex != srcIndex)
                {
                    suballocations1st[dstIndex] = suballocations1st[srcIndex];
                }
                ++srcIndex;
            }
            suballocations1st.resize(nonNullItemCount);
            m_1stNullItemsBeginCount = 0;
            m_1stNullItemsMiddleCount = 0;
        }


        if (suballocations2nd.empty())
        {
            m_2ndVectorMode = SECOND_VECTOR_EMPTY;
        }


        if (suballocations1st.size() - m_1stNullItemsBeginCount == 0)
        {
            suballocations1st.clear();
            m_1stNullItemsBeginCount = 0;

            if (!suballocations2nd.empty() && m_2ndVectorMode == SECOND_VECTOR_RING_BUFFER)
            {

                m_2ndVectorMode = SECOND_VECTOR_EMPTY;
                m_1stNullItemsMiddleCount = m_2ndNullItemsCount;
                while (m_1stNullItemsBeginCount < suballocations2nd.size() &&
                    suballocations2nd[m_1stNullItemsBeginCount].type == VMA_SUBALLOCATION_TYPE_FREE)
                {
                    ++m_1stNullItemsBeginCount;
                    --m_1stNullItemsMiddleCount;
                }
                m_2ndNullItemsCount = 0;
                m_1stVectorIndex ^= 1;
            }
        }
    }

    ;
}

bool VmaBlockMetadata_Linear::CreateAllocationRequest_LowerAddress(
    VkDeviceSize allocSize,
    VkDeviceSize allocAlignment,
    VmaSuballocationType allocType,
    uint32_t strategy,
    VmaAllocationRequest* pAllocationRequest)
{
    const VkDeviceSize blockSize = GetSize();
    const VkDeviceSize debugMargin = GetDebugMargin();
    const VkDeviceSize bufferImageGranularity = GetBufferImageGranularity();
    SuballocationVectorType& suballocations1st = AccessSuballocations1st();
    SuballocationVectorType& suballocations2nd = AccessSuballocations2nd();

    if (m_2ndVectorMode == SECOND_VECTOR_EMPTY || m_2ndVectorMode == SECOND_VECTOR_DOUBLE_STACK)
    {


        VkDeviceSize resultBaseOffset = 0;
        if (!suballocations1st.empty())
        {
            const VmaSuballocation& lastSuballoc = suballocations1st.back();
            resultBaseOffset = lastSuballoc.offset + lastSuballoc.size + debugMargin;
        }


        VkDeviceSize resultOffset = resultBaseOffset;


        resultOffset = VmaAlignUp(resultOffset, allocAlignment);



        if (bufferImageGranularity > 1 && bufferImageGranularity != allocAlignment && !suballocations1st.empty())
        {
            bool bufferImageGranularityConflict = false;
            for (size_t prevSuballocIndex = suballocations1st.size(); prevSuballocIndex--; )
            {
                const VmaSuballocation& prevSuballoc = suballocations1st[prevSuballocIndex];
                if (VmaBlocksOnSamePage(prevSuballoc.offset, prevSuballoc.size, resultOffset, bufferImageGranularity))
                {
                    if (VmaIsBufferImageGranularityConflict(prevSuballoc.type, allocType))
                    {
                        bufferImageGranularityConflict = true;
                        break;
                    }
                }
                else

                    break;
            }
            if (bufferImageGranularityConflict)
            {
                resultOffset = VmaAlignUp(resultOffset, bufferImageGranularity);
            }
        }

        const VkDeviceSize freeSpaceEnd = m_2ndVectorMode == SECOND_VECTOR_DOUBLE_STACK ?
            suballocations2nd.back().offset : blockSize;


        if (resultOffset + allocSize + debugMargin <= freeSpaceEnd)
        {


            if ((allocSize % bufferImageGranularity || resultOffset % bufferImageGranularity) && m_2ndVectorMode == SECOND_VECTOR_DOUBLE_STACK)
            {
                for (size_t nextSuballocIndex = suballocations2nd.size(); nextSuballocIndex--; )
                {
                    const VmaSuballocation& nextSuballoc = suballocations2nd[nextSuballocIndex];
                    if (VmaBlocksOnSamePage(resultOffset, allocSize, nextSuballoc.offset, bufferImageGranularity))
                    {
                        if (VmaIsBufferImageGranularityConflict(allocType, nextSuballoc.type))
                        {
                            return false;
                        }
                    }
                    else
                    {

                        break;
                    }
                }
            }


            pAllocationRequest->allocHandle = (VmaAllocHandle)(resultOffset + 1);

            pAllocationRequest->type = VmaAllocationRequestType::EndOf1st;
            return true;
        }
    }



    if (m_2ndVectorMode == SECOND_VECTOR_EMPTY || m_2ndVectorMode == SECOND_VECTOR_RING_BUFFER)
    {
        
# 8587 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 8587 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       !suballocations1st.empty()
# 8587 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 8587 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "!suballocations1st.empty()"
# 8587 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8587),0))
# 8587 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                             ;

        VkDeviceSize resultBaseOffset = 0;
        if (!suballocations2nd.empty())
        {
            const VmaSuballocation& lastSuballoc = suballocations2nd.back();
            resultBaseOffset = lastSuballoc.offset + lastSuballoc.size + debugMargin;
        }


        VkDeviceSize resultOffset = resultBaseOffset;


        resultOffset = VmaAlignUp(resultOffset, allocAlignment);



        if (bufferImageGranularity > 1 && bufferImageGranularity != allocAlignment && !suballocations2nd.empty())
        {
            bool bufferImageGranularityConflict = false;
            for (size_t prevSuballocIndex = suballocations2nd.size(); prevSuballocIndex--; )
            {
                const VmaSuballocation& prevSuballoc = suballocations2nd[prevSuballocIndex];
                if (VmaBlocksOnSamePage(prevSuballoc.offset, prevSuballoc.size, resultOffset, bufferImageGranularity))
                {
                    if (VmaIsBufferImageGranularityConflict(prevSuballoc.type, allocType))
                    {
                        bufferImageGranularityConflict = true;
                        break;
                    }
                }
                else

                    break;
            }
            if (bufferImageGranularityConflict)
            {
                resultOffset = VmaAlignUp(resultOffset, bufferImageGranularity);
            }
        }

        size_t index1st = m_1stNullItemsBeginCount;


        if ((index1st == suballocations1st.size() && resultOffset + allocSize + debugMargin <= blockSize) ||
            (index1st < suballocations1st.size() && resultOffset + allocSize + debugMargin <= suballocations1st[index1st].offset))
        {


            if (allocSize % bufferImageGranularity || resultOffset % bufferImageGranularity)
            {
                for (size_t nextSuballocIndex = index1st;
                    nextSuballocIndex < suballocations1st.size();
                    nextSuballocIndex++)
                {
                    const VmaSuballocation& nextSuballoc = suballocations1st[nextSuballocIndex];
                    if (VmaBlocksOnSamePage(resultOffset, allocSize, nextSuballoc.offset, bufferImageGranularity))
                    {
                        if (VmaIsBufferImageGranularityConflict(allocType, nextSuballoc.type))
                        {
                            return false;
                        }
                    }
                    else
                    {

                        break;
                    }
                }
            }


            pAllocationRequest->allocHandle = (VmaAllocHandle)(resultOffset + 1);
            pAllocationRequest->type = VmaAllocationRequestType::EndOf2nd;

            return true;
        }
    }

    return false;
}

bool VmaBlockMetadata_Linear::CreateAllocationRequest_UpperAddress(
    VkDeviceSize allocSize,
    VkDeviceSize allocAlignment,
    VmaSuballocationType allocType,
    uint32_t strategy,
    VmaAllocationRequest* pAllocationRequest)
{
    const VkDeviceSize blockSize = GetSize();
    const VkDeviceSize bufferImageGranularity = GetBufferImageGranularity();
    SuballocationVectorType& suballocations1st = AccessSuballocations1st();
    SuballocationVectorType& suballocations2nd = AccessSuballocations2nd();

    if (m_2ndVectorMode == SECOND_VECTOR_RING_BUFFER)
    {
        
# 8683 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 8683 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Trying to use pool with linear algorithm as double stack, while it is already being used as ring buffer."
# 8683 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 8683 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Trying to use pool with linear algorithm as double stack, while it is already being used as ring buffer.\""
# 8683 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8683),0))
# 8683 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                  ;
        return false;
    }


    if (allocSize > blockSize)
    {
        return false;
    }
    VkDeviceSize resultBaseOffset = blockSize - allocSize;
    if (!suballocations2nd.empty())
    {
        const VmaSuballocation& lastSuballoc = suballocations2nd.back();
        resultBaseOffset = lastSuballoc.offset - allocSize;
        if (allocSize > lastSuballoc.offset)
        {
            return false;
        }
    }


    VkDeviceSize resultOffset = resultBaseOffset;

    const VkDeviceSize debugMargin = GetDebugMargin();


    if (debugMargin > 0)
    {
        if (resultOffset < debugMargin)
        {
            return false;
        }
        resultOffset -= debugMargin;
    }


    resultOffset = VmaAlignDown(resultOffset, allocAlignment);



    if (bufferImageGranularity > 1 && bufferImageGranularity != allocAlignment && !suballocations2nd.empty())
    {
        bool bufferImageGranularityConflict = false;
        for (size_t nextSuballocIndex = suballocations2nd.size(); nextSuballocIndex--; )
        {
            const VmaSuballocation& nextSuballoc = suballocations2nd[nextSuballocIndex];
            if (VmaBlocksOnSamePage(resultOffset, allocSize, nextSuballoc.offset, bufferImageGranularity))
            {
                if (VmaIsBufferImageGranularityConflict(nextSuballoc.type, allocType))
                {
                    bufferImageGranularityConflict = true;
                    break;
                }
            }
            else

                break;
        }
        if (bufferImageGranularityConflict)
        {
            resultOffset = VmaAlignDown(resultOffset, bufferImageGranularity);
        }
    }


    const VkDeviceSize endOf1st = !suballocations1st.empty() ?
        suballocations1st.back().offset + suballocations1st.back().size :
        0;
    if (endOf1st + debugMargin <= resultOffset)
    {


        if (bufferImageGranularity > 1)
        {
            for (size_t prevSuballocIndex = suballocations1st.size(); prevSuballocIndex--; )
            {
                const VmaSuballocation& prevSuballoc = suballocations1st[prevSuballocIndex];
                if (VmaBlocksOnSamePage(prevSuballoc.offset, prevSuballoc.size, resultOffset, bufferImageGranularity))
                {
                    if (VmaIsBufferImageGranularityConflict(allocType, prevSuballoc.type))
                    {
                        return false;
                    }
                }
                else
                {

                    break;
                }
            }
        }


        pAllocationRequest->allocHandle = (VmaAllocHandle)(resultOffset + 1);

        pAllocationRequest->type = VmaAllocationRequestType::UpperAddress;
        return true;
    }

    return false;
}
# 8792 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
class VmaBlockMetadata_TLSF : public VmaBlockMetadata
{
    private: VmaBlockMetadata_TLSF(const VmaBlockMetadata_TLSF&) = delete; VmaBlockMetadata_TLSF(VmaBlockMetadata_TLSF&&) = delete; VmaBlockMetadata_TLSF& operator=(const VmaBlockMetadata_TLSF&) = delete; VmaBlockMetadata_TLSF& operator=(VmaBlockMetadata_TLSF&&) = delete;
public:
    VmaBlockMetadata_TLSF(const VkAllocationCallbacks* pAllocationCallbacks,
        VkDeviceSize bufferImageGranularity, bool isVirtual);
    virtual ~VmaBlockMetadata_TLSF();

    size_t GetAllocationCount() const override { return m_AllocCount; }
    size_t GetFreeRegionsCount() const override { return m_BlocksFreeCount + 1; }
    VkDeviceSize GetSumFreeSize() const override { return m_BlocksFreeSize + m_NullBlock->size; }
    bool IsEmpty() const override { return m_NullBlock->offset == 0; }
    VkDeviceSize GetAllocationOffset(VmaAllocHandle allocHandle) const override { return ((Block*)allocHandle)->offset; }

    void Init(VkDeviceSize size) override;
    bool Validate() const override;

    void AddDetailedStatistics(VmaDetailedStatistics& inoutStats) const override;
    void AddStatistics(VmaStatistics& inoutStats) const override;


    void PrintDetailedMap(class VmaJsonWriter& json) const override;


    bool CreateAllocationRequest(
        VkDeviceSize allocSize,
        VkDeviceSize allocAlignment,
        bool upperAddress,
        VmaSuballocationType allocType,
        uint32_t strategy,
        VmaAllocationRequest* pAllocationRequest) override;

    VkResult CheckCorruption(const void* pBlockData) override;
    void Alloc(
        const VmaAllocationRequest& request,
        VmaSuballocationType type,
        void* userData) override;

    void Free(VmaAllocHandle allocHandle) override;
    void GetAllocationInfo(VmaAllocHandle allocHandle, VmaVirtualAllocationInfo& outInfo) override;
    void* GetAllocationUserData(VmaAllocHandle allocHandle) const override;
    VmaAllocHandle GetAllocationListBegin() const override;
    VmaAllocHandle GetNextAllocation(VmaAllocHandle prevAlloc) const override;
    VkDeviceSize GetNextFreeRegionSize(VmaAllocHandle alloc) const override;
    void Clear() override;
    void SetAllocationUserData(VmaAllocHandle allocHandle, void* userData) override;
    void DebugLogAllAllocations() const override;

private:



    static const uint8_t SECOND_LEVEL_INDEX = 5;
    static const uint16_t SMALL_BUFFER_SIZE = 256;
    static const uint32_t INITIAL_BLOCK_ALLOC_COUNT = 16;
    static const uint8_t MEMORY_CLASS_SHIFT = 7;
    static const uint8_t MAX_MEMORY_CLASSES = 65 - MEMORY_CLASS_SHIFT;

    class Block
    {
    public:
        VkDeviceSize offset;
        VkDeviceSize size;
        Block* prevPhysical;
        Block* nextPhysical;

        void MarkFree() { prevFree = nullptr; }
        void MarkTaken() { prevFree = this; }
        bool IsFree() const { return prevFree != this; }
        void*& UserData() { ; return userData; }
        Block*& PrevFree() { return prevFree; }
        Block*& NextFree() { ; return nextFree; }

    private:
        Block* prevFree;
        union
        {
            Block* nextFree;
            void* userData;
        };
    };

    size_t m_AllocCount;

    size_t m_BlocksFreeCount;

    VkDeviceSize m_BlocksFreeSize;
    uint32_t m_IsFreeBitmap;
    uint8_t m_MemoryClasses;
    uint32_t m_InnerIsFreeBitmap[MAX_MEMORY_CLASSES];
    uint32_t m_ListsCount;




    Block** m_FreeList;
    VmaPoolAllocator<Block> m_BlockAllocator;
    Block* m_NullBlock;
    VmaBlockBufferImageGranularity m_GranularityHandler;

    uint8_t SizeToMemoryClass(VkDeviceSize size) const;
    uint16_t SizeToSecondIndex(VkDeviceSize size, uint8_t memoryClass) const;
    uint32_t GetListIndex(uint8_t memoryClass, uint16_t secondIndex) const;
    uint32_t GetListIndex(VkDeviceSize size) const;

    void RemoveFreeBlock(Block* block);
    void InsertFreeBlock(Block* block);
    void MergeBlock(Block* block, Block* prev);

    Block* FindFreeBlock(VkDeviceSize size, uint32_t& listIndex) const;
    bool CheckBlock(
        Block& block,
        uint32_t listIndex,
        VkDeviceSize allocSize,
        VkDeviceSize allocAlignment,
        VmaSuballocationType allocType,
        VmaAllocationRequest* pAllocationRequest);
};


VmaBlockMetadata_TLSF::VmaBlockMetadata_TLSF(const VkAllocationCallbacks* pAllocationCallbacks,
    VkDeviceSize bufferImageGranularity, bool isVirtual)
    : VmaBlockMetadata(pAllocationCallbacks, bufferImageGranularity, isVirtual),
    m_AllocCount(0),
    m_BlocksFreeCount(0),
    m_BlocksFreeSize(0),
    m_IsFreeBitmap(0),
    m_MemoryClasses(0),
    m_ListsCount(0),
    m_FreeList(nullptr),
    m_BlockAllocator(pAllocationCallbacks, INITIAL_BLOCK_ALLOC_COUNT),
    m_NullBlock(nullptr),
    m_GranularityHandler(bufferImageGranularity) {}

VmaBlockMetadata_TLSF::~VmaBlockMetadata_TLSF()
{
    if (m_FreeList)
        vma_delete_array(GetAllocationCallbacks(), m_FreeList, m_ListsCount);
    m_GranularityHandler.Destroy(GetAllocationCallbacks());
}

void VmaBlockMetadata_TLSF::Init(VkDeviceSize size)
{
    VmaBlockMetadata::Init(size);

    if (!IsVirtual())
        m_GranularityHandler.Init(GetAllocationCallbacks(), size);

    m_NullBlock = m_BlockAllocator.Alloc();
    m_NullBlock->size = size;
    m_NullBlock->offset = 0;
    m_NullBlock->prevPhysical = nullptr;
    m_NullBlock->nextPhysical = nullptr;
    m_NullBlock->MarkFree();
    m_NullBlock->NextFree() = nullptr;
    m_NullBlock->PrevFree() = nullptr;
    uint8_t memoryClass = SizeToMemoryClass(size);
    uint16_t sli = SizeToSecondIndex(size, memoryClass);
    m_ListsCount = (memoryClass == 0 ? 0 : (memoryClass - 1) * (1UL << SECOND_LEVEL_INDEX) + sli) + 1;
    if (IsVirtual())
        m_ListsCount += 1UL << SECOND_LEVEL_INDEX;
    else
        m_ListsCount += 4;

    m_MemoryClasses = memoryClass + uint8_t(2);
    memset(m_InnerIsFreeBitmap, 0, MAX_MEMORY_CLASSES * sizeof(uint32_t));

    m_FreeList = new(VmaAllocateArray<Block*>((GetAllocationCallbacks()), (m_ListsCount)))(Block*);
    memset(m_FreeList, 0, m_ListsCount * sizeof(Block*));
}

bool VmaBlockMetadata_TLSF::Validate() const
{
    do { if(!(GetSumFreeSize() <= GetSize())) { 
# 8965 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 8965 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Validation failed: " "GetSumFreeSize() <= GetSize()"
# 8965 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 8965 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Validation failed: \" \"GetSumFreeSize() <= GetSize()\""
# 8965 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8965),0))
# 8965 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   ; return false; } } while(false);

    VkDeviceSize calculatedSize = m_NullBlock->size;
    VkDeviceSize calculatedFreeSize = m_NullBlock->size;
    size_t allocCount = 0;
    size_t freeCount = 0;


    for (uint32_t list = 0; list < m_ListsCount; ++list)
    {
        Block* block = m_FreeList[list];
        if (block != nullptr)
        {
            do { if(!(block->IsFree())) { 
# 8978 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 8978 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0 && "Validation failed: " "block->IsFree()"
# 8978 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 8978 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0 && \"Validation failed: \" \"block->IsFree()\""
# 8978 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8978),0))
# 8978 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           ; return false; } } while(false);
            do { if(!(block->PrevFree() == nullptr)) { 
# 8979 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 8979 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0 && "Validation failed: " "block->PrevFree() == VMA_NULL"
# 8979 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 8979 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0 && \"Validation failed: \" \"block->PrevFree() == VMA_NULL\""
# 8979 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8979),0))
# 8979 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           ; return false; } } while(false);
            while (block->NextFree())
            {
                do { if(!(block->NextFree()->IsFree())) { 
# 8982 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 8982 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               0 && "Validation failed: " "block->NextFree()->IsFree()"
# 8982 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 8982 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "0 && \"Validation failed: \" \"block->NextFree()->IsFree()\""
# 8982 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8982),0))
# 8982 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               ; return false; } } while(false);
                do { if(!(block->NextFree()->PrevFree() == block)) { 
# 8983 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 8983 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               0 && "Validation failed: " "block->NextFree()->PrevFree() == block"
# 8983 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 8983 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "0 && \"Validation failed: \" \"block->NextFree()->PrevFree() == block\""
# 8983 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8983),0))
# 8983 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               ; return false; } } while(false);
                block = block->NextFree();
            }
        }
    }

    VkDeviceSize nextOffset = m_NullBlock->offset;
    auto validateCtx = m_GranularityHandler.StartValidation(GetAllocationCallbacks(), IsVirtual());

    do { if(!(m_NullBlock->nextPhysical == nullptr)) { 
# 8992 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 8992 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Validation failed: " "m_NullBlock->nextPhysical == VMA_NULL"
# 8992 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 8992 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Validation failed: \" \"m_NullBlock->nextPhysical == VMA_NULL\""
# 8992 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8992),0))
# 8992 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   ; return false; } } while(false);
    if (m_NullBlock->prevPhysical)
    {
        do { if(!(m_NullBlock->prevPhysical->nextPhysical == m_NullBlock)) { 
# 8995 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 8995 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Validation failed: " "m_NullBlock->prevPhysical->nextPhysical == m_NullBlock"
# 8995 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 8995 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Validation failed: \" \"m_NullBlock->prevPhysical->nextPhysical == m_NullBlock\""
# 8995 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",8995),0))
# 8995 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       ; return false; } } while(false);
    }

    for (Block* prev = m_NullBlock->prevPhysical; prev != nullptr; prev = prev->prevPhysical)
    {
        do { if(!(prev->offset + prev->size == nextOffset)) { 
# 9000 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 9000 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Validation failed: " "prev->offset + prev->size == nextOffset"
# 9000 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 9000 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Validation failed: \" \"prev->offset + prev->size == nextOffset\""
# 9000 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9000),0))
# 9000 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       ; return false; } } while(false);
        nextOffset = prev->offset;
        calculatedSize += prev->size;

        uint32_t listIndex = GetListIndex(prev->size);
        if (prev->IsFree())
        {
            ++freeCount;

            Block* freeBlock = m_FreeList[listIndex];
            do { if(!(freeBlock != nullptr)) { 
# 9010 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 9010 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0 && "Validation failed: " "freeBlock != VMA_NULL"
# 9010 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 9010 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0 && \"Validation failed: \" \"freeBlock != VMA_NULL\""
# 9010 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9010),0))
# 9010 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           ; return false; } } while(false);

            bool found = false;
            do
            {
                if (freeBlock == prev)
                    found = true;

                freeBlock = freeBlock->NextFree();
            } while (!found && freeBlock != nullptr);

            do { if(!(found)) { 
# 9021 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 9021 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0 && "Validation failed: " "found"
# 9021 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 9021 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0 && \"Validation failed: \" \"found\""
# 9021 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9021),0))
# 9021 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           ; return false; } } while(false);
            calculatedFreeSize += prev->size;
        }
        else
        {
            ++allocCount;

            Block* freeBlock = m_FreeList[listIndex];
            while (freeBlock)
            {
                do { if(!(freeBlock != prev)) { 
# 9031 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 9031 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               0 && "Validation failed: " "freeBlock != prev"
# 9031 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 9031 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "0 && \"Validation failed: \" \"freeBlock != prev\""
# 9031 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9031),0))
# 9031 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               ; return false; } } while(false);
                freeBlock = freeBlock->NextFree();
            }

            if (!IsVirtual())
            {
                do { if(!(m_GranularityHandler.Validate(validateCtx, prev->offset, prev->size))) { 
# 9037 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 9037 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               0 && "Validation failed: " "m_GranularityHandler.Validate(validateCtx, prev->offset, prev->size)"
# 9037 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 9037 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "0 && \"Validation failed: \" \"m_GranularityHandler.Validate(validateCtx, prev->offset, prev->size)\""
# 9037 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9037),0))
# 9037 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               ; return false; } } while(false);
            }
        }

        if (prev->prevPhysical)
        {
            do { if(!(prev->prevPhysical->nextPhysical == prev)) { 
# 9043 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 9043 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0 && "Validation failed: " "prev->prevPhysical->nextPhysical == prev"
# 9043 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 9043 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0 && \"Validation failed: \" \"prev->prevPhysical->nextPhysical == prev\""
# 9043 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9043),0))
# 9043 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           ; return false; } } while(false);
        }
    }

    if (!IsVirtual())
    {
        do { if(!(m_GranularityHandler.FinishValidation(validateCtx))) { 
# 9049 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 9049 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Validation failed: " "m_GranularityHandler.FinishValidation(validateCtx)"
# 9049 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 9049 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Validation failed: \" \"m_GranularityHandler.FinishValidation(validateCtx)\""
# 9049 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9049),0))
# 9049 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       ; return false; } } while(false);
    }

    do { if(!(nextOffset == 0)) { 
# 9052 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9052 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Validation failed: " "nextOffset == 0"
# 9052 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9052 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Validation failed: \" \"nextOffset == 0\""
# 9052 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9052),0))
# 9052 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   ; return false; } } while(false);
    do { if(!(calculatedSize == GetSize())) { 
# 9053 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9053 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Validation failed: " "calculatedSize == GetSize()"
# 9053 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9053 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Validation failed: \" \"calculatedSize == GetSize()\""
# 9053 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9053),0))
# 9053 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   ; return false; } } while(false);
    do { if(!(calculatedFreeSize == GetSumFreeSize())) { 
# 9054 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9054 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Validation failed: " "calculatedFreeSize == GetSumFreeSize()"
# 9054 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9054 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Validation failed: \" \"calculatedFreeSize == GetSumFreeSize()\""
# 9054 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9054),0))
# 9054 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   ; return false; } } while(false);
    do { if(!(allocCount == m_AllocCount)) { 
# 9055 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9055 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Validation failed: " "allocCount == m_AllocCount"
# 9055 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9055 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Validation failed: \" \"allocCount == m_AllocCount\""
# 9055 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9055),0))
# 9055 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   ; return false; } } while(false);
    do { if(!(freeCount == m_BlocksFreeCount)) { 
# 9056 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9056 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Validation failed: " "freeCount == m_BlocksFreeCount"
# 9056 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9056 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Validation failed: \" \"freeCount == m_BlocksFreeCount\""
# 9056 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9056),0))
# 9056 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   ; return false; } } while(false);

    return true;
}

void VmaBlockMetadata_TLSF::AddDetailedStatistics(VmaDetailedStatistics& inoutStats) const
{
    inoutStats.statistics.blockCount++;
    inoutStats.statistics.blockBytes += GetSize();
    if (m_NullBlock->size > 0)
        VmaAddDetailedStatisticsUnusedRange(inoutStats, m_NullBlock->size);

    for (Block* block = m_NullBlock->prevPhysical; block != nullptr; block = block->prevPhysical)
    {
        if (block->IsFree())
            VmaAddDetailedStatisticsUnusedRange(inoutStats, block->size);
        else
            VmaAddDetailedStatisticsAllocation(inoutStats, block->size);
    }
}

void VmaBlockMetadata_TLSF::AddStatistics(VmaStatistics& inoutStats) const
{
    inoutStats.blockCount++;
    inoutStats.allocationCount += (uint32_t)m_AllocCount;
    inoutStats.blockBytes += GetSize();
    inoutStats.allocationBytes += GetSize() - GetSumFreeSize();
}


void VmaBlockMetadata_TLSF::PrintDetailedMap(class VmaJsonWriter& json) const
{
    size_t blockCount = m_AllocCount + m_BlocksFreeCount;
    VmaStlAllocator<Block*> allocator(GetAllocationCallbacks());
    VmaVector<Block*, VmaStlAllocator<Block*>> blockList(blockCount, allocator);

    size_t i = blockCount;
    for (Block* block = m_NullBlock->prevPhysical; block != nullptr; block = block->prevPhysical)
    {
        blockList[--i] = block;
    }
    
# 9097 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9097 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   i == 0
# 9097 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9097 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "i == 0"
# 9097 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9097),0))
# 9097 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                     ;

    VmaDetailedStatistics stats;
    VmaClearDetailedStatistics(stats);
    AddDetailedStatistics(stats);

    PrintDetailedMap_Begin(json,
        stats.statistics.blockBytes - stats.statistics.allocationBytes,
        stats.statistics.allocationCount,
        stats.unusedRangeCount);

    for (; i < blockCount; ++i)
    {
        Block* block = blockList[i];
        if (block->IsFree())
            PrintDetailedMap_UnusedRange(json, block->offset, block->size);
        else
            PrintDetailedMap_Allocation(json, block->offset, block->size, block->UserData());
    }
    if (m_NullBlock->size > 0)
        PrintDetailedMap_UnusedRange(json, m_NullBlock->offset, m_NullBlock->size);

    PrintDetailedMap_End(json);
}


bool VmaBlockMetadata_TLSF::CreateAllocationRequest(
    VkDeviceSize allocSize,
    VkDeviceSize allocAlignment,
    bool upperAddress,
    VmaSuballocationType allocType,
    uint32_t strategy,
    VmaAllocationRequest* pAllocationRequest)
{
    
# 9131 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9131 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocSize > 0 && "Cannot allocate empty block!"
# 9131 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9131 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocSize > 0 && \"Cannot allocate empty block!\""
# 9131 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9131),0))
# 9131 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                              ;
    
# 9132 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9132 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !upperAddress && "VMA_ALLOCATION_CREATE_UPPER_ADDRESS_BIT can be used only with linear algorithm."
# 9132 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9132 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!upperAddress && \"VMA_ALLOCATION_CREATE_UPPER_ADDRESS_BIT can be used only with linear algorithm.\""
# 9132 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9132),0))
# 9132 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                 ;


    if (!IsVirtual())
        m_GranularityHandler.RoundupAllocRequest(allocType, allocSize, allocAlignment);

    allocSize += GetDebugMargin();

    if (allocSize > GetSumFreeSize())
        return false;


    if (m_BlocksFreeCount == 0)
        return CheckBlock(*m_NullBlock, m_ListsCount, allocSize, allocAlignment, allocType, pAllocationRequest);


    VkDeviceSize sizeForNextList = allocSize;
    VkDeviceSize smallSizeStep = VkDeviceSize(SMALL_BUFFER_SIZE / (IsVirtual() ? 1 << SECOND_LEVEL_INDEX : 4));
    if (allocSize > SMALL_BUFFER_SIZE)
    {
        sizeForNextList += (1ULL << (VmaBitScanMSB(allocSize) - SECOND_LEVEL_INDEX));
    }
    else if (allocSize > SMALL_BUFFER_SIZE - smallSizeStep)
        sizeForNextList = SMALL_BUFFER_SIZE + 1;
    else
        sizeForNextList += smallSizeStep;

    uint32_t nextListIndex = m_ListsCount;
    uint32_t prevListIndex = m_ListsCount;
    Block* nextListBlock = nullptr;
    Block* prevListBlock = nullptr;


    if (strategy & VMA_ALLOCATION_CREATE_STRATEGY_MIN_TIME_BIT)
    {

        nextListBlock = FindFreeBlock(sizeForNextList, nextListIndex);
        if (nextListBlock != nullptr && CheckBlock(*nextListBlock, nextListIndex, allocSize, allocAlignment, allocType, pAllocationRequest))
            return true;


        if (CheckBlock(*m_NullBlock, m_ListsCount, allocSize, allocAlignment, allocType, pAllocationRequest))
            return true;


        while (nextListBlock)
        {
            if (CheckBlock(*nextListBlock, nextListIndex, allocSize, allocAlignment, allocType, pAllocationRequest))
                return true;
            nextListBlock = nextListBlock->NextFree();
        }


        prevListBlock = FindFreeBlock(allocSize, prevListIndex);
        while (prevListBlock)
        {
            if (CheckBlock(*prevListBlock, prevListIndex, allocSize, allocAlignment, allocType, pAllocationRequest))
                return true;
            prevListBlock = prevListBlock->NextFree();
        }
    }
    else if (strategy & VMA_ALLOCATION_CREATE_STRATEGY_MIN_MEMORY_BIT)
    {

        prevListBlock = FindFreeBlock(allocSize, prevListIndex);
        while (prevListBlock)
        {
            if (CheckBlock(*prevListBlock, prevListIndex, allocSize, allocAlignment, allocType, pAllocationRequest))
                return true;
            prevListBlock = prevListBlock->NextFree();
        }


        if (CheckBlock(*m_NullBlock, m_ListsCount, allocSize, allocAlignment, allocType, pAllocationRequest))
            return true;


        nextListBlock = FindFreeBlock(sizeForNextList, nextListIndex);
        while (nextListBlock)
        {
            if (CheckBlock(*nextListBlock, nextListIndex, allocSize, allocAlignment, allocType, pAllocationRequest))
                return true;
            nextListBlock = nextListBlock->NextFree();
        }
    }
    else if (strategy & VMA_ALLOCATION_CREATE_STRATEGY_MIN_OFFSET_BIT )
    {

        VmaStlAllocator<Block*> allocator(GetAllocationCallbacks());
        VmaVector<Block*, VmaStlAllocator<Block*>> blockList(m_BlocksFreeCount, allocator);

        size_t i = m_BlocksFreeCount;
        for (Block* block = m_NullBlock->prevPhysical; block != nullptr; block = block->prevPhysical)
        {
            if (block->IsFree() && block->size >= allocSize)
                blockList[--i] = block;
        }

        for (; i < m_BlocksFreeCount; ++i)
        {
            Block& block = *blockList[i];
            if (CheckBlock(block, GetListIndex(block.size), allocSize, allocAlignment, allocType, pAllocationRequest))
                return true;
        }


        if (CheckBlock(*m_NullBlock, m_ListsCount, allocSize, allocAlignment, allocType, pAllocationRequest))
            return true;


        return false;
    }
    else
    {

        nextListBlock = FindFreeBlock(sizeForNextList, nextListIndex);
        while (nextListBlock)
        {
            if (CheckBlock(*nextListBlock, nextListIndex, allocSize, allocAlignment, allocType, pAllocationRequest))
                return true;
            nextListBlock = nextListBlock->NextFree();
        }


        if (CheckBlock(*m_NullBlock, m_ListsCount, allocSize, allocAlignment, allocType, pAllocationRequest))
            return true;


        prevListBlock = FindFreeBlock(allocSize, prevListIndex);
        while (prevListBlock)
        {
            if (CheckBlock(*prevListBlock, prevListIndex, allocSize, allocAlignment, allocType, pAllocationRequest))
                return true;
            prevListBlock = prevListBlock->NextFree();
        }
    }


    while (++nextListIndex < m_ListsCount)
    {
        nextListBlock = m_FreeList[nextListIndex];
        while (nextListBlock)
        {
            if (CheckBlock(*nextListBlock, nextListIndex, allocSize, allocAlignment, allocType, pAllocationRequest))
                return true;
            nextListBlock = nextListBlock->NextFree();
        }
    }


    return false;
}

VkResult VmaBlockMetadata_TLSF::CheckCorruption(const void* pBlockData)
{
    for (Block* block = m_NullBlock->prevPhysical; block != nullptr; block = block->prevPhysical)
    {
        if (!block->IsFree())
        {
            if (!VmaValidateMagicValue(pBlockData, block->offset + block->size))
            {
                
# 9293 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 9293 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               0 && "MEMORY CORRUPTION DETECTED AFTER VALIDATED ALLOCATION!"
# 9293 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 9293 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "0 && \"MEMORY CORRUPTION DETECTED AFTER VALIDATED ALLOCATION!\""
# 9293 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9293),0))
# 9293 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                        ;
                return ((VkResult)-13);
            }
        }
    }

    return VK_SUCCESS;
}

void VmaBlockMetadata_TLSF::Alloc(
    const VmaAllocationRequest& request,
    VmaSuballocationType type,
    void* userData)
{
    
# 9307 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9307 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   request.type == VmaAllocationRequestType::TLSF
# 9307 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9307 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "request.type == VmaAllocationRequestType::TLSF"
# 9307 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9307),0))
# 9307 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                             ;


    Block* currentBlock = (Block*)request.allocHandle;
    VkDeviceSize offset = request.algorithmData;
    
# 9312 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9312 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   currentBlock != nullptr
# 9312 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9312 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "currentBlock != nullptr"
# 9312 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9312),0))
# 9312 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                       ;
    
# 9313 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9313 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   currentBlock->offset <= offset
# 9313 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9313 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "currentBlock->offset <= offset"
# 9313 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9313),0))
# 9313 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                             ;

    if (currentBlock != m_NullBlock)
        RemoveFreeBlock(currentBlock);

    VkDeviceSize debugMargin = GetDebugMargin();
    VkDeviceSize missingAlignment = offset - currentBlock->offset;


    if (missingAlignment)
    {
        Block* prevBlock = currentBlock->prevPhysical;
        
# 9325 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 9325 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       prevBlock != nullptr && "There should be no missing alignment at offset 0!"
# 9325 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 9325 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "prevBlock != nullptr && \"There should be no missing alignment at offset 0!\""
# 9325 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9325),0))
# 9325 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                               ;

        if (prevBlock->IsFree() && prevBlock->size != debugMargin)
        {
            uint32_t oldList = GetListIndex(prevBlock->size);
            prevBlock->size += missingAlignment;

            if (oldList != GetListIndex(prevBlock->size))
            {
                prevBlock->size -= missingAlignment;
                RemoveFreeBlock(prevBlock);
                prevBlock->size += missingAlignment;
                InsertFreeBlock(prevBlock);
            }
            else
                m_BlocksFreeSize += missingAlignment;
        }
        else
        {
            Block* newBlock = m_BlockAllocator.Alloc();
            currentBlock->prevPhysical = newBlock;
            prevBlock->nextPhysical = newBlock;
            newBlock->prevPhysical = prevBlock;
            newBlock->nextPhysical = currentBlock;
            newBlock->size = missingAlignment;
            newBlock->offset = currentBlock->offset;
            newBlock->MarkTaken();

            InsertFreeBlock(newBlock);
        }

        currentBlock->size -= missingAlignment;
        currentBlock->offset += missingAlignment;
    }

    VkDeviceSize size = request.size + debugMargin;
    if (currentBlock->size == size)
    {
        if (currentBlock == m_NullBlock)
        {

            m_NullBlock = m_BlockAllocator.Alloc();
            m_NullBlock->size = 0;
            m_NullBlock->offset = currentBlock->offset + size;
            m_NullBlock->prevPhysical = currentBlock;
            m_NullBlock->nextPhysical = nullptr;
            m_NullBlock->MarkFree();
            m_NullBlock->PrevFree() = nullptr;
            m_NullBlock->NextFree() = nullptr;
            currentBlock->nextPhysical = m_NullBlock;
            currentBlock->MarkTaken();
        }
    }
    else
    {
        
# 9380 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 9380 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       currentBlock->size > size && "Proper block already found, shouldn't find smaller one!"
# 9380 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 9380 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "currentBlock->size > size && \"Proper block already found, shouldn't find smaller one!\""
# 9380 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9380),0))
# 9380 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                         ;


        Block* newBlock = m_BlockAllocator.Alloc();
        newBlock->size = currentBlock->size - size;
        newBlock->offset = currentBlock->offset + size;
        newBlock->prevPhysical = currentBlock;
        newBlock->nextPhysical = currentBlock->nextPhysical;
        currentBlock->nextPhysical = newBlock;
        currentBlock->size = size;

        if (currentBlock == m_NullBlock)
        {
            m_NullBlock = newBlock;
            m_NullBlock->MarkFree();
            m_NullBlock->NextFree() = nullptr;
            m_NullBlock->PrevFree() = nullptr;
            currentBlock->MarkTaken();
        }
        else
        {
            newBlock->nextPhysical->prevPhysical = newBlock;
            newBlock->MarkTaken();
            InsertFreeBlock(newBlock);
        }
    }
    currentBlock->UserData() = userData;

    if (debugMargin > 0)
    {
        currentBlock->size -= debugMargin;
        Block* newBlock = m_BlockAllocator.Alloc();
        newBlock->size = debugMargin;
        newBlock->offset = currentBlock->offset + currentBlock->size;
        newBlock->prevPhysical = currentBlock;
        newBlock->nextPhysical = currentBlock->nextPhysical;
        newBlock->MarkTaken();
        currentBlock->nextPhysical->prevPhysical = newBlock;
        currentBlock->nextPhysical = newBlock;
        InsertFreeBlock(newBlock);
    }

    if (!IsVirtual())
        m_GranularityHandler.AllocPages((uint8_t)(uintptr_t)request.customData,
            currentBlock->offset, currentBlock->size);
    ++m_AllocCount;
}

void VmaBlockMetadata_TLSF::Free(VmaAllocHandle allocHandle)
{
    Block* block = (Block*)allocHandle;
    Block* next = block->nextPhysical;
    
# 9432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !block->IsFree() && "Block is already free!"
# 9432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!block->IsFree() && \"Block is already free!\""
# 9432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9432),0))
# 9432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                           ;

    if (!IsVirtual())
        m_GranularityHandler.FreePages(block->offset, block->size);
    --m_AllocCount;

    VkDeviceSize debugMargin = GetDebugMargin();
    if (debugMargin > 0)
    {
        RemoveFreeBlock(next);
        MergeBlock(next, block);
        block = next;
        next = next->nextPhysical;
    }


    Block* prev = block->prevPhysical;
    if (prev != nullptr && prev->IsFree() && prev->size != debugMargin)
    {
        RemoveFreeBlock(prev);
        MergeBlock(block, prev);
    }

    if (!next->IsFree())
        InsertFreeBlock(block);
    else if (next == m_NullBlock)
        MergeBlock(m_NullBlock, block);
    else
    {
        RemoveFreeBlock(next);
        MergeBlock(next, block);
        InsertFreeBlock(next);
    }
}

void VmaBlockMetadata_TLSF::GetAllocationInfo(VmaAllocHandle allocHandle, VmaVirtualAllocationInfo& outInfo)
{
    Block* block = (Block*)allocHandle;
    
# 9470 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9470 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !block->IsFree() && "Cannot get allocation info for free block!"
# 9470 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9470 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!block->IsFree() && \"Cannot get allocation info for free block!\""
# 9470 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9470),0))
# 9470 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                               ;
    outInfo.offset = block->offset;
    outInfo.size = block->size;
    outInfo.pUserData = block->UserData();
}

void* VmaBlockMetadata_TLSF::GetAllocationUserData(VmaAllocHandle allocHandle) const
{
    Block* block = (Block*)allocHandle;
    
# 9479 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9479 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !block->IsFree() && "Cannot get user data for free block!"
# 9479 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9479 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!block->IsFree() && \"Cannot get user data for free block!\""
# 9479 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9479),0))
# 9479 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                         ;
    return block->UserData();
}

VmaAllocHandle VmaBlockMetadata_TLSF::GetAllocationListBegin() const
{
    if (m_AllocCount == 0)
        return 
# 9486 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
              nullptr
# 9486 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            ;

    for (Block* block = m_NullBlock->prevPhysical; block; block = block->prevPhysical)
    {
        if (!block->IsFree())
            return (VmaAllocHandle)block;
    }
    
# 9493 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9493 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   false && "If m_AllocCount > 0 then should find any allocation!"
# 9493 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9493 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "false && \"If m_AllocCount > 0 then should find any allocation!\""
# 9493 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9493),0))
# 9493 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                              ;
    return 
# 9494 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
          nullptr
# 9494 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;
}

VmaAllocHandle VmaBlockMetadata_TLSF::GetNextAllocation(VmaAllocHandle prevAlloc) const
{
    Block* startBlock = (Block*)prevAlloc;
    
# 9500 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9500 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !startBlock->IsFree() && "Incorrect block!"
# 9500 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9500 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!startBlock->IsFree() && \"Incorrect block!\""
# 9500 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9500),0))
# 9500 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                          ;

    for (Block* block = startBlock->prevPhysical; block; block = block->prevPhysical)
    {
        if (!block->IsFree())
            return (VmaAllocHandle)block;
    }
    return 
# 9507 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
          nullptr
# 9507 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;
}

VkDeviceSize VmaBlockMetadata_TLSF::GetNextFreeRegionSize(VmaAllocHandle alloc) const
{
    Block* block = (Block*)alloc;
    
# 9513 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9513 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !block->IsFree() && "Incorrect block!"
# 9513 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9513 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!block->IsFree() && \"Incorrect block!\""
# 9513 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9513),0))
# 9513 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                     ;

    if (block->prevPhysical)
        return block->prevPhysical->IsFree() ? block->prevPhysical->size : 0;
    return 0;
}

void VmaBlockMetadata_TLSF::Clear()
{
    m_AllocCount = 0;
    m_BlocksFreeCount = 0;
    m_BlocksFreeSize = 0;
    m_IsFreeBitmap = 0;
    m_NullBlock->offset = 0;
    m_NullBlock->size = GetSize();
    Block* block = m_NullBlock->prevPhysical;
    m_NullBlock->prevPhysical = nullptr;
    while (block)
    {
        Block* prev = block->prevPhysical;
        m_BlockAllocator.Free(block);
        block = prev;
    }
    memset(m_FreeList, 0, m_ListsCount * sizeof(Block*));
    memset(m_InnerIsFreeBitmap, 0, m_MemoryClasses * sizeof(uint32_t));
    m_GranularityHandler.Clear();
}

void VmaBlockMetadata_TLSF::SetAllocationUserData(VmaAllocHandle allocHandle, void* userData)
{
    Block* block = (Block*)allocHandle;
    
# 9544 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9544 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !block->IsFree() && "Trying to set user data for not allocated block!"
# 9544 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9544 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!block->IsFree() && \"Trying to set user data for not allocated block!\""
# 9544 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9544),0))
# 9544 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                     ;
    block->UserData() = userData;
}

void VmaBlockMetadata_TLSF::DebugLogAllAllocations() const
{
    for (Block* block = m_NullBlock->prevPhysical; block != nullptr; block = block->prevPhysical)
        if (!block->IsFree())
            DebugLogAllocation(block->offset, block->size, block->UserData());
}

uint8_t VmaBlockMetadata_TLSF::SizeToMemoryClass(VkDeviceSize size) const
{
    if (size > SMALL_BUFFER_SIZE)
        return uint8_t(VmaBitScanMSB(size) - MEMORY_CLASS_SHIFT);
    return 0;
}

uint16_t VmaBlockMetadata_TLSF::SizeToSecondIndex(VkDeviceSize size, uint8_t memoryClass) const
{
    if (memoryClass == 0)
    {
        if (IsVirtual())
            return static_cast<uint16_t>((size - 1) / 8);
        else
            return static_cast<uint16_t>((size - 1) / 64);
    }
    return static_cast<uint16_t>((size >> (memoryClass + MEMORY_CLASS_SHIFT - SECOND_LEVEL_INDEX)) ^ (1U << SECOND_LEVEL_INDEX));
}

uint32_t VmaBlockMetadata_TLSF::GetListIndex(uint8_t memoryClass, uint16_t secondIndex) const
{
    if (memoryClass == 0)
        return secondIndex;

    const uint32_t index = static_cast<uint32_t>(memoryClass - 1) * (1 << SECOND_LEVEL_INDEX) + secondIndex;
    if (IsVirtual())
        return index + (1 << SECOND_LEVEL_INDEX);
    else
        return index + 4;
}

uint32_t VmaBlockMetadata_TLSF::GetListIndex(VkDeviceSize size) const
{
    uint8_t memoryClass = SizeToMemoryClass(size);
    return GetListIndex(memoryClass, SizeToSecondIndex(size, memoryClass));
}

void VmaBlockMetadata_TLSF::RemoveFreeBlock(Block* block)
{
    
# 9594 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9594 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   block != m_NullBlock
# 9594 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9594 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "block != m_NullBlock"
# 9594 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9594),0))
# 9594 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   ;
    
# 9595 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9595 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   block->IsFree()
# 9595 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9595 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "block->IsFree()"
# 9595 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9595),0))
# 9595 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                              ;

    if (block->NextFree() != nullptr)
        block->NextFree()->PrevFree() = block->PrevFree();
    if (block->PrevFree() != nullptr)
        block->PrevFree()->NextFree() = block->NextFree();
    else
    {
        uint8_t memClass = SizeToMemoryClass(block->size);
        uint16_t secondIndex = SizeToSecondIndex(block->size, memClass);
        uint32_t index = GetListIndex(memClass, secondIndex);
        
# 9606 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 9606 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       m_FreeList[index] == block
# 9606 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 9606 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "m_FreeList[index] == block"
# 9606 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9606),0))
# 9606 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                             ;
        m_FreeList[index] = block->NextFree();
        if (block->NextFree() == nullptr)
        {
            m_InnerIsFreeBitmap[memClass] &= ~(1U << secondIndex);
            if (m_InnerIsFreeBitmap[memClass] == 0)
                m_IsFreeBitmap &= ~(1UL << memClass);
        }
    }
    block->MarkTaken();
    block->UserData() = nullptr;
    --m_BlocksFreeCount;
    m_BlocksFreeSize -= block->size;
}

void VmaBlockMetadata_TLSF::InsertFreeBlock(Block* block)
{
    
# 9623 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9623 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   block != m_NullBlock
# 9623 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9623 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "block != m_NullBlock"
# 9623 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9623),0))
# 9623 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   ;
    
# 9624 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9624 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !block->IsFree() && "Cannot insert block twice!"
# 9624 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9624 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!block->IsFree() && \"Cannot insert block twice!\""
# 9624 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9624),0))
# 9624 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                               ;

    uint8_t memClass = SizeToMemoryClass(block->size);
    uint16_t secondIndex = SizeToSecondIndex(block->size, memClass);
    uint32_t index = GetListIndex(memClass, secondIndex);
    
# 9629 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9629 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   index < m_ListsCount
# 9629 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9629 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "index < m_ListsCount"
# 9629 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9629),0))
# 9629 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   ;
    block->PrevFree() = nullptr;
    block->NextFree() = m_FreeList[index];
    m_FreeList[index] = block;
    if (block->NextFree() != nullptr)
        block->NextFree()->PrevFree() = block;
    else
    {
        m_InnerIsFreeBitmap[memClass] |= 1U << secondIndex;
        m_IsFreeBitmap |= 1UL << memClass;
    }
    ++m_BlocksFreeCount;
    m_BlocksFreeSize += block->size;
}

void VmaBlockMetadata_TLSF::MergeBlock(Block* block, Block* prev)
{
    
# 9646 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9646 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   block->prevPhysical == prev && "Cannot merge separate physical regions!"
# 9646 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9646 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "block->prevPhysical == prev && \"Cannot merge separate physical regions!\""
# 9646 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9646),0))
# 9646 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                       ;
    
# 9647 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9647 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   !prev->IsFree() && "Cannot merge block that belongs to free list!"
# 9647 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9647 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "!prev->IsFree() && \"Cannot merge block that belongs to free list!\""
# 9647 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9647),0))
# 9647 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                 ;

    block->offset = prev->offset;
    block->size += prev->size;
    block->prevPhysical = prev->prevPhysical;
    if (block->prevPhysical)
        block->prevPhysical->nextPhysical = block;
    m_BlockAllocator.Free(prev);
}

VmaBlockMetadata_TLSF::Block* VmaBlockMetadata_TLSF::FindFreeBlock(VkDeviceSize size, uint32_t& listIndex) const
{
    uint8_t memoryClass = SizeToMemoryClass(size);
    uint32_t innerFreeMap = m_InnerIsFreeBitmap[memoryClass] & (~0U << SizeToSecondIndex(size, memoryClass));
    if (!innerFreeMap)
    {

        uint32_t freeMap = m_IsFreeBitmap & (~0UL << (memoryClass + 1));
        if (!freeMap)
            return nullptr;


        memoryClass = VmaBitScanLSB(freeMap);
        innerFreeMap = m_InnerIsFreeBitmap[memoryClass];
        
# 9671 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 9671 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       innerFreeMap != 0
# 9671 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 9671 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "innerFreeMap != 0"
# 9671 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9671),0))
# 9671 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                    ;
    }

    listIndex = GetListIndex(memoryClass, VmaBitScanLSB(innerFreeMap));
    
# 9675 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9675 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_FreeList[listIndex]
# 9675 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9675 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_FreeList[listIndex]"
# 9675 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9675),0))
# 9675 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                    ;
    return m_FreeList[listIndex];
}

bool VmaBlockMetadata_TLSF::CheckBlock(
    Block& block,
    uint32_t listIndex,
    VkDeviceSize allocSize,
    VkDeviceSize allocAlignment,
    VmaSuballocationType allocType,
    VmaAllocationRequest* pAllocationRequest)
{
    
# 9687 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 9687 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   block.IsFree() && "Block is already taken!"
# 9687 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 9687 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "block.IsFree() && \"Block is already taken!\""
# 9687 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9687),0))
# 9687 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                          ;

    VkDeviceSize alignedOffset = VmaAlignUp(block.offset, allocAlignment);
    if (block.size < allocSize + alignedOffset - block.offset)
        return false;


    if (!IsVirtual() &&
        m_GranularityHandler.CheckConflictAndAlignUp(alignedOffset, allocSize, block.offset, block.size, allocType))
        return false;


    pAllocationRequest->type = VmaAllocationRequestType::TLSF;
    pAllocationRequest->allocHandle = (VmaAllocHandle)&block;
    pAllocationRequest->size = allocSize - GetDebugMargin();
    pAllocationRequest->customData = (void*)allocType;
    pAllocationRequest->algorithmData = alignedOffset;


    if (listIndex != m_ListsCount && block.PrevFree())
    {
        block.PrevFree()->NextFree() = block.NextFree();
        if (block.NextFree())
            block.NextFree()->PrevFree() = block.PrevFree();
        block.PrevFree() = nullptr;
        block.NextFree() = m_FreeList[listIndex];
        m_FreeList[listIndex] = &block;
        if (block.NextFree())
            block.NextFree()->PrevFree() = &block;
    }

    return true;
}
# 9730 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
class VmaBlockVector
{
    friend struct VmaDefragmentationContext_T;
    private: VmaBlockVector(const VmaBlockVector&) = delete; VmaBlockVector(VmaBlockVector&&) = delete; VmaBlockVector& operator=(const VmaBlockVector&) = delete; VmaBlockVector& operator=(VmaBlockVector&&) = delete;
public:
    VmaBlockVector(
        VmaAllocator hAllocator,
        VmaPool hParentPool,
        uint32_t memoryTypeIndex,
        VkDeviceSize preferredBlockSize,
        size_t minBlockCount,
        size_t maxBlockCount,
        VkDeviceSize bufferImageGranularity,
        bool explicitBlockSize,
        uint32_t algorithm,
        float priority,
        VkDeviceSize minAllocationAlignment,
        void* pMemoryAllocateNext);
    ~VmaBlockVector();

    VmaAllocator GetAllocator() const { return m_hAllocator; }
    VmaPool GetParentPool() const { return m_hParentPool; }
    bool IsCustomPool() const { return m_hParentPool != nullptr; }
    uint32_t GetMemoryTypeIndex() const { return m_MemoryTypeIndex; }
    VkDeviceSize GetPreferredBlockSize() const { return m_PreferredBlockSize; }
    VkDeviceSize GetBufferImageGranularity() const { return m_BufferImageGranularity; }
    uint32_t GetAlgorithm() const { return m_Algorithm; }
    bool HasExplicitBlockSize() const { return m_ExplicitBlockSize; }
    float GetPriority() const { return m_Priority; }
    const void* GetAllocationNextPtr() const { return m_pMemoryAllocateNext; }

    size_t GetBlockCount() const { return m_Blocks.size(); }

    VmaDeviceMemoryBlock* GetBlock(size_t index) const { return m_Blocks[index]; }
    VmaRWMutex &GetMutex() { return m_Mutex; }

    VkResult CreateMinBlocks();
    void AddStatistics(VmaStatistics& inoutStats);
    void AddDetailedStatistics(VmaDetailedStatistics& inoutStats);
    bool IsEmpty();
    bool IsCorruptionDetectionEnabled() const;

    VkResult Allocate(
        VkDeviceSize size,
        VkDeviceSize alignment,
        const VmaAllocationCreateInfo& createInfo,
        VmaSuballocationType suballocType,
        size_t allocationCount,
        VmaAllocation* pAllocations);

    void Free(const VmaAllocation hAllocation);


    void PrintDetailedMap(class VmaJsonWriter& json);


    VkResult CheckCorruption();

private:
    const VmaAllocator m_hAllocator;
    const VmaPool m_hParentPool;
    const uint32_t m_MemoryTypeIndex;
    const VkDeviceSize m_PreferredBlockSize;
    const size_t m_MinBlockCount;
    const size_t m_MaxBlockCount;
    const VkDeviceSize m_BufferImageGranularity;
    const bool m_ExplicitBlockSize;
    const uint32_t m_Algorithm;
    const float m_Priority;
    const VkDeviceSize m_MinAllocationAlignment;

    void* const m_pMemoryAllocateNext;
    VmaRWMutex m_Mutex;

    VmaVector<VmaDeviceMemoryBlock*, VmaStlAllocator<VmaDeviceMemoryBlock*>> m_Blocks;
    uint32_t m_NextBlockId;
    bool m_IncrementalSort = true;

    void SetIncrementalSort(bool val) { m_IncrementalSort = val; }

    VkDeviceSize CalcMaxBlockSize() const;

    void Remove(VmaDeviceMemoryBlock* pBlock);


    void IncrementallySortBlocks();
    void SortByFreeSize();

    VkResult AllocatePage(
        VkDeviceSize size,
        VkDeviceSize alignment,
        const VmaAllocationCreateInfo& createInfo,
        VmaSuballocationType suballocType,
        VmaAllocation* pAllocation);

    VkResult AllocateFromBlock(
        VmaDeviceMemoryBlock* pBlock,
        VkDeviceSize size,
        VkDeviceSize alignment,
        VmaAllocationCreateFlags allocFlags,
        void* pUserData,
        VmaSuballocationType suballocType,
        uint32_t strategy,
        VmaAllocation* pAllocation);

    VkResult CommitAllocationRequest(
        VmaAllocationRequest& allocRequest,
        VmaDeviceMemoryBlock* pBlock,
        VkDeviceSize alignment,
        VmaAllocationCreateFlags allocFlags,
        void* pUserData,
        VmaSuballocationType suballocType,
        VmaAllocation* pAllocation);

    VkResult CreateBlock(VkDeviceSize blockSize, size_t* pNewBlockIndex);
    bool HasEmptyBlock();
};



struct VmaDefragmentationContext_T
{
    private: VmaDefragmentationContext_T(const VmaDefragmentationContext_T&) = delete; VmaDefragmentationContext_T(VmaDefragmentationContext_T&&) = delete; VmaDefragmentationContext_T& operator=(const VmaDefragmentationContext_T&) = delete; VmaDefragmentationContext_T& operator=(VmaDefragmentationContext_T&&) = delete;
public:
    VmaDefragmentationContext_T(
        VmaAllocator hAllocator,
        const VmaDefragmentationInfo& info);
    ~VmaDefragmentationContext_T();

    void GetStats(VmaDefragmentationStats& outStats) { outStats = m_GlobalStats; }

    VkResult DefragmentPassBegin(VmaDefragmentationPassMoveInfo& moveInfo);
    VkResult DefragmentPassEnd(VmaDefragmentationPassMoveInfo& moveInfo);

private:

    static const uint8_t MAX_ALLOCS_TO_IGNORE = 16;
    enum class CounterStatus { Pass, Ignore, End };

    struct FragmentedBlock
    {
        uint32_t data;
        VmaDeviceMemoryBlock* block;
    };
    struct StateBalanced
    {
        VkDeviceSize avgFreeSize = 0;
        VkDeviceSize avgAllocSize = 
# 9877 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                   0xffffffffffffffffULL
# 9877 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                             ;
    };
    struct StateExtensive
    {
        enum class Operation : uint8_t
        {
            FindFreeBlockBuffer, FindFreeBlockTexture, FindFreeBlockAll,
            MoveBuffers, MoveTextures, MoveAll,
            Cleanup, Done
        };

        Operation operation = Operation::FindFreeBlockTexture;
        size_t firstFreeBlock = 
# 9889 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                               0xffffffffffffffffULL
# 9889 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                       ;
    };
    struct MoveAllocationData
    {
        VkDeviceSize size;
        VkDeviceSize alignment;
        VmaSuballocationType type;
        VmaAllocationCreateFlags flags;
        VmaDefragmentationMove move = {};
    };

    const VkDeviceSize m_MaxPassBytes;
    const uint32_t m_MaxPassAllocations;
    const PFN_vmaCheckDefragmentationBreakFunction m_BreakCallback;
    void* m_BreakCallbackUserData;

    VmaStlAllocator<VmaDefragmentationMove> m_MoveAllocator;
    VmaVector<VmaDefragmentationMove, VmaStlAllocator<VmaDefragmentationMove>> m_Moves;

    uint8_t m_IgnoredAllocs = 0;
    uint32_t m_Algorithm;
    uint32_t m_BlockVectorCount;
    VmaBlockVector* m_PoolBlockVector;
    VmaBlockVector** m_pBlockVectors;
    size_t m_ImmovableBlockCount = 0;
    VmaDefragmentationStats m_GlobalStats = { 0 };
    VmaDefragmentationStats m_PassStats = { 0 };
    void* m_AlgorithmState = nullptr;

    static MoveAllocationData GetMoveData(VmaAllocHandle handle, VmaBlockMetadata* metadata);
    CounterStatus CheckCounters(VkDeviceSize bytes);
    bool IncrementCounters(VkDeviceSize bytes);
    bool ReallocWithinBlock(VmaBlockVector& vector, VmaDeviceMemoryBlock* block);
    bool AllocInOtherBlock(size_t start, size_t end, MoveAllocationData& data, VmaBlockVector& vector);

    bool ComputeDefragmentation(VmaBlockVector& vector, size_t index);
    bool ComputeDefragmentation_Fast(VmaBlockVector& vector);
    bool ComputeDefragmentation_Balanced(VmaBlockVector& vector, size_t index, bool update);
    bool ComputeDefragmentation_Full(VmaBlockVector& vector);
    bool ComputeDefragmentation_Extensive(VmaBlockVector& vector, size_t index);

    void UpdateVectorStatistics(VmaBlockVector& vector, StateBalanced& state);
    bool MoveDataToFreeBlocks(VmaSuballocationType currentType,
        VmaBlockVector& vector, size_t firstFreeBlock,
        bool& texturePresent, bool& bufferPresent, bool& otherPresent);
};



struct VmaPool_T
{
    friend struct VmaPoolListItemTraits;
    private: VmaPool_T(const VmaPool_T&) = delete; VmaPool_T(VmaPool_T&&) = delete; VmaPool_T& operator=(const VmaPool_T&) = delete; VmaPool_T& operator=(VmaPool_T&&) = delete;
public:
    VmaBlockVector m_BlockVector;
    VmaDedicatedAllocationList m_DedicatedAllocations;

    VmaPool_T(
        VmaAllocator hAllocator,
        const VmaPoolCreateInfo& createInfo,
        VkDeviceSize preferredBlockSize);
    ~VmaPool_T();

    uint32_t GetId() const { return m_Id; }
    void SetId(uint32_t id) { 
# 9953 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                             (void) ((!!(
# 9953 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                             m_Id == 0
# 9953 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                             )) || (_assert(
# 9953 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                             "m_Id == 0"
# 9953 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                             ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",9953),0))
# 9953 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                  ; m_Id = id; }

    const char* GetName() const { return m_Name; }
    void SetName(const char* pName);





private:
    uint32_t m_Id;
    char* m_Name;
    VmaPool_T* m_PrevPool = nullptr;
    VmaPool_T* m_NextPool = nullptr;
};

struct VmaPoolListItemTraits
{
    typedef VmaPool_T ItemType;

    static ItemType* GetPrev(const ItemType* item) { return item->m_PrevPool; }
    static ItemType* GetNext(const ItemType* item) { return item->m_NextPool; }
    static ItemType*& AccessPrev(ItemType* item) { return item->m_PrevPool; }
    static ItemType*& AccessNext(ItemType* item) { return item->m_NextPool; }
};



struct VmaCurrentBudgetData
{
    private: VmaCurrentBudgetData(const VmaCurrentBudgetData&) = delete; VmaCurrentBudgetData(VmaCurrentBudgetData&&) = delete; VmaCurrentBudgetData& operator=(const VmaCurrentBudgetData&) = delete; VmaCurrentBudgetData& operator=(VmaCurrentBudgetData&&) = delete;
public:

    std::atomic<uint32_t> m_BlockCount[
# 9986 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                  16U
# 9986 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                     ];
    std::atomic<uint32_t> m_AllocationCount[
# 9987 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                       16U
# 9987 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                          ];
    std::atomic<uint64_t> m_BlockBytes[
# 9988 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                  16U
# 9988 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                     ];
    std::atomic<uint64_t> m_AllocationBytes[
# 9989 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                       16U
# 9989 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                          ];


    std::atomic<uint32_t> m_OperationsSinceBudgetFetch;
    VmaRWMutex m_BudgetMutex;
    uint64_t m_VulkanUsage[
# 9994 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                          16U
# 9994 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                             ];
    uint64_t m_VulkanBudget[
# 9995 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                           16U
# 9995 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                              ];
    uint64_t m_BlockBytesAtBudgetFetch[
# 9996 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                      16U
# 9996 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                         ];


    VmaCurrentBudgetData();

    void AddAllocation(uint32_t heapIndex, VkDeviceSize allocationSize);
    void RemoveAllocation(uint32_t heapIndex, VkDeviceSize allocationSize);
};


VmaCurrentBudgetData::VmaCurrentBudgetData()
{
    for (uint32_t heapIndex = 0; heapIndex < 
# 10008 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                            16U
# 10008 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                               ; ++heapIndex)
    {
        m_BlockCount[heapIndex] = 0;
        m_AllocationCount[heapIndex] = 0;
        m_BlockBytes[heapIndex] = 0;
        m_AllocationBytes[heapIndex] = 0;

        m_VulkanUsage[heapIndex] = 0;
        m_VulkanBudget[heapIndex] = 0;
        m_BlockBytesAtBudgetFetch[heapIndex] = 0;

    }


    m_OperationsSinceBudgetFetch = 0;

}

void VmaCurrentBudgetData::AddAllocation(uint32_t heapIndex, VkDeviceSize allocationSize)
{
    m_AllocationBytes[heapIndex] += allocationSize;
    ++m_AllocationCount[heapIndex];

    ++m_OperationsSinceBudgetFetch;

}

void VmaCurrentBudgetData::RemoveAllocation(uint32_t heapIndex, VkDeviceSize allocationSize)
{
    
# 10037 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10037 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_AllocationBytes[heapIndex] >= allocationSize
# 10037 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10037 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_AllocationBytes[heapIndex] >= allocationSize"
# 10037 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10037),0))
# 10037 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                             ;
    m_AllocationBytes[heapIndex] -= allocationSize;
    
# 10039 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10039 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_AllocationCount[heapIndex] > 0
# 10039 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10039 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_AllocationCount[heapIndex] > 0"
# 10039 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10039),0))
# 10039 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                               ;
    --m_AllocationCount[heapIndex];

    ++m_OperationsSinceBudgetFetch;

}







class VmaAllocationObjectAllocator
{
    private: VmaAllocationObjectAllocator(const VmaAllocationObjectAllocator&) = delete; VmaAllocationObjectAllocator(VmaAllocationObjectAllocator&&) = delete; VmaAllocationObjectAllocator& operator=(const VmaAllocationObjectAllocator&) = delete; VmaAllocationObjectAllocator& operator=(VmaAllocationObjectAllocator&&) = delete;
public:
    VmaAllocationObjectAllocator(const VkAllocationCallbacks* pAllocationCallbacks)
        : m_Allocator(pAllocationCallbacks, 1024) {}

    template<typename... Types> VmaAllocation Allocate(Types&&... args);
    void Free(VmaAllocation hAlloc);

private:
    VmaMutex m_Mutex;
    VmaPoolAllocator<VmaAllocation_T> m_Allocator;
};

template<typename... Types>
VmaAllocation VmaAllocationObjectAllocator::Allocate(Types&&... args)
{
    VmaMutexLock mutexLock(m_Mutex);
    return m_Allocator.Alloc<Types...>(std::forward<Types>(args)...);
}

void VmaAllocationObjectAllocator::Free(VmaAllocation hAlloc)
{
    VmaMutexLock mutexLock(m_Mutex);
    m_Allocator.Free(hAlloc);
}



struct VmaVirtualBlock_T
{
    private: VmaVirtualBlock_T(const VmaVirtualBlock_T&) = delete; VmaVirtualBlock_T(VmaVirtualBlock_T&&) = delete; VmaVirtualBlock_T& operator=(const VmaVirtualBlock_T&) = delete; VmaVirtualBlock_T& operator=(VmaVirtualBlock_T&&) = delete;
public:
    const bool m_AllocationCallbacksSpecified;
    const VkAllocationCallbacks m_AllocationCallbacks;

    VmaVirtualBlock_T(const VmaVirtualBlockCreateInfo& createInfo);
    ~VmaVirtualBlock_T();

    VkResult Init() { return VK_SUCCESS; }
    bool IsEmpty() const { return m_Metadata->IsEmpty(); }
    void Free(VmaVirtualAllocation allocation) { m_Metadata->Free((VmaAllocHandle)allocation); }
    void SetAllocationUserData(VmaVirtualAllocation allocation, void* userData) { m_Metadata->SetAllocationUserData((VmaAllocHandle)allocation, userData); }
    void Clear() { m_Metadata->Clear(); }

    const VkAllocationCallbacks* GetAllocationCallbacks() const;
    void GetAllocationInfo(VmaVirtualAllocation allocation, VmaVirtualAllocationInfo& outInfo);
    VkResult Allocate(const VmaVirtualAllocationCreateInfo& createInfo, VmaVirtualAllocation& outAllocation,
        VkDeviceSize* outOffset);
    void GetStatistics(VmaStatistics& outStats) const;
    void CalculateDetailedStatistics(VmaDetailedStatistics& outStats) const;

    void BuildStatsString(bool detailedMap, VmaStringBuilder& sb) const;


private:
    VmaBlockMetadata* m_Metadata;
};


VmaVirtualBlock_T::VmaVirtualBlock_T(const VmaVirtualBlockCreateInfo& createInfo)
    : m_AllocationCallbacksSpecified(createInfo.pAllocationCallbacks != nullptr),
    m_AllocationCallbacks(createInfo.pAllocationCallbacks != nullptr ? *createInfo.pAllocationCallbacks : VmaEmptyAllocationCallbacks)
{
    const uint32_t algorithm = createInfo.flags & VMA_VIRTUAL_BLOCK_CREATE_ALGORITHM_MASK;
    switch (algorithm)
    {
    case 0:
        m_Metadata = new(VmaAllocate<VmaBlockMetadata_TLSF>(GetAllocationCallbacks()))(VmaBlockMetadata_TLSF)(
# 10121 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                                             nullptr
# 10121 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                           , 1, true);
        break;
    case VMA_VIRTUAL_BLOCK_CREATE_LINEAR_ALGORITHM_BIT:
        m_Metadata = new(VmaAllocate<VmaBlockMetadata_Linear>(GetAllocationCallbacks()))(VmaBlockMetadata_Linear)(
# 10124 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                                               nullptr
# 10124 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                             , 1, true);
        break;
    default:
        
# 10127 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 10127 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0
# 10127 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 10127 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0"
# 10127 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10127),0))
# 10127 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                    ;
        m_Metadata = new(VmaAllocate<VmaBlockMetadata_TLSF>(GetAllocationCallbacks()))(VmaBlockMetadata_TLSF)(
# 10128 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                                             nullptr
# 10128 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                           , 1, true);
    }

    m_Metadata->Init(createInfo.size);
}

VmaVirtualBlock_T::~VmaVirtualBlock_T()
{


    if (!m_Metadata->IsEmpty())
        m_Metadata->DebugLogAllAllocations();


    
# 10142 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10142 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_Metadata->IsEmpty() && "Some virtual allocations were not freed before destruction of this virtual block!"
# 10142 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10142 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_Metadata->IsEmpty() && \"Some virtual allocations were not freed before destruction of this virtual block!\""
# 10142 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10142),0))
# 10142 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                ;

    vma_delete(GetAllocationCallbacks(), m_Metadata);
}

const VkAllocationCallbacks* VmaVirtualBlock_T::GetAllocationCallbacks() const
{
    return m_AllocationCallbacksSpecified ? &m_AllocationCallbacks : nullptr;
}

void VmaVirtualBlock_T::GetAllocationInfo(VmaVirtualAllocation allocation, VmaVirtualAllocationInfo& outInfo)
{
    m_Metadata->GetAllocationInfo((VmaAllocHandle)allocation, outInfo);
}

VkResult VmaVirtualBlock_T::Allocate(const VmaVirtualAllocationCreateInfo& createInfo, VmaVirtualAllocation& outAllocation,
    VkDeviceSize* outOffset)
{
    VmaAllocationRequest request = {};
    if (m_Metadata->CreateAllocationRequest(
        createInfo.size,
        ((std::max)((createInfo.alignment), ((VkDeviceSize)1))),
        (createInfo.flags & VMA_VIRTUAL_ALLOCATION_CREATE_UPPER_ADDRESS_BIT) != 0,
        VMA_SUBALLOCATION_TYPE_UNKNOWN,
        createInfo.flags & VMA_VIRTUAL_ALLOCATION_CREATE_STRATEGY_MASK,
        &request))
    {
        m_Metadata->Alloc(request,
            VMA_SUBALLOCATION_TYPE_UNKNOWN,
            createInfo.pUserData);
        outAllocation = (VmaVirtualAllocation)request.allocHandle;
        if(outOffset)
            *outOffset = m_Metadata->GetAllocationOffset(request.allocHandle);
        return VK_SUCCESS;
    }
    outAllocation = (VmaVirtualAllocation)
# 10177 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                         nullptr
# 10177 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                       ;
    if (outOffset)
        *outOffset = 
# 10179 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                    0xffffffffffffffffULL
# 10179 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                              ;
    return VK_ERROR_OUT_OF_DEVICE_MEMORY;
}

void VmaVirtualBlock_T::GetStatistics(VmaStatistics& outStats) const
{
    VmaClearStatistics(outStats);
    m_Metadata->AddStatistics(outStats);
}

void VmaVirtualBlock_T::CalculateDetailedStatistics(VmaDetailedStatistics& outStats) const
{
    VmaClearDetailedStatistics(outStats);
    m_Metadata->AddDetailedStatistics(outStats);
}


void VmaVirtualBlock_T::BuildStatsString(bool detailedMap, VmaStringBuilder& sb) const
{
    VmaJsonWriter json(GetAllocationCallbacks(), sb);
    json.BeginObject();

    VmaDetailedStatistics stats;
    CalculateDetailedStatistics(stats);

    json.WriteString("Stats");
    VmaPrintDetailedStatistics(json, stats);

    if (detailedMap)
    {
        json.WriteString("Details");
        json.BeginObject();
        m_Metadata->PrintDetailedMap(json);
        json.EndObject();
    }

    json.EndObject();
}






struct VmaAllocator_T
{
    private: VmaAllocator_T(const VmaAllocator_T&) = delete; VmaAllocator_T(VmaAllocator_T&&) = delete; VmaAllocator_T& operator=(const VmaAllocator_T&) = delete; VmaAllocator_T& operator=(VmaAllocator_T&&) = delete;
public:
    const bool m_UseMutex;
    const uint32_t m_VulkanApiVersion;
    bool m_UseKhrDedicatedAllocation;
    bool m_UseKhrBindMemory2;
    bool m_UseExtMemoryBudget;
    bool m_UseAmdDeviceCoherentMemory;
    bool m_UseKhrBufferDeviceAddress;
    bool m_UseExtMemoryPriority;
    bool m_UseKhrMaintenance4;
    bool m_UseKhrMaintenance5;
    bool m_UseKhrExternalMemoryWin32;
    const VkDevice m_hDevice;
    const VkInstance m_hInstance;
    const bool m_AllocationCallbacksSpecified;
    const VkAllocationCallbacks m_AllocationCallbacks;
    VmaDeviceMemoryCallbacks m_DeviceMemoryCallbacks;
    VmaAllocationObjectAllocator m_AllocationObjectAllocator;


    uint32_t m_HeapSizeLimitMask;

    VkPhysicalDeviceProperties m_PhysicalDeviceProperties;
    VkPhysicalDeviceMemoryProperties m_MemProps;


    VmaBlockVector* m_pBlockVectors[
# 10252 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                   32U
# 10252 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                      ];
    VmaDedicatedAllocationList m_DedicatedAllocations[
# 10253 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                     32U
# 10253 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                        ];

    VmaCurrentBudgetData m_Budget;
    std::atomic<uint32_t> m_DeviceMemoryCount;

    VmaAllocator_T(const VmaAllocatorCreateInfo* pCreateInfo);
    VkResult Init(const VmaAllocatorCreateInfo* pCreateInfo);
    ~VmaAllocator_T();

    const VkAllocationCallbacks* GetAllocationCallbacks() const
    {
        return m_AllocationCallbacksSpecified ? &m_AllocationCallbacks : nullptr;
    }
    const VmaVulkanFunctions& GetVulkanFunctions() const
    {
        return m_VulkanFunctions;
    }

    VkPhysicalDevice GetPhysicalDevice() const { return m_PhysicalDevice; }

    VkDeviceSize GetBufferImageGranularity() const
    {
        return ((std::max)((static_cast<VkDeviceSize>((1))), (m_PhysicalDeviceProperties.limits.bufferImageGranularity)))

                                                                     ;
    }

    uint32_t GetMemoryHeapCount() const { return m_MemProps.memoryHeapCount; }
    uint32_t GetMemoryTypeCount() const { return m_MemProps.memoryTypeCount; }

    uint32_t MemoryTypeIndexToHeapIndex(uint32_t memTypeIndex) const
    {
        
# 10285 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 10285 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       memTypeIndex < m_MemProps.memoryTypeCount
# 10285 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 10285 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "memTypeIndex < m_MemProps.memoryTypeCount"
# 10285 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10285),0))
# 10285 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                            ;
        return m_MemProps.memoryTypes[memTypeIndex].heapIndex;
    }

    bool IsMemoryTypeNonCoherent(uint32_t memTypeIndex) const
    {
        return (m_MemProps.memoryTypes[memTypeIndex].propertyFlags & (VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT)) ==
            VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT;
    }

    VkDeviceSize GetMemoryTypeMinAlignment(uint32_t memTypeIndex) const
    {
        return IsMemoryTypeNonCoherent(memTypeIndex) ?
            ((std::max)(((VkDeviceSize)(1)), (m_PhysicalDeviceProperties.limits.nonCoherentAtomSize))) :
            (VkDeviceSize)(1);
    }

    bool IsIntegratedGpu() const
    {
        return m_PhysicalDeviceProperties.deviceType == VK_PHYSICAL_DEVICE_TYPE_INTEGRATED_GPU;
    }

    uint32_t GetGlobalMemoryTypeBits() const { return m_GlobalMemoryTypeBits; }

    void GetBufferMemoryRequirements(
        VkBuffer hBuffer,
        VkMemoryRequirements& memReq,
        bool& requiresDedicatedAllocation,
        bool& prefersDedicatedAllocation) const;
    void GetImageMemoryRequirements(
        VkImage hImage,
        VkMemoryRequirements& memReq,
        bool& requiresDedicatedAllocation,
        bool& prefersDedicatedAllocation) const;
    VkResult FindMemoryTypeIndex(
        uint32_t memoryTypeBits,
        const VmaAllocationCreateInfo* pAllocationCreateInfo,
        VmaBufferImageUsage bufImgUsage,
        uint32_t* pMemoryTypeIndex) const;


    VkResult AllocateMemory(
        const VkMemoryRequirements& vkMemReq,
        bool requiresDedicatedAllocation,
        bool prefersDedicatedAllocation,
        VkBuffer dedicatedBuffer,
        VkImage dedicatedImage,
        VmaBufferImageUsage dedicatedBufferImageUsage,
        const VmaAllocationCreateInfo& createInfo,
        VmaSuballocationType suballocType,
        size_t allocationCount,
        VmaAllocation* pAllocations);


    void FreeMemory(
        size_t allocationCount,
        const VmaAllocation* pAllocations);

    void CalculateStatistics(VmaTotalStatistics* pStats);

    void GetHeapBudgets(
        VmaBudget* outBudgets, uint32_t firstHeap, uint32_t heapCount);


    void PrintDetailedMap(class VmaJsonWriter& json);


    void GetAllocationInfo(VmaAllocation hAllocation, VmaAllocationInfo* pAllocationInfo);
    void GetAllocationInfo2(VmaAllocation hAllocation, VmaAllocationInfo2* pAllocationInfo);

    VkResult CreatePool(const VmaPoolCreateInfo* pCreateInfo, VmaPool* pPool);
    void DestroyPool(VmaPool pool);
    void GetPoolStatistics(VmaPool pool, VmaStatistics* pPoolStats);
    void CalculatePoolStatistics(VmaPool pool, VmaDetailedStatistics* pPoolStats);

    void SetCurrentFrameIndex(uint32_t frameIndex);
    uint32_t GetCurrentFrameIndex() const { return m_CurrentFrameIndex.load(); }

    VkResult CheckPoolCorruption(VmaPool hPool);
    VkResult CheckCorruption(uint32_t memoryTypeBits);


    VkResult AllocateVulkanMemory(const VkMemoryAllocateInfo* pAllocateInfo, VkDeviceMemory* pMemory);

    void FreeVulkanMemory(uint32_t memoryType, VkDeviceSize size, VkDeviceMemory hMemory);

    VkResult BindVulkanBuffer(
        VkDeviceMemory memory,
        VkDeviceSize memoryOffset,
        VkBuffer buffer,
        const void* pNext);

    VkResult BindVulkanImage(
        VkDeviceMemory memory,
        VkDeviceSize memoryOffset,
        VkImage image,
        const void* pNext);

    VkResult Map(VmaAllocation hAllocation, void** ppData);
    void Unmap(VmaAllocation hAllocation);

    VkResult BindBufferMemory(
        VmaAllocation hAllocation,
        VkDeviceSize allocationLocalOffset,
        VkBuffer hBuffer,
        const void* pNext);
    VkResult BindImageMemory(
        VmaAllocation hAllocation,
        VkDeviceSize allocationLocalOffset,
        VkImage hImage,
        const void* pNext);

    VkResult FlushOrInvalidateAllocation(
        VmaAllocation hAllocation,
        VkDeviceSize offset, VkDeviceSize size,
        VMA_CACHE_OPERATION op);
    VkResult FlushOrInvalidateAllocations(
        uint32_t allocationCount,
        const VmaAllocation* allocations,
        const VkDeviceSize* offsets, const VkDeviceSize* sizes,
        VMA_CACHE_OPERATION op);

    VkResult CopyMemoryToAllocation(
        const void* pSrcHostPointer,
        VmaAllocation dstAllocation,
        VkDeviceSize dstAllocationLocalOffset,
        VkDeviceSize size);
    VkResult CopyAllocationToMemory(
        VmaAllocation srcAllocation,
        VkDeviceSize srcAllocationLocalOffset,
        void* pDstHostPointer,
        VkDeviceSize size);

    void FillAllocation(const VmaAllocation hAllocation, uint8_t pattern);





    uint32_t GetGpuDefragmentationMemoryTypeBits();


    VkExternalMemoryHandleTypeFlagsKHR GetExternalMemoryHandleTypeFlags(uint32_t memTypeIndex) const
    {
        return m_TypeExternalMemoryHandleTypes[memTypeIndex];
    }


private:
    VkDeviceSize m_PreferredLargeHeapBlockSize;

    VkPhysicalDevice m_PhysicalDevice;
    std::atomic<uint32_t> m_CurrentFrameIndex;
    std::atomic<uint32_t> m_GpuDefragmentationMemoryTypeBits;

    VkExternalMemoryHandleTypeFlagsKHR m_TypeExternalMemoryHandleTypes[
# 10440 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                                      32U
# 10440 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                         ];


    VmaRWMutex m_PoolsMutex;
    typedef VmaIntrusiveLinkedList<VmaPoolListItemTraits> PoolList;

    PoolList m_Pools;
    uint32_t m_NextPoolId;

    VmaVulkanFunctions m_VulkanFunctions;


    uint32_t m_GlobalMemoryTypeBits;

    void ImportVulkanFunctions(const VmaVulkanFunctions* pVulkanFunctions);


    void ImportVulkanFunctions_Static();


    void ImportVulkanFunctions_Custom(const VmaVulkanFunctions* pVulkanFunctions);


    void ImportVulkanFunctions_Dynamic();


    void ValidateVulkanFunctions();

    VkDeviceSize CalcPreferredBlockSize(uint32_t memTypeIndex);

    VkResult AllocateMemoryOfType(
        VmaPool pool,
        VkDeviceSize size,
        VkDeviceSize alignment,
        bool dedicatedPreferred,
        VkBuffer dedicatedBuffer,
        VkImage dedicatedImage,
        VmaBufferImageUsage dedicatedBufferImageUsage,
        const VmaAllocationCreateInfo& createInfo,
        uint32_t memTypeIndex,
        VmaSuballocationType suballocType,
        VmaDedicatedAllocationList& dedicatedAllocations,
        VmaBlockVector& blockVector,
        size_t allocationCount,
        VmaAllocation* pAllocations);


    VkResult AllocateDedicatedMemoryPage(
        VmaPool pool,
        VkDeviceSize size,
        VmaSuballocationType suballocType,
        uint32_t memTypeIndex,
        const VkMemoryAllocateInfo& allocInfo,
        bool map,
        bool isUserDataString,
        bool isMappingAllowed,
        void* pUserData,
        VmaAllocation* pAllocation);


    VkResult AllocateDedicatedMemory(
        VmaPool pool,
        VkDeviceSize size,
        VmaSuballocationType suballocType,
        VmaDedicatedAllocationList& dedicatedAllocations,
        uint32_t memTypeIndex,
        bool map,
        bool isUserDataString,
        bool isMappingAllowed,
        bool canAliasMemory,
        void* pUserData,
        float priority,
        VkBuffer dedicatedBuffer,
        VkImage dedicatedImage,
        VmaBufferImageUsage dedicatedBufferImageUsage,
        size_t allocationCount,
        VmaAllocation* pAllocations,
        const void* pNextChain = nullptr);

    void FreeDedicatedMemory(const VmaAllocation allocation);

    VkResult CalcMemTypeParams(
        VmaAllocationCreateInfo& outCreateInfo,
        uint32_t memTypeIndex,
        VkDeviceSize size,
        size_t allocationCount);
    VkResult CalcAllocationParams(
        VmaAllocationCreateInfo& outCreateInfo,
        bool dedicatedRequired,
        bool dedicatedPreferred);





    uint32_t CalculateGpuDefragmentationMemoryTypeBits() const;
    uint32_t CalculateGlobalMemoryTypeBits() const;

    bool GetFlushOrInvalidateRange(
        VmaAllocation allocation,
        VkDeviceSize offset, VkDeviceSize size,
        VkMappedMemoryRange& outRange) const;


    void UpdateVulkanBudget();

};



static void* VmaMalloc(VmaAllocator hAllocator, size_t size, size_t alignment)
{
    return VmaMalloc(&hAllocator->m_AllocationCallbacks, size, alignment);
}

static void VmaFree(VmaAllocator hAllocator, void* ptr)
{
    VmaFree(&hAllocator->m_AllocationCallbacks, ptr);
}

template<typename T>
static T* VmaAllocate(VmaAllocator hAllocator)
{
    return (T*)VmaMalloc(hAllocator, sizeof(T), (alignof(T)));
}

template<typename T>
static T* VmaAllocateArray(VmaAllocator hAllocator, size_t count)
{
    return (T*)VmaMalloc(hAllocator, sizeof(T) * count, (alignof(T)));
}

template<typename T>
static void vma_delete(VmaAllocator hAllocator, T* ptr)
{
    if(ptr != nullptr)
    {
        ptr->~T();
        VmaFree(hAllocator, ptr);
    }
}

template<typename T>
static void vma_delete_array(VmaAllocator hAllocator, T* ptr, size_t count)
{
    if(ptr != nullptr)
    {
        for(size_t i = count; i--; )
            ptr[i].~T();
        VmaFree(hAllocator, ptr);
    }
}



VmaDeviceMemoryBlock::VmaDeviceMemoryBlock(VmaAllocator hAllocator)
    : m_pMetadata(nullptr),
    m_MemoryTypeIndex(
# 10597 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                     0xffffffffU
# 10597 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                               ),
    m_Id(0),
    m_hMemory(
# 10599 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
             nullptr
# 10599 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                           ),
    m_MapCount(0),
    m_pMappedData(nullptr){}

VmaDeviceMemoryBlock::~VmaDeviceMemoryBlock()
{
    
# 10605 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10605 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_MapCount == 0 && "VkDeviceMemory block is being destroyed while it is still mapped."
# 10605 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10605 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_MapCount == 0 && \"VkDeviceMemory block is being destroyed while it is still mapped.\""
# 10605 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10605),0))
# 10605 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                          ;
    
# 10606 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10606 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_hMemory == 
# 10606 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   nullptr)) || (_assert(
# 10606 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_hMemory == nullptr"
# 10606 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10606),0))
# 10606 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                               ;
}

void VmaDeviceMemoryBlock::Init(
    VmaAllocator hAllocator,
    VmaPool hParentPool,
    uint32_t newMemoryTypeIndex,
    VkDeviceMemory newMemory,
    VkDeviceSize newSize,
    uint32_t id,
    uint32_t algorithm,
    VkDeviceSize bufferImageGranularity)
{
    
# 10619 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10619 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_hMemory == 
# 10619 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   nullptr)) || (_assert(
# 10619 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_hMemory == nullptr"
# 10619 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10619),0))
# 10619 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                          ;

    m_hParentPool = hParentPool;
    m_MemoryTypeIndex = newMemoryTypeIndex;
    m_Id = id;
    m_hMemory = newMemory;

    switch (algorithm)
    {
    case 0:
        m_pMetadata = new(VmaAllocate<VmaBlockMetadata_TLSF>(hAllocator))(VmaBlockMetadata_TLSF)(hAllocator->GetAllocationCallbacks(),
            bufferImageGranularity, false);
        break;
    case VMA_POOL_CREATE_LINEAR_ALGORITHM_BIT:
        m_pMetadata = new(VmaAllocate<VmaBlockMetadata_Linear>(hAllocator))(VmaBlockMetadata_Linear)(hAllocator->GetAllocationCallbacks(),
            bufferImageGranularity, false);
        break;
    default:
        
# 10637 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 10637 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0
# 10637 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 10637 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0"
# 10637 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10637),0))
# 10637 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                    ;
        m_pMetadata = new(VmaAllocate<VmaBlockMetadata_TLSF>(hAllocator))(VmaBlockMetadata_TLSF)(hAllocator->GetAllocationCallbacks(),
            bufferImageGranularity, false);
    }
    m_pMetadata->Init(newSize);
}

void VmaDeviceMemoryBlock::Destroy(VmaAllocator allocator)
{


    if (!m_pMetadata->IsEmpty())
        m_pMetadata->DebugLogAllAllocations();


    
# 10652 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10652 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_pMetadata->IsEmpty() && "Some allocations were not freed before destruction of this memory block!"
# 10652 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10652 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_pMetadata->IsEmpty() && \"Some allocations were not freed before destruction of this memory block!\""
# 10652 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10652),0))
# 10652 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                        ;

    
# 10654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_hMemory != 
# 10654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   nullptr)) || (_assert(
# 10654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_hMemory != nullptr"
# 10654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10654),0))
# 10654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                               ;
    allocator->FreeVulkanMemory(m_MemoryTypeIndex, m_pMetadata->GetSize(), m_hMemory);
    m_hMemory = 
# 10656 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
               nullptr
# 10656 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                             ;

    vma_delete(allocator, m_pMetadata);
    m_pMetadata = nullptr;
}

void VmaDeviceMemoryBlock::PostAlloc(VmaAllocator hAllocator)
{
    VmaMutexLock lock(m_MapAndBindMutex, hAllocator->m_UseMutex);
    m_MappingHysteresis.PostAlloc();
}

void VmaDeviceMemoryBlock::PostFree(VmaAllocator hAllocator)
{
    VmaMutexLock lock(m_MapAndBindMutex, hAllocator->m_UseMutex);
    if(m_MappingHysteresis.PostFree())
    {
        
# 10673 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 10673 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       m_MappingHysteresis.GetExtraMapping() == 0
# 10673 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 10673 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "m_MappingHysteresis.GetExtraMapping() == 0"
# 10673 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10673),0))
# 10673 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                             ;
        if (m_MapCount == 0)
        {
            m_pMappedData = nullptr;
            (*hAllocator->GetVulkanFunctions().vkUnmapMemory)(hAllocator->m_hDevice, m_hMemory);
        }
    }
}

bool VmaDeviceMemoryBlock::Validate() const
{
    do { if(!((m_hMemory != 
# 10684 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   nullptr
# 10684 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   ) && (m_pMetadata->GetSize() != 0))) { 
# 10684 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10684 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0 && "Validation failed: " "(m_hMemory != VK_NULL_HANDLE) && (m_pMetadata->GetSize() != 0)"
# 10684 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10684 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0 && \"Validation failed: \" \"(m_hMemory != VK_NULL_HANDLE) && (m_pMetadata->GetSize() != 0)\""
# 10684 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10684),0))
# 10684 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   ; return false; } } while(false)
                                      ;

    return m_pMetadata->Validate();
}

VkResult VmaDeviceMemoryBlock::CheckCorruption(VmaAllocator hAllocator)
{
    void* pData = nullptr;
    VkResult res = Map(hAllocator, 1, &pData);
    if (res != VK_SUCCESS)
    {
        return res;
    }

    res = m_pMetadata->CheckCorruption(pData);

    Unmap(hAllocator, 1);

    return res;
}

VkResult VmaDeviceMemoryBlock::Map(VmaAllocator hAllocator, uint32_t count, void** ppData)
{
    if (count == 0)
    {
        return VK_SUCCESS;
    }

    VmaMutexLock lock(m_MapAndBindMutex, hAllocator->m_UseMutex);
    const uint32_t oldTotalMapCount = m_MapCount + m_MappingHysteresis.GetExtraMapping();
    if (oldTotalMapCount != 0)
    {
        
# 10717 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 10717 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       m_pMappedData != nullptr
# 10717 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 10717 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "m_pMappedData != nullptr"
# 10717 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10717),0))
# 10717 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                            ;
        m_MappingHysteresis.PostMap();
        m_MapCount += count;
        if (ppData != nullptr)
        {
            *ppData = m_pMappedData;
        }
        return VK_SUCCESS;
    }
    else
    {
        VkResult result = (*hAllocator->GetVulkanFunctions().vkMapMemory)(
            hAllocator->m_hDevice,
            m_hMemory,
            0,
            
# 10732 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
           (~0ULL)
# 10732 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ,
            0,
            &m_pMappedData);
        if (result == VK_SUCCESS)
        {
            
# 10737 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 10737 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           m_pMappedData != nullptr
# 10737 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 10737 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "m_pMappedData != nullptr"
# 10737 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10737),0))
# 10737 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                ;
            m_MappingHysteresis.PostMap();
            m_MapCount = count;
            if (ppData != nullptr)
            {
                *ppData = m_pMappedData;
            }
        }
        return result;
    }
}

void VmaDeviceMemoryBlock::Unmap(VmaAllocator hAllocator, uint32_t count)
{
    if (count == 0)
    {
        return;
    }

    VmaMutexLock lock(m_MapAndBindMutex, hAllocator->m_UseMutex);
    if (m_MapCount >= count)
    {
        m_MapCount -= count;
        const uint32_t totalMapCount = m_MapCount + m_MappingHysteresis.GetExtraMapping();
        if (totalMapCount == 0)
        {
            m_pMappedData = nullptr;
            (*hAllocator->GetVulkanFunctions().vkUnmapMemory)(hAllocator->m_hDevice, m_hMemory);
        }
        m_MappingHysteresis.PostUnmap();
    }
    else
    {
        
# 10770 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 10770 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "VkDeviceMemory block is being unmapped while it was not previously mapped."
# 10770 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 10770 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"VkDeviceMemory block is being unmapped while it was not previously mapped.\""
# 10770 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10770),0))
# 10770 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                    ;
    }
}

VkResult VmaDeviceMemoryBlock::WriteMagicValueAfterAllocation(VmaAllocator hAllocator, VkDeviceSize allocOffset, VkDeviceSize allocSize)
{
    
# 10776 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10776 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   (0) > 0 && (0) % 4 == 0 && (0)
# 10776 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10776 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "(0) > 0 && (0) % 4 == 0 && (0)"
# 10776 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10776),0))
# 10776 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                               ;

    void* pData;
    VkResult res = Map(hAllocator, 1, &pData);
    if (res != VK_SUCCESS)
    {
        return res;
    }

    VmaWriteMagicValue(pData, allocOffset + allocSize);

    Unmap(hAllocator, 1);
    return VK_SUCCESS;
}

VkResult VmaDeviceMemoryBlock::ValidateMagicValueAfterAllocation(VmaAllocator hAllocator, VkDeviceSize allocOffset, VkDeviceSize allocSize)
{
    
# 10793 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10793 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   (0) > 0 && (0) % 4 == 0 && (0)
# 10793 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10793 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "(0) > 0 && (0) % 4 == 0 && (0)"
# 10793 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10793),0))
# 10793 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                               ;

    void* pData;
    VkResult res = Map(hAllocator, 1, &pData);
    if (res != VK_SUCCESS)
    {
        return res;
    }

    if (!VmaValidateMagicValue(pData, allocOffset + allocSize))
    {
        
# 10804 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 10804 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "MEMORY CORRUPTION DETECTED AFTER FREED ALLOCATION!"
# 10804 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 10804 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"MEMORY CORRUPTION DETECTED AFTER FREED ALLOCATION!\""
# 10804 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10804),0))
# 10804 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                            ;
    }

    Unmap(hAllocator, 1);
    return VK_SUCCESS;
}

VkResult VmaDeviceMemoryBlock::BindBufferMemory(
    const VmaAllocator hAllocator,
    const VmaAllocation hAllocation,
    VkDeviceSize allocationLocalOffset,
    VkBuffer hBuffer,
    const void* pNext)
{
    
# 10818 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10818 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   hAllocation->GetType() == VmaAllocation_T::ALLOCATION_TYPE_BLOCK && hAllocation->GetBlock() == this
# 10818 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10818 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "hAllocation->GetType() == VmaAllocation_T::ALLOCATION_TYPE_BLOCK && hAllocation->GetBlock() == this"
# 10818 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10818),0))
                                        
# 10819 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                       ;
    
# 10820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocationLocalOffset < hAllocation->GetSize() && "Invalid allocationLocalOffset. Did you forget that this offset is relative to the beginning of the allocation, not the whole memory block?"
# 10820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocationLocalOffset < hAllocation->GetSize() && \"Invalid allocationLocalOffset. Did you forget that this offset is relative to the beginning of the allocation, not the whole memory block?\""
# 10820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10820),0))
                                                                                                                                                     
# 10821 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                                    ;
    const VkDeviceSize memoryOffset = hAllocation->GetOffset() + allocationLocalOffset;

    VmaMutexLock lock(m_MapAndBindMutex, hAllocator->m_UseMutex);
    return hAllocator->BindVulkanBuffer(m_hMemory, memoryOffset, hBuffer, pNext);
}

VkResult VmaDeviceMemoryBlock::BindImageMemory(
    const VmaAllocator hAllocator,
    const VmaAllocation hAllocation,
    VkDeviceSize allocationLocalOffset,
    VkImage hImage,
    const void* pNext)
{
    
# 10835 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10835 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   hAllocation->GetType() == VmaAllocation_T::ALLOCATION_TYPE_BLOCK && hAllocation->GetBlock() == this
# 10835 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10835 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "hAllocation->GetType() == VmaAllocation_T::ALLOCATION_TYPE_BLOCK && hAllocation->GetBlock() == this"
# 10835 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10835),0))
                                        
# 10836 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                       ;
    
# 10837 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10837 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocationLocalOffset < hAllocation->GetSize() && "Invalid allocationLocalOffset. Did you forget that this offset is relative to the beginning of the allocation, not the whole memory block?"
# 10837 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10837 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocationLocalOffset < hAllocation->GetSize() && \"Invalid allocationLocalOffset. Did you forget that this offset is relative to the beginning of the allocation, not the whole memory block?\""
# 10837 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10837),0))
                                                                                                                                                     
# 10838 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                                    ;
    const VkDeviceSize memoryOffset = hAllocation->GetOffset() + allocationLocalOffset;

    VmaMutexLock lock(m_MapAndBindMutex, hAllocator->m_UseMutex);
    return hAllocator->BindVulkanImage(m_hMemory, memoryOffset, hImage, pNext);
}
# 10855 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
VmaAllocation_T::VmaAllocation_T(bool mappingAllowed)
    : m_Alignment{ 1 },
    m_Size{ 0 },
    m_pUserData{ nullptr },
    m_pName{ nullptr },
    m_MemoryTypeIndex{ 0 },
    m_Type{ (uint8_t)ALLOCATION_TYPE_NONE },
    m_SuballocationType{ (uint8_t)VMA_SUBALLOCATION_TYPE_UNKNOWN },
    m_MapCount{ 0 },
    m_Flags{ 0 }
{
    if(mappingAllowed)
        m_Flags |= (uint8_t)FLAG_MAPPING_ALLOWED;
}

VmaAllocation_T::~VmaAllocation_T()
{
    
# 10872 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10872 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_MapCount == 0 && "Allocation was not unmapped before destruction."
# 10872 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10872 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_MapCount == 0 && \"Allocation was not unmapped before destruction.\""
# 10872 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10872),0))
# 10872 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                        ;


    
# 10875 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10875 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_pName == nullptr
# 10875 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10875 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_pName == nullptr"
# 10875 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10875),0))
# 10875 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                  ;
}

void VmaAllocation_T::InitBlockAllocation(
    VmaDeviceMemoryBlock* block,
    VmaAllocHandle allocHandle,
    VkDeviceSize alignment,
    VkDeviceSize size,
    uint32_t memoryTypeIndex,
    VmaSuballocationType suballocationType,
    bool mapped)
{
    
# 10887 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10887 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_Type == ALLOCATION_TYPE_NONE
# 10887 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10887 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_Type == ALLOCATION_TYPE_NONE"
# 10887 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10887),0))
# 10887 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                             ;
    
# 10888 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10888 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   block != nullptr
# 10888 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10888 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "block != nullptr"
# 10888 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10888),0))
# 10888 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                ;
    m_Type = (uint8_t)ALLOCATION_TYPE_BLOCK;
    m_Alignment = alignment;
    m_Size = size;
    m_MemoryTypeIndex = memoryTypeIndex;
    if(mapped)
    {
        
# 10895 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 10895 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       IsMappingAllowed() && "Mapping is not allowed on this allocation! Please use one of the new VMA_ALLOCATION_CREATE_HOST_ACCESS_* flags when creating it."
# 10895 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 10895 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "IsMappingAllowed() && \"Mapping is not allowed on this allocation! Please use one of the new VMA_ALLOCATION_CREATE_HOST_ACCESS_* flags when creating it.\""
# 10895 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10895),0))
# 10895 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                                                           ;
        m_Flags |= (uint8_t)FLAG_PERSISTENT_MAP;
    }
    m_SuballocationType = (uint8_t)suballocationType;
    m_BlockAllocation.m_Block = block;
    m_BlockAllocation.m_AllocHandle = allocHandle;
}

void VmaAllocation_T::InitDedicatedAllocation(
    VmaAllocator allocator,
    VmaPool hParentPool,
    uint32_t memoryTypeIndex,
    VkDeviceMemory hMemory,
    VmaSuballocationType suballocationType,
    void* pMappedData,
    VkDeviceSize size)
{
    
# 10912 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10912 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_Type == ALLOCATION_TYPE_NONE
# 10912 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10912 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_Type == ALLOCATION_TYPE_NONE"
# 10912 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10912),0))
# 10912 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                             ;
    
# 10913 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10913 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   hMemory != 
# 10913 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   nullptr)) || (_assert(
# 10913 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "hMemory != nullptr"
# 10913 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10913),0))
# 10913 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                        ;
    m_Type = (uint8_t)ALLOCATION_TYPE_DEDICATED;
    m_Alignment = 0;
    m_Size = size;
    m_MemoryTypeIndex = memoryTypeIndex;
    m_SuballocationType = (uint8_t)suballocationType;
    m_DedicatedAllocation.m_ExtraData = nullptr;
    m_DedicatedAllocation.m_hParentPool = hParentPool;
    m_DedicatedAllocation.m_hMemory = hMemory;
    m_DedicatedAllocation.m_Prev = nullptr;
    m_DedicatedAllocation.m_Next = nullptr;

    if (pMappedData != nullptr)
    {
        
# 10927 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 10927 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       IsMappingAllowed() && "Mapping is not allowed on this allocation! Please use one of the new VMA_ALLOCATION_CREATE_HOST_ACCESS_* flags when creating it."
# 10927 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 10927 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "IsMappingAllowed() && \"Mapping is not allowed on this allocation! Please use one of the new VMA_ALLOCATION_CREATE_HOST_ACCESS_* flags when creating it.\""
# 10927 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10927),0))
# 10927 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                                                           ;
        m_Flags |= (uint8_t)FLAG_PERSISTENT_MAP;
        EnsureExtraData(allocator);
        m_DedicatedAllocation.m_ExtraData->m_pMappedData = pMappedData;
    }
}

void VmaAllocation_T::Destroy(VmaAllocator allocator)
{
    FreeName(allocator);

    if (GetType() == ALLOCATION_TYPE_DEDICATED)
    {
        vma_delete(allocator, m_DedicatedAllocation.m_ExtraData);
    }
}

void VmaAllocation_T::SetName(VmaAllocator hAllocator, const char* pName)
{
    
# 10946 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10946 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pName == nullptr || pName != m_pName
# 10946 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10946 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pName == nullptr || pName != m_pName"
# 10946 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10946),0))
# 10946 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                    ;

    FreeName(hAllocator);

    if (pName != nullptr)
        m_pName = VmaCreateStringCopy(hAllocator->GetAllocationCallbacks(), pName);
}

uint8_t VmaAllocation_T::SwapBlockAllocation(VmaAllocator hAllocator, VmaAllocation allocation)
{
    
# 10956 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10956 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocation != nullptr
# 10956 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10956 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocation != nullptr"
# 10956 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10956),0))
# 10956 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                     ;
    
# 10957 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10957 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_Type == ALLOCATION_TYPE_BLOCK
# 10957 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10957 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_Type == ALLOCATION_TYPE_BLOCK"
# 10957 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10957),0))
# 10957 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                              ;
    
# 10958 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 10958 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocation->m_Type == ALLOCATION_TYPE_BLOCK
# 10958 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 10958 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocation->m_Type == ALLOCATION_TYPE_BLOCK"
# 10958 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10958),0))
# 10958 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                          ;

    if (m_MapCount != 0)
        m_BlockAllocation.m_Block->Unmap(hAllocator, m_MapCount);

    m_BlockAllocation.m_Block->m_pMetadata->SetAllocationUserData(m_BlockAllocation.m_AllocHandle, allocation);
    std::swap(m_BlockAllocation, allocation->m_BlockAllocation);
    m_BlockAllocation.m_Block->m_pMetadata->SetAllocationUserData(m_BlockAllocation.m_AllocHandle, this);


    std::swap(m_BufferImageUsage, allocation->m_BufferImageUsage);

    return m_MapCount;
}

VmaAllocHandle VmaAllocation_T::GetAllocHandle() const
{
    switch (m_Type)
    {
    case ALLOCATION_TYPE_BLOCK:
        return m_BlockAllocation.m_AllocHandle;
    case ALLOCATION_TYPE_DEDICATED:
        return 
# 10980 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
              nullptr
# 10980 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            ;
    default:
        
# 10982 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 10982 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0
# 10982 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 10982 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0"
# 10982 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10982),0))
# 10982 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                    ;
        return 
# 10983 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
              nullptr
# 10983 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            ;
    }
}

VkDeviceSize VmaAllocation_T::GetOffset() const
{
    switch (m_Type)
    {
    case ALLOCATION_TYPE_BLOCK:
        return m_BlockAllocation.m_Block->m_pMetadata->GetAllocationOffset(m_BlockAllocation.m_AllocHandle);
    case ALLOCATION_TYPE_DEDICATED:
        return 0;
    default:
        
# 10996 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 10996 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0
# 10996 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 10996 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0"
# 10996 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",10996),0))
# 10996 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                    ;
        return 0;
    }
}

VmaPool VmaAllocation_T::GetParentPool() const
{
    switch (m_Type)
    {
    case ALLOCATION_TYPE_BLOCK:
        return m_BlockAllocation.m_Block->GetParentPool();
    case ALLOCATION_TYPE_DEDICATED:
        return m_DedicatedAllocation.m_hParentPool;
    default:
        
# 11010 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 11010 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0
# 11010 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 11010 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0"
# 11010 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11010),0))
# 11010 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                    ;
        return 
# 11011 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
              nullptr
# 11011 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            ;
    }
}

VkDeviceMemory VmaAllocation_T::GetMemory() const
{
    switch (m_Type)
    {
    case ALLOCATION_TYPE_BLOCK:
        return m_BlockAllocation.m_Block->GetDeviceMemory();
    case ALLOCATION_TYPE_DEDICATED:
        return m_DedicatedAllocation.m_hMemory;
    default:
        
# 11024 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 11024 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0
# 11024 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 11024 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0"
# 11024 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11024),0))
# 11024 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                    ;
        return 
# 11025 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
              nullptr
# 11025 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            ;
    }
}

void* VmaAllocation_T::GetMappedData() const
{
    switch (m_Type)
    {
    case ALLOCATION_TYPE_BLOCK:
        if (m_MapCount != 0 || IsPersistentMap())
        {
            void* pBlockData = m_BlockAllocation.m_Block->GetMappedData();
            
# 11037 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 11037 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           pBlockData != nullptr
# 11037 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 11037 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "pBlockData != nullptr"
# 11037 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11037),0))
# 11037 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                             ;
            return (char*)pBlockData + GetOffset();
        }
        else
        {
            return nullptr;
        }
        break;
    case ALLOCATION_TYPE_DEDICATED:
        
# 11046 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 11046 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       (m_DedicatedAllocation.m_ExtraData != nullptr && m_DedicatedAllocation.m_ExtraData->m_pMappedData != nullptr) == (m_MapCount != 0 || IsPersistentMap())
# 11046 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 11046 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "(m_DedicatedAllocation.m_ExtraData != nullptr && m_DedicatedAllocation.m_ExtraData->m_pMappedData != nullptr) == (m_MapCount != 0 || IsPersistentMap())"
# 11046 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11046),0))
                                                   
# 11047 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                  ;
        return m_DedicatedAllocation.m_ExtraData != nullptr ? m_DedicatedAllocation.m_ExtraData->m_pMappedData : nullptr;
    default:
        
# 11050 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 11050 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0
# 11050 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 11050 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0"
# 11050 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11050),0))
# 11050 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                    ;
        return nullptr;
    }
}

void VmaAllocation_T::BlockAllocMap()
{
    
# 11057 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 11057 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   GetType() == ALLOCATION_TYPE_BLOCK
# 11057 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 11057 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "GetType() == ALLOCATION_TYPE_BLOCK"
# 11057 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11057),0))
# 11057 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                 ;
    
# 11058 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 11058 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   IsMappingAllowed() && "Mapping is not allowed on this allocation! Please use one of the new VMA_ALLOCATION_CREATE_HOST_ACCESS_* flags when creating it."
# 11058 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 11058 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "IsMappingAllowed() && \"Mapping is not allowed on this allocation! Please use one of the new VMA_ALLOCATION_CREATE_HOST_ACCESS_* flags when creating it.\""
# 11058 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11058),0))
# 11058 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                                                       ;

    if (m_MapCount < 0xFF)
    {
        ++m_MapCount;
    }
    else
    {
        
# 11066 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 11066 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Allocation mapped too many times simultaneously."
# 11066 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 11066 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Allocation mapped too many times simultaneously.\""
# 11066 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11066),0))
# 11066 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                          ;
    }
}

void VmaAllocation_T::BlockAllocUnmap()
{
    
# 11072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 11072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   GetType() == ALLOCATION_TYPE_BLOCK
# 11072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 11072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "GetType() == ALLOCATION_TYPE_BLOCK"
# 11072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11072),0))
# 11072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                 ;

    if (m_MapCount > 0)
    {
        --m_MapCount;
    }
    else
    {
        
# 11080 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 11080 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Unmapping allocation not previously mapped."
# 11080 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 11080 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Unmapping allocation not previously mapped.\""
# 11080 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11080),0))
# 11080 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                     ;
    }
}

VkResult VmaAllocation_T::DedicatedAllocMap(VmaAllocator hAllocator, void** ppData)
{
    
# 11086 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 11086 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   GetType() == ALLOCATION_TYPE_DEDICATED
# 11086 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 11086 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "GetType() == ALLOCATION_TYPE_DEDICATED"
# 11086 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11086),0))
# 11086 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                     ;
    
# 11087 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 11087 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   IsMappingAllowed() && "Mapping is not allowed on this allocation! Please use one of the new VMA_ALLOCATION_CREATE_HOST_ACCESS_* flags when creating it."
# 11087 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 11087 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "IsMappingAllowed() && \"Mapping is not allowed on this allocation! Please use one of the new VMA_ALLOCATION_CREATE_HOST_ACCESS_* flags when creating it.\""
# 11087 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11087),0))
# 11087 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                                                       ;

    EnsureExtraData(hAllocator);

    if (m_MapCount != 0 || IsPersistentMap())
    {
        if (m_MapCount < 0xFF)
        {
            
# 11095 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 11095 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           m_DedicatedAllocation.m_ExtraData->m_pMappedData != nullptr
# 11095 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 11095 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "m_DedicatedAllocation.m_ExtraData->m_pMappedData != nullptr"
# 11095 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11095),0))
# 11095 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                   ;
            *ppData = m_DedicatedAllocation.m_ExtraData->m_pMappedData;
            ++m_MapCount;
            return VK_SUCCESS;
        }
        else
        {
            
# 11102 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 11102 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0 && "Dedicated allocation mapped too many times simultaneously."
# 11102 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 11102 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0 && \"Dedicated allocation mapped too many times simultaneously.\""
# 11102 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11102),0))
# 11102 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                        ;
            return VK_ERROR_MEMORY_MAP_FAILED;
        }
    }
    else
    {
        VkResult result = (*hAllocator->GetVulkanFunctions().vkMapMemory)(
            hAllocator->m_hDevice,
            m_DedicatedAllocation.m_hMemory,
            0,
            
# 11112 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
           (~0ULL)
# 11112 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ,
            0,
            ppData);
        if (result == VK_SUCCESS)
        {
            m_DedicatedAllocation.m_ExtraData->m_pMappedData = *ppData;
            m_MapCount = 1;
        }
        return result;
    }
}

void VmaAllocation_T::DedicatedAllocUnmap(VmaAllocator hAllocator)
{
    
# 11126 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 11126 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   GetType() == ALLOCATION_TYPE_DEDICATED
# 11126 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 11126 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "GetType() == ALLOCATION_TYPE_DEDICATED"
# 11126 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11126),0))
# 11126 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                     ;

    if (m_MapCount > 0)
    {
        --m_MapCount;
        if (m_MapCount == 0 && !IsPersistentMap())
        {
            
# 11133 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 11133 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           m_DedicatedAllocation.m_ExtraData != nullptr
# 11133 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 11133 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "m_DedicatedAllocation.m_ExtraData != nullptr"
# 11133 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11133),0))
# 11133 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                    ;
            m_DedicatedAllocation.m_ExtraData->m_pMappedData = nullptr;
            (*hAllocator->GetVulkanFunctions().vkUnmapMemory)(
                hAllocator->m_hDevice,
                m_DedicatedAllocation.m_hMemory);
        }
    }
    else
    {
        
# 11142 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 11142 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Unmapping dedicated allocation not previously mapped."
# 11142 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 11142 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Unmapping dedicated allocation not previously mapped.\""
# 11142 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11142),0))
# 11142 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                               ;
    }
}


void VmaAllocation_T::PrintParameters(class VmaJsonWriter& json) const
{
    json.WriteString("Type");
    json.WriteString(VMA_SUBALLOCATION_TYPE_NAMES[m_SuballocationType]);

    json.WriteString("Size");
    json.WriteNumber(m_Size);
    json.WriteString("Usage");
    json.WriteNumber(m_BufferImageUsage.Value);

    if (m_pUserData != nullptr)
    {
        json.WriteString("CustomData");
        json.BeginString();
        json.ContinueString_Pointer(m_pUserData);
        json.EndString();
    }
    if (m_pName != nullptr)
    {
        json.WriteString("Name");
        json.WriteString(m_pName);
    }
}
# 11189 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
void VmaAllocation_T::EnsureExtraData(VmaAllocator hAllocator)
{
    if (m_DedicatedAllocation.m_ExtraData == nullptr)
    {
        m_DedicatedAllocation.m_ExtraData = new(VmaAllocate<VmaAllocationExtraData>(hAllocator))(VmaAllocationExtraData)();
    }
}

void VmaAllocation_T::FreeName(VmaAllocator hAllocator)
{
    if(m_pName)
    {
        VmaFreeString(hAllocator->GetAllocationCallbacks(), m_pName);
        m_pName = nullptr;
    }
}



VmaBlockVector::VmaBlockVector(
    VmaAllocator hAllocator,
    VmaPool hParentPool,
    uint32_t memoryTypeIndex,
    VkDeviceSize preferredBlockSize,
    size_t minBlockCount,
    size_t maxBlockCount,
    VkDeviceSize bufferImageGranularity,
    bool explicitBlockSize,
    uint32_t algorithm,
    float priority,
    VkDeviceSize minAllocationAlignment,
    void* pMemoryAllocateNext)
    : m_hAllocator(hAllocator),
    m_hParentPool(hParentPool),
    m_MemoryTypeIndex(memoryTypeIndex),
    m_PreferredBlockSize(preferredBlockSize),
    m_MinBlockCount(minBlockCount),
    m_MaxBlockCount(maxBlockCount),
    m_BufferImageGranularity(bufferImageGranularity),
    m_ExplicitBlockSize(explicitBlockSize),
    m_Algorithm(algorithm),
    m_Priority(priority),
    m_MinAllocationAlignment(minAllocationAlignment),
    m_pMemoryAllocateNext(pMemoryAllocateNext),
    m_Blocks(VmaStlAllocator<VmaDeviceMemoryBlock*>(hAllocator->GetAllocationCallbacks())),
    m_NextBlockId(0) {}

VmaBlockVector::~VmaBlockVector()
{
    for (size_t i = m_Blocks.size(); i--; )
    {
        m_Blocks[i]->Destroy(m_hAllocator);
        vma_delete(m_hAllocator, m_Blocks[i]);
    }
}

VkResult VmaBlockVector::CreateMinBlocks()
{
    for (size_t i = 0; i < m_MinBlockCount; ++i)
    {
        VkResult res = CreateBlock(m_PreferredBlockSize, nullptr);
        if (res != VK_SUCCESS)
        {
            return res;
        }
    }
    return VK_SUCCESS;
}

void VmaBlockVector::AddStatistics(VmaStatistics& inoutStats)
{
    VmaMutexLockRead lock(m_Mutex, m_hAllocator->m_UseMutex);

    const size_t blockCount = m_Blocks.size();
    for (uint32_t blockIndex = 0; blockIndex < blockCount; ++blockIndex)
    {
        const VmaDeviceMemoryBlock* const pBlock = m_Blocks[blockIndex];
        
# 11266 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 11266 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       pBlock
# 11266 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 11266 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "pBlock"
# 11266 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11266),0))
# 11266 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                         ;
        ;
        pBlock->m_pMetadata->AddStatistics(inoutStats);
    }
}

void VmaBlockVector::AddDetailedStatistics(VmaDetailedStatistics& inoutStats)
{
    VmaMutexLockRead lock(m_Mutex, m_hAllocator->m_UseMutex);

    const size_t blockCount = m_Blocks.size();
    for (uint32_t blockIndex = 0; blockIndex < blockCount; ++blockIndex)
    {
        const VmaDeviceMemoryBlock* const pBlock = m_Blocks[blockIndex];
        
# 11280 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 11280 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       pBlock
# 11280 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 11280 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "pBlock"
# 11280 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11280),0))
# 11280 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                         ;
        ;
        pBlock->m_pMetadata->AddDetailedStatistics(inoutStats);
    }
}

bool VmaBlockVector::IsEmpty()
{
    VmaMutexLockRead lock(m_Mutex, m_hAllocator->m_UseMutex);
    return m_Blocks.empty();
}

bool VmaBlockVector::IsCorruptionDetectionEnabled() const
{
    const uint32_t requiredMemFlags = VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT;
    return ((0) != 0) &&
        ((0) > 0) &&
        (m_Algorithm == 0 || m_Algorithm == VMA_POOL_CREATE_LINEAR_ALGORITHM_BIT) &&
        (m_hAllocator->m_MemProps.memoryTypes[m_MemoryTypeIndex].propertyFlags & requiredMemFlags) == requiredMemFlags;
}

VkResult VmaBlockVector::Allocate(
    VkDeviceSize size,
    VkDeviceSize alignment,
    const VmaAllocationCreateInfo& createInfo,
    VmaSuballocationType suballocType,
    size_t allocationCount,
    VmaAllocation* pAllocations)
{
    size_t allocIndex;
    VkResult res = VK_SUCCESS;

    alignment = ((std::max)((alignment), (m_MinAllocationAlignment)));

    if (IsCorruptionDetectionEnabled())
    {
        size = VmaAlignUp<VkDeviceSize>(size, sizeof(VMA_CORRUPTION_DETECTION_MAGIC_VALUE));
        alignment = VmaAlignUp<VkDeviceSize>(alignment, sizeof(VMA_CORRUPTION_DETECTION_MAGIC_VALUE));
    }

    {
        VmaMutexLockWrite lock(m_Mutex, m_hAllocator->m_UseMutex);
        for (allocIndex = 0; allocIndex < allocationCount; ++allocIndex)
        {
            res = AllocatePage(
                size,
                alignment,
                createInfo,
                suballocType,
                pAllocations + allocIndex);
            if (res != VK_SUCCESS)
            {
                break;
            }
        }
    }

    if (res != VK_SUCCESS)
    {

        while (allocIndex--)
            Free(pAllocations[allocIndex]);
        memset(pAllocations, 0, sizeof(VmaAllocation) * allocationCount);
    }

    return res;
}

VkResult VmaBlockVector::AllocatePage(
    VkDeviceSize size,
    VkDeviceSize alignment,
    const VmaAllocationCreateInfo& createInfo,
    VmaSuballocationType suballocType,
    VmaAllocation* pAllocation)
{
    const bool isUpperAddress = (createInfo.flags & VMA_ALLOCATION_CREATE_UPPER_ADDRESS_BIT) != 0;

    VkDeviceSize freeMemory;
    {
        const uint32_t heapIndex = m_hAllocator->MemoryTypeIndexToHeapIndex(m_MemoryTypeIndex);
        VmaBudget heapBudget = {};
        m_hAllocator->GetHeapBudgets(&heapBudget, heapIndex, 1);
        freeMemory = (heapBudget.usage < heapBudget.budget) ? (heapBudget.budget - heapBudget.usage) : 0;
    }

    const bool canFallbackToDedicated = !HasExplicitBlockSize() &&
        (createInfo.flags & VMA_ALLOCATION_CREATE_NEVER_ALLOCATE_BIT) == 0;
    const bool canCreateNewBlock =
        ((createInfo.flags & VMA_ALLOCATION_CREATE_NEVER_ALLOCATE_BIT) == 0) &&
        (m_Blocks.size() < m_MaxBlockCount) &&
        (freeMemory >= size || !canFallbackToDedicated);
    uint32_t strategy = createInfo.flags & VMA_ALLOCATION_CREATE_STRATEGY_MASK;


    if (isUpperAddress &&
        (m_Algorithm != VMA_POOL_CREATE_LINEAR_ALGORITHM_BIT || m_MaxBlockCount > 1))
    {
        return VK_ERROR_FEATURE_NOT_PRESENT;
    }


    if (size + (0) > m_PreferredBlockSize)
    {
        return VK_ERROR_OUT_OF_DEVICE_MEMORY;
    }


    if (m_Algorithm == VMA_POOL_CREATE_LINEAR_ALGORITHM_BIT)
    {

        if (!m_Blocks.empty())
        {
            VmaDeviceMemoryBlock* const pCurrBlock = m_Blocks.back();
            
# 11393 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 11393 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           pCurrBlock
# 11393 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 11393 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "pCurrBlock"
# 11393 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11393),0))
# 11393 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                 ;
            VkResult res = AllocateFromBlock(
                pCurrBlock, size, alignment, createInfo.flags, createInfo.pUserData, suballocType, strategy, pAllocation);
            if (res == VK_SUCCESS)
            {
                ;
                IncrementallySortBlocks();
                return VK_SUCCESS;
            }
        }
    }
    else
    {
        if (strategy != VMA_ALLOCATION_CREATE_STRATEGY_MIN_TIME_BIT)
        {
            const bool isHostVisible =
                (m_hAllocator->m_MemProps.memoryTypes[m_MemoryTypeIndex].propertyFlags & VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT) != 0;
            if(isHostVisible)
            {
                const bool isMappingAllowed = (createInfo.flags &
                    (VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT | VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT)) != 0;






                for(size_t mappingI = 0; mappingI < 2; ++mappingI)
                {

                    for (size_t blockIndex = 0; blockIndex < m_Blocks.size(); ++blockIndex)
                    {
                        VmaDeviceMemoryBlock* const pCurrBlock = m_Blocks[blockIndex];
                        
# 11426 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                       (void) ((!!(
# 11426 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                       pCurrBlock
# 11426 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                       )) || (_assert(
# 11426 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                       "pCurrBlock"
# 11426 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11426),0))
# 11426 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                             ;
                        const bool isBlockMapped = pCurrBlock->GetMappedData() != nullptr;
                        if((mappingI == 0) == (isMappingAllowed == isBlockMapped))
                        {
                            VkResult res = AllocateFromBlock(
                                pCurrBlock, size, alignment, createInfo.flags, createInfo.pUserData, suballocType, strategy, pAllocation);
                            if (res == VK_SUCCESS)
                            {
                                ;
                                IncrementallySortBlocks();
                                return VK_SUCCESS;
                            }
                        }
                    }
                }
            }
            else
            {

                for (size_t blockIndex = 0; blockIndex < m_Blocks.size(); ++blockIndex)
                {
                    VmaDeviceMemoryBlock* const pCurrBlock = m_Blocks[blockIndex];
                    
# 11448 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                   (void) ((!!(
# 11448 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                   pCurrBlock
# 11448 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                   )) || (_assert(
# 11448 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                   "pCurrBlock"
# 11448 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11448),0))
# 11448 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                         ;
                    VkResult res = AllocateFromBlock(
                        pCurrBlock, size, alignment, createInfo.flags, createInfo.pUserData, suballocType, strategy, pAllocation);
                    if (res == VK_SUCCESS)
                    {
                        ;
                        IncrementallySortBlocks();
                        return VK_SUCCESS;
                    }
                }
            }
        }
        else
        {

            for (size_t blockIndex = m_Blocks.size(); blockIndex--; )
            {
                VmaDeviceMemoryBlock* const pCurrBlock = m_Blocks[blockIndex];
                
# 11466 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 11466 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               pCurrBlock
# 11466 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 11466 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "pCurrBlock"
# 11466 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11466),0))
# 11466 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                     ;
                VkResult res = AllocateFromBlock(pCurrBlock, size, alignment, createInfo.flags, createInfo.pUserData, suballocType, strategy, pAllocation);
                if (res == VK_SUCCESS)
                {
                    ;
                    IncrementallySortBlocks();
                    return VK_SUCCESS;
                }
            }
        }
    }


    if (canCreateNewBlock)
    {

        VkDeviceSize newBlockSize = m_PreferredBlockSize;
        uint32_t newBlockSizeShift = 0;
        const uint32_t NEW_BLOCK_SIZE_SHIFT_MAX = 3;

        if (!m_ExplicitBlockSize)
        {

            const VkDeviceSize maxExistingBlockSize = CalcMaxBlockSize();
            for (uint32_t i = 0; i < NEW_BLOCK_SIZE_SHIFT_MAX; ++i)
            {
                const VkDeviceSize smallerNewBlockSize = newBlockSize / 2;
                if (smallerNewBlockSize > maxExistingBlockSize && smallerNewBlockSize >= size * 2)
                {
                    newBlockSize = smallerNewBlockSize;
                    ++newBlockSizeShift;
                }
                else
                {
                    break;
                }
            }
        }

        size_t newBlockIndex = 0;
        VkResult res = (newBlockSize <= freeMemory || !canFallbackToDedicated) ?
            CreateBlock(newBlockSize, &newBlockIndex) : VK_ERROR_OUT_OF_DEVICE_MEMORY;

        if (!m_ExplicitBlockSize)
        {
            while (res < 0 && newBlockSizeShift < NEW_BLOCK_SIZE_SHIFT_MAX)
            {
                const VkDeviceSize smallerNewBlockSize = newBlockSize / 2;
                if (smallerNewBlockSize >= size)
                {
                    newBlockSize = smallerNewBlockSize;
                    ++newBlockSizeShift;
                    res = (newBlockSize <= freeMemory || !canFallbackToDedicated) ?
                        CreateBlock(newBlockSize, &newBlockIndex) : VK_ERROR_OUT_OF_DEVICE_MEMORY;
                }
                else
                {
                    break;
                }
            }
        }

        if (res == VK_SUCCESS)
        {
            VmaDeviceMemoryBlock* const pBlock = m_Blocks[newBlockIndex];
            
# 11531 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 11531 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           pBlock->m_pMetadata->GetSize() >= size
# 11531 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 11531 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "pBlock->m_pMetadata->GetSize() >= size"
# 11531 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11531),0))
# 11531 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                             ;

            res = AllocateFromBlock(
                pBlock, size, alignment, createInfo.flags, createInfo.pUserData, suballocType, strategy, pAllocation);
            if (res == VK_SUCCESS)
            {
                ;
                IncrementallySortBlocks();
                return VK_SUCCESS;
            }
            else
            {

                return VK_ERROR_OUT_OF_DEVICE_MEMORY;
            }
        }
    }

    return VK_ERROR_OUT_OF_DEVICE_MEMORY;
}

void VmaBlockVector::Free(const VmaAllocation hAllocation)
{
    VmaDeviceMemoryBlock* pBlockToDelete = nullptr;

    bool budgetExceeded = false;
    {
        const uint32_t heapIndex = m_hAllocator->MemoryTypeIndexToHeapIndex(m_MemoryTypeIndex);
        VmaBudget heapBudget = {};
        m_hAllocator->GetHeapBudgets(&heapBudget, heapIndex, 1);
        budgetExceeded = heapBudget.usage >= heapBudget.budget;
    }


    {
        VmaMutexLockWrite lock(m_Mutex, m_hAllocator->m_UseMutex);

        VmaDeviceMemoryBlock* pBlock = hAllocation->GetBlock();

        if (IsCorruptionDetectionEnabled())
        {
            VkResult res = pBlock->ValidateMagicValueAfterAllocation(m_hAllocator, hAllocation->GetOffset(), hAllocation->GetSize());
            
# 11573 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 11573 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           res == VK_SUCCESS && "Couldn't map block memory to validate magic value."
# 11573 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 11573 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "res == VK_SUCCESS && \"Couldn't map block memory to validate magic value.\""
# 11573 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11573),0))
# 11573 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                ;
        }

        if (hAllocation->IsPersistentMap())
        {
            pBlock->Unmap(m_hAllocator, 1);
        }

        const bool hadEmptyBlockBeforeFree = HasEmptyBlock();
        pBlock->m_pMetadata->Free(hAllocation->GetAllocHandle());
        pBlock->PostFree(m_hAllocator);
        ;

        ;

        const bool canDeleteBlock = m_Blocks.size() > m_MinBlockCount;

        if (pBlock->m_pMetadata->IsEmpty())
        {

            if ((hadEmptyBlockBeforeFree || budgetExceeded) && canDeleteBlock)
            {
                pBlockToDelete = pBlock;
                Remove(pBlock);
            }

        }


        else if (hadEmptyBlockBeforeFree && canDeleteBlock)
        {
            VmaDeviceMemoryBlock* pLastBlock = m_Blocks.back();
            if (pLastBlock->m_pMetadata->IsEmpty())
            {
                pBlockToDelete = pLastBlock;
                m_Blocks.pop_back();
            }
        }

        IncrementallySortBlocks();

        m_hAllocator->m_Budget.RemoveAllocation(m_hAllocator->MemoryTypeIndexToHeapIndex(m_MemoryTypeIndex), hAllocation->GetSize());
        hAllocation->Destroy(m_hAllocator);
        m_hAllocator->m_AllocationObjectAllocator.Free(hAllocation);
    }



    if (pBlockToDelete != nullptr)
    {
        ;
        pBlockToDelete->Destroy(m_hAllocator);
        vma_delete(m_hAllocator, pBlockToDelete);
    }
}

VkDeviceSize VmaBlockVector::CalcMaxBlockSize() const
{
    VkDeviceSize result = 0;
    for (size_t i = m_Blocks.size(); i--; )
    {
        result = ((std::max)((result), (m_Blocks[i]->m_pMetadata->GetSize())));
        if (result >= m_PreferredBlockSize)
        {
            break;
        }
    }
    return result;
}

void VmaBlockVector::Remove(VmaDeviceMemoryBlock* pBlock)
{
    for (uint32_t blockIndex = 0; blockIndex < m_Blocks.size(); ++blockIndex)
    {
        if (m_Blocks[blockIndex] == pBlock)
        {
            VmaVectorRemove(m_Blocks, blockIndex);
            return;
        }
    }
    
# 11653 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 11653 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   0
# 11653 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 11653 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "0"
# 11653 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11653),0))
# 11653 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                ;
}

void VmaBlockVector::IncrementallySortBlocks()
{
    if (!m_IncrementalSort)
        return;
    if (m_Algorithm != VMA_POOL_CREATE_LINEAR_ALGORITHM_BIT)
    {

        for (size_t i = 1; i < m_Blocks.size(); ++i)
        {
            if (m_Blocks[i - 1]->m_pMetadata->GetSumFreeSize() > m_Blocks[i]->m_pMetadata->GetSumFreeSize())
            {
                std::swap(m_Blocks[i - 1], m_Blocks[i]);
                return;
            }
        }
    }
}

void VmaBlockVector::SortByFreeSize()
{
    std::sort(m_Blocks.begin(), m_Blocks.end(), [](VmaDeviceMemoryBlock* b1, VmaDeviceMemoryBlock* b2) -> bool { return b1->m_pMetadata->GetSumFreeSize() < b2->m_pMetadata->GetSumFreeSize(); })



          ;
}

VkResult VmaBlockVector::AllocateFromBlock(
    VmaDeviceMemoryBlock* pBlock,
    VkDeviceSize size,
    VkDeviceSize alignment,
    VmaAllocationCreateFlags allocFlags,
    void* pUserData,
    VmaSuballocationType suballocType,
    uint32_t strategy,
    VmaAllocation* pAllocation)
{
    const bool isUpperAddress = (allocFlags & VMA_ALLOCATION_CREATE_UPPER_ADDRESS_BIT) != 0;

    VmaAllocationRequest currRequest = {};
    if (pBlock->m_pMetadata->CreateAllocationRequest(
        size,
        alignment,
        isUpperAddress,
        suballocType,
        strategy,
        &currRequest))
    {
        return CommitAllocationRequest(currRequest, pBlock, alignment, allocFlags, pUserData, suballocType, pAllocation);
    }
    return VK_ERROR_OUT_OF_DEVICE_MEMORY;
}

VkResult VmaBlockVector::CommitAllocationRequest(
    VmaAllocationRequest& allocRequest,
    VmaDeviceMemoryBlock* pBlock,
    VkDeviceSize alignment,
    VmaAllocationCreateFlags allocFlags,
    void* pUserData,
    VmaSuballocationType suballocType,
    VmaAllocation* pAllocation)
{
    const bool mapped = (allocFlags & VMA_ALLOCATION_CREATE_MAPPED_BIT) != 0;
    const bool isUserDataString = (allocFlags & VMA_ALLOCATION_CREATE_USER_DATA_COPY_STRING_BIT) != 0;
    const bool isMappingAllowed = (allocFlags &
        (VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT | VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT)) != 0;

    pBlock->PostAlloc(m_hAllocator);

    if (mapped)
    {
        VkResult res = pBlock->Map(m_hAllocator, 1, nullptr);
        if (res != VK_SUCCESS)
        {
            return res;
        }
    }

    *pAllocation = m_hAllocator->m_AllocationObjectAllocator.Allocate(isMappingAllowed);
    pBlock->m_pMetadata->Alloc(allocRequest, suballocType, *pAllocation);
    (*pAllocation)->InitBlockAllocation(
        pBlock,
        allocRequest.allocHandle,
        alignment,
        allocRequest.size,
        m_MemoryTypeIndex,
        suballocType,
        mapped);
    ;
    if (isUserDataString)
        (*pAllocation)->SetName(m_hAllocator, (const char*)pUserData);
    else
        (*pAllocation)->SetUserData(m_hAllocator, pUserData);
    m_hAllocator->m_Budget.AddAllocation(m_hAllocator->MemoryTypeIndexToHeapIndex(m_MemoryTypeIndex), allocRequest.size);
    if ((0))
    {
        m_hAllocator->FillAllocation(*pAllocation, VMA_ALLOCATION_FILL_PATTERN_CREATED);
    }
    if (IsCorruptionDetectionEnabled())
    {
        VkResult res = pBlock->WriteMagicValueAfterAllocation(m_hAllocator, (*pAllocation)->GetOffset(), allocRequest.size);
        
# 11757 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 11757 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       res == VK_SUCCESS && "Couldn't map block memory to write magic value."
# 11757 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 11757 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "res == VK_SUCCESS && \"Couldn't map block memory to write magic value.\""
# 11757 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11757),0))
# 11757 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                         ;
    }
    return VK_SUCCESS;
}

VkResult VmaBlockVector::CreateBlock(VkDeviceSize blockSize, size_t* pNewBlockIndex)
{
    VkMemoryAllocateInfo allocInfo = { VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO };
    allocInfo.pNext = m_pMemoryAllocateNext;
    allocInfo.memoryTypeIndex = m_MemoryTypeIndex;
    allocInfo.allocationSize = blockSize;



    VkMemoryAllocateFlagsInfoKHR allocFlagsInfo = { VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_FLAGS_INFO_KHR };
    if (m_hAllocator->m_UseKhrBufferDeviceAddress)
    {
        allocFlagsInfo.flags = VK_MEMORY_ALLOCATE_DEVICE_ADDRESS_BIT_KHR;
        VmaPnextChainPushFront(&allocInfo, &allocFlagsInfo);
    }



    VkMemoryPriorityAllocateInfoEXT priorityInfo = { VK_STRUCTURE_TYPE_MEMORY_PRIORITY_ALLOCATE_INFO_EXT };
    if (m_hAllocator->m_UseExtMemoryPriority)
    {
        
# 11783 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 11783 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       m_Priority >= 0.f && m_Priority <= 1.f
# 11783 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 11783 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "m_Priority >= 0.f && m_Priority <= 1.f"
# 11783 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11783),0))
# 11783 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                         ;
        priorityInfo.priority = m_Priority;
        VmaPnextChainPushFront(&allocInfo, &priorityInfo);
    }




    VkExportMemoryAllocateInfoKHR exportMemoryAllocInfo = { VK_STRUCTURE_TYPE_EXPORT_MEMORY_ALLOCATE_INFO_KHR };
    exportMemoryAllocInfo.handleTypes = m_hAllocator->GetExternalMemoryHandleTypeFlags(m_MemoryTypeIndex);
    if (exportMemoryAllocInfo.handleTypes != 0)
    {
        VmaPnextChainPushFront(&allocInfo, &exportMemoryAllocInfo);
    }


    VkDeviceMemory mem = 
# 11799 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                        nullptr
# 11799 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                      ;
    VkResult res = m_hAllocator->AllocateVulkanMemory(&allocInfo, &mem);
    if (res < 0)
    {
        return res;
    }




    VmaDeviceMemoryBlock* const pBlock = new(VmaAllocate<VmaDeviceMemoryBlock>(m_hAllocator))(VmaDeviceMemoryBlock)(m_hAllocator);
    pBlock->Init(
        m_hAllocator,
        m_hParentPool,
        m_MemoryTypeIndex,
        mem,
        allocInfo.allocationSize,
        m_NextBlockId++,
        m_Algorithm,
        m_BufferImageGranularity);

    m_Blocks.push_back(pBlock);
    if (pNewBlockIndex != nullptr)
    {
        *pNewBlockIndex = m_Blocks.size() - 1;
    }

    return VK_SUCCESS;
}

bool VmaBlockVector::HasEmptyBlock()
{
    for (size_t index = 0, count = m_Blocks.size(); index < count; ++index)
    {
        VmaDeviceMemoryBlock* const pBlock = m_Blocks[index];
        if (pBlock->m_pMetadata->IsEmpty())
        {
            return true;
        }
    }
    return false;
}


void VmaBlockVector::PrintDetailedMap(class VmaJsonWriter& json)
{
    VmaMutexLockRead lock(m_Mutex, m_hAllocator->m_UseMutex);


    json.BeginObject();
    for (size_t i = 0; i < m_Blocks.size(); ++i)
    {
        json.BeginString();
        json.ContinueString(m_Blocks[i]->GetId());
        json.EndString();

        json.BeginObject();
        json.WriteString("MapRefCount");
        json.WriteNumber(m_Blocks[i]->GetMapRefCount());

        m_Blocks[i]->m_pMetadata->PrintDetailedMap(json);
        json.EndObject();
    }
    json.EndObject();
}


VkResult VmaBlockVector::CheckCorruption()
{
    if (!IsCorruptionDetectionEnabled())
    {
        return VK_ERROR_FEATURE_NOT_PRESENT;
    }

    VmaMutexLockRead lock(m_Mutex, m_hAllocator->m_UseMutex);
    for (uint32_t blockIndex = 0; blockIndex < m_Blocks.size(); ++blockIndex)
    {
        VmaDeviceMemoryBlock* const pBlock = m_Blocks[blockIndex];
        
# 11877 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 11877 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       pBlock
# 11877 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 11877 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "pBlock"
# 11877 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11877),0))
# 11877 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                         ;
        VkResult res = pBlock->CheckCorruption(m_hAllocator);
        if (res != VK_SUCCESS)
        {
            return res;
        }
    }
    return VK_SUCCESS;
}




VmaDefragmentationContext_T::VmaDefragmentationContext_T(
    VmaAllocator hAllocator,
    const VmaDefragmentationInfo& info)
    : m_MaxPassBytes(info.maxBytesPerPass == 0 ? 
# 11893 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                (~0ULL) 
# 11893 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                              : info.maxBytesPerPass),
    m_MaxPassAllocations(info.maxAllocationsPerPass == 0 ? 
# 11894 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                          0xffffffffU 
# 11894 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                     : info.maxAllocationsPerPass),
    m_BreakCallback(info.pfnBreakCallback),
    m_BreakCallbackUserData(info.pBreakCallbackUserData),
    m_MoveAllocator(hAllocator->GetAllocationCallbacks()),
    m_Moves(m_MoveAllocator)
{
    m_Algorithm = info.flags & VMA_DEFRAGMENTATION_FLAG_ALGORITHM_MASK;

    if (info.pool != nullptr)
    {
        m_BlockVectorCount = 1;
        m_PoolBlockVector = &info.pool->m_BlockVector;
        m_pBlockVectors = &m_PoolBlockVector;
        m_PoolBlockVector->SetIncrementalSort(false);
        m_PoolBlockVector->SortByFreeSize();
    }
    else
    {
        m_BlockVectorCount = hAllocator->GetMemoryTypeCount();
        m_PoolBlockVector = nullptr;
        m_pBlockVectors = hAllocator->m_pBlockVectors;
        for (uint32_t i = 0; i < m_BlockVectorCount; ++i)
        {
            VmaBlockVector* vector = m_pBlockVectors[i];
            if (vector != nullptr)
            {
                vector->SetIncrementalSort(false);
                vector->SortByFreeSize();
            }
        }
    }

    switch (m_Algorithm)
    {
    case 0:
        m_Algorithm = VMA_DEFRAGMENTATION_FLAG_ALGORITHM_BALANCED_BIT;
        m_AlgorithmState = new(VmaAllocateArray<StateBalanced>((hAllocator), (m_BlockVectorCount)))(StateBalanced);
        break;
    case VMA_DEFRAGMENTATION_FLAG_ALGORITHM_BALANCED_BIT:
        m_AlgorithmState = new(VmaAllocateArray<StateBalanced>((hAllocator), (m_BlockVectorCount)))(StateBalanced);
        break;
    case VMA_DEFRAGMENTATION_FLAG_ALGORITHM_EXTENSIVE_BIT:
        if (hAllocator->GetBufferImageGranularity() > 1)
        {
            m_AlgorithmState = new(VmaAllocateArray<StateExtensive>((hAllocator), (m_BlockVectorCount)))(StateExtensive);
        }
        break;
    }
}

VmaDefragmentationContext_T::~VmaDefragmentationContext_T()
{
    if (m_PoolBlockVector != nullptr)
    {
        m_PoolBlockVector->SetIncrementalSort(true);
    }
    else
    {
        for (uint32_t i = 0; i < m_BlockVectorCount; ++i)
        {
            VmaBlockVector* vector = m_pBlockVectors[i];
            if (vector != nullptr)
                vector->SetIncrementalSort(true);
        }
    }

    if (m_AlgorithmState)
    {
        switch (m_Algorithm)
        {
        case VMA_DEFRAGMENTATION_FLAG_ALGORITHM_BALANCED_BIT:
            vma_delete_array(m_MoveAllocator.m_pCallbacks, reinterpret_cast<StateBalanced*>(m_AlgorithmState), m_BlockVectorCount);
            break;
        case VMA_DEFRAGMENTATION_FLAG_ALGORITHM_EXTENSIVE_BIT:
            vma_delete_array(m_MoveAllocator.m_pCallbacks, reinterpret_cast<StateExtensive*>(m_AlgorithmState), m_BlockVectorCount);
            break;
        default:
            
# 11971 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 11971 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0
# 11971 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 11971 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0"
# 11971 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",11971),0))
# 11971 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;
        }
    }
}

VkResult VmaDefragmentationContext_T::DefragmentPassBegin(VmaDefragmentationPassMoveInfo& moveInfo)
{
    if (m_PoolBlockVector != nullptr)
    {
        VmaMutexLockWrite lock(m_PoolBlockVector->GetMutex(), m_PoolBlockVector->GetAllocator()->m_UseMutex);

        if (m_PoolBlockVector->GetBlockCount() > 1)
            ComputeDefragmentation(*m_PoolBlockVector, 0);
        else if (m_PoolBlockVector->GetBlockCount() == 1)
            ReallocWithinBlock(*m_PoolBlockVector, m_PoolBlockVector->GetBlock(0));
    }
    else
    {
        for (uint32_t i = 0; i < m_BlockVectorCount; ++i)
        {
            if (m_pBlockVectors[i] != nullptr)
            {
                VmaMutexLockWrite lock(m_pBlockVectors[i]->GetMutex(), m_pBlockVectors[i]->GetAllocator()->m_UseMutex);

                if (m_pBlockVectors[i]->GetBlockCount() > 1)
                {
                    if (ComputeDefragmentation(*m_pBlockVectors[i], i))
                        break;
                }
                else if (m_pBlockVectors[i]->GetBlockCount() == 1)
                {
                    if (ReallocWithinBlock(*m_pBlockVectors[i], m_pBlockVectors[i]->GetBlock(0)))
                        break;
                }
            }
        }
    }

    moveInfo.moveCount = static_cast<uint32_t>(m_Moves.size());
    if (moveInfo.moveCount > 0)
    {
        moveInfo.pMoves = m_Moves.data();
        return VK_INCOMPLETE;
    }

    moveInfo.pMoves = nullptr;
    return VK_SUCCESS;
}

VkResult VmaDefragmentationContext_T::DefragmentPassEnd(VmaDefragmentationPassMoveInfo& moveInfo)
{
    
# 12022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 12022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   moveInfo.moveCount > 0 ? moveInfo.pMoves != nullptr : true
# 12022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 12022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "moveInfo.moveCount > 0 ? moveInfo.pMoves != nullptr : true"
# 12022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",12022),0))
# 12022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                          ;

    VkResult result = VK_SUCCESS;
    VmaStlAllocator<FragmentedBlock> blockAllocator(m_MoveAllocator.m_pCallbacks);
    VmaVector<FragmentedBlock, VmaStlAllocator<FragmentedBlock>> immovableBlocks(blockAllocator);
    VmaVector<FragmentedBlock, VmaStlAllocator<FragmentedBlock>> mappedBlocks(blockAllocator);

    VmaAllocator allocator = nullptr;
    for (uint32_t i = 0; i < moveInfo.moveCount; ++i)
    {
        VmaDefragmentationMove& move = moveInfo.pMoves[i];
        size_t prevCount = 0, currentCount = 0;
        VkDeviceSize freedBlockSize = 0;

        uint32_t vectorIndex;
        VmaBlockVector* vector;
        if (m_PoolBlockVector != nullptr)
        {
            vectorIndex = 0;
            vector = m_PoolBlockVector;
        }
        else
        {
            vectorIndex = move.srcAllocation->GetMemoryTypeIndex();
            vector = m_pBlockVectors[vectorIndex];
            
# 12047 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 12047 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           vector != nullptr
# 12047 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 12047 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "vector != nullptr"
# 12047 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",12047),0))
# 12047 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                         ;
        }

        switch (move.operation)
        {
        case VMA_DEFRAGMENTATION_MOVE_OPERATION_COPY:
        {
            uint8_t mapCount = move.srcAllocation->SwapBlockAllocation(vector->m_hAllocator, move.dstTmpAllocation);
            if (mapCount > 0)
            {
                allocator = vector->m_hAllocator;
                VmaDeviceMemoryBlock* newMapBlock = move.srcAllocation->GetBlock();
                bool notPresent = true;
                for (FragmentedBlock& block : mappedBlocks)
                {
                    if (block.block == newMapBlock)
                    {
                        notPresent = false;
                        block.data += mapCount;
                        break;
                    }
                }
                if (notPresent)
                    mappedBlocks.push_back({ mapCount, newMapBlock });
            }


            {
                VmaMutexLockRead lock(vector->GetMutex(), vector->GetAllocator()->m_UseMutex);
                prevCount = vector->GetBlockCount();
                freedBlockSize = move.dstTmpAllocation->GetBlock()->m_pMetadata->GetSize();
            }
            vector->Free(move.dstTmpAllocation);
            {
                VmaMutexLockRead lock(vector->GetMutex(), vector->GetAllocator()->m_UseMutex);
                currentCount = vector->GetBlockCount();
            }

            result = VK_INCOMPLETE;
            break;
        }
        case VMA_DEFRAGMENTATION_MOVE_OPERATION_IGNORE:
        {
            m_PassStats.bytesMoved -= move.srcAllocation->GetSize();
            --m_PassStats.allocationsMoved;
            vector->Free(move.dstTmpAllocation);

            VmaDeviceMemoryBlock* newBlock = move.srcAllocation->GetBlock();
            bool notPresent = true;
            for (const FragmentedBlock& block : immovableBlocks)
            {
                if (block.block == newBlock)
                {
                    notPresent = false;
                    break;
                }
            }
            if (notPresent)
                immovableBlocks.push_back({ vectorIndex, newBlock });
            break;
        }
        case VMA_DEFRAGMENTATION_MOVE_OPERATION_DESTROY:
        {
            m_PassStats.bytesMoved -= move.srcAllocation->GetSize();
            --m_PassStats.allocationsMoved;

            {
                VmaMutexLockRead lock(vector->GetMutex(), vector->GetAllocator()->m_UseMutex);
                prevCount = vector->GetBlockCount();
                freedBlockSize = move.srcAllocation->GetBlock()->m_pMetadata->GetSize();
            }
            vector->Free(move.srcAllocation);
            {
                VmaMutexLockRead lock(vector->GetMutex(), vector->GetAllocator()->m_UseMutex);
                currentCount = vector->GetBlockCount();
            }
            freedBlockSize *= prevCount - currentCount;

            VkDeviceSize dstBlockSize;
            {
                VmaMutexLockRead lock(vector->GetMutex(), vector->GetAllocator()->m_UseMutex);
                dstBlockSize = move.dstTmpAllocation->GetBlock()->m_pMetadata->GetSize();
            }
            vector->Free(move.dstTmpAllocation);
            {
                VmaMutexLockRead lock(vector->GetMutex(), vector->GetAllocator()->m_UseMutex);
                freedBlockSize += dstBlockSize * (currentCount - vector->GetBlockCount());
                currentCount = vector->GetBlockCount();
            }

            result = VK_INCOMPLETE;
            break;
        }
        default:
            
# 12141 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 12141 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0
# 12141 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 12141 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0"
# 12141 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",12141),0))
# 12141 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;
        }

        if (prevCount > currentCount)
        {
            size_t freedBlocks = prevCount - currentCount;
            m_PassStats.deviceMemoryBlocksFreed += static_cast<uint32_t>(freedBlocks);
            m_PassStats.bytesFreed += freedBlockSize;
        }

        if(m_Algorithm == VMA_DEFRAGMENTATION_FLAG_ALGORITHM_EXTENSIVE_BIT &&
            m_AlgorithmState != nullptr)
        {

            StateExtensive& state = reinterpret_cast<StateExtensive*>(m_AlgorithmState)[vectorIndex];
            if (state.firstFreeBlock != 
# 12156 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                       0xffffffffffffffffULL
# 12156 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                               )
            {
                const size_t diff = prevCount - currentCount;
                if (state.firstFreeBlock >= diff)
                {
                    state.firstFreeBlock -= diff;
                    if (state.firstFreeBlock != 0)
                        state.firstFreeBlock -= vector->GetBlock(state.firstFreeBlock - 1)->m_pMetadata->IsEmpty();
                }
                else
                    state.firstFreeBlock = 0;
            }
        }
    }
    moveInfo.moveCount = 0;
    moveInfo.pMoves = nullptr;
    m_Moves.clear();


    m_GlobalStats.allocationsMoved += m_PassStats.allocationsMoved;
    m_GlobalStats.bytesFreed += m_PassStats.bytesFreed;
    m_GlobalStats.bytesMoved += m_PassStats.bytesMoved;
    m_GlobalStats.deviceMemoryBlocksFreed += m_PassStats.deviceMemoryBlocksFreed;
    m_PassStats = { 0 };


    if (immovableBlocks.size() > 0)
    {
        do
        {
            if(m_Algorithm == VMA_DEFRAGMENTATION_FLAG_ALGORITHM_EXTENSIVE_BIT)
            {
                if (m_AlgorithmState != nullptr)
                {
                    bool swapped = false;

                    for (const FragmentedBlock& block : immovableBlocks)
                    {
                        StateExtensive& state = reinterpret_cast<StateExtensive*>(m_AlgorithmState)[block.data];
                        if (state.operation != StateExtensive::Operation::Cleanup)
                        {
                            VmaBlockVector* vector = m_pBlockVectors[block.data];
                            VmaMutexLockWrite lock(vector->GetMutex(), vector->GetAllocator()->m_UseMutex);

                            for (size_t i = 0, count = vector->GetBlockCount() - m_ImmovableBlockCount; i < count; ++i)
                            {
                                if (vector->GetBlock(i) == block.block)
                                {
                                    std::swap(vector->m_Blocks[i], vector->m_Blocks[vector->GetBlockCount() - ++m_ImmovableBlockCount]);
                                    if (state.firstFreeBlock != 
# 12205 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                               0xffffffffffffffffULL
# 12205 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                       )
                                    {
                                        if (i + 1 < state.firstFreeBlock)
                                        {
                                            if (state.firstFreeBlock > 1)
                                                std::swap(vector->m_Blocks[i], vector->m_Blocks[--state.firstFreeBlock]);
                                            else
                                                --state.firstFreeBlock;
                                        }
                                    }
                                    swapped = true;
                                    break;
                                }
                            }
                        }
                    }
                    if (swapped)
                        result = VK_INCOMPLETE;
                    break;
                }
            }


            for (const FragmentedBlock& block : immovableBlocks)
            {
                VmaBlockVector* vector = m_pBlockVectors[block.data];
                VmaMutexLockWrite lock(vector->GetMutex(), vector->GetAllocator()->m_UseMutex);

                for (size_t i = m_ImmovableBlockCount; i < vector->GetBlockCount(); ++i)
                {
                    if (vector->GetBlock(i) == block.block)
                    {
                        std::swap(vector->m_Blocks[i], vector->m_Blocks[m_ImmovableBlockCount++]);
                        break;
                    }
                }
            }
        } while (false);
    }


    for (const FragmentedBlock& block : mappedBlocks)
    {
        VkResult res = block.block->Map(allocator, block.data, nullptr);
        
# 12249 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 12249 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       res == VK_SUCCESS
# 12249 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 12249 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "res == VK_SUCCESS"
# 12249 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",12249),0))
# 12249 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                    ;
    }
    return result;
}

bool VmaDefragmentationContext_T::ComputeDefragmentation(VmaBlockVector& vector, size_t index)
{
    switch (m_Algorithm)
    {
    case VMA_DEFRAGMENTATION_FLAG_ALGORITHM_FAST_BIT:
        return ComputeDefragmentation_Fast(vector);
    case VMA_DEFRAGMENTATION_FLAG_ALGORITHM_BALANCED_BIT:
        return ComputeDefragmentation_Balanced(vector, index, true);
    case VMA_DEFRAGMENTATION_FLAG_ALGORITHM_FULL_BIT:
        return ComputeDefragmentation_Full(vector);
    case VMA_DEFRAGMENTATION_FLAG_ALGORITHM_EXTENSIVE_BIT:
        return ComputeDefragmentation_Extensive(vector, index);
    default:
        
# 12267 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 12267 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0
# 12267 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 12267 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0"
# 12267 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",12267),0))
# 12267 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                    ;
        return ComputeDefragmentation_Balanced(vector, index, true);
    }
}

VmaDefragmentationContext_T::MoveAllocationData VmaDefragmentationContext_T::GetMoveData(
    VmaAllocHandle handle, VmaBlockMetadata* metadata)
{
    MoveAllocationData moveData;
    moveData.move.srcAllocation = (VmaAllocation)metadata->GetAllocationUserData(handle);
    moveData.size = moveData.move.srcAllocation->GetSize();
    moveData.alignment = moveData.move.srcAllocation->GetAlignment();
    moveData.type = moveData.move.srcAllocation->GetSuballocationType();
    moveData.flags = 0;

    if (moveData.move.srcAllocation->IsPersistentMap())
        moveData.flags |= VMA_ALLOCATION_CREATE_MAPPED_BIT;
    if (moveData.move.srcAllocation->IsMappingAllowed())
        moveData.flags |= VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT | VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT;

    return moveData;
}

VmaDefragmentationContext_T::CounterStatus VmaDefragmentationContext_T::CheckCounters(VkDeviceSize bytes)
{

    if (m_BreakCallback && m_BreakCallback(m_BreakCallbackUserData))
        return CounterStatus::End;


    if (m_PassStats.bytesMoved + bytes > m_MaxPassBytes)
    {
        if (++m_IgnoredAllocs < MAX_ALLOCS_TO_IGNORE)
            return CounterStatus::Ignore;
        else
            return CounterStatus::End;
    }
    else
        m_IgnoredAllocs = 0;
    return CounterStatus::Pass;
}

bool VmaDefragmentationContext_T::IncrementCounters(VkDeviceSize bytes)
{
    m_PassStats.bytesMoved += bytes;

    if (++m_PassStats.allocationsMoved >= m_MaxPassAllocations || m_PassStats.bytesMoved >= m_MaxPassBytes)
    {
        
# 12315 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 12315 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       (m_PassStats.allocationsMoved == m_MaxPassAllocations || m_PassStats.bytesMoved == m_MaxPassBytes) && "Exceeded maximal pass threshold!"
# 12315 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 12315 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "(m_PassStats.allocationsMoved == m_MaxPassAllocations || m_PassStats.bytesMoved == m_MaxPassBytes) && \"Exceeded maximal pass threshold!\""
# 12315 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",12315),0))
                                                                                            
# 12316 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                           ;
        return true;
    }
    return false;
}

bool VmaDefragmentationContext_T::ReallocWithinBlock(VmaBlockVector& vector, VmaDeviceMemoryBlock* block)
{
    VmaBlockMetadata* metadata = block->m_pMetadata;

    for (VmaAllocHandle handle = metadata->GetAllocationListBegin();
        handle != 
# 12327 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                 nullptr
# 12327 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                               ;
        handle = metadata->GetNextAllocation(handle))
    {
        MoveAllocationData moveData = GetMoveData(handle, metadata);

        if (moveData.move.srcAllocation->GetUserData() == this)
            continue;
        switch (CheckCounters(moveData.move.srcAllocation->GetSize()))
        {
        case CounterStatus::Ignore:
            continue;
        case CounterStatus::End:
            return true;
        case CounterStatus::Pass:
            break;
        default:
            
# 12343 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 12343 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0
# 12343 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 12343 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0"
# 12343 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",12343),0))
# 12343 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;
        }

        VkDeviceSize offset = moveData.move.srcAllocation->GetOffset();
        if (offset != 0 && metadata->GetSumFreeSize() >= moveData.size)
        {
            VmaAllocationRequest request = {};
            if (metadata->CreateAllocationRequest(
                moveData.size,
                moveData.alignment,
                false,
                moveData.type,
                VMA_ALLOCATION_CREATE_STRATEGY_MIN_OFFSET_BIT,
                &request))
            {
                if (metadata->GetAllocationOffset(request.allocHandle) < offset)
                {
                    if (vector.CommitAllocationRequest(
                        request,
                        block,
                        moveData.alignment,
                        moveData.flags,
                        this,
                        moveData.type,
                        &moveData.move.dstTmpAllocation) == VK_SUCCESS)
                    {
                        m_Moves.push_back(moveData.move);
                        if (IncrementCounters(moveData.size))
                            return true;
                    }
                }
            }
        }
    }
    return false;
}

bool VmaDefragmentationContext_T::AllocInOtherBlock(size_t start, size_t end, MoveAllocationData& data, VmaBlockVector& vector)
{
    for (; start < end; ++start)
    {
        VmaDeviceMemoryBlock* dstBlock = vector.GetBlock(start);
        if (dstBlock->m_pMetadata->GetSumFreeSize() >= data.size)
        {
            if (vector.AllocateFromBlock(dstBlock,
                data.size,
                data.alignment,
                data.flags,
                this,
                data.type,
                0,
                &data.move.dstTmpAllocation) == VK_SUCCESS)
            {
                m_Moves.push_back(data.move);
                if (IncrementCounters(data.size))
                    return true;
                break;
            }
        }
    }
    return false;
}

bool VmaDefragmentationContext_T::ComputeDefragmentation_Fast(VmaBlockVector& vector)
{



    for (size_t i = vector.GetBlockCount() - 1; i > m_ImmovableBlockCount; --i)
    {
        VmaBlockMetadata* metadata = vector.GetBlock(i)->m_pMetadata;

        for (VmaAllocHandle handle = metadata->GetAllocationListBegin();
            handle != 
# 12416 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                     nullptr
# 12416 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   ;
            handle = metadata->GetNextAllocation(handle))
        {
            MoveAllocationData moveData = GetMoveData(handle, metadata);

            if (moveData.move.srcAllocation->GetUserData() == this)
                continue;
            switch (CheckCounters(moveData.move.srcAllocation->GetSize()))
            {
            case CounterStatus::Ignore:
                continue;
            case CounterStatus::End:
                return true;
            case CounterStatus::Pass:
                break;
            default:
                
# 12432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 12432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               0
# 12432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 12432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "0"
# 12432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",12432),0))
# 12432 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            ;
            }


            if (AllocInOtherBlock(0, i, moveData, vector))
                return true;
        }
    }
    return false;
}

bool VmaDefragmentationContext_T::ComputeDefragmentation_Balanced(VmaBlockVector& vector, size_t index, bool update)
{



    
# 12448 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 12448 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_AlgorithmState != nullptr
# 12448 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 12448 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_AlgorithmState != nullptr"
# 12448 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",12448),0))
# 12448 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                           ;

    StateBalanced& vectorState = reinterpret_cast<StateBalanced*>(m_AlgorithmState)[index];
    if (update && vectorState.avgAllocSize == 
# 12451 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                             0xffffffffffffffffULL
# 12451 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                       )
        UpdateVectorStatistics(vector, vectorState);

    const size_t startMoveCount = m_Moves.size();
    VkDeviceSize minimalFreeRegion = vectorState.avgFreeSize / 2;
    for (size_t i = vector.GetBlockCount() - 1; i > m_ImmovableBlockCount; --i)
    {
        VmaDeviceMemoryBlock* block = vector.GetBlock(i);
        VmaBlockMetadata* metadata = block->m_pMetadata;
        VkDeviceSize prevFreeRegionSize = 0;

        for (VmaAllocHandle handle = metadata->GetAllocationListBegin();
            handle != 
# 12463 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                     nullptr
# 12463 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   ;
            handle = metadata->GetNextAllocation(handle))
        {
            MoveAllocationData moveData = GetMoveData(handle, metadata);

            if (moveData.move.srcAllocation->GetUserData() == this)
                continue;
            switch (CheckCounters(moveData.move.srcAllocation->GetSize()))
            {
            case CounterStatus::Ignore:
                continue;
            case CounterStatus::End:
                return true;
            case CounterStatus::Pass:
                break;
            default:
                
# 12479 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 12479 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               0
# 12479 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 12479 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "0"
# 12479 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",12479),0))
# 12479 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            ;
            }


            const size_t prevMoveCount = m_Moves.size();
            if (AllocInOtherBlock(0, i, moveData, vector))
                return true;

            VkDeviceSize nextFreeRegionSize = metadata->GetNextFreeRegionSize(handle);

            VkDeviceSize offset = moveData.move.srcAllocation->GetOffset();
            if (prevMoveCount == m_Moves.size() && offset != 0 && metadata->GetSumFreeSize() >= moveData.size)
            {

                if (prevFreeRegionSize >= minimalFreeRegion ||
                    nextFreeRegionSize >= minimalFreeRegion ||
                    moveData.size <= vectorState.avgFreeSize ||
                    moveData.size <= vectorState.avgAllocSize)
                {
                    VmaAllocationRequest request = {};
                    if (metadata->CreateAllocationRequest(
                        moveData.size,
                        moveData.alignment,
                        false,
                        moveData.type,
                        VMA_ALLOCATION_CREATE_STRATEGY_MIN_OFFSET_BIT,
                        &request))
                    {
                        if (metadata->GetAllocationOffset(request.allocHandle) < offset)
                        {
                            if (vector.CommitAllocationRequest(
                                request,
                                block,
                                moveData.alignment,
                                moveData.flags,
                                this,
                                moveData.type,
                                &moveData.move.dstTmpAllocation) == VK_SUCCESS)
                            {
                                m_Moves.push_back(moveData.move);
                                if (IncrementCounters(moveData.size))
                                    return true;
                            }
                        }
                    }
                }
            }
            prevFreeRegionSize = nextFreeRegionSize;
        }
    }


    if (startMoveCount == m_Moves.size() && !update)
    {
        vectorState.avgAllocSize = 
# 12533 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                  0xffffffffffffffffULL
# 12533 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                            ;
        return ComputeDefragmentation_Balanced(vector, index, false);
    }
    return false;
}

bool VmaDefragmentationContext_T::ComputeDefragmentation_Full(VmaBlockVector& vector)
{



    for (size_t i = vector.GetBlockCount() - 1; i > m_ImmovableBlockCount; --i)
    {
        VmaDeviceMemoryBlock* block = vector.GetBlock(i);
        VmaBlockMetadata* metadata = block->m_pMetadata;

        for (VmaAllocHandle handle = metadata->GetAllocationListBegin();
            handle != 
# 12550 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                     nullptr
# 12550 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   ;
            handle = metadata->GetNextAllocation(handle))
        {
            MoveAllocationData moveData = GetMoveData(handle, metadata);

            if (moveData.move.srcAllocation->GetUserData() == this)
                continue;
            switch (CheckCounters(moveData.move.srcAllocation->GetSize()))
            {
            case CounterStatus::Ignore:
                continue;
            case CounterStatus::End:
                return true;
            case CounterStatus::Pass:
                break;
            default:
                
# 12566 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 12566 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               0
# 12566 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 12566 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "0"
# 12566 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",12566),0))
# 12566 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            ;
            }


            const size_t prevMoveCount = m_Moves.size();
            if (AllocInOtherBlock(0, i, moveData, vector))
                return true;


            VkDeviceSize offset = moveData.move.srcAllocation->GetOffset();
            if (prevMoveCount == m_Moves.size() && offset != 0 && metadata->GetSumFreeSize() >= moveData.size)
            {
                VmaAllocationRequest request = {};
                if (metadata->CreateAllocationRequest(
                    moveData.size,
                    moveData.alignment,
                    false,
                    moveData.type,
                    VMA_ALLOCATION_CREATE_STRATEGY_MIN_OFFSET_BIT,
                    &request))
                {
                    if (metadata->GetAllocationOffset(request.allocHandle) < offset)
                    {
                        if (vector.CommitAllocationRequest(
                            request,
                            block,
                            moveData.alignment,
                            moveData.flags,
                            this,
                            moveData.type,
                            &moveData.move.dstTmpAllocation) == VK_SUCCESS)
                        {
                            m_Moves.push_back(moveData.move);
                            if (IncrementCounters(moveData.size))
                                return true;
                        }
                    }
                }
            }
        }
    }
    return false;
}

bool VmaDefragmentationContext_T::ComputeDefragmentation_Extensive(VmaBlockVector& vector, size_t index)
{



    if (vector.m_BufferImageGranularity == 1)
        return ComputeDefragmentation_Full(vector);

    
# 12618 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 12618 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_AlgorithmState != nullptr
# 12618 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 12618 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_AlgorithmState != nullptr"
# 12618 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",12618),0))
# 12618 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                           ;

    StateExtensive& vectorState = reinterpret_cast<StateExtensive*>(m_AlgorithmState)[index];

    bool texturePresent = false, bufferPresent = false, otherPresent = false;
    switch (vectorState.operation)
    {
    case StateExtensive::Operation::Done:
        return false;
    case StateExtensive::Operation::FindFreeBlockBuffer:
    case StateExtensive::Operation::FindFreeBlockTexture:
    case StateExtensive::Operation::FindFreeBlockAll:
    {

        if (vectorState.firstFreeBlock == 0)
        {
            vectorState.operation = StateExtensive::Operation::Cleanup;
            return ComputeDefragmentation_Fast(vector);
        }


        size_t last = (vectorState.firstFreeBlock == 
# 12639 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                    0xffffffffffffffffULL 
# 12639 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                             ? vector.GetBlockCount() : vectorState.firstFreeBlock) - 1;
        VmaBlockMetadata* freeMetadata = vector.GetBlock(last)->m_pMetadata;

        const size_t prevMoveCount = m_Moves.size();
        for (VmaAllocHandle handle = freeMetadata->GetAllocationListBegin();
            handle != 
# 12644 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                     nullptr
# 12644 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   ;
            handle = freeMetadata->GetNextAllocation(handle))
        {
            MoveAllocationData moveData = GetMoveData(handle, freeMetadata);
            switch (CheckCounters(moveData.move.srcAllocation->GetSize()))
            {
            case CounterStatus::Ignore:
                continue;
            case CounterStatus::End:
                return true;
            case CounterStatus::Pass:
                break;
            default:
                
# 12657 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 12657 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               0
# 12657 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 12657 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "0"
# 12657 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",12657),0))
# 12657 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            ;
            }


            if (AllocInOtherBlock(0, last, moveData, vector))
            {

                if (prevMoveCount != m_Moves.size() && freeMetadata->GetNextAllocation(handle) == 
# 12664 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                                                                 nullptr
# 12664 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                               )
                    vectorState.firstFreeBlock = last;
                return true;
            }
        }

        if (prevMoveCount == m_Moves.size())
        {

            if (last != 0)
            {
                for (size_t i = last - 1; i; --i)
                {
                    if (ReallocWithinBlock(vector, vector.GetBlock(i)))
                        return true;
                }
            }

            if (prevMoveCount == m_Moves.size())
            {

                return ComputeDefragmentation_Fast(vector);
            }
        }
        else
        {
            switch (vectorState.operation)
            {
            case StateExtensive::Operation::FindFreeBlockBuffer:
                vectorState.operation = StateExtensive::Operation::MoveBuffers;
                break;
            case StateExtensive::Operation::FindFreeBlockTexture:
                vectorState.operation = StateExtensive::Operation::MoveTextures;
                break;
            case StateExtensive::Operation::FindFreeBlockAll:
                vectorState.operation = StateExtensive::Operation::MoveAll;
                break;
            default:
                
# 12702 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 12702 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               0
# 12702 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 12702 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "0"
# 12702 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",12702),0))
# 12702 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            ;
                vectorState.operation = StateExtensive::Operation::MoveTextures;
            }
            vectorState.firstFreeBlock = last;

            return ComputeDefragmentation_Extensive(vector, index);
        }
        break;
    }
    case StateExtensive::Operation::MoveTextures:
    {
        if (MoveDataToFreeBlocks(VMA_SUBALLOCATION_TYPE_IMAGE_OPTIMAL, vector,
            vectorState.firstFreeBlock, texturePresent, bufferPresent, otherPresent))
        {
            if (texturePresent)
            {
                vectorState.operation = StateExtensive::Operation::FindFreeBlockTexture;
                return ComputeDefragmentation_Extensive(vector, index);
            }

            if (!bufferPresent && !otherPresent)
            {
                vectorState.operation = StateExtensive::Operation::Cleanup;
                break;
            }


            vectorState.operation = StateExtensive::Operation::MoveBuffers;
            bufferPresent = false;
            otherPresent = false;
        }
        else
            break;
        [[fallthrough]];
    }
    case StateExtensive::Operation::MoveBuffers:
    {
        if (MoveDataToFreeBlocks(VMA_SUBALLOCATION_TYPE_BUFFER, vector,
            vectorState.firstFreeBlock, texturePresent, bufferPresent, otherPresent))
        {
            if (bufferPresent)
            {
                vectorState.operation = StateExtensive::Operation::FindFreeBlockBuffer;
                return ComputeDefragmentation_Extensive(vector, index);
            }

            if (!otherPresent)
            {
                vectorState.operation = StateExtensive::Operation::Cleanup;
                break;
            }


            vectorState.operation = StateExtensive::Operation::MoveAll;
            otherPresent = false;
        }
        else
            break;
        [[fallthrough]];
    }
    case StateExtensive::Operation::MoveAll:
    {
        if (MoveDataToFreeBlocks(VMA_SUBALLOCATION_TYPE_FREE, vector,
            vectorState.firstFreeBlock, texturePresent, bufferPresent, otherPresent))
        {
            if (otherPresent)
            {
                vectorState.operation = StateExtensive::Operation::FindFreeBlockBuffer;
                return ComputeDefragmentation_Extensive(vector, index);
            }

            vectorState.operation = StateExtensive::Operation::Cleanup;
        }
        break;
    }
    case StateExtensive::Operation::Cleanup:

        break;
    }

    if (vectorState.operation == StateExtensive::Operation::Cleanup)
    {

        const size_t prevMoveCount = m_Moves.size();
        for (size_t i = 0; i < vector.GetBlockCount(); ++i)
        {
            if (ReallocWithinBlock(vector, vector.GetBlock(i)))
                return true;
        }

        if (prevMoveCount == m_Moves.size())
            vectorState.operation = StateExtensive::Operation::Done;
    }
    return false;
}

void VmaDefragmentationContext_T::UpdateVectorStatistics(VmaBlockVector& vector, StateBalanced& state)
{
    size_t allocCount = 0;
    size_t freeCount = 0;
    state.avgFreeSize = 0;
    state.avgAllocSize = 0;

    for (size_t i = 0; i < vector.GetBlockCount(); ++i)
    {
        VmaBlockMetadata* metadata = vector.GetBlock(i)->m_pMetadata;

        allocCount += metadata->GetAllocationCount();
        freeCount += metadata->GetFreeRegionsCount();
        state.avgFreeSize += metadata->GetSumFreeSize();
        state.avgAllocSize += metadata->GetSize();
    }

    state.avgAllocSize = (state.avgAllocSize - state.avgFreeSize) / allocCount;
    state.avgFreeSize /= freeCount;
}

bool VmaDefragmentationContext_T::MoveDataToFreeBlocks(VmaSuballocationType currentType,
    VmaBlockVector& vector, size_t firstFreeBlock,
    bool& texturePresent, bool& bufferPresent, bool& otherPresent)
{
    const size_t prevMoveCount = m_Moves.size();
    for (size_t i = firstFreeBlock ; i;)
    {
        VmaDeviceMemoryBlock* block = vector.GetBlock(--i);
        VmaBlockMetadata* metadata = block->m_pMetadata;

        for (VmaAllocHandle handle = metadata->GetAllocationListBegin();
            handle != 
# 12830 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                     nullptr
# 12830 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   ;
            handle = metadata->GetNextAllocation(handle))
        {
            MoveAllocationData moveData = GetMoveData(handle, metadata);

            if (moveData.move.srcAllocation->GetUserData() == this)
                continue;
            switch (CheckCounters(moveData.move.srcAllocation->GetSize()))
            {
            case CounterStatus::Ignore:
                continue;
            case CounterStatus::End:
                return true;
            case CounterStatus::Pass:
                break;
            default:
                
# 12846 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 12846 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               0
# 12846 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 12846 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "0"
# 12846 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",12846),0))
# 12846 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            ;
            }


            if (!VmaIsBufferImageGranularityConflict(moveData.type, currentType))
            {

                if (AllocInOtherBlock(firstFreeBlock, vector.GetBlockCount(), moveData, vector))
                    return false;
            }

            if (!VmaIsBufferImageGranularityConflict(moveData.type, VMA_SUBALLOCATION_TYPE_IMAGE_OPTIMAL))
                texturePresent = true;
            else if (!VmaIsBufferImageGranularityConflict(moveData.type, VMA_SUBALLOCATION_TYPE_BUFFER))
                bufferPresent = true;
            else
                otherPresent = true;
        }
    }
    return prevMoveCount == m_Moves.size();
}



VmaPool_T::VmaPool_T(
    VmaAllocator hAllocator,
    const VmaPoolCreateInfo& createInfo,
    VkDeviceSize preferredBlockSize)
    : m_BlockVector(
        hAllocator,
        this,
        createInfo.memoryTypeIndex,
        createInfo.blockSize != 0 ? createInfo.blockSize : preferredBlockSize,
        createInfo.minBlockCount,
        createInfo.maxBlockCount,
        (createInfo.flags& VMA_POOL_CREATE_IGNORE_BUFFER_IMAGE_GRANULARITY_BIT) != 0 ? 1 : hAllocator->GetBufferImageGranularity(),
        createInfo.blockSize != 0,
        createInfo.flags & VMA_POOL_CREATE_ALGORITHM_MASK,
        createInfo.priority,
        ((std::max)((hAllocator->GetMemoryTypeMinAlignment(createInfo.memoryTypeIndex)), (createInfo.minAllocationAlignment))),
        createInfo.pMemoryAllocateNext),
    m_Id(0),
    m_Name(nullptr) {}

VmaPool_T::~VmaPool_T()
{
    
# 12892 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 12892 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_PrevPool == nullptr && m_NextPool == nullptr
# 12892 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 12892 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_PrevPool == nullptr && m_NextPool == nullptr"
# 12892 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",12892),0))
# 12892 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                               ;

    const VkAllocationCallbacks* allocs = m_BlockVector.GetAllocator()->GetAllocationCallbacks();
    VmaFreeString(allocs, m_Name);
}

void VmaPool_T::SetName(const char* pName)
{
    const VkAllocationCallbacks* allocs = m_BlockVector.GetAllocator()->GetAllocationCallbacks();
    VmaFreeString(allocs, m_Name);

    if (pName != nullptr)
    {
        m_Name = VmaCreateStringCopy(allocs, pName);
    }
    else
    {
        m_Name = nullptr;
    }
}



VmaAllocator_T::VmaAllocator_T(const VmaAllocatorCreateInfo* pCreateInfo) :
    m_UseMutex((pCreateInfo->flags & VMA_ALLOCATOR_CREATE_EXTERNALLY_SYNCHRONIZED_BIT) == 0),
    m_VulkanApiVersion(pCreateInfo->vulkanApiVersion != 0 ? pCreateInfo->vulkanApiVersion : 
# 12917 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                                                           ((((uint32_t)(0)) << 29U) | (((uint32_t)(1)) << 22U) | (((uint32_t)(0)) << 12U) | ((uint32_t)(0)))
# 12917 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                             ),
    m_UseKhrDedicatedAllocation((pCreateInfo->flags & VMA_ALLOCATOR_CREATE_KHR_DEDICATED_ALLOCATION_BIT) != 0),
    m_UseKhrBindMemory2((pCreateInfo->flags & VMA_ALLOCATOR_CREATE_KHR_BIND_MEMORY2_BIT) != 0),
    m_UseExtMemoryBudget((pCreateInfo->flags & VMA_ALLOCATOR_CREATE_EXT_MEMORY_BUDGET_BIT) != 0),
    m_UseAmdDeviceCoherentMemory((pCreateInfo->flags & VMA_ALLOCATOR_CREATE_AMD_DEVICE_COHERENT_MEMORY_BIT) != 0),
    m_UseKhrBufferDeviceAddress((pCreateInfo->flags & VMA_ALLOCATOR_CREATE_BUFFER_DEVICE_ADDRESS_BIT) != 0),
    m_UseExtMemoryPriority((pCreateInfo->flags & VMA_ALLOCATOR_CREATE_EXT_MEMORY_PRIORITY_BIT) != 0),
    m_UseKhrMaintenance4((pCreateInfo->flags & VMA_ALLOCATOR_CREATE_KHR_MAINTENANCE4_BIT) != 0),
    m_UseKhrMaintenance5((pCreateInfo->flags & VMA_ALLOCATOR_CREATE_KHR_MAINTENANCE5_BIT) != 0),
    m_UseKhrExternalMemoryWin32((pCreateInfo->flags & VMA_ALLOCATOR_CREATE_KHR_EXTERNAL_MEMORY_WIN32_BIT) != 0),
    m_hDevice(pCreateInfo->device),
    m_hInstance(pCreateInfo->instance),
    m_AllocationCallbacksSpecified(pCreateInfo->pAllocationCallbacks != nullptr),
    m_AllocationCallbacks(pCreateInfo->pAllocationCallbacks ?
        *pCreateInfo->pAllocationCallbacks : VmaEmptyAllocationCallbacks),
    m_AllocationObjectAllocator(&m_AllocationCallbacks),
    m_HeapSizeLimitMask(0),
    m_DeviceMemoryCount(0),
    m_PreferredLargeHeapBlockSize(0),
    m_PhysicalDevice(pCreateInfo->physicalDevice),
    m_GpuDefragmentationMemoryTypeBits(
# 12937 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                      0xffffffffU
# 12937 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                ),
    m_NextPoolId(0),
    m_GlobalMemoryTypeBits(
# 12939 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                          0xffffffffU
# 12939 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                    )
{
    if(m_VulkanApiVersion >= 
# 12941 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            ((((uint32_t)(
# 12941 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            1
# 12941 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 22U) | (((uint32_t)(
# 12941 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            1
# 12941 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 12U) | ((uint32_t)(
# 12941 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            0
# 12941 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )))
# 12941 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                    )
    {
        m_UseKhrDedicatedAllocation = false;
        m_UseKhrBindMemory2 = false;
    }

    if((0))
    {

        
# 12950 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 12950 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       (0) % sizeof(uint32_t) == 0
# 12950 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 12950 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "(0) % sizeof(uint32_t) == 0"
# 12950 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",12950),0))
# 12950 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                           ;
    }

    
# 12953 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 12953 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pCreateInfo->physicalDevice && pCreateInfo->device && pCreateInfo->instance
# 12953 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 12953 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pCreateInfo->physicalDevice && pCreateInfo->device && pCreateInfo->instance"
# 12953 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",12953),0))
# 12953 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                          ;

    if(m_VulkanApiVersion < 
# 12955 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                           ((((uint32_t)(
# 12955 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                           1
# 12955 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                           )) << 22U) | (((uint32_t)(
# 12955 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                           1
# 12955 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                           )) << 12U) | ((uint32_t)(
# 12955 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                           0
# 12955 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                           )))
# 12955 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                   )
    {
# 12969 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    }
# 13020 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    if(m_UseKhrExternalMemoryWin32)
    {
        
# 13022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 13022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "VMA_ALLOCATOR_CREATE_KHR_EXTERNAL_MEMORY_WIN32_BIT is set but required extension is not available in your Vulkan header or its support in VMA has been disabled by a preprocessor macro."
# 13022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 13022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"VMA_ALLOCATOR_CREATE_KHR_EXTERNAL_MEMORY_WIN32_BIT is set but required extension is not available in your Vulkan header or its support in VMA has been disabled by a preprocessor macro.\""
# 13022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13022),0))
# 13022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                                                                                                  ;
    }


    memset(&m_DeviceMemoryCallbacks, 0 ,sizeof(m_DeviceMemoryCallbacks));
    memset(&m_PhysicalDeviceProperties, 0, sizeof(m_PhysicalDeviceProperties));
    memset(&m_MemProps, 0, sizeof(m_MemProps));

    memset(&m_pBlockVectors, 0, sizeof(m_pBlockVectors));
    memset(&m_VulkanFunctions, 0, sizeof(m_VulkanFunctions));


    memset(&m_TypeExternalMemoryHandleTypes, 0, sizeof(m_TypeExternalMemoryHandleTypes));


    if(pCreateInfo->pDeviceMemoryCallbacks != nullptr)
    {
        m_DeviceMemoryCallbacks.pUserData = pCreateInfo->pDeviceMemoryCallbacks->pUserData;
        m_DeviceMemoryCallbacks.pfnAllocate = pCreateInfo->pDeviceMemoryCallbacks->pfnAllocate;
        m_DeviceMemoryCallbacks.pfnFree = pCreateInfo->pDeviceMemoryCallbacks->pfnFree;
    }

    ImportVulkanFunctions(pCreateInfo->pVulkanFunctions);

    (*m_VulkanFunctions.vkGetPhysicalDeviceProperties)(m_PhysicalDevice, &m_PhysicalDeviceProperties);
    (*m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties)(m_PhysicalDevice, &m_MemProps);

    
# 13049 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13049 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   VmaIsPow2((1))
# 13049 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13049 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "VmaIsPow2((1))"
# 13049 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13049),0))
# 13049 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                           ;
    
# 13050 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13050 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   VmaIsPow2((1))
# 13050 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13050 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "VmaIsPow2((1))"
# 13050 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13050),0))
# 13050 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                ;
    
# 13051 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13051 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   VmaIsPow2(m_PhysicalDeviceProperties.limits.bufferImageGranularity)
# 13051 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13051 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "VmaIsPow2(m_PhysicalDeviceProperties.limits.bufferImageGranularity)"
# 13051 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13051),0))
# 13051 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                  ;
    
# 13052 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13052 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   VmaIsPow2(m_PhysicalDeviceProperties.limits.nonCoherentAtomSize)
# 13052 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13052 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "VmaIsPow2(m_PhysicalDeviceProperties.limits.nonCoherentAtomSize)"
# 13052 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13052),0))
# 13052 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                               ;

    m_PreferredLargeHeapBlockSize = (pCreateInfo->preferredLargeHeapBlockSize != 0) ?
        pCreateInfo->preferredLargeHeapBlockSize : static_cast<VkDeviceSize>((256ull * 1024 * 1024));

    m_GlobalMemoryTypeBits = CalculateGlobalMemoryTypeBits();


    if(pCreateInfo->pTypeExternalMemoryHandleTypes != nullptr)
    {
        memcpy(m_TypeExternalMemoryHandleTypes, pCreateInfo->pTypeExternalMemoryHandleTypes,
            sizeof(VkExternalMemoryHandleTypeFlagsKHR) * GetMemoryTypeCount());
    }


    if(pCreateInfo->pHeapSizeLimit != nullptr)
    {
        for(uint32_t heapIndex = 0; heapIndex < GetMemoryHeapCount(); ++heapIndex)
        {
            const VkDeviceSize limit = pCreateInfo->pHeapSizeLimit[heapIndex];
            if(limit != 
# 13072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                       (~0ULL)
# 13072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                    )
            {
                m_HeapSizeLimitMask |= 1u << heapIndex;
                if(limit < m_MemProps.memoryHeaps[heapIndex].size)
                {
                    m_MemProps.memoryHeaps[heapIndex].size = limit;
                }
            }
        }
    }

    for(uint32_t memTypeIndex = 0; memTypeIndex < GetMemoryTypeCount(); ++memTypeIndex)
    {

        if((m_GlobalMemoryTypeBits & (1u << memTypeIndex)) != 0)
        {
            const VkDeviceSize preferredBlockSize = CalcPreferredBlockSize(memTypeIndex);
            m_pBlockVectors[memTypeIndex] = new(VmaAllocate<VmaBlockVector>(this))(VmaBlockVector)(
                this,
                
# 13091 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
               nullptr
# 13091 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                             ,
                memTypeIndex,
                preferredBlockSize,
                0,
                
# 13095 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
               0xffffffffffffffffULL
# 13095 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                       ,
                GetBufferImageGranularity(),
                false,
                0,
                0.5f,
                GetMemoryTypeMinAlignment(memTypeIndex),
                nullptr);


        }
    }
}

VkResult VmaAllocator_T::Init(const VmaAllocatorCreateInfo* pCreateInfo)
{
    VkResult res = VK_SUCCESS;


    if(m_UseExtMemoryBudget)
    {
        UpdateVulkanBudget();
    }


    return res;
}

VmaAllocator_T::~VmaAllocator_T()
{
    
# 13124 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13124 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_Pools.IsEmpty()
# 13124 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13124 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_Pools.IsEmpty()"
# 13124 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13124),0))
# 13124 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                ;

    for(size_t memTypeIndex = GetMemoryTypeCount(); memTypeIndex--; )
    {
        vma_delete(this, m_pBlockVectors[memTypeIndex]);
    }
}

void VmaAllocator_T::ImportVulkanFunctions(const VmaVulkanFunctions* pVulkanFunctions)
{

    ImportVulkanFunctions_Static();


    if(pVulkanFunctions != nullptr)
    {
        ImportVulkanFunctions_Custom(pVulkanFunctions);
    }


    ImportVulkanFunctions_Dynamic();


    ValidateVulkanFunctions();
}



void VmaAllocator_T::ImportVulkanFunctions_Static()
{

    m_VulkanFunctions.vkGetInstanceProcAddr = (PFN_vkGetInstanceProcAddr)vkGetInstanceProcAddr;
    m_VulkanFunctions.vkGetDeviceProcAddr = (PFN_vkGetDeviceProcAddr)vkGetDeviceProcAddr;
    m_VulkanFunctions.vkGetPhysicalDeviceProperties = (PFN_vkGetPhysicalDeviceProperties)vkGetPhysicalDeviceProperties;
    m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties = (PFN_vkGetPhysicalDeviceMemoryProperties)vkGetPhysicalDeviceMemoryProperties;
    m_VulkanFunctions.vkAllocateMemory = (PFN_vkAllocateMemory)vkAllocateMemory;
    m_VulkanFunctions.vkFreeMemory = (PFN_vkFreeMemory)vkFreeMemory;
    m_VulkanFunctions.vkMapMemory = (PFN_vkMapMemory)vkMapMemory;
    m_VulkanFunctions.vkUnmapMemory = (PFN_vkUnmapMemory)vkUnmapMemory;
    m_VulkanFunctions.vkFlushMappedMemoryRanges = (PFN_vkFlushMappedMemoryRanges)vkFlushMappedMemoryRanges;
    m_VulkanFunctions.vkInvalidateMappedMemoryRanges = (PFN_vkInvalidateMappedMemoryRanges)vkInvalidateMappedMemoryRanges;
    m_VulkanFunctions.vkBindBufferMemory = (PFN_vkBindBufferMemory)vkBindBufferMemory;
    m_VulkanFunctions.vkBindImageMemory = (PFN_vkBindImageMemory)vkBindImageMemory;
    m_VulkanFunctions.vkGetBufferMemoryRequirements = (PFN_vkGetBufferMemoryRequirements)vkGetBufferMemoryRequirements;
    m_VulkanFunctions.vkGetImageMemoryRequirements = (PFN_vkGetImageMemoryRequirements)vkGetImageMemoryRequirements;
    m_VulkanFunctions.vkCreateBuffer = (PFN_vkCreateBuffer)vkCreateBuffer;
    m_VulkanFunctions.vkDestroyBuffer = (PFN_vkDestroyBuffer)vkDestroyBuffer;
    m_VulkanFunctions.vkCreateImage = (PFN_vkCreateImage)vkCreateImage;
    m_VulkanFunctions.vkDestroyImage = (PFN_vkDestroyImage)vkDestroyImage;
    m_VulkanFunctions.vkCmdCopyBuffer = (PFN_vkCmdCopyBuffer)vkCmdCopyBuffer;



    if(m_VulkanApiVersion >= 
# 13177 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            ((((uint32_t)(
# 13177 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            1
# 13177 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 22U) | (((uint32_t)(
# 13177 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            1
# 13177 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 12U) | ((uint32_t)(
# 13177 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            0
# 13177 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )))
# 13177 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                    )
    {
        m_VulkanFunctions.vkGetBufferMemoryRequirements2KHR = (PFN_vkGetBufferMemoryRequirements2)vkGetBufferMemoryRequirements2;
        m_VulkanFunctions.vkGetImageMemoryRequirements2KHR = (PFN_vkGetImageMemoryRequirements2)vkGetImageMemoryRequirements2;
        m_VulkanFunctions.vkBindBufferMemory2KHR = (PFN_vkBindBufferMemory2)vkBindBufferMemory2;
        m_VulkanFunctions.vkBindImageMemory2KHR = (PFN_vkBindImageMemory2)vkBindImageMemory2;
    }



    if(m_VulkanApiVersion >= 
# 13187 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            ((((uint32_t)(
# 13187 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            1
# 13187 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 22U) | (((uint32_t)(
# 13187 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            1
# 13187 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 12U) | ((uint32_t)(
# 13187 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            0
# 13187 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )))
# 13187 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                    )
    {
        m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties2KHR = (PFN_vkGetPhysicalDeviceMemoryProperties2)vkGetPhysicalDeviceMemoryProperties2;
    }



    if(m_VulkanApiVersion >= 
# 13194 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            ((((uint32_t)(
# 13194 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            1
# 13194 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 22U) | (((uint32_t)(
# 13194 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            3
# 13194 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 12U) | ((uint32_t)(
# 13194 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            0
# 13194 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )))
# 13194 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                    )
    {
        m_VulkanFunctions.vkGetDeviceBufferMemoryRequirements = (PFN_vkGetDeviceBufferMemoryRequirements)vkGetDeviceBufferMemoryRequirements;
        m_VulkanFunctions.vkGetDeviceImageMemoryRequirements = (PFN_vkGetDeviceImageMemoryRequirements)vkGetDeviceImageMemoryRequirements;
    }

}



void VmaAllocator_T::ImportVulkanFunctions_Custom(const VmaVulkanFunctions* pVulkanFunctions)
{
    
# 13206 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13206 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pVulkanFunctions != nullptr
# 13206 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13206 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pVulkanFunctions != nullptr"
# 13206 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13206),0))
# 13206 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                           ;




    if(pVulkanFunctions->vkGetInstanceProcAddr != nullptr) m_VulkanFunctions.vkGetInstanceProcAddr = pVulkanFunctions->vkGetInstanceProcAddr;;
    if(pVulkanFunctions->vkGetDeviceProcAddr != nullptr) m_VulkanFunctions.vkGetDeviceProcAddr = pVulkanFunctions->vkGetDeviceProcAddr;;
    if(pVulkanFunctions->vkGetPhysicalDeviceProperties != nullptr) m_VulkanFunctions.vkGetPhysicalDeviceProperties = pVulkanFunctions->vkGetPhysicalDeviceProperties;;
    if(pVulkanFunctions->vkGetPhysicalDeviceMemoryProperties != nullptr) m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties = pVulkanFunctions->vkGetPhysicalDeviceMemoryProperties;;
    if(pVulkanFunctions->vkAllocateMemory != nullptr) m_VulkanFunctions.vkAllocateMemory = pVulkanFunctions->vkAllocateMemory;;
    if(pVulkanFunctions->vkFreeMemory != nullptr) m_VulkanFunctions.vkFreeMemory = pVulkanFunctions->vkFreeMemory;;
    if(pVulkanFunctions->vkMapMemory != nullptr) m_VulkanFunctions.vkMapMemory = pVulkanFunctions->vkMapMemory;;
    if(pVulkanFunctions->vkUnmapMemory != nullptr) m_VulkanFunctions.vkUnmapMemory = pVulkanFunctions->vkUnmapMemory;;
    if(pVulkanFunctions->vkFlushMappedMemoryRanges != nullptr) m_VulkanFunctions.vkFlushMappedMemoryRanges = pVulkanFunctions->vkFlushMappedMemoryRanges;;
    if(pVulkanFunctions->vkInvalidateMappedMemoryRanges != nullptr) m_VulkanFunctions.vkInvalidateMappedMemoryRanges = pVulkanFunctions->vkInvalidateMappedMemoryRanges;;
    if(pVulkanFunctions->vkBindBufferMemory != nullptr) m_VulkanFunctions.vkBindBufferMemory = pVulkanFunctions->vkBindBufferMemory;;
    if(pVulkanFunctions->vkBindImageMemory != nullptr) m_VulkanFunctions.vkBindImageMemory = pVulkanFunctions->vkBindImageMemory;;
    if(pVulkanFunctions->vkGetBufferMemoryRequirements != nullptr) m_VulkanFunctions.vkGetBufferMemoryRequirements = pVulkanFunctions->vkGetBufferMemoryRequirements;;
    if(pVulkanFunctions->vkGetImageMemoryRequirements != nullptr) m_VulkanFunctions.vkGetImageMemoryRequirements = pVulkanFunctions->vkGetImageMemoryRequirements;;
    if(pVulkanFunctions->vkCreateBuffer != nullptr) m_VulkanFunctions.vkCreateBuffer = pVulkanFunctions->vkCreateBuffer;;
    if(pVulkanFunctions->vkDestroyBuffer != nullptr) m_VulkanFunctions.vkDestroyBuffer = pVulkanFunctions->vkDestroyBuffer;;
    if(pVulkanFunctions->vkCreateImage != nullptr) m_VulkanFunctions.vkCreateImage = pVulkanFunctions->vkCreateImage;;
    if(pVulkanFunctions->vkDestroyImage != nullptr) m_VulkanFunctions.vkDestroyImage = pVulkanFunctions->vkDestroyImage;;
    if(pVulkanFunctions->vkCmdCopyBuffer != nullptr) m_VulkanFunctions.vkCmdCopyBuffer = pVulkanFunctions->vkCmdCopyBuffer;;


    if(pVulkanFunctions->vkGetBufferMemoryRequirements2KHR != nullptr) m_VulkanFunctions.vkGetBufferMemoryRequirements2KHR = pVulkanFunctions->vkGetBufferMemoryRequirements2KHR;;
    if(pVulkanFunctions->vkGetImageMemoryRequirements2KHR != nullptr) m_VulkanFunctions.vkGetImageMemoryRequirements2KHR = pVulkanFunctions->vkGetImageMemoryRequirements2KHR;;



    if(pVulkanFunctions->vkBindBufferMemory2KHR != nullptr) m_VulkanFunctions.vkBindBufferMemory2KHR = pVulkanFunctions->vkBindBufferMemory2KHR;;
    if(pVulkanFunctions->vkBindImageMemory2KHR != nullptr) m_VulkanFunctions.vkBindImageMemory2KHR = pVulkanFunctions->vkBindImageMemory2KHR;;



    if(pVulkanFunctions->vkGetPhysicalDeviceMemoryProperties2KHR != nullptr) m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties2KHR = pVulkanFunctions->vkGetPhysicalDeviceMemoryProperties2KHR;;



    if(pVulkanFunctions->vkGetDeviceBufferMemoryRequirements != nullptr) m_VulkanFunctions.vkGetDeviceBufferMemoryRequirements = pVulkanFunctions->vkGetDeviceBufferMemoryRequirements;;
    if(pVulkanFunctions->vkGetDeviceImageMemoryRequirements != nullptr) m_VulkanFunctions.vkGetDeviceImageMemoryRequirements = pVulkanFunctions->vkGetDeviceImageMemoryRequirements;;





}



void VmaAllocator_T::ImportVulkanFunctions_Dynamic()
{
    
# 13259 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13259 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_VulkanFunctions.vkGetInstanceProcAddr && m_VulkanFunctions.vkGetDeviceProcAddr && "To use VMA_DYNAMIC_VULKAN_FUNCTIONS in new versions of VMA you now have to pass " "VmaVulkanFunctions::vkGetInstanceProcAddr and vkGetDeviceProcAddr as VmaAllocatorCreateInfo::pVulkanFunctions. " "Other members can be null."
# 13259 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13259 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_VulkanFunctions.vkGetInstanceProcAddr && m_VulkanFunctions.vkGetDeviceProcAddr && \"To use VMA_DYNAMIC_VULKAN_FUNCTIONS in new versions of VMA you now have to pass \" \"VmaVulkanFunctions::vkGetInstanceProcAddr and vkGetDeviceProcAddr as VmaAllocatorCreateInfo::pVulkanFunctions. \" \"Other members can be null.\""
# 13259 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13259),0))


                                     
# 13262 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                    ;
# 13273 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    if(m_VulkanFunctions.vkGetPhysicalDeviceProperties == nullptr) m_VulkanFunctions.vkGetPhysicalDeviceProperties = (PFN_vkGetPhysicalDeviceProperties)m_VulkanFunctions.vkGetInstanceProcAddr(m_hInstance, "vkGetPhysicalDeviceProperties");;
    if(m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties == nullptr) m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties = (PFN_vkGetPhysicalDeviceMemoryProperties)m_VulkanFunctions.vkGetInstanceProcAddr(m_hInstance, "vkGetPhysicalDeviceMemoryProperties");;
    if(m_VulkanFunctions.vkAllocateMemory == nullptr) m_VulkanFunctions.vkAllocateMemory = (PFN_vkAllocateMemory)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkAllocateMemory");;
    if(m_VulkanFunctions.vkFreeMemory == nullptr) m_VulkanFunctions.vkFreeMemory = (PFN_vkFreeMemory)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkFreeMemory");;
    if(m_VulkanFunctions.vkMapMemory == nullptr) m_VulkanFunctions.vkMapMemory = (PFN_vkMapMemory)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkMapMemory");;
    if(m_VulkanFunctions.vkUnmapMemory == nullptr) m_VulkanFunctions.vkUnmapMemory = (PFN_vkUnmapMemory)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkUnmapMemory");;
    if(m_VulkanFunctions.vkFlushMappedMemoryRanges == nullptr) m_VulkanFunctions.vkFlushMappedMemoryRanges = (PFN_vkFlushMappedMemoryRanges)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkFlushMappedMemoryRanges");;
    if(m_VulkanFunctions.vkInvalidateMappedMemoryRanges == nullptr) m_VulkanFunctions.vkInvalidateMappedMemoryRanges = (PFN_vkInvalidateMappedMemoryRanges)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkInvalidateMappedMemoryRanges");;
    if(m_VulkanFunctions.vkBindBufferMemory == nullptr) m_VulkanFunctions.vkBindBufferMemory = (PFN_vkBindBufferMemory)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkBindBufferMemory");;
    if(m_VulkanFunctions.vkBindImageMemory == nullptr) m_VulkanFunctions.vkBindImageMemory = (PFN_vkBindImageMemory)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkBindImageMemory");;
    if(m_VulkanFunctions.vkGetBufferMemoryRequirements == nullptr) m_VulkanFunctions.vkGetBufferMemoryRequirements = (PFN_vkGetBufferMemoryRequirements)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkGetBufferMemoryRequirements");;
    if(m_VulkanFunctions.vkGetImageMemoryRequirements == nullptr) m_VulkanFunctions.vkGetImageMemoryRequirements = (PFN_vkGetImageMemoryRequirements)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkGetImageMemoryRequirements");;
    if(m_VulkanFunctions.vkCreateBuffer == nullptr) m_VulkanFunctions.vkCreateBuffer = (PFN_vkCreateBuffer)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkCreateBuffer");;
    if(m_VulkanFunctions.vkDestroyBuffer == nullptr) m_VulkanFunctions.vkDestroyBuffer = (PFN_vkDestroyBuffer)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkDestroyBuffer");;
    if(m_VulkanFunctions.vkCreateImage == nullptr) m_VulkanFunctions.vkCreateImage = (PFN_vkCreateImage)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkCreateImage");;
    if(m_VulkanFunctions.vkDestroyImage == nullptr) m_VulkanFunctions.vkDestroyImage = (PFN_vkDestroyImage)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkDestroyImage");;
    if(m_VulkanFunctions.vkCmdCopyBuffer == nullptr) m_VulkanFunctions.vkCmdCopyBuffer = (PFN_vkCmdCopyBuffer)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkCmdCopyBuffer");;


    if(m_VulkanApiVersion >= 
# 13292 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            ((((uint32_t)(
# 13292 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            1
# 13292 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 22U) | (((uint32_t)(
# 13292 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            1
# 13292 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 12U) | ((uint32_t)(
# 13292 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            0
# 13292 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )))
# 13292 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                    )
    {
        if(m_VulkanFunctions.vkGetBufferMemoryRequirements2KHR == nullptr) m_VulkanFunctions.vkGetBufferMemoryRequirements2KHR = (PFN_vkGetBufferMemoryRequirements2)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkGetBufferMemoryRequirements2");;
        if(m_VulkanFunctions.vkGetImageMemoryRequirements2KHR == nullptr) m_VulkanFunctions.vkGetImageMemoryRequirements2KHR = (PFN_vkGetImageMemoryRequirements2)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkGetImageMemoryRequirements2");;
        if(m_VulkanFunctions.vkBindBufferMemory2KHR == nullptr) m_VulkanFunctions.vkBindBufferMemory2KHR = (PFN_vkBindBufferMemory2)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkBindBufferMemory2");;
        if(m_VulkanFunctions.vkBindImageMemory2KHR == nullptr) m_VulkanFunctions.vkBindImageMemory2KHR = (PFN_vkBindImageMemory2)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkBindImageMemory2");;
    }



    if(m_VulkanApiVersion >= 
# 13302 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            ((((uint32_t)(
# 13302 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            1
# 13302 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 22U) | (((uint32_t)(
# 13302 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            1
# 13302 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 12U) | ((uint32_t)(
# 13302 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            0
# 13302 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )))
# 13302 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                    )
    {
        if(m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties2KHR == nullptr) m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties2KHR = (PFN_vkGetPhysicalDeviceMemoryProperties2KHR)m_VulkanFunctions.vkGetInstanceProcAddr(m_hInstance, "vkGetPhysicalDeviceMemoryProperties2");;

        if(m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties2KHR == nullptr) m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties2KHR = (PFN_vkGetPhysicalDeviceMemoryProperties2KHR)m_VulkanFunctions.vkGetInstanceProcAddr(m_hInstance, "vkGetPhysicalDeviceMemoryProperties2KHR");;
    }
    else if(m_UseExtMemoryBudget)
    {
        if(m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties2KHR == nullptr) m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties2KHR = (PFN_vkGetPhysicalDeviceMemoryProperties2KHR)m_VulkanFunctions.vkGetInstanceProcAddr(m_hInstance, "vkGetPhysicalDeviceMemoryProperties2KHR");;

        if(m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties2KHR == nullptr) m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties2KHR = (PFN_vkGetPhysicalDeviceMemoryProperties2KHR)m_VulkanFunctions.vkGetInstanceProcAddr(m_hInstance, "vkGetPhysicalDeviceMemoryProperties2");;
    }



    if(m_UseKhrDedicatedAllocation)
    {
        if(m_VulkanFunctions.vkGetBufferMemoryRequirements2KHR == nullptr) m_VulkanFunctions.vkGetBufferMemoryRequirements2KHR = (PFN_vkGetBufferMemoryRequirements2KHR)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkGetBufferMemoryRequirements2KHR");;
        if(m_VulkanFunctions.vkGetImageMemoryRequirements2KHR == nullptr) m_VulkanFunctions.vkGetImageMemoryRequirements2KHR = (PFN_vkGetImageMemoryRequirements2KHR)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkGetImageMemoryRequirements2KHR");;
    }



    if(m_UseKhrBindMemory2)
    {
        if(m_VulkanFunctions.vkBindBufferMemory2KHR == nullptr) m_VulkanFunctions.vkBindBufferMemory2KHR = (PFN_vkBindBufferMemory2KHR)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkBindBufferMemory2KHR");;
        if(m_VulkanFunctions.vkBindImageMemory2KHR == nullptr) m_VulkanFunctions.vkBindImageMemory2KHR = (PFN_vkBindImageMemory2KHR)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkBindImageMemory2KHR");;
    }



    if(m_VulkanApiVersion >= 
# 13333 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            ((((uint32_t)(
# 13333 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            1
# 13333 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 22U) | (((uint32_t)(
# 13333 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            1
# 13333 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 12U) | ((uint32_t)(
# 13333 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            0
# 13333 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )))
# 13333 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                    )
    {
        if(m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties2KHR == nullptr) m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties2KHR = (PFN_vkGetPhysicalDeviceMemoryProperties2KHR)m_VulkanFunctions.vkGetInstanceProcAddr(m_hInstance, "vkGetPhysicalDeviceMemoryProperties2");;
    }
    else if(m_UseExtMemoryBudget)
    {
        if(m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties2KHR == nullptr) m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties2KHR = (PFN_vkGetPhysicalDeviceMemoryProperties2KHR)m_VulkanFunctions.vkGetInstanceProcAddr(m_hInstance, "vkGetPhysicalDeviceMemoryProperties2KHR");;
    }



    if(m_VulkanApiVersion >= 
# 13344 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            ((((uint32_t)(
# 13344 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            1
# 13344 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 22U) | (((uint32_t)(
# 13344 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            3
# 13344 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 12U) | ((uint32_t)(
# 13344 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            0
# 13344 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )))
# 13344 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                    )
    {
        if(m_VulkanFunctions.vkGetDeviceBufferMemoryRequirements == nullptr) m_VulkanFunctions.vkGetDeviceBufferMemoryRequirements = (PFN_vkGetDeviceBufferMemoryRequirements)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkGetDeviceBufferMemoryRequirements");;
        if(m_VulkanFunctions.vkGetDeviceImageMemoryRequirements == nullptr) m_VulkanFunctions.vkGetDeviceImageMemoryRequirements = (PFN_vkGetDeviceImageMemoryRequirements)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkGetDeviceImageMemoryRequirements");;
    }


    if(m_UseKhrMaintenance4)
    {
        if(m_VulkanFunctions.vkGetDeviceBufferMemoryRequirements == nullptr) m_VulkanFunctions.vkGetDeviceBufferMemoryRequirements = (PFN_vkGetDeviceBufferMemoryRequirementsKHR)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkGetDeviceBufferMemoryRequirementsKHR");;
        if(m_VulkanFunctions.vkGetDeviceImageMemoryRequirements == nullptr) m_VulkanFunctions.vkGetDeviceImageMemoryRequirements = (PFN_vkGetDeviceImageMemoryRequirementsKHR)m_VulkanFunctions.vkGetDeviceProcAddr(m_hDevice, "vkGetDeviceImageMemoryRequirementsKHR");;
    }
# 13365 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
}



void VmaAllocator_T::ValidateVulkanFunctions()
{
    
# 13371 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13371 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_VulkanFunctions.vkGetPhysicalDeviceProperties != nullptr
# 13371 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13371 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_VulkanFunctions.vkGetPhysicalDeviceProperties != nullptr"
# 13371 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13371),0))
# 13371 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                          ;
    
# 13372 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13372 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties != nullptr
# 13372 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13372 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties != nullptr"
# 13372 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13372),0))
# 13372 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                ;
    
# 13373 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13373 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_VulkanFunctions.vkAllocateMemory != nullptr
# 13373 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13373 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_VulkanFunctions.vkAllocateMemory != nullptr"
# 13373 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13373),0))
# 13373 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                             ;
    
# 13374 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13374 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_VulkanFunctions.vkFreeMemory != nullptr
# 13374 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13374 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_VulkanFunctions.vkFreeMemory != nullptr"
# 13374 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13374),0))
# 13374 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                         ;
    
# 13375 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13375 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_VulkanFunctions.vkMapMemory != nullptr
# 13375 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13375 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_VulkanFunctions.vkMapMemory != nullptr"
# 13375 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13375),0))
# 13375 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                        ;
    
# 13376 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13376 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_VulkanFunctions.vkUnmapMemory != nullptr
# 13376 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13376 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_VulkanFunctions.vkUnmapMemory != nullptr"
# 13376 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13376),0))
# 13376 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                          ;
    
# 13377 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13377 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_VulkanFunctions.vkFlushMappedMemoryRanges != nullptr
# 13377 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13377 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_VulkanFunctions.vkFlushMappedMemoryRanges != nullptr"
# 13377 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13377),0))
# 13377 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                      ;
    
# 13378 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13378 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_VulkanFunctions.vkInvalidateMappedMemoryRanges != nullptr
# 13378 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13378 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_VulkanFunctions.vkInvalidateMappedMemoryRanges != nullptr"
# 13378 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13378),0))
# 13378 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                           ;
    
# 13379 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13379 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_VulkanFunctions.vkBindBufferMemory != nullptr
# 13379 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13379 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_VulkanFunctions.vkBindBufferMemory != nullptr"
# 13379 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13379),0))
# 13379 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                               ;
    
# 13380 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13380 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_VulkanFunctions.vkBindImageMemory != nullptr
# 13380 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13380 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_VulkanFunctions.vkBindImageMemory != nullptr"
# 13380 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13380),0))
# 13380 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                              ;
    
# 13381 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13381 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_VulkanFunctions.vkGetBufferMemoryRequirements != nullptr
# 13381 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13381 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_VulkanFunctions.vkGetBufferMemoryRequirements != nullptr"
# 13381 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13381),0))
# 13381 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                          ;
    
# 13382 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13382 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_VulkanFunctions.vkGetImageMemoryRequirements != nullptr
# 13382 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13382 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_VulkanFunctions.vkGetImageMemoryRequirements != nullptr"
# 13382 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13382),0))
# 13382 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                         ;
    
# 13383 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13383 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_VulkanFunctions.vkCreateBuffer != nullptr
# 13383 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13383 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_VulkanFunctions.vkCreateBuffer != nullptr"
# 13383 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13383),0))
# 13383 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                           ;
    
# 13384 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13384 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_VulkanFunctions.vkDestroyBuffer != nullptr
# 13384 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13384 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_VulkanFunctions.vkDestroyBuffer != nullptr"
# 13384 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13384),0))
# 13384 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                            ;
    
# 13385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_VulkanFunctions.vkCreateImage != nullptr
# 13385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_VulkanFunctions.vkCreateImage != nullptr"
# 13385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13385),0))
# 13385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                          ;
    
# 13386 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13386 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_VulkanFunctions.vkDestroyImage != nullptr
# 13386 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13386 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_VulkanFunctions.vkDestroyImage != nullptr"
# 13386 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13386),0))
# 13386 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                           ;
    
# 13387 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13387 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_VulkanFunctions.vkCmdCopyBuffer != nullptr
# 13387 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13387 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_VulkanFunctions.vkCmdCopyBuffer != nullptr"
# 13387 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13387),0))
# 13387 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                            ;


    if(m_VulkanApiVersion >= 
# 13390 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            ((((uint32_t)(
# 13390 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            1
# 13390 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 22U) | (((uint32_t)(
# 13390 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            1
# 13390 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 12U) | ((uint32_t)(
# 13390 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            0
# 13390 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            ))) 
# 13390 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                     || m_UseKhrDedicatedAllocation)
    {
        
# 13392 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 13392 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       m_VulkanFunctions.vkGetBufferMemoryRequirements2KHR != nullptr
# 13392 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 13392 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "m_VulkanFunctions.vkGetBufferMemoryRequirements2KHR != nullptr"
# 13392 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13392),0))
# 13392 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                  ;
        
# 13393 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 13393 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       m_VulkanFunctions.vkGetImageMemoryRequirements2KHR != nullptr
# 13393 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 13393 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "m_VulkanFunctions.vkGetImageMemoryRequirements2KHR != nullptr"
# 13393 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13393),0))
# 13393 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                 ;
    }



    if(m_VulkanApiVersion >= 
# 13398 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            ((((uint32_t)(
# 13398 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            1
# 13398 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 22U) | (((uint32_t)(
# 13398 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            1
# 13398 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            )) << 12U) | ((uint32_t)(
# 13398 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            0
# 13398 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            ))) 
# 13398 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                     || m_UseKhrBindMemory2)
    {
        
# 13400 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 13400 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       m_VulkanFunctions.vkBindBufferMemory2KHR != nullptr
# 13400 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 13400 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "m_VulkanFunctions.vkBindBufferMemory2KHR != nullptr"
# 13400 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13400),0))
# 13400 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                       ;
        
# 13401 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 13401 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       m_VulkanFunctions.vkBindImageMemory2KHR != nullptr
# 13401 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 13401 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "m_VulkanFunctions.vkBindImageMemory2KHR != nullptr"
# 13401 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13401),0))
# 13401 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                      ;
    }



    if(m_UseExtMemoryBudget || m_VulkanApiVersion >= 
# 13406 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                    ((((uint32_t)(
# 13406 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                    1
# 13406 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                    )) << 22U) | (((uint32_t)(
# 13406 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                    1
# 13406 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                    )) << 12U) | ((uint32_t)(
# 13406 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                    0
# 13406 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                    )))
# 13406 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                            )
    {
        
# 13408 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 13408 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties2KHR != nullptr
# 13408 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 13408 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "m_VulkanFunctions.vkGetPhysicalDeviceMemoryProperties2KHR != nullptr"
# 13408 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13408),0))
# 13408 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                        ;
    }
# 13424 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
}

VkDeviceSize VmaAllocator_T::CalcPreferredBlockSize(uint32_t memTypeIndex)
{
    const uint32_t heapIndex = MemoryTypeIndexToHeapIndex(memTypeIndex);
    const VkDeviceSize heapSize = m_MemProps.memoryHeaps[heapIndex].size;
    const bool isSmallHeap = heapSize <= (1024ull * 1024 * 1024);
    return VmaAlignUp(isSmallHeap ? (heapSize / 8) : m_PreferredLargeHeapBlockSize, (VkDeviceSize)32);
}

VkResult VmaAllocator_T::AllocateMemoryOfType(
    VmaPool pool,
    VkDeviceSize size,
    VkDeviceSize alignment,
    bool dedicatedPreferred,
    VkBuffer dedicatedBuffer,
    VkImage dedicatedImage,
    VmaBufferImageUsage dedicatedBufferImageUsage,
    const VmaAllocationCreateInfo& createInfo,
    uint32_t memTypeIndex,
    VmaSuballocationType suballocType,
    VmaDedicatedAllocationList& dedicatedAllocations,
    VmaBlockVector& blockVector,
    size_t allocationCount,
    VmaAllocation* pAllocations)
{
    
# 13450 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13450 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pAllocations != nullptr
# 13450 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13450 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pAllocations != nullptr"
# 13450 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13450),0))
# 13450 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                       ;
    ;

    VmaAllocationCreateInfo finalCreateInfo = createInfo;
    VkResult res = CalcMemTypeParams(
        finalCreateInfo,
        memTypeIndex,
        size,
        allocationCount);
    if(res != VK_SUCCESS)
        return res;

    if((finalCreateInfo.flags & VMA_ALLOCATION_CREATE_DEDICATED_MEMORY_BIT) != 0)
    {
        return AllocateDedicatedMemory(
            pool,
            size,
            suballocType,
            dedicatedAllocations,
            memTypeIndex,
            (finalCreateInfo.flags & VMA_ALLOCATION_CREATE_MAPPED_BIT) != 0,
            (finalCreateInfo.flags & VMA_ALLOCATION_CREATE_USER_DATA_COPY_STRING_BIT) != 0,
            (finalCreateInfo.flags &
                (VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT | VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT)) != 0,
            (finalCreateInfo.flags & VMA_ALLOCATION_CREATE_CAN_ALIAS_BIT) != 0,
            finalCreateInfo.pUserData,
            finalCreateInfo.priority,
            dedicatedBuffer,
            dedicatedImage,
            dedicatedBufferImageUsage,
            allocationCount,
            pAllocations,
            blockVector.GetAllocationNextPtr());
    }
    else
    {
        const bool canAllocateDedicated =
            (finalCreateInfo.flags & VMA_ALLOCATION_CREATE_NEVER_ALLOCATE_BIT) == 0 &&
            (pool == 
# 13488 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                    nullptr 
# 13488 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   || !blockVector.HasExplicitBlockSize());

        if(canAllocateDedicated)
        {

            if(size > blockVector.GetPreferredBlockSize() / 2)
            {
                dedicatedPreferred = true;
            }



            if(m_PhysicalDeviceProperties.limits.maxMemoryAllocationCount < 
# 13500 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                                           0xffffffffU 
# 13500 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                      / 4 &&
                m_DeviceMemoryCount.load() > m_PhysicalDeviceProperties.limits.maxMemoryAllocationCount * 3 / 4)
            {
                dedicatedPreferred = false;
            }

            if(dedicatedPreferred)
            {
                res = AllocateDedicatedMemory(
                    pool,
                    size,
                    suballocType,
                    dedicatedAllocations,
                    memTypeIndex,
                    (finalCreateInfo.flags & VMA_ALLOCATION_CREATE_MAPPED_BIT) != 0,
                    (finalCreateInfo.flags & VMA_ALLOCATION_CREATE_USER_DATA_COPY_STRING_BIT) != 0,
                    (finalCreateInfo.flags &
                        (VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT | VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT)) != 0,
                    (finalCreateInfo.flags & VMA_ALLOCATION_CREATE_CAN_ALIAS_BIT) != 0,
                    finalCreateInfo.pUserData,
                    finalCreateInfo.priority,
                    dedicatedBuffer,
                    dedicatedImage,
                    dedicatedBufferImageUsage,
                    allocationCount,
                    pAllocations,
                    blockVector.GetAllocationNextPtr());
                if(res == VK_SUCCESS)
                {

                    ;
                    return VK_SUCCESS;
                }
            }
        }

        res = blockVector.Allocate(
            size,
            alignment,
            finalCreateInfo,
            suballocType,
            allocationCount,
            pAllocations);
        if(res == VK_SUCCESS)
            return VK_SUCCESS;


        if(canAllocateDedicated && !dedicatedPreferred)
        {
            res = AllocateDedicatedMemory(
                pool,
                size,
                suballocType,
                dedicatedAllocations,
                memTypeIndex,
                (finalCreateInfo.flags & VMA_ALLOCATION_CREATE_MAPPED_BIT) != 0,
                (finalCreateInfo.flags & VMA_ALLOCATION_CREATE_USER_DATA_COPY_STRING_BIT) != 0,
                (finalCreateInfo.flags &
                    (VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT | VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT)) != 0,
                (finalCreateInfo.flags & VMA_ALLOCATION_CREATE_CAN_ALIAS_BIT) != 0,
                finalCreateInfo.pUserData,
                finalCreateInfo.priority,
                dedicatedBuffer,
                dedicatedImage,
                dedicatedBufferImageUsage,
                allocationCount,
                pAllocations,
                blockVector.GetAllocationNextPtr());
            if(res == VK_SUCCESS)
            {

                ;
                return VK_SUCCESS;
            }
        }

        ;
        return res;
    }
}

VkResult VmaAllocator_T::AllocateDedicatedMemory(
    VmaPool pool,
    VkDeviceSize size,
    VmaSuballocationType suballocType,
    VmaDedicatedAllocationList& dedicatedAllocations,
    uint32_t memTypeIndex,
    bool map,
    bool isUserDataString,
    bool isMappingAllowed,
    bool canAliasMemory,
    void* pUserData,
    float priority,
    VkBuffer dedicatedBuffer,
    VkImage dedicatedImage,
    VmaBufferImageUsage dedicatedBufferImageUsage,
    size_t allocationCount,
    VmaAllocation* pAllocations,
    const void* pNextChain)
{
    
# 13600 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13600 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocationCount > 0 && pAllocations
# 13600 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13600 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocationCount > 0 && pAllocations"
# 13600 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13600),0))
# 13600 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                  ;

    VkMemoryAllocateInfo allocInfo = { VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO };
    allocInfo.memoryTypeIndex = memTypeIndex;
    allocInfo.allocationSize = size;
    allocInfo.pNext = pNextChain;


    VkMemoryDedicatedAllocateInfoKHR dedicatedAllocInfo = { VK_STRUCTURE_TYPE_MEMORY_DEDICATED_ALLOCATE_INFO_KHR };
    if(!canAliasMemory)
    {
        if(m_UseKhrDedicatedAllocation || m_VulkanApiVersion >= 
# 13611 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                               ((((uint32_t)(
# 13611 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                               1
# 13611 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                               )) << 22U) | (((uint32_t)(
# 13611 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                               1
# 13611 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                               )) << 12U) | ((uint32_t)(
# 13611 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                               0
# 13611 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                               )))
# 13611 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                       )
        {
            if(dedicatedBuffer != 
# 13613 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                 nullptr
# 13613 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                               )
            {
                
# 13615 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 13615 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               dedicatedImage == 
# 13615 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
               nullptr)) || (_assert(
# 13615 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "dedicatedImage == nullptr"
# 13615 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13615),0))
# 13615 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                           ;
                dedicatedAllocInfo.buffer = dedicatedBuffer;
                VmaPnextChainPushFront(&allocInfo, &dedicatedAllocInfo);
            }
            else if(dedicatedImage != 
# 13619 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                     nullptr
# 13619 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                   )
            {
                dedicatedAllocInfo.image = dedicatedImage;
                VmaPnextChainPushFront(&allocInfo, &dedicatedAllocInfo);
            }
        }
    }



    VkMemoryAllocateFlagsInfoKHR allocFlagsInfo = { VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_FLAGS_INFO_KHR };
    if(m_UseKhrBufferDeviceAddress)
    {
        bool canContainBufferWithDeviceAddress = true;
        if(dedicatedBuffer != 
# 13633 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                             nullptr
# 13633 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                           )
        {
            canContainBufferWithDeviceAddress = dedicatedBufferImageUsage == VmaBufferImageUsage::UNKNOWN ||
                dedicatedBufferImageUsage.Contains(VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT_EXT);
        }
        else if(dedicatedImage != 
# 13638 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                 nullptr
# 13638 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                               )
        {
            canContainBufferWithDeviceAddress = false;
        }
        if(canContainBufferWithDeviceAddress)
        {
            allocFlagsInfo.flags = VK_MEMORY_ALLOCATE_DEVICE_ADDRESS_BIT_KHR;
            VmaPnextChainPushFront(&allocInfo, &allocFlagsInfo);
        }
    }



    VkMemoryPriorityAllocateInfoEXT priorityInfo = { VK_STRUCTURE_TYPE_MEMORY_PRIORITY_ALLOCATE_INFO_EXT };
    if(m_UseExtMemoryPriority)
    {
        
# 13654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 13654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       priority >= 0.f && priority <= 1.f
# 13654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 13654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "priority >= 0.f && priority <= 1.f"
# 13654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13654),0))
# 13654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                     ;
        priorityInfo.priority = priority;
        VmaPnextChainPushFront(&allocInfo, &priorityInfo);
    }




    VkExportMemoryAllocateInfoKHR exportMemoryAllocInfo = { VK_STRUCTURE_TYPE_EXPORT_MEMORY_ALLOCATE_INFO_KHR };
    exportMemoryAllocInfo.handleTypes = GetExternalMemoryHandleTypeFlags(memTypeIndex);
    if(exportMemoryAllocInfo.handleTypes != 0)
    {
        VmaPnextChainPushFront(&allocInfo, &exportMemoryAllocInfo);
    }


    size_t allocIndex;
    VkResult res = VK_SUCCESS;
    for(allocIndex = 0; allocIndex < allocationCount; ++allocIndex)
    {
        res = AllocateDedicatedMemoryPage(
            pool,
            size,
            suballocType,
            memTypeIndex,
            allocInfo,
            map,
            isUserDataString,
            isMappingAllowed,
            pUserData,
            pAllocations + allocIndex);
        if(res != VK_SUCCESS)
        {
            break;
        }
    }

    if(res == VK_SUCCESS)
    {
        for (allocIndex = 0; allocIndex < allocationCount; ++allocIndex)
        {
            dedicatedAllocations.Register(pAllocations[allocIndex]);
        }
        ;
    }
    else
    {

        while(allocIndex--)
        {
            VmaAllocation currAlloc = pAllocations[allocIndex];
            VkDeviceMemory hMemory = currAlloc->GetMemory();
# 13717 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
            FreeVulkanMemory(memTypeIndex, currAlloc->GetSize(), hMemory);
            m_Budget.RemoveAllocation(MemoryTypeIndexToHeapIndex(memTypeIndex), currAlloc->GetSize());
            m_AllocationObjectAllocator.Free(currAlloc);
        }

        memset(pAllocations, 0, sizeof(VmaAllocation) * allocationCount);
    }

    return res;
}

VkResult VmaAllocator_T::AllocateDedicatedMemoryPage(
    VmaPool pool,
    VkDeviceSize size,
    VmaSuballocationType suballocType,
    uint32_t memTypeIndex,
    const VkMemoryAllocateInfo& allocInfo,
    bool map,
    bool isUserDataString,
    bool isMappingAllowed,
    void* pUserData,
    VmaAllocation* pAllocation)
{
    VkDeviceMemory hMemory = 
# 13740 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                            nullptr
# 13740 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                          ;
    VkResult res = AllocateVulkanMemory(&allocInfo, &hMemory);
    if(res < 0)
    {
        ;
        return res;
    }

    void* pMappedData = nullptr;
    if(map)
    {
        res = (*m_VulkanFunctions.vkMapMemory)(
            m_hDevice,
            hMemory,
            0,
            
# 13755 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
           (~0ULL)
# 13755 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ,
            0,
            &pMappedData);
        if(res < 0)
        {
            ;
            FreeVulkanMemory(memTypeIndex, size, hMemory);
            return res;
        }
    }

    *pAllocation = m_AllocationObjectAllocator.Allocate(isMappingAllowed);
    (*pAllocation)->InitDedicatedAllocation(this, pool, memTypeIndex, hMemory, suballocType, pMappedData, size);
    if (isUserDataString)
        (*pAllocation)->SetName(this, (const char*)pUserData);
    else
        (*pAllocation)->SetUserData(this, pUserData);
    m_Budget.AddAllocation(MemoryTypeIndexToHeapIndex(memTypeIndex), size);
    if((0))
    {
        FillAllocation(*pAllocation, VMA_ALLOCATION_FILL_PATTERN_CREATED);
    }

    return VK_SUCCESS;
}

void VmaAllocator_T::GetBufferMemoryRequirements(
    VkBuffer hBuffer,
    VkMemoryRequirements& memReq,
    bool& requiresDedicatedAllocation,
    bool& prefersDedicatedAllocation) const
{

    if(m_UseKhrDedicatedAllocation || m_VulkanApiVersion >= 
# 13788 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                           ((((uint32_t)(
# 13788 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                           1
# 13788 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                           )) << 22U) | (((uint32_t)(
# 13788 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                           1
# 13788 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                           )) << 12U) | ((uint32_t)(
# 13788 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                           0
# 13788 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                           )))
# 13788 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                   )
    {
        VkBufferMemoryRequirementsInfo2KHR memReqInfo = { VK_STRUCTURE_TYPE_BUFFER_MEMORY_REQUIREMENTS_INFO_2_KHR };
        memReqInfo.buffer = hBuffer;

        VkMemoryDedicatedRequirementsKHR memDedicatedReq = { VK_STRUCTURE_TYPE_MEMORY_DEDICATED_REQUIREMENTS_KHR };

        VkMemoryRequirements2KHR memReq2 = { VK_STRUCTURE_TYPE_MEMORY_REQUIREMENTS_2_KHR };
        VmaPnextChainPushFront(&memReq2, &memDedicatedReq);

        (*m_VulkanFunctions.vkGetBufferMemoryRequirements2KHR)(m_hDevice, &memReqInfo, &memReq2);

        memReq = memReq2.memoryRequirements;
        requiresDedicatedAllocation = (memDedicatedReq.requiresDedicatedAllocation != 
# 13801 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                                                     0U
# 13801 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                             );
        prefersDedicatedAllocation = (memDedicatedReq.prefersDedicatedAllocation != 
# 13802 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                                                     0U
# 13802 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                             );
    }
    else

    {
        (*m_VulkanFunctions.vkGetBufferMemoryRequirements)(m_hDevice, hBuffer, &memReq);
        requiresDedicatedAllocation = false;
        prefersDedicatedAllocation = false;
    }
}

void VmaAllocator_T::GetImageMemoryRequirements(
    VkImage hImage,
    VkMemoryRequirements& memReq,
    bool& requiresDedicatedAllocation,
    bool& prefersDedicatedAllocation) const
{

    if(m_UseKhrDedicatedAllocation || m_VulkanApiVersion >= 
# 13820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                           ((((uint32_t)(
# 13820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                           1
# 13820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                           )) << 22U) | (((uint32_t)(
# 13820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                           1
# 13820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                           )) << 12U) | ((uint32_t)(
# 13820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                           0
# 13820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                           )))
# 13820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                   )
    {
        VkImageMemoryRequirementsInfo2KHR memReqInfo = { VK_STRUCTURE_TYPE_IMAGE_MEMORY_REQUIREMENTS_INFO_2_KHR };
        memReqInfo.image = hImage;

        VkMemoryDedicatedRequirementsKHR memDedicatedReq = { VK_STRUCTURE_TYPE_MEMORY_DEDICATED_REQUIREMENTS_KHR };

        VkMemoryRequirements2KHR memReq2 = { VK_STRUCTURE_TYPE_MEMORY_REQUIREMENTS_2_KHR };
        VmaPnextChainPushFront(&memReq2, &memDedicatedReq);

        (*m_VulkanFunctions.vkGetImageMemoryRequirements2KHR)(m_hDevice, &memReqInfo, &memReq2);

        memReq = memReq2.memoryRequirements;
        requiresDedicatedAllocation = (memDedicatedReq.requiresDedicatedAllocation != 
# 13833 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                                                     0U
# 13833 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                             );
        prefersDedicatedAllocation = (memDedicatedReq.prefersDedicatedAllocation != 
# 13834 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                                                     0U
# 13834 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                             );
    }
    else

    {
        (*m_VulkanFunctions.vkGetImageMemoryRequirements)(m_hDevice, hImage, &memReq);
        requiresDedicatedAllocation = false;
        prefersDedicatedAllocation = false;
    }
}

VkResult VmaAllocator_T::FindMemoryTypeIndex(
    uint32_t memoryTypeBits,
    const VmaAllocationCreateInfo* pAllocationCreateInfo,
    VmaBufferImageUsage bufImgUsage,
    uint32_t* pMemoryTypeIndex) const
{
    memoryTypeBits &= GetGlobalMemoryTypeBits();

    if(pAllocationCreateInfo->memoryTypeBits != 0)
    {
        memoryTypeBits &= pAllocationCreateInfo->memoryTypeBits;
    }

    VkMemoryPropertyFlags requiredFlags = 0, preferredFlags = 0, notPreferredFlags = 0;
    if(!FindMemoryPreferences(
        IsIntegratedGpu(),
        *pAllocationCreateInfo,
        bufImgUsage,
        requiredFlags, preferredFlags, notPreferredFlags))
    {
        return VK_ERROR_FEATURE_NOT_PRESENT;
    }

    *pMemoryTypeIndex = 
# 13868 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                       0xffffffffU
# 13868 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                 ;
    uint32_t minCost = 
# 13869 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                      0xffffffffU
# 13869 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                ;
    for(uint32_t memTypeIndex = 0, memTypeBit = 1;
        memTypeIndex < GetMemoryTypeCount();
        ++memTypeIndex, memTypeBit <<= 1)
    {

        if((memTypeBit & memoryTypeBits) != 0)
        {
            const VkMemoryPropertyFlags currFlags =
                m_MemProps.memoryTypes[memTypeIndex].propertyFlags;

            if((requiredFlags & ~currFlags) == 0)
            {

                uint32_t currCost = VmaCountBitsSet(preferredFlags & ~currFlags) +
                    VmaCountBitsSet(currFlags & notPreferredFlags);

                if(currCost < minCost)
                {
                    *pMemoryTypeIndex = memTypeIndex;
                    if(currCost == 0)
                    {
                        return VK_SUCCESS;
                    }
                    minCost = currCost;
                }
            }
        }
    }
    return (*pMemoryTypeIndex != 
# 13898 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                0xffffffffU
# 13898 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                          ) ? VK_SUCCESS : VK_ERROR_FEATURE_NOT_PRESENT;
}

VkResult VmaAllocator_T::CalcMemTypeParams(
    VmaAllocationCreateInfo& inoutCreateInfo,
    uint32_t memTypeIndex,
    VkDeviceSize size,
    size_t allocationCount)
{

    if((inoutCreateInfo.flags & VMA_ALLOCATION_CREATE_MAPPED_BIT) != 0 &&
        (m_MemProps.memoryTypes[memTypeIndex].propertyFlags & VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT) == 0)
    {
        inoutCreateInfo.flags &= ~VMA_ALLOCATION_CREATE_MAPPED_BIT;
    }

    if((inoutCreateInfo.flags & VMA_ALLOCATION_CREATE_DEDICATED_MEMORY_BIT) != 0 &&
        (inoutCreateInfo.flags & VMA_ALLOCATION_CREATE_WITHIN_BUDGET_BIT) != 0)
    {
        const uint32_t heapIndex = MemoryTypeIndexToHeapIndex(memTypeIndex);
        VmaBudget heapBudget = {};
        GetHeapBudgets(&heapBudget, heapIndex, 1);
        if(heapBudget.usage + size * allocationCount > heapBudget.budget)
        {
            return VK_ERROR_OUT_OF_DEVICE_MEMORY;
        }
    }
    return VK_SUCCESS;
}

VkResult VmaAllocator_T::CalcAllocationParams(
    VmaAllocationCreateInfo& inoutCreateInfo,
    bool dedicatedRequired,
    bool dedicatedPreferred)
{
    
# 13933 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13933 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   (inoutCreateInfo.flags & (VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT | VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT)) != (VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT | VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT) && "Specifying both flags VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT and VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT is incorrect."
# 13933 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13933 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "(inoutCreateInfo.flags & (VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT | VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT)) != (VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT | VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT) && \"Specifying both flags VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT and VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT is incorrect.\""
# 13933 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13933),0))


                                                                                                                                                      
# 13936 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                                     ;
    
# 13937 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 13937 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   (((inoutCreateInfo.flags & VMA_ALLOCATION_CREATE_HOST_ACCESS_ALLOW_TRANSFER_INSTEAD_BIT) == 0 || (inoutCreateInfo.flags & (VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT | VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT)) != 0)) && "Specifying VMA_ALLOCATION_CREATE_HOST_ACCESS_ALLOW_TRANSFER_INSTEAD_BIT requires also VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT or VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT."
# 13937 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 13937 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "(((inoutCreateInfo.flags & VMA_ALLOCATION_CREATE_HOST_ACCESS_ALLOW_TRANSFER_INSTEAD_BIT) == 0 || (inoutCreateInfo.flags & (VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT | VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT)) != 0)) && \"Specifying VMA_ALLOCATION_CREATE_HOST_ACCESS_ALLOW_TRANSFER_INSTEAD_BIT requires also VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT or VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT.\""
# 13937 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13937),0))

                                                                                                                                                                                                        
# 13939 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                                                                                       ;
    if(inoutCreateInfo.usage == VMA_MEMORY_USAGE_AUTO || inoutCreateInfo.usage == VMA_MEMORY_USAGE_AUTO_PREFER_DEVICE || inoutCreateInfo.usage == VMA_MEMORY_USAGE_AUTO_PREFER_HOST)
    {
        if((inoutCreateInfo.flags & VMA_ALLOCATION_CREATE_MAPPED_BIT) != 0)
        {
            
# 13944 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 13944 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           (inoutCreateInfo.flags & (VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT | VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT)) != 0 && "When using VMA_ALLOCATION_CREATE_MAPPED_BIT and usage = VMA_MEMORY_USAGE_AUTO*, you must also specify VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT or VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT."
# 13944 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 13944 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "(inoutCreateInfo.flags & (VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT | VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT)) != 0 && \"When using VMA_ALLOCATION_CREATE_MAPPED_BIT and usage = VMA_MEMORY_USAGE_AUTO*, you must also specify VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT or VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT.\""
# 13944 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13944),0))
                                                                                                                                                                                                                                
# 13945 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                                                                                                               ;
        }
    }


    if(dedicatedRequired ||
        inoutCreateInfo.usage == VMA_MEMORY_USAGE_GPU_LAZILY_ALLOCATED)
    {
        inoutCreateInfo.flags |= VMA_ALLOCATION_CREATE_DEDICATED_MEMORY_BIT;
    }

    if(inoutCreateInfo.pool != 
# 13956 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                              nullptr
# 13956 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                            )
    {
        if(inoutCreateInfo.pool->m_BlockVector.HasExplicitBlockSize() &&
            (inoutCreateInfo.flags & VMA_ALLOCATION_CREATE_DEDICATED_MEMORY_BIT) != 0)
        {
            
# 13961 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 13961 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0 && "Specifying VMA_ALLOCATION_CREATE_DEDICATED_MEMORY_BIT while current custom pool doesn't support dedicated allocations."
# 13961 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 13961 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0 && \"Specifying VMA_ALLOCATION_CREATE_DEDICATED_MEMORY_BIT while current custom pool doesn't support dedicated allocations.\""
# 13961 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13961),0))
# 13961 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                                    ;
            return VK_ERROR_FEATURE_NOT_PRESENT;
        }
        inoutCreateInfo.priority = inoutCreateInfo.pool->m_BlockVector.GetPriority();
    }

    if((inoutCreateInfo.flags & VMA_ALLOCATION_CREATE_DEDICATED_MEMORY_BIT) != 0 &&
        (inoutCreateInfo.flags & VMA_ALLOCATION_CREATE_NEVER_ALLOCATE_BIT) != 0)
    {
        
# 13970 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 13970 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Specifying VMA_ALLOCATION_CREATE_DEDICATED_MEMORY_BIT together with VMA_ALLOCATION_CREATE_NEVER_ALLOCATE_BIT makes no sense."
# 13970 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 13970 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Specifying VMA_ALLOCATION_CREATE_DEDICATED_MEMORY_BIT together with VMA_ALLOCATION_CREATE_NEVER_ALLOCATE_BIT makes no sense.\""
# 13970 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",13970),0))
# 13970 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                                      ;
        return VK_ERROR_FEATURE_NOT_PRESENT;
    }

    if((0) &&
        (inoutCreateInfo.flags & VMA_ALLOCATION_CREATE_NEVER_ALLOCATE_BIT) != 0)
    {
        inoutCreateInfo.flags |= VMA_ALLOCATION_CREATE_DEDICATED_MEMORY_BIT;
    }





    if(inoutCreateInfo.usage != VMA_MEMORY_USAGE_AUTO &&
        inoutCreateInfo.usage != VMA_MEMORY_USAGE_AUTO_PREFER_DEVICE &&
        inoutCreateInfo.usage != VMA_MEMORY_USAGE_AUTO_PREFER_HOST)
    {
        if((inoutCreateInfo.flags & (VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT | VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT)) == 0)
        {
            inoutCreateInfo.flags |= VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT;
        }
    }

    return VK_SUCCESS;
}

VkResult VmaAllocator_T::AllocateMemory(
    const VkMemoryRequirements& vkMemReq,
    bool requiresDedicatedAllocation,
    bool prefersDedicatedAllocation,
    VkBuffer dedicatedBuffer,
    VkImage dedicatedImage,
    VmaBufferImageUsage dedicatedBufferImageUsage,
    const VmaAllocationCreateInfo& createInfo,
    VmaSuballocationType suballocType,
    size_t allocationCount,
    VmaAllocation* pAllocations)
{
    memset(pAllocations, 0, sizeof(VmaAllocation) * allocationCount);

    
# 14011 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 14011 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   VmaIsPow2(vkMemReq.alignment)
# 14011 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 14011 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "VmaIsPow2(vkMemReq.alignment)"
# 14011 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14011),0))
# 14011 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                            ;

    if(vkMemReq.size == 0)
    {
        return VK_ERROR_INITIALIZATION_FAILED;
    }

    VmaAllocationCreateInfo createInfoFinal = createInfo;
    VkResult res = CalcAllocationParams(createInfoFinal, requiresDedicatedAllocation, prefersDedicatedAllocation);
    if(res != VK_SUCCESS)
        return res;

    if(createInfoFinal.pool != 
# 14023 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                              nullptr
# 14023 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                            )
    {
        VmaBlockVector& blockVector = createInfoFinal.pool->m_BlockVector;
        return AllocateMemoryOfType(
            createInfoFinal.pool,
            vkMemReq.size,
            vkMemReq.alignment,
            prefersDedicatedAllocation,
            dedicatedBuffer,
            dedicatedImage,
            dedicatedBufferImageUsage,
            createInfoFinal,
            blockVector.GetMemoryTypeIndex(),
            suballocType,
            createInfoFinal.pool->m_DedicatedAllocations,
            blockVector,
            allocationCount,
            pAllocations);
    }
    else
    {

        uint32_t memoryTypeBits = vkMemReq.memoryTypeBits;
        uint32_t memTypeIndex = 
# 14046 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                               0xffffffffU
# 14046 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                         ;
        res = FindMemoryTypeIndex(memoryTypeBits, &createInfoFinal, dedicatedBufferImageUsage, &memTypeIndex);

        if(res != VK_SUCCESS)
            return res;
        do
        {
            VmaBlockVector* blockVector = m_pBlockVectors[memTypeIndex];
            
# 14054 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 14054 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           blockVector && "Trying to use unsupported memory type!"
# 14054 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 14054 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "blockVector && \"Trying to use unsupported memory type!\""
# 14054 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14054),0))
# 14054 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                              ;
            res = AllocateMemoryOfType(
                
# 14056 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
               nullptr
# 14056 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                             ,
                vkMemReq.size,
                vkMemReq.alignment,
                requiresDedicatedAllocation || prefersDedicatedAllocation,
                dedicatedBuffer,
                dedicatedImage,
                dedicatedBufferImageUsage,
                createInfoFinal,
                memTypeIndex,
                suballocType,
                m_DedicatedAllocations[memTypeIndex],
                *blockVector,
                allocationCount,
                pAllocations);

            if(res == VK_SUCCESS)
                return VK_SUCCESS;


            memoryTypeBits &= ~(1u << memTypeIndex);

            res = FindMemoryTypeIndex(memoryTypeBits, &createInfoFinal, dedicatedBufferImageUsage, &memTypeIndex);
        } while(res == VK_SUCCESS);



        return VK_ERROR_OUT_OF_DEVICE_MEMORY;
    }
}

void VmaAllocator_T::FreeMemory(
    size_t allocationCount,
    const VmaAllocation* pAllocations)
{
    
# 14090 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 14090 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pAllocations
# 14090 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 14090 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pAllocations"
# 14090 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14090),0))
# 14090 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                           ;

    for(size_t allocIndex = allocationCount; allocIndex--; )
    {
        VmaAllocation allocation = pAllocations[allocIndex];

        if(allocation != 
# 14096 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                        nullptr
# 14096 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                      )
        {
            if((0))
            {
                FillAllocation(allocation, VMA_ALLOCATION_FILL_PATTERN_DESTROYED);
            }

            switch(allocation->GetType())
            {
            case VmaAllocation_T::ALLOCATION_TYPE_BLOCK:
                {
                    VmaBlockVector* pBlockVector = nullptr;
                    VmaPool hPool = allocation->GetParentPool();
                    if(hPool != 
# 14109 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                               nullptr
# 14109 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                             )
                    {
                        pBlockVector = &hPool->m_BlockVector;
                    }
                    else
                    {
                        const uint32_t memTypeIndex = allocation->GetMemoryTypeIndex();
                        pBlockVector = m_pBlockVectors[memTypeIndex];
                        
# 14117 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                       (void) ((!!(
# 14117 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                       pBlockVector && "Trying to free memory of unsupported type!"
# 14117 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                       )) || (_assert(
# 14117 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                       "pBlockVector && \"Trying to free memory of unsupported type!\""
# 14117 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
                       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14117),0))
# 14117 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                               ;
                    }
                    pBlockVector->Free(allocation);
                }
                break;
            case VmaAllocation_T::ALLOCATION_TYPE_DEDICATED:
                FreeDedicatedMemory(allocation);
                break;
            default:
                
# 14126 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 14126 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               0
# 14126 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 14126 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "0"
# 14126 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14126),0))
# 14126 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            ;
            }
        }
    }
}

void VmaAllocator_T::CalculateStatistics(VmaTotalStatistics* pStats)
{

    VmaClearDetailedStatistics(pStats->total);
    for(uint32_t i = 0; i < 
# 14136 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                           32U
# 14136 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                              ; ++i)
        VmaClearDetailedStatistics(pStats->memoryType[i]);
    for(uint32_t i = 0; i < 
# 14138 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                           16U
# 14138 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                              ; ++i)
        VmaClearDetailedStatistics(pStats->memoryHeap[i]);


    for(uint32_t memTypeIndex = 0; memTypeIndex < GetMemoryTypeCount(); ++memTypeIndex)
    {
        VmaBlockVector* const pBlockVector = m_pBlockVectors[memTypeIndex];
        if (pBlockVector != nullptr)
            pBlockVector->AddDetailedStatistics(pStats->memoryType[memTypeIndex]);
    }


    {
        VmaMutexLockRead lock(m_PoolsMutex, m_UseMutex);
        for(VmaPool pool = m_Pools.Front(); pool != nullptr; pool = m_Pools.GetNext(pool))
        {
            VmaBlockVector& blockVector = pool->m_BlockVector;
            const uint32_t memTypeIndex = blockVector.GetMemoryTypeIndex();
            blockVector.AddDetailedStatistics(pStats->memoryType[memTypeIndex]);
            pool->m_DedicatedAllocations.AddDetailedStatistics(pStats->memoryType[memTypeIndex]);
        }
    }


    for(uint32_t memTypeIndex = 0; memTypeIndex < GetMemoryTypeCount(); ++memTypeIndex)
    {
        m_DedicatedAllocations[memTypeIndex].AddDetailedStatistics(pStats->memoryType[memTypeIndex]);
    }


    for(uint32_t memTypeIndex = 0; memTypeIndex < GetMemoryTypeCount(); ++memTypeIndex)
    {
        const uint32_t memHeapIndex = m_MemProps.memoryTypes[memTypeIndex].heapIndex;
        VmaAddDetailedStatistics(pStats->memoryHeap[memHeapIndex], pStats->memoryType[memTypeIndex]);
    }


    for(uint32_t memHeapIndex = 0; memHeapIndex < GetMemoryHeapCount(); ++memHeapIndex)
        VmaAddDetailedStatistics(pStats->total, pStats->memoryHeap[memHeapIndex]);

    
# 14178 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 14178 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pStats->total.statistics.allocationCount == 0 || pStats->total.allocationSizeMax >= pStats->total.allocationSizeMin
# 14178 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 14178 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pStats->total.statistics.allocationCount == 0 || pStats->total.allocationSizeMax >= pStats->total.allocationSizeMin"
# 14178 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14178),0))
                                                                           
# 14179 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                          ;
    
# 14180 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 14180 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pStats->total.unusedRangeCount == 0 || pStats->total.unusedRangeSizeMax >= pStats->total.unusedRangeSizeMin
# 14180 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 14180 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pStats->total.unusedRangeCount == 0 || pStats->total.unusedRangeSizeMax >= pStats->total.unusedRangeSizeMin"
# 14180 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14180),0))
                                                                             
# 14181 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                            ;
}

void VmaAllocator_T::GetHeapBudgets(VmaBudget* outBudgets, uint32_t firstHeap, uint32_t heapCount)
{

    if(m_UseExtMemoryBudget)
    {
        if(m_Budget.m_OperationsSinceBudgetFetch < 30)
        {
            VmaMutexLockRead lockRead(m_Budget.m_BudgetMutex, m_UseMutex);
            for(uint32_t i = 0; i < heapCount; ++i, ++outBudgets)
            {
                const uint32_t heapIndex = firstHeap + i;

                outBudgets->statistics.blockCount = m_Budget.m_BlockCount[heapIndex];
                outBudgets->statistics.allocationCount = m_Budget.m_AllocationCount[heapIndex];
                outBudgets->statistics.blockBytes = m_Budget.m_BlockBytes[heapIndex];
                outBudgets->statistics.allocationBytes = m_Budget.m_AllocationBytes[heapIndex];

                if(m_Budget.m_VulkanUsage[heapIndex] + outBudgets->statistics.blockBytes > m_Budget.m_BlockBytesAtBudgetFetch[heapIndex])
                {
                    outBudgets->usage = m_Budget.m_VulkanUsage[heapIndex] +
                        outBudgets->statistics.blockBytes - m_Budget.m_BlockBytesAtBudgetFetch[heapIndex];
                }
                else
                {
                    outBudgets->usage = 0;
                }


                outBudgets->budget = ((std::min)((m_Budget.m_VulkanBudget[heapIndex]), (m_MemProps.memoryHeaps[heapIndex].size)))
                                                                                               ;
            }
        }
        else
        {
            UpdateVulkanBudget();
            GetHeapBudgets(outBudgets, firstHeap, heapCount);
        }
    }
    else

    {
        for(uint32_t i = 0; i < heapCount; ++i, ++outBudgets)
        {
            const uint32_t heapIndex = firstHeap + i;

            outBudgets->statistics.blockCount = m_Budget.m_BlockCount[heapIndex];
            outBudgets->statistics.allocationCount = m_Budget.m_AllocationCount[heapIndex];
            outBudgets->statistics.blockBytes = m_Budget.m_BlockBytes[heapIndex];
            outBudgets->statistics.allocationBytes = m_Budget.m_AllocationBytes[heapIndex];

            outBudgets->usage = outBudgets->statistics.blockBytes;
            outBudgets->budget = m_MemProps.memoryHeaps[heapIndex].size * 8 / 10;
        }
    }
}

void VmaAllocator_T::GetAllocationInfo(VmaAllocation hAllocation, VmaAllocationInfo* pAllocationInfo)
{
    pAllocationInfo->memoryType = hAllocation->GetMemoryTypeIndex();
    pAllocationInfo->deviceMemory = hAllocation->GetMemory();
    pAllocationInfo->offset = hAllocation->GetOffset();
    pAllocationInfo->size = hAllocation->GetSize();
    pAllocationInfo->pMappedData = hAllocation->GetMappedData();
    pAllocationInfo->pUserData = hAllocation->GetUserData();
    pAllocationInfo->pName = hAllocation->GetName();
}

void VmaAllocator_T::GetAllocationInfo2(VmaAllocation hAllocation, VmaAllocationInfo2* pAllocationInfo)
{
    GetAllocationInfo(hAllocation, &pAllocationInfo->allocationInfo);

    switch (hAllocation->GetType())
    {
    case VmaAllocation_T::ALLOCATION_TYPE_BLOCK:
        pAllocationInfo->blockSize = hAllocation->GetBlock()->m_pMetadata->GetSize();
        pAllocationInfo->dedicatedMemory = 
# 14259 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                          0U
# 14259 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                  ;
        break;
    case VmaAllocation_T::ALLOCATION_TYPE_DEDICATED:
        pAllocationInfo->blockSize = pAllocationInfo->allocationInfo.size;
        pAllocationInfo->dedicatedMemory = 
# 14263 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                          1U
# 14263 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                 ;
        break;
    default:
        
# 14266 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 14266 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0
# 14266 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 14266 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0"
# 14266 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14266),0))
# 14266 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                    ;
    }
}

VkResult VmaAllocator_T::CreatePool(const VmaPoolCreateInfo* pCreateInfo, VmaPool* pPool)
{
    ;

    VmaPoolCreateInfo newCreateInfo = *pCreateInfo;


    if(pCreateInfo->pMemoryAllocateNext)
    {
        
# 14279 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 14279 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       ((const VkBaseInStructure*)pCreateInfo->pMemoryAllocateNext)->sType != 0
# 14279 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 14279 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "((const VkBaseInStructure*)pCreateInfo->pMemoryAllocateNext)->sType != 0"
# 14279 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14279),0))
# 14279 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                           ;
    }

    if(newCreateInfo.maxBlockCount == 0)
    {
        newCreateInfo.maxBlockCount = 
# 14284 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                     0xffffffffffffffffULL
# 14284 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                             ;
    }
    if(newCreateInfo.minBlockCount > newCreateInfo.maxBlockCount)
    {
        return VK_ERROR_INITIALIZATION_FAILED;
    }

    if(pCreateInfo->memoryTypeIndex >= GetMemoryTypeCount() ||
        ((1u << pCreateInfo->memoryTypeIndex) & m_GlobalMemoryTypeBits) == 0)
    {
        return VK_ERROR_FEATURE_NOT_PRESENT;
    }
    if(newCreateInfo.minAllocationAlignment > 0)
    {
        
# 14298 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 14298 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       VmaIsPow2(newCreateInfo.minAllocationAlignment)
# 14298 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 14298 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "VmaIsPow2(newCreateInfo.minAllocationAlignment)"
# 14298 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14298),0))
# 14298 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                  ;
    }

    const VkDeviceSize preferredBlockSize = CalcPreferredBlockSize(newCreateInfo.memoryTypeIndex);

    *pPool = new(VmaAllocate<VmaPool_T>(this))(VmaPool_T)(this, newCreateInfo, preferredBlockSize);

    VkResult res = (*pPool)->m_BlockVector.CreateMinBlocks();
    if(res != VK_SUCCESS)
    {
        vma_delete(this, *pPool);
        *pPool = nullptr;
        return res;
    }


    {
        VmaMutexLockWrite lock(m_PoolsMutex, m_UseMutex);
        (*pPool)->SetId(m_NextPoolId++);
        m_Pools.PushBack(*pPool);
    }

    return VK_SUCCESS;
}

void VmaAllocator_T::DestroyPool(VmaPool pool)
{

    {
        VmaMutexLockWrite lock(m_PoolsMutex, m_UseMutex);
        m_Pools.Remove(pool);
    }

    vma_delete(this, pool);
}

void VmaAllocator_T::GetPoolStatistics(VmaPool pool, VmaStatistics* pPoolStats)
{
    VmaClearStatistics(*pPoolStats);
    pool->m_BlockVector.AddStatistics(*pPoolStats);
    pool->m_DedicatedAllocations.AddStatistics(*pPoolStats);
}

void VmaAllocator_T::CalculatePoolStatistics(VmaPool pool, VmaDetailedStatistics* pPoolStats)
{
    VmaClearDetailedStatistics(*pPoolStats);
    pool->m_BlockVector.AddDetailedStatistics(*pPoolStats);
    pool->m_DedicatedAllocations.AddDetailedStatistics(*pPoolStats);
}

void VmaAllocator_T::SetCurrentFrameIndex(uint32_t frameIndex)
{
    m_CurrentFrameIndex.store(frameIndex);


    if(m_UseExtMemoryBudget)
    {
        UpdateVulkanBudget();
    }

}

VkResult VmaAllocator_T::CheckPoolCorruption(VmaPool hPool)
{
    return hPool->m_BlockVector.CheckCorruption();
}

VkResult VmaAllocator_T::CheckCorruption(uint32_t memoryTypeBits)
{
    VkResult finalRes = VK_ERROR_FEATURE_NOT_PRESENT;


    for(uint32_t memTypeIndex = 0; memTypeIndex < GetMemoryTypeCount(); ++memTypeIndex)
    {
        VmaBlockVector* const pBlockVector = m_pBlockVectors[memTypeIndex];
        if(pBlockVector != nullptr)
        {
            VkResult localRes = pBlockVector->CheckCorruption();
            switch(localRes)
            {
            case VK_ERROR_FEATURE_NOT_PRESENT:
                break;
            case VK_SUCCESS:
                finalRes = VK_SUCCESS;
                break;
            default:
                return localRes;
            }
        }
    }


    {
        VmaMutexLockRead lock(m_PoolsMutex, m_UseMutex);
        for(VmaPool pool = m_Pools.Front(); pool != nullptr; pool = m_Pools.GetNext(pool))
        {
            if(((1u << pool->m_BlockVector.GetMemoryTypeIndex()) & memoryTypeBits) != 0)
            {
                VkResult localRes = pool->m_BlockVector.CheckCorruption();
                switch(localRes)
                {
                case VK_ERROR_FEATURE_NOT_PRESENT:
                    break;
                case VK_SUCCESS:
                    finalRes = VK_SUCCESS;
                    break;
                default:
                    return localRes;
                }
            }
        }
    }

    return finalRes;
}

VkResult VmaAllocator_T::AllocateVulkanMemory(const VkMemoryAllocateInfo* pAllocateInfo, VkDeviceMemory* pMemory)
{
    AtomicTransactionalIncrement<std::atomic<uint32_t> > deviceMemoryCountIncrement;
    const uint64_t prevDeviceMemoryCount = deviceMemoryCountIncrement.Increment(&m_DeviceMemoryCount);







    const uint32_t heapIndex = MemoryTypeIndexToHeapIndex(pAllocateInfo->memoryTypeIndex);


    if((m_HeapSizeLimitMask & (1u << heapIndex)) != 0)
    {
        const VkDeviceSize heapSize = m_MemProps.memoryHeaps[heapIndex].size;
        VkDeviceSize blockBytes = m_Budget.m_BlockBytes[heapIndex];
        for(;;)
        {
            const VkDeviceSize blockBytesAfterAllocation = blockBytes + pAllocateInfo->allocationSize;
            if(blockBytesAfterAllocation > heapSize)
            {
                return VK_ERROR_OUT_OF_DEVICE_MEMORY;
            }
            if(m_Budget.m_BlockBytes[heapIndex].compare_exchange_strong(blockBytes, blockBytesAfterAllocation))
            {
                break;
            }
        }
    }
    else
    {
        m_Budget.m_BlockBytes[heapIndex] += pAllocateInfo->allocationSize;
    }
    ++m_Budget.m_BlockCount[heapIndex];


    VkResult res = (*m_VulkanFunctions.vkAllocateMemory)(m_hDevice, pAllocateInfo, GetAllocationCallbacks(), pMemory);

    if(res == VK_SUCCESS)
    {

        ++m_Budget.m_OperationsSinceBudgetFetch;



        if(m_DeviceMemoryCallbacks.pfnAllocate != nullptr)
        {
            (*m_DeviceMemoryCallbacks.pfnAllocate)(this, pAllocateInfo->memoryTypeIndex, *pMemory, pAllocateInfo->allocationSize, m_DeviceMemoryCallbacks.pUserData);
        }

        deviceMemoryCountIncrement.Commit();
    }
    else
    {
        --m_Budget.m_BlockCount[heapIndex];
        m_Budget.m_BlockBytes[heapIndex] -= pAllocateInfo->allocationSize;
    }

    return res;
}

void VmaAllocator_T::FreeVulkanMemory(uint32_t memoryType, VkDeviceSize size, VkDeviceMemory hMemory)
{

    if(m_DeviceMemoryCallbacks.pfnFree != nullptr)
    {
        (*m_DeviceMemoryCallbacks.pfnFree)(this, memoryType, hMemory, size, m_DeviceMemoryCallbacks.pUserData);
    }


    (*m_VulkanFunctions.vkFreeMemory)(m_hDevice, hMemory, GetAllocationCallbacks());

    const uint32_t heapIndex = MemoryTypeIndexToHeapIndex(memoryType);
    --m_Budget.m_BlockCount[heapIndex];
    m_Budget.m_BlockBytes[heapIndex] -= size;

    --m_DeviceMemoryCount;
}

VkResult VmaAllocator_T::BindVulkanBuffer(
    VkDeviceMemory memory,
    VkDeviceSize memoryOffset,
    VkBuffer buffer,
    const void* pNext)
{
    if(pNext != nullptr)
    {

        if((m_UseKhrBindMemory2 || m_VulkanApiVersion >= 
# 14504 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                        ((((uint32_t)(
# 14504 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                        1
# 14504 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                        )) << 22U) | (((uint32_t)(
# 14504 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                        1
# 14504 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                        )) << 12U) | ((uint32_t)(
# 14504 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                        0
# 14504 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                        )))
# 14504 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                ) &&
            m_VulkanFunctions.vkBindBufferMemory2KHR != nullptr)
        {
            VkBindBufferMemoryInfoKHR bindBufferMemoryInfo = { VK_STRUCTURE_TYPE_BIND_BUFFER_MEMORY_INFO_KHR };
            bindBufferMemoryInfo.pNext = pNext;
            bindBufferMemoryInfo.buffer = buffer;
            bindBufferMemoryInfo.memory = memory;
            bindBufferMemoryInfo.memoryOffset = memoryOffset;
            return (*m_VulkanFunctions.vkBindBufferMemory2KHR)(m_hDevice, 1, &bindBufferMemoryInfo);
        }
        else

        {
            return VK_ERROR_EXTENSION_NOT_PRESENT;
        }
    }
    else
    {
        return (*m_VulkanFunctions.vkBindBufferMemory)(m_hDevice, buffer, memory, memoryOffset);
    }
}

VkResult VmaAllocator_T::BindVulkanImage(
    VkDeviceMemory memory,
    VkDeviceSize memoryOffset,
    VkImage image,
    const void* pNext)
{
    if(pNext != nullptr)
    {

        if((m_UseKhrBindMemory2 || m_VulkanApiVersion >= 
# 14535 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                        ((((uint32_t)(
# 14535 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                        1
# 14535 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                        )) << 22U) | (((uint32_t)(
# 14535 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                        1
# 14535 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                        )) << 12U) | ((uint32_t)(
# 14535 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                        0
# 14535 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                        )))
# 14535 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                ) &&
            m_VulkanFunctions.vkBindImageMemory2KHR != nullptr)
        {
            VkBindImageMemoryInfoKHR bindBufferMemoryInfo = { VK_STRUCTURE_TYPE_BIND_IMAGE_MEMORY_INFO_KHR };
            bindBufferMemoryInfo.pNext = pNext;
            bindBufferMemoryInfo.image = image;
            bindBufferMemoryInfo.memory = memory;
            bindBufferMemoryInfo.memoryOffset = memoryOffset;
            return (*m_VulkanFunctions.vkBindImageMemory2KHR)(m_hDevice, 1, &bindBufferMemoryInfo);
        }
        else

        {
            return VK_ERROR_EXTENSION_NOT_PRESENT;
        }
    }
    else
    {
        return (*m_VulkanFunctions.vkBindImageMemory)(m_hDevice, image, memory, memoryOffset);
    }
}

VkResult VmaAllocator_T::Map(VmaAllocation hAllocation, void** ppData)
{
    switch(hAllocation->GetType())
    {
    case VmaAllocation_T::ALLOCATION_TYPE_BLOCK:
        {
            VmaDeviceMemoryBlock* const pBlock = hAllocation->GetBlock();
            char *pBytes = nullptr;
            VkResult res = pBlock->Map(this, 1, (void**)&pBytes);
            if(res == VK_SUCCESS)
            {
                *ppData = pBytes + (ptrdiff_t)hAllocation->GetOffset();
                hAllocation->BlockAllocMap();
            }
            return res;
        }
    case VmaAllocation_T::ALLOCATION_TYPE_DEDICATED:
        return hAllocation->DedicatedAllocMap(this, ppData);
    default:
        
# 14576 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 14576 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0
# 14576 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 14576 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0"
# 14576 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14576),0))
# 14576 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                    ;
        return VK_ERROR_MEMORY_MAP_FAILED;
    }
}

void VmaAllocator_T::Unmap(VmaAllocation hAllocation)
{
    switch(hAllocation->GetType())
    {
    case VmaAllocation_T::ALLOCATION_TYPE_BLOCK:
        {
            VmaDeviceMemoryBlock* const pBlock = hAllocation->GetBlock();
            hAllocation->BlockAllocUnmap();
            pBlock->Unmap(this, 1);
        }
        break;
    case VmaAllocation_T::ALLOCATION_TYPE_DEDICATED:
        hAllocation->DedicatedAllocUnmap(this);
        break;
    default:
        
# 14596 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 14596 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0
# 14596 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 14596 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0"
# 14596 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14596),0))
# 14596 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                    ;
    }
}

VkResult VmaAllocator_T::BindBufferMemory(
    VmaAllocation hAllocation,
    VkDeviceSize allocationLocalOffset,
    VkBuffer hBuffer,
    const void* pNext)
{
    VkResult res = ((VkResult)-13);
    switch(hAllocation->GetType())
    {
    case VmaAllocation_T::ALLOCATION_TYPE_DEDICATED:
        res = BindVulkanBuffer(hAllocation->GetMemory(), allocationLocalOffset, hBuffer, pNext);
        break;
    case VmaAllocation_T::ALLOCATION_TYPE_BLOCK:
    {
        VmaDeviceMemoryBlock* const pBlock = hAllocation->GetBlock();
        
# 14615 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 14615 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       pBlock && "Binding buffer to allocation that doesn't belong to any block."
# 14615 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 14615 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "pBlock && \"Binding buffer to allocation that doesn't belong to any block.\""
# 14615 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14615),0))
# 14615 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                             ;
        res = pBlock->BindBufferMemory(this, hAllocation, allocationLocalOffset, hBuffer, pNext);
        break;
    }
    default:
        
# 14620 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 14620 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0
# 14620 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 14620 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0"
# 14620 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14620),0))
# 14620 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                    ;
    }
    return res;
}

VkResult VmaAllocator_T::BindImageMemory(
    VmaAllocation hAllocation,
    VkDeviceSize allocationLocalOffset,
    VkImage hImage,
    const void* pNext)
{
    VkResult res = ((VkResult)-13);
    switch(hAllocation->GetType())
    {
    case VmaAllocation_T::ALLOCATION_TYPE_DEDICATED:
        res = BindVulkanImage(hAllocation->GetMemory(), allocationLocalOffset, hImage, pNext);
        break;
    case VmaAllocation_T::ALLOCATION_TYPE_BLOCK:
    {
        VmaDeviceMemoryBlock* pBlock = hAllocation->GetBlock();
        
# 14640 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 14640 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       pBlock && "Binding image to allocation that doesn't belong to any block."
# 14640 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 14640 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "pBlock && \"Binding image to allocation that doesn't belong to any block.\""
# 14640 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14640),0))
# 14640 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                            ;
        res = pBlock->BindImageMemory(this, hAllocation, allocationLocalOffset, hImage, pNext);
        break;
    }
    default:
        
# 14645 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 14645 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0
# 14645 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 14645 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0"
# 14645 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14645),0))
# 14645 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                    ;
    }
    return res;
}

VkResult VmaAllocator_T::FlushOrInvalidateAllocation(
    VmaAllocation hAllocation,
    VkDeviceSize offset, VkDeviceSize size,
    VMA_CACHE_OPERATION op)
{
    VkResult res = VK_SUCCESS;

    VkMappedMemoryRange memRange = {};
    if(GetFlushOrInvalidateRange(hAllocation, offset, size, memRange))
    {
        switch(op)
        {
        case VMA_CACHE_FLUSH:
            res = (*GetVulkanFunctions().vkFlushMappedMemoryRanges)(m_hDevice, 1, &memRange);
            break;
        case VMA_CACHE_INVALIDATE:
            res = (*GetVulkanFunctions().vkInvalidateMappedMemoryRanges)(m_hDevice, 1, &memRange);
            break;
        default:
            
# 14669 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 14669 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0
# 14669 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 14669 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0"
# 14669 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14669),0))
# 14669 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;
        }
    }

    return res;
}

VkResult VmaAllocator_T::FlushOrInvalidateAllocations(
    uint32_t allocationCount,
    const VmaAllocation* allocations,
    const VkDeviceSize* offsets, const VkDeviceSize* sizes,
    VMA_CACHE_OPERATION op)
{
    typedef VmaStlAllocator<VkMappedMemoryRange> RangeAllocator;
    typedef VmaSmallVector<VkMappedMemoryRange, RangeAllocator, 16> RangeVector;
    RangeVector ranges = RangeVector(RangeAllocator(GetAllocationCallbacks()));

    for(uint32_t allocIndex = 0; allocIndex < allocationCount; ++allocIndex)
    {
        const VmaAllocation alloc = allocations[allocIndex];
        const VkDeviceSize offset = offsets != nullptr ? offsets[allocIndex] : 0;
        const VkDeviceSize size = sizes != nullptr ? sizes[allocIndex] : 
# 14690 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                                         (~0ULL)
# 14690 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                      ;
        VkMappedMemoryRange newRange;
        if(GetFlushOrInvalidateRange(alloc, offset, size, newRange))
        {
            ranges.push_back(newRange);
        }
    }

    VkResult res = VK_SUCCESS;
    if(!ranges.empty())
    {
        switch(op)
        {
        case VMA_CACHE_FLUSH:
            res = (*GetVulkanFunctions().vkFlushMappedMemoryRanges)(m_hDevice, (uint32_t)ranges.size(), ranges.data());
            break;
        case VMA_CACHE_INVALIDATE:
            res = (*GetVulkanFunctions().vkInvalidateMappedMemoryRanges)(m_hDevice, (uint32_t)ranges.size(), ranges.data());
            break;
        default:
            
# 14710 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 14710 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0
# 14710 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 14710 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0"
# 14710 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14710),0))
# 14710 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;
        }
    }

    return res;
}

VkResult VmaAllocator_T::CopyMemoryToAllocation(
    const void* pSrcHostPointer,
    VmaAllocation dstAllocation,
    VkDeviceSize dstAllocationLocalOffset,
    VkDeviceSize size)
{
    void* dstMappedData = nullptr;
    VkResult res = Map(dstAllocation, &dstMappedData);
    if(res == VK_SUCCESS)
    {
        memcpy((char*)dstMappedData + dstAllocationLocalOffset, pSrcHostPointer, (size_t)size);
        Unmap(dstAllocation);
        res = FlushOrInvalidateAllocation(dstAllocation, dstAllocationLocalOffset, size, VMA_CACHE_FLUSH);
    }
    return res;
}

VkResult VmaAllocator_T::CopyAllocationToMemory(
    VmaAllocation srcAllocation,
    VkDeviceSize srcAllocationLocalOffset,
    void* pDstHostPointer,
    VkDeviceSize size)
{
    void* srcMappedData = nullptr;
    VkResult res = Map(srcAllocation, &srcMappedData);
    if(res == VK_SUCCESS)
    {
        res = FlushOrInvalidateAllocation(srcAllocation, srcAllocationLocalOffset, size, VMA_CACHE_INVALIDATE);
        if(res == VK_SUCCESS)
        {
            memcpy(pDstHostPointer, (const char*)srcMappedData + srcAllocationLocalOffset, (size_t)size);
            Unmap(srcAllocation);
        }
    }
    return res;
}

void VmaAllocator_T::FreeDedicatedMemory(const VmaAllocation allocation)
{
    
# 14756 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 14756 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocation && allocation->GetType() == VmaAllocation_T::ALLOCATION_TYPE_DEDICATED
# 14756 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 14756 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocation && allocation->GetType() == VmaAllocation_T::ALLOCATION_TYPE_DEDICATED"
# 14756 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14756),0))
# 14756 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                ;

    const uint32_t memTypeIndex = allocation->GetMemoryTypeIndex();
    VmaPool parentPool = allocation->GetParentPool();
    if(parentPool == 
# 14760 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                    nullptr
# 14760 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                  )
    {

        m_DedicatedAllocations[memTypeIndex].Unregister(allocation);
    }
    else
    {

        parentPool->m_DedicatedAllocations.Unregister(allocation);
    }

    VkDeviceMemory hMemory = allocation->GetMemory();
# 14783 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
    FreeVulkanMemory(memTypeIndex, allocation->GetSize(), hMemory);

    m_Budget.RemoveAllocation(MemoryTypeIndexToHeapIndex(allocation->GetMemoryTypeIndex()), allocation->GetSize());
    allocation->Destroy(this);
    m_AllocationObjectAllocator.Free(allocation);

    ;
}

uint32_t VmaAllocator_T::CalculateGpuDefragmentationMemoryTypeBits() const
{
    VkBufferCreateInfo dummyBufCreateInfo;
    VmaFillGpuDefragmentationBufferCreateInfo(dummyBufCreateInfo);

    uint32_t memoryTypeBits = 0;


    VkBuffer buf = 
# 14800 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                  nullptr
# 14800 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                ;
    VkResult res = (*GetVulkanFunctions().vkCreateBuffer)(
        m_hDevice, &dummyBufCreateInfo, GetAllocationCallbacks(), &buf);
    if(res == VK_SUCCESS)
    {

        VkMemoryRequirements memReq;
        (*GetVulkanFunctions().vkGetBufferMemoryRequirements)(m_hDevice, buf, &memReq);
        memoryTypeBits = memReq.memoryTypeBits;


        (*GetVulkanFunctions().vkDestroyBuffer)(m_hDevice, buf, GetAllocationCallbacks());
    }

    return memoryTypeBits;
}

uint32_t VmaAllocator_T::CalculateGlobalMemoryTypeBits() const
{

    
# 14820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 14820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   GetMemoryTypeCount() > 0
# 14820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 14820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "GetMemoryTypeCount() > 0"
# 14820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14820),0))
# 14820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                       ;

    uint32_t memoryTypeBits = 
# 14822 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                             0xffffffffU
# 14822 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                       ;

    if(!m_UseAmdDeviceCoherentMemory)
    {

        for(uint32_t memTypeIndex = 0; memTypeIndex < GetMemoryTypeCount(); ++memTypeIndex)
        {
            if((m_MemProps.memoryTypes[memTypeIndex].propertyFlags & VK_MEMORY_PROPERTY_DEVICE_COHERENT_BIT_AMD_COPY) != 0)
            {
                memoryTypeBits &= ~(1u << memTypeIndex);
            }
        }
    }

    return memoryTypeBits;
}

bool VmaAllocator_T::GetFlushOrInvalidateRange(
    VmaAllocation allocation,
    VkDeviceSize offset, VkDeviceSize size,
    VkMappedMemoryRange& outRange) const
{
    const uint32_t memTypeIndex = allocation->GetMemoryTypeIndex();
    if(size > 0 && IsMemoryTypeNonCoherent(memTypeIndex))
    {
        const VkDeviceSize nonCoherentAtomSize = m_PhysicalDeviceProperties.limits.nonCoherentAtomSize;
        const VkDeviceSize allocationSize = allocation->GetSize();
        
# 14849 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 14849 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       offset <= allocationSize
# 14849 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 14849 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "offset <= allocationSize"
# 14849 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14849),0))
# 14849 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                           ;

        outRange.sType = VK_STRUCTURE_TYPE_MAPPED_MEMORY_RANGE;
        outRange.pNext = nullptr;
        outRange.memory = allocation->GetMemory();

        switch(allocation->GetType())
        {
        case VmaAllocation_T::ALLOCATION_TYPE_DEDICATED:
            outRange.offset = VmaAlignDown(offset, nonCoherentAtomSize);
            if(size == 
# 14859 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                      (~0ULL)
# 14859 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   )
            {
                outRange.size = allocationSize - outRange.offset;
            }
            else
            {
                
# 14865 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 14865 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               offset + size <= allocationSize
# 14865 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 14865 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "offset + size <= allocationSize"
# 14865 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14865),0))
# 14865 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                          ;
                outRange.size = ((std::min)((VmaAlignUp(size + (offset - outRange.offset), nonCoherentAtomSize)), (allocationSize - outRange.offset)))

                                                     ;
            }
            break;
        case VmaAllocation_T::ALLOCATION_TYPE_BLOCK:
        {

            outRange.offset = VmaAlignDown(offset, nonCoherentAtomSize);
            if(size == 
# 14875 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                      (~0ULL)
# 14875 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   )
            {
                size = allocationSize - offset;
            }
            else
            {
                
# 14881 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               (void) ((!!(
# 14881 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               offset + size <= allocationSize
# 14881 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               )) || (_assert(
# 14881 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
               "offset + size <= allocationSize"
# 14881 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
               ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14881),0))
# 14881 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                          ;
            }
            outRange.size = VmaAlignUp(size + (offset - outRange.offset), nonCoherentAtomSize);


            const VkDeviceSize allocationOffset = allocation->GetOffset();
            
# 14887 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 14887 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           allocationOffset % nonCoherentAtomSize == 0
# 14887 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 14887 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "allocationOffset % nonCoherentAtomSize == 0"
# 14887 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14887),0))
# 14887 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                  ;
            const VkDeviceSize blockSize = allocation->GetBlock()->m_pMetadata->GetSize();
            outRange.offset += allocationOffset;
            outRange.size = ((std::min)((outRange.size), (blockSize - outRange.offset)));

            break;
        }
        default:
            
# 14895 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 14895 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0
# 14895 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 14895 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0"
# 14895 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14895),0))
# 14895 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;
        }
        return true;
    }
    return false;
}


void VmaAllocator_T::UpdateVulkanBudget()
{
    
# 14905 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 14905 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   m_UseExtMemoryBudget
# 14905 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 14905 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "m_UseExtMemoryBudget"
# 14905 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14905),0))
# 14905 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   ;

    VkPhysicalDeviceMemoryProperties2KHR memProps = { VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MEMORY_PROPERTIES_2_KHR };

    VkPhysicalDeviceMemoryBudgetPropertiesEXT budgetProps = { VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MEMORY_BUDGET_PROPERTIES_EXT };
    VmaPnextChainPushFront(&memProps, &budgetProps);

    GetVulkanFunctions().vkGetPhysicalDeviceMemoryProperties2KHR(m_PhysicalDevice, &memProps);

    {
        VmaMutexLockWrite lockWrite(m_Budget.m_BudgetMutex, m_UseMutex);

        for(uint32_t heapIndex = 0; heapIndex < GetMemoryHeapCount(); ++heapIndex)
        {
            m_Budget.m_VulkanUsage[heapIndex] = budgetProps.heapUsage[heapIndex];
            m_Budget.m_VulkanBudget[heapIndex] = budgetProps.heapBudget[heapIndex];
            m_Budget.m_BlockBytesAtBudgetFetch[heapIndex] = m_Budget.m_BlockBytes[heapIndex].load();


            if(m_Budget.m_VulkanBudget[heapIndex] == 0)
            {
                m_Budget.m_VulkanBudget[heapIndex] = m_MemProps.memoryHeaps[heapIndex].size * 8 / 10;
            }
            else if(m_Budget.m_VulkanBudget[heapIndex] > m_MemProps.memoryHeaps[heapIndex].size)
            {
                m_Budget.m_VulkanBudget[heapIndex] = m_MemProps.memoryHeaps[heapIndex].size;
            }
            if(m_Budget.m_VulkanUsage[heapIndex] == 0 && m_Budget.m_BlockBytesAtBudgetFetch[heapIndex] > 0)
            {
                m_Budget.m_VulkanUsage[heapIndex] = m_Budget.m_BlockBytesAtBudgetFetch[heapIndex];
            }
        }
        m_Budget.m_OperationsSinceBudgetFetch = 0;
    }
}


void VmaAllocator_T::FillAllocation(const VmaAllocation hAllocation, uint8_t pattern)
{
    if((0) &&
        hAllocation->IsMappingAllowed() &&
        (m_MemProps.memoryTypes[hAllocation->GetMemoryTypeIndex()].propertyFlags & VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT) != 0)
    {
        void* pData = nullptr;
        VkResult res = Map(hAllocation, &pData);
        if(res == VK_SUCCESS)
        {
            memset(pData, (int)pattern, (size_t)hAllocation->GetSize());
            FlushOrInvalidateAllocation(hAllocation, 0, 
# 14953 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                       (~0ULL)
# 14953 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                    , VMA_CACHE_FLUSH);
            Unmap(hAllocation);
        }
        else
        {
            
# 14958 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           (void) ((!!(
# 14958 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           0 && "VMA_DEBUG_INITIALIZE_ALLOCATIONS is enabled, but couldn't map memory to fill allocation."
# 14958 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           )) || (_assert(
# 14958 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
           "0 && \"VMA_DEBUG_INITIALIZE_ALLOCATIONS is enabled, but couldn't map memory to fill allocation.\""
# 14958 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
           ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",14958),0))
# 14958 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                      ;
        }
    }
}

uint32_t VmaAllocator_T::GetGpuDefragmentationMemoryTypeBits()
{
    uint32_t memoryTypeBits = m_GpuDefragmentationMemoryTypeBits.load();
    if(memoryTypeBits == 
# 14966 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                        0xffffffffU
# 14966 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                  )
    {
        memoryTypeBits = CalculateGpuDefragmentationMemoryTypeBits();
        m_GpuDefragmentationMemoryTypeBits.store(memoryTypeBits);
    }
    return memoryTypeBits;
}


void VmaAllocator_T::PrintDetailedMap(VmaJsonWriter& json)
{
    json.WriteString("DefaultPools");
    json.BeginObject();
    {
        for (uint32_t memTypeIndex = 0; memTypeIndex < GetMemoryTypeCount(); ++memTypeIndex)
        {
            VmaBlockVector* pBlockVector = m_pBlockVectors[memTypeIndex];
            VmaDedicatedAllocationList& dedicatedAllocList = m_DedicatedAllocations[memTypeIndex];
            if (pBlockVector != nullptr)
            {
                json.BeginString("Type ");
                json.ContinueString(memTypeIndex);
                json.EndString();
                json.BeginObject();
                {
                    json.WriteString("PreferredBlockSize");
                    json.WriteNumber(pBlockVector->GetPreferredBlockSize());

                    json.WriteString("Blocks");
                    pBlockVector->PrintDetailedMap(json);

                    json.WriteString("DedicatedAllocations");
                    dedicatedAllocList.BuildStatsString(json);
                }
                json.EndObject();
            }
        }
    }
    json.EndObject();

    json.WriteString("CustomPools");
    json.BeginObject();
    {
        VmaMutexLockRead lock(m_PoolsMutex, m_UseMutex);
        if (!m_Pools.IsEmpty())
        {
            for (uint32_t memTypeIndex = 0; memTypeIndex < GetMemoryTypeCount(); ++memTypeIndex)
            {
                bool displayType = true;
                size_t index = 0;
                for (VmaPool pool = m_Pools.Front(); pool != nullptr; pool = m_Pools.GetNext(pool))
                {
                    VmaBlockVector& blockVector = pool->m_BlockVector;
                    if (blockVector.GetMemoryTypeIndex() == memTypeIndex)
                    {
                        if (displayType)
                        {
                            json.BeginString("Type ");
                            json.ContinueString(memTypeIndex);
                            json.EndString();
                            json.BeginArray();
                            displayType = false;
                        }

                        json.BeginObject();
                        {
                            json.WriteString("Name");
                            json.BeginString();
                            json.ContinueString((uint64_t)index++);
                            if (pool->GetName())
                            {
                                json.ContinueString(" - ");
                                json.ContinueString(pool->GetName());
                            }
                            json.EndString();

                            json.WriteString("PreferredBlockSize");
                            json.WriteNumber(blockVector.GetPreferredBlockSize());

                            json.WriteString("Blocks");
                            blockVector.PrintDetailedMap(json);

                            json.WriteString("DedicatedAllocations");
                            pool->m_DedicatedAllocations.BuildStatsString(json);
                        }
                        json.EndObject();
                    }
                }

                if (!displayType)
                    json.EndArray();
            }
        }
    }
    json.EndObject();
}





 VkResult vmaCreateAllocator(
    const VmaAllocatorCreateInfo* pCreateInfo,
    VmaAllocator* pAllocator)
{
    
# 15071 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15071 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pCreateInfo && pAllocator
# 15071 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15071 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pCreateInfo && pAllocator"
# 15071 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15071),0))
# 15071 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                        ;
    
# 15072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pCreateInfo->vulkanApiVersion == 0 || (
# 15072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   ((uint32_t)(
# 15072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pCreateInfo->vulkanApiVersion
# 15072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   ) >> 22U) 
# 15072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   == 1 && 
# 15072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   (((uint32_t)(
# 15072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pCreateInfo->vulkanApiVersion
# 15072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   ) >> 12U) & 0x3FFU) 
# 15072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   <= 4)
# 15072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pCreateInfo->vulkanApiVersion == 0 || (((uint32_t)(pCreateInfo->vulkanApiVersion) >> 22U) == 1 && (((uint32_t)(pCreateInfo->vulkanApiVersion) >> 12U) & 0x3FFU) <= 4)"
# 15072 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15072),0))
                                                                                                                       
# 15073 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                      ;
    ;
    *pAllocator = new(VmaAllocate<VmaAllocator_T>(pCreateInfo->pAllocationCallbacks))(VmaAllocator_T)(pCreateInfo);
    VkResult result = (*pAllocator)->Init(pCreateInfo);
    if(result < 0)
    {
        vma_delete(pCreateInfo->pAllocationCallbacks, *pAllocator);
        *pAllocator = 
# 15080 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                     nullptr
# 15080 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   ;
    }
    return result;
}

 void vmaDestroyAllocator(
    VmaAllocator allocator)
{
    if(allocator != 
# 15088 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                   nullptr
# 15088 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                 )
    {
        ;
        VkAllocationCallbacks allocationCallbacks = allocator->m_AllocationCallbacks;
        vma_delete(&allocationCallbacks, allocator);
    }
}

 void vmaGetAllocatorInfo(VmaAllocator allocator, VmaAllocatorInfo* pAllocatorInfo)
{
    
# 15098 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15098 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pAllocatorInfo
# 15098 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15098 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pAllocatorInfo"
# 15098 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15098),0))
# 15098 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                          ;
    pAllocatorInfo->instance = allocator->m_hInstance;
    pAllocatorInfo->physicalDevice = allocator->GetPhysicalDevice();
    pAllocatorInfo->device = allocator->m_hDevice;
}

 void vmaGetPhysicalDeviceProperties(
    VmaAllocator allocator,
    const VkPhysicalDeviceProperties **ppPhysicalDeviceProperties)
{
    
# 15108 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15108 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && ppPhysicalDeviceProperties
# 15108 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15108 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && ppPhysicalDeviceProperties"
# 15108 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15108),0))
# 15108 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                      ;
    *ppPhysicalDeviceProperties = &allocator->m_PhysicalDeviceProperties;
}

 void vmaGetMemoryProperties(
    VmaAllocator allocator,
    const VkPhysicalDeviceMemoryProperties** ppPhysicalDeviceMemoryProperties)
{
    
# 15116 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15116 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && ppPhysicalDeviceMemoryProperties
# 15116 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15116 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && ppPhysicalDeviceMemoryProperties"
# 15116 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15116),0))
# 15116 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                            ;
    *ppPhysicalDeviceMemoryProperties = &allocator->m_MemProps;
}

 void vmaGetMemoryTypeProperties(
    VmaAllocator allocator,
    uint32_t memoryTypeIndex,
    VkMemoryPropertyFlags* pFlags)
{
    
# 15125 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15125 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pFlags
# 15125 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15125 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pFlags"
# 15125 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15125),0))
# 15125 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                  ;
    
# 15126 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15126 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   memoryTypeIndex < allocator->GetMemoryTypeCount()
# 15126 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15126 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "memoryTypeIndex < allocator->GetMemoryTypeCount()"
# 15126 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15126),0))
# 15126 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                ;
    *pFlags = allocator->m_MemProps.memoryTypes[memoryTypeIndex].propertyFlags;
}

 void vmaSetCurrentFrameIndex(
    VmaAllocator allocator,
    uint32_t frameIndex)
{
    
# 15134 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15134 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator
# 15134 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15134 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator"
# 15134 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15134),0))
# 15134 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;

   

    allocator->SetCurrentFrameIndex(frameIndex);
}

 void vmaCalculateStatistics(
    VmaAllocator allocator,
    VmaTotalStatistics* pStats)
{
    
# 15145 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15145 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pStats
# 15145 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15145 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pStats"
# 15145 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15145),0))
# 15145 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                  ;
   
    allocator->CalculateStatistics(pStats);
}

 void vmaGetHeapBudgets(
    VmaAllocator allocator,
    VmaBudget* pBudgets)
{
    
# 15154 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15154 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pBudgets
# 15154 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15154 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pBudgets"
# 15154 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15154),0))
# 15154 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                    ;
   
    allocator->GetHeapBudgets(pBudgets, 0, allocator->GetMemoryHeapCount());
}



 void vmaBuildStatsString(
    VmaAllocator allocator,
    char** ppStatsString,
    VkBool32 detailedMap)
{
    
# 15166 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15166 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && ppStatsString
# 15166 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15166 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && ppStatsString"
# 15166 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15166),0))
# 15166 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                         ;
   

    VmaStringBuilder sb(allocator->GetAllocationCallbacks());
    {
        VmaBudget budgets[
# 15171 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                         16U
# 15171 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                            ];
        allocator->GetHeapBudgets(budgets, 0, allocator->GetMemoryHeapCount());

        VmaTotalStatistics stats;
        allocator->CalculateStatistics(&stats);

        VmaJsonWriter json(allocator->GetAllocationCallbacks(), sb);
        json.BeginObject();
        {
            json.WriteString("General");
            json.BeginObject();
            {
                const VkPhysicalDeviceProperties& deviceProperties = allocator->m_PhysicalDeviceProperties;
                const VkPhysicalDeviceMemoryProperties& memoryProperties = allocator->m_MemProps;

                json.WriteString("API");
                json.WriteString("Vulkan");

                json.WriteString("apiVersion");
                json.BeginString();
                json.ContinueString(
# 15191 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                   ((uint32_t)(
# 15191 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   deviceProperties.apiVersion
# 15191 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                   ) >> 22U)
# 15191 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                );
                json.ContinueString(".");
                json.ContinueString(
# 15193 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                   (((uint32_t)(
# 15193 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   deviceProperties.apiVersion
# 15193 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                   ) >> 12U) & 0x3FFU)
# 15193 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                );
                json.ContinueString(".");
                json.ContinueString(
# 15195 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                   ((uint32_t)(
# 15195 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   deviceProperties.apiVersion
# 15195 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                   ) & 0xFFFU)
# 15195 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                );
                json.EndString();

                json.WriteString("GPU");
                json.WriteString(deviceProperties.deviceName);
                json.WriteString("deviceType");
                json.WriteNumber(static_cast<uint32_t>(deviceProperties.deviceType));

                json.WriteString("maxMemoryAllocationCount");
                json.WriteNumber(deviceProperties.limits.maxMemoryAllocationCount);
                json.WriteString("bufferImageGranularity");
                json.WriteNumber(deviceProperties.limits.bufferImageGranularity);
                json.WriteString("nonCoherentAtomSize");
                json.WriteNumber(deviceProperties.limits.nonCoherentAtomSize);

                json.WriteString("memoryHeapCount");
                json.WriteNumber(memoryProperties.memoryHeapCount);
                json.WriteString("memoryTypeCount");
                json.WriteNumber(memoryProperties.memoryTypeCount);
            }
            json.EndObject();
        }
        {
            json.WriteString("Total");
            VmaPrintDetailedStatistics(json, stats.total);
        }
        {
            json.WriteString("MemoryInfo");
            json.BeginObject();
            {
                for (uint32_t heapIndex = 0; heapIndex < allocator->GetMemoryHeapCount(); ++heapIndex)
                {
                    json.BeginString("Heap ");
                    json.ContinueString(heapIndex);
                    json.EndString();
                    json.BeginObject();
                    {
                        const VkMemoryHeap& heapInfo = allocator->m_MemProps.memoryHeaps[heapIndex];
                        json.WriteString("Flags");
                        json.BeginArray(true);
                        {
                            if (heapInfo.flags & VK_MEMORY_HEAP_DEVICE_LOCAL_BIT)
                                json.WriteString("DEVICE_LOCAL");

                            if (heapInfo.flags & VK_MEMORY_HEAP_MULTI_INSTANCE_BIT)
                                json.WriteString("MULTI_INSTANCE");


                            VkMemoryHeapFlags flags = heapInfo.flags &
                                ~(VK_MEMORY_HEAP_DEVICE_LOCAL_BIT

                                    | VK_MEMORY_HEAP_MULTI_INSTANCE_BIT

                                    );
                            if (flags != 0)
                                json.WriteNumber(flags);
                        }
                        json.EndArray();

                        json.WriteString("Size");
                        json.WriteNumber(heapInfo.size);

                        json.WriteString("Budget");
                        json.BeginObject();
                        {
                            json.WriteString("BudgetBytes");
                            json.WriteNumber(budgets[heapIndex].budget);
                            json.WriteString("UsageBytes");
                            json.WriteNumber(budgets[heapIndex].usage);
                        }
                        json.EndObject();

                        json.WriteString("Stats");
                        VmaPrintDetailedStatistics(json, stats.memoryHeap[heapIndex]);

                        json.WriteString("MemoryPools");
                        json.BeginObject();
                        {
                            for (uint32_t typeIndex = 0; typeIndex < allocator->GetMemoryTypeCount(); ++typeIndex)
                            {
                                if (allocator->MemoryTypeIndexToHeapIndex(typeIndex) == heapIndex)
                                {
                                    json.BeginString("Type ");
                                    json.ContinueString(typeIndex);
                                    json.EndString();
                                    json.BeginObject();
                                    {
                                        json.WriteString("Flags");
                                        json.BeginArray(true);
                                        {
                                            VkMemoryPropertyFlags flags = allocator->m_MemProps.memoryTypes[typeIndex].propertyFlags;
                                            if (flags & VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT)
                                                json.WriteString("DEVICE_LOCAL");
                                            if (flags & VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT)
                                                json.WriteString("HOST_VISIBLE");
                                            if (flags & VK_MEMORY_PROPERTY_HOST_COHERENT_BIT)
                                                json.WriteString("HOST_COHERENT");
                                            if (flags & VK_MEMORY_PROPERTY_HOST_CACHED_BIT)
                                                json.WriteString("HOST_CACHED");
                                            if (flags & VK_MEMORY_PROPERTY_LAZILY_ALLOCATED_BIT)
                                                json.WriteString("LAZILY_ALLOCATED");

                                            if (flags & VK_MEMORY_PROPERTY_PROTECTED_BIT)
                                                json.WriteString("PROTECTED");


                                            if (flags & VK_MEMORY_PROPERTY_DEVICE_COHERENT_BIT_AMD_COPY)
                                                json.WriteString("DEVICE_COHERENT_AMD");
                                            if (flags & VK_MEMORY_PROPERTY_DEVICE_UNCACHED_BIT_AMD_COPY)
                                                json.WriteString("DEVICE_UNCACHED_AMD");


                                            flags &= ~(VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT

                                                | VK_MEMORY_PROPERTY_LAZILY_ALLOCATED_BIT


                                                | VK_MEMORY_PROPERTY_DEVICE_COHERENT_BIT_AMD_COPY
                                                | VK_MEMORY_PROPERTY_DEVICE_UNCACHED_BIT_AMD_COPY

                                                | VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT
                                                | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT
                                                | VK_MEMORY_PROPERTY_HOST_CACHED_BIT);
                                            if (flags != 0)
                                                json.WriteNumber(flags);
                                        }
                                        json.EndArray();

                                        json.WriteString("Stats");
                                        VmaPrintDetailedStatistics(json, stats.memoryType[typeIndex]);
                                    }
                                    json.EndObject();
                                }
                            }

                        }
                        json.EndObject();
                    }
                    json.EndObject();
                }
            }
            json.EndObject();
        }

        if (detailedMap == 
# 15339 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                          1U
# 15339 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                 )
            allocator->PrintDetailedMap(json);

        json.EndObject();
    }

    *ppStatsString = VmaCreateStringCopy(allocator->GetAllocationCallbacks(), sb.GetData(), sb.GetLength());
}

 void vmaFreeStatsString(
    VmaAllocator allocator,
    char* pStatsString)
{
    if(pStatsString != nullptr)
    {
        
# 15354 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 15354 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       allocator
# 15354 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 15354 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "allocator"
# 15354 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15354),0))
# 15354 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            ;
        VmaFreeString(allocator->GetAllocationCallbacks(), pStatsString);
    }
}






 VkResult vmaFindMemoryTypeIndex(
    VmaAllocator allocator,
    uint32_t memoryTypeBits,
    const VmaAllocationCreateInfo* pAllocationCreateInfo,
    uint32_t* pMemoryTypeIndex)
{
    
# 15370 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15370 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator != 
# 15370 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   nullptr)) || (_assert(
# 15370 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator != nullptr"
# 15370 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15370),0))
# 15370 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                          ;
    
# 15371 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15371 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pAllocationCreateInfo != nullptr
# 15371 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15371 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pAllocationCreateInfo != nullptr"
# 15371 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15371),0))
# 15371 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                ;
    
# 15372 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15372 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pMemoryTypeIndex != nullptr
# 15372 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15372 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pMemoryTypeIndex != nullptr"
# 15372 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15372),0))
# 15372 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                           ;

    return allocator->FindMemoryTypeIndex(memoryTypeBits, pAllocationCreateInfo, VmaBufferImageUsage::UNKNOWN, pMemoryTypeIndex);
}

 VkResult vmaFindMemoryTypeIndexForBufferInfo(
    VmaAllocator allocator,
    const VkBufferCreateInfo* pBufferCreateInfo,
    const VmaAllocationCreateInfo* pAllocationCreateInfo,
    uint32_t* pMemoryTypeIndex)
{
    
# 15383 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15383 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator != 
# 15383 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   nullptr)) || (_assert(
# 15383 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator != nullptr"
# 15383 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15383),0))
# 15383 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                          ;
    
# 15384 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15384 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pBufferCreateInfo != nullptr
# 15384 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15384 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pBufferCreateInfo != nullptr"
# 15384 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15384),0))
# 15384 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                            ;
    
# 15385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pAllocationCreateInfo != nullptr
# 15385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pAllocationCreateInfo != nullptr"
# 15385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15385),0))
# 15385 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                ;
    
# 15386 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15386 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pMemoryTypeIndex != nullptr
# 15386 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15386 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pMemoryTypeIndex != nullptr"
# 15386 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15386),0))
# 15386 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                           ;

    const VkDevice hDev = allocator->m_hDevice;
    const VmaVulkanFunctions* funcs = &allocator->GetVulkanFunctions();
    VkResult res;


    if(funcs->vkGetDeviceBufferMemoryRequirements)
    {

        VkDeviceBufferMemoryRequirementsKHR devBufMemReq = {VK_STRUCTURE_TYPE_DEVICE_BUFFER_MEMORY_REQUIREMENTS_KHR};
        devBufMemReq.pCreateInfo = pBufferCreateInfo;

        VkMemoryRequirements2 memReq = {VK_STRUCTURE_TYPE_MEMORY_REQUIREMENTS_2};
        (*funcs->vkGetDeviceBufferMemoryRequirements)(hDev, &devBufMemReq, &memReq);

        res = allocator->FindMemoryTypeIndex(
            memReq.memoryRequirements.memoryTypeBits, pAllocationCreateInfo,
            VmaBufferImageUsage(*pBufferCreateInfo, allocator->m_UseKhrMaintenance5), pMemoryTypeIndex);
    }
    else

    {

        VkBuffer hBuffer = 
# 15410 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                          nullptr
# 15410 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                        ;
        res = funcs->vkCreateBuffer(
            hDev, pBufferCreateInfo, allocator->GetAllocationCallbacks(), &hBuffer);
        if(res == VK_SUCCESS)
        {
            VkMemoryRequirements memReq = {};
            funcs->vkGetBufferMemoryRequirements(hDev, hBuffer, &memReq);

            res = allocator->FindMemoryTypeIndex(
                memReq.memoryTypeBits, pAllocationCreateInfo,
                VmaBufferImageUsage(*pBufferCreateInfo, allocator->m_UseKhrMaintenance5), pMemoryTypeIndex);

            funcs->vkDestroyBuffer(
                hDev, hBuffer, allocator->GetAllocationCallbacks());
        }
    }
    return res;
}

 VkResult vmaFindMemoryTypeIndexForImageInfo(
    VmaAllocator allocator,
    const VkImageCreateInfo* pImageCreateInfo,
    const VmaAllocationCreateInfo* pAllocationCreateInfo,
    uint32_t* pMemoryTypeIndex)
{
    
# 15435 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15435 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator != 
# 15435 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   nullptr)) || (_assert(
# 15435 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator != nullptr"
# 15435 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15435),0))
# 15435 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                          ;
    
# 15436 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15436 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pImageCreateInfo != nullptr
# 15436 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15436 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pImageCreateInfo != nullptr"
# 15436 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15436),0))
# 15436 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                           ;
    
# 15437 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15437 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pAllocationCreateInfo != nullptr
# 15437 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15437 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pAllocationCreateInfo != nullptr"
# 15437 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15437),0))
# 15437 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                ;
    
# 15438 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15438 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pMemoryTypeIndex != nullptr
# 15438 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15438 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pMemoryTypeIndex != nullptr"
# 15438 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15438),0))
# 15438 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                           ;

    const VkDevice hDev = allocator->m_hDevice;
    const VmaVulkanFunctions* funcs = &allocator->GetVulkanFunctions();
    VkResult res;


    if(funcs->vkGetDeviceImageMemoryRequirements)
    {

        VkDeviceImageMemoryRequirementsKHR devImgMemReq = {VK_STRUCTURE_TYPE_DEVICE_IMAGE_MEMORY_REQUIREMENTS_KHR};
        devImgMemReq.pCreateInfo = pImageCreateInfo;
        
# 15450 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 15450 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       pImageCreateInfo->tiling != VK_IMAGE_TILING_DRM_FORMAT_MODIFIER_EXT_COPY && (pImageCreateInfo->flags & VK_IMAGE_CREATE_DISJOINT_BIT_COPY) == 0 && "Cannot use this VkImageCreateInfo with vmaFindMemoryTypeIndexForImageInfo as I don't know what to pass as VkDeviceImageMemoryRequirements::planeAspect."
# 15450 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 15450 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "pImageCreateInfo->tiling != VK_IMAGE_TILING_DRM_FORMAT_MODIFIER_EXT_COPY && (pImageCreateInfo->flags & VK_IMAGE_CREATE_DISJOINT_BIT_COPY) == 0 && \"Cannot use this VkImageCreateInfo with vmaFindMemoryTypeIndexForImageInfo as I don't know what to pass as VkDeviceImageMemoryRequirements::planeAspect.\""
# 15450 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15450),0))
                                                                                                                                                                      
# 15451 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                                                     ;

        VkMemoryRequirements2 memReq = {VK_STRUCTURE_TYPE_MEMORY_REQUIREMENTS_2};
        (*funcs->vkGetDeviceImageMemoryRequirements)(hDev, &devImgMemReq, &memReq);

        res = allocator->FindMemoryTypeIndex(
            memReq.memoryRequirements.memoryTypeBits, pAllocationCreateInfo,
            VmaBufferImageUsage(*pImageCreateInfo), pMemoryTypeIndex);
    }
    else

    {

        VkImage hImage = 
# 15464 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                        nullptr
# 15464 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                      ;
        res = funcs->vkCreateImage(
            hDev, pImageCreateInfo, allocator->GetAllocationCallbacks(), &hImage);
        if(res == VK_SUCCESS)
        {
            VkMemoryRequirements memReq = {};
            funcs->vkGetImageMemoryRequirements(hDev, hImage, &memReq);

            res = allocator->FindMemoryTypeIndex(
                memReq.memoryTypeBits, pAllocationCreateInfo,
                VmaBufferImageUsage(*pImageCreateInfo), pMemoryTypeIndex);

            funcs->vkDestroyImage(
                hDev, hImage, allocator->GetAllocationCallbacks());
        }
    }
    return res;
}

 VkResult vmaCreatePool(
    VmaAllocator allocator,
    const VmaPoolCreateInfo* pCreateInfo,
    VmaPool* pPool)
{
    
# 15488 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15488 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pCreateInfo && pPool
# 15488 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15488 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pCreateInfo && pPool"
# 15488 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15488),0))
# 15488 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                ;

    ;

   

    return allocator->CreatePool(pCreateInfo, pPool);
}

 void vmaDestroyPool(
    VmaAllocator allocator,
    VmaPool pool)
{
    
# 15501 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15501 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator
# 15501 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15501 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator"
# 15501 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15501),0))
# 15501 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;

    if(pool == 
# 15503 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
              nullptr
# 15503 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            )
    {
        return;
    }

    ;

   

    allocator->DestroyPool(pool);
}

 void vmaGetPoolStatistics(
    VmaAllocator allocator,
    VmaPool pool,
    VmaStatistics* pPoolStats)
{
    
# 15520 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15520 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pool && pPoolStats
# 15520 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15520 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pool && pPoolStats"
# 15520 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15520),0))
# 15520 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                              ;

   

    allocator->GetPoolStatistics(pool, pPoolStats);
}

 void vmaCalculatePoolStatistics(
    VmaAllocator allocator,
    VmaPool pool,
    VmaDetailedStatistics* pPoolStats)
{
    
# 15532 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15532 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pool && pPoolStats
# 15532 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15532 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pool && pPoolStats"
# 15532 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15532),0))
# 15532 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                              ;

   

    allocator->CalculatePoolStatistics(pool, pPoolStats);
}

 VkResult vmaCheckPoolCorruption(VmaAllocator allocator, VmaPool pool)
{
    
# 15541 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15541 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pool
# 15541 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15541 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pool"
# 15541 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15541),0))
# 15541 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                ;

   

    ;

    return allocator->CheckPoolCorruption(pool);
}

 void vmaGetPoolName(
    VmaAllocator allocator,
    VmaPool pool,
    const char** ppName)
{
    
# 15555 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15555 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pool && ppName
# 15555 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15555 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pool && ppName"
# 15555 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15555),0))
# 15555 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                          ;

    ;

   

    *ppName = pool->GetName();
}

 void vmaSetPoolName(
    VmaAllocator allocator,
    VmaPool pool,
    const char* pName)
{
    
# 15569 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15569 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pool
# 15569 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15569 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pool"
# 15569 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15569),0))
# 15569 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                ;

    ;

   

    pool->SetName(pName);
}

 VkResult vmaAllocateMemory(
    VmaAllocator allocator,
    const VkMemoryRequirements* pVkMemoryRequirements,
    const VmaAllocationCreateInfo* pCreateInfo,
    VmaAllocation* pAllocation,
    VmaAllocationInfo* pAllocationInfo)
{
    
# 15585 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15585 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pVkMemoryRequirements && pCreateInfo && pAllocation
# 15585 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15585 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pVkMemoryRequirements && pCreateInfo && pAllocation"
# 15585 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15585),0))
# 15585 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                               ;

    ;

   

    VkResult result = allocator->AllocateMemory(
        *pVkMemoryRequirements,
        false,
        false,
        
# 15595 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
       nullptr
# 15595 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                     ,
        
# 15596 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
       nullptr
# 15596 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                     ,
        VmaBufferImageUsage::UNKNOWN,
        *pCreateInfo,
        VMA_SUBALLOCATION_TYPE_UNKNOWN,
        1,
        pAllocation);

    if(pAllocationInfo != nullptr && result == VK_SUCCESS)
    {
        allocator->GetAllocationInfo(*pAllocation, pAllocationInfo);
    }

    return result;
}

 VkResult vmaAllocateMemoryPages(
    VmaAllocator allocator,
    const VkMemoryRequirements* pVkMemoryRequirements,
    const VmaAllocationCreateInfo* pCreateInfo,
    size_t allocationCount,
    VmaAllocation* pAllocations,
    VmaAllocationInfo* pAllocationInfo)
{
    if(allocationCount == 0)
    {
        return VK_SUCCESS;
    }

    
# 15624 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15624 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pVkMemoryRequirements && pCreateInfo && pAllocations
# 15624 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15624 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pVkMemoryRequirements && pCreateInfo && pAllocations"
# 15624 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15624),0))
# 15624 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                ;

    ;

   

    VkResult result = allocator->AllocateMemory(
        *pVkMemoryRequirements,
        false,
        false,
        
# 15634 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
       nullptr
# 15634 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                     ,
        
# 15635 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
       nullptr
# 15635 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                     ,
        VmaBufferImageUsage::UNKNOWN,
        *pCreateInfo,
        VMA_SUBALLOCATION_TYPE_UNKNOWN,
        allocationCount,
        pAllocations);

    if(pAllocationInfo != nullptr && result == VK_SUCCESS)
    {
        for(size_t i = 0; i < allocationCount; ++i)
        {
            allocator->GetAllocationInfo(pAllocations[i], pAllocationInfo + i);
        }
    }

    return result;
}

 VkResult vmaAllocateMemoryForBuffer(
    VmaAllocator allocator,
    VkBuffer buffer,
    const VmaAllocationCreateInfo* pCreateInfo,
    VmaAllocation* pAllocation,
    VmaAllocationInfo* pAllocationInfo)
{
    
# 15660 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15660 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && buffer != 
# 15660 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   nullptr 
# 15660 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   && pCreateInfo && pAllocation
# 15660 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15660 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && buffer != nullptr && pCreateInfo && pAllocation"
# 15660 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15660),0))
# 15660 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                  ;

    ;

   

    VkMemoryRequirements vkMemReq = {};
    bool requiresDedicatedAllocation = false;
    bool prefersDedicatedAllocation = false;
    allocator->GetBufferMemoryRequirements(buffer, vkMemReq,
        requiresDedicatedAllocation,
        prefersDedicatedAllocation);

    VkResult result = allocator->AllocateMemory(
        vkMemReq,
        requiresDedicatedAllocation,
        prefersDedicatedAllocation,
        buffer,
        
# 15678 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
       nullptr
# 15678 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                     ,
        VmaBufferImageUsage::UNKNOWN,
        *pCreateInfo,
        VMA_SUBALLOCATION_TYPE_BUFFER,
        1,
        pAllocation);

    if(pAllocationInfo && result == VK_SUCCESS)
    {
        allocator->GetAllocationInfo(*pAllocation, pAllocationInfo);
    }

    return result;
}

 VkResult vmaAllocateMemoryForImage(
    VmaAllocator allocator,
    VkImage image,
    const VmaAllocationCreateInfo* pCreateInfo,
    VmaAllocation* pAllocation,
    VmaAllocationInfo* pAllocationInfo)
{
    
# 15700 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15700 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && image != 
# 15700 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   nullptr 
# 15700 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   && pCreateInfo && pAllocation
# 15700 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15700 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && image != nullptr && pCreateInfo && pAllocation"
# 15700 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15700),0))
# 15700 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                 ;

    ;

   

    VkMemoryRequirements vkMemReq = {};
    bool requiresDedicatedAllocation = false;
    bool prefersDedicatedAllocation = false;
    allocator->GetImageMemoryRequirements(image, vkMemReq,
        requiresDedicatedAllocation, prefersDedicatedAllocation);

    VkResult result = allocator->AllocateMemory(
        vkMemReq,
        requiresDedicatedAllocation,
        prefersDedicatedAllocation,
        
# 15716 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
       nullptr
# 15716 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                     ,
        image,
        VmaBufferImageUsage::UNKNOWN,
        *pCreateInfo,
        VMA_SUBALLOCATION_TYPE_IMAGE_UNKNOWN,
        1,
        pAllocation);

    if(pAllocationInfo && result == VK_SUCCESS)
    {
        allocator->GetAllocationInfo(*pAllocation, pAllocationInfo);
    }

    return result;
}

 void vmaFreeMemory(
    VmaAllocator allocator,
    VmaAllocation allocation)
{
    
# 15736 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15736 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator
# 15736 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15736 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator"
# 15736 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15736),0))
# 15736 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;

    if(allocation == 
# 15738 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                    nullptr
# 15738 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                  )
    {
        return;
    }

    ;

   

    allocator->FreeMemory(
        1,
        &allocation);
}

 void vmaFreeMemoryPages(
    VmaAllocator allocator,
    size_t allocationCount,
    const VmaAllocation* pAllocations)
{
    if(allocationCount == 0)
    {
        return;
    }

    
# 15762 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15762 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator
# 15762 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15762 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator"
# 15762 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15762),0))
# 15762 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;

    ;

   

    allocator->FreeMemory(allocationCount, pAllocations);
}

 void vmaGetAllocationInfo(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VmaAllocationInfo* pAllocationInfo)
{
    
# 15776 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15776 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && allocation && pAllocationInfo
# 15776 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15776 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && allocation && pAllocationInfo"
# 15776 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15776),0))
# 15776 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                         ;

   

    allocator->GetAllocationInfo(allocation, pAllocationInfo);
}

 void vmaGetAllocationInfo2(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VmaAllocationInfo2* pAllocationInfo)
{
    
# 15788 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15788 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && allocation && pAllocationInfo
# 15788 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15788 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && allocation && pAllocationInfo"
# 15788 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15788),0))
# 15788 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                         ;

   

    allocator->GetAllocationInfo2(allocation, pAllocationInfo);
}

 void vmaSetAllocationUserData(
    VmaAllocator allocator,
    VmaAllocation allocation,
    void* pUserData)
{
    
# 15800 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15800 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && allocation
# 15800 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15800 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && allocation"
# 15800 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15800),0))
# 15800 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                      ;

   

    allocation->SetUserData(allocator, pUserData);
}

 void vmaSetAllocationName(
    VmaAllocator allocator,
    VmaAllocation allocation,
    const char* pName)
{
    allocation->SetName(allocator, pName);
}

 void vmaGetAllocationMemoryProperties(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VkMemoryPropertyFlags* pFlags)
{
    
# 15820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && allocation && pFlags
# 15820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && allocation && pFlags"
# 15820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15820),0))
# 15820 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                ;
    const uint32_t memTypeIndex = allocation->GetMemoryTypeIndex();
    *pFlags = allocator->m_MemProps.memoryTypes[memTypeIndex].propertyFlags;
}

 VkResult vmaMapMemory(
    VmaAllocator allocator,
    VmaAllocation allocation,
    void** ppData)
{
    
# 15830 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15830 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && allocation && ppData
# 15830 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15830 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && allocation && ppData"
# 15830 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15830),0))
# 15830 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                ;

   

    return allocator->Map(allocation, ppData);
}

 void vmaUnmapMemory(
    VmaAllocator allocator,
    VmaAllocation allocation)
{
    
# 15841 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15841 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && allocation
# 15841 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15841 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && allocation"
# 15841 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15841),0))
# 15841 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                      ;

   

    allocator->Unmap(allocation);
}

 VkResult vmaFlushAllocation(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VkDeviceSize offset,
    VkDeviceSize size)
{
    
# 15854 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15854 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && allocation
# 15854 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15854 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && allocation"
# 15854 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15854),0))
# 15854 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                      ;

    ;

   

    return allocator->FlushOrInvalidateAllocation(allocation, offset, size, VMA_CACHE_FLUSH);
}

 VkResult vmaInvalidateAllocation(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VkDeviceSize offset,
    VkDeviceSize size)
{
    
# 15869 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15869 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && allocation
# 15869 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15869 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && allocation"
# 15869 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15869),0))
# 15869 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                      ;

    ;

   

    return allocator->FlushOrInvalidateAllocation(allocation, offset, size, VMA_CACHE_INVALIDATE);
}

 VkResult vmaFlushAllocations(
    VmaAllocator allocator,
    uint32_t allocationCount,
    const VmaAllocation* allocations,
    const VkDeviceSize* offsets,
    const VkDeviceSize* sizes)
{
    
# 15885 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15885 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator
# 15885 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15885 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator"
# 15885 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15885),0))
# 15885 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;

    if(allocationCount == 0)
    {
        return VK_SUCCESS;
    }

    
# 15892 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15892 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocations
# 15892 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15892 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocations"
# 15892 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15892),0))
# 15892 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                          ;

    ;

   

    return allocator->FlushOrInvalidateAllocations(allocationCount, allocations, offsets, sizes, VMA_CACHE_FLUSH);
}

 VkResult vmaInvalidateAllocations(
    VmaAllocator allocator,
    uint32_t allocationCount,
    const VmaAllocation* allocations,
    const VkDeviceSize* offsets,
    const VkDeviceSize* sizes)
{
    
# 15908 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15908 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator
# 15908 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15908 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator"
# 15908 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15908),0))
# 15908 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;

    if(allocationCount == 0)
    {
        return VK_SUCCESS;
    }

    
# 15915 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15915 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocations
# 15915 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15915 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocations"
# 15915 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15915),0))
# 15915 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                          ;

    ;

   

    return allocator->FlushOrInvalidateAllocations(allocationCount, allocations, offsets, sizes, VMA_CACHE_INVALIDATE);
}

 VkResult vmaCopyMemoryToAllocation(
    VmaAllocator allocator,
    const void* pSrcHostPointer,
    VmaAllocation dstAllocation,
    VkDeviceSize dstAllocationLocalOffset,
    VkDeviceSize size)
{
    
# 15931 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15931 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pSrcHostPointer && dstAllocation
# 15931 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15931 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pSrcHostPointer && dstAllocation"
# 15931 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15931),0))
# 15931 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                            ;

    if(size == 0)
    {
        return VK_SUCCESS;
    }

    ;

   

    return allocator->CopyMemoryToAllocation(pSrcHostPointer, dstAllocation, dstAllocationLocalOffset, size);
}

 VkResult vmaCopyAllocationToMemory(
    VmaAllocator allocator,
    VmaAllocation srcAllocation,
    VkDeviceSize srcAllocationLocalOffset,
    void* pDstHostPointer,
    VkDeviceSize size)
{
    
# 15952 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15952 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && srcAllocation && pDstHostPointer
# 15952 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15952 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && srcAllocation && pDstHostPointer"
# 15952 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15952),0))
# 15952 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                            ;

    if(size == 0)
    {
        return VK_SUCCESS;
    }

    ;

   

    return allocator->CopyAllocationToMemory(srcAllocation, srcAllocationLocalOffset, pDstHostPointer, size);
}

 VkResult vmaCheckCorruption(
    VmaAllocator allocator,
    uint32_t memoryTypeBits)
{
    
# 15970 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15970 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator
# 15970 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15970 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator"
# 15970 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15970),0))
# 15970 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;

    ;

   

    return allocator->CheckCorruption(memoryTypeBits);
}

 VkResult vmaBeginDefragmentation(
    VmaAllocator allocator,
    const VmaDefragmentationInfo* pInfo,
    VmaDefragmentationContext* pContext)
{
    
# 15984 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 15984 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pInfo && pContext
# 15984 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 15984 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pInfo && pContext"
# 15984 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",15984),0))
# 15984 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                             ;

    ;

    if (pInfo->pool != nullptr)
    {

        if (pInfo->pool->m_BlockVector.GetAlgorithm() & VMA_POOL_CREATE_LINEAR_ALGORITHM_BIT)
            return VK_ERROR_FEATURE_NOT_PRESENT;
    }

   

    *pContext = new(VmaAllocate<VmaDefragmentationContext_T>(allocator))(VmaDefragmentationContext_T)(allocator, *pInfo);
    return VK_SUCCESS;
}

 void vmaEndDefragmentation(
    VmaAllocator allocator,
    VmaDefragmentationContext context,
    VmaDefragmentationStats* pStats)
{
    
# 16006 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16006 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && context
# 16006 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16006 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && context"
# 16006 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16006),0))
# 16006 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   ;

    ;

   

    if (pStats)
        context->GetStats(*pStats);
    vma_delete(allocator, context);
}

 VkResult vmaBeginDefragmentationPass(
    VmaAllocator allocator,
    VmaDefragmentationContext context,
    VmaDefragmentationPassMoveInfo* pPassInfo)
{
    
# 16022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   context && pPassInfo
# 16022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "context && pPassInfo"
# 16022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16022),0))
# 16022 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   ;

    ;

   

    return context->DefragmentPassBegin(*pPassInfo);
}

 VkResult vmaEndDefragmentationPass(
    VmaAllocator allocator,
    VmaDefragmentationContext context,
    VmaDefragmentationPassMoveInfo* pPassInfo)
{
    
# 16036 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16036 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   context && pPassInfo
# 16036 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16036 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "context && pPassInfo"
# 16036 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16036),0))
# 16036 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   ;

    ;

   

    return context->DefragmentPassEnd(*pPassInfo);
}

 VkResult vmaBindBufferMemory(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VkBuffer buffer)
{
    
# 16050 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16050 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && allocation && buffer
# 16050 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16050 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && allocation && buffer"
# 16050 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16050),0))
# 16050 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                ;

    ;

   

    return allocator->BindBufferMemory(allocation, 0, buffer, nullptr);
}

 VkResult vmaBindBufferMemory2(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VkDeviceSize allocationLocalOffset,
    VkBuffer buffer,
    const void* pNext)
{
    
# 16066 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16066 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && allocation && buffer
# 16066 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16066 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && allocation && buffer"
# 16066 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16066),0))
# 16066 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                ;

    ;

   

    return allocator->BindBufferMemory(allocation, allocationLocalOffset, buffer, pNext);
}

 VkResult vmaBindImageMemory(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VkImage image)
{
    
# 16080 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16080 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && allocation && image
# 16080 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16080 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && allocation && image"
# 16080 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16080),0))
# 16080 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                               ;

    ;

   

    return allocator->BindImageMemory(allocation, 0, image, nullptr);
}

 VkResult vmaBindImageMemory2(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VkDeviceSize allocationLocalOffset,
    VkImage image,
    const void* pNext)
{
    
# 16096 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16096 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && allocation && image
# 16096 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16096 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && allocation && image"
# 16096 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16096),0))
# 16096 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                               ;

    ;

   

        return allocator->BindImageMemory(allocation, allocationLocalOffset, image, pNext);
}

 VkResult vmaCreateBuffer(
    VmaAllocator allocator,
    const VkBufferCreateInfo* pBufferCreateInfo,
    const VmaAllocationCreateInfo* pAllocationCreateInfo,
    VkBuffer* pBuffer,
    VmaAllocation* pAllocation,
    VmaAllocationInfo* pAllocationInfo)
{
    
# 16113 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16113 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pBufferCreateInfo && pAllocationCreateInfo && pBuffer && pAllocation
# 16113 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16113 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pBufferCreateInfo && pAllocationCreateInfo && pBuffer && pAllocation"
# 16113 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16113),0))
# 16113 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                ;

    if(pBufferCreateInfo->size == 0)
    {
        return VK_ERROR_INITIALIZATION_FAILED;
    }
    if((pBufferCreateInfo->usage & VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT_COPY) != 0 &&
        !allocator->m_UseKhrBufferDeviceAddress)
    {
        
# 16122 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 16122 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Creating a buffer with VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT is not valid if VMA_ALLOCATOR_CREATE_BUFFER_DEVICE_ADDRESS_BIT was not used."
# 16122 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 16122 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Creating a buffer with VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT is not valid if VMA_ALLOCATOR_CREATE_BUFFER_DEVICE_ADDRESS_BIT was not used.\""
# 16122 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16122),0))
# 16122 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                                                       ;
        return VK_ERROR_INITIALIZATION_FAILED;
    }

    ;

   

    *pBuffer = 
# 16130 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
              nullptr
# 16130 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            ;
    *pAllocation = 
# 16131 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                  nullptr
# 16131 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                ;


    VkResult res = (*allocator->GetVulkanFunctions().vkCreateBuffer)(
        allocator->m_hDevice,
        pBufferCreateInfo,
        allocator->GetAllocationCallbacks(),
        pBuffer);
    if(res >= 0)
    {

        VkMemoryRequirements vkMemReq = {};
        bool requiresDedicatedAllocation = false;
        bool prefersDedicatedAllocation = false;
        allocator->GetBufferMemoryRequirements(*pBuffer, vkMemReq,
            requiresDedicatedAllocation, prefersDedicatedAllocation);


        res = allocator->AllocateMemory(
            vkMemReq,
            requiresDedicatedAllocation,
            prefersDedicatedAllocation,
            *pBuffer,
            
# 16154 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
           nullptr
# 16154 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                         ,
            VmaBufferImageUsage(*pBufferCreateInfo, allocator->m_UseKhrMaintenance5),
            *pAllocationCreateInfo,
            VMA_SUBALLOCATION_TYPE_BUFFER,
            1,
            pAllocation);

        if(res >= 0)
        {

            if((pAllocationCreateInfo->flags & VMA_ALLOCATION_CREATE_DONT_BIND_BIT) == 0)
            {
                res = allocator->BindBufferMemory(*pAllocation, 0, *pBuffer, nullptr);
            }
            if(res >= 0)
            {


                    (*pAllocation)->InitBufferUsage(*pBufferCreateInfo, allocator->m_UseKhrMaintenance5);

                if(pAllocationInfo != nullptr)
                {
                    allocator->GetAllocationInfo(*pAllocation, pAllocationInfo);
                }

                return VK_SUCCESS;
            }
            allocator->FreeMemory(
                1,
                pAllocation);
            *pAllocation = 
# 16184 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                          nullptr
# 16184 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                        ;
            (*allocator->GetVulkanFunctions().vkDestroyBuffer)(allocator->m_hDevice, *pBuffer, allocator->GetAllocationCallbacks());
            *pBuffer = 
# 16186 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                      nullptr
# 16186 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                    ;
            return res;
        }
        (*allocator->GetVulkanFunctions().vkDestroyBuffer)(allocator->m_hDevice, *pBuffer, allocator->GetAllocationCallbacks());
        *pBuffer = 
# 16190 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                  nullptr
# 16190 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                ;
        return res;
    }
    return res;
}

 VkResult vmaCreateBufferWithAlignment(
    VmaAllocator allocator,
    const VkBufferCreateInfo* pBufferCreateInfo,
    const VmaAllocationCreateInfo* pAllocationCreateInfo,
    VkDeviceSize minAlignment,
    VkBuffer* pBuffer,
    VmaAllocation* pAllocation,
    VmaAllocationInfo* pAllocationInfo)
{
    
# 16205 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16205 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pBufferCreateInfo && pAllocationCreateInfo && VmaIsPow2(minAlignment) && pBuffer && pAllocation
# 16205 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16205 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pBufferCreateInfo && pAllocationCreateInfo && VmaIsPow2(minAlignment) && pBuffer && pAllocation"
# 16205 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16205),0))
# 16205 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                           ;

    if(pBufferCreateInfo->size == 0)
    {
        return VK_ERROR_INITIALIZATION_FAILED;
    }
    if((pBufferCreateInfo->usage & VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT_COPY) != 0 &&
        !allocator->m_UseKhrBufferDeviceAddress)
    {
        
# 16214 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 16214 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Creating a buffer with VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT is not valid if VMA_ALLOCATOR_CREATE_BUFFER_DEVICE_ADDRESS_BIT was not used."
# 16214 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 16214 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Creating a buffer with VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT is not valid if VMA_ALLOCATOR_CREATE_BUFFER_DEVICE_ADDRESS_BIT was not used.\""
# 16214 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16214),0))
# 16214 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                                                       ;
        return VK_ERROR_INITIALIZATION_FAILED;
    }

    ;

   

    *pBuffer = 
# 16222 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
              nullptr
# 16222 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            ;
    *pAllocation = 
# 16223 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                  nullptr
# 16223 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                ;


    VkResult res = (*allocator->GetVulkanFunctions().vkCreateBuffer)(
        allocator->m_hDevice,
        pBufferCreateInfo,
        allocator->GetAllocationCallbacks(),
        pBuffer);
    if(res >= 0)
    {

        VkMemoryRequirements vkMemReq = {};
        bool requiresDedicatedAllocation = false;
        bool prefersDedicatedAllocation = false;
        allocator->GetBufferMemoryRequirements(*pBuffer, vkMemReq,
            requiresDedicatedAllocation, prefersDedicatedAllocation);


        vkMemReq.alignment = ((std::max)((vkMemReq.alignment), (minAlignment)));


        res = allocator->AllocateMemory(
            vkMemReq,
            requiresDedicatedAllocation,
            prefersDedicatedAllocation,
            *pBuffer,
            
# 16249 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
           nullptr
# 16249 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                         ,
            VmaBufferImageUsage(*pBufferCreateInfo, allocator->m_UseKhrMaintenance5),
            *pAllocationCreateInfo,
            VMA_SUBALLOCATION_TYPE_BUFFER,
            1,
            pAllocation);

        if(res >= 0)
        {

            if((pAllocationCreateInfo->flags & VMA_ALLOCATION_CREATE_DONT_BIND_BIT) == 0)
            {
                res = allocator->BindBufferMemory(*pAllocation, 0, *pBuffer, nullptr);
            }
            if(res >= 0)
            {


                    (*pAllocation)->InitBufferUsage(*pBufferCreateInfo, allocator->m_UseKhrMaintenance5);

                if(pAllocationInfo != nullptr)
                {
                    allocator->GetAllocationInfo(*pAllocation, pAllocationInfo);
                }

                return VK_SUCCESS;
            }
            allocator->FreeMemory(
                1,
                pAllocation);
            *pAllocation = 
# 16279 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                          nullptr
# 16279 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                        ;
            (*allocator->GetVulkanFunctions().vkDestroyBuffer)(allocator->m_hDevice, *pBuffer, allocator->GetAllocationCallbacks());
            *pBuffer = 
# 16281 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                      nullptr
# 16281 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                    ;
            return res;
        }
        (*allocator->GetVulkanFunctions().vkDestroyBuffer)(allocator->m_hDevice, *pBuffer, allocator->GetAllocationCallbacks());
        *pBuffer = 
# 16285 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                  nullptr
# 16285 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                ;
        return res;
    }
    return res;
}

 VkResult vmaCreateAliasingBuffer(
    VmaAllocator allocator,
    VmaAllocation allocation,
    const VkBufferCreateInfo* pBufferCreateInfo,
    VkBuffer * pBuffer)
{
    return vmaCreateAliasingBuffer2(allocator, allocation, 0, pBufferCreateInfo, pBuffer);
}

 VkResult vmaCreateAliasingBuffer2(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VkDeviceSize allocationLocalOffset,
    const VkBufferCreateInfo* pBufferCreateInfo,
    VkBuffer * pBuffer)
{
    
# 16307 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16307 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pBufferCreateInfo && pBuffer && allocation
# 16307 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16307 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pBufferCreateInfo && pBuffer && allocation"
# 16307 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16307),0))
# 16307 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                      ;
    
# 16308 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16308 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocationLocalOffset + pBufferCreateInfo->size <= allocation->GetSize()
# 16308 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16308 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocationLocalOffset + pBufferCreateInfo->size <= allocation->GetSize()"
# 16308 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16308),0))
# 16308 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                       ;

    ;

    *pBuffer = 
# 16312 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
              nullptr
# 16312 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                            ;

    if (pBufferCreateInfo->size == 0)
    {
        return VK_ERROR_INITIALIZATION_FAILED;
    }
    if ((pBufferCreateInfo->usage & VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT_COPY) != 0 &&
        !allocator->m_UseKhrBufferDeviceAddress)
    {
        
# 16321 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 16321 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       0 && "Creating a buffer with VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT is not valid if VMA_ALLOCATOR_CREATE_BUFFER_DEVICE_ADDRESS_BIT was not used."
# 16321 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       )) || (_assert(
# 16321 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "0 && \"Creating a buffer with VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT is not valid if VMA_ALLOCATOR_CREATE_BUFFER_DEVICE_ADDRESS_BIT was not used.\""
# 16321 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16321),0))
# 16321 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                                                                                       ;
        return VK_ERROR_INITIALIZATION_FAILED;
    }

   


    VkResult res = (*allocator->GetVulkanFunctions().vkCreateBuffer)(
        allocator->m_hDevice,
        pBufferCreateInfo,
        allocator->GetAllocationCallbacks(),
        pBuffer);
    if (res >= 0)
    {

        res = allocator->BindBufferMemory(allocation, allocationLocalOffset, *pBuffer, nullptr);
        if (res >= 0)
        {
            return VK_SUCCESS;
        }
        (*allocator->GetVulkanFunctions().vkDestroyBuffer)(allocator->m_hDevice, *pBuffer, allocator->GetAllocationCallbacks());
    }
    return res;
}

 void vmaDestroyBuffer(
    VmaAllocator allocator,
    VkBuffer buffer,
    VmaAllocation allocation)
{
    
# 16351 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16351 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator
# 16351 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16351 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator"
# 16351 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16351),0))
# 16351 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;

    if(buffer == 
# 16353 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                nullptr 
# 16353 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                               && allocation == 
# 16353 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                nullptr
# 16353 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                              )
    {
        return;
    }

    ;

   

    if(buffer != 
# 16362 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                nullptr
# 16362 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                              )
    {
        (*allocator->GetVulkanFunctions().vkDestroyBuffer)(allocator->m_hDevice, buffer, allocator->GetAllocationCallbacks());
    }

    if(allocation != 
# 16367 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                    nullptr
# 16367 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                  )
    {
        allocator->FreeMemory(
            1,
            &allocation);
    }
}

 VkResult vmaCreateImage(
    VmaAllocator allocator,
    const VkImageCreateInfo* pImageCreateInfo,
    const VmaAllocationCreateInfo* pAllocationCreateInfo,
    VkImage* pImage,
    VmaAllocation* pAllocation,
    VmaAllocationInfo* pAllocationInfo)
{
    
# 16383 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16383 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pImageCreateInfo && pAllocationCreateInfo && pImage && pAllocation
# 16383 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16383 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pImageCreateInfo && pAllocationCreateInfo && pImage && pAllocation"
# 16383 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16383),0))
# 16383 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                              ;

    if(pImageCreateInfo->extent.width == 0 ||
        pImageCreateInfo->extent.height == 0 ||
        pImageCreateInfo->extent.depth == 0 ||
        pImageCreateInfo->mipLevels == 0 ||
        pImageCreateInfo->arrayLayers == 0)
    {
        return VK_ERROR_INITIALIZATION_FAILED;
    }

    ;

   

    *pImage = 
# 16398 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
             nullptr
# 16398 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                           ;
    *pAllocation = 
# 16399 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                  nullptr
# 16399 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                ;


    VkResult res = (*allocator->GetVulkanFunctions().vkCreateImage)(
        allocator->m_hDevice,
        pImageCreateInfo,
        allocator->GetAllocationCallbacks(),
        pImage);
    if(res == VK_SUCCESS)
    {
        VmaSuballocationType suballocType = pImageCreateInfo->tiling == VK_IMAGE_TILING_OPTIMAL ?
            VMA_SUBALLOCATION_TYPE_IMAGE_OPTIMAL :
            VMA_SUBALLOCATION_TYPE_IMAGE_LINEAR;


        VkMemoryRequirements vkMemReq = {};
        bool requiresDedicatedAllocation = false;
        bool prefersDedicatedAllocation = false;
        allocator->GetImageMemoryRequirements(*pImage, vkMemReq,
            requiresDedicatedAllocation, prefersDedicatedAllocation);

        res = allocator->AllocateMemory(
            vkMemReq,
            requiresDedicatedAllocation,
            prefersDedicatedAllocation,
            
# 16424 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
           nullptr
# 16424 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                         ,
            *pImage,
            VmaBufferImageUsage(*pImageCreateInfo),
            *pAllocationCreateInfo,
            suballocType,
            1,
            pAllocation);

        if(res == VK_SUCCESS)
        {

            if((pAllocationCreateInfo->flags & VMA_ALLOCATION_CREATE_DONT_BIND_BIT) == 0)
            {
                res = allocator->BindImageMemory(*pAllocation, 0, *pImage, nullptr);
            }
            if(res == VK_SUCCESS)
            {


                    (*pAllocation)->InitImageUsage(*pImageCreateInfo);

                if(pAllocationInfo != nullptr)
                {
                    allocator->GetAllocationInfo(*pAllocation, pAllocationInfo);
                }

                return VK_SUCCESS;
            }
            allocator->FreeMemory(
                1,
                pAllocation);
            *pAllocation = 
# 16455 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                          nullptr
# 16455 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                        ;
            (*allocator->GetVulkanFunctions().vkDestroyImage)(allocator->m_hDevice, *pImage, allocator->GetAllocationCallbacks());
            *pImage = 
# 16457 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                     nullptr
# 16457 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                   ;
            return res;
        }
        (*allocator->GetVulkanFunctions().vkDestroyImage)(allocator->m_hDevice, *pImage, allocator->GetAllocationCallbacks());
        *pImage = 
# 16461 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                 nullptr
# 16461 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                               ;
        return res;
    }
    return res;
}

 VkResult vmaCreateAliasingImage(
    VmaAllocator allocator,
    VmaAllocation allocation,
    const VkImageCreateInfo* pImageCreateInfo,
    VkImage * pImage)
{
    return vmaCreateAliasingImage2(allocator, allocation, 0, pImageCreateInfo, pImage);
}

 VkResult vmaCreateAliasingImage2(
    VmaAllocator allocator,
    VmaAllocation allocation,
    VkDeviceSize allocationLocalOffset,
    const VkImageCreateInfo* pImageCreateInfo,
    VkImage * pImage)
{
    
# 16483 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16483 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator && pImageCreateInfo && pImage && allocation
# 16483 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16483 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator && pImageCreateInfo && pImage && allocation"
# 16483 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16483),0))
# 16483 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                    ;

    *pImage = 
# 16485 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
             nullptr
# 16485 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                           ;

    ;

    if (pImageCreateInfo->extent.width == 0 ||
        pImageCreateInfo->extent.height == 0 ||
        pImageCreateInfo->extent.depth == 0 ||
        pImageCreateInfo->mipLevels == 0 ||
        pImageCreateInfo->arrayLayers == 0)
    {
        return VK_ERROR_INITIALIZATION_FAILED;
    }

   


    VkResult res = (*allocator->GetVulkanFunctions().vkCreateImage)(
        allocator->m_hDevice,
        pImageCreateInfo,
        allocator->GetAllocationCallbacks(),
        pImage);
    if (res >= 0)
    {

        res = allocator->BindImageMemory(allocation, allocationLocalOffset, *pImage, nullptr);
        if (res >= 0)
        {
            return VK_SUCCESS;
        }
        (*allocator->GetVulkanFunctions().vkDestroyImage)(allocator->m_hDevice, *pImage, allocator->GetAllocationCallbacks());
    }
    return res;
}

 void vmaDestroyImage(
    VmaAllocator allocator,
    VkImage image,
    VmaAllocation allocation)
{
    
# 16524 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16524 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   allocator
# 16524 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16524 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "allocator"
# 16524 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16524),0))
# 16524 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                        ;

    if(image == 
# 16526 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
               nullptr 
# 16526 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                              && allocation == 
# 16526 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                               nullptr
# 16526 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                             )
    {
        return;
    }

    ;

   

    if(image != 
# 16535 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
               nullptr
# 16535 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                             )
    {
        (*allocator->GetVulkanFunctions().vkDestroyImage)(allocator->m_hDevice, image, allocator->GetAllocationCallbacks());
    }
    if(allocation != 
# 16539 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                    nullptr
# 16539 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                  )
    {
        allocator->FreeMemory(
            1,
            &allocation);
    }
}

 VkResult vmaCreateVirtualBlock(
    const VmaVirtualBlockCreateInfo* pCreateInfo,
    VmaVirtualBlock * pVirtualBlock)
{
    
# 16551 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16551 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pCreateInfo && pVirtualBlock
# 16551 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16551 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pCreateInfo && pVirtualBlock"
# 16551 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16551),0))
# 16551 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                           ;
    
# 16552 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16552 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   pCreateInfo->size > 0
# 16552 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16552 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "pCreateInfo->size > 0"
# 16552 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16552),0))
# 16552 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                    ;
    ;
    ;
    *pVirtualBlock = new(VmaAllocate<VmaVirtualBlock_T>(pCreateInfo->pAllocationCallbacks))(VmaVirtualBlock_T)(*pCreateInfo);
    VkResult res = (*pVirtualBlock)->Init();
    if(res < 0)
    {
        vma_delete(pCreateInfo->pAllocationCallbacks, *pVirtualBlock);
        *pVirtualBlock = 
# 16560 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                        nullptr
# 16560 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                      ;
    }
    return res;
}

 void vmaDestroyVirtualBlock(VmaVirtualBlock virtualBlock)
{
    if(virtualBlock != 
# 16567 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                      nullptr
# 16567 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                    )
    {
        ;
        ;
        VkAllocationCallbacks allocationCallbacks = virtualBlock->m_AllocationCallbacks;
        vma_delete(&allocationCallbacks, virtualBlock);
    }
}

 VkBool32 vmaIsVirtualBlockEmpty(VmaVirtualBlock virtualBlock)
{
    
# 16578 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16578 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   virtualBlock != 
# 16578 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   nullptr)) || (_assert(
# 16578 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "virtualBlock != nullptr"
# 16578 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16578),0))
# 16578 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                             ;
    ;
    ;
    return virtualBlock->IsEmpty() ? 
# 16581 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                    1U 
# 16581 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                            : 
# 16581 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                              0U
# 16581 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                      ;
}

 void vmaGetVirtualAllocationInfo(VmaVirtualBlock virtualBlock,
    VmaVirtualAllocation allocation, VmaVirtualAllocationInfo* pVirtualAllocInfo)
{
    
# 16587 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16587 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   virtualBlock != 
# 16587 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   nullptr 
# 16587 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   && pVirtualAllocInfo != nullptr
# 16587 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16587 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "virtualBlock != nullptr && pVirtualAllocInfo != nullptr"
# 16587 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16587),0))
# 16587 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                              ;
    ;
    ;
    virtualBlock->GetAllocationInfo(allocation, *pVirtualAllocInfo);
}

 VkResult vmaVirtualAllocate(VmaVirtualBlock virtualBlock,
    const VmaVirtualAllocationCreateInfo* pCreateInfo, VmaVirtualAllocation * pAllocation,
    VkDeviceSize* pOffset)
{
    
# 16597 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16597 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   virtualBlock != 
# 16597 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   nullptr 
# 16597 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   && pCreateInfo != nullptr && pAllocation != nullptr
# 16597 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16597 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "virtualBlock != nullptr && pCreateInfo != nullptr && pAllocation != nullptr"
# 16597 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16597),0))
# 16597 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                                                   ;
    ;
    ;
    return virtualBlock->Allocate(*pCreateInfo, *pAllocation, pOffset);
}

 void vmaVirtualFree(VmaVirtualBlock virtualBlock, VmaVirtualAllocation allocation)
{
    if(allocation != 
# 16605 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                    nullptr
# 16605 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                  )
    {
        
# 16607 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 16607 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       virtualBlock != 
# 16607 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
       nullptr)) || (_assert(
# 16607 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "virtualBlock != nullptr"
# 16607 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16607),0))
# 16607 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                 ;
        ;
        ;
        virtualBlock->Free(allocation);
    }
}

 void vmaClearVirtualBlock(VmaVirtualBlock virtualBlock)
{
    
# 16616 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16616 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   virtualBlock != 
# 16616 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   nullptr)) || (_assert(
# 16616 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "virtualBlock != nullptr"
# 16616 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16616),0))
# 16616 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                             ;
    ;
    ;
    virtualBlock->Clear();
}

 void vmaSetVirtualAllocationUserData(VmaVirtualBlock virtualBlock,
    VmaVirtualAllocation allocation, void* pUserData)
{
    
# 16625 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16625 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   virtualBlock != 
# 16625 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   nullptr)) || (_assert(
# 16625 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "virtualBlock != nullptr"
# 16625 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16625),0))
# 16625 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                             ;
    ;
    ;
    virtualBlock->SetAllocationUserData(allocation, pUserData);
}

 void vmaGetVirtualBlockStatistics(VmaVirtualBlock virtualBlock,
    VmaStatistics* pStats)
{
    
# 16634 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16634 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   virtualBlock != 
# 16634 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   nullptr 
# 16634 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   && pStats != nullptr
# 16634 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16634 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "virtualBlock != nullptr && pStats != nullptr"
# 16634 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16634),0))
# 16634 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                   ;
    ;
    ;
    virtualBlock->GetStatistics(*pStats);
}

 void vmaCalculateVirtualBlockStatistics(VmaVirtualBlock virtualBlock,
    VmaDetailedStatistics* pStats)
{
    
# 16643 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16643 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   virtualBlock != 
# 16643 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   nullptr 
# 16643 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   && pStats != nullptr
# 16643 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16643 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "virtualBlock != nullptr && pStats != nullptr"
# 16643 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16643),0))
# 16643 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                   ;
    ;
    ;
    virtualBlock->CalculateDetailedStatistics(*pStats);
}



 void vmaBuildVirtualBlockStatsString(VmaVirtualBlock virtualBlock,
    char* * ppStatsString, VkBool32 detailedMap)
{
    
# 16654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   (void) ((!!(
# 16654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   virtualBlock != 
# 16654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
   nullptr 
# 16654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   && ppStatsString != nullptr
# 16654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   )) || (_assert(
# 16654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
   "virtualBlock != nullptr && ppStatsString != nullptr"
# 16654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
   ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16654),0))
# 16654 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                                          ;
    ;
    const VkAllocationCallbacks* allocationCallbacks = virtualBlock->GetAllocationCallbacks();
    VmaStringBuilder sb(allocationCallbacks);
    virtualBlock->BuildStatsString(detailedMap != 
# 16658 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
                                                 0U
# 16658 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                         , sb);
    *ppStatsString = VmaCreateStringCopy(allocationCallbacks, sb.GetData(), sb.GetLength());
}

 void vmaFreeVirtualBlockStatsString(VmaVirtualBlock virtualBlock,
    char* pStatsString)
{
    if(pStatsString != nullptr)
    {
        
# 16667 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       (void) ((!!(
# 16667 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       virtualBlock != 
# 16667 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3 4
       nullptr)) || (_assert(
# 16667 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
       "virtualBlock != nullptr"
# 16667 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h" 3
       ,"C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h",16667),0))
# 16667 "C:/Users/darkg/HAG/imr_mesh/VulkanMemoryAllocator/include/vk_mem_alloc.h"
                                                 ;
        ;
        VmaFreeString(virtualBlock->GetAllocationCallbacks(), pStatsString);
    }
}
# 4 "C:/Users/darkg/HAG/imr_mesh/imr/src/vma.cpp" 2
